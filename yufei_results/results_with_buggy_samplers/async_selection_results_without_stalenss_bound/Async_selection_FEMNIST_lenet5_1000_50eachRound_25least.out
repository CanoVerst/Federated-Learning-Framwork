[INFO][12:36:09]: [Server #615782] Started training on 1000 clients with 50 per round.
[INFO][12:36:09]: [Server #615782] Configuring the server...
[INFO][12:36:09]: Training: 100 rounds or accuracy above 98.0%

[INFO][12:36:09]: Trainer: basic
[INFO][12:36:09]: Algorithm: fedavg
[INFO][12:36:09]: Data source: FEMNIST
[INFO][12:36:20]: Starting client #1's process.
[INFO][12:36:20]: Starting client #2's process.
[INFO][12:36:21]: Setting the random seed for selecting clients: 1
[INFO][12:36:21]: Starting a server at address 127.0.0.1 and port 6300.
[INFO][12:36:23]: Client: simple
[INFO][12:36:23]: Starting a simple client #1.
[INFO][12:36:23]: Trainer: basic
[INFO][12:36:23]: Algorithm: fedavg
[INFO][12:36:23]: Client: simple
[INFO][12:36:23]: Starting a simple client #2.
[INFO][12:36:23]: Trainer: basic
[INFO][12:36:23]: Algorithm: fedavg
[INFO][12:36:28]: [Client #1] Contacting the server.
[INFO][12:36:28]: [Client #1] Connecting to the server at http://127.0.0.1:6300.
[INFO][12:36:28]: 127.0.0.1 [08/Jul/2022:16:36:28 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1657298188.021092 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.1"
[INFO][12:36:28]: [Client #2] Contacting the server.
[INFO][12:36:28]: [Client #2] Connecting to the server at http://127.0.0.1:6300.
[INFO][12:36:28]: [Server #615782] A new client just connected.
[INFO][12:36:28]: [Client #1] Connected to the server.
[INFO][12:36:28]: [Client #1] Waiting to be selected.
[INFO][12:36:28]: 127.0.0.1 [08/Jul/2022:16:36:28 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1657298188.0310845 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.1"
[INFO][12:36:28]: [Server #615782] New client with id #1 arrived.
[INFO][12:36:28]: [Server #615782] A new client just connected.
[INFO][12:36:28]: [Client #2] Connected to the server.
[INFO][12:36:28]: [Client #2] Waiting to be selected.
[INFO][12:36:28]: [Server #615782] New client with id #2 arrived.
[INFO][12:36:28]: [Server #615782] Starting training.
[INFO][12:36:28]: [93m[1m
[Server #615782] Starting round 1/100.[0m
======== Running on http://127.0.0.1:6300 ========
(Press CTRL+C to quit)
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.6009e+00  1e+03  1e+00  1e+00
 1:  7.5249e+00  6.6020e+00  1e+01  1e-02  1e-02
 2:  7.6002e+00  6.6912e+00  1e+00  9e-05  9e-05
 3:  7.6009e+00  7.5207e+00  8e-02  4e-07  4e-07
 4:  7.6009e+00  7.6001e+00  8e-04  3e-09  3e-09
 5:  7.6009e+00  7.6009e+00  8e-06  3e-11  3e-11
 6:  7.6009e+00  7.6009e+00  8e-08  3e-13  3e-13
Optimal solution found.
The calculated probability is:  [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
 0.001 0.001 0.001 0.001]
current clients pool:  [INFO][12:36:29]: [Server #615782] Selected clients: [326 890 752 763 470 211  42 322  38 694 671 431 768 537  40 135 194 336
  53 606 513 618 433 848 455  16 874 657 824 952  51 236  64 422 864  82
 474 126 773 842  44 487 240 953 944 614 974 345 898 435]
[INFO][12:36:29]: [Server #615782] Selecting client #326 for training.
[INFO][12:36:29]: [Server #615782] Sending the current model to client #326 (simulated).
[INFO][12:36:29]: [Server #615782] Sending 0.26 MB of payload data to client #326 (simulated).
[INFO][12:36:29]: [Server #615782] Selecting client #890 for training.
[INFO][12:36:29]: [Server #615782] Sending the current model to client #890 (simulated).
[INFO][12:36:29]: [Server #615782] Sending 0.26 MB of payload data to client #890 (simulated).
[INFO][12:36:29]: [Client #326] Selected by the server.
[INFO][12:36:29]: [Client #326] Loading its data source...
[INFO][12:36:29]: Data source: FEMNIST
[INFO][12:36:29]: [Client #890] Selected by the server.
[INFO][12:36:29]: [Client #890] Loading its data source...
[INFO][12:36:29]: Data source: FEMNIST
[INFO][12:36:29]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:36:29]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/890.zip.
[INFO][12:36:29]: [Client #326] Dataset size: 135
[INFO][12:36:29]: [Client #326] Sampler: all_inclusive
[INFO][12:36:29]: [Client #326] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:29]: [93m[1m[Client #326] Started training in communication round #1.[0m
2.8%5.6%8.4%11.2%14.0%16.8%19.6%22.4%25.2%28.1%30.9%33.7%36.5%39.3%42.1%44.9%47.7%50.5%53.3%56.1%58.9%61.7%64.5%67.3%70.1%72.9%75.7%78.6%81.4%84.2%87.0%89.8%92.6%95.4%98.2%100.0%[INFO][12:36:30]: Decompressing the dataset downloaded.
[INFO][12:36:30]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/890.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:36:30]: [Client #890] Dataset size: 161
[INFO][12:36:30]: [Client #890] Sampler: all_inclusive
[INFO][12:36:30]: [Client #890] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:30]: [93m[1m[Client #890] Started training in communication round #1.[0m

[INFO][12:36:31]: [Client #326] Loading the dataset.
[INFO][12:36:32]: [Client #890] Loading the dataset.
[INFO][12:36:37]: [Client #326] Epoch: [1/5][0/14]	Loss: 4.113837
[INFO][12:36:37]: [Client #326] Epoch: [1/5][10/14]	Loss: 4.123139
[INFO][12:36:37]: [Client #326] Going to sleep for 0.91 seconds.
[INFO][12:36:37]: [Client #890] Epoch: [1/5][0/17]	Loss: 4.110315
[INFO][12:36:37]: [Client #890] Epoch: [1/5][10/17]	Loss: 4.079903
[INFO][12:36:37]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][12:36:38]: [Client #890] Woke up.
[INFO][12:36:38]: [Client #890] Epoch: [2/5][0/17]	Loss: 4.041406
[INFO][12:36:38]: [Client #890] Epoch: [2/5][10/17]	Loss: 3.874117
[INFO][12:36:38]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][12:36:38]: [Client #326] Woke up.
[INFO][12:36:38]: [Client #326] Epoch: [2/5][0/14]	Loss: 3.990210
[INFO][12:36:38]: [Client #326] Epoch: [2/5][10/14]	Loss: 4.040091
[INFO][12:36:38]: [Client #326] Going to sleep for 0.91 seconds.
[INFO][12:36:38]: [Client #890] Woke up.
[INFO][12:36:38]: [Client #890] Epoch: [3/5][0/17]	Loss: 3.446486
[INFO][12:36:39]: [Client #890] Epoch: [3/5][10/17]	Loss: 3.713160
[INFO][12:36:39]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][12:36:39]: [Client #326] Woke up.
[INFO][12:36:39]: [Client #326] Epoch: [3/5][0/14]	Loss: 3.838844
[INFO][12:36:39]: [Client #326] Epoch: [3/5][10/14]	Loss: 4.114854
[INFO][12:36:39]: [Client #326] Going to sleep for 0.91 seconds.
[INFO][12:36:39]: [Client #890] Woke up.
[INFO][12:36:39]: [Client #890] Epoch: [4/5][0/17]	Loss: 3.369725
[INFO][12:36:39]: [Client #890] Epoch: [4/5][10/17]	Loss: 3.413249
[INFO][12:36:39]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][12:36:40]: [Client #890] Woke up.
[INFO][12:36:40]: [Client #890] Epoch: [5/5][0/17]	Loss: 3.587827
[INFO][12:36:40]: [Client #890] Epoch: [5/5][10/17]	Loss: 2.969131
[INFO][12:36:40]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][12:36:40]: [Client #326] Woke up.
[INFO][12:36:40]: [Client #326] Epoch: [4/5][0/14]	Loss: 3.525432
[INFO][12:36:40]: [Client #326] Epoch: [4/5][10/14]	Loss: 3.921142
[INFO][12:36:40]: [Client #326] Going to sleep for 0.91 seconds.
[INFO][12:36:41]: [Client #890] Woke up.
[INFO][12:36:41]: [Client #890] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_890_615875.pth.
[INFO][12:36:41]: [Client #326] Woke up.
[INFO][12:36:41]: [Client #326] Epoch: [5/5][0/14]	Loss: 3.409196
[INFO][12:36:41]: [Client #326] Epoch: [5/5][10/14]	Loss: 4.380626
[INFO][12:36:41]: [Client #326] Going to sleep for 0.91 seconds.
[INFO][12:36:41]: [Client #890] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_890_615875.pth.
[INFO][12:36:41]: [Client #890] Model trained.
[INFO][12:36:41]: [Client #890] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:36:41]: [Server #615782] Received 0.26 MB of payload data from client #890 (simulated).
[INFO][12:36:42]: [Client #326] Woke up.
[INFO][12:36:42]: [Client #326] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_326_615874.pth.
[INFO][12:36:43]: [Client #326] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_326_615874.pth.
[INFO][12:36:43]: [Client #326] Model trained.
[INFO][12:36:43]: [Client #326] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:36:43]: [Server #615782] Received 0.26 MB of payload data from client #326 (simulated).
[INFO][12:36:43]: [Server #615782] Selecting client #752 for training.
[INFO][12:36:43]: [Server #615782] Sending the current model to client #752 (simulated).
[INFO][12:36:43]: [Server #615782] Sending 0.26 MB of payload data to client #752 (simulated).
[INFO][12:36:43]: [Server #615782] Selecting client #763 for training.
[INFO][12:36:43]: [Server #615782] Sending the current model to client #763 (simulated).
[INFO][12:36:43]: [Server #615782] Sending 0.26 MB of payload data to client #763 (simulated).
[INFO][12:36:43]: [Client #752] Selected by the server.
[INFO][12:36:43]: [Client #752] Loading its data source...
[INFO][12:36:43]: Data source: FEMNIST
[INFO][12:36:43]: [Client #763] Selected by the server.
[INFO][12:36:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:36:43]: [Client #763] Loading its data source...
[INFO][12:36:43]: Data source: FEMNIST
[INFO][12:36:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/752.zip.
[INFO][12:36:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:36:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/763.zip.
2.6%5.1%7.7%10.3%12.8%15.4%17.9%20.5%23.1%25.6%28.2%30.8%33.3%35.9%38.4%41.0%43.6%46.1%48.7%51.3%53.8%56.4%58.9%61.5%64.1%66.6%69.2%71.8%74.3%76.9%79.5%82.0%84.6%87.1%89.7%92.3%94.8%97.4%100.0%100.0%[INFO][12:36:43]: Decompressing the dataset downloaded.
[INFO][12:36:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/763.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
2.9%5.8%8.7%11.6%14.5%17.4%20.3%23.3%26.2%29.1%32.0%34.9%37.8%40.7%43.6%46.5%49.4%52.3%55.2%58.1%61.0%63.9%66.8%69.8%72.7%75.6%78.5%81.4%84.3%87.2%90.1%93.0%95.9%98.8%[INFO][12:36:43]: [Client #763] Dataset size: 153
[INFO][12:36:43]: [Client #763] Sampler: all_inclusive
100.0%[INFO][12:36:43]: Decompressing the dataset downloaded.
[INFO][12:36:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/752.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:36:43]: [Client #763] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:43]: [93m[1m[Client #763] Started training in communication round #1.[0m

[INFO][12:36:43]: [Client #752] Dataset size: 161
[INFO][12:36:43]: [Client #752] Sampler: all_inclusive
[INFO][12:36:43]: [Client #752] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:43]: [93m[1m[Client #752] Started training in communication round #1.[0m

[INFO][12:36:45]: [Client #763] Loading the dataset.
[INFO][12:36:45]: [Client #752] Loading the dataset.
[INFO][12:36:51]: [Client #752] Epoch: [1/5][0/17]	Loss: 4.126996
[INFO][12:36:51]: [Client #763] Epoch: [1/5][0/16]	Loss: 4.102703
[INFO][12:36:51]: [Client #763] Epoch: [1/5][10/16]	Loss: 4.071253
[INFO][12:36:51]: [Client #752] Epoch: [1/5][10/17]	Loss: 4.033034
[INFO][12:36:51]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][12:36:51]: [Client #752] Going to sleep for 0.16 seconds.
[INFO][12:36:51]: [Client #752] Woke up.
[INFO][12:36:51]: [Client #752] Epoch: [2/5][0/17]	Loss: 4.025524
[INFO][12:36:51]: [Client #752] Epoch: [2/5][10/17]	Loss: 3.495505
[INFO][12:36:51]: [Client #752] Going to sleep for 0.16 seconds.
[INFO][12:36:51]: [Client #763] Woke up.
[INFO][12:36:51]: [Client #763] Epoch: [2/5][0/16]	Loss: 3.982051
[INFO][12:36:51]: [Client #752] Woke up.
[INFO][12:36:51]: [Client #752] Epoch: [3/5][0/17]	Loss: 3.568140
[INFO][12:36:51]: [Client #763] Epoch: [2/5][10/16]	Loss: 3.733693
[INFO][12:36:51]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][12:36:51]: [Client #752] Epoch: [3/5][10/17]	Loss: 3.868456
[INFO][12:36:51]: [Client #752] Going to sleep for 0.16 seconds.
[INFO][12:36:52]: [Client #752] Woke up.
[INFO][12:36:52]: [Client #752] Epoch: [4/5][0/17]	Loss: 3.315128
[INFO][12:36:52]: [Client #752] Epoch: [4/5][10/17]	Loss: 4.023120
[INFO][12:36:52]: [Client #752] Going to sleep for 0.16 seconds.
[INFO][12:36:52]: [Client #763] Woke up.
[INFO][12:36:52]: [Client #763] Epoch: [3/5][0/16]	Loss: 3.847080
[INFO][12:36:52]: [Client #752] Woke up.
[INFO][12:36:52]: [Client #763] Epoch: [3/5][10/16]	Loss: 3.931195
[INFO][12:36:52]: [Client #752] Epoch: [5/5][0/17]	Loss: 3.776476
[INFO][12:36:52]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][12:36:52]: [Client #752] Epoch: [5/5][10/17]	Loss: 3.407129
[INFO][12:36:52]: [Client #752] Going to sleep for 0.16 seconds.
[INFO][12:36:52]: [Client #752] Woke up.
[INFO][12:36:52]: [Client #752] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_752_615874.pth.
[INFO][12:36:52]: [Client #763] Woke up.
[INFO][12:36:52]: [Client #763] Epoch: [4/5][0/16]	Loss: 3.844373
[INFO][12:36:52]: [Client #763] Epoch: [4/5][10/16]	Loss: 3.276768
[INFO][12:36:52]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][12:36:53]: [Client #752] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_752_615874.pth.
[INFO][12:36:53]: [Client #752] Model trained.
[INFO][12:36:53]: [Client #752] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:36:53]: [Server #615782] Received 0.26 MB of payload data from client #752 (simulated).
[INFO][12:36:53]: [Client #763] Woke up.
[INFO][12:36:53]: [Client #763] Epoch: [5/5][0/16]	Loss: 3.042583
[INFO][12:36:53]: [Client #763] Epoch: [5/5][10/16]	Loss: 3.735475
[INFO][12:36:53]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][12:36:53]: [Client #763] Woke up.
[INFO][12:36:53]: [Client #763] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_763_615875.pth.
[INFO][12:36:54]: [Client #763] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_763_615875.pth.
[INFO][12:36:54]: [Client #763] Model trained.
[INFO][12:36:54]: [Client #763] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:36:54]: [Server #615782] Received 0.26 MB of payload data from client #763 (simulated).
[INFO][12:36:54]: [Server #615782] Selecting client #470 for training.
[INFO][12:36:54]: [Server #615782] Sending the current model to client #470 (simulated).
[INFO][12:36:54]: [Server #615782] Sending 0.26 MB of payload data to client #470 (simulated).
[INFO][12:36:54]: [Server #615782] Selecting client #211 for training.
[INFO][12:36:54]: [Server #615782] Sending the current model to client #211 (simulated).
[INFO][12:36:54]: [Server #615782] Sending 0.26 MB of payload data to client #211 (simulated).
[INFO][12:36:54]: [Client #470] Selected by the server.
[INFO][12:36:54]: [Client #470] Loading its data source...
[INFO][12:36:54]: [Client #211] Selected by the server.
[INFO][12:36:54]: Data source: FEMNIST
[INFO][12:36:54]: [Client #211] Loading its data source...
[INFO][12:36:54]: Data source: FEMNIST
[INFO][12:36:54]: [Client #211] Dataset size: 250
[INFO][12:36:54]: [Client #211] Sampler: all_inclusive
[INFO][12:36:54]: [Client #211] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:54]: [Client #470] Dataset size: 159
[INFO][12:36:54]: [Client #470] Sampler: all_inclusive
[INFO][12:36:54]: [93m[1m[Client #211] Started training in communication round #1.[0m
[INFO][12:36:54]: [Client #470] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:36:54]: [93m[1m[Client #470] Started training in communication round #1.[0m
[INFO][12:36:56]: [Client #470] Loading the dataset.
[INFO][12:36:56]: [Client #211] Loading the dataset.
[INFO][12:37:02]: [Client #470] Epoch: [1/5][0/16]	Loss: 4.129186
[INFO][12:37:02]: [Client #211] Epoch: [1/5][0/25]	Loss: 4.151510
[INFO][12:37:02]: [Client #470] Epoch: [1/5][10/16]	Loss: 4.179468
[INFO][12:37:02]: [Client #470] Going to sleep for 0.46 seconds.
[INFO][12:37:02]: [Client #211] Epoch: [1/5][10/25]	Loss: 4.077950
[INFO][12:37:02]: [Client #211] Epoch: [1/5][20/25]	Loss: 4.132245
[INFO][12:37:02]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][12:37:02]: [Client #470] Woke up.
[INFO][12:37:02]: [Client #470] Epoch: [2/5][0/16]	Loss: 4.064341
[INFO][12:37:02]: [Client #470] Epoch: [2/5][10/16]	Loss: 4.098508
[INFO][12:37:02]: [Client #470] Going to sleep for 0.46 seconds.
[INFO][12:37:03]: [Client #211] Woke up.
[INFO][12:37:03]: [Client #211] Epoch: [2/5][0/25]	Loss: 3.996566
[INFO][12:37:03]: [Client #211] Epoch: [2/5][10/25]	Loss: 3.790279
[INFO][12:37:03]: [Client #211] Epoch: [2/5][20/25]	Loss: 3.993304
[INFO][12:37:03]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][12:37:03]: [Client #470] Woke up.
[INFO][12:37:03]: [Client #470] Epoch: [3/5][0/16]	Loss: 3.645164
[INFO][12:37:03]: [Client #470] Epoch: [3/5][10/16]	Loss: 3.762396
[INFO][12:37:03]: [Client #470] Going to sleep for 0.46 seconds.
[INFO][12:37:04]: [Client #211] Woke up.
[INFO][12:37:04]: [Client #211] Epoch: [3/5][0/25]	Loss: 3.697451
[INFO][12:37:04]: [Client #470] Woke up.
[INFO][12:37:04]: [Client #470] Epoch: [4/5][0/16]	Loss: 3.372835
[INFO][12:37:04]: [Client #211] Epoch: [3/5][10/25]	Loss: 3.421131
[INFO][12:37:04]: [Client #470] Epoch: [4/5][10/16]	Loss: 3.688546
[INFO][12:37:04]: [Client #470] Going to sleep for 0.46 seconds.
[INFO][12:37:04]: [Client #211] Epoch: [3/5][20/25]	Loss: 3.327783
[INFO][12:37:04]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][12:37:04]: [Client #470] Woke up.
[INFO][12:37:04]: [Client #470] Epoch: [5/5][0/16]	Loss: 3.287525
[INFO][12:37:04]: [Client #470] Epoch: [5/5][10/16]	Loss: 3.201766
[INFO][12:37:04]: [Client #470] Going to sleep for 0.46 seconds.
[INFO][12:37:04]: [Client #211] Woke up.
[INFO][12:37:04]: [Client #211] Epoch: [4/5][0/25]	Loss: 3.192890
[INFO][12:37:04]: [Client #211] Epoch: [4/5][10/25]	Loss: 3.651569
[INFO][12:37:05]: [Client #211] Epoch: [4/5][20/25]	Loss: 3.893861
[INFO][12:37:05]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][12:37:05]: [Client #470] Woke up.
[INFO][12:37:05]: [Client #470] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_470_615874.pth.
[INFO][12:37:05]: [Client #211] Woke up.
[INFO][12:37:05]: [Client #211] Epoch: [5/5][0/25]	Loss: 3.815650
[INFO][12:37:05]: [Client #211] Epoch: [5/5][10/25]	Loss: 3.669241
[INFO][12:37:05]: [Client #211] Epoch: [5/5][20/25]	Loss: 3.546544
[INFO][12:37:05]: [Client #470] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_470_615874.pth.
[INFO][12:37:05]: [Client #470] Model trained.
[INFO][12:37:05]: [Client #470] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:37:05]: [Server #615782] Received 0.26 MB of payload data from client #470 (simulated).
[INFO][12:37:06]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][12:37:06]: [Client #211] Woke up.
[INFO][12:37:06]: [Client #211] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_211_615875.pth.
[INFO][12:37:07]: [Client #211] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_211_615875.pth.
[INFO][12:37:07]: [Client #211] Model trained.
[INFO][12:37:07]: [Client #211] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:37:07]: [Server #615782] Received 0.26 MB of payload data from client #211 (simulated).
[INFO][12:37:07]: [Server #615782] Selecting client #42 for training.
[INFO][12:37:07]: [Server #615782] Sending the current model to client #42 (simulated).
[INFO][12:37:07]: [Server #615782] Sending 0.26 MB of payload data to client #42 (simulated).
[INFO][12:37:07]: [Server #615782] Selecting client #322 for training.
[INFO][12:37:07]: [Server #615782] Sending the current model to client #322 (simulated).
[INFO][12:37:07]: [Server #615782] Sending 0.26 MB of payload data to client #322 (simulated).
[INFO][12:37:07]: [Client #42] Selected by the server.
[INFO][12:37:07]: [Client #42] Loading its data source...
[INFO][12:37:07]: Data source: FEMNIST
[INFO][12:37:07]: [Client #322] Selected by the server.
[INFO][12:37:07]: [Client #322] Loading its data source...
[INFO][12:37:07]: Data source: FEMNIST
[INFO][12:37:07]: [Client #42] Dataset size: 156
[INFO][12:37:07]: [Client #42] Sampler: all_inclusive
[INFO][12:37:07]: [Client #42] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:37:07]: [93m[1m[Client #42] Started training in communication round #1.[0m
[INFO][12:37:07]: [Client #322] Dataset size: 218
[INFO][12:37:07]: [Client #322] Sampler: all_inclusive
[INFO][12:37:07]: [Client #322] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:37:07]: [93m[1m[Client #322] Started training in communication round #1.[0m
[INFO][12:37:09]: [Client #42] Loading the dataset.
[INFO][12:37:09]: [Client #322] Loading the dataset.
[INFO][12:37:14]: [Client #322] Epoch: [1/5][0/22]	Loss: 4.098253
[INFO][12:37:14]: [Client #42] Epoch: [1/5][0/16]	Loss: 4.087193
[INFO][12:37:14]: [Client #322] Epoch: [1/5][10/22]	Loss: 4.078212
[INFO][12:37:15]: [Client #42] Epoch: [1/5][10/16]	Loss: 4.102276
[INFO][12:37:15]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][12:37:15]: [Client #322] Epoch: [1/5][20/22]	Loss: 4.045168
[INFO][12:37:15]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][12:37:16]: [Client #322] Woke up.
[INFO][12:37:16]: [Client #322] Epoch: [2/5][0/22]	Loss: 3.929637
[INFO][12:37:16]: [Client #322] Epoch: [2/5][10/22]	Loss: 4.135735
[INFO][12:37:16]: [Client #322] Epoch: [2/5][20/22]	Loss: 3.988425
[INFO][12:37:16]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][12:37:18]: [Client #42] Woke up.
[INFO][12:37:18]: [Client #42] Epoch: [2/5][0/16]	Loss: 3.963882
[INFO][12:37:18]: [Client #42] Epoch: [2/5][10/16]	Loss: 3.614177
[INFO][12:37:18]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][12:37:18]: [Client #322] Woke up.
[INFO][12:37:18]: [Client #322] Epoch: [3/5][0/22]	Loss: 3.330060
[INFO][12:37:18]: [Client #322] Epoch: [3/5][10/22]	Loss: 3.949539
[INFO][12:37:18]: [Client #322] Epoch: [3/5][20/22]	Loss: 3.734150
[INFO][12:37:18]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][12:37:20]: [Client #322] Woke up.
[INFO][12:37:20]: [Client #322] Epoch: [4/5][0/22]	Loss: 3.823818
[INFO][12:37:20]: [Client #322] Epoch: [4/5][10/22]	Loss: 3.341436
[INFO][12:37:20]: [Client #322] Epoch: [4/5][20/22]	Loss: 3.464648
[INFO][12:37:20]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][12:37:21]: [Client #42] Woke up.
[INFO][12:37:21]: [Client #42] Epoch: [3/5][0/16]	Loss: 3.973448
[INFO][12:37:21]: [Client #42] Epoch: [3/5][10/16]	Loss: 3.925739
[INFO][12:37:21]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][12:37:22]: [Client #322] Woke up.
[INFO][12:37:22]: [Client #322] Epoch: [5/5][0/22]	Loss: 4.016074
[INFO][12:37:22]: [Client #322] Epoch: [5/5][10/22]	Loss: 3.180965
[INFO][12:37:22]: [Client #322] Epoch: [5/5][20/22]	Loss: 3.935437
[INFO][12:37:22]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][12:37:23]: [Client #322] Woke up.
[INFO][12:37:23]: [Client #322] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_615875.pth.
[INFO][12:37:24]: [Client #42] Woke up.
[INFO][12:37:24]: [Client #42] Epoch: [4/5][0/16]	Loss: 3.619782
[INFO][12:37:24]: [Client #42] Epoch: [4/5][10/16]	Loss: 3.391620
[INFO][12:37:24]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][12:37:24]: [Client #322] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_615875.pth.
[INFO][12:37:24]: [Client #322] Model trained.
[INFO][12:37:24]: [Client #322] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:37:24]: [Server #615782] Received 0.26 MB of payload data from client #322 (simulated).
[INFO][12:37:27]: [Client #42] Woke up.
[INFO][12:37:27]: [Client #42] Epoch: [5/5][0/16]	Loss: 3.241840
[INFO][12:37:27]: [Client #42] Epoch: [5/5][10/16]	Loss: 3.463997
[INFO][12:37:27]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][12:37:30]: [Client #42] Woke up.
[INFO][12:37:30]: [Client #42] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_42_615874.pth.
[INFO][12:37:31]: [Client #42] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_42_615874.pth.
[INFO][12:37:31]: [Client #42] Model trained.
[INFO][12:37:31]: [Client #42] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:37:31]: [Server #615782] Received 0.26 MB of payload data from client #42 (simulated).
[INFO][12:37:31]: [Server #615782] Selecting client #38 for training.
[INFO][12:37:31]: [Server #615782] Sending the current model to client #38 (simulated).
[INFO][12:37:31]: [Server #615782] Sending 0.26 MB of payload data to client #38 (simulated).
[INFO][12:37:31]: [Server #615782] Selecting client #694 for training.
[INFO][12:37:31]: [Server #615782] Sending the current model to client #694 (simulated).
[INFO][12:37:31]: [Server #615782] Sending 0.26 MB of payload data to client #694 (simulated).
[INFO][12:37:31]: [Client #38] Selected by the server.
[INFO][12:37:31]: [Client #38] Loading its data source...
[INFO][12:37:31]: Data source: FEMNIST
[INFO][12:37:31]: [Client #694] Selected by the server.
[INFO][12:37:31]: [Client #694] Loading its data source...
[INFO][12:37:31]: Data source: FEMNIST
[INFO][12:37:31]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:37:31]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/694.zip.
[INFO][12:37:31]: [Client #38] Dataset size: 162
[INFO][12:37:31]: [Client #38] Sampler: all_inclusive
[INFO][12:37:31]: [Client #38] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:37:31]: [93m[1m[Client #38] Started training in communication round #1.[0m
2.2%4.5%6.7%9.0%11.2%13.4%15.7%17.9%20.1%22.4%24.6%26.9%29.1%31.3%33.6%35.8%38.0%40.3%42.5%44.8%47.0%49.2%51.5%53.7%55.9%58.2%60.4%62.7%64.9%67.1%69.4%71.6%73.8%76.1%78.3%80.6%82.8%85.0%87.3%89.5%91.7%94.0%96.2%98.5%100.0%[INFO][12:37:31]: Decompressing the dataset downloaded.
[INFO][12:37:31]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/694.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:37:31]: [Client #694] Dataset size: 140
[INFO][12:37:31]: [Client #694] Sampler: all_inclusive
[INFO][12:37:31]: [Client #694] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:37:31]: [93m[1m[Client #694] Started training in communication round #1.[0m

[INFO][12:37:33]: [Client #38] Loading the dataset.
[INFO][12:37:33]: [Client #694] Loading the dataset.
[INFO][12:37:38]: [Client #38] Epoch: [1/5][0/17]	Loss: 4.148633
[INFO][12:37:38]: [Client #694] Epoch: [1/5][0/14]	Loss: 4.066117
[INFO][12:37:38]: [Client #38] Epoch: [1/5][10/17]	Loss: 4.087668
[INFO][12:37:38]: [Client #694] Epoch: [1/5][10/14]	Loss: 4.022934
[INFO][12:37:38]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][12:37:38]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][12:37:39]: [Client #694] Woke up.
[INFO][12:37:39]: [Client #694] Epoch: [2/5][0/14]	Loss: 3.972448
[INFO][12:37:39]: [Client #694] Epoch: [2/5][10/14]	Loss: 3.589710
[INFO][12:37:39]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][12:37:39]: [Client #694] Woke up.
[INFO][12:37:39]: [Client #694] Epoch: [3/5][0/14]	Loss: 3.784943
[INFO][12:37:39]: [Client #694] Epoch: [3/5][10/14]	Loss: 3.797699
[INFO][12:37:39]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][12:37:40]: [Client #694] Woke up.
[INFO][12:37:40]: [Client #694] Epoch: [4/5][0/14]	Loss: 3.218514
[INFO][12:37:40]: [Client #694] Epoch: [4/5][10/14]	Loss: 3.804686
[INFO][12:37:40]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][12:37:40]: [Client #694] Woke up.
[INFO][12:37:40]: [Client #694] Epoch: [5/5][0/14]	Loss: 3.448705
[INFO][12:37:40]: [Client #694] Epoch: [5/5][10/14]	Loss: 3.239758
[INFO][12:37:40]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][12:37:41]: [Client #694] Woke up.
[INFO][12:37:41]: [Client #694] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_694_615875.pth.
[INFO][12:37:41]: [Client #694] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_694_615875.pth.
[INFO][12:37:41]: [Client #694] Model trained.
[INFO][12:37:41]: [Client #694] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:37:41]: [Server #615782] Received 0.26 MB of payload data from client #694 (simulated).
[INFO][12:37:44]: [Client #38] Woke up.
[INFO][12:37:44]: [Client #38] Epoch: [2/5][0/17]	Loss: 3.980572
[INFO][12:37:44]: [Client #38] Epoch: [2/5][10/17]	Loss: 3.865152
[INFO][12:37:44]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][12:37:49]: [Client #38] Woke up.
[INFO][12:37:49]: [Client #38] Epoch: [3/5][0/17]	Loss: 3.434158
[INFO][12:37:49]: [Client #38] Epoch: [3/5][10/17]	Loss: 3.939918
[INFO][12:37:49]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][12:37:54]: [Client #38] Woke up.
[INFO][12:37:54]: [Client #38] Epoch: [4/5][0/17]	Loss: 3.525310
[INFO][12:37:54]: [Client #38] Epoch: [4/5][10/17]	Loss: 4.157990
[INFO][12:37:54]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][12:37:59]: [Client #38] Woke up.
[INFO][12:37:59]: [Client #38] Epoch: [5/5][0/17]	Loss: 2.726844
[INFO][12:37:59]: [Client #38] Epoch: [5/5][10/17]	Loss: 3.462082
[INFO][12:37:59]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][12:38:04]: [Client #38] Woke up.
[INFO][12:38:04]: [Client #38] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_615874.pth.
[INFO][12:38:05]: [Client #38] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_615874.pth.
[INFO][12:38:05]: [Client #38] Model trained.
[INFO][12:38:05]: [Client #38] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:38:05]: [Server #615782] Received 0.26 MB of payload data from client #38 (simulated).
[INFO][12:38:05]: [Server #615782] Selecting client #671 for training.
[INFO][12:38:05]: [Server #615782] Sending the current model to client #671 (simulated).
[INFO][12:38:05]: [Server #615782] Sending 0.26 MB of payload data to client #671 (simulated).
[INFO][12:38:05]: [Server #615782] Selecting client #431 for training.
[INFO][12:38:05]: [Server #615782] Sending the current model to client #431 (simulated).
[INFO][12:38:05]: [Server #615782] Sending 0.26 MB of payload data to client #431 (simulated).
[INFO][12:38:05]: [Client #671] Selected by the server.
[INFO][12:38:05]: [Client #671] Loading its data source...
[INFO][12:38:05]: Data source: FEMNIST
[INFO][12:38:05]: [Client #431] Selected by the server.
[INFO][12:38:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:38:05]: [Client #431] Loading its data source...
[INFO][12:38:05]: Data source: FEMNIST
[INFO][12:38:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/671.zip.
[INFO][12:38:05]: [Client #431] Dataset size: 162
[INFO][12:38:05]: [Client #431] Sampler: all_inclusive
[INFO][12:38:05]: [Client #431] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:38:05]: [93m[1m[Client #431] Started training in communication round #1.[0m
2.6%5.2%7.8%10.4%13.1%15.7%18.3%20.9%23.5%26.1%28.7%31.3%33.9%36.5%39.2%41.8%44.4%47.0%49.6%52.2%54.8%57.4%60.0%62.6%65.3%67.9%70.5%73.1%75.7%78.3%80.9%83.5%86.1%88.7%91.4%94.0%96.6%99.2%100.0%[INFO][12:38:05]: Decompressing the dataset downloaded.
[INFO][12:38:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/671.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:38:05]: [Client #671] Dataset size: 162
[INFO][12:38:05]: [Client #671] Sampler: all_inclusive
[INFO][12:38:05]: [Client #671] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:38:05]: [93m[1m[Client #671] Started training in communication round #1.[0m

[INFO][12:38:07]: [Client #431] Loading the dataset.
[INFO][12:38:07]: [Client #671] Loading the dataset.
[INFO][12:38:13]: [Client #431] Epoch: [1/5][0/17]	Loss: 4.011226
[INFO][12:38:13]: [Client #671] Epoch: [1/5][0/17]	Loss: 4.116673
[INFO][12:38:13]: [Client #431] Epoch: [1/5][10/17]	Loss: 4.031162
[INFO][12:38:13]: [Client #671] Epoch: [1/5][10/17]	Loss: 4.063492
[INFO][12:38:13]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:38:13]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][12:38:14]: [Client #431] Woke up.
[INFO][12:38:14]: [Client #431] Epoch: [2/5][0/17]	Loss: 3.961296
[INFO][12:38:14]: [Client #431] Epoch: [2/5][10/17]	Loss: 2.909986
[INFO][12:38:14]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:38:15]: [Client #431] Woke up.
[INFO][12:38:15]: [Client #431] Epoch: [3/5][0/17]	Loss: 3.118133
[INFO][12:38:15]: [Client #431] Epoch: [3/5][10/17]	Loss: 3.575235
[INFO][12:38:15]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:38:16]: [Client #431] Woke up.
[INFO][12:38:16]: [Client #431] Epoch: [4/5][0/17]	Loss: 3.560659
[INFO][12:38:16]: [Client #431] Epoch: [4/5][10/17]	Loss: 3.571122
[INFO][12:38:16]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:38:17]: [Client #431] Woke up.
[INFO][12:38:17]: [Client #431] Epoch: [5/5][0/17]	Loss: 3.185290
[INFO][12:38:17]: [Client #431] Epoch: [5/5][10/17]	Loss: 2.932719
[INFO][12:38:17]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:38:18]: [Client #431] Woke up.
[INFO][12:38:18]: [Client #431] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_615875.pth.
[INFO][12:38:19]: [Client #431] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_615875.pth.
[INFO][12:38:19]: [Client #431] Model trained.
[INFO][12:38:19]: [Client #431] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:38:19]: [Server #615782] Received 0.26 MB of payload data from client #431 (simulated).
[INFO][12:38:19]: [Client #671] Woke up.
[INFO][12:38:19]: [Client #671] Epoch: [2/5][0/17]	Loss: 3.967754
[INFO][12:38:19]: [Client #671] Epoch: [2/5][10/17]	Loss: 3.331258
[INFO][12:38:20]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][12:38:26]: [Client #671] Woke up.
[INFO][12:38:26]: [Client #671] Epoch: [3/5][0/17]	Loss: 3.711377
[INFO][12:38:26]: [Client #671] Epoch: [3/5][10/17]	Loss: 3.281448
[INFO][12:38:26]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][12:38:32]: [Client #671] Woke up.
[INFO][12:38:32]: [Client #671] Epoch: [4/5][0/17]	Loss: 4.007934
[INFO][12:38:32]: [Client #671] Epoch: [4/5][10/17]	Loss: 2.931717
[INFO][12:38:32]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][12:38:38]: [Client #671] Woke up.
[INFO][12:38:38]: [Client #671] Epoch: [5/5][0/17]	Loss: 3.076011
[INFO][12:38:38]: [Client #671] Epoch: [5/5][10/17]	Loss: 4.022046
[INFO][12:38:38]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][12:38:45]: [Client #671] Woke up.
[INFO][12:38:45]: [Client #671] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_671_615874.pth.
[INFO][12:38:45]: [Client #671] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_671_615874.pth.
[INFO][12:38:45]: [Client #671] Model trained.
[INFO][12:38:45]: [Client #671] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:38:45]: [Server #615782] Received 0.26 MB of payload data from client #671 (simulated).
[INFO][12:38:45]: [Server #615782] Selecting client #768 for training.
[INFO][12:38:45]: [Server #615782] Sending the current model to client #768 (simulated).
[INFO][12:38:45]: [Server #615782] Sending 0.26 MB of payload data to client #768 (simulated).
[INFO][12:38:45]: [Server #615782] Selecting client #537 for training.
[INFO][12:38:45]: [Server #615782] Sending the current model to client #537 (simulated).
[INFO][12:38:45]: [Server #615782] Sending 0.26 MB of payload data to client #537 (simulated).
[INFO][12:38:45]: [Client #768] Selected by the server.
[INFO][12:38:45]: [Client #768] Loading its data source...
[INFO][12:38:45]: Data source: FEMNIST
[INFO][12:38:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:38:45]: [Client #537] Selected by the server.
[INFO][12:38:45]: [Client #537] Loading its data source...
[INFO][12:38:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/768.zip.
[INFO][12:38:45]: Data source: FEMNIST
[INFO][12:38:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:38:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/537.zip.
2.2%4.4%6.5%8.7%10.9%13.1%15.3%17.5%19.6%21.8%24.0%26.2%28.4%30.6%32.7%34.9%37.1%39.3%41.5%43.7%45.8%48.0%50.2%52.4%54.6%56.8%58.9%61.1%63.3%65.5%67.7%69.9%72.0%74.2%76.4%78.6%80.8%83.0%85.1%87.3%89.5%91.7%93.9%96.0%98.2%100.0%[INFO][12:38:46]: Decompressing the dataset downloaded.
[INFO][12:38:46]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/537.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
2.5%5.0%7.5%10.0%12.5%14.9%17.4%19.9%22.4%24.9%27.4%29.9%32.4%34.9%37.4%39.9%42.3%[INFO][12:38:46]: [Client #537] Dataset size: 160
[INFO][12:38:46]: [Client #537] Sampler: all_inclusive
[INFO][12:38:46]: [Client #537] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:38:46]: [93m[1m[Client #537] Started training in communication round #1.[0m

44.8%47.3%49.8%52.3%54.8%57.3%59.8%62.3%64.8%67.2%69.7%72.2%74.7%77.2%79.7%82.2%84.7%87.2%89.7%92.2%94.6%97.1%99.6%100.0%[INFO][12:38:46]: Decompressing the dataset downloaded.
[INFO][12:38:46]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/768.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:38:46]: [Client #768] Dataset size: 157
[INFO][12:38:46]: [Client #768] Sampler: all_inclusive
[INFO][12:38:46]: [Client #768] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:38:46]: [93m[1m[Client #768] Started training in communication round #1.[0m

[INFO][12:38:48]: [Client #768] Loading the dataset.
[INFO][12:38:48]: [Client #537] Loading the dataset.
[INFO][12:38:53]: [Client #768] Epoch: [1/5][0/16]	Loss: 4.133733
[INFO][12:38:53]: [Client #537] Epoch: [1/5][0/16]	Loss: 4.108073
[INFO][12:38:53]: [Client #768] Epoch: [1/5][10/16]	Loss: 4.113008
[INFO][12:38:53]: [Client #768] Going to sleep for 1.30 seconds.
[INFO][12:38:53]: [Client #537] Epoch: [1/5][10/16]	Loss: 4.084529
[INFO][12:38:53]: [Client #537] Going to sleep for 2.02 seconds.
[INFO][12:38:54]: [Client #768] Woke up.
[INFO][12:38:55]: [Client #768] Epoch: [2/5][0/16]	Loss: 4.086096
[INFO][12:38:55]: [Client #768] Epoch: [2/5][10/16]	Loss: 3.660127
[INFO][12:38:55]: [Client #768] Going to sleep for 1.30 seconds.
[INFO][12:38:55]: [Client #537] Woke up.
[INFO][12:38:55]: [Client #537] Epoch: [2/5][0/16]	Loss: 3.955554
[INFO][12:38:55]: [Client #537] Epoch: [2/5][10/16]	Loss: 3.282456
[INFO][12:38:55]: [Client #537] Going to sleep for 2.02 seconds.
[INFO][12:38:56]: [Client #768] Woke up.
[INFO][12:38:56]: [Client #768] Epoch: [3/5][0/16]	Loss: 3.117098
[INFO][12:38:56]: [Client #768] Epoch: [3/5][10/16]	Loss: 3.817525
[INFO][12:38:56]: [Client #768] Going to sleep for 1.30 seconds.
[INFO][12:38:57]: [Client #768] Woke up.
[INFO][12:38:57]: [Client #768] Epoch: [4/5][0/16]	Loss: 3.653249
[INFO][12:38:57]: [Client #537] Woke up.
[INFO][12:38:57]: [Client #768] Epoch: [4/5][10/16]	Loss: 3.339157
[INFO][12:38:57]: [Client #537] Epoch: [3/5][0/16]	Loss: 3.650393
[INFO][12:38:58]: [Client #768] Going to sleep for 1.30 seconds.
[INFO][12:38:58]: [Client #537] Epoch: [3/5][10/16]	Loss: 2.967673
[INFO][12:38:58]: [Client #537] Going to sleep for 2.02 seconds.
[INFO][12:38:59]: [Client #768] Woke up.
[INFO][12:38:59]: [Client #768] Epoch: [5/5][0/16]	Loss: 3.459788
[INFO][12:38:59]: [Client #768] Epoch: [5/5][10/16]	Loss: 3.405864
[INFO][12:38:59]: [Client #768] Going to sleep for 1.30 seconds.
[INFO][12:39:00]: [Client #537] Woke up.
[INFO][12:39:00]: [Client #537] Epoch: [4/5][0/16]	Loss: 3.409761
[INFO][12:39:00]: [Client #537] Epoch: [4/5][10/16]	Loss: 3.469212
[INFO][12:39:00]: [Client #537] Going to sleep for 2.02 seconds.
[INFO][12:39:00]: [Client #768] Woke up.
[INFO][12:39:00]: [Client #768] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_768_615874.pth.
[INFO][12:39:01]: [Client #768] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_768_615874.pth.
[INFO][12:39:01]: [Client #768] Model trained.
[INFO][12:39:01]: [Client #768] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:39:01]: [Server #615782] Received 0.26 MB of payload data from client #768 (simulated).
[INFO][12:39:02]: [Client #537] Woke up.
[INFO][12:39:02]: [Client #537] Epoch: [5/5][0/16]	Loss: 3.430267
[INFO][12:39:02]: [Client #537] Epoch: [5/5][10/16]	Loss: 4.139382
[INFO][12:39:02]: [Client #537] Going to sleep for 2.02 seconds.
[INFO][12:39:04]: [Client #537] Woke up.
[INFO][12:39:04]: [Client #537] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_537_615875.pth.
[INFO][12:39:05]: [Client #537] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_537_615875.pth.
[INFO][12:39:05]: [Client #537] Model trained.
[INFO][12:39:05]: [Client #537] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:39:05]: [Server #615782] Received 0.26 MB of payload data from client #537 (simulated).
[INFO][12:39:05]: [Server #615782] Selecting client #40 for training.
[INFO][12:39:05]: [Server #615782] Sending the current model to client #40 (simulated).
[INFO][12:39:05]: [Server #615782] Sending 0.26 MB of payload data to client #40 (simulated).
[INFO][12:39:05]: [Server #615782] Selecting client #135 for training.
[INFO][12:39:05]: [Server #615782] Sending the current model to client #135 (simulated).
[INFO][12:39:05]: [Server #615782] Sending 0.26 MB of payload data to client #135 (simulated).
[INFO][12:39:05]: [Client #40] Selected by the server.
[INFO][12:39:05]: [Client #40] Loading its data source...
[INFO][12:39:05]: Data source: FEMNIST
[INFO][12:39:05]: [Client #135] Selected by the server.
[INFO][12:39:05]: [Client #135] Loading its data source...
[INFO][12:39:05]: Data source: FEMNIST
[INFO][12:39:05]: [Client #40] Dataset size: 155
[INFO][12:39:05]: [Client #40] Sampler: all_inclusive
[INFO][12:39:05]: [Client #40] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:39:05]: [93m[1m[Client #40] Started training in communication round #1.[0m
[INFO][12:39:05]: [Client #135] Dataset size: 151
[INFO][12:39:05]: [Client #135] Sampler: all_inclusive
[INFO][12:39:05]: [Client #135] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:39:05]: [93m[1m[Client #135] Started training in communication round #1.[0m
[INFO][12:39:07]: [Client #40] Loading the dataset.
[INFO][12:39:07]: [Client #135] Loading the dataset.
[INFO][12:39:12]: [Client #40] Epoch: [1/5][0/16]	Loss: 4.082368
[INFO][12:39:12]: [Client #135] Epoch: [1/5][0/16]	Loss: 4.107493
[INFO][12:39:12]: [Client #40] Epoch: [1/5][10/16]	Loss: 4.109981
[INFO][12:39:12]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][12:39:12]: [Client #135] Epoch: [1/5][10/16]	Loss: 4.104426
[INFO][12:39:12]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:39:15]: [Client #40] Woke up.
[INFO][12:39:15]: [Client #40] Epoch: [2/5][0/16]	Loss: 3.956952
[INFO][12:39:15]: [Client #40] Epoch: [2/5][10/16]	Loss: 3.704750
[INFO][12:39:15]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][12:39:16]: [Client #135] Woke up.
[INFO][12:39:16]: [Client #135] Epoch: [2/5][0/16]	Loss: 4.009529
[INFO][12:39:16]: [Client #135] Epoch: [2/5][10/16]	Loss: 3.759960
[INFO][12:39:16]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:39:18]: [Client #40] Woke up.
[INFO][12:39:18]: [Client #40] Epoch: [3/5][0/16]	Loss: 4.314666
[INFO][12:39:19]: [Client #40] Epoch: [3/5][10/16]	Loss: 3.750141
[INFO][12:39:19]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][12:39:20]: [Client #135] Woke up.
[INFO][12:39:21]: [Client #135] Epoch: [3/5][0/16]	Loss: 3.749051
[INFO][12:39:21]: [Client #135] Epoch: [3/5][10/16]	Loss: 3.677655
[INFO][12:39:21]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:39:22]: [Client #40] Woke up.
[INFO][12:39:22]: [Client #40] Epoch: [4/5][0/16]	Loss: 3.200131
[INFO][12:39:22]: [Client #40] Epoch: [4/5][10/16]	Loss: 3.063456
[INFO][12:39:22]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][12:39:25]: [Client #135] Woke up.
[INFO][12:39:25]: [Client #135] Epoch: [4/5][0/16]	Loss: 3.359544
[INFO][12:39:25]: [Client #40] Woke up.
[INFO][12:39:25]: [Client #40] Epoch: [5/5][0/16]	Loss: 3.416539
[INFO][12:39:25]: [Client #135] Epoch: [4/5][10/16]	Loss: 3.551310
[INFO][12:39:25]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:39:25]: [Client #40] Epoch: [5/5][10/16]	Loss: 3.151998
[INFO][12:39:25]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][12:39:28]: [Client #40] Woke up.
[INFO][12:39:28]: [Client #40] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615874.pth.
[INFO][12:39:29]: [Client #40] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615874.pth.
[INFO][12:39:29]: [Client #40] Model trained.
[INFO][12:39:29]: [Client #40] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:39:29]: [Server #615782] Received 0.26 MB of payload data from client #40 (simulated).
[INFO][12:39:29]: [Client #135] Woke up.
[INFO][12:39:29]: [Client #135] Epoch: [5/5][0/16]	Loss: 3.007063
[INFO][12:39:29]: [Client #135] Epoch: [5/5][10/16]	Loss: 3.968491
[INFO][12:39:29]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:39:33]: [Client #135] Woke up.
[INFO][12:39:33]: [Client #135] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_615875.pth.
[INFO][12:39:34]: [Client #135] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_615875.pth.
[INFO][12:39:34]: [Client #135] Model trained.
[INFO][12:39:34]: [Client #135] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:39:34]: [Server #615782] Received 0.26 MB of payload data from client #135 (simulated).
[INFO][12:39:34]: [Server #615782] Selecting client #194 for training.
[INFO][12:39:34]: [Server #615782] Sending the current model to client #194 (simulated).
[INFO][12:39:34]: [Server #615782] Sending 0.26 MB of payload data to client #194 (simulated).
[INFO][12:39:34]: [Server #615782] Selecting client #336 for training.
[INFO][12:39:34]: [Server #615782] Sending the current model to client #336 (simulated).
[INFO][12:39:34]: [Server #615782] Sending 0.26 MB of payload data to client #336 (simulated).
[INFO][12:39:34]: [Client #194] Selected by the server.
[INFO][12:39:34]: [Client #336] Selected by the server.
[INFO][12:39:34]: [Client #194] Loading its data source...
[INFO][12:39:34]: [Client #336] Loading its data source...
[INFO][12:39:34]: Data source: FEMNIST
[INFO][12:39:34]: Data source: FEMNIST
[INFO][12:39:34]: [Client #336] Dataset size: 160
[INFO][12:39:34]: [Client #336] Sampler: all_inclusive
[INFO][12:39:34]: [Client #336] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:39:34]: [Client #194] Dataset size: 158
[INFO][12:39:34]: [Client #194] Sampler: all_inclusive
[INFO][12:39:34]: [93m[1m[Client #336] Started training in communication round #1.[0m
[INFO][12:39:34]: [Client #194] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:39:34]: [93m[1m[Client #194] Started training in communication round #1.[0m
[INFO][12:39:36]: [Client #336] Loading the dataset.
[INFO][12:39:36]: [Client #194] Loading the dataset.
[INFO][12:39:42]: [Client #194] Epoch: [1/5][0/16]	Loss: 4.140562
[INFO][12:39:42]: [Client #336] Epoch: [1/5][0/16]	Loss: 4.094986
[INFO][12:39:42]: [Client #194] Epoch: [1/5][10/16]	Loss: 4.056655
[INFO][12:39:42]: [Client #336] Epoch: [1/5][10/16]	Loss: 4.080996
[INFO][12:39:42]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:39:42]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][12:39:42]: [Client #336] Woke up.
[INFO][12:39:42]: [Client #336] Epoch: [2/5][0/16]	Loss: 3.942720
[INFO][12:39:42]: [Client #336] Epoch: [2/5][10/16]	Loss: 3.387366
[INFO][12:39:42]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][12:39:42]: [Client #336] Woke up.
[INFO][12:39:42]: [Client #336] Epoch: [3/5][0/16]	Loss: 3.832418
[INFO][12:39:42]: [Client #336] Epoch: [3/5][10/16]	Loss: 3.789310
[INFO][12:39:42]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][12:39:42]: [Client #336] Woke up.
[INFO][12:39:42]: [Client #336] Epoch: [4/5][0/16]	Loss: 3.382483
[INFO][12:39:42]: [Client #336] Epoch: [4/5][10/16]	Loss: 3.287332
[INFO][12:39:42]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][12:39:42]: [Client #336] Woke up.
[INFO][12:39:42]: [Client #336] Epoch: [5/5][0/16]	Loss: 3.499467
[INFO][12:39:42]: [Client #336] Epoch: [5/5][10/16]	Loss: 3.385690
[INFO][12:39:42]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][12:39:42]: [Client #336] Woke up.
[INFO][12:39:43]: [Client #336] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_615875.pth.
[INFO][12:39:43]: [Client #336] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_615875.pth.
[INFO][12:39:43]: [Client #336] Model trained.
[INFO][12:39:43]: [Client #336] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:39:43]: [Server #615782] Received 0.26 MB of payload data from client #336 (simulated).
[INFO][12:39:45]: [Client #194] Woke up.
[INFO][12:39:45]: [Client #194] Epoch: [2/5][0/16]	Loss: 4.017438
[INFO][12:39:45]: [Client #194] Epoch: [2/5][10/16]	Loss: 3.522549
[INFO][12:39:45]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:39:49]: [Client #194] Woke up.
[INFO][12:39:49]: [Client #194] Epoch: [3/5][0/16]	Loss: 3.195576
[INFO][12:39:49]: [Client #194] Epoch: [3/5][10/16]	Loss: 3.919238
[INFO][12:39:49]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:39:52]: [Client #194] Woke up.
[INFO][12:39:52]: [Client #194] Epoch: [4/5][0/16]	Loss: 3.419772
[INFO][12:39:52]: [Client #194] Epoch: [4/5][10/16]	Loss: 3.278537
[INFO][12:39:52]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:39:56]: [Client #194] Woke up.
[INFO][12:39:56]: [Client #194] Epoch: [5/5][0/16]	Loss: 3.043980
[INFO][12:39:56]: [Client #194] Epoch: [5/5][10/16]	Loss: 3.468324
[INFO][12:39:56]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:39:59]: [Client #194] Woke up.
[INFO][12:39:59]: [Client #194] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_615874.pth.
[INFO][12:40:00]: [Client #194] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_615874.pth.
[INFO][12:40:00]: [Client #194] Model trained.
[INFO][12:40:00]: [Client #194] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:40:00]: [Server #615782] Received 0.26 MB of payload data from client #194 (simulated).
[INFO][12:40:00]: [Server #615782] Selecting client #53 for training.
[INFO][12:40:00]: [Server #615782] Sending the current model to client #53 (simulated).
[INFO][12:40:00]: [Server #615782] Sending 0.26 MB of payload data to client #53 (simulated).
[INFO][12:40:00]: [Server #615782] Selecting client #606 for training.
[INFO][12:40:00]: [Server #615782] Sending the current model to client #606 (simulated).
[INFO][12:40:00]: [Server #615782] Sending 0.26 MB of payload data to client #606 (simulated).
[INFO][12:40:00]: [Client #53] Selected by the server.
[INFO][12:40:00]: [Client #53] Loading its data source...
[INFO][12:40:00]: Data source: FEMNIST
[INFO][12:40:00]: [Client #606] Selected by the server.
[INFO][12:40:00]: [Client #606] Loading its data source...
[INFO][12:40:00]: Data source: FEMNIST
[INFO][12:40:00]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:40:00]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/606.zip.
[INFO][12:40:00]: [Client #53] Dataset size: 155
[INFO][12:40:00]: [Client #53] Sampler: all_inclusive
[INFO][12:40:00]: [Client #53] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:40:00]: [93m[1m[Client #53] Started training in communication round #1.[0m
2.8%5.6%8.3%11.1%13.9%16.7%19.4%22.2%25.0%27.8%30.6%33.3%36.1%38.9%41.7%44.4%47.2%50.0%52.8%55.5%58.3%61.1%63.9%66.7%69.4%72.2%75.0%77.8%80.5%83.3%86.1%88.9%91.7%94.4%97.2%100.0%100.0%[INFO][12:40:00]: Decompressing the dataset downloaded.
[INFO][12:40:00]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/606.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:40:00]: [Client #606] Dataset size: 160
[INFO][12:40:00]: [Client #606] Sampler: all_inclusive
[INFO][12:40:00]: [Client #606] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:40:00]: [93m[1m[Client #606] Started training in communication round #1.[0m

[INFO][12:40:02]: [Client #53] Loading the dataset.
[INFO][12:40:02]: [Client #606] Loading the dataset.
[INFO][12:40:08]: [Client #53] Epoch: [1/5][0/16]	Loss: 4.093227
[INFO][12:40:08]: [Client #53] Epoch: [1/5][10/16]	Loss: 4.072670
[INFO][12:40:08]: [Client #606] Epoch: [1/5][0/16]	Loss: 4.091082
[INFO][12:40:08]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:40:08]: [Client #606] Epoch: [1/5][10/16]	Loss: 4.051282
[INFO][12:40:08]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][12:40:08]: [Client #53] Woke up.
[INFO][12:40:08]: [Client #53] Epoch: [2/5][0/16]	Loss: 4.001764
[INFO][12:40:08]: [Client #53] Epoch: [2/5][10/16]	Loss: 3.176568
[INFO][12:40:08]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:40:08]: [Client #53] Woke up.
[INFO][12:40:08]: [Client #53] Epoch: [3/5][0/16]	Loss: 3.130198
[INFO][12:40:08]: [Client #53] Epoch: [3/5][10/16]	Loss: 3.523579
[INFO][12:40:08]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:40:09]: [Client #53] Woke up.
[INFO][12:40:09]: [Client #53] Epoch: [4/5][0/16]	Loss: 3.450864
[INFO][12:40:09]: [Client #53] Epoch: [4/5][10/16]	Loss: 3.111439
[INFO][12:40:09]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:40:09]: [Client #53] Woke up.
[INFO][12:40:09]: [Client #53] Epoch: [5/5][0/16]	Loss: 3.010948
[INFO][12:40:09]: [Client #53] Epoch: [5/5][10/16]	Loss: 2.993647
[INFO][12:40:09]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:40:10]: [Client #53] Woke up.
[INFO][12:40:10]: [Client #53] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_615874.pth.
[INFO][12:40:10]: [Client #53] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_615874.pth.
[INFO][12:40:10]: [Client #53] Model trained.
[INFO][12:40:10]: [Client #53] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:40:10]: [Server #615782] Received 0.26 MB of payload data from client #53 (simulated).
[INFO][12:40:19]: [Client #606] Woke up.
[INFO][12:40:19]: [Client #606] Epoch: [2/5][0/16]	Loss: 4.035181
[INFO][12:40:19]: [Client #606] Epoch: [2/5][10/16]	Loss: 3.639083
[INFO][12:40:19]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][12:40:30]: [Client #606] Woke up.
[INFO][12:40:30]: [Client #606] Epoch: [3/5][0/16]	Loss: 3.076271
[INFO][12:40:30]: [Client #606] Epoch: [3/5][10/16]	Loss: 3.607464
[INFO][12:40:30]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][12:40:41]: [Client #606] Woke up.
[INFO][12:40:41]: [Client #606] Epoch: [4/5][0/16]	Loss: 3.779997
[INFO][12:40:41]: [Client #606] Epoch: [4/5][10/16]	Loss: 3.081314
[INFO][12:40:42]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][12:40:53]: [Client #606] Woke up.
[INFO][12:40:53]: [Client #606] Epoch: [5/5][0/16]	Loss: 3.431043
[INFO][12:40:53]: [Client #606] Epoch: [5/5][10/16]	Loss: 3.061327
[INFO][12:40:53]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][12:41:04]: [Client #606] Woke up.
[INFO][12:41:04]: [Client #606] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_606_615875.pth.
[INFO][12:41:05]: [Client #606] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_606_615875.pth.
[INFO][12:41:05]: [Client #606] Model trained.
[INFO][12:41:05]: [Client #606] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:05]: [Server #615782] Received 0.26 MB of payload data from client #606 (simulated).
[INFO][12:41:05]: [Server #615782] Selecting client #513 for training.
[INFO][12:41:05]: [Server #615782] Sending the current model to client #513 (simulated).
[INFO][12:41:05]: [Server #615782] Sending 0.26 MB of payload data to client #513 (simulated).
[INFO][12:41:05]: [Server #615782] Selecting client #618 for training.
[INFO][12:41:05]: [Server #615782] Sending the current model to client #618 (simulated).
[INFO][12:41:05]: [Server #615782] Sending 0.26 MB of payload data to client #618 (simulated).
[INFO][12:41:05]: [Client #513] Selected by the server.
[INFO][12:41:05]: [Client #513] Loading its data source...
[INFO][12:41:05]: [Client #618] Selected by the server.
[INFO][12:41:05]: Data source: FEMNIST
[INFO][12:41:05]: [Client #618] Loading its data source...
[INFO][12:41:05]: Data source: FEMNIST
[INFO][12:41:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:41:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:41:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/513.zip.
[INFO][12:41:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/618.zip.
2.6%5.3%7.9%10.6%13.2%15.8%18.5%21.1%23.8%26.4%29.0%31.7%34.3%37.0%39.6%42.2%44.9%47.5%50.2%52.8%55.4%58.1%60.7%63.4%66.0%68.6%71.3%73.9%76.6%79.2%81.8%84.5%87.1%89.8%92.4%95.0%97.7%100.0%[INFO][12:41:05]: Decompressing the dataset downloaded.
[INFO][12:41:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/618.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
2.5%4.9%7.4%9.9%12.3%14.8%17.3%19.7%22.2%24.7%27.1%29.6%32.1%34.5%37.0%39.5%41.9%44.4%46.9%49.3%51.8%54.3%56.7%59.2%61.7%64.1%66.6%69.1%71.5%74.0%76.5%78.9%81.4%83.9%86.4%88.8%91.3%93.8%96.2%98.7%100.0%[INFO][12:41:05]: Decompressing the dataset downloaded.
[INFO][12:41:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/513.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:41:05]: [Client #618] Dataset size: 162
[INFO][12:41:05]: [Client #618] Sampler: all_inclusive
[INFO][12:41:05]: [Client #618] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:05]: [93m[1m[Client #618] Started training in communication round #1.[0m

[INFO][12:41:05]: [Client #513] Dataset size: 164
[INFO][12:41:05]: [Client #513] Sampler: all_inclusive
[INFO][12:41:05]: [Client #513] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:05]: [93m[1m[Client #513] Started training in communication round #1.[0m

[INFO][12:41:07]: [Client #618] Loading the dataset.
[INFO][12:41:07]: [Client #513] Loading the dataset.
[INFO][12:41:13]: [Client #618] Epoch: [1/5][0/17]	Loss: 4.116496
[INFO][12:41:13]: [Client #513] Epoch: [1/5][0/17]	Loss: 4.122963
[INFO][12:41:13]: [Client #618] Epoch: [1/5][10/17]	Loss: 4.046342
[INFO][12:41:13]: [Client #513] Epoch: [1/5][10/17]	Loss: 4.040898
[INFO][12:41:13]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][12:41:13]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][12:41:13]: [Client #513] Woke up.
[INFO][12:41:13]: [Client #513] Epoch: [2/5][0/17]	Loss: 3.864613
[INFO][12:41:13]: [Client #513] Epoch: [2/5][10/17]	Loss: 3.347080
[INFO][12:41:13]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][12:41:13]: [Client #618] Woke up.
[INFO][12:41:13]: [Client #618] Epoch: [2/5][0/17]	Loss: 3.903038
[INFO][12:41:13]: [Client #513] Woke up.
[INFO][12:41:13]: [Client #513] Epoch: [3/5][0/17]	Loss: 3.789288
[INFO][12:41:13]: [Client #618] Epoch: [2/5][10/17]	Loss: 3.667786
[INFO][12:41:13]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][12:41:13]: [Client #513] Epoch: [3/5][10/17]	Loss: 3.264858
[INFO][12:41:13]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][12:41:13]: [Client #513] Woke up.
[INFO][12:41:13]: [Client #513] Epoch: [4/5][0/17]	Loss: 2.955535
[INFO][12:41:13]: [Client #513] Epoch: [4/5][10/17]	Loss: 3.212868
[INFO][12:41:14]: [Client #618] Woke up.
[INFO][12:41:14]: [Client #618] Epoch: [3/5][0/17]	Loss: 2.855046
[INFO][12:41:14]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][12:41:14]: [Client #513] Woke up.
[INFO][12:41:14]: [Client #513] Epoch: [5/5][0/17]	Loss: 3.677253
[INFO][12:41:14]: [Client #618] Epoch: [3/5][10/17]	Loss: 3.955339
[INFO][12:41:14]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][12:41:14]: [Client #513] Epoch: [5/5][10/17]	Loss: 3.459077
[INFO][12:41:14]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][12:41:14]: [Client #513] Woke up.
[INFO][12:41:14]: [Client #513] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_513_615874.pth.
[INFO][12:41:14]: [Client #618] Woke up.
[INFO][12:41:14]: [Client #618] Epoch: [4/5][0/17]	Loss: 3.200519
[INFO][12:41:14]: [Client #618] Epoch: [4/5][10/17]	Loss: 3.588835
[INFO][12:41:14]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][12:41:14]: [Client #618] Woke up.
[INFO][12:41:14]: [Client #618] Epoch: [5/5][0/17]	Loss: 3.789551
[INFO][12:41:14]: [Client #618] Epoch: [5/5][10/17]	Loss: 2.829817
[INFO][12:41:15]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][12:41:15]: [Client #513] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_513_615874.pth.
[INFO][12:41:15]: [Client #513] Model trained.
[INFO][12:41:15]: [Client #513] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:15]: [Server #615782] Received 0.26 MB of payload data from client #513 (simulated).
[INFO][12:41:15]: [Client #618] Woke up.
[INFO][12:41:15]: [Client #618] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_618_615875.pth.
[INFO][12:41:15]: [Client #618] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_618_615875.pth.
[INFO][12:41:15]: [Client #618] Model trained.
[INFO][12:41:15]: [Client #618] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:15]: [Server #615782] Received 0.26 MB of payload data from client #618 (simulated).
[INFO][12:41:15]: [Server #615782] Selecting client #433 for training.
[INFO][12:41:15]: [Server #615782] Sending the current model to client #433 (simulated).
[INFO][12:41:15]: [Server #615782] Sending 0.26 MB of payload data to client #433 (simulated).
[INFO][12:41:15]: [Server #615782] Selecting client #848 for training.
[INFO][12:41:15]: [Server #615782] Sending the current model to client #848 (simulated).
[INFO][12:41:15]: [Server #615782] Sending 0.26 MB of payload data to client #848 (simulated).
[INFO][12:41:15]: [Client #433] Selected by the server.
[INFO][12:41:15]: [Client #433] Loading its data source...
[INFO][12:41:15]: Data source: FEMNIST
[INFO][12:41:15]: [Client #848] Selected by the server.
[INFO][12:41:15]: [Client #848] Loading its data source...
[INFO][12:41:15]: Data source: FEMNIST
[INFO][12:41:15]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:41:15]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/848.zip.
[INFO][12:41:16]: [Client #433] Dataset size: 240
[INFO][12:41:16]: [Client #433] Sampler: all_inclusive
[INFO][12:41:16]: [Client #433] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:16]: [93m[1m[Client #433] Started training in communication round #1.[0m
2.2%4.4%6.7%8.9%11.1%13.3%15.5%17.7%20.0%22.2%24.4%26.6%28.8%31.0%33.3%35.5%37.7%39.9%42.1%44.3%46.6%48.8%51.0%53.2%55.4%57.6%59.9%62.1%64.3%66.5%68.7%70.9%73.2%75.4%77.6%79.8%82.0%84.2%86.5%88.7%90.9%93.1%95.3%97.5%99.8%100.0%[INFO][12:41:16]: Decompressing the dataset downloaded.
[INFO][12:41:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/848.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:41:16]: [Client #848] Dataset size: 145
[INFO][12:41:16]: [Client #848] Sampler: all_inclusive
[INFO][12:41:16]: [Client #848] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:16]: [93m[1m[Client #848] Started training in communication round #1.[0m

[INFO][12:41:18]: [Client #433] Loading the dataset.
[INFO][12:41:18]: [Client #848] Loading the dataset.
[INFO][12:41:23]: [Client #433] Epoch: [1/5][0/24]	Loss: 4.096436
[INFO][12:41:23]: [Client #848] Epoch: [1/5][0/15]	Loss: 4.100667
[INFO][12:41:23]: [Client #433] Epoch: [1/5][10/24]	Loss: 4.094923
[INFO][12:41:23]: [Client #848] Epoch: [1/5][10/15]	Loss: 4.074681
[INFO][12:41:23]: [Client #848] Going to sleep for 0.17 seconds.
[INFO][12:41:23]: [Client #433] Epoch: [1/5][20/24]	Loss: 4.083894
[INFO][12:41:23]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][12:41:24]: [Client #848] Woke up.
[INFO][12:41:24]: [Client #848] Epoch: [2/5][0/15]	Loss: 3.961749
[INFO][12:41:24]: [Client #848] Epoch: [2/5][10/15]	Loss: 3.497404
[INFO][12:41:24]: [Client #848] Going to sleep for 0.17 seconds.
[INFO][12:41:24]: [Client #848] Woke up.
[INFO][12:41:24]: [Client #848] Epoch: [3/5][0/15]	Loss: 3.445410
[INFO][12:41:24]: [Client #848] Epoch: [3/5][10/15]	Loss: 3.568190
[INFO][12:41:24]: [Client #848] Going to sleep for 0.17 seconds.
[INFO][12:41:24]: [Client #848] Woke up.
[INFO][12:41:24]: [Client #848] Epoch: [4/5][0/15]	Loss: 3.273724
[INFO][12:41:24]: [Client #848] Epoch: [4/5][10/15]	Loss: 3.324030
[INFO][12:41:24]: [Client #848] Going to sleep for 0.17 seconds.
[INFO][12:41:24]: [Client #433] Woke up.
[INFO][12:41:24]: [Client #433] Epoch: [2/5][0/24]	Loss: 4.045358
[INFO][12:41:24]: [Client #433] Epoch: [2/5][10/24]	Loss: 3.711863
[INFO][12:41:24]: [Client #848] Woke up.
[INFO][12:41:24]: [Client #848] Epoch: [5/5][0/15]	Loss: 3.426427
[INFO][12:41:24]: [Client #433] Epoch: [2/5][20/24]	Loss: 3.778611
[INFO][12:41:25]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][12:41:25]: [Client #848] Epoch: [5/5][10/15]	Loss: 3.926095
[INFO][12:41:25]: [Client #848] Going to sleep for 0.17 seconds.
[INFO][12:41:25]: [Client #848] Woke up.
[INFO][12:41:25]: [Client #848] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_848_615875.pth.
[INFO][12:41:25]: [Client #848] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_848_615875.pth.
[INFO][12:41:25]: [Client #848] Model trained.
[INFO][12:41:25]: [Client #848] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:25]: [Server #615782] Received 0.26 MB of payload data from client #848 (simulated).
[INFO][12:41:25]: [Client #433] Woke up.
[INFO][12:41:25]: [Client #433] Epoch: [3/5][0/24]	Loss: 4.058288
[INFO][12:41:26]: [Client #433] Epoch: [3/5][10/24]	Loss: 3.701740
[INFO][12:41:26]: [Client #433] Epoch: [3/5][20/24]	Loss: 3.939097
[INFO][12:41:26]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][12:41:27]: [Client #433] Woke up.
[INFO][12:41:27]: [Client #433] Epoch: [4/5][0/24]	Loss: 3.845100
[INFO][12:41:27]: [Client #433] Epoch: [4/5][10/24]	Loss: 3.701936
[INFO][12:41:27]: [Client #433] Epoch: [4/5][20/24]	Loss: 3.960401
[INFO][12:41:27]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][12:41:28]: [Client #433] Woke up.
[INFO][12:41:28]: [Client #433] Epoch: [5/5][0/24]	Loss: 3.755234
[INFO][12:41:28]: [Client #433] Epoch: [5/5][10/24]	Loss: 3.449668
[INFO][12:41:28]: [Client #433] Epoch: [5/5][20/24]	Loss: 3.314477
[INFO][12:41:28]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][12:41:29]: [Client #433] Woke up.
[INFO][12:41:29]: [Client #433] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_615874.pth.
[INFO][12:41:29]: [Client #433] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_615874.pth.
[INFO][12:41:29]: [Client #433] Model trained.
[INFO][12:41:29]: [Client #433] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:29]: [Server #615782] Received 0.26 MB of payload data from client #433 (simulated).
[INFO][12:41:29]: [Server #615782] Selecting client #455 for training.
[INFO][12:41:29]: [Server #615782] Sending the current model to client #455 (simulated).
[INFO][12:41:29]: [Server #615782] Sending 0.26 MB of payload data to client #455 (simulated).
[INFO][12:41:29]: [Server #615782] Selecting client #16 for training.
[INFO][12:41:29]: [Server #615782] Sending the current model to client #16 (simulated).
[INFO][12:41:29]: [Server #615782] Sending 0.26 MB of payload data to client #16 (simulated).
[INFO][12:41:29]: [Client #455] Selected by the server.
[INFO][12:41:29]: [Client #455] Loading its data source...
[INFO][12:41:29]: Data source: FEMNIST
[INFO][12:41:29]: [Client #16] Selected by the server.
[INFO][12:41:29]: [Client #16] Loading its data source...
[INFO][12:41:29]: Data source: FEMNIST
[INFO][12:41:30]: [Client #16] Dataset size: 164
[INFO][12:41:30]: [Client #16] Sampler: all_inclusive
[INFO][12:41:30]: [Client #16] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:30]: [Client #455] Dataset size: 149
[INFO][12:41:30]: [Client #455] Sampler: all_inclusive
[INFO][12:41:30]: [93m[1m[Client #16] Started training in communication round #1.[0m
[INFO][12:41:30]: [Client #455] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:30]: [93m[1m[Client #455] Started training in communication round #1.[0m
[INFO][12:41:31]: [Client #455] Loading the dataset.
[INFO][12:41:31]: [Client #16] Loading the dataset.
[INFO][12:41:37]: [Client #455] Epoch: [1/5][0/15]	Loss: 4.078417
[INFO][12:41:37]: [Client #16] Epoch: [1/5][0/17]	Loss: 4.108457
[INFO][12:41:37]: [Client #455] Epoch: [1/5][10/15]	Loss: 4.136829
[INFO][12:41:37]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][12:41:37]: [Client #16] Epoch: [1/5][10/17]	Loss: 4.044363
[INFO][12:41:37]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][12:41:39]: [Client #16] Woke up.
[INFO][12:41:39]: [Client #16] Epoch: [2/5][0/17]	Loss: 3.987087
[INFO][12:41:39]: [Client #16] Epoch: [2/5][10/17]	Loss: 3.569088
[INFO][12:41:39]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][12:41:40]: [Client #455] Woke up.
[INFO][12:41:40]: [Client #455] Epoch: [2/5][0/15]	Loss: 3.918170
[INFO][12:41:40]: [Client #455] Epoch: [2/5][10/15]	Loss: 3.784776
[INFO][12:41:40]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][12:41:41]: [Client #16] Woke up.
[INFO][12:41:41]: [Client #16] Epoch: [3/5][0/17]	Loss: 3.806130
[INFO][12:41:41]: [Client #16] Epoch: [3/5][10/17]	Loss: 3.654257
[INFO][12:41:42]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][12:41:42]: [Client #455] Woke up.
[INFO][12:41:42]: [Client #455] Epoch: [3/5][0/15]	Loss: 3.983648
[INFO][12:41:42]: [Client #455] Epoch: [3/5][10/15]	Loss: 3.735955
[INFO][12:41:42]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][12:41:44]: [Client #16] Woke up.
[INFO][12:41:44]: [Client #16] Epoch: [4/5][0/17]	Loss: 3.245669
[INFO][12:41:44]: [Client #16] Epoch: [4/5][10/17]	Loss: 3.720607
[INFO][12:41:44]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][12:41:45]: [Client #455] Woke up.
[INFO][12:41:45]: [Client #455] Epoch: [4/5][0/15]	Loss: 2.959618
[INFO][12:41:45]: [Client #455] Epoch: [4/5][10/15]	Loss: 3.697530
[INFO][12:41:45]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][12:41:46]: [Client #16] Woke up.
[INFO][12:41:46]: [Client #16] Epoch: [5/5][0/17]	Loss: 3.638623
[INFO][12:41:46]: [Client #16] Epoch: [5/5][10/17]	Loss: 3.417879
[INFO][12:41:46]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][12:41:47]: [Client #455] Woke up.
[INFO][12:41:47]: [Client #455] Epoch: [5/5][0/15]	Loss: 3.471870
[INFO][12:41:47]: [Client #455] Epoch: [5/5][10/15]	Loss: 3.609667
[INFO][12:41:47]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][12:41:48]: [Client #16] Woke up.
[INFO][12:41:48]: [Client #16] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_615875.pth.
[INFO][12:41:49]: [Client #16] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_615875.pth.
[INFO][12:41:49]: [Client #16] Model trained.
[INFO][12:41:49]: [Client #16] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:49]: [Server #615782] Received 0.26 MB of payload data from client #16 (simulated).
[INFO][12:41:50]: [Client #455] Woke up.
[INFO][12:41:50]: [Client #455] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_615874.pth.
[INFO][12:41:51]: [Client #455] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_615874.pth.
[INFO][12:41:51]: [Client #455] Model trained.
[INFO][12:41:51]: [Client #455] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:41:51]: [Server #615782] Received 0.26 MB of payload data from client #455 (simulated).
[INFO][12:41:51]: [Server #615782] Selecting client #874 for training.
[INFO][12:41:51]: [Server #615782] Sending the current model to client #874 (simulated).
[INFO][12:41:51]: [Server #615782] Sending 0.26 MB of payload data to client #874 (simulated).
[INFO][12:41:51]: [Server #615782] Selecting client #657 for training.
[INFO][12:41:51]: [Server #615782] Sending the current model to client #657 (simulated).
[INFO][12:41:51]: [Server #615782] Sending 0.26 MB of payload data to client #657 (simulated).
[INFO][12:41:51]: [Client #657] Selected by the server.
[INFO][12:41:51]: [Client #874] Selected by the server.
[INFO][12:41:51]: [Client #657] Loading its data source...
[INFO][12:41:51]: Data source: FEMNIST
[INFO][12:41:51]: [Client #874] Loading its data source...
[INFO][12:41:51]: Data source: FEMNIST
[INFO][12:41:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:41:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/657.zip.
[INFO][12:41:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:41:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/874.zip.
2.6%2.7%5.1%7.7%10.2%12.8%15.3%17.9%20.4%23.0%25.6%28.1%30.7%33.2%35.8%38.3%40.9%43.4%46.0%48.6%51.1%53.7%56.2%58.8%61.3%63.9%66.4%69.0%71.6%74.1%76.7%79.2%81.8%84.3%86.9%89.5%92.0%94.6%97.1%99.7%100.0%[INFO][12:41:51]: Decompressing the dataset downloaded.
[INFO][12:41:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/657.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
5.5%8.2%10.9%13.6%16.4%19.1%21.8%24.5%27.3%30.0%32.7%35.4%38.2%40.9%43.6%46.3%49.1%51.8%54.5%57.2%60.0%62.7%65.4%68.1%70.9%73.6%76.3%79.0%81.8%84.5%87.2%89.9%92.7%95.4%98.1%100.0%[INFO][12:41:51]: Decompressing the dataset downloaded.
[INFO][12:41:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/874.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:41:51]: [Client #657] Dataset size: 154
[INFO][12:41:51]: [Client #657] Sampler: all_inclusive
[INFO][12:41:51]: [Client #657] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:51]: [93m[1m[Client #657] Started training in communication round #1.[0m

[INFO][12:41:51]: [Client #874] Dataset size: 158
[INFO][12:41:51]: [Client #874] Sampler: all_inclusive
[INFO][12:41:51]: [Client #874] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:41:51]: [93m[1m[Client #874] Started training in communication round #1.[0m

[INFO][12:41:53]: [Client #657] Loading the dataset.
[INFO][12:41:53]: [Client #874] Loading the dataset.
[INFO][12:41:58]: [Client #657] Epoch: [1/5][0/16]	Loss: 4.137437
[INFO][12:41:58]: [Client #874] Epoch: [1/5][0/16]	Loss: 4.140946
[INFO][12:41:58]: [Client #657] Epoch: [1/5][10/16]	Loss: 4.069591
[INFO][12:41:58]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][12:41:58]: [Client #874] Epoch: [1/5][10/16]	Loss: 4.044328
[INFO][12:41:58]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][12:41:59]: [Client #874] Woke up.
[INFO][12:41:59]: [Client #874] Epoch: [2/5][0/16]	Loss: 4.034443
[INFO][12:41:59]: [Client #874] Epoch: [2/5][10/16]	Loss: 3.277573
[INFO][12:41:59]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][12:41:59]: [Client #874] Woke up.
[INFO][12:41:59]: [Client #874] Epoch: [3/5][0/16]	Loss: 3.763875
[INFO][12:41:59]: [Client #874] Epoch: [3/5][10/16]	Loss: 3.244959
[INFO][12:41:59]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][12:41:59]: [Client #874] Woke up.
[INFO][12:41:59]: [Client #874] Epoch: [4/5][0/16]	Loss: 3.172773
[INFO][12:41:59]: [Client #874] Epoch: [4/5][10/16]	Loss: 3.220699
[INFO][12:41:59]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][12:41:59]: [Client #874] Woke up.
[INFO][12:41:59]: [Client #874] Epoch: [5/5][0/16]	Loss: 2.992233
[INFO][12:42:00]: [Client #874] Epoch: [5/5][10/16]	Loss: 3.072744
[INFO][12:42:00]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][12:42:00]: [Client #874] Woke up.
[INFO][12:42:00]: [Client #874] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615874.pth.
[INFO][12:42:00]: [Client #657] Woke up.
[INFO][12:42:00]: [Client #657] Epoch: [2/5][0/16]	Loss: 3.968292
[INFO][12:42:00]: [Client #657] Epoch: [2/5][10/16]	Loss: 3.914117
[INFO][12:42:00]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][12:42:00]: [Client #874] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615874.pth.
[INFO][12:42:00]: [Client #874] Model trained.
[INFO][12:42:00]: [Client #874] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:00]: [Server #615782] Received 0.26 MB of payload data from client #874 (simulated).
[INFO][12:42:01]: [Client #657] Woke up.
[INFO][12:42:01]: [Client #657] Epoch: [3/5][0/16]	Loss: 3.849555
[INFO][12:42:01]: [Client #657] Epoch: [3/5][10/16]	Loss: 3.450678
[INFO][12:42:01]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][12:42:03]: [Client #657] Woke up.
[INFO][12:42:03]: [Client #657] Epoch: [4/5][0/16]	Loss: 2.931005
[INFO][12:42:03]: [Client #657] Epoch: [4/5][10/16]	Loss: 3.656967
[INFO][12:42:03]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][12:42:04]: [Client #657] Woke up.
[INFO][12:42:04]: [Client #657] Epoch: [5/5][0/16]	Loss: 3.579158
[INFO][12:42:04]: [Client #657] Epoch: [5/5][10/16]	Loss: 3.166596
[INFO][12:42:04]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][12:42:06]: [Client #657] Woke up.
[INFO][12:42:06]: [Client #657] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_657_615875.pth.
[INFO][12:42:06]: [Client #657] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_657_615875.pth.
[INFO][12:42:06]: [Client #657] Model trained.
[INFO][12:42:06]: [Client #657] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:06]: [Server #615782] Received 0.26 MB of payload data from client #657 (simulated).
[INFO][12:42:06]: [Server #615782] Selecting client #824 for training.
[INFO][12:42:06]: [Server #615782] Sending the current model to client #824 (simulated).
[INFO][12:42:06]: [Server #615782] Sending 0.26 MB of payload data to client #824 (simulated).
[INFO][12:42:06]: [Server #615782] Selecting client #952 for training.
[INFO][12:42:06]: [Server #615782] Sending the current model to client #952 (simulated).
[INFO][12:42:07]: [Server #615782] Sending 0.26 MB of payload data to client #952 (simulated).
[INFO][12:42:07]: [Client #824] Selected by the server.
[INFO][12:42:07]: [Client #952] Selected by the server.
[INFO][12:42:07]: [Client #824] Loading its data source...
[INFO][12:42:07]: [Client #952] Loading its data source...
[INFO][12:42:07]: Data source: FEMNIST
[INFO][12:42:07]: Data source: FEMNIST
[INFO][12:42:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:42:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:42:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/952.zip.
[INFO][12:42:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/824.zip.
2.3%2.1%4.6%6.9%9.2%11.5%13.8%16.1%18.4%20.7%23.0%25.3%27.6%29.9%32.2%34.5%36.8%4.3%6.4%8.5%10.6%12.8%14.9%17.0%19.1%39.1%21.3%23.4%41.4%25.5%43.7%27.7%46.0%29.8%31.9%48.3%34.0%50.6%36.2%52.9%55.2%38.3%57.5%59.8%40.4%62.1%42.5%64.4%44.7%66.7%46.8%69.0%48.9%71.3%51.1%73.6%53.2%55.3%57.4%75.9%59.6%78.2%61.7%63.8%80.4%65.9%82.7%68.1%85.0%70.2%87.3%72.3%89.6%91.9%74.4%94.2%76.6%96.5%78.7%98.8%80.8%83.0%85.1%87.2%89.3%91.5%93.6%95.7%97.8%100.0%100.0%100.0%[INFO][12:42:07]: Decompressing the dataset downloaded.
[INFO][12:42:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/952.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:42:07]: Decompressing the dataset downloaded.
[INFO][12:42:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/824.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:42:07]: [Client #952] Dataset size: 157
[INFO][12:42:07]: [Client #952] Sampler: all_inclusive
[INFO][12:42:07]: [Client #824] Dataset size: 162
[INFO][12:42:07]: [Client #824] Sampler: all_inclusive
[INFO][12:42:07]: [Client #952] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:07]: [Client #824] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:07]: [93m[1m[Client #952] Started training in communication round #1.[0m

[INFO][12:42:07]: [93m[1m[Client #824] Started training in communication round #1.[0m

[INFO][12:42:09]: [Client #824] Loading the dataset.
[INFO][12:42:09]: [Client #952] Loading the dataset.
[INFO][12:42:14]: [Client #952] Epoch: [1/5][0/16]	Loss: 4.142354
[INFO][12:42:14]: [Client #824] Epoch: [1/5][0/17]	Loss: 4.118320
[INFO][12:42:15]: [Client #952] Epoch: [1/5][10/16]	Loss: 4.073985
[INFO][12:42:15]: [Client #824] Epoch: [1/5][10/17]	Loss: 4.050682
[INFO][12:42:15]: [Client #952] Going to sleep for 1.94 seconds.
[INFO][12:42:15]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][12:42:15]: [Client #824] Woke up.
[INFO][12:42:15]: [Client #824] Epoch: [2/5][0/17]	Loss: 3.985924
[INFO][12:42:15]: [Client #824] Epoch: [2/5][10/17]	Loss: 3.467069
[INFO][12:42:15]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][12:42:15]: [Client #824] Woke up.
[INFO][12:42:15]: [Client #824] Epoch: [3/5][0/17]	Loss: 3.536664
[INFO][12:42:15]: [Client #824] Epoch: [3/5][10/17]	Loss: 3.700859
[INFO][12:42:16]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][12:42:16]: [Client #824] Woke up.
[INFO][12:42:16]: [Client #824] Epoch: [4/5][0/17]	Loss: 3.907172
[INFO][12:42:16]: [Client #824] Epoch: [4/5][10/17]	Loss: 3.431553
[INFO][12:42:16]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][12:42:16]: [Client #824] Woke up.
[INFO][12:42:16]: [Client #824] Epoch: [5/5][0/17]	Loss: 3.416962
[INFO][12:42:16]: [Client #824] Epoch: [5/5][10/17]	Loss: 3.513554
[INFO][12:42:16]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][12:42:17]: [Client #952] Woke up.
[INFO][12:42:17]: [Client #952] Epoch: [2/5][0/16]	Loss: 3.913990
[INFO][12:42:17]: [Client #952] Epoch: [2/5][10/16]	Loss: 4.128990
[INFO][12:42:17]: [Client #952] Going to sleep for 1.94 seconds.
[INFO][12:42:17]: [Client #824] Woke up.
[INFO][12:42:17]: [Client #824] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_824_615874.pth.
[INFO][12:42:17]: [Client #824] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_824_615874.pth.
[INFO][12:42:17]: [Client #824] Model trained.
[INFO][12:42:17]: [Client #824] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:17]: [Server #615782] Received 0.26 MB of payload data from client #824 (simulated).
[INFO][12:42:19]: [Client #952] Woke up.
[INFO][12:42:19]: [Client #952] Epoch: [3/5][0/16]	Loss: 3.333289
[INFO][12:42:19]: [Client #952] Epoch: [3/5][10/16]	Loss: 3.826560
[INFO][12:42:19]: [Client #952] Going to sleep for 1.94 seconds.
[INFO][12:42:21]: [Client #952] Woke up.
[INFO][12:42:21]: [Client #952] Epoch: [4/5][0/16]	Loss: 3.011245
[INFO][12:42:21]: [Client #952] Epoch: [4/5][10/16]	Loss: 3.257266
[INFO][12:42:21]: [Client #952] Going to sleep for 1.94 seconds.
[INFO][12:42:23]: [Client #952] Woke up.
[INFO][12:42:23]: [Client #952] Epoch: [5/5][0/16]	Loss: 3.010179
[INFO][12:42:23]: [Client #952] Epoch: [5/5][10/16]	Loss: 3.222022
[INFO][12:42:23]: [Client #952] Going to sleep for 1.94 seconds.
[INFO][12:42:25]: [Client #952] Woke up.
[INFO][12:42:25]: [Client #952] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_952_615875.pth.
[INFO][12:42:26]: [Client #952] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_952_615875.pth.
[INFO][12:42:26]: [Client #952] Model trained.
[INFO][12:42:26]: [Client #952] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:26]: [Server #615782] Received 0.26 MB of payload data from client #952 (simulated).
[INFO][12:42:26]: [Server #615782] Selecting client #51 for training.
[INFO][12:42:26]: [Server #615782] Sending the current model to client #51 (simulated).
[INFO][12:42:26]: [Server #615782] Sending 0.26 MB of payload data to client #51 (simulated).
[INFO][12:42:26]: [Server #615782] Selecting client #236 for training.
[INFO][12:42:26]: [Server #615782] Sending the current model to client #236 (simulated).
[INFO][12:42:26]: [Server #615782] Sending 0.26 MB of payload data to client #236 (simulated).
[INFO][12:42:26]: [Client #51] Selected by the server.
[INFO][12:42:26]: [Client #236] Selected by the server.
[INFO][12:42:26]: [Client #51] Loading its data source...
[INFO][12:42:26]: [Client #236] Loading its data source...
[INFO][12:42:26]: Data source: FEMNIST
[INFO][12:42:26]: Data source: FEMNIST
[INFO][12:42:26]: [Client #51] Dataset size: 135
[INFO][12:42:26]: [Client #51] Sampler: all_inclusive
[INFO][12:42:26]: [Client #51] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:26]: [93m[1m[Client #51] Started training in communication round #1.[0m
[INFO][12:42:26]: [Client #236] Dataset size: 161
[INFO][12:42:26]: [Client #236] Sampler: all_inclusive
[INFO][12:42:26]: [Client #236] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:26]: [93m[1m[Client #236] Started training in communication round #1.[0m
[INFO][12:42:28]: [Client #51] Loading the dataset.
[INFO][12:42:28]: [Client #236] Loading the dataset.
[INFO][12:42:33]: [Client #236] Epoch: [1/5][0/17]	Loss: 4.083621
[INFO][12:42:33]: [Client #51] Epoch: [1/5][0/14]	Loss: 4.100336
[INFO][12:42:33]: [Client #236] Epoch: [1/5][10/17]	Loss: 4.101384
[INFO][12:42:33]: [Client #51] Epoch: [1/5][10/14]	Loss: 4.147433
[INFO][12:42:33]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][12:42:33]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][12:42:33]: [Client #51] Woke up.
[INFO][12:42:33]: [Client #51] Epoch: [2/5][0/14]	Loss: 3.922347
[INFO][12:42:33]: [Client #51] Epoch: [2/5][10/14]	Loss: 3.731992
[INFO][12:42:33]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][12:42:33]: [Client #51] Woke up.
[INFO][12:42:33]: [Client #51] Epoch: [3/5][0/14]	Loss: 3.841108
[INFO][12:42:33]: [Client #51] Epoch: [3/5][10/14]	Loss: 3.683722
[INFO][12:42:33]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][12:42:33]: [Client #51] Woke up.
[INFO][12:42:33]: [Client #51] Epoch: [4/5][0/14]	Loss: 3.322412
[INFO][12:42:34]: [Client #51] Epoch: [4/5][10/14]	Loss: 3.541005
[INFO][12:42:34]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][12:42:34]: [Client #51] Woke up.
[INFO][12:42:34]: [Client #51] Epoch: [5/5][0/14]	Loss: 3.400538
[INFO][12:42:34]: [Client #51] Epoch: [5/5][10/14]	Loss: 3.691024
[INFO][12:42:34]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][12:42:34]: [Client #51] Woke up.
[INFO][12:42:34]: [Client #51] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_51_615874.pth.
[INFO][12:42:34]: [Client #51] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_51_615874.pth.
[INFO][12:42:34]: [Client #51] Model trained.
[INFO][12:42:34]: [Client #51] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:34]: [Server #615782] Received 0.26 MB of payload data from client #51 (simulated).
[INFO][12:42:35]: [Client #236] Woke up.
[INFO][12:42:35]: [Client #236] Epoch: [2/5][0/17]	Loss: 3.999803
[INFO][12:42:35]: [Client #236] Epoch: [2/5][10/17]	Loss: 3.844586
[INFO][12:42:35]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][12:42:36]: [Client #236] Woke up.
[INFO][12:42:36]: [Client #236] Epoch: [3/5][0/17]	Loss: 4.029220
[INFO][12:42:36]: [Client #236] Epoch: [3/5][10/17]	Loss: 4.040195
[INFO][12:42:36]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][12:42:38]: [Client #236] Woke up.
[INFO][12:42:38]: [Client #236] Epoch: [4/5][0/17]	Loss: 3.478703
[INFO][12:42:38]: [Client #236] Epoch: [4/5][10/17]	Loss: 3.252925
[INFO][12:42:38]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][12:42:40]: [Client #236] Woke up.
[INFO][12:42:40]: [Client #236] Epoch: [5/5][0/17]	Loss: 3.062302
[INFO][12:42:40]: [Client #236] Epoch: [5/5][10/17]	Loss: 3.235943
[INFO][12:42:40]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][12:42:41]: [Client #236] Woke up.
[INFO][12:42:41]: [Client #236] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_615875.pth.
[INFO][12:42:42]: [Client #236] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_615875.pth.
[INFO][12:42:42]: [Client #236] Model trained.
[INFO][12:42:42]: [Client #236] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:42]: [Server #615782] Received 0.26 MB of payload data from client #236 (simulated).
[INFO][12:42:42]: [Server #615782] Selecting client #64 for training.
[INFO][12:42:42]: [Server #615782] Sending the current model to client #64 (simulated).
[INFO][12:42:42]: [Server #615782] Sending 0.26 MB of payload data to client #64 (simulated).
[INFO][12:42:42]: [Server #615782] Selecting client #422 for training.
[INFO][12:42:42]: [Server #615782] Sending the current model to client #422 (simulated).
[INFO][12:42:42]: [Server #615782] Sending 0.26 MB of payload data to client #422 (simulated).
[INFO][12:42:42]: [Client #64] Selected by the server.
[INFO][12:42:42]: [Client #64] Loading its data source...
[INFO][12:42:42]: Data source: FEMNIST
[INFO][12:42:42]: [Client #422] Selected by the server.
[INFO][12:42:42]: [Client #422] Loading its data source...
[INFO][12:42:42]: Data source: FEMNIST
[INFO][12:42:42]: [Client #64] Dataset size: 140
[INFO][12:42:42]: [Client #64] Sampler: all_inclusive
[INFO][12:42:42]: [Client #64] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:42]: [93m[1m[Client #64] Started training in communication round #1.[0m
[INFO][12:42:42]: [Client #422] Dataset size: 273
[INFO][12:42:42]: [Client #422] Sampler: all_inclusive
[INFO][12:42:42]: [Client #422] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:42]: [93m[1m[Client #422] Started training in communication round #1.[0m
[INFO][12:42:44]: [Client #64] Loading the dataset.
[INFO][12:42:44]: [Client #422] Loading the dataset.
[INFO][12:42:50]: [Client #422] Epoch: [1/5][0/28]	Loss: 4.123900
[INFO][12:42:50]: [Client #64] Epoch: [1/5][0/14]	Loss: 4.085176
[INFO][12:42:50]: [Client #422] Epoch: [1/5][10/28]	Loss: 4.150839
[INFO][12:42:50]: [Client #64] Epoch: [1/5][10/14]	Loss: 4.136050
[INFO][12:42:50]: [Client #64] Going to sleep for 0.71 seconds.
[INFO][12:42:50]: [Client #422] Epoch: [1/5][20/28]	Loss: 4.060227
[INFO][12:42:50]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:42:50]: [Client #422] Woke up.
[INFO][12:42:50]: [Client #422] Epoch: [2/5][0/28]	Loss: 4.053007
[INFO][12:42:50]: [Client #422] Epoch: [2/5][10/28]	Loss: 3.932746
[INFO][12:42:50]: [Client #422] Epoch: [2/5][20/28]	Loss: 3.424727
[INFO][12:42:50]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:42:50]: [Client #422] Woke up.
[INFO][12:42:50]: [Client #422] Epoch: [3/5][0/28]	Loss: 3.920535
[INFO][12:42:50]: [Client #422] Epoch: [3/5][10/28]	Loss: 3.830831
[INFO][12:42:51]: [Client #64] Woke up.
[INFO][12:42:51]: [Client #422] Epoch: [3/5][20/28]	Loss: 3.737815
[INFO][12:42:51]: [Client #64] Epoch: [2/5][0/14]	Loss: 4.093732
[INFO][12:42:51]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:42:51]: [Client #64] Epoch: [2/5][10/14]	Loss: 3.682070
[INFO][12:42:51]: [Client #64] Going to sleep for 0.71 seconds.
[INFO][12:42:51]: [Client #422] Woke up.
[INFO][12:42:51]: [Client #422] Epoch: [4/5][0/28]	Loss: 3.739030
[INFO][12:42:51]: [Client #422] Epoch: [4/5][10/28]	Loss: 3.964532
[INFO][12:42:51]: [Client #422] Epoch: [4/5][20/28]	Loss: 3.639814
[INFO][12:42:51]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:42:51]: [Client #422] Woke up.
[INFO][12:42:51]: [Client #422] Epoch: [5/5][0/28]	Loss: 3.350505
[INFO][12:42:51]: [Client #422] Epoch: [5/5][10/28]	Loss: 3.840512
[INFO][12:42:51]: [Client #422] Epoch: [5/5][20/28]	Loss: 3.472069
[INFO][12:42:51]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:42:51]: [Client #422] Woke up.
[INFO][12:42:51]: [Client #422] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_615875.pth.
[INFO][12:42:51]: [Client #64] Woke up.
[INFO][12:42:51]: [Client #64] Epoch: [3/5][0/14]	Loss: 3.860873
[INFO][12:42:51]: [Client #64] Epoch: [3/5][10/14]	Loss: 3.150497
[INFO][12:42:51]: [Client #64] Going to sleep for 0.71 seconds.
[INFO][12:42:52]: [Client #422] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_615875.pth.
[INFO][12:42:52]: [Client #422] Model trained.
[INFO][12:42:52]: [Client #422] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:52]: [Server #615782] Received 0.26 MB of payload data from client #422 (simulated).
[INFO][12:42:52]: [Client #64] Woke up.
[INFO][12:42:52]: [Client #64] Epoch: [4/5][0/14]	Loss: 3.827120
[INFO][12:42:52]: [Client #64] Epoch: [4/5][10/14]	Loss: 3.777058
[INFO][12:42:52]: [Client #64] Going to sleep for 0.71 seconds.
[INFO][12:42:53]: [Client #64] Woke up.
[INFO][12:42:53]: [Client #64] Epoch: [5/5][0/14]	Loss: 3.361150
[INFO][12:42:53]: [Client #64] Epoch: [5/5][10/14]	Loss: 3.101522
[INFO][12:42:53]: [Client #64] Going to sleep for 0.71 seconds.
[INFO][12:42:54]: [Client #64] Woke up.
[INFO][12:42:54]: [Client #64] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_64_615874.pth.
[INFO][12:42:55]: [Client #64] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_64_615874.pth.
[INFO][12:42:55]: [Client #64] Model trained.
[INFO][12:42:55]: [Client #64] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:42:55]: [Server #615782] Received 0.26 MB of payload data from client #64 (simulated).
[INFO][12:42:55]: [Server #615782] Selecting client #864 for training.
[INFO][12:42:55]: [Server #615782] Sending the current model to client #864 (simulated).
[INFO][12:42:55]: [Server #615782] Sending 0.26 MB of payload data to client #864 (simulated).
[INFO][12:42:55]: [Server #615782] Selecting client #82 for training.
[INFO][12:42:55]: [Server #615782] Sending the current model to client #82 (simulated).
[INFO][12:42:55]: [Server #615782] Sending 0.26 MB of payload data to client #82 (simulated).
[INFO][12:42:55]: [Client #864] Selected by the server.
[INFO][12:42:55]: [Client #864] Loading its data source...
[INFO][12:42:55]: Data source: FEMNIST
[INFO][12:42:55]: [Client #82] Selected by the server.
[INFO][12:42:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:42:55]: [Client #82] Loading its data source...
[INFO][12:42:55]: Data source: FEMNIST
[INFO][12:42:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/864.zip.
[INFO][12:42:55]: [Client #82] Dataset size: 162
[INFO][12:42:55]: [Client #82] Sampler: all_inclusive
[INFO][12:42:55]: [Client #82] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:55]: [93m[1m[Client #82] Started training in communication round #1.[0m
2.3%4.6%6.9%9.3%11.6%13.9%16.2%18.5%20.8%23.2%25.5%27.8%30.1%32.4%34.7%37.1%39.4%41.7%44.0%46.3%48.6%51.0%53.3%55.6%57.9%60.2%62.5%64.8%67.2%69.5%71.8%74.1%76.4%78.7%81.1%83.4%85.7%88.0%90.3%92.6%95.0%97.3%99.6%100.0%[INFO][12:42:55]: Decompressing the dataset downloaded.
[INFO][12:42:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/864.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:42:55]: [Client #864] Dataset size: 153
[INFO][12:42:55]: [Client #864] Sampler: all_inclusive
[INFO][12:42:55]: [Client #864] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:42:55]: [93m[1m[Client #864] Started training in communication round #1.[0m

[INFO][12:42:57]: [Client #82] Loading the dataset.
[INFO][12:42:57]: [Client #864] Loading the dataset.
[INFO][12:43:02]: [Client #82] Epoch: [1/5][0/17]	Loss: 4.121521
[INFO][12:43:02]: [Client #864] Epoch: [1/5][0/16]	Loss: 4.110072
[INFO][12:43:02]: [Client #82] Epoch: [1/5][10/17]	Loss: 4.111569
[INFO][12:43:02]: [Client #864] Epoch: [1/5][10/16]	Loss: 3.976620
[INFO][12:43:02]: [Client #82] Going to sleep for 1.66 seconds.
[INFO][12:43:02]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][12:43:04]: [Client #864] Woke up.
[INFO][12:43:04]: [Client #864] Epoch: [2/5][0/16]	Loss: 3.859769
[INFO][12:43:04]: [Client #864] Epoch: [2/5][10/16]	Loss: 3.778482
[INFO][12:43:04]: [Client #82] Woke up.
[INFO][12:43:04]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][12:43:04]: [Client #82] Epoch: [2/5][0/17]	Loss: 4.041701
[INFO][12:43:04]: [Client #82] Epoch: [2/5][10/17]	Loss: 3.725806
[INFO][12:43:04]: [Client #82] Going to sleep for 1.66 seconds.
[INFO][12:43:06]: [Client #864] Woke up.
[INFO][12:43:06]: [Client #864] Epoch: [3/5][0/16]	Loss: 2.958998
[INFO][12:43:06]: [Client #864] Epoch: [3/5][10/16]	Loss: 3.180991
[INFO][12:43:06]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][12:43:06]: [Client #82] Woke up.
[INFO][12:43:06]: [Client #82] Epoch: [3/5][0/17]	Loss: 2.293179
[INFO][12:43:06]: [Client #82] Epoch: [3/5][10/17]	Loss: 3.632772
[INFO][12:43:06]: [Client #82] Going to sleep for 1.66 seconds.
[INFO][12:43:07]: [Client #864] Woke up.
[INFO][12:43:07]: [Client #864] Epoch: [4/5][0/16]	Loss: 2.593445
[INFO][12:43:07]: [Client #864] Epoch: [4/5][10/16]	Loss: 3.616274
[INFO][12:43:07]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][12:43:08]: [Client #82] Woke up.
[INFO][12:43:08]: [Client #82] Epoch: [4/5][0/17]	Loss: 3.190977
[INFO][12:43:08]: [Client #82] Epoch: [4/5][10/17]	Loss: 3.402833
[INFO][12:43:08]: [Client #82] Going to sleep for 1.66 seconds.
[INFO][12:43:09]: [Client #864] Woke up.
[INFO][12:43:09]: [Client #864] Epoch: [5/5][0/16]	Loss: 2.850396
[INFO][12:43:09]: [Client #864] Epoch: [5/5][10/16]	Loss: 3.559722
[INFO][12:43:09]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][12:43:10]: [Client #82] Woke up.
[INFO][12:43:10]: [Client #82] Epoch: [5/5][0/17]	Loss: 3.388812
[INFO][12:43:10]: [Client #82] Epoch: [5/5][10/17]	Loss: 3.430377
[INFO][12:43:10]: [Client #82] Going to sleep for 1.66 seconds.
[INFO][12:43:11]: [Client #864] Woke up.
[INFO][12:43:11]: [Client #864] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615874.pth.
[INFO][12:43:11]: [Client #864] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615874.pth.
[INFO][12:43:11]: [Client #864] Model trained.
[INFO][12:43:11]: [Client #864] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:11]: [Server #615782] Received 0.26 MB of payload data from client #864 (simulated).
[INFO][12:43:11]: [Client #82] Woke up.
[INFO][12:43:11]: [Client #82] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_82_615875.pth.
[INFO][12:43:12]: [Client #82] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_82_615875.pth.
[INFO][12:43:12]: [Client #82] Model trained.
[INFO][12:43:12]: [Client #82] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:12]: [Server #615782] Received 0.26 MB of payload data from client #82 (simulated).
[INFO][12:43:12]: [Server #615782] Selecting client #474 for training.
[INFO][12:43:12]: [Server #615782] Sending the current model to client #474 (simulated).
[INFO][12:43:12]: [Server #615782] Sending 0.26 MB of payload data to client #474 (simulated).
[INFO][12:43:12]: [Server #615782] Selecting client #126 for training.
[INFO][12:43:12]: [Server #615782] Sending the current model to client #126 (simulated).
[INFO][12:43:12]: [Server #615782] Sending 0.26 MB of payload data to client #126 (simulated).
[INFO][12:43:12]: [Client #474] Selected by the server.
[INFO][12:43:12]: [Client #474] Loading its data source...
[INFO][12:43:12]: Data source: FEMNIST
[INFO][12:43:12]: [Client #126] Selected by the server.
[INFO][12:43:12]: [Client #126] Loading its data source...
[INFO][12:43:12]: Data source: FEMNIST
[INFO][12:43:12]: [Client #126] Dataset size: 164
[INFO][12:43:12]: [Client #126] Sampler: all_inclusive
[INFO][12:43:12]: [Client #126] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:12]: [93m[1m[Client #126] Started training in communication round #1.[0m
[INFO][12:43:12]: [Client #474] Dataset size: 162
[INFO][12:43:12]: [Client #474] Sampler: all_inclusive
[INFO][12:43:12]: [Client #474] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:12]: [93m[1m[Client #474] Started training in communication round #1.[0m
[INFO][12:43:14]: [Client #474] Loading the dataset.
[INFO][12:43:14]: [Client #126] Loading the dataset.
[INFO][12:43:19]: [Client #474] Epoch: [1/5][0/17]	Loss: 4.094344
[INFO][12:43:20]: [Client #126] Epoch: [1/5][0/17]	Loss: 4.161352
[INFO][12:43:20]: [Client #474] Epoch: [1/5][10/17]	Loss: 4.078351
[INFO][12:43:20]: [Client #474] Going to sleep for 1.05 seconds.
[INFO][12:43:20]: [Client #126] Epoch: [1/5][10/17]	Loss: 4.106910
[INFO][12:43:20]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][12:43:21]: [Client #474] Woke up.
[INFO][12:43:21]: [Client #474] Epoch: [2/5][0/17]	Loss: 4.043975
[INFO][12:43:21]: [Client #474] Epoch: [2/5][10/17]	Loss: 3.592473
[INFO][12:43:21]: [Client #474] Going to sleep for 1.05 seconds.
[INFO][12:43:21]: [Client #126] Woke up.
[INFO][12:43:21]: [Client #126] Epoch: [2/5][0/17]	Loss: 3.985847
[INFO][12:43:21]: [Client #126] Epoch: [2/5][10/17]	Loss: 3.372618
[INFO][12:43:21]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][12:43:22]: [Client #474] Woke up.
[INFO][12:43:22]: [Client #474] Epoch: [3/5][0/17]	Loss: 3.309921
[INFO][12:43:22]: [Client #474] Epoch: [3/5][10/17]	Loss: 3.756974
[INFO][12:43:22]: [Client #474] Going to sleep for 1.05 seconds.
[INFO][12:43:22]: [Client #126] Woke up.
[INFO][12:43:22]: [Client #126] Epoch: [3/5][0/17]	Loss: 3.381519
[INFO][12:43:22]: [Client #126] Epoch: [3/5][10/17]	Loss: 3.618446
[INFO][12:43:22]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][12:43:23]: [Client #474] Woke up.
[INFO][12:43:23]: [Client #474] Epoch: [4/5][0/17]	Loss: 3.209675
[INFO][12:43:23]: [Client #474] Epoch: [4/5][10/17]	Loss: 3.766139
[INFO][12:43:23]: [Client #474] Going to sleep for 1.05 seconds.
[INFO][12:43:23]: [Client #126] Woke up.
[INFO][12:43:23]: [Client #126] Epoch: [4/5][0/17]	Loss: 3.448142
[INFO][12:43:24]: [Client #126] Epoch: [4/5][10/17]	Loss: 3.269469
[INFO][12:43:24]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][12:43:24]: [Client #474] Woke up.
[INFO][12:43:24]: [Client #474] Epoch: [5/5][0/17]	Loss: 3.166217
[INFO][12:43:24]: [Client #474] Epoch: [5/5][10/17]	Loss: 3.184862
[INFO][12:43:24]: [Client #474] Going to sleep for 1.05 seconds.
[INFO][12:43:25]: [Client #126] Woke up.
[INFO][12:43:25]: [Client #126] Epoch: [5/5][0/17]	Loss: 2.583743
[INFO][12:43:25]: [Client #126] Epoch: [5/5][10/17]	Loss: 3.016004
[INFO][12:43:25]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][12:43:25]: [Client #474] Woke up.
[INFO][12:43:25]: [Client #474] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_474_615874.pth.
[INFO][12:43:26]: [Client #474] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_474_615874.pth.
[INFO][12:43:26]: [Client #474] Model trained.
[INFO][12:43:26]: [Client #474] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:26]: [Server #615782] Received 0.26 MB of payload data from client #474 (simulated).
[INFO][12:43:26]: [Client #126] Woke up.
[INFO][12:43:26]: [Client #126] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_615875.pth.
[INFO][12:43:27]: [Client #126] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_615875.pth.
[INFO][12:43:27]: [Client #126] Model trained.
[INFO][12:43:27]: [Client #126] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:27]: [Server #615782] Received 0.26 MB of payload data from client #126 (simulated).
[INFO][12:43:27]: [Server #615782] Selecting client #773 for training.
[INFO][12:43:27]: [Server #615782] Sending the current model to client #773 (simulated).
[INFO][12:43:27]: [Server #615782] Sending 0.26 MB of payload data to client #773 (simulated).
[INFO][12:43:27]: [Server #615782] Selecting client #842 for training.
[INFO][12:43:27]: [Server #615782] Sending the current model to client #842 (simulated).
[INFO][12:43:27]: [Server #615782] Sending 0.26 MB of payload data to client #842 (simulated).
[INFO][12:43:27]: [Client #842] Selected by the server.
[INFO][12:43:27]: [Client #773] Selected by the server.
[INFO][12:43:27]: [Client #842] Loading its data source...
[INFO][12:43:27]: [Client #773] Loading its data source...
[INFO][12:43:27]: Data source: FEMNIST
[INFO][12:43:27]: Data source: FEMNIST
[INFO][12:43:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:43:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:43:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/842.zip.
[INFO][12:43:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/773.zip.
2.6%3.4%5.3%7.9%10.6%13.2%15.9%18.5%21.2%23.8%26.5%29.1%31.8%34.4%37.1%39.7%42.4%45.0%47.7%50.3%53.0%55.6%58.3%60.9%63.6%66.2%68.9%71.5%74.2%76.8%79.5%82.1%84.8%87.4%90.1%92.7%95.4%98.0%100.0%[INFO][12:43:27]: Decompressing the dataset downloaded.
[INFO][12:43:27]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/842.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
6.7%10.1%13.5%16.9%20.2%23.6%27.0%30.4%33.7%37.1%40.5%43.9%47.2%50.6%54.0%57.4%60.7%64.1%67.5%70.9%74.2%77.6%81.0%84.4%87.7%91.1%94.5%97.8%100.0%[INFO][12:43:27]: Decompressing the dataset downloaded.
[INFO][12:43:27]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/773.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:43:27]: [Client #842] Dataset size: 160
[INFO][12:43:27]: [Client #842] Sampler: all_inclusive
[INFO][12:43:27]: [Client #773] Dataset size: 117
[INFO][12:43:27]: [Client #773] Sampler: all_inclusive
[INFO][12:43:27]: [Client #842] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:27]: [Client #773] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:27]: [93m[1m[Client #842] Started training in communication round #1.[0m

[INFO][12:43:27]: [93m[1m[Client #773] Started training in communication round #1.[0m

[INFO][12:43:29]: [Client #773] Loading the dataset.
[INFO][12:43:29]: [Client #842] Loading the dataset.
[INFO][12:43:34]: [Client #773] Epoch: [1/5][0/12]	Loss: 4.060575
[INFO][12:43:35]: [Client #842] Epoch: [1/5][0/16]	Loss: 4.098011
[INFO][12:43:35]: [Client #773] Epoch: [1/5][10/12]	Loss: 4.053290
[INFO][12:43:35]: [Client #773] Going to sleep for 3.50 seconds.
[INFO][12:43:35]: [Client #842] Epoch: [1/5][10/16]	Loss: 4.093206
[INFO][12:43:35]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:43:35]: [Client #842] Woke up.
[INFO][12:43:35]: [Client #842] Epoch: [2/5][0/16]	Loss: 4.018946
[INFO][12:43:35]: [Client #842] Epoch: [2/5][10/16]	Loss: 3.947105
[INFO][12:43:35]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:43:36]: [Client #842] Woke up.
[INFO][12:43:36]: [Client #842] Epoch: [3/5][0/16]	Loss: 3.698602
[INFO][12:43:36]: [Client #842] Epoch: [3/5][10/16]	Loss: 3.259264
[INFO][12:43:36]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:43:37]: [Client #842] Woke up.
[INFO][12:43:37]: [Client #842] Epoch: [4/5][0/16]	Loss: 3.618419
[INFO][12:43:37]: [Client #842] Epoch: [4/5][10/16]	Loss: 3.373904
[INFO][12:43:37]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:43:37]: [Client #842] Woke up.
[INFO][12:43:37]: [Client #842] Epoch: [5/5][0/16]	Loss: 3.574365
[INFO][12:43:37]: [Client #842] Epoch: [5/5][10/16]	Loss: 3.216956
[INFO][12:43:37]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:43:38]: [Client #842] Woke up.
[INFO][12:43:38]: [Client #842] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_842_615875.pth.
[INFO][12:43:38]: [Client #773] Woke up.
[INFO][12:43:38]: [Client #773] Epoch: [2/5][0/12]	Loss: 4.003798
[INFO][12:43:38]: [Client #773] Epoch: [2/5][10/12]	Loss: 3.788249
[INFO][12:43:38]: [Client #773] Going to sleep for 3.50 seconds.
[INFO][12:43:39]: [Client #842] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_842_615875.pth.
[INFO][12:43:39]: [Client #842] Model trained.
[INFO][12:43:39]: [Client #842] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:39]: [Server #615782] Received 0.26 MB of payload data from client #842 (simulated).
[INFO][12:43:42]: [Client #773] Woke up.
[INFO][12:43:42]: [Client #773] Epoch: [3/5][0/12]	Loss: 3.400453
[INFO][12:43:42]: [Client #773] Epoch: [3/5][10/12]	Loss: 3.983593
[INFO][12:43:42]: [Client #773] Going to sleep for 3.50 seconds.
[INFO][12:43:45]: [Client #773] Woke up.
[INFO][12:43:45]: [Client #773] Epoch: [4/5][0/12]	Loss: 3.709191
[INFO][12:43:45]: [Client #773] Epoch: [4/5][10/12]	Loss: 3.586612
[INFO][12:43:45]: [Client #773] Going to sleep for 3.50 seconds.
[INFO][12:43:49]: [Client #773] Woke up.
[INFO][12:43:49]: [Client #773] Epoch: [5/5][0/12]	Loss: 3.189027
[INFO][12:43:49]: [Client #773] Epoch: [5/5][10/12]	Loss: 3.481457
[INFO][12:43:49]: [Client #773] Going to sleep for 3.50 seconds.
[INFO][12:43:53]: [Client #773] Woke up.
[INFO][12:43:53]: [Client #773] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_773_615874.pth.
[INFO][12:43:53]: [Client #773] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_773_615874.pth.
[INFO][12:43:53]: [Client #773] Model trained.
[INFO][12:43:53]: [Client #773] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:43:53]: [Server #615782] Received 0.26 MB of payload data from client #773 (simulated).
[INFO][12:43:53]: [Server #615782] Selecting client #44 for training.
[INFO][12:43:53]: [Server #615782] Sending the current model to client #44 (simulated).
[INFO][12:43:53]: [Server #615782] Sending 0.26 MB of payload data to client #44 (simulated).
[INFO][12:43:53]: [Server #615782] Selecting client #487 for training.
[INFO][12:43:53]: [Server #615782] Sending the current model to client #487 (simulated).
[INFO][12:43:53]: [Server #615782] Sending 0.26 MB of payload data to client #487 (simulated).
[INFO][12:43:53]: [Client #44] Selected by the server.
[INFO][12:43:53]: [Client #44] Loading its data source...
[INFO][12:43:53]: Data source: FEMNIST
[INFO][12:43:53]: [Client #487] Selected by the server.
[INFO][12:43:53]: [Client #487] Loading its data source...
[INFO][12:43:53]: Data source: FEMNIST
[INFO][12:43:53]: [Client #44] Dataset size: 166
[INFO][12:43:53]: [Client #44] Sampler: all_inclusive
[INFO][12:43:53]: [Client #44] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:53]: [93m[1m[Client #44] Started training in communication round #1.[0m
[INFO][12:43:53]: [Client #487] Dataset size: 155
[INFO][12:43:53]: [Client #487] Sampler: all_inclusive
[INFO][12:43:53]: [Client #487] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:43:53]: [93m[1m[Client #487] Started training in communication round #1.[0m
[INFO][12:43:55]: [Client #44] Loading the dataset.
[INFO][12:43:55]: [Client #487] Loading the dataset.
[INFO][12:44:01]: [Client #487] Epoch: [1/5][0/16]	Loss: 4.123734
[INFO][12:44:01]: [Client #44] Epoch: [1/5][0/17]	Loss: 4.110518
[INFO][12:44:01]: [Client #44] Epoch: [1/5][10/17]	Loss: 4.108747
[INFO][12:44:01]: [Client #487] Epoch: [1/5][10/16]	Loss: 4.171990
[INFO][12:44:01]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][12:44:01]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:44:01]: [Client #487] Woke up.
[INFO][12:44:01]: [Client #487] Epoch: [2/5][0/16]	Loss: 4.009753
[INFO][12:44:01]: [Client #487] Epoch: [2/5][10/16]	Loss: 3.487893
[INFO][12:44:02]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][12:44:02]: [Client #487] Woke up.
[INFO][12:44:02]: [Client #487] Epoch: [3/5][0/16]	Loss: 4.504174
[INFO][12:44:02]: [Client #487] Epoch: [3/5][10/16]	Loss: 3.661972
[INFO][12:44:02]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][12:44:02]: [Client #487] Woke up.
[INFO][12:44:02]: [Client #487] Epoch: [4/5][0/16]	Loss: 3.168176
[INFO][12:44:03]: [Client #487] Epoch: [4/5][10/16]	Loss: 3.183050
[INFO][12:44:03]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][12:44:03]: [Client #487] Woke up.
[INFO][12:44:03]: [Client #487] Epoch: [5/5][0/16]	Loss: 3.406804
[INFO][12:44:03]: [Client #487] Epoch: [5/5][10/16]	Loss: 3.152850
[INFO][12:44:03]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][12:44:04]: [Client #487] Woke up.
[INFO][12:44:04]: [Client #487] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_615875.pth.
[INFO][12:44:04]: [Client #487] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_615875.pth.
[INFO][12:44:04]: [Client #487] Model trained.
[INFO][12:44:04]: [Client #487] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:44:04]: [Server #615782] Received 0.26 MB of payload data from client #487 (simulated).
[INFO][12:44:05]: [Client #44] Woke up.
[INFO][12:44:05]: [Client #44] Epoch: [2/5][0/17]	Loss: 4.012456
[INFO][12:44:05]: [Client #44] Epoch: [2/5][10/17]	Loss: 3.790795
[INFO][12:44:05]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:44:09]: [Client #44] Woke up.
[INFO][12:44:09]: [Client #44] Epoch: [3/5][0/17]	Loss: 3.363059
[INFO][12:44:09]: [Client #44] Epoch: [3/5][10/17]	Loss: 3.908062
[INFO][12:44:09]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:44:12]: [Client #44] Woke up.
[INFO][12:44:13]: [Client #44] Epoch: [4/5][0/17]	Loss: 3.432330
[INFO][12:44:13]: [Client #44] Epoch: [4/5][10/17]	Loss: 3.341804
[INFO][12:44:13]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:44:16]: [Client #44] Woke up.
[INFO][12:44:16]: [Client #44] Epoch: [5/5][0/17]	Loss: 3.312344
[INFO][12:44:16]: [Client #44] Epoch: [5/5][10/17]	Loss: 2.974278
[INFO][12:44:17]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:44:20]: [Client #44] Woke up.
[INFO][12:44:20]: [Client #44] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_615874.pth.
[INFO][12:44:21]: [Client #44] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_615874.pth.
[INFO][12:44:21]: [Client #44] Model trained.
[INFO][12:44:21]: [Client #44] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:44:21]: [Server #615782] Received 0.26 MB of payload data from client #44 (simulated).
[INFO][12:44:21]: [Server #615782] Selecting client #240 for training.
[INFO][12:44:21]: [Server #615782] Sending the current model to client #240 (simulated).
[INFO][12:44:21]: [Server #615782] Sending 0.26 MB of payload data to client #240 (simulated).
[INFO][12:44:21]: [Server #615782] Selecting client #953 for training.
[INFO][12:44:21]: [Server #615782] Sending the current model to client #953 (simulated).
[INFO][12:44:21]: [Server #615782] Sending 0.26 MB of payload data to client #953 (simulated).
[INFO][12:44:21]: [Client #240] Selected by the server.
[INFO][12:44:21]: [Client #240] Loading its data source...
[INFO][12:44:21]: Data source: FEMNIST
[INFO][12:44:21]: [Client #953] Selected by the server.
[INFO][12:44:21]: [Client #953] Loading its data source...
[INFO][12:44:21]: Data source: FEMNIST
[INFO][12:44:21]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:44:21]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/953.zip.
[INFO][12:44:21]: [Client #240] Dataset size: 156
[INFO][12:44:21]: [Client #240] Sampler: all_inclusive
[INFO][12:44:21]: [Client #240] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:44:21]: [93m[1m[Client #240] Started training in communication round #1.[0m
3.2%6.4%9.6%12.7%15.9%19.1%22.3%25.5%28.7%31.9%35.0%38.2%41.4%44.6%47.8%51.0%54.2%57.3%60.5%63.7%66.9%70.1%73.3%76.4%79.6%82.8%86.0%89.2%92.4%95.6%98.7%100.0%[INFO][12:44:21]: Decompressing the dataset downloaded.
[INFO][12:44:21]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/953.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:44:21]: [Client #953] Dataset size: 133
[INFO][12:44:21]: [Client #953] Sampler: all_inclusive
[INFO][12:44:21]: [Client #953] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:44:21]: [93m[1m[Client #953] Started training in communication round #1.[0m

[INFO][12:44:23]: [Client #240] Loading the dataset.
[INFO][12:44:23]: [Client #953] Loading the dataset.
[INFO][12:44:29]: [Client #953] Epoch: [1/5][0/14]	Loss: 4.096780
[INFO][12:44:29]: [Client #240] Epoch: [1/5][0/16]	Loss: 4.094041
[INFO][12:44:29]: [Client #953] Epoch: [1/5][10/14]	Loss: 4.111321
[INFO][12:44:29]: [Client #240] Epoch: [1/5][10/16]	Loss: 4.073018
[INFO][12:44:29]: [Client #953] Going to sleep for 0.08 seconds.
[INFO][12:44:29]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][12:44:29]: [Client #953] Woke up.
[INFO][12:44:29]: [Client #953] Epoch: [2/5][0/14]	Loss: 3.922036
[INFO][12:44:29]: [Client #953] Epoch: [2/5][10/14]	Loss: 3.613685
[INFO][12:44:29]: [Client #953] Going to sleep for 0.08 seconds.
[INFO][12:44:29]: [Client #953] Woke up.
[INFO][12:44:29]: [Client #953] Epoch: [3/5][0/14]	Loss: 3.153851
[INFO][12:44:29]: [Client #953] Epoch: [3/5][10/14]	Loss: 3.447567
[INFO][12:44:29]: [Client #953] Going to sleep for 0.08 seconds.
[INFO][12:44:29]: [Client #953] Woke up.
[INFO][12:44:29]: [Client #953] Epoch: [4/5][0/14]	Loss: 4.121018
[INFO][12:44:29]: [Client #953] Epoch: [4/5][10/14]	Loss: 3.396950
[INFO][12:44:29]: [Client #953] Going to sleep for 0.08 seconds.
[INFO][12:44:29]: [Client #953] Woke up.
[INFO][12:44:29]: [Client #953] Epoch: [5/5][0/14]	Loss: 3.306171
[INFO][12:44:29]: [Client #953] Epoch: [5/5][10/14]	Loss: 3.431412
[INFO][12:44:29]: [Client #953] Going to sleep for 0.08 seconds.
[INFO][12:44:30]: [Client #953] Woke up.
[INFO][12:44:30]: [Client #953] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_953_615875.pth.
[INFO][12:44:30]: [Client #953] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_953_615875.pth.
[INFO][12:44:30]: [Client #953] Model trained.
[INFO][12:44:30]: [Client #953] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:44:30]: [Server #615782] Received 0.26 MB of payload data from client #953 (simulated).
[INFO][12:44:33]: [Client #240] Woke up.
[INFO][12:44:33]: [Client #240] Epoch: [2/5][0/16]	Loss: 3.976268
[INFO][12:44:33]: [Client #240] Epoch: [2/5][10/16]	Loss: 4.152334
[INFO][12:44:33]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][12:44:37]: [Client #240] Woke up.
[INFO][12:44:37]: [Client #240] Epoch: [3/5][0/16]	Loss: 3.600611
[INFO][12:44:37]: [Client #240] Epoch: [3/5][10/16]	Loss: 3.344934
[INFO][12:44:37]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][12:44:42]: [Client #240] Woke up.
[INFO][12:44:42]: [Client #240] Epoch: [4/5][0/16]	Loss: 3.422173
[INFO][12:44:42]: [Client #240] Epoch: [4/5][10/16]	Loss: 3.838815
[INFO][12:44:42]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][12:44:46]: [Client #240] Woke up.
[INFO][12:44:46]: [Client #240] Epoch: [5/5][0/16]	Loss: 3.441478
[INFO][12:44:46]: [Client #240] Epoch: [5/5][10/16]	Loss: 3.133008
[INFO][12:44:46]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][12:44:50]: [Client #240] Woke up.
[INFO][12:44:50]: [Client #240] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_615874.pth.
[INFO][12:44:51]: [Client #240] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_615874.pth.
[INFO][12:44:51]: [Client #240] Model trained.
[INFO][12:44:51]: [Client #240] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:44:51]: [Server #615782] Received 0.26 MB of payload data from client #240 (simulated).
[INFO][12:44:51]: [Server #615782] Selecting client #944 for training.
[INFO][12:44:51]: [Server #615782] Sending the current model to client #944 (simulated).
[INFO][12:44:51]: [Server #615782] Sending 0.26 MB of payload data to client #944 (simulated).
[INFO][12:44:51]: [Server #615782] Selecting client #614 for training.
[INFO][12:44:51]: [Server #615782] Sending the current model to client #614 (simulated).
[INFO][12:44:51]: [Server #615782] Sending 0.26 MB of payload data to client #614 (simulated).
[INFO][12:44:51]: [Client #944] Selected by the server.
[INFO][12:44:51]: [Client #944] Loading its data source...
[INFO][12:44:51]: Data source: FEMNIST
[INFO][12:44:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:44:51]: [Client #614] Selected by the server.
[INFO][12:44:51]: [Client #614] Loading its data source...
[INFO][12:44:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/944.zip.
[INFO][12:44:51]: Data source: FEMNIST
[INFO][12:44:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:44:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/614.zip.
2.7%2.0%4.0%6.1%8.1%10.1%12.1%14.2%16.2%18.2%20.2%22.2%24.3%26.3%28.3%30.3%32.3%5.5%8.2%11.0%13.7%16.5%19.2%21.9%24.7%27.4%30.2%32.9%35.6%38.4%41.1%43.9%46.6%49.4%52.1%54.8%57.6%60.3%63.1%65.8%68.5%71.3%74.0%76.8%79.5%82.3%85.0%87.7%90.5%93.2%96.0%98.7%100.0%[INFO][12:44:51]: Decompressing the dataset downloaded.
[INFO][12:44:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/614.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
34.4%36.4%38.4%40.4%42.5%44.5%46.5%48.5%50.5%52.6%54.6%56.6%58.6%60.6%62.7%64.7%66.7%68.7%70.8%72.8%74.8%76.8%78.8%80.9%82.9%84.9%86.9%88.9%91.0%93.0%95.0%97.0%99.1%100.0%[INFO][12:44:51]: Decompressing the dataset downloaded.
[INFO][12:44:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/944.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:44:51]: [Client #614] Dataset size: 161
[INFO][12:44:51]: [Client #614] Sampler: all_inclusive
[INFO][12:44:51]: [Client #614] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:44:51]: [93m[1m[Client #614] Started training in communication round #1.[0m

[INFO][12:44:51]: [Client #944] Dataset size: 211
[INFO][12:44:51]: [Client #944] Sampler: all_inclusive
[INFO][12:44:51]: [Client #944] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:44:51]: [93m[1m[Client #944] Started training in communication round #1.[0m

[INFO][12:44:53]: [Client #614] Loading the dataset.
[INFO][12:44:53]: [Client #944] Loading the dataset.
[INFO][12:44:59]: [Client #944] Epoch: [1/5][0/22]	Loss: 4.104797
[INFO][12:44:59]: [Client #614] Epoch: [1/5][0/17]	Loss: 4.098822
[INFO][12:44:59]: [Client #944] Epoch: [1/5][10/22]	Loss: 4.129883
[INFO][12:44:59]: [Client #614] Epoch: [1/5][10/17]	Loss: 4.023780
[INFO][12:44:59]: [Client #614] Going to sleep for 0.92 seconds.
[INFO][12:44:59]: [Client #944] Epoch: [1/5][20/22]	Loss: 4.057129
[INFO][12:44:59]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][12:45:00]: [Client #614] Woke up.
[INFO][12:45:00]: [Client #614] Epoch: [2/5][0/17]	Loss: 3.963822
[INFO][12:45:00]: [Client #614] Epoch: [2/5][10/17]	Loss: 3.211742
[INFO][12:45:00]: [Client #614] Going to sleep for 0.92 seconds.
[INFO][12:45:01]: [Client #614] Woke up.
[INFO][12:45:01]: [Client #614] Epoch: [3/5][0/17]	Loss: 3.866952
[INFO][12:45:01]: [Client #614] Epoch: [3/5][10/17]	Loss: 3.674668
[INFO][12:45:01]: [Client #614] Going to sleep for 0.92 seconds.
[INFO][12:45:02]: [Client #614] Woke up.
[INFO][12:45:02]: [Client #614] Epoch: [4/5][0/17]	Loss: 3.760933
[INFO][12:45:02]: [Client #614] Epoch: [4/5][10/17]	Loss: 4.249387
[INFO][12:45:02]: [Client #614] Going to sleep for 0.92 seconds.
[INFO][12:45:03]: [Client #944] Woke up.
[INFO][12:45:03]: [Client #944] Epoch: [2/5][0/22]	Loss: 4.054560
[INFO][12:45:03]: [Client #944] Epoch: [2/5][10/22]	Loss: 3.801530
[INFO][12:45:03]: [Client #614] Woke up.
[INFO][12:45:03]: [Client #944] Epoch: [2/5][20/22]	Loss: 4.387975
[INFO][12:45:03]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][12:45:03]: [Client #614] Epoch: [5/5][0/17]	Loss: 3.429191
[INFO][12:45:03]: [Client #614] Epoch: [5/5][10/17]	Loss: 3.411357
[INFO][12:45:03]: [Client #614] Going to sleep for 0.92 seconds.
[INFO][12:45:04]: [Client #614] Woke up.
[INFO][12:45:04]: [Client #614] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_614_615875.pth.
[INFO][12:45:05]: [Client #614] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_614_615875.pth.
[INFO][12:45:05]: [Client #614] Model trained.
[INFO][12:45:05]: [Client #614] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:45:05]: [Server #615782] Received 0.26 MB of payload data from client #614 (simulated).
[INFO][12:45:07]: [Client #944] Woke up.
[INFO][12:45:07]: [Client #944] Epoch: [3/5][0/22]	Loss: 3.654421
[INFO][12:45:07]: [Client #944] Epoch: [3/5][10/22]	Loss: 3.932664
[INFO][12:45:07]: [Client #944] Epoch: [3/5][20/22]	Loss: 3.948892
[INFO][12:45:07]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][12:45:11]: [Client #944] Woke up.
[INFO][12:45:11]: [Client #944] Epoch: [4/5][0/22]	Loss: 3.802361
[INFO][12:45:11]: [Client #944] Epoch: [4/5][10/22]	Loss: 4.228177
[INFO][12:45:11]: [Client #944] Epoch: [4/5][20/22]	Loss: 3.994114
[INFO][12:45:11]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][12:45:15]: [Client #944] Woke up.
[INFO][12:45:15]: [Client #944] Epoch: [5/5][0/22]	Loss: 3.667973
[INFO][12:45:15]: [Client #944] Epoch: [5/5][10/22]	Loss: 3.737271
[INFO][12:45:15]: [Client #944] Epoch: [5/5][20/22]	Loss: 3.562207
[INFO][12:45:15]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][12:45:19]: [Client #944] Woke up.
[INFO][12:45:19]: [Client #944] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_944_615874.pth.
[INFO][12:45:20]: [Client #944] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_944_615874.pth.
[INFO][12:45:20]: [Client #944] Model trained.
[INFO][12:45:20]: [Client #944] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:45:20]: [Server #615782] Received 0.26 MB of payload data from client #944 (simulated).
[INFO][12:45:20]: [Server #615782] Selecting client #974 for training.
[INFO][12:45:20]: [Server #615782] Sending the current model to client #974 (simulated).
[INFO][12:45:20]: [Server #615782] Sending 0.26 MB of payload data to client #974 (simulated).
[INFO][12:45:20]: [Server #615782] Selecting client #345 for training.
[INFO][12:45:20]: [Server #615782] Sending the current model to client #345 (simulated).
[INFO][12:45:20]: [Server #615782] Sending 0.26 MB of payload data to client #345 (simulated).
[INFO][12:45:20]: [Client #974] Selected by the server.
[INFO][12:45:20]: [Client #974] Loading its data source...
[INFO][12:45:20]: Data source: FEMNIST
[INFO][12:45:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:45:20]: [Client #345] Selected by the server.
[INFO][12:45:20]: [Client #345] Loading its data source...
[INFO][12:45:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/974.zip.
[INFO][12:45:20]: Data source: FEMNIST
[INFO][12:45:20]: [Client #345] Dataset size: 239
[INFO][12:45:20]: [Client #345] Sampler: all_inclusive
[INFO][12:45:20]: [Client #345] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:45:20]: [93m[1m[Client #345] Started training in communication round #1.[0m
2.6%5.2%7.8%10.4%13.0%15.6%18.1%20.7%23.3%25.9%28.5%31.1%33.7%36.3%38.9%41.5%44.1%46.7%49.2%51.8%54.4%57.0%59.6%62.2%64.8%67.4%70.0%72.6%75.2%77.8%80.3%82.9%85.5%88.1%90.7%93.3%95.9%98.5%100.0%[INFO][12:45:20]: Decompressing the dataset downloaded.
[INFO][12:45:20]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/974.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:45:20]: [Client #974] Dataset size: 158
[INFO][12:45:20]: [Client #974] Sampler: all_inclusive
[INFO][12:45:20]: [Client #974] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:45:20]: [93m[1m[Client #974] Started training in communication round #1.[0m

[INFO][12:45:22]: [Client #345] Loading the dataset.
[INFO][12:45:22]: [Client #974] Loading the dataset.
[INFO][12:45:27]: [Client #345] Epoch: [1/5][0/24]	Loss: 4.094522
[INFO][12:45:28]: [Client #345] Epoch: [1/5][10/24]	Loss: 4.106581
[INFO][12:45:28]: [Client #974] Epoch: [1/5][0/16]	Loss: 4.110750
[INFO][12:45:28]: [Client #345] Epoch: [1/5][20/24]	Loss: 4.155440
[INFO][12:45:28]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][12:45:28]: [Client #974] Epoch: [1/5][10/16]	Loss: 4.124168
[INFO][12:45:28]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][12:45:28]: [Client #345] Woke up.
[INFO][12:45:28]: [Client #345] Epoch: [2/5][0/24]	Loss: 3.986893
[INFO][12:45:28]: [Client #345] Epoch: [2/5][10/24]	Loss: 3.917038
[INFO][12:45:28]: [Client #345] Epoch: [2/5][20/24]	Loss: 3.848649
[INFO][12:45:28]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][12:45:28]: [Client #345] Woke up.
[INFO][12:45:28]: [Client #345] Epoch: [3/5][0/24]	Loss: 3.479006
[INFO][12:45:28]: [Client #345] Epoch: [3/5][10/24]	Loss: 3.751075
[INFO][12:45:28]: [Client #345] Epoch: [3/5][20/24]	Loss: 3.630385
[INFO][12:45:28]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][12:45:28]: [Client #345] Woke up.
[INFO][12:45:28]: [Client #345] Epoch: [4/5][0/24]	Loss: 3.527356
[INFO][12:45:28]: [Client #345] Epoch: [4/5][10/24]	Loss: 3.860330
[INFO][12:45:29]: [Client #345] Epoch: [4/5][20/24]	Loss: 3.460915
[INFO][12:45:29]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][12:45:29]: [Client #345] Woke up.
[INFO][12:45:29]: [Client #345] Epoch: [5/5][0/24]	Loss: 3.110164
[INFO][12:45:29]: [Client #345] Epoch: [5/5][10/24]	Loss: 3.651257
[INFO][12:45:29]: [Client #345] Epoch: [5/5][20/24]	Loss: 3.765399
[INFO][12:45:29]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][12:45:29]: [Client #345] Woke up.
[INFO][12:45:29]: [Client #345] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_615875.pth.
[INFO][12:45:30]: [Client #345] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_615875.pth.
[INFO][12:45:30]: [Client #345] Model trained.
[INFO][12:45:30]: [Client #345] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:45:30]: [Server #615782] Received 0.26 MB of payload data from client #345 (simulated).
[INFO][12:45:35]: [Client #974] Woke up.
[INFO][12:45:35]: [Client #974] Epoch: [2/5][0/16]	Loss: 4.023233
[INFO][12:45:35]: [Client #974] Epoch: [2/5][10/16]	Loss: 3.614872
[INFO][12:45:35]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][12:45:42]: [Client #974] Woke up.
[INFO][12:45:42]: [Client #974] Epoch: [3/5][0/16]	Loss: 2.904223
[INFO][12:45:42]: [Client #974] Epoch: [3/5][10/16]	Loss: 3.932556
[INFO][12:45:42]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][12:45:49]: [Client #974] Woke up.
[INFO][12:45:49]: [Client #974] Epoch: [4/5][0/16]	Loss: 3.673855
[INFO][12:45:50]: [Client #974] Epoch: [4/5][10/16]	Loss: 3.422349
[INFO][12:45:50]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][12:45:57]: [Client #974] Woke up.
[INFO][12:45:57]: [Client #974] Epoch: [5/5][0/16]	Loss: 3.446207
[INFO][12:45:57]: [Client #974] Epoch: [5/5][10/16]	Loss: 3.506959
[INFO][12:45:57]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][12:46:04]: [Client #974] Woke up.
[INFO][12:46:04]: [Client #974] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615874.pth.
[INFO][12:46:05]: [Client #974] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615874.pth.
[INFO][12:46:05]: [Client #974] Model trained.
[INFO][12:46:05]: [Client #974] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:46:05]: [Server #615782] Received 0.26 MB of payload data from client #974 (simulated).
[INFO][12:46:05]: [Server #615782] Selecting client #898 for training.
[INFO][12:46:05]: [Server #615782] Sending the current model to client #898 (simulated).
[INFO][12:46:05]: [Server #615782] Sending 0.26 MB of payload data to client #898 (simulated).
[INFO][12:46:05]: [Server #615782] Selecting client #435 for training.
[INFO][12:46:05]: [Server #615782] Sending the current model to client #435 (simulated).
[INFO][12:46:05]: [Server #615782] Sending 0.26 MB of payload data to client #435 (simulated).
[INFO][12:46:05]: [Client #898] Selected by the server.
[INFO][12:46:05]: [Client #898] Loading its data source...
[INFO][12:46:05]: Data source: FEMNIST
[INFO][12:46:05]: [Client #435] Selected by the server.
[INFO][12:46:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:46:05]: [Client #435] Loading its data source...
[INFO][12:46:05]: Data source: FEMNIST
[INFO][12:46:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/898.zip.
[INFO][12:46:05]: [Client #435] Dataset size: 159
[INFO][12:46:05]: [Client #435] Sampler: all_inclusive
[INFO][12:46:05]: [Client #435] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:46:05]: [93m[1m[Client #435] Started training in communication round #1.[0m
3.3%6.5%9.8%13.1%16.4%19.6%22.9%26.2%29.4%32.7%36.0%39.3%42.5%45.8%49.1%52.3%55.6%58.9%62.2%65.4%68.7%72.0%75.2%78.5%81.8%85.1%88.3%91.6%94.9%98.1%100.0%[INFO][12:46:05]: Decompressing the dataset downloaded.
[INFO][12:46:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/898.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:46:05]: [Client #898] Dataset size: 155
[INFO][12:46:05]: [Client #898] Sampler: all_inclusive
[INFO][12:46:05]: [Client #898] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:46:05]: [93m[1m[Client #898] Started training in communication round #1.[0m

[INFO][12:46:07]: [Client #435] Loading the dataset.
[INFO][12:46:07]: [Client #898] Loading the dataset.
[INFO][12:46:12]: [Client #435] Epoch: [1/5][0/16]	Loss: 4.104472
[INFO][12:46:12]: [Client #435] Epoch: [1/5][10/16]	Loss: 4.128060
[INFO][12:46:12]: [Client #435] Going to sleep for 4.08 seconds.
[INFO][12:46:12]: [Client #898] Epoch: [1/5][0/16]	Loss: 4.115365
[INFO][12:46:12]: [Client #898] Epoch: [1/5][10/16]	Loss: 4.020611
[INFO][12:46:12]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][12:46:14]: [Client #898] Woke up.
[INFO][12:46:14]: [Client #898] Epoch: [2/5][0/16]	Loss: 3.885821
[INFO][12:46:14]: [Client #898] Epoch: [2/5][10/16]	Loss: 3.496473
[INFO][12:46:14]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][12:46:15]: [Client #898] Woke up.
[INFO][12:46:15]: [Client #898] Epoch: [3/5][0/16]	Loss: 3.444687
[INFO][12:46:15]: [Client #898] Epoch: [3/5][10/16]	Loss: 3.524828
[INFO][12:46:15]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][12:46:16]: [Client #435] Woke up.
[INFO][12:46:16]: [Client #435] Epoch: [2/5][0/16]	Loss: 3.968524
[INFO][12:46:16]: [Client #898] Woke up.
[INFO][12:46:16]: [Client #898] Epoch: [4/5][0/16]	Loss: 3.343538
[INFO][12:46:17]: [Client #435] Epoch: [2/5][10/16]	Loss: 2.835260
[INFO][12:46:17]: [Client #435] Going to sleep for 4.08 seconds.
[INFO][12:46:17]: [Client #898] Epoch: [4/5][10/16]	Loss: 3.276463
[INFO][12:46:17]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][12:46:18]: [Client #898] Woke up.
[INFO][12:46:18]: [Client #898] Epoch: [5/5][0/16]	Loss: 3.254665
[INFO][12:46:18]: [Client #898] Epoch: [5/5][10/16]	Loss: 2.790229
[INFO][12:46:18]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][12:46:19]: [Client #898] Woke up.
[INFO][12:46:19]: [Client #898] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_898_615874.pth.
[INFO][12:46:20]: [Client #898] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_898_615874.pth.
[INFO][12:46:20]: [Client #898] Model trained.
[INFO][12:46:20]: [Client #898] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:46:20]: [Server #615782] Received 0.26 MB of payload data from client #898 (simulated).
[INFO][12:46:21]: [Client #435] Woke up.
[INFO][12:46:21]: [Client #435] Epoch: [3/5][0/16]	Loss: 3.571112
[INFO][12:46:21]: [Client #435] Epoch: [3/5][10/16]	Loss: 3.909420
[INFO][12:46:21]: [Client #435] Going to sleep for 4.08 seconds.
[INFO][12:46:25]: [Client #435] Woke up.
[INFO][12:46:25]: [Client #435] Epoch: [4/5][0/16]	Loss: 3.205726
[INFO][12:46:25]: [Client #435] Epoch: [4/5][10/16]	Loss: 3.601154
[INFO][12:46:25]: [Client #435] Going to sleep for 4.08 seconds.
[INFO][12:46:29]: [Client #435] Woke up.
[INFO][12:46:29]: [Client #435] Epoch: [5/5][0/16]	Loss: 3.644361
[INFO][12:46:29]: [Client #435] Epoch: [5/5][10/16]	Loss: 3.261744
[INFO][12:46:29]: [Client #435] Going to sleep for 4.08 seconds.
[INFO][12:46:33]: [Client #435] Woke up.
[INFO][12:46:33]: [Client #435] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_435_615875.pth.
[INFO][12:46:34]: [Client #435] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_435_615875.pth.
[INFO][12:46:34]: [Client #435] Model trained.
[INFO][12:46:34]: [Client #435] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:46:34]: [Server #615782] Received 0.26 MB of payload data from client #435 (simulated).
[INFO][12:46:34]: [Server #615782] Adding client #51 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #953 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #336 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #874 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #345 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #848 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #513 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #752 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #422 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #53 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #694 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #824 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #618 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #487 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #763 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #470 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #842 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #890 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #211 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #64 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #326 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #614 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #431 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #433 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Adding client #474 to the list of clients for aggregation.
[INFO][12:46:34]: [Server #615782] Aggregating 25 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14396406 0.         0.18007407 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15100977 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09971625 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12156734 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09091528
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10627596 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17261424 0.         0.         0.         0.
 0.         0.         0.         0.         0.13624601 0.
 0.10221792 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10434553 0.         0.         0.         0.21909044
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09520966 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11675763 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13677629 0.         0.         0.         0.13592416
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10209378 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17231254 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1413166  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13659415 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10374258 0.         0.         0.         0.
 0.         0.14362843 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11931308 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19137997 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1062441  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14396406 0.         0.18007407 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15100977 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09971625 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12156734 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09091528
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10627596 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17261424 0.         0.         0.         0.
 0.         0.         0.         0.         0.13624601 0.
 0.10221792 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10434553 0.         0.         0.         0.21909044
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09520966 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11675763 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13677629 0.         0.         0.         0.13592416
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10209378 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17231254 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1413166  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13659415 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10374258 0.         0.         0.         0.
 0.         0.14362843 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11931308 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19137997 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1062441  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03195266 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.05656805 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06461538 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0383432  0.001
 0.05680473 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03881657 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0383432  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03786982 0.001      0.001      0.001      0.001
 0.001      0.03431953 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03739645 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03147929 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001     ][INFO][12:47:22]: [Server #615782] Global model accuracy: 10.69%

[INFO][12:47:22]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_1.pth.
[INFO][12:47:22]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_1.pth.
[INFO][12:47:22]: [93m[1m
[Server #615782] Starting round 2/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5756e+00  1e+03  1e+00  1e+00
 1:  7.4998e+00  6.5767e+00  1e+01  1e-02  1e-02
 2:  7.5749e+00  6.6680e+00  1e+00  9e-05  9e-05
 3:  7.5756e+00  7.4975e+00  8e-02  4e-07  4e-07
 4:  7.5756e+00  7.5748e+00  8e-04  4e-09  4e-09
 5:  7.5756e+00  7.5756e+00  8e-06  4e-11  4e-11
 6:  7.5756e+00  7.5756e+00  8e-08  4e-13  4e-13
Optimal solution found.
The calculated probability is:  [0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102431 0.00102569 0.00102284
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102405 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102341 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.0010247  0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102492
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102333 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.0010176  0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102391 0.00102569
 0.00102349 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102468
 0.00102569 0.00102569 0.00102569 0.00102109 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102489 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102435 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102391 0.00102569 0.00102569
 0.00102569 0.00102391 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102494 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102287 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102398 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.0010239
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102468
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.0010241
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102439 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102222 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102496 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569 0.00102569
 0.00102569 0.00102569 0.00102569][INFO][12:47:24]: [Server #615782] Selected clients: [241 940 686  69 870 702 605 733 259 601 815  58 136 842 619 533 254 299
 872 424  68 896 208 826 881]
[INFO][12:47:24]: [Server #615782] Selecting client #241 for training.
[INFO][12:47:24]: [Server #615782] Sending the current model to client #241 (simulated).
[INFO][12:47:24]: [Server #615782] Sending 0.26 MB of payload data to client #241 (simulated).
[INFO][12:47:24]: [Server #615782] Selecting client #940 for training.
[INFO][12:47:24]: [Server #615782] Sending the current model to client #940 (simulated).
[INFO][12:47:24]: [Server #615782] Sending 0.26 MB of payload data to client #940 (simulated).
[INFO][12:47:24]: [Client #241] Selected by the server.
[INFO][12:47:24]: [Client #241] Loading its data source...
[INFO][12:47:24]: Data source: FEMNIST
[INFO][12:47:24]: [Client #940] Selected by the server.
[INFO][12:47:24]: [Client #940] Loading its data source...
[INFO][12:47:24]: Data source: FEMNIST
[INFO][12:47:24]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:47:24]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/940.zip.
[INFO][12:47:24]: [Client #241] Dataset size: 149
[INFO][12:47:24]: [Client #241] Sampler: all_inclusive
[INFO][12:47:24]: [Client #241] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:47:24]: [93m[1m[Client #241] Started training in communication round #2.[0m
2.6%5.1%7.7%10.2%12.8%15.3%17.9%20.5%23.0%25.6%28.1%30.7%33.2%35.8%38.4%40.9%43.5%46.0%48.6%51.1%53.7%56.3%58.8%61.4%63.9%66.5%69.0%71.6%74.2%76.7%79.3%81.8%84.4%86.9%89.5%92.1%94.6%97.2%99.7%100.0%[INFO][12:47:24]: Decompressing the dataset downloaded.
[INFO][12:47:24]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/940.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:47:24]: [Client #940] Dataset size: 156
[INFO][12:47:24]: [Client #940] Sampler: all_inclusive
[INFO][12:47:24]: [Client #940] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:47:24]: [93m[1m[Client #940] Started training in communication round #2.[0m

[INFO][12:47:26]: [Client #241] Loading the dataset.
[INFO][12:47:26]: [Client #940] Loading the dataset.
[INFO][12:47:31]: [Client #241] Epoch: [1/5][0/15]	Loss: 3.378640
[INFO][12:47:31]: [Client #241] Epoch: [1/5][10/15]	Loss: 3.959341
[INFO][12:47:31]: [Client #940] Epoch: [1/5][0/16]	Loss: 3.457246
[INFO][12:47:31]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][12:47:31]: [Client #940] Epoch: [1/5][10/16]	Loss: 3.254277
[INFO][12:47:31]: [Client #940] Going to sleep for 3.49 seconds.
[INFO][12:47:32]: [Client #241] Woke up.
[INFO][12:47:32]: [Client #241] Epoch: [2/5][0/15]	Loss: 3.837829
[INFO][12:47:32]: [Client #241] Epoch: [2/5][10/15]	Loss: 3.585774
[INFO][12:47:32]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][12:47:32]: [Client #241] Woke up.
[INFO][12:47:32]: [Client #241] Epoch: [3/5][0/15]	Loss: 2.948987
[INFO][12:47:32]: [Client #241] Epoch: [3/5][10/15]	Loss: 3.825377
[INFO][12:47:32]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][12:47:33]: [Client #241] Woke up.
[INFO][12:47:33]: [Client #241] Epoch: [4/5][0/15]	Loss: 2.889157
[INFO][12:47:33]: [Client #241] Epoch: [4/5][10/15]	Loss: 3.165461
[INFO][12:47:33]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][12:47:33]: [Client #241] Woke up.
[INFO][12:47:33]: [Client #241] Epoch: [5/5][0/15]	Loss: 1.767955
[INFO][12:47:33]: [Client #241] Epoch: [5/5][10/15]	Loss: 2.523567
[INFO][12:47:34]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][12:47:34]: [Client #241] Woke up.
[INFO][12:47:34]: [Client #241] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_615874.pth.
[INFO][12:47:35]: [Client #241] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_615874.pth.
[INFO][12:47:35]: [Client #241] Model trained.
[INFO][12:47:35]: [Client #241] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:47:35]: [Server #615782] Received 0.26 MB of payload data from client #241 (simulated).
[INFO][12:47:35]: [Client #940] Woke up.
[INFO][12:47:35]: [Client #940] Epoch: [2/5][0/16]	Loss: 3.235819
[INFO][12:47:35]: [Client #940] Epoch: [2/5][10/16]	Loss: 3.093788
[INFO][12:47:35]: [Client #940] Going to sleep for 3.49 seconds.
[INFO][12:47:38]: [Client #940] Woke up.
[INFO][12:47:38]: [Client #940] Epoch: [3/5][0/16]	Loss: 2.870212
[INFO][12:47:38]: [Client #940] Epoch: [3/5][10/16]	Loss: 3.327044
[INFO][12:47:38]: [Client #940] Going to sleep for 3.49 seconds.
[INFO][12:47:42]: [Client #940] Woke up.
[INFO][12:47:42]: [Client #940] Epoch: [4/5][0/16]	Loss: 3.479305
[INFO][12:47:42]: [Client #940] Epoch: [4/5][10/16]	Loss: 3.040339
[INFO][12:47:42]: [Client #940] Going to sleep for 3.49 seconds.
[INFO][12:47:46]: [Client #940] Woke up.
[INFO][12:47:46]: [Client #940] Epoch: [5/5][0/16]	Loss: 2.952840
[INFO][12:47:46]: [Client #940] Epoch: [5/5][10/16]	Loss: 2.990424
[INFO][12:47:46]: [Client #940] Going to sleep for 3.49 seconds.
[INFO][12:47:49]: [Client #940] Woke up.
[INFO][12:47:49]: [Client #940] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_940_615875.pth.
[INFO][12:47:50]: [Client #940] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_940_615875.pth.
[INFO][12:47:50]: [Client #940] Model trained.
[INFO][12:47:50]: [Client #940] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:47:50]: [Server #615782] Received 0.26 MB of payload data from client #940 (simulated).
[INFO][12:47:50]: [Server #615782] Selecting client #686 for training.
[INFO][12:47:50]: [Server #615782] Sending the current model to client #686 (simulated).
[INFO][12:47:50]: [Server #615782] Sending 0.26 MB of payload data to client #686 (simulated).
[INFO][12:47:50]: [Server #615782] Selecting client #69 for training.
[INFO][12:47:50]: [Server #615782] Sending the current model to client #69 (simulated).
[INFO][12:47:50]: [Server #615782] Sending 0.26 MB of payload data to client #69 (simulated).
[INFO][12:47:50]: [Client #686] Selected by the server.
[INFO][12:47:50]: [Client #686] Loading its data source...
[INFO][12:47:50]: Data source: FEMNIST
[INFO][12:47:50]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:47:50]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/686.zip.
[INFO][12:47:50]: [Client #69] Selected by the server.
[INFO][12:47:50]: [Client #69] Loading its data source...
[INFO][12:47:50]: Data source: FEMNIST
[INFO][12:47:50]: [Client #69] Dataset size: 161
[INFO][12:47:50]: [Client #69] Sampler: all_inclusive
[INFO][12:47:50]: [Client #69] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:47:50]: [93m[1m[Client #69] Started training in communication round #2.[0m
2.7%5.4%8.0%10.7%13.4%16.1%18.7%21.4%24.1%26.8%29.4%32.1%34.8%37.5%40.1%42.8%45.5%48.2%50.8%53.5%56.2%58.9%61.5%64.2%66.9%69.6%72.2%74.9%77.6%80.3%82.9%85.6%88.3%91.0%93.6%96.3%99.0%100.0%[INFO][12:47:50]: Decompressing the dataset downloaded.
[INFO][12:47:50]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/686.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:47:50]: [Client #686] Dataset size: 149
[INFO][12:47:50]: [Client #686] Sampler: all_inclusive
[INFO][12:47:50]: [Client #686] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:47:50]: [93m[1m[Client #686] Started training in communication round #2.[0m

[INFO][12:47:52]: [Client #69] Loading the dataset.
[INFO][12:47:52]: [Client #686] Loading the dataset.
[INFO][12:47:57]: [Client #69] Epoch: [1/5][0/17]	Loss: 3.637480
[INFO][12:47:57]: [Client #686] Epoch: [1/5][0/15]	Loss: 3.686631
[INFO][12:47:57]: [Client #69] Epoch: [1/5][10/17]	Loss: 3.209271
[INFO][12:47:58]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][12:47:58]: [Client #686] Epoch: [1/5][10/15]	Loss: 3.873875
[INFO][12:47:58]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][12:48:01]: [Client #686] Woke up.
[INFO][12:48:01]: [Client #686] Epoch: [2/5][0/15]	Loss: 3.122396
[INFO][12:48:01]: [Client #686] Epoch: [2/5][10/15]	Loss: 3.233597
[INFO][12:48:01]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][12:48:04]: [Client #686] Woke up.
[INFO][12:48:04]: [Client #686] Epoch: [3/5][0/15]	Loss: 3.326752
[INFO][12:48:05]: [Client #686] Epoch: [3/5][10/15]	Loss: 2.801382
[INFO][12:48:05]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][12:48:08]: [Client #686] Woke up.
[INFO][12:48:08]: [Client #686] Epoch: [4/5][0/15]	Loss: 4.020671
[INFO][12:48:08]: [Client #686] Epoch: [4/5][10/15]	Loss: 2.705462
[INFO][12:48:08]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][12:48:11]: [Client #686] Woke up.
[INFO][12:48:11]: [Client #686] Epoch: [5/5][0/15]	Loss: 2.793307
[INFO][12:48:12]: [Client #686] Epoch: [5/5][10/15]	Loss: 3.143160
[INFO][12:48:12]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][12:48:15]: [Client #69] Woke up.
[INFO][12:48:15]: [Client #69] Epoch: [2/5][0/17]	Loss: 3.605201
[INFO][12:48:15]: [Client #69] Epoch: [2/5][10/17]	Loss: 3.603570
[INFO][12:48:15]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][12:48:15]: [Client #686] Woke up.
[INFO][12:48:15]: [Client #686] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_686_615874.pth.
[INFO][12:48:16]: [Client #686] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_686_615874.pth.
[INFO][12:48:16]: [Client #686] Model trained.
[INFO][12:48:16]: [Client #686] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:48:16]: [Server #615782] Received 0.26 MB of payload data from client #686 (simulated).
[INFO][12:48:32]: [Client #69] Woke up.
[INFO][12:48:32]: [Client #69] Epoch: [3/5][0/17]	Loss: 3.293839
[INFO][12:48:32]: [Client #69] Epoch: [3/5][10/17]	Loss: 2.949944
[INFO][12:48:32]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][12:48:49]: [Client #69] Woke up.
[INFO][12:48:49]: [Client #69] Epoch: [4/5][0/17]	Loss: 3.244703
[INFO][12:48:49]: [Client #69] Epoch: [4/5][10/17]	Loss: 3.490127
[INFO][12:48:49]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][12:49:06]: [Client #69] Woke up.
[INFO][12:49:07]: [Client #69] Epoch: [5/5][0/17]	Loss: 2.814218
[INFO][12:49:07]: [Client #69] Epoch: [5/5][10/17]	Loss: 3.350332
[INFO][12:49:07]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][12:49:24]: [Client #69] Woke up.
[INFO][12:49:24]: [Client #69] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_69_615875.pth.
[INFO][12:49:24]: [Client #69] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_69_615875.pth.
[INFO][12:49:24]: [Client #69] Model trained.
[INFO][12:49:24]: [Client #69] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:49:24]: [Server #615782] Received 0.26 MB of payload data from client #69 (simulated).
[INFO][12:49:24]: [Server #615782] Selecting client #870 for training.
[INFO][12:49:24]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][12:49:24]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][12:49:24]: [Server #615782] Selecting client #702 for training.
[INFO][12:49:24]: [Server #615782] Sending the current model to client #702 (simulated).
[INFO][12:49:24]: [Server #615782] Sending 0.26 MB of payload data to client #702 (simulated).
[INFO][12:49:24]: [Client #870] Selected by the server.
[INFO][12:49:24]: [Client #702] Selected by the server.
[INFO][12:49:24]: [Client #870] Loading its data source...
[INFO][12:49:24]: [Client #702] Loading its data source...
[INFO][12:49:24]: Data source: FEMNIST
[INFO][12:49:24]: Data source: FEMNIST
[INFO][12:49:24]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:49:24]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:49:24]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/870.zip.
[INFO][12:49:24]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/702.zip.
2.8%5.6%8.4%11.2%14.0%16.8%19.6%22.4%25.2%28.0%30.8%33.6%36.4%39.2%42.0%44.8%47.6%3.3%6.6%9.9%13.2%16.5%19.8%23.1%26.4%29.6%32.9%36.2%39.5%42.8%46.1%49.4%52.7%56.0%50.4%53.2%56.0%58.8%61.5%64.3%67.1%69.9%72.7%75.5%78.3%81.1%83.9%86.7%89.5%92.3%95.1%97.9%100.0%[INFO][12:49:25]: Decompressing the dataset downloaded.
[INFO][12:49:25]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/870.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
59.3%62.6%65.9%69.2%72.5%75.8%79.1%82.4%85.6%88.9%92.2%95.5%98.8%[INFO][12:49:25]: [Client #870] Dataset size: 148
[INFO][12:49:25]: [Client #870] Sampler: all_inclusive
100.0%[INFO][12:49:25]: Decompressing the dataset downloaded.
[INFO][12:49:25]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/702.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:49:25]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:49:25]: [93m[1m[Client #870] Started training in communication round #2.[0m

[INFO][12:49:25]: [Client #702] Dataset size: 150
[INFO][12:49:25]: [Client #702] Sampler: all_inclusive
[INFO][12:49:25]: [Client #702] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:49:25]: [93m[1m[Client #702] Started training in communication round #2.[0m

[INFO][12:49:27]: [Client #870] Loading the dataset.
[INFO][12:49:27]: [Client #702] Loading the dataset.
[INFO][12:49:32]: [Client #870] Epoch: [1/5][0/15]	Loss: 3.436922
[INFO][12:49:32]: [Client #702] Epoch: [1/5][0/15]	Loss: 3.253150
[INFO][12:49:32]: [Client #870] Epoch: [1/5][10/15]	Loss: 3.302358
[INFO][12:49:32]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][12:49:32]: [Client #702] Epoch: [1/5][10/15]	Loss: 3.597463
[INFO][12:49:33]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][12:49:33]: [Client #702] Woke up.
[INFO][12:49:33]: [Client #702] Epoch: [2/5][0/15]	Loss: 2.670230
[INFO][12:49:33]: [Client #702] Epoch: [2/5][10/15]	Loss: 3.351934
[INFO][12:49:33]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][12:49:33]: [Client #702] Woke up.
[INFO][12:49:33]: [Client #702] Epoch: [3/5][0/15]	Loss: 2.963598
[INFO][12:49:34]: [Client #702] Epoch: [3/5][10/15]	Loss: 3.190740
[INFO][12:49:34]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][12:49:34]: [Client #702] Woke up.
[INFO][12:49:34]: [Client #702] Epoch: [4/5][0/15]	Loss: 3.548880
[INFO][12:49:34]: [Client #702] Epoch: [4/5][10/15]	Loss: 3.684863
[INFO][12:49:34]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][12:49:35]: [Client #702] Woke up.
[INFO][12:49:35]: [Client #702] Epoch: [5/5][0/15]	Loss: 2.948577
[INFO][12:49:35]: [Client #702] Epoch: [5/5][10/15]	Loss: 3.024939
[INFO][12:49:35]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][12:49:35]: [Client #702] Woke up.
[INFO][12:49:35]: [Client #702] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_702_615875.pth.
[INFO][12:49:36]: [Client #702] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_702_615875.pth.
[INFO][12:49:36]: [Client #702] Model trained.
[INFO][12:49:36]: [Client #702] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:49:36]: [Server #615782] Received 0.26 MB of payload data from client #702 (simulated).
[INFO][12:50:33]: [Client #870] Woke up.
[INFO][12:50:33]: [Client #870] Epoch: [2/5][0/15]	Loss: 3.507612
[INFO][12:50:33]: [Client #870] Epoch: [2/5][10/15]	Loss: 3.731936
[INFO][12:50:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][12:51:33]: [Client #870] Woke up.
[INFO][12:51:33]: [Client #870] Epoch: [3/5][0/15]	Loss: 3.344436
[INFO][12:51:33]: [Client #870] Epoch: [3/5][10/15]	Loss: 4.072793
[INFO][12:51:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][12:52:33]: [Client #870] Woke up.
[INFO][12:52:33]: [Client #870] Epoch: [4/5][0/15]	Loss: 3.293903
[INFO][12:52:33]: [Client #870] Epoch: [4/5][10/15]	Loss: 3.215781
[INFO][12:52:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][12:53:33]: [Client #870] Woke up.
[INFO][12:53:33]: [Client #870] Epoch: [5/5][0/15]	Loss: 2.715006
[INFO][12:53:34]: [Client #870] Epoch: [5/5][10/15]	Loss: 2.692345
[INFO][12:53:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][12:54:34]: [Client #870] Woke up.
[INFO][12:54:34]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][12:54:34]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][12:54:34]: [Client #870] Model trained.
[INFO][12:54:34]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:54:34]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][12:54:34]: [Server #615782] Selecting client #605 for training.
[INFO][12:54:34]: [Server #615782] Sending the current model to client #605 (simulated).
[INFO][12:54:34]: [Server #615782] Sending 0.26 MB of payload data to client #605 (simulated).
[INFO][12:54:34]: [Server #615782] Selecting client #733 for training.
[INFO][12:54:34]: [Server #615782] Sending the current model to client #733 (simulated).
[INFO][12:54:34]: [Server #615782] Sending 0.26 MB of payload data to client #733 (simulated).
[INFO][12:54:34]: [Client #605] Selected by the server.
[INFO][12:54:34]: [Client #605] Loading its data source...
[INFO][12:54:34]: Data source: FEMNIST
[INFO][12:54:34]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:54:34]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/605.zip.
[INFO][12:54:34]: [Client #733] Selected by the server.
[INFO][12:54:34]: [Client #733] Loading its data source...
[INFO][12:54:34]: Data source: FEMNIST
[INFO][12:54:34]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:54:34]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/733.zip.
3.1%2.7%5.4%8.2%10.9%13.6%16.3%19.0%21.8%24.5%27.2%29.9%32.6%35.4%38.1%40.8%43.5%6.1%9.2%12.2%15.3%18.3%21.4%24.5%27.5%30.6%33.6%36.7%39.7%42.8%45.9%48.9%52.0%55.0%58.1%61.1%64.2%67.3%70.3%73.4%76.4%79.5%82.5%85.6%88.7%91.7%94.8%97.8%46.2%48.9%51.7%54.4%57.1%59.8%62.5%65.3%68.0%100.0%[INFO][12:54:35]: Decompressing the dataset downloaded.
[INFO][12:54:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/605.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
70.7%73.4%76.1%78.9%81.6%84.3%87.0%89.7%92.5%95.2%97.9%100.0%[INFO][12:54:35]: Decompressing the dataset downloaded.
[INFO][12:54:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/733.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:54:35]: [Client #605] Dataset size: 153
[INFO][12:54:35]: [Client #605] Sampler: all_inclusive
[INFO][12:54:35]: [Client #605] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:54:35]: [93m[1m[Client #605] Started training in communication round #2.[0m

[INFO][12:54:35]: [Client #733] Dataset size: 171
[INFO][12:54:35]: [Client #733] Sampler: all_inclusive
[INFO][12:54:35]: [Client #733] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:54:35]: [93m[1m[Client #733] Started training in communication round #2.[0m

[INFO][12:54:37]: [Client #733] Loading the dataset.
[INFO][12:54:37]: [Client #605] Loading the dataset.
[INFO][12:54:42]: [Client #605] Epoch: [1/5][0/16]	Loss: 3.567183
[INFO][12:54:43]: [Client #733] Epoch: [1/5][0/18]	Loss: 3.899387
[INFO][12:54:43]: [Client #605] Epoch: [1/5][10/16]	Loss: 3.746815
[INFO][12:54:43]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][12:54:43]: [Client #733] Epoch: [1/5][10/18]	Loss: 3.654978
[INFO][12:54:43]: [Client #733] Going to sleep for 5.58 seconds.
[INFO][12:54:43]: [Client #605] Woke up.
[INFO][12:54:43]: [Client #605] Epoch: [2/5][0/16]	Loss: 3.168031
[INFO][12:54:43]: [Client #605] Epoch: [2/5][10/16]	Loss: 4.136120
[INFO][12:54:43]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][12:54:43]: [Client #605] Woke up.
[INFO][12:54:43]: [Client #605] Epoch: [3/5][0/16]	Loss: 3.297401
[INFO][12:54:43]: [Client #605] Epoch: [3/5][10/16]	Loss: 4.277911
[INFO][12:54:43]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][12:54:44]: [Client #605] Woke up.
[INFO][12:54:44]: [Client #605] Epoch: [4/5][0/16]	Loss: 2.914156
[INFO][12:54:44]: [Client #605] Epoch: [4/5][10/16]	Loss: 2.827858
[INFO][12:54:44]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][12:54:44]: [Client #605] Woke up.
[INFO][12:54:44]: [Client #605] Epoch: [5/5][0/16]	Loss: 3.717019
[INFO][12:54:44]: [Client #605] Epoch: [5/5][10/16]	Loss: 2.675858
[INFO][12:54:44]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][12:54:44]: [Client #605] Woke up.
[INFO][12:54:44]: [Client #605] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_605_615874.pth.
[INFO][12:54:45]: [Client #605] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_605_615874.pth.
[INFO][12:54:45]: [Client #605] Model trained.
[INFO][12:54:45]: [Client #605] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:54:45]: [Server #615782] Received 0.26 MB of payload data from client #605 (simulated).
[INFO][12:54:48]: [Client #733] Woke up.
[INFO][12:54:48]: [Client #733] Epoch: [2/5][0/18]	Loss: 3.469692
[INFO][12:54:48]: [Client #733] Epoch: [2/5][10/18]	Loss: 3.642368
[INFO][12:54:48]: [Client #733] Going to sleep for 5.58 seconds.
[INFO][12:54:54]: [Client #733] Woke up.
[INFO][12:54:54]: [Client #733] Epoch: [3/5][0/18]	Loss: 3.747144
[INFO][12:54:54]: [Client #733] Epoch: [3/5][10/18]	Loss: 3.570760
[INFO][12:54:54]: [Client #733] Going to sleep for 5.58 seconds.
[INFO][12:55:00]: [Client #733] Woke up.
[INFO][12:55:00]: [Client #733] Epoch: [4/5][0/18]	Loss: 3.584233
[INFO][12:55:00]: [Client #733] Epoch: [4/5][10/18]	Loss: 3.423349
[INFO][12:55:00]: [Client #733] Going to sleep for 5.58 seconds.
[INFO][12:55:05]: [Client #733] Woke up.
[INFO][12:55:05]: [Client #733] Epoch: [5/5][0/18]	Loss: 3.324857
[INFO][12:55:06]: [Client #733] Epoch: [5/5][10/18]	Loss: 3.749213
[INFO][12:55:06]: [Client #733] Going to sleep for 5.58 seconds.
[INFO][12:55:11]: [Client #733] Woke up.
[INFO][12:55:11]: [Client #733] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_733_615875.pth.
[INFO][12:55:12]: [Client #733] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_733_615875.pth.
[INFO][12:55:12]: [Client #733] Model trained.
[INFO][12:55:12]: [Client #733] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:55:12]: [Server #615782] Received 0.26 MB of payload data from client #733 (simulated).
[INFO][12:55:12]: [Server #615782] Selecting client #259 for training.
[INFO][12:55:12]: [Server #615782] Sending the current model to client #259 (simulated).
[INFO][12:55:12]: [Server #615782] Sending 0.26 MB of payload data to client #259 (simulated).
[INFO][12:55:12]: [Server #615782] Selecting client #601 for training.
[INFO][12:55:12]: [Server #615782] Sending the current model to client #601 (simulated).
[INFO][12:55:12]: [Server #615782] Sending 0.26 MB of payload data to client #601 (simulated).
[INFO][12:55:12]: [Client #259] Selected by the server.
[INFO][12:55:12]: [Client #259] Loading its data source...
[INFO][12:55:12]: Data source: FEMNIST
[INFO][12:55:12]: [Client #601] Selected by the server.
[INFO][12:55:12]: [Client #601] Loading its data source...
[INFO][12:55:12]: Data source: FEMNIST
[INFO][12:55:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:55:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/601.zip.
[INFO][12:55:12]: [Client #259] Dataset size: 125
[INFO][12:55:12]: [Client #259] Sampler: all_inclusive
[INFO][12:55:12]: [Client #259] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:12]: [93m[1m[Client #259] Started training in communication round #2.[0m
2.9%5.9%8.8%11.7%14.6%17.6%20.5%23.4%26.3%29.3%32.2%35.1%38.0%41.0%43.9%46.8%49.7%52.7%55.6%58.5%61.4%64.4%67.3%70.2%73.1%76.1%79.0%81.9%84.8%87.8%90.7%93.6%96.5%99.5%100.0%[INFO][12:55:12]: Decompressing the dataset downloaded.
[INFO][12:55:12]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/601.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:55:12]: [Client #601] Dataset size: 146
[INFO][12:55:12]: [Client #601] Sampler: all_inclusive
[INFO][12:55:12]: [Client #601] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:12]: [93m[1m[Client #601] Started training in communication round #2.[0m

[INFO][12:55:14]: [Client #259] Loading the dataset.
[INFO][12:55:14]: [Client #601] Loading the dataset.
[INFO][12:55:20]: [Client #259] Epoch: [1/5][0/13]	Loss: 3.271587
[INFO][12:55:20]: [Client #601] Epoch: [1/5][0/15]	Loss: 2.997554
[INFO][12:55:20]: [Client #259] Epoch: [1/5][10/13]	Loss: 2.991022
[INFO][12:55:20]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:55:20]: [Client #601] Epoch: [1/5][10/15]	Loss: 3.293596
[INFO][12:55:20]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][12:55:20]: [Client #259] Woke up.
[INFO][12:55:20]: [Client #259] Epoch: [2/5][0/13]	Loss: 3.131591
[INFO][12:55:20]: [Client #259] Epoch: [2/5][10/13]	Loss: 2.707686
[INFO][12:55:20]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:55:21]: [Client #259] Woke up.
[INFO][12:55:21]: [Client #259] Epoch: [3/5][0/13]	Loss: 2.932931
[INFO][12:55:21]: [Client #259] Epoch: [3/5][10/13]	Loss: 2.973101
[INFO][12:55:21]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:55:21]: [Client #259] Woke up.
[INFO][12:55:21]: [Client #259] Epoch: [4/5][0/13]	Loss: 2.295494
[INFO][12:55:21]: [Client #259] Epoch: [4/5][10/13]	Loss: 2.744426
[INFO][12:55:21]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:55:22]: [Client #259] Woke up.
[INFO][12:55:22]: [Client #259] Epoch: [5/5][0/13]	Loss: 2.401049
[INFO][12:55:22]: [Client #259] Epoch: [5/5][10/13]	Loss: 2.629922
[INFO][12:55:22]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:55:22]: [Client #601] Woke up.
[INFO][12:55:22]: [Client #601] Epoch: [2/5][0/15]	Loss: 3.231573
[INFO][12:55:22]: [Client #601] Epoch: [2/5][10/15]	Loss: 3.183952
[INFO][12:55:22]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][12:55:22]: [Client #259] Woke up.
[INFO][12:55:22]: [Client #259] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_615874.pth.
[INFO][12:55:23]: [Client #259] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_615874.pth.
[INFO][12:55:23]: [Client #259] Model trained.
[INFO][12:55:23]: [Client #259] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:55:23]: [Server #615782] Received 0.26 MB of payload data from client #259 (simulated).
[INFO][12:55:24]: [Client #601] Woke up.
[INFO][12:55:24]: [Client #601] Epoch: [3/5][0/15]	Loss: 3.003206
[INFO][12:55:24]: [Client #601] Epoch: [3/5][10/15]	Loss: 3.088990
[INFO][12:55:24]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][12:55:26]: [Client #601] Woke up.
[INFO][12:55:26]: [Client #601] Epoch: [4/5][0/15]	Loss: 3.169569
[INFO][12:55:26]: [Client #601] Epoch: [4/5][10/15]	Loss: 3.261836
[INFO][12:55:26]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][12:55:28]: [Client #601] Woke up.
[INFO][12:55:28]: [Client #601] Epoch: [5/5][0/15]	Loss: 3.273770
[INFO][12:55:29]: [Client #601] Epoch: [5/5][10/15]	Loss: 3.160178
[INFO][12:55:29]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][12:55:31]: [Client #601] Woke up.
[INFO][12:55:31]: [Client #601] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_601_615875.pth.
[INFO][12:55:31]: [Client #601] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_601_615875.pth.
[INFO][12:55:31]: [Client #601] Model trained.
[INFO][12:55:31]: [Client #601] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:55:31]: [Server #615782] Received 0.26 MB of payload data from client #601 (simulated).
[INFO][12:55:31]: [Server #615782] Selecting client #815 for training.
[INFO][12:55:31]: [Server #615782] Sending the current model to client #815 (simulated).
[INFO][12:55:31]: [Server #615782] Sending 0.26 MB of payload data to client #815 (simulated).
[INFO][12:55:31]: [Server #615782] Selecting client #58 for training.
[INFO][12:55:31]: [Server #615782] Sending the current model to client #58 (simulated).
[INFO][12:55:31]: [Server #615782] Sending 0.26 MB of payload data to client #58 (simulated).
[INFO][12:55:31]: [Client #58] Selected by the server.
[INFO][12:55:31]: [Client #58] Loading its data source...
[INFO][12:55:31]: [Client #815] Selected by the server.
[INFO][12:55:31]: Data source: FEMNIST
[INFO][12:55:31]: [Client #815] Loading its data source...
[INFO][12:55:31]: Data source: FEMNIST
[INFO][12:55:31]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:55:31]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/815.zip.
[INFO][12:55:31]: [Client #58] Dataset size: 130
[INFO][12:55:31]: [Client #58] Sampler: all_inclusive
[INFO][12:55:31]: [Client #58] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:31]: [93m[1m[Client #58] Started training in communication round #2.[0m
3.0%5.9%8.9%11.8%14.8%17.8%20.7%23.7%26.6%29.6%32.5%35.5%38.5%41.4%44.4%47.3%50.3%53.3%56.2%59.2%62.1%65.1%68.1%71.0%74.0%76.9%79.9%82.9%85.8%88.8%91.7%94.7%97.6%100.0%[INFO][12:55:32]: Decompressing the dataset downloaded.
[INFO][12:55:32]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/815.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:55:32]: [Client #815] Dataset size: 158
[INFO][12:55:32]: [Client #815] Sampler: all_inclusive
[INFO][12:55:32]: [Client #815] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:32]: [93m[1m[Client #815] Started training in communication round #2.[0m

[INFO][12:55:33]: [Client #58] Loading the dataset.
[INFO][12:55:34]: [Client #815] Loading the dataset.
[INFO][12:55:39]: [Client #58] Epoch: [1/5][0/13]	Loss: 3.056609
[INFO][12:55:39]: [Client #815] Epoch: [1/5][0/16]	Loss: 3.597971
[INFO][12:55:39]: [Client #58] Epoch: [1/5][10/13]	Loss: 3.153375
[INFO][12:55:39]: [Client #58] Going to sleep for 0.17 seconds.
[INFO][12:55:39]: [Client #815] Epoch: [1/5][10/16]	Loss: 3.171731
[INFO][12:55:39]: [Client #815] Going to sleep for 3.54 seconds.
[INFO][12:55:39]: [Client #58] Woke up.
[INFO][12:55:39]: [Client #58] Epoch: [2/5][0/13]	Loss: 2.747413
[INFO][12:55:39]: [Client #58] Epoch: [2/5][10/13]	Loss: 3.651262
[INFO][12:55:39]: [Client #58] Going to sleep for 0.17 seconds.
[INFO][12:55:39]: [Client #58] Woke up.
[INFO][12:55:39]: [Client #58] Epoch: [3/5][0/13]	Loss: 3.314607
[INFO][12:55:39]: [Client #58] Epoch: [3/5][10/13]	Loss: 3.008963
[INFO][12:55:39]: [Client #58] Going to sleep for 0.17 seconds.
[INFO][12:55:40]: [Client #58] Woke up.
[INFO][12:55:40]: [Client #58] Epoch: [4/5][0/13]	Loss: 3.060489
[INFO][12:55:40]: [Client #58] Epoch: [4/5][10/13]	Loss: 2.291796
[INFO][12:55:40]: [Client #58] Going to sleep for 0.17 seconds.
[INFO][12:55:40]: [Client #58] Woke up.
[INFO][12:55:40]: [Client #58] Epoch: [5/5][0/13]	Loss: 2.949248
[INFO][12:55:40]: [Client #58] Epoch: [5/5][10/13]	Loss: 2.279237
[INFO][12:55:40]: [Client #58] Going to sleep for 0.17 seconds.
[INFO][12:55:40]: [Client #58] Woke up.
[INFO][12:55:40]: [Client #58] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_58_615875.pth.
[INFO][12:55:41]: [Client #58] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_58_615875.pth.
[INFO][12:55:41]: [Client #58] Model trained.
[INFO][12:55:41]: [Client #58] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:55:41]: [Server #615782] Received 0.26 MB of payload data from client #58 (simulated).
[INFO][12:55:42]: [Client #815] Woke up.
[INFO][12:55:43]: [Client #815] Epoch: [2/5][0/16]	Loss: 3.986204
[INFO][12:55:43]: [Client #815] Epoch: [2/5][10/16]	Loss: 3.078448
[INFO][12:55:43]: [Client #815] Going to sleep for 3.54 seconds.
[INFO][12:55:46]: [Client #815] Woke up.
[INFO][12:55:46]: [Client #815] Epoch: [3/5][0/16]	Loss: 3.099268
[INFO][12:55:46]: [Client #815] Epoch: [3/5][10/16]	Loss: 3.480827
[INFO][12:55:46]: [Client #815] Going to sleep for 3.54 seconds.
[INFO][12:55:50]: [Client #815] Woke up.
[INFO][12:55:50]: [Client #815] Epoch: [4/5][0/16]	Loss: 3.353882
[INFO][12:55:50]: [Client #815] Epoch: [4/5][10/16]	Loss: 3.445650
[INFO][12:55:50]: [Client #815] Going to sleep for 3.54 seconds.
[INFO][12:55:54]: [Client #815] Woke up.
[INFO][12:55:54]: [Client #815] Epoch: [5/5][0/16]	Loss: 3.106556
[INFO][12:55:54]: [Client #815] Epoch: [5/5][10/16]	Loss: 2.455020
[INFO][12:55:54]: [Client #815] Going to sleep for 3.54 seconds.
[INFO][12:55:57]: [Client #815] Woke up.
[INFO][12:55:57]: [Client #815] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_815_615874.pth.
[INFO][12:55:58]: [Client #815] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_815_615874.pth.
[INFO][12:55:58]: [Client #815] Model trained.
[INFO][12:55:58]: [Client #815] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:55:58]: [Server #615782] Received 0.26 MB of payload data from client #815 (simulated).
[INFO][12:55:58]: [Server #615782] Selecting client #136 for training.
[INFO][12:55:58]: [Server #615782] Sending the current model to client #136 (simulated).
[INFO][12:55:58]: [Server #615782] Sending 0.26 MB of payload data to client #136 (simulated).
[INFO][12:55:58]: [Server #615782] Selecting client #842 for training.
[INFO][12:55:58]: [Server #615782] Sending the current model to client #842 (simulated).
[INFO][12:55:58]: [Server #615782] Sending 0.26 MB of payload data to client #842 (simulated).
[INFO][12:55:58]: [Client #842] Selected by the server.
[INFO][12:55:58]: [Client #842] Loading its data source...
[INFO][12:55:58]: Data source: FEMNIST
[INFO][12:55:58]: [Client #136] Selected by the server.
[INFO][12:55:58]: [Client #136] Loading its data source...
[INFO][12:55:58]: Data source: FEMNIST
[INFO][12:55:58]: [Client #842] Dataset size: 160
[INFO][12:55:58]: [Client #842] Sampler: all_inclusive
[INFO][12:55:58]: [Client #842] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:58]: [93m[1m[Client #842] Started training in communication round #2.[0m
[INFO][12:55:58]: [Client #136] Dataset size: 158
[INFO][12:55:58]: [Client #136] Sampler: all_inclusive
[INFO][12:55:58]: [Client #136] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:55:58]: [93m[1m[Client #136] Started training in communication round #2.[0m
[INFO][12:56:00]: [Client #842] Loading the dataset.
[INFO][12:56:00]: [Client #136] Loading the dataset.
[INFO][12:56:06]: [Client #842] Epoch: [1/5][0/16]	Loss: 3.328246
[INFO][12:56:06]: [Client #136] Epoch: [1/5][0/16]	Loss: 3.425716
[INFO][12:56:06]: [Client #842] Epoch: [1/5][10/16]	Loss: 3.906239
[INFO][12:56:06]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:56:06]: [Client #136] Epoch: [1/5][10/16]	Loss: 3.651530
[INFO][12:56:06]: [Client #136] Going to sleep for 0.30 seconds.
[INFO][12:56:06]: [Client #136] Woke up.
[INFO][12:56:06]: [Client #136] Epoch: [2/5][0/16]	Loss: 3.281078
[INFO][12:56:06]: [Client #136] Epoch: [2/5][10/16]	Loss: 3.023282
[INFO][12:56:06]: [Client #136] Going to sleep for 0.30 seconds.
[INFO][12:56:07]: [Client #842] Woke up.
[INFO][12:56:07]: [Client #842] Epoch: [2/5][0/16]	Loss: 3.425863
[INFO][12:56:07]: [Client #842] Epoch: [2/5][10/16]	Loss: 3.612954
[INFO][12:56:07]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:56:07]: [Client #136] Woke up.
[INFO][12:56:07]: [Client #136] Epoch: [3/5][0/16]	Loss: 3.600145
[INFO][12:56:07]: [Client #136] Epoch: [3/5][10/16]	Loss: 3.464672
[INFO][12:56:07]: [Client #136] Going to sleep for 0.30 seconds.
[INFO][12:56:07]: [Client #842] Woke up.
[INFO][12:56:07]: [Client #842] Epoch: [3/5][0/16]	Loss: 3.569962
[INFO][12:56:07]: [Client #136] Woke up.
[INFO][12:56:07]: [Client #136] Epoch: [4/5][0/16]	Loss: 2.421257
[INFO][12:56:07]: [Client #842] Epoch: [3/5][10/16]	Loss: 2.316710
[INFO][12:56:07]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:56:07]: [Client #136] Epoch: [4/5][10/16]	Loss: 3.269547
[INFO][12:56:07]: [Client #136] Going to sleep for 0.30 seconds.
[INFO][12:56:08]: [Client #136] Woke up.
[INFO][12:56:08]: [Client #136] Epoch: [5/5][0/16]	Loss: 3.371127
[INFO][12:56:08]: [Client #136] Epoch: [5/5][10/16]	Loss: 3.149485
[INFO][12:56:08]: [Client #136] Going to sleep for 0.30 seconds.
[INFO][12:56:08]: [Client #842] Woke up.
[INFO][12:56:08]: [Client #842] Epoch: [4/5][0/16]	Loss: 2.644825
[INFO][12:56:08]: [Client #842] Epoch: [4/5][10/16]	Loss: 3.623591
[INFO][12:56:08]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:56:08]: [Client #136] Woke up.
[INFO][12:56:08]: [Client #136] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_136_615874.pth.
[INFO][12:56:09]: [Client #842] Woke up.
[INFO][12:56:09]: [Client #842] Epoch: [5/5][0/16]	Loss: 2.595014
[INFO][12:56:09]: [Client #842] Epoch: [5/5][10/16]	Loss: 2.297599
[INFO][12:56:09]: [Client #842] Going to sleep for 0.52 seconds.
[INFO][12:56:09]: [Client #136] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_136_615874.pth.
[INFO][12:56:09]: [Client #136] Model trained.
[INFO][12:56:09]: [Client #136] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:56:09]: [Server #615782] Received 0.26 MB of payload data from client #136 (simulated).
[INFO][12:56:09]: [Client #842] Woke up.
[INFO][12:56:09]: [Client #842] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_842_615875.pth.
[INFO][12:56:10]: [Client #842] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_842_615875.pth.
[INFO][12:56:10]: [Client #842] Model trained.
[INFO][12:56:10]: [Client #842] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:56:10]: [Server #615782] Received 0.26 MB of payload data from client #842 (simulated).
[INFO][12:56:10]: [Server #615782] Selecting client #619 for training.
[INFO][12:56:10]: [Server #615782] Sending the current model to client #619 (simulated).
[INFO][12:56:10]: [Server #615782] Sending 0.26 MB of payload data to client #619 (simulated).
[INFO][12:56:10]: [Server #615782] Selecting client #533 for training.
[INFO][12:56:10]: [Server #615782] Sending the current model to client #533 (simulated).
[INFO][12:56:10]: [Server #615782] Sending 0.26 MB of payload data to client #533 (simulated).
[INFO][12:56:10]: [Client #619] Selected by the server.
[INFO][12:56:10]: [Client #533] Selected by the server.
[INFO][12:56:10]: [Client #619] Loading its data source...
[INFO][12:56:10]: [Client #533] Loading its data source...
[INFO][12:56:10]: Data source: FEMNIST
[INFO][12:56:10]: Data source: FEMNIST
[INFO][12:56:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:56:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:56:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/533.zip.
[INFO][12:56:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/619.zip.
1.6%3.8%7.6%11.3%15.1%18.9%22.7%26.5%30.2%34.0%37.8%41.6%45.3%49.1%52.9%56.7%60.5%64.2%3.3%4.9%6.6%8.2%9.9%11.5%13.2%14.8%16.5%18.1%19.7%21.4%23.0%24.7%26.3%28.0%29.6%31.3%32.9%34.5%36.2%37.8%39.5%41.1%42.8%44.4%46.1%47.7%49.4%51.0%52.6%54.3%55.9%57.6%59.2%60.9%62.5%64.2%65.8%67.5%69.1%70.7%72.4%74.0%75.7%77.3%79.0%80.6%82.3%83.9%85.5%68.0%71.8%75.6%79.4%83.1%86.9%90.7%94.5%98.2%100.0%[INFO][12:56:10]: Decompressing the dataset downloaded.
[INFO][12:56:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/619.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
87.2%88.8%90.5%92.1%93.8%95.4%97.1%98.7%100.0%[INFO][12:56:10]: Decompressing the dataset downloaded.
[INFO][12:56:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/533.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:56:10]: [Client #619] Dataset size: 144
[INFO][12:56:10]: [Client #619] Sampler: all_inclusive
[INFO][12:56:10]: [Client #619] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:56:10]: [93m[1m[Client #619] Started training in communication round #2.[0m

[INFO][12:56:10]: [Client #533] Dataset size: 273
[INFO][12:56:10]: [Client #533] Sampler: all_inclusive
[INFO][12:56:10]: [Client #533] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:56:10]: [93m[1m[Client #533] Started training in communication round #2.[0m

[INFO][12:56:12]: [Client #619] Loading the dataset.
[INFO][12:56:12]: [Client #533] Loading the dataset.
[INFO][12:56:18]: [Client #619] Epoch: [1/5][0/15]	Loss: 3.303296
[INFO][12:56:18]: [Client #619] Epoch: [1/5][10/15]	Loss: 3.092005
[INFO][12:56:18]: [Client #533] Epoch: [1/5][0/28]	Loss: 3.669516
[INFO][12:56:18]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][12:56:19]: [Client #533] Epoch: [1/5][10/28]	Loss: 4.028488
[INFO][12:56:19]: [Client #533] Epoch: [1/5][20/28]	Loss: 3.840944
[INFO][12:56:19]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][12:56:19]: [Client #619] Woke up.
[INFO][12:56:19]: [Client #619] Epoch: [2/5][0/15]	Loss: 3.443785
[INFO][12:56:19]: [Client #619] Epoch: [2/5][10/15]	Loss: 3.495391
[INFO][12:56:19]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][12:56:20]: [Client #619] Woke up.
[INFO][12:56:20]: [Client #619] Epoch: [3/5][0/15]	Loss: 3.190245
[INFO][12:56:20]: [Client #619] Epoch: [3/5][10/15]	Loss: 2.980368
[INFO][12:56:20]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][12:56:21]: [Client #619] Woke up.
[INFO][12:56:21]: [Client #619] Epoch: [4/5][0/15]	Loss: 2.885306
[INFO][12:56:21]: [Client #619] Epoch: [4/5][10/15]	Loss: 3.278682
[INFO][12:56:21]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][12:56:22]: [Client #619] Woke up.
[INFO][12:56:22]: [Client #619] Epoch: [5/5][0/15]	Loss: 3.276585
[INFO][12:56:22]: [Client #619] Epoch: [5/5][10/15]	Loss: 3.541558
[INFO][12:56:22]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][12:56:23]: [Client #619] Woke up.
[INFO][12:56:23]: [Client #619] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615874.pth.
[INFO][12:56:23]: [Client #619] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615874.pth.
[INFO][12:56:23]: [Client #619] Model trained.
[INFO][12:56:23]: [Client #619] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:56:23]: [Server #615782] Received 0.26 MB of payload data from client #619 (simulated).
[INFO][12:56:54]: [Client #533] Woke up.
[INFO][12:56:55]: [Client #533] Epoch: [2/5][0/28]	Loss: 3.540730
[INFO][12:56:55]: [Client #533] Epoch: [2/5][10/28]	Loss: 3.296010
[INFO][12:56:55]: [Client #533] Epoch: [2/5][20/28]	Loss: 3.953651
[INFO][12:56:55]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][12:57:31]: [Client #533] Woke up.
[INFO][12:57:31]: [Client #533] Epoch: [3/5][0/28]	Loss: 4.009639
[INFO][12:57:31]: [Client #533] Epoch: [3/5][10/28]	Loss: 3.756557
[INFO][12:57:31]: [Client #533] Epoch: [3/5][20/28]	Loss: 3.491749
[INFO][12:57:31]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][12:58:07]: [Client #533] Woke up.
[INFO][12:58:07]: [Client #533] Epoch: [4/5][0/28]	Loss: 3.236100
[INFO][12:58:07]: [Client #533] Epoch: [4/5][10/28]	Loss: 2.918426
[INFO][12:58:07]: [Client #533] Epoch: [4/5][20/28]	Loss: 3.746199
[INFO][12:58:07]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][12:58:43]: [Client #533] Woke up.
[INFO][12:58:43]: [Client #533] Epoch: [5/5][0/28]	Loss: 3.495903
[INFO][12:58:43]: [Client #533] Epoch: [5/5][10/28]	Loss: 2.987780
[INFO][12:58:43]: [Client #533] Epoch: [5/5][20/28]	Loss: 3.170956
[INFO][12:58:43]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][12:59:19]: [Client #533] Woke up.
[INFO][12:59:19]: [Client #533] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615875.pth.
[INFO][12:59:20]: [Client #533] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615875.pth.
[INFO][12:59:20]: [Client #533] Model trained.
[INFO][12:59:20]: [Client #533] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:59:20]: [Server #615782] Received 0.26 MB of payload data from client #533 (simulated).
[INFO][12:59:20]: [Server #615782] Selecting client #254 for training.
[INFO][12:59:20]: [Server #615782] Sending the current model to client #254 (simulated).
[INFO][12:59:20]: [Server #615782] Sending 0.26 MB of payload data to client #254 (simulated).
[INFO][12:59:20]: [Server #615782] Selecting client #299 for training.
[INFO][12:59:20]: [Server #615782] Sending the current model to client #299 (simulated).
[INFO][12:59:20]: [Server #615782] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][12:59:20]: [Client #254] Selected by the server.
[INFO][12:59:20]: [Client #299] Selected by the server.
[INFO][12:59:20]: [Client #254] Loading its data source...
[INFO][12:59:20]: [Client #299] Loading its data source...
[INFO][12:59:20]: Data source: FEMNIST
[INFO][12:59:20]: Data source: FEMNIST
[INFO][12:59:20]: [Client #254] Dataset size: 150
[INFO][12:59:20]: [Client #254] Sampler: all_inclusive
[INFO][12:59:20]: [Client #254] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:59:20]: [93m[1m[Client #254] Started training in communication round #2.[0m
[INFO][12:59:20]: [Client #299] Dataset size: 157
[INFO][12:59:20]: [Client #299] Sampler: all_inclusive
[INFO][12:59:20]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:59:20]: [93m[1m[Client #299] Started training in communication round #2.[0m
[INFO][12:59:22]: [Client #254] Loading the dataset.
[INFO][12:59:22]: [Client #299] Loading the dataset.
[INFO][12:59:27]: [Client #254] Epoch: [1/5][0/15]	Loss: 3.528866
[INFO][12:59:27]: [Client #299] Epoch: [1/5][0/16]	Loss: 3.264079
[INFO][12:59:28]: [Client #254] Epoch: [1/5][10/15]	Loss: 4.068265
[INFO][12:59:28]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][12:59:28]: [Client #299] Epoch: [1/5][10/16]	Loss: 3.888283
[INFO][12:59:28]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][13:00:05]: [Client #254] Woke up.
[INFO][13:00:05]: [Client #254] Epoch: [2/5][0/15]	Loss: 3.510726
[INFO][13:00:05]: [Client #254] Epoch: [2/5][10/15]	Loss: 3.603422
[INFO][13:00:05]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][13:00:25]: [Client #299] Woke up.
[INFO][13:00:25]: [Client #299] Epoch: [2/5][0/16]	Loss: 3.430644
[INFO][13:00:25]: [Client #299] Epoch: [2/5][10/16]	Loss: 3.372482
[INFO][13:00:25]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][13:00:42]: [Client #254] Woke up.
[INFO][13:00:42]: [Client #254] Epoch: [3/5][0/15]	Loss: 3.514306
[INFO][13:00:42]: [Client #254] Epoch: [3/5][10/15]	Loss: 3.652963
[INFO][13:00:42]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][13:01:20]: [Client #254] Woke up.
[INFO][13:01:20]: [Client #254] Epoch: [4/5][0/15]	Loss: 3.216420
[INFO][13:01:20]: [Client #254] Epoch: [4/5][10/15]	Loss: 2.992641
[INFO][13:01:20]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][13:01:22]: [Client #299] Woke up.
[INFO][13:01:22]: [Client #299] Epoch: [3/5][0/16]	Loss: 3.380021
[INFO][13:01:22]: [Client #299] Epoch: [3/5][10/16]	Loss: 3.089328
[INFO][13:01:22]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][13:01:57]: [Client #254] Woke up.
[INFO][13:01:57]: [Client #254] Epoch: [5/5][0/15]	Loss: 2.197759
[INFO][13:01:57]: [Client #254] Epoch: [5/5][10/15]	Loss: 2.489163
[INFO][13:01:57]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][13:02:20]: [Client #299] Woke up.
[INFO][13:02:20]: [Client #299] Epoch: [4/5][0/16]	Loss: 3.390208
[INFO][13:02:20]: [Client #299] Epoch: [4/5][10/16]	Loss: 3.212649
[INFO][13:02:20]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][13:02:34]: [Client #254] Woke up.
[INFO][13:02:34]: [Client #254] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_254_615874.pth.
[INFO][13:02:35]: [Client #254] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_254_615874.pth.
[INFO][13:02:35]: [Client #254] Model trained.
[INFO][13:02:35]: [Client #254] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:02:35]: [Server #615782] Received 0.26 MB of payload data from client #254 (simulated).
[INFO][13:03:17]: [Client #299] Woke up.
[INFO][13:03:17]: [Client #299] Epoch: [5/5][0/16]	Loss: 3.180345
[INFO][13:03:17]: [Client #299] Epoch: [5/5][10/16]	Loss: 4.108598
[INFO][13:03:17]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][13:04:15]: [Client #299] Woke up.
[INFO][13:04:15]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_615875.pth.
[INFO][13:04:15]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_615875.pth.
[INFO][13:04:15]: [Client #299] Model trained.
[INFO][13:04:15]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:15]: [Server #615782] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][13:04:15]: [Server #615782] Selecting client #872 for training.
[INFO][13:04:15]: [Server #615782] Sending the current model to client #872 (simulated).
[INFO][13:04:15]: [Server #615782] Sending 0.26 MB of payload data to client #872 (simulated).
[INFO][13:04:15]: [Server #615782] Selecting client #424 for training.
[INFO][13:04:15]: [Server #615782] Sending the current model to client #424 (simulated).
[INFO][13:04:15]: [Server #615782] Sending 0.26 MB of payload data to client #424 (simulated).
[INFO][13:04:15]: [Client #872] Selected by the server.
[INFO][13:04:15]: [Client #872] Loading its data source...
[INFO][13:04:15]: Data source: FEMNIST
[INFO][13:04:15]: [Client #424] Selected by the server.
[INFO][13:04:15]: [Client #424] Loading its data source...
[INFO][13:04:15]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:04:15]: Data source: FEMNIST
[INFO][13:04:15]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/872.zip.
[INFO][13:04:15]: [Client #424] Dataset size: 160
[INFO][13:04:15]: [Client #424] Sampler: all_inclusive
[INFO][13:04:15]: [Client #424] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:15]: [93m[1m[Client #424] Started training in communication round #2.[0m
2.9%5.7%8.6%11.5%14.3%17.2%20.1%22.9%25.8%28.7%31.5%34.4%37.3%40.2%43.0%45.9%48.8%51.6%54.5%57.4%60.2%63.1%66.0%68.8%71.7%74.6%77.4%80.3%83.2%86.0%88.9%91.8%94.6%97.5%100.0%[INFO][13:04:16]: Decompressing the dataset downloaded.
[INFO][13:04:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/872.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:04:16]: [Client #872] Dataset size: 158
[INFO][13:04:16]: [Client #872] Sampler: all_inclusive
[INFO][13:04:16]: [Client #872] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:16]: [93m[1m[Client #872] Started training in communication round #2.[0m

[INFO][13:04:18]: [Client #424] Loading the dataset.
[INFO][13:04:18]: [Client #872] Loading the dataset.
[INFO][13:04:23]: [Client #424] Epoch: [1/5][0/16]	Loss: 3.401684
[INFO][13:04:23]: [Client #872] Epoch: [1/5][0/16]	Loss: 3.554468
[INFO][13:04:23]: [Client #424] Epoch: [1/5][10/16]	Loss: 3.260601
[INFO][13:04:23]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][13:04:24]: [Client #872] Epoch: [1/5][10/16]	Loss: 3.661242
[INFO][13:04:24]: [Client #424] Woke up.
[INFO][13:04:24]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:04:24]: [Client #424] Epoch: [2/5][0/16]	Loss: 3.936031
[INFO][13:04:24]: [Client #424] Epoch: [2/5][10/16]	Loss: 3.374025
[INFO][13:04:24]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][13:04:24]: [Client #424] Woke up.
[INFO][13:04:24]: [Client #424] Epoch: [3/5][0/16]	Loss: 3.558346
[INFO][13:04:24]: [Client #872] Woke up.
[INFO][13:04:24]: [Client #872] Epoch: [2/5][0/16]	Loss: 3.491613
[INFO][13:04:24]: [Client #424] Epoch: [3/5][10/16]	Loss: 3.761323
[INFO][13:04:24]: [Client #872] Epoch: [2/5][10/16]	Loss: 3.376652
[INFO][13:04:24]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][13:04:24]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:04:24]: [Client #424] Woke up.
[INFO][13:04:24]: [Client #424] Epoch: [4/5][0/16]	Loss: 2.934981
[INFO][13:04:24]: [Client #424] Epoch: [4/5][10/16]	Loss: 3.313746
[INFO][13:04:24]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][13:04:24]: [Client #872] Woke up.
[INFO][13:04:24]: [Client #424] Woke up.
[INFO][13:04:24]: [Client #872] Epoch: [3/5][0/16]	Loss: 2.995239
[INFO][13:04:24]: [Client #424] Epoch: [5/5][0/16]	Loss: 3.454845
[INFO][13:04:24]: [Client #872] Epoch: [3/5][10/16]	Loss: 3.394078
[INFO][13:04:24]: [Client #424] Epoch: [5/5][10/16]	Loss: 3.057548
[INFO][13:04:24]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:04:24]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][13:04:24]: [Client #424] Woke up.
[INFO][13:04:24]: [Client #424] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_424_615875.pth.
[INFO][13:04:25]: [Client #872] Woke up.
[INFO][13:04:25]: [Client #872] Epoch: [4/5][0/16]	Loss: 3.067884
[INFO][13:04:25]: [Client #872] Epoch: [4/5][10/16]	Loss: 2.741171
[INFO][13:04:25]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:04:25]: [Client #872] Woke up.
[INFO][13:04:25]: [Client #872] Epoch: [5/5][0/16]	Loss: 2.917008
[INFO][13:04:25]: [Client #424] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_424_615875.pth.
[INFO][13:04:25]: [Client #424] Model trained.
[INFO][13:04:25]: [Client #424] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:25]: [Server #615782] Received 0.26 MB of payload data from client #424 (simulated).
[INFO][13:04:25]: [Client #872] Epoch: [5/5][10/16]	Loss: 2.147517
[INFO][13:04:25]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:04:25]: [Client #872] Woke up.
[INFO][13:04:25]: [Client #872] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_872_615874.pth.
[INFO][13:04:26]: [Client #872] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_872_615874.pth.
[INFO][13:04:26]: [Client #872] Model trained.
[INFO][13:04:26]: [Client #872] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:26]: [Server #615782] Received 0.26 MB of payload data from client #872 (simulated).
[INFO][13:04:26]: [Server #615782] Selecting client #68 for training.
[INFO][13:04:26]: [Server #615782] Sending the current model to client #68 (simulated).
[INFO][13:04:26]: [Server #615782] Sending 0.26 MB of payload data to client #68 (simulated).
[INFO][13:04:26]: [Server #615782] Selecting client #896 for training.
[INFO][13:04:26]: [Server #615782] Sending the current model to client #896 (simulated).
[INFO][13:04:26]: [Server #615782] Sending 0.26 MB of payload data to client #896 (simulated).
[INFO][13:04:26]: [Client #68] Selected by the server.
[INFO][13:04:26]: [Client #68] Loading its data source...
[INFO][13:04:26]: Data source: FEMNIST
[INFO][13:04:26]: [Client #896] Selected by the server.
[INFO][13:04:26]: [Client #896] Loading its data source...
[INFO][13:04:26]: Data source: FEMNIST
[INFO][13:04:26]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:04:26]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/896.zip.
[INFO][13:04:26]: [Client #68] Dataset size: 162
[INFO][13:04:26]: [Client #68] Sampler: all_inclusive
[INFO][13:04:26]: [Client #68] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:26]: [93m[1m[Client #68] Started training in communication round #2.[0m
3.2%6.4%9.6%12.7%15.9%19.1%22.3%25.5%28.7%31.9%35.1%38.2%41.4%44.6%47.8%51.0%54.2%57.4%60.5%63.7%66.9%70.1%73.3%76.5%79.7%82.8%86.0%89.2%92.4%95.6%98.8%100.0%[INFO][13:04:26]: Decompressing the dataset downloaded.
[INFO][13:04:26]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/896.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:04:26]: [Client #896] Dataset size: 122
[INFO][13:04:26]: [Client #896] Sampler: all_inclusive
[INFO][13:04:26]: [Client #896] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:26]: [93m[1m[Client #896] Started training in communication round #2.[0m

[INFO][13:04:28]: [Client #68] Loading the dataset.
[INFO][13:04:28]: [Client #896] Loading the dataset.
[INFO][13:04:34]: [Client #68] Epoch: [1/5][0/17]	Loss: 2.832539
[INFO][13:04:34]: [Client #896] Epoch: [1/5][0/13]	Loss: 3.347117
[INFO][13:04:34]: [Client #68] Epoch: [1/5][10/17]	Loss: 3.149699
[INFO][13:04:34]: [Client #896] Epoch: [1/5][10/13]	Loss: 3.687283
[INFO][13:04:34]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][13:04:34]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][13:04:34]: [Client #896] Woke up.
[INFO][13:04:35]: [Client #896] Epoch: [2/5][0/13]	Loss: 3.591837
[INFO][13:04:35]: [Client #896] Epoch: [2/5][10/13]	Loss: 3.658881
[INFO][13:04:35]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][13:04:35]: [Client #68] Woke up.
[INFO][13:04:35]: [Client #68] Epoch: [2/5][0/17]	Loss: 2.797956
[INFO][13:04:35]: [Client #68] Epoch: [2/5][10/17]	Loss: 2.647271
[INFO][13:04:35]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][13:04:35]: [Client #896] Woke up.
[INFO][13:04:35]: [Client #896] Epoch: [3/5][0/13]	Loss: 3.043751
[INFO][13:04:35]: [Client #896] Epoch: [3/5][10/13]	Loss: 4.363540
[INFO][13:04:35]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][13:04:36]: [Client #896] Woke up.
[INFO][13:04:36]: [Client #896] Epoch: [4/5][0/13]	Loss: 3.631585
[INFO][13:04:36]: [Client #896] Epoch: [4/5][10/13]	Loss: 3.101704
[INFO][13:04:36]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][13:04:36]: [Client #68] Woke up.
[INFO][13:04:36]: [Client #68] Epoch: [3/5][0/17]	Loss: 3.166521
[INFO][13:04:36]: [Client #68] Epoch: [3/5][10/17]	Loss: 2.951792
[INFO][13:04:36]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][13:04:37]: [Client #896] Woke up.
[INFO][13:04:37]: [Client #896] Epoch: [5/5][0/13]	Loss: 3.701398
[INFO][13:04:37]: [Client #896] Epoch: [5/5][10/13]	Loss: 3.182880
[INFO][13:04:37]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][13:04:37]: [Client #896] Woke up.
[INFO][13:04:37]: [Client #896] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_896_615875.pth.
[INFO][13:04:37]: [Client #68] Woke up.
[INFO][13:04:37]: [Client #68] Epoch: [4/5][0/17]	Loss: 2.647578
[INFO][13:04:38]: [Client #68] Epoch: [4/5][10/17]	Loss: 3.305861
[INFO][13:04:38]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][13:04:38]: [Client #896] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_896_615875.pth.
[INFO][13:04:38]: [Client #896] Model trained.
[INFO][13:04:38]: [Client #896] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:38]: [Server #615782] Received 0.26 MB of payload data from client #896 (simulated).
[INFO][13:04:39]: [Client #68] Woke up.
[INFO][13:04:39]: [Client #68] Epoch: [5/5][0/17]	Loss: 2.662453
[INFO][13:04:39]: [Client #68] Epoch: [5/5][10/17]	Loss: 3.137489
[INFO][13:04:39]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][13:04:40]: [Client #68] Woke up.
[INFO][13:04:40]: [Client #68] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_68_615874.pth.
[INFO][13:04:41]: [Client #68] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_68_615874.pth.
[INFO][13:04:41]: [Client #68] Model trained.
[INFO][13:04:41]: [Client #68] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:41]: [Server #615782] Received 0.26 MB of payload data from client #68 (simulated).
[INFO][13:04:41]: [Server #615782] Selecting client #208 for training.
[INFO][13:04:41]: [Server #615782] Sending the current model to client #208 (simulated).
[INFO][13:04:41]: [Server #615782] Sending 0.26 MB of payload data to client #208 (simulated).
[INFO][13:04:41]: [Server #615782] Selecting client #826 for training.
[INFO][13:04:41]: [Server #615782] Sending the current model to client #826 (simulated).
[INFO][13:04:41]: [Server #615782] Sending 0.26 MB of payload data to client #826 (simulated).
[INFO][13:04:41]: [Client #208] Selected by the server.
[INFO][13:04:41]: [Client #208] Loading its data source...
[INFO][13:04:41]: Data source: FEMNIST
[INFO][13:04:41]: [Client #826] Selected by the server.
[INFO][13:04:41]: [Client #826] Loading its data source...
[INFO][13:04:41]: Data source: FEMNIST
[INFO][13:04:41]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:04:41]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/826.zip.
[INFO][13:04:41]: [Client #208] Dataset size: 164
[INFO][13:04:41]: [Client #208] Sampler: all_inclusive
[INFO][13:04:41]: [Client #208] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:41]: [93m[1m[Client #208] Started training in communication round #2.[0m
4.0%7.9%11.9%15.9%19.8%23.8%27.8%31.8%35.7%39.7%43.7%47.6%51.6%55.6%59.5%63.5%67.5%71.4%75.4%79.4%83.4%87.3%91.3%95.3%99.2%100.0%[INFO][13:04:41]: Decompressing the dataset downloaded.
[INFO][13:04:41]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/826.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:04:41]: [Client #826] Dataset size: 113
[INFO][13:04:41]: [Client #826] Sampler: all_inclusive
[INFO][13:04:41]: [Client #826] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:41]: [93m[1m[Client #826] Started training in communication round #2.[0m

[INFO][13:04:43]: [Client #208] Loading the dataset.
[INFO][13:04:43]: [Client #826] Loading the dataset.
[INFO][13:04:48]: [Client #208] Epoch: [1/5][0/17]	Loss: 3.448251
[INFO][13:04:48]: [Client #826] Epoch: [1/5][0/12]	Loss: 3.452759
[INFO][13:04:48]: [Client #208] Epoch: [1/5][10/17]	Loss: 3.258641
[INFO][13:04:48]: [Client #208] Going to sleep for 1.22 seconds.
[INFO][13:04:48]: [Client #826] Epoch: [1/5][10/12]	Loss: 4.028267
[INFO][13:04:48]: [Client #826] Going to sleep for 0.59 seconds.
[INFO][13:04:49]: [Client #826] Woke up.
[INFO][13:04:49]: [Client #826] Epoch: [2/5][0/12]	Loss: 3.846658
[INFO][13:04:49]: [Client #826] Epoch: [2/5][10/12]	Loss: 3.451647
[INFO][13:04:49]: [Client #826] Going to sleep for 0.59 seconds.
[INFO][13:04:50]: [Client #208] Woke up.
[INFO][13:04:50]: [Client #208] Epoch: [2/5][0/17]	Loss: 3.329414
[INFO][13:04:50]: [Client #826] Woke up.
[INFO][13:04:50]: [Client #826] Epoch: [3/5][0/12]	Loss: 3.611104
[INFO][13:04:50]: [Client #208] Epoch: [2/5][10/17]	Loss: 3.506801
[INFO][13:04:50]: [Client #208] Going to sleep for 1.22 seconds.
[INFO][13:04:50]: [Client #826] Epoch: [3/5][10/12]	Loss: 3.720209
[INFO][13:04:50]: [Client #826] Going to sleep for 0.59 seconds.
[INFO][13:04:50]: [Client #826] Woke up.
[INFO][13:04:51]: [Client #826] Epoch: [4/5][0/12]	Loss: 3.439565
[INFO][13:04:51]: [Client #826] Epoch: [4/5][10/12]	Loss: 3.450848
[INFO][13:04:51]: [Client #826] Going to sleep for 0.59 seconds.
[INFO][13:04:51]: [Client #208] Woke up.
[INFO][13:04:51]: [Client #208] Epoch: [3/5][0/17]	Loss: 3.045095
[INFO][13:04:51]: [Client #208] Epoch: [3/5][10/17]	Loss: 3.099047
[INFO][13:04:51]: [Client #826] Woke up.
[INFO][13:04:51]: [Client #826] Epoch: [5/5][0/12]	Loss: 3.539801
[INFO][13:04:51]: [Client #208] Going to sleep for 1.22 seconds.
[INFO][13:04:51]: [Client #826] Epoch: [5/5][10/12]	Loss: 3.145622
[INFO][13:04:51]: [Client #826] Going to sleep for 0.59 seconds.
[INFO][13:04:52]: [Client #826] Woke up.
[INFO][13:04:52]: [Client #826] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_826_615875.pth.
[INFO][13:04:52]: [Client #208] Woke up.
[INFO][13:04:52]: [Client #208] Epoch: [4/5][0/17]	Loss: 3.546482
[INFO][13:04:53]: [Client #826] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_826_615875.pth.
[INFO][13:04:53]: [Client #826] Model trained.
[INFO][13:04:53]: [Client #826] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:53]: [Server #615782] Received 0.26 MB of payload data from client #826 (simulated).
[INFO][13:04:53]: [Client #208] Epoch: [4/5][10/17]	Loss: 2.770385
[INFO][13:04:53]: [Client #208] Going to sleep for 1.22 seconds.
[INFO][13:04:54]: [Client #208] Woke up.
[INFO][13:04:54]: [Client #208] Epoch: [5/5][0/17]	Loss: 2.929848
[INFO][13:04:54]: [Client #208] Epoch: [5/5][10/17]	Loss: 3.224429
[INFO][13:04:54]: [Client #208] Going to sleep for 1.22 seconds.
[INFO][13:04:55]: [Client #208] Woke up.
[INFO][13:04:55]: [Client #208] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_208_615874.pth.
[INFO][13:04:56]: [Client #208] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_208_615874.pth.
[INFO][13:04:56]: [Client #208] Model trained.
[INFO][13:04:56]: [Client #208] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:04:56]: [Server #615782] Received 0.26 MB of payload data from client #208 (simulated).
[INFO][13:04:56]: [Server #615782] Selecting client #881 for training.
[INFO][13:04:56]: [Server #615782] Sending the current model to client #881 (simulated).
[INFO][13:04:56]: [Server #615782] Sending 0.26 MB of payload data to client #881 (simulated).
[INFO][13:04:56]: [Client #881] Selected by the server.
[INFO][13:04:56]: [Client #881] Loading its data source...
[INFO][13:04:56]: Data source: FEMNIST
[INFO][13:04:56]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:04:56]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/881.zip.
2.4%4.8%7.2%9.6%12.0%14.4%16.8%19.2%21.6%24.0%26.4%28.8%31.2%33.6%36.0%38.4%40.8%43.2%45.6%48.0%50.4%52.8%55.2%57.6%60.0%62.4%64.8%67.2%69.5%71.9%74.3%76.7%79.1%81.5%83.9%86.3%88.7%91.1%93.5%95.9%98.3%100.0%[INFO][13:04:56]: Decompressing the dataset downloaded.
[INFO][13:04:56]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/881.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:04:56]: [Client #881] Dataset size: 150
[INFO][13:04:56]: [Client #881] Sampler: all_inclusive
[INFO][13:04:56]: [Client #881] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:04:56]: [93m[1m[Client #881] Started training in communication round #2.[0m

[INFO][13:04:58]: [Client #881] Loading the dataset.
[INFO][13:05:03]: [Client #881] Epoch: [1/5][0/15]	Loss: 3.167600
[INFO][13:05:03]: [Client #881] Epoch: [1/5][10/15]	Loss: 3.531281
[INFO][13:05:03]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][13:05:04]: [Client #881] Woke up.
[INFO][13:05:04]: [Client #881] Epoch: [2/5][0/15]	Loss: 3.227740
[INFO][13:05:04]: [Client #881] Epoch: [2/5][10/15]	Loss: 3.433438
[INFO][13:05:04]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][13:05:05]: [Client #881] Woke up.
[INFO][13:05:05]: [Client #881] Epoch: [3/5][0/15]	Loss: 3.008745
[INFO][13:05:05]: [Client #881] Epoch: [3/5][10/15]	Loss: 3.992013
[INFO][13:05:05]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][13:05:05]: [Client #881] Woke up.
[INFO][13:05:05]: [Client #881] Epoch: [4/5][0/15]	Loss: 3.622363
[INFO][13:05:06]: [Client #881] Epoch: [4/5][10/15]	Loss: 2.287029
[INFO][13:05:06]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][13:05:06]: [Client #881] Woke up.
[INFO][13:05:06]: [Client #881] Epoch: [5/5][0/15]	Loss: 3.263740
[INFO][13:05:06]: [Client #881] Epoch: [5/5][10/15]	Loss: 3.195636
[INFO][13:05:06]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][13:05:07]: [Client #881] Woke up.
[INFO][13:05:07]: [Client #881] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_881_615874.pth.
[INFO][13:05:08]: [Client #881] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_881_615874.pth.
[INFO][13:05:08]: [Client #881] Model trained.
[INFO][13:05:08]: [Client #881] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:05:08]: [Server #615782] Received 0.26 MB of payload data from client #881 (simulated).
[INFO][13:05:08]: [Server #615782] Adding client #126 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #898 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #768 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #657 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #236 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #864 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #322 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #82 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #952 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #16 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #537 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #455 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #58 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #424 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #42 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #40 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #605 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #872 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #136 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #259 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #241 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #702 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #881 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #826 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #896 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #842 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #194 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #773 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #619 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #44 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #68 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #944 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #135 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #208 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #435 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #240 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #601 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #38 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #686 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #671 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #940 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #815 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #974 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #733 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Adding client #606 to the list of clients for aggregation.
[INFO][13:05:08]: [Server #615782] Aggregating 45 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 945, 946, 947, 948, 949, 950, 951, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02151406 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07154778 0.         0.02451188 0.         0.03686884
 0.         0.02325854 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03956001 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09704608 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02661283 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0394905
 0.         0.         0.         0.         0.         0.
 0.         0.         0.03516985 0.05321241 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0495834  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08568254 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05436962 0.         0.         0.         0.02159511
 0.06003148 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.04756206 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17658738 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04197895 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01596069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01800842 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01365553 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03090782 0.         0.         0.         0.07332407 0.01518212
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03575821 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01982149 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0319138  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03932853 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03918404
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10120648 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02213813
 0.         0.         0.         0.         0.03377049 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05717108 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02739652 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05052944 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03800984
 0.         0.         0.         0.         0.         0.
 0.         0.06023997 0.         0.         0.         0.
 0.         0.         0.         0.         0.05483045 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04058896 0.         0.02624417 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07378429 0.         0.
 0.         0.07251381 0.         0.         0.         0.
 0.         0.         0.         0.02312647 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03243221 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02151406 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07154778 0.         0.02451188 0.         0.03686884
 0.         0.02325854 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03956001 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09704608 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02661283 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0394905
 0.         0.         0.         0.         0.         0.
 0.         0.         0.03516985 0.05321241 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0495834  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08568254 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05436962 0.         0.         0.         0.02159511
 0.06003148 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.04756206 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17658738 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04197895 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01596069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01800842 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01365553 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03090782 0.         0.         0.         0.07332407 0.01518212
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03575821 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01982149 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0319138  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03932853 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03918404
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10120648 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02213813
 0.         0.         0.         0.         0.03377049 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05717108 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02739652 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05052944 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03800984
 0.         0.         0.         0.         0.         0.
 0.         0.06023997 0.         0.         0.         0.
 0.         0.         0.         0.         0.05483045 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04058896 0.         0.02624417 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07378429 0.         0.
 0.         0.07251381 0.         0.         0.         0.
 0.         0.         0.         0.02312647 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03243221 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.02341853
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02256176 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01784949 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03112952 0.001      0.001
 0.001      0.03195266 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.05656805 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.001      0.001      0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0212766  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03881657 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02284735 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02084821 0.001      0.001      0.001      0.02184778 0.02284735
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.02056262 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02199058 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02313294 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0212766  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02441811 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.001      0.001      0.001      0.001      0.01670713 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0383432  0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02284735 0.001      0.001      0.001      0.001
 0.001      0.03431953 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.02184778
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02256176 0.001      0.03739645 0.001      0.001
 0.001      0.001      0.001      0.001      0.02141939 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.01742111 0.001      0.02213337 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02256176 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001     ][INFO][13:05:52]: [Server #615782] Global model accuracy: 15.45%

[INFO][13:05:52]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_2.pth.
[INFO][13:05:52]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_2.pth.
[INFO][13:05:52]: [93m[1m
[Server #615782] Starting round 3/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5959e+00  1e+03  1e+00  1e+00
 1:  7.5199e+00  6.5970e+00  1e+01  1e-02  1e-02
 2:  7.5952e+00  6.6866e+00  1e+00  9e-05  9e-05
 3:  7.5959e+00  7.5161e+00  8e-02  4e-07  4e-07
 4:  7.5959e+00  7.5950e+00  9e-04  4e-09  4e-09
 5:  7.5959e+00  7.5958e+00  1e-04  4e-10  4e-10
 6:  7.5959e+00  7.5958e+00  9e-05  3e-10  3e-10
 7:  7.5959e+00  7.5958e+00  9e-05  5e-09  1e-09
 8:  7.5959e+00  7.5958e+00  6e-05  5e-09  9e-10
 9:  7.5959e+00  7.5958e+00  4e-05  1e-08  2e-09
10:  7.5958e+00  7.5958e+00  9e-06  4e-08  7e-09
11:  7.5958e+00  7.5958e+00  1e-06  7e-09  1e-09
Optimal solution found.
The calculated probability is:  [1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 2.29290634e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 4.58953847e-05 1.86223837e-05 2.36781427e-05
 1.86223837e-05 2.73035731e-05 1.86223837e-05 2.33595503e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86222948e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86215527e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.42304620e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.82059328e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 2.67464498e-05 1.86221461e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 3.22480012e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86217198e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 3.45502024e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 2.29487444e-05 1.86221147e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86222649e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 9.81292388e-01 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86222320e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 2.16513360e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 2.21068446e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.11589410e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223153e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86219606e-05 2.14826765e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86222946e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.25251646e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 2.57348719e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86222683e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86222676e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86213767e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 2.30813799e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.63030186e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86221094e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223515e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86221640e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 2.76897622e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86220791e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86221563e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223013e-05 1.86223837e-05
 2.41318470e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86219383e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 4.67267524e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 2.33264463e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 2.58912156e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05 1.86223837e-05
 1.86223837e-05 1.86223837e-05 1.86223837e-05][INFO][13:05:55]: [Server #615782] Selected clients: [322 191 755   8 328 920 590 857 607 824 882 320 122 723 441 126 592  37
 198 790  13 302  22 998 584]
[INFO][13:05:55]: [Server #615782] Selecting client #322 for training.
[INFO][13:05:55]: [Server #615782] Sending the current model to client #322 (simulated).
[INFO][13:05:55]: [Server #615782] Sending 0.26 MB of payload data to client #322 (simulated).
[INFO][13:05:55]: [Server #615782] Selecting client #191 for training.
[INFO][13:05:55]: [Server #615782] Sending the current model to client #191 (simulated).
[INFO][13:05:55]: [Server #615782] Sending 0.26 MB of payload data to client #191 (simulated).
[INFO][13:05:55]: [Client #322] Selected by the server.
[INFO][13:05:55]: [Client #322] Loading its data source...
[INFO][13:05:55]: Data source: FEMNIST
[INFO][13:05:55]: [Client #191] Selected by the server.
[INFO][13:05:55]: [Client #191] Loading its data source...
[INFO][13:05:55]: Data source: FEMNIST
[INFO][13:05:55]: [Client #322] Dataset size: 218
[INFO][13:05:55]: [Client #322] Sampler: all_inclusive
[INFO][13:05:55]: [Client #322] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:05:55]: [93m[1m[Client #322] Started training in communication round #3.[0m
[INFO][13:05:55]: [Client #191] Dataset size: 164
[INFO][13:05:55]: [Client #191] Sampler: all_inclusive
[INFO][13:05:55]: [Client #191] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:05:55]: [93m[1m[Client #191] Started training in communication round #3.[0m
[INFO][13:05:57]: [Client #322] Loading the dataset.
[INFO][13:05:57]: [Client #191] Loading the dataset.
[INFO][13:06:03]: [Client #191] Epoch: [1/5][0/17]	Loss: 3.272279
[INFO][13:06:03]: [Client #322] Epoch: [1/5][0/22]	Loss: 4.309712
[INFO][13:06:03]: [Client #191] Epoch: [1/5][10/17]	Loss: 3.241834
[INFO][13:06:03]: [Client #322] Epoch: [1/5][10/22]	Loss: 3.950696
[INFO][13:06:03]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][13:06:03]: [Client #322] Epoch: [1/5][20/22]	Loss: 3.913407
[INFO][13:06:03]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][13:06:03]: [Client #191] Woke up.
[INFO][13:06:03]: [Client #191] Epoch: [2/5][0/17]	Loss: 3.667157
[INFO][13:06:03]: [Client #191] Epoch: [2/5][10/17]	Loss: 2.259612
[INFO][13:06:04]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][13:06:04]: [Client #191] Woke up.
[INFO][13:06:04]: [Client #191] Epoch: [3/5][0/17]	Loss: 2.615656
[INFO][13:06:04]: [Client #191] Epoch: [3/5][10/17]	Loss: 2.845612
[INFO][13:06:04]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][13:06:04]: [Client #191] Woke up.
[INFO][13:06:04]: [Client #191] Epoch: [4/5][0/17]	Loss: 3.441232
[INFO][13:06:05]: [Client #191] Epoch: [4/5][10/17]	Loss: 2.764602
[INFO][13:06:05]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][13:06:05]: [Client #322] Woke up.
[INFO][13:06:05]: [Client #322] Epoch: [2/5][0/22]	Loss: 3.976799
[INFO][13:06:05]: [Client #322] Epoch: [2/5][10/22]	Loss: 3.258915
[INFO][13:06:05]: [Client #322] Epoch: [2/5][20/22]	Loss: 3.208823
[INFO][13:06:05]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][13:06:05]: [Client #191] Woke up.
[INFO][13:06:05]: [Client #191] Epoch: [5/5][0/17]	Loss: 2.860371
[INFO][13:06:05]: [Client #191] Epoch: [5/5][10/17]	Loss: 2.176076
[INFO][13:06:05]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][13:06:05]: [Client #191] Woke up.
[INFO][13:06:05]: [Client #191] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_191_615875.pth.
[INFO][13:06:06]: [Client #191] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_191_615875.pth.
[INFO][13:06:06]: [Client #191] Model trained.
[INFO][13:06:06]: [Client #191] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:06]: [Server #615782] Received 0.26 MB of payload data from client #191 (simulated).
[INFO][13:06:07]: [Client #322] Woke up.
[INFO][13:06:07]: [Client #322] Epoch: [3/5][0/22]	Loss: 3.605068
[INFO][13:06:07]: [Client #322] Epoch: [3/5][10/22]	Loss: 3.652569
[INFO][13:06:07]: [Client #322] Epoch: [3/5][20/22]	Loss: 3.450480
[INFO][13:06:07]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][13:06:08]: [Client #322] Woke up.
[INFO][13:06:08]: [Client #322] Epoch: [4/5][0/22]	Loss: 3.168699
[INFO][13:06:08]: [Client #322] Epoch: [4/5][10/22]	Loss: 3.538708
[INFO][13:06:08]: [Client #322] Epoch: [4/5][20/22]	Loss: 3.058466
[INFO][13:06:09]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][13:06:10]: [Client #322] Woke up.
[INFO][13:06:10]: [Client #322] Epoch: [5/5][0/22]	Loss: 2.940698
[INFO][13:06:10]: [Client #322] Epoch: [5/5][10/22]	Loss: 3.570309
[INFO][13:06:10]: [Client #322] Epoch: [5/5][20/22]	Loss: 2.949115
[INFO][13:06:10]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][13:06:12]: [Client #322] Woke up.
[INFO][13:06:12]: [Client #322] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_615874.pth.
[INFO][13:06:13]: [Client #322] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_615874.pth.
[INFO][13:06:13]: [Client #322] Model trained.
[INFO][13:06:13]: [Client #322] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:13]: [Server #615782] Received 0.26 MB of payload data from client #322 (simulated).
[INFO][13:06:13]: [Server #615782] Selecting client #755 for training.
[INFO][13:06:13]: [Server #615782] Sending the current model to client #755 (simulated).
[INFO][13:06:13]: [Server #615782] Sending 0.26 MB of payload data to client #755 (simulated).
[INFO][13:06:13]: [Server #615782] Selecting client #8 for training.
[INFO][13:06:13]: [Server #615782] Sending the current model to client #8 (simulated).
[INFO][13:06:13]: [Server #615782] Sending 0.26 MB of payload data to client #8 (simulated).
[INFO][13:06:13]: [Client #755] Selected by the server.
[INFO][13:06:13]: [Client #755] Loading its data source...
[INFO][13:06:13]: Data source: FEMNIST
[INFO][13:06:13]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:06:13]: [Client #8] Selected by the server.
[INFO][13:06:13]: [Client #8] Loading its data source...
[INFO][13:06:13]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/755.zip.
[INFO][13:06:13]: Data source: FEMNIST
[INFO][13:06:13]: [Client #8] Dataset size: 141
[INFO][13:06:13]: [Client #8] Sampler: all_inclusive
[INFO][13:06:13]: [Client #8] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:13]: [93m[1m[Client #8] Started training in communication round #3.[0m
2.2%4.5%6.7%8.9%11.2%13.4%15.6%17.8%20.1%22.3%24.5%26.8%29.0%31.2%33.5%35.7%37.9%40.1%42.4%44.6%46.8%49.1%51.3%53.5%55.8%58.0%60.2%62.4%64.7%66.9%69.1%71.4%73.6%75.8%78.1%80.3%82.5%84.7%87.0%89.2%91.4%93.7%95.9%98.1%100.0%[INFO][13:06:13]: Decompressing the dataset downloaded.
[INFO][13:06:13]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/755.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:06:13]: [Client #755] Dataset size: 194
[INFO][13:06:13]: [Client #755] Sampler: all_inclusive
[INFO][13:06:13]: [Client #755] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:13]: [93m[1m[Client #755] Started training in communication round #3.[0m

[INFO][13:06:15]: [Client #8] Loading the dataset.
[INFO][13:06:15]: [Client #755] Loading the dataset.
[INFO][13:06:20]: [Client #8] Epoch: [1/5][0/15]	Loss: 3.322385
[INFO][13:06:20]: [Client #755] Epoch: [1/5][0/20]	Loss: 3.779574
[INFO][13:06:21]: [Client #8] Epoch: [1/5][10/15]	Loss: 3.158359
[INFO][13:06:21]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][13:06:21]: [Client #755] Epoch: [1/5][10/20]	Loss: 3.749217
[INFO][13:06:21]: [Client #755] Going to sleep for 0.97 seconds.
[INFO][13:06:21]: [Client #8] Woke up.
[INFO][13:06:21]: [Client #8] Epoch: [2/5][0/15]	Loss: 3.128551
[INFO][13:06:21]: [Client #8] Epoch: [2/5][10/15]	Loss: 3.918359
[INFO][13:06:21]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][13:06:22]: [Client #755] Woke up.
[INFO][13:06:22]: [Client #755] Epoch: [2/5][0/20]	Loss: 3.641156
[INFO][13:06:22]: [Client #8] Woke up.
[INFO][13:06:22]: [Client #755] Epoch: [2/5][10/20]	Loss: 3.139193
[INFO][13:06:22]: [Client #8] Epoch: [3/5][0/15]	Loss: 2.983633
[INFO][13:06:22]: [Client #755] Going to sleep for 0.97 seconds.
[INFO][13:06:22]: [Client #8] Epoch: [3/5][10/15]	Loss: 2.632225
[INFO][13:06:22]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][13:06:22]: [Client #8] Woke up.
[INFO][13:06:22]: [Client #8] Epoch: [4/5][0/15]	Loss: 4.426157
[INFO][13:06:23]: [Client #8] Epoch: [4/5][10/15]	Loss: 3.682204
[INFO][13:06:23]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][13:06:23]: [Client #755] Woke up.
[INFO][13:06:23]: [Client #755] Epoch: [3/5][0/20]	Loss: 3.324392
[INFO][13:06:23]: [Client #755] Epoch: [3/5][10/20]	Loss: 3.942526
[INFO][13:06:23]: [Client #755] Going to sleep for 0.97 seconds.
[INFO][13:06:23]: [Client #8] Woke up.
[INFO][13:06:23]: [Client #8] Epoch: [5/5][0/15]	Loss: 3.245478
[INFO][13:06:23]: [Client #8] Epoch: [5/5][10/15]	Loss: 2.886285
[INFO][13:06:23]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][13:06:24]: [Client #8] Woke up.
[INFO][13:06:24]: [Client #8] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_8_615875.pth.
[INFO][13:06:24]: [Client #755] Woke up.
[INFO][13:06:24]: [Client #755] Epoch: [4/5][0/20]	Loss: 3.207716
[INFO][13:06:24]: [Client #755] Epoch: [4/5][10/20]	Loss: 3.260518
[INFO][13:06:24]: [Client #755] Going to sleep for 0.97 seconds.
[INFO][13:06:24]: [Client #8] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_8_615875.pth.
[INFO][13:06:24]: [Client #8] Model trained.
[INFO][13:06:24]: [Client #8] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:24]: [Server #615782] Received 0.26 MB of payload data from client #8 (simulated).
[INFO][13:06:25]: [Client #755] Woke up.
[INFO][13:06:25]: [Client #755] Epoch: [5/5][0/20]	Loss: 3.043188
[INFO][13:06:25]: [Client #755] Epoch: [5/5][10/20]	Loss: 3.457320
[INFO][13:06:25]: [Client #755] Going to sleep for 0.97 seconds.
[INFO][13:06:26]: [Client #755] Woke up.
[INFO][13:06:26]: [Client #755] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_755_615874.pth.
[INFO][13:06:27]: [Client #755] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_755_615874.pth.
[INFO][13:06:27]: [Client #755] Model trained.
[INFO][13:06:27]: [Client #755] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:27]: [Server #615782] Received 0.26 MB of payload data from client #755 (simulated).
[INFO][13:06:27]: [Server #615782] Selecting client #328 for training.
[INFO][13:06:27]: [Server #615782] Sending the current model to client #328 (simulated).
[INFO][13:06:27]: [Server #615782] Sending 0.26 MB of payload data to client #328 (simulated).
[INFO][13:06:27]: [Server #615782] Selecting client #920 for training.
[INFO][13:06:27]: [Server #615782] Sending the current model to client #920 (simulated).
[INFO][13:06:27]: [Server #615782] Sending 0.26 MB of payload data to client #920 (simulated).
[INFO][13:06:27]: [Client #328] Selected by the server.
[INFO][13:06:27]: [Client #328] Loading its data source...
[INFO][13:06:27]: Data source: FEMNIST
[INFO][13:06:27]: [Client #920] Selected by the server.
[INFO][13:06:27]: [Client #920] Loading its data source...
[INFO][13:06:27]: Data source: FEMNIST
[INFO][13:06:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:06:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/920.zip.
[INFO][13:06:27]: [Client #328] Dataset size: 164
[INFO][13:06:27]: [Client #328] Sampler: all_inclusive
[INFO][13:06:27]: [Client #328] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:27]: [93m[1m[Client #328] Started training in communication round #3.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.6%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.6%45.1%47.6%50.1%52.6%55.1%57.6%60.1%62.7%65.2%67.7%70.2%72.7%75.2%77.7%80.2%82.7%85.2%87.7%90.2%92.7%95.2%97.7%100.0%[INFO][13:06:27]: Decompressing the dataset downloaded.
[INFO][13:06:27]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/920.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:06:27]: [Client #920] Dataset size: 161
[INFO][13:06:27]: [Client #920] Sampler: all_inclusive
[INFO][13:06:27]: [Client #920] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:27]: [93m[1m[Client #920] Started training in communication round #3.[0m

[INFO][13:06:29]: [Client #328] Loading the dataset.
[INFO][13:06:29]: [Client #920] Loading the dataset.
[INFO][13:06:34]: [Client #328] Epoch: [1/5][0/17]	Loss: 3.509885
[INFO][13:06:35]: [Client #920] Epoch: [1/5][0/17]	Loss: 4.029593
[INFO][13:06:35]: [Client #328] Epoch: [1/5][10/17]	Loss: 4.650941
[INFO][13:06:35]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][13:06:35]: [Client #920] Epoch: [1/5][10/17]	Loss: 2.805007
[INFO][13:06:35]: [Client #920] Going to sleep for 1.12 seconds.
[INFO][13:06:36]: [Client #920] Woke up.
[INFO][13:06:36]: [Client #920] Epoch: [2/5][0/17]	Loss: 3.949750
[INFO][13:06:36]: [Client #920] Epoch: [2/5][10/17]	Loss: 3.825358
[INFO][13:06:36]: [Client #920] Going to sleep for 1.12 seconds.
[INFO][13:06:36]: [Client #328] Woke up.
[INFO][13:06:36]: [Client #328] Epoch: [2/5][0/17]	Loss: 2.911322
[INFO][13:06:36]: [Client #328] Epoch: [2/5][10/17]	Loss: 2.694398
[INFO][13:06:36]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][13:06:37]: [Client #920] Woke up.
[INFO][13:06:37]: [Client #920] Epoch: [3/5][0/17]	Loss: 2.624282
[INFO][13:06:37]: [Client #920] Epoch: [3/5][10/17]	Loss: 2.963763
[INFO][13:06:37]: [Client #920] Going to sleep for 1.12 seconds.
[INFO][13:06:38]: [Client #328] Woke up.
[INFO][13:06:38]: [Client #328] Epoch: [3/5][0/17]	Loss: 3.723301
[INFO][13:06:38]: [Client #328] Epoch: [3/5][10/17]	Loss: 2.441514
[INFO][13:06:38]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][13:06:38]: [Client #920] Woke up.
[INFO][13:06:38]: [Client #920] Epoch: [4/5][0/17]	Loss: 2.771719
[INFO][13:06:38]: [Client #920] Epoch: [4/5][10/17]	Loss: 3.856813
[INFO][13:06:38]: [Client #920] Going to sleep for 1.12 seconds.
[INFO][13:06:40]: [Client #920] Woke up.
[INFO][13:06:40]: [Client #920] Epoch: [5/5][0/17]	Loss: 2.973019
[INFO][13:06:40]: [Client #920] Epoch: [5/5][10/17]	Loss: 2.890203
[INFO][13:06:40]: [Client #920] Going to sleep for 1.12 seconds.
[INFO][13:06:40]: [Client #328] Woke up.
[INFO][13:06:40]: [Client #328] Epoch: [4/5][0/17]	Loss: 3.584606
[INFO][13:06:40]: [Client #328] Epoch: [4/5][10/17]	Loss: 1.945997
[INFO][13:06:40]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][13:06:41]: [Client #920] Woke up.
[INFO][13:06:41]: [Client #920] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_920_615875.pth.
[INFO][13:06:42]: [Client #920] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_920_615875.pth.
[INFO][13:06:42]: [Client #920] Model trained.
[INFO][13:06:42]: [Client #920] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:42]: [Server #615782] Received 0.26 MB of payload data from client #920 (simulated).
[INFO][13:06:42]: [Client #328] Woke up.
[INFO][13:06:42]: [Client #328] Epoch: [5/5][0/17]	Loss: 1.896989
[INFO][13:06:42]: [Client #328] Epoch: [5/5][10/17]	Loss: 3.123190
[INFO][13:06:42]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][13:06:43]: [Client #328] Woke up.
[INFO][13:06:43]: [Client #328] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_328_615874.pth.
[INFO][13:06:44]: [Client #328] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_328_615874.pth.
[INFO][13:06:44]: [Client #328] Model trained.
[INFO][13:06:44]: [Client #328] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:06:44]: [Server #615782] Received 0.26 MB of payload data from client #328 (simulated).
[INFO][13:06:44]: [Server #615782] Selecting client #590 for training.
[INFO][13:06:44]: [Server #615782] Sending the current model to client #590 (simulated).
[INFO][13:06:44]: [Server #615782] Sending 0.26 MB of payload data to client #590 (simulated).
[INFO][13:06:44]: [Server #615782] Selecting client #857 for training.
[INFO][13:06:44]: [Server #615782] Sending the current model to client #857 (simulated).
[INFO][13:06:44]: [Server #615782] Sending 0.26 MB of payload data to client #857 (simulated).
[INFO][13:06:44]: [Client #857] Selected by the server.
[INFO][13:06:44]: [Client #857] Loading its data source...
[INFO][13:06:44]: Data source: FEMNIST
[INFO][13:06:44]: [Client #590] Selected by the server.
[INFO][13:06:44]: [Client #590] Loading its data source...
[INFO][13:06:44]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:06:44]: Data source: FEMNIST
[INFO][13:06:44]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/857.zip.
[INFO][13:06:44]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:06:44]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/590.zip.
2.6%5.2%7.8%10.4%13.0%15.5%18.1%20.7%23.3%25.9%28.5%31.1%33.7%36.3%38.9%41.5%44.1%46.6%49.2%51.8%54.4%57.0%59.6%62.2%64.8%67.4%70.0%72.6%75.2%77.7%80.3%82.9%85.5%88.1%90.7%93.3%95.9%98.5%100.0%[INFO][13:06:44]: Decompressing the dataset downloaded.
[INFO][13:06:44]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/857.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
2.3%4.6%6.9%9.2%11.5%13.8%16.1%18.4%20.7%23.0%25.3%27.6%29.9%32.2%34.4%36.7%[INFO][13:06:44]: [Client #857] Dataset size: 154
[INFO][13:06:44]: [Client #857] Sampler: all_inclusive
[INFO][13:06:44]: [Client #857] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:44]: [93m[1m[Client #857] Started training in communication round #3.[0m

39.0%41.3%43.6%45.9%48.2%50.5%52.8%55.1%57.4%59.7%62.0%64.3%66.6%68.9%71.2%73.5%75.8%78.1%80.4%82.7%85.0%87.3%89.6%91.9%94.2%96.5%98.8%100.0%[INFO][13:06:44]: Decompressing the dataset downloaded.
[INFO][13:06:44]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/590.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:06:44]: [Client #590] Dataset size: 153
[INFO][13:06:44]: [Client #590] Sampler: all_inclusive
[INFO][13:06:44]: [Client #590] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:06:44]: [93m[1m[Client #590] Started training in communication round #3.[0m

[INFO][13:06:46]: [Client #857] Loading the dataset.
[INFO][13:06:46]: [Client #590] Loading the dataset.
[INFO][13:06:52]: [Client #590] Epoch: [1/5][0/16]	Loss: 3.569515
[INFO][13:06:52]: [Client #857] Epoch: [1/5][0/16]	Loss: 3.245143
[INFO][13:06:52]: [Client #590] Epoch: [1/5][10/16]	Loss: 2.921590
[INFO][13:06:52]: [Client #857] Epoch: [1/5][10/16]	Loss: 3.346547
[INFO][13:06:52]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:06:52]: [Client #857] Going to sleep for 18.34 seconds.
[INFO][13:06:55]: [Client #590] Woke up.
[INFO][13:06:55]: [Client #590] Epoch: [2/5][0/16]	Loss: 2.944315
[INFO][13:06:55]: [Client #590] Epoch: [2/5][10/16]	Loss: 1.979730
[INFO][13:06:55]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:06:59]: [Client #590] Woke up.
[INFO][13:06:59]: [Client #590] Epoch: [3/5][0/16]	Loss: 2.013081
[INFO][13:06:59]: [Client #590] Epoch: [3/5][10/16]	Loss: 3.184050
[INFO][13:06:59]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:07:02]: [Client #590] Woke up.
[INFO][13:07:02]: [Client #590] Epoch: [4/5][0/16]	Loss: 2.704765
[INFO][13:07:02]: [Client #590] Epoch: [4/5][10/16]	Loss: 1.994863
[INFO][13:07:02]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:07:06]: [Client #590] Woke up.
[INFO][13:07:06]: [Client #590] Epoch: [5/5][0/16]	Loss: 2.294765
[INFO][13:07:06]: [Client #590] Epoch: [5/5][10/16]	Loss: 2.309377
[INFO][13:07:06]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:07:09]: [Client #590] Woke up.
[INFO][13:07:09]: [Client #590] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615874.pth.
[INFO][13:07:10]: [Client #590] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615874.pth.
[INFO][13:07:10]: [Client #590] Model trained.
[INFO][13:07:10]: [Client #590] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:07:10]: [Server #615782] Received 0.26 MB of payload data from client #590 (simulated).
[INFO][13:07:10]: [Client #857] Woke up.
[INFO][13:07:10]: [Client #857] Epoch: [2/5][0/16]	Loss: 2.951396
[INFO][13:07:11]: [Client #857] Epoch: [2/5][10/16]	Loss: 2.700113
[INFO][13:07:11]: [Client #857] Going to sleep for 18.34 seconds.
[INFO][13:07:29]: [Client #857] Woke up.
[INFO][13:07:29]: [Client #857] Epoch: [3/5][0/16]	Loss: 2.018428
[INFO][13:07:29]: [Client #857] Epoch: [3/5][10/16]	Loss: 3.257822
[INFO][13:07:29]: [Client #857] Going to sleep for 18.34 seconds.
[INFO][13:07:48]: [Client #857] Woke up.
[INFO][13:07:48]: [Client #857] Epoch: [4/5][0/16]	Loss: 2.879424
[INFO][13:07:48]: [Client #857] Epoch: [4/5][10/16]	Loss: 2.407487
[INFO][13:07:48]: [Client #857] Going to sleep for 18.34 seconds.
[INFO][13:08:06]: [Client #857] Woke up.
[INFO][13:08:06]: [Client #857] Epoch: [5/5][0/16]	Loss: 3.403199
[INFO][13:08:06]: [Client #857] Epoch: [5/5][10/16]	Loss: 2.340260
[INFO][13:08:06]: [Client #857] Going to sleep for 18.34 seconds.
[INFO][13:08:25]: [Client #857] Woke up.
[INFO][13:08:25]: [Client #857] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_857_615875.pth.
[INFO][13:08:25]: [Client #857] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_857_615875.pth.
[INFO][13:08:25]: [Client #857] Model trained.
[INFO][13:08:25]: [Client #857] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:08:26]: [Server #615782] Received 0.26 MB of payload data from client #857 (simulated).
[INFO][13:08:26]: [Server #615782] Selecting client #607 for training.
[INFO][13:08:26]: [Server #615782] Sending the current model to client #607 (simulated).
[INFO][13:08:26]: [Server #615782] Sending 0.26 MB of payload data to client #607 (simulated).
[INFO][13:08:26]: [Server #615782] Selecting client #824 for training.
[INFO][13:08:26]: [Server #615782] Sending the current model to client #824 (simulated).
[INFO][13:08:26]: [Server #615782] Sending 0.26 MB of payload data to client #824 (simulated).
[INFO][13:08:26]: [Client #607] Selected by the server.
[INFO][13:08:26]: [Client #824] Selected by the server.
[INFO][13:08:26]: [Client #607] Loading its data source...
[INFO][13:08:26]: [Client #824] Loading its data source...
[INFO][13:08:26]: Data source: FEMNIST
[INFO][13:08:26]: Data source: FEMNIST
[INFO][13:08:26]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:08:26]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/607.zip.
[INFO][13:08:26]: [Client #824] Dataset size: 162
[INFO][13:08:26]: [Client #824] Sampler: all_inclusive
[INFO][13:08:26]: [Client #824] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:08:26]: [93m[1m[Client #824] Started training in communication round #3.[0m
2.6%5.2%7.8%10.4%13.0%15.6%18.2%20.8%23.4%26.0%28.6%31.2%33.8%36.4%39.0%41.6%44.2%46.8%49.4%52.0%54.6%57.2%59.8%62.4%65.0%67.6%70.2%72.8%75.4%77.9%80.5%83.1%85.7%88.3%90.9%93.5%96.1%98.7%100.0%[INFO][13:08:26]: Decompressing the dataset downloaded.
[INFO][13:08:26]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/607.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:08:26]: [Client #607] Dataset size: 154
[INFO][13:08:26]: [Client #607] Sampler: all_inclusive
[INFO][13:08:26]: [Client #607] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:08:26]: [93m[1m[Client #607] Started training in communication round #3.[0m

[INFO][13:08:28]: [Client #824] Loading the dataset.
[INFO][13:08:28]: [Client #607] Loading the dataset.
[INFO][13:08:33]: [Client #824] Epoch: [1/5][0/17]	Loss: 3.180551
[INFO][13:08:33]: [Client #607] Epoch: [1/5][0/16]	Loss: 3.569986
[INFO][13:08:33]: [Client #824] Epoch: [1/5][10/17]	Loss: 3.719362
[INFO][13:08:33]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][13:08:33]: [Client #607] Epoch: [1/5][10/16]	Loss: 2.820149
[INFO][13:08:33]: [Client #607] Going to sleep for 2.46 seconds.
[INFO][13:08:34]: [Client #824] Woke up.
[INFO][13:08:34]: [Client #824] Epoch: [2/5][0/17]	Loss: 3.217542
[INFO][13:08:34]: [Client #824] Epoch: [2/5][10/17]	Loss: 3.009700
[INFO][13:08:34]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][13:08:34]: [Client #824] Woke up.
[INFO][13:08:34]: [Client #824] Epoch: [3/5][0/17]	Loss: 3.034960
[INFO][13:08:34]: [Client #824] Epoch: [3/5][10/17]	Loss: 3.243114
[INFO][13:08:34]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][13:08:35]: [Client #824] Woke up.
[INFO][13:08:35]: [Client #824] Epoch: [4/5][0/17]	Loss: 3.086542
[INFO][13:08:35]: [Client #824] Epoch: [4/5][10/17]	Loss: 2.906175
[INFO][13:08:35]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][13:08:35]: [Client #824] Woke up.
[INFO][13:08:35]: [Client #824] Epoch: [5/5][0/17]	Loss: 1.920125
[INFO][13:08:35]: [Client #824] Epoch: [5/5][10/17]	Loss: 2.961444
[INFO][13:08:35]: [Client #824] Going to sleep for 0.29 seconds.
[INFO][13:08:35]: [Client #824] Woke up.
[INFO][13:08:35]: [Client #824] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_824_615875.pth.
[INFO][13:08:36]: [Client #607] Woke up.
[INFO][13:08:36]: [Client #607] Epoch: [2/5][0/16]	Loss: 3.621279
[INFO][13:08:36]: [Client #607] Epoch: [2/5][10/16]	Loss: 2.863742
[INFO][13:08:36]: [Client #607] Going to sleep for 2.46 seconds.
[INFO][13:08:36]: [Client #824] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_824_615875.pth.
[INFO][13:08:36]: [Client #824] Model trained.
[INFO][13:08:36]: [Client #824] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:08:36]: [Server #615782] Received 0.26 MB of payload data from client #824 (simulated).
[INFO][13:08:38]: [Client #607] Woke up.
[INFO][13:08:39]: [Client #607] Epoch: [3/5][0/16]	Loss: 2.726085
[INFO][13:08:39]: [Client #607] Epoch: [3/5][10/16]	Loss: 2.370572
[INFO][13:08:39]: [Client #607] Going to sleep for 2.46 seconds.
[INFO][13:08:41]: [Client #607] Woke up.
[INFO][13:08:41]: [Client #607] Epoch: [4/5][0/16]	Loss: 2.805167
[INFO][13:08:41]: [Client #607] Epoch: [4/5][10/16]	Loss: 3.752398
[INFO][13:08:41]: [Client #607] Going to sleep for 2.46 seconds.
[INFO][13:08:44]: [Client #607] Woke up.
[INFO][13:08:44]: [Client #607] Epoch: [5/5][0/16]	Loss: 2.768154
[INFO][13:08:44]: [Client #607] Epoch: [5/5][10/16]	Loss: 1.914900
[INFO][13:08:44]: [Client #607] Going to sleep for 2.46 seconds.
[INFO][13:08:46]: [Client #607] Woke up.
[INFO][13:08:46]: [Client #607] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_607_615874.pth.
[INFO][13:08:47]: [Client #607] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_607_615874.pth.
[INFO][13:08:47]: [Client #607] Model trained.
[INFO][13:08:47]: [Client #607] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:08:47]: [Server #615782] Received 0.26 MB of payload data from client #607 (simulated).
[INFO][13:08:47]: [Server #615782] Selecting client #882 for training.
[INFO][13:08:47]: [Server #615782] Sending the current model to client #882 (simulated).
[INFO][13:08:47]: [Server #615782] Sending 0.26 MB of payload data to client #882 (simulated).
[INFO][13:08:47]: [Server #615782] Selecting client #320 for training.
[INFO][13:08:47]: [Server #615782] Sending the current model to client #320 (simulated).
[INFO][13:08:47]: [Server #615782] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][13:08:47]: [Client #882] Selected by the server.
[INFO][13:08:47]: [Client #882] Loading its data source...
[INFO][13:08:47]: Data source: FEMNIST
[INFO][13:08:47]: [Client #320] Selected by the server.
[INFO][13:08:47]: [Client #320] Loading its data source...
[INFO][13:08:47]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:08:47]: Data source: FEMNIST
[INFO][13:08:47]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/882.zip.
[INFO][13:08:47]: [Client #320] Dataset size: 153
[INFO][13:08:47]: [Client #320] Sampler: all_inclusive
[INFO][13:08:47]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:08:47]: [93m[1m[Client #320] Started training in communication round #3.[0m
5.2%10.4%15.7%20.9%26.1%31.3%36.5%41.7%47.0%52.2%57.4%62.6%67.8%73.0%78.3%83.5%88.7%93.9%99.1%100.0%[INFO][13:08:47]: Decompressing the dataset downloaded.
[INFO][13:08:47]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/882.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:08:47]: [Client #882] Dataset size: 93
[INFO][13:08:47]: [Client #882] Sampler: all_inclusive
[INFO][13:08:47]: [Client #882] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:08:47]: [93m[1m[Client #882] Started training in communication round #3.[0m

[INFO][13:08:49]: [Client #320] Loading the dataset.
[INFO][13:08:49]: [Client #882] Loading the dataset.
[INFO][13:08:55]: [Client #882] Epoch: [1/5][0/10]	Loss: 3.471791
[INFO][13:08:55]: [Client #320] Epoch: [1/5][0/16]	Loss: 3.418595
[INFO][13:08:55]: [Client #882] Going to sleep for 0.23 seconds.
[INFO][13:08:55]: [Client #320] Epoch: [1/5][10/16]	Loss: 3.599668
[INFO][13:08:55]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][13:08:55]: [Client #882] Woke up.
[INFO][13:08:55]: [Client #882] Epoch: [2/5][0/10]	Loss: 2.612851
[INFO][13:08:55]: [Client #882] Going to sleep for 0.23 seconds.
[INFO][13:08:55]: [Client #882] Woke up.
[INFO][13:08:55]: [Client #882] Epoch: [3/5][0/10]	Loss: 3.248620
[INFO][13:08:56]: [Client #882] Going to sleep for 0.23 seconds.
[INFO][13:08:56]: [Client #882] Woke up.
[INFO][13:08:56]: [Client #882] Epoch: [4/5][0/10]	Loss: 3.153923
[INFO][13:08:56]: [Client #882] Going to sleep for 0.23 seconds.
[INFO][13:08:56]: [Client #882] Woke up.
[INFO][13:08:56]: [Client #882] Epoch: [5/5][0/10]	Loss: 2.128615
[INFO][13:08:56]: [Client #882] Going to sleep for 0.23 seconds.
[INFO][13:08:56]: [Client #882] Woke up.
[INFO][13:08:56]: [Client #882] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_882_615874.pth.
[INFO][13:08:57]: [Client #882] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_882_615874.pth.
[INFO][13:08:57]: [Client #882] Model trained.
[INFO][13:08:57]: [Client #882] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:08:57]: [Server #615782] Received 0.26 MB of payload data from client #882 (simulated).
[INFO][13:09:01]: [Client #320] Woke up.
[INFO][13:09:01]: [Client #320] Epoch: [2/5][0/16]	Loss: 2.972542
[INFO][13:09:01]: [Client #320] Epoch: [2/5][10/16]	Loss: 3.561602
[INFO][13:09:01]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][13:09:07]: [Client #320] Woke up.
[INFO][13:09:07]: [Client #320] Epoch: [3/5][0/16]	Loss: 3.018123
[INFO][13:09:07]: [Client #320] Epoch: [3/5][10/16]	Loss: 3.089851
[INFO][13:09:07]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][13:09:12]: [Client #320] Woke up.
[INFO][13:09:12]: [Client #320] Epoch: [4/5][0/16]	Loss: 3.563814
[INFO][13:09:13]: [Client #320] Epoch: [4/5][10/16]	Loss: 3.194406
[INFO][13:09:13]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][13:09:18]: [Client #320] Woke up.
[INFO][13:09:18]: [Client #320] Epoch: [5/5][0/16]	Loss: 2.311123
[INFO][13:09:18]: [Client #320] Epoch: [5/5][10/16]	Loss: 2.649545
[INFO][13:09:19]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][13:09:24]: [Client #320] Woke up.
[INFO][13:09:24]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_615875.pth.
[INFO][13:09:25]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_615875.pth.
[INFO][13:09:25]: [Client #320] Model trained.
[INFO][13:09:25]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:09:25]: [Server #615782] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][13:09:25]: [Server #615782] Selecting client #122 for training.
[INFO][13:09:25]: [Server #615782] Sending the current model to client #122 (simulated).
[INFO][13:09:25]: [Server #615782] Sending 0.26 MB of payload data to client #122 (simulated).
[INFO][13:09:25]: [Server #615782] Selecting client #723 for training.
[INFO][13:09:25]: [Server #615782] Sending the current model to client #723 (simulated).
[INFO][13:09:25]: [Server #615782] Sending 0.26 MB of payload data to client #723 (simulated).
[INFO][13:09:25]: [Client #122] Selected by the server.
[INFO][13:09:25]: [Client #122] Loading its data source...
[INFO][13:09:25]: Data source: FEMNIST
[INFO][13:09:25]: [Client #723] Selected by the server.
[INFO][13:09:25]: [Client #723] Loading its data source...
[INFO][13:09:25]: Data source: FEMNIST
[INFO][13:09:25]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:09:25]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/723.zip.
[INFO][13:09:25]: [Client #122] Dataset size: 161
[INFO][13:09:25]: [Client #122] Sampler: all_inclusive
[INFO][13:09:25]: [Client #122] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:09:25]: [93m[1m[Client #122] Started training in communication round #3.[0m
2.7%5.3%8.0%10.6%13.3%15.9%18.6%21.2%23.9%26.5%29.2%31.8%34.5%37.1%39.8%42.4%45.1%47.7%50.4%53.0%55.7%58.3%61.0%63.6%66.3%68.9%71.6%74.2%76.9%79.5%82.2%84.8%87.5%90.2%92.8%95.5%98.1%100.0%[INFO][13:09:25]: Decompressing the dataset downloaded.
[INFO][13:09:25]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/723.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:09:25]: [Client #723] Dataset size: 161
[INFO][13:09:25]: [Client #723] Sampler: all_inclusive
[INFO][13:09:25]: [Client #723] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:09:25]: [93m[1m[Client #723] Started training in communication round #3.[0m

[INFO][13:09:27]: [Client #122] Loading the dataset.
[INFO][13:09:27]: [Client #723] Loading the dataset.
[INFO][13:09:33]: [Client #122] Epoch: [1/5][0/17]	Loss: 3.236985
[INFO][13:09:33]: [Client #122] Epoch: [1/5][10/17]	Loss: 2.720578
[INFO][13:09:33]: [Client #723] Epoch: [1/5][0/17]	Loss: 3.368238
[INFO][13:09:33]: [Client #122] Going to sleep for 0.03 seconds.
[INFO][13:09:33]: [Client #122] Woke up.
[INFO][13:09:33]: [Client #122] Epoch: [2/5][0/17]	Loss: 3.366316
[INFO][13:09:33]: [Client #723] Epoch: [1/5][10/17]	Loss: 3.027628
[INFO][13:09:33]: [Client #723] Going to sleep for 1.53 seconds.
[INFO][13:09:33]: [Client #122] Epoch: [2/5][10/17]	Loss: 3.350832
[INFO][13:09:33]: [Client #122] Going to sleep for 0.03 seconds.
[INFO][13:09:33]: [Client #122] Woke up.
[INFO][13:09:33]: [Client #122] Epoch: [3/5][0/17]	Loss: 3.372178
[INFO][13:09:33]: [Client #122] Epoch: [3/5][10/17]	Loss: 2.977775
[INFO][13:09:34]: [Client #122] Going to sleep for 0.03 seconds.
[INFO][13:09:34]: [Client #122] Woke up.
[INFO][13:09:34]: [Client #122] Epoch: [4/5][0/17]	Loss: 3.526555
[INFO][13:09:34]: [Client #122] Epoch: [4/5][10/17]	Loss: 2.447026
[INFO][13:09:34]: [Client #122] Going to sleep for 0.03 seconds.
[INFO][13:09:34]: [Client #122] Woke up.
[INFO][13:09:34]: [Client #122] Epoch: [5/5][0/17]	Loss: 3.090241
[INFO][13:09:34]: [Client #122] Epoch: [5/5][10/17]	Loss: 2.219838
[INFO][13:09:34]: [Client #122] Going to sleep for 0.03 seconds.
[INFO][13:09:34]: [Client #122] Woke up.
[INFO][13:09:34]: [Client #122] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_122_615874.pth.
[INFO][13:09:35]: [Client #122] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_122_615874.pth.
[INFO][13:09:35]: [Client #122] Model trained.
[INFO][13:09:35]: [Client #122] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:09:35]: [Server #615782] Received 0.26 MB of payload data from client #122 (simulated).
[INFO][13:09:35]: [Client #723] Woke up.
[INFO][13:09:35]: [Client #723] Epoch: [2/5][0/17]	Loss: 2.716273
[INFO][13:09:35]: [Client #723] Epoch: [2/5][10/17]	Loss: 3.776901
[INFO][13:09:35]: [Client #723] Going to sleep for 1.53 seconds.
[INFO][13:09:37]: [Client #723] Woke up.
[INFO][13:09:37]: [Client #723] Epoch: [3/5][0/17]	Loss: 3.172078
[INFO][13:09:37]: [Client #723] Epoch: [3/5][10/17]	Loss: 3.219858
[INFO][13:09:37]: [Client #723] Going to sleep for 1.53 seconds.
[INFO][13:09:38]: [Client #723] Woke up.
[INFO][13:09:38]: [Client #723] Epoch: [4/5][0/17]	Loss: 3.184296
[INFO][13:09:38]: [Client #723] Epoch: [4/5][10/17]	Loss: 3.212571
[INFO][13:09:38]: [Client #723] Going to sleep for 1.53 seconds.
[INFO][13:09:40]: [Client #723] Woke up.
[INFO][13:09:40]: [Client #723] Epoch: [5/5][0/17]	Loss: 3.267544
[INFO][13:09:40]: [Client #723] Epoch: [5/5][10/17]	Loss: 2.303221
[INFO][13:09:40]: [Client #723] Going to sleep for 1.53 seconds.
[INFO][13:09:42]: [Client #723] Woke up.
[INFO][13:09:42]: [Client #723] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_723_615875.pth.
[INFO][13:09:42]: [Client #723] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_723_615875.pth.
[INFO][13:09:42]: [Client #723] Model trained.
[INFO][13:09:42]: [Client #723] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:09:42]: [Server #615782] Received 0.26 MB of payload data from client #723 (simulated).
[INFO][13:09:42]: [Server #615782] Selecting client #441 for training.
[INFO][13:09:42]: [Server #615782] Sending the current model to client #441 (simulated).
[INFO][13:09:42]: [Server #615782] Sending 0.26 MB of payload data to client #441 (simulated).
[INFO][13:09:42]: [Server #615782] Selecting client #126 for training.
[INFO][13:09:42]: [Server #615782] Sending the current model to client #126 (simulated).
[INFO][13:09:42]: [Server #615782] Sending 0.26 MB of payload data to client #126 (simulated).
[INFO][13:09:42]: [Client #441] Selected by the server.
[INFO][13:09:42]: [Client #441] Loading its data source...
[INFO][13:09:42]: Data source: FEMNIST
[INFO][13:09:42]: [Client #126] Selected by the server.
[INFO][13:09:42]: [Client #126] Loading its data source...
[INFO][13:09:42]: Data source: FEMNIST
[INFO][13:09:42]: [Client #126] Dataset size: 164
[INFO][13:09:42]: [Client #126] Sampler: all_inclusive
[INFO][13:09:42]: [Client #126] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:09:42]: [93m[1m[Client #126] Started training in communication round #3.[0m
[INFO][13:09:42]: [Client #441] Dataset size: 155
[INFO][13:09:42]: [Client #441] Sampler: all_inclusive
[INFO][13:09:42]: [Client #441] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:09:42]: [93m[1m[Client #441] Started training in communication round #3.[0m
[INFO][13:09:45]: [Client #441] Loading the dataset.
[INFO][13:09:45]: [Client #126] Loading the dataset.
[INFO][13:09:50]: [Client #126] Epoch: [1/5][0/17]	Loss: 3.743770
[INFO][13:09:50]: [Client #441] Epoch: [1/5][0/16]	Loss: 3.339118
[INFO][13:09:50]: [Client #126] Epoch: [1/5][10/17]	Loss: 3.218510
[INFO][13:09:50]: [Client #441] Epoch: [1/5][10/16]	Loss: 3.525699
[INFO][13:09:50]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][13:09:50]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][13:09:52]: [Client #126] Woke up.
[INFO][13:09:52]: [Client #126] Epoch: [2/5][0/17]	Loss: 3.096298
[INFO][13:09:52]: [Client #126] Epoch: [2/5][10/17]	Loss: 2.922601
[INFO][13:09:52]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][13:09:52]: [Client #441] Woke up.
[INFO][13:09:52]: [Client #441] Epoch: [2/5][0/16]	Loss: 2.860694
[INFO][13:09:52]: [Client #441] Epoch: [2/5][10/16]	Loss: 3.432774
[INFO][13:09:52]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][13:09:53]: [Client #126] Woke up.
[INFO][13:09:53]: [Client #126] Epoch: [3/5][0/17]	Loss: 3.067436
[INFO][13:09:53]: [Client #126] Epoch: [3/5][10/17]	Loss: 2.458560
[INFO][13:09:53]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][13:09:54]: [Client #441] Woke up.
[INFO][13:09:54]: [Client #441] Epoch: [3/5][0/16]	Loss: 2.908394
[INFO][13:09:54]: [Client #441] Epoch: [3/5][10/16]	Loss: 2.565130
[INFO][13:09:54]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][13:09:54]: [Client #126] Woke up.
[INFO][13:09:54]: [Client #126] Epoch: [4/5][0/17]	Loss: 2.914074
[INFO][13:09:54]: [Client #126] Epoch: [4/5][10/17]	Loss: 3.012370
[INFO][13:09:54]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][13:09:55]: [Client #126] Woke up.
[INFO][13:09:55]: [Client #126] Epoch: [5/5][0/17]	Loss: 2.751196
[INFO][13:09:56]: [Client #441] Woke up.
[INFO][13:09:56]: [Client #441] Epoch: [4/5][0/16]	Loss: 2.724750
[INFO][13:09:56]: [Client #126] Epoch: [5/5][10/17]	Loss: 2.769562
[INFO][13:09:56]: [Client #441] Epoch: [4/5][10/16]	Loss: 2.252577
[INFO][13:09:56]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][13:09:56]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][13:09:57]: [Client #126] Woke up.
[INFO][13:09:57]: [Client #126] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_615875.pth.
[INFO][13:09:57]: [Client #441] Woke up.
[INFO][13:09:57]: [Client #441] Epoch: [5/5][0/16]	Loss: 3.096344
[INFO][13:09:57]: [Client #441] Epoch: [5/5][10/16]	Loss: 2.732517
[INFO][13:09:57]: [Client #126] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_615875.pth.
[INFO][13:09:57]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][13:09:57]: [Client #126] Model trained.
[INFO][13:09:57]: [Client #126] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:09:57]: [Server #615782] Received 0.26 MB of payload data from client #126 (simulated).
[INFO][13:09:59]: [Client #441] Woke up.
[INFO][13:09:59]: [Client #441] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_441_615874.pth.
[INFO][13:10:00]: [Client #441] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_441_615874.pth.
[INFO][13:10:00]: [Client #441] Model trained.
[INFO][13:10:00]: [Client #441] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:10:00]: [Server #615782] Received 0.26 MB of payload data from client #441 (simulated).
[INFO][13:10:00]: [Server #615782] Selecting client #592 for training.
[INFO][13:10:00]: [Server #615782] Sending the current model to client #592 (simulated).
[INFO][13:10:00]: [Server #615782] Sending 0.26 MB of payload data to client #592 (simulated).
[INFO][13:10:00]: [Server #615782] Selecting client #37 for training.
[INFO][13:10:00]: [Server #615782] Sending the current model to client #37 (simulated).
[INFO][13:10:00]: [Server #615782] Sending 0.26 MB of payload data to client #37 (simulated).
[INFO][13:10:00]: [Client #592] Selected by the server.
[INFO][13:10:00]: [Client #592] Loading its data source...
[INFO][13:10:00]: Data source: FEMNIST
[INFO][13:10:00]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:10:00]: [Client #37] Selected by the server.
[INFO][13:10:00]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/592.zip.
[INFO][13:10:00]: [Client #37] Loading its data source...
[INFO][13:10:00]: Data source: FEMNIST
[INFO][13:10:00]: [Client #37] Dataset size: 164
[INFO][13:10:00]: [Client #37] Sampler: all_inclusive
[INFO][13:10:00]: [Client #37] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:00]: [93m[1m[Client #37] Started training in communication round #3.[0m
3.1%6.2%9.2%12.3%15.4%18.5%21.6%24.6%27.7%30.8%33.9%37.0%40.0%43.1%46.2%49.3%52.4%55.4%58.5%61.6%64.7%67.8%70.8%73.9%77.0%80.1%83.2%86.2%89.3%92.4%95.5%98.6%100.0%[INFO][13:10:00]: Decompressing the dataset downloaded.
[INFO][13:10:00]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/592.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:10:00]: [Client #592] Dataset size: 150
[INFO][13:10:00]: [Client #592] Sampler: all_inclusive
[INFO][13:10:00]: [Client #592] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:00]: [93m[1m[Client #592] Started training in communication round #3.[0m

[INFO][13:10:02]: [Client #37] Loading the dataset.
[INFO][13:10:02]: [Client #592] Loading the dataset.
[INFO][13:10:07]: [Client #37] Epoch: [1/5][0/17]	Loss: 3.267092
[INFO][13:10:07]: [Client #592] Epoch: [1/5][0/15]	Loss: 3.522515
[INFO][13:10:07]: [Client #37] Epoch: [1/5][10/17]	Loss: 4.141708
[INFO][13:10:07]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][13:10:07]: [Client #592] Epoch: [1/5][10/15]	Loss: 2.978704
[INFO][13:10:07]: [Client #592] Going to sleep for 2.75 seconds.
[INFO][13:10:10]: [Client #37] Woke up.
[INFO][13:10:10]: [Client #37] Epoch: [2/5][0/17]	Loss: 3.651788
[INFO][13:10:10]: [Client #37] Epoch: [2/5][10/17]	Loss: 2.636851
[INFO][13:10:10]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][13:10:10]: [Client #592] Woke up.
[INFO][13:10:10]: [Client #592] Epoch: [2/5][0/15]	Loss: 3.540091
[INFO][13:10:10]: [Client #592] Epoch: [2/5][10/15]	Loss: 2.815592
[INFO][13:10:10]: [Client #592] Going to sleep for 2.75 seconds.
[INFO][13:10:12]: [Client #37] Woke up.
[INFO][13:10:12]: [Client #37] Epoch: [3/5][0/17]	Loss: 2.817265
[INFO][13:10:12]: [Client #37] Epoch: [3/5][10/17]	Loss: 3.000422
[INFO][13:10:12]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][13:10:13]: [Client #592] Woke up.
[INFO][13:10:13]: [Client #592] Epoch: [3/5][0/15]	Loss: 2.878605
[INFO][13:10:13]: [Client #592] Epoch: [3/5][10/15]	Loss: 2.634593
[INFO][13:10:13]: [Client #592] Going to sleep for 2.75 seconds.
[INFO][13:10:14]: [Client #37] Woke up.
[INFO][13:10:14]: [Client #37] Epoch: [4/5][0/17]	Loss: 2.226043
[INFO][13:10:14]: [Client #37] Epoch: [4/5][10/17]	Loss: 2.736706
[INFO][13:10:14]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][13:10:16]: [Client #592] Woke up.
[INFO][13:10:16]: [Client #592] Epoch: [4/5][0/15]	Loss: 3.813719
[INFO][13:10:16]: [Client #592] Epoch: [4/5][10/15]	Loss: 2.843823
[INFO][13:10:16]: [Client #592] Going to sleep for 2.75 seconds.
[INFO][13:10:17]: [Client #37] Woke up.
[INFO][13:10:17]: [Client #37] Epoch: [5/5][0/17]	Loss: 3.175418
[INFO][13:10:17]: [Client #37] Epoch: [5/5][10/17]	Loss: 1.757284
[INFO][13:10:17]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][13:10:19]: [Client #592] Woke up.
[INFO][13:10:19]: [Client #592] Epoch: [5/5][0/15]	Loss: 2.036077
[INFO][13:10:19]: [Client #37] Woke up.
[INFO][13:10:19]: [Client #592] Epoch: [5/5][10/15]	Loss: 2.091938
[INFO][13:10:19]: [Client #37] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_37_615875.pth.
[INFO][13:10:19]: [Client #592] Going to sleep for 2.75 seconds.
[INFO][13:10:20]: [Client #37] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_37_615875.pth.
[INFO][13:10:20]: [Client #37] Model trained.
[INFO][13:10:20]: [Client #37] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:10:20]: [Server #615782] Received 0.26 MB of payload data from client #37 (simulated).
[INFO][13:10:22]: [Client #592] Woke up.
[INFO][13:10:22]: [Client #592] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_592_615874.pth.
[INFO][13:10:22]: [Client #592] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_592_615874.pth.
[INFO][13:10:22]: [Client #592] Model trained.
[INFO][13:10:22]: [Client #592] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:10:22]: [Server #615782] Received 0.26 MB of payload data from client #592 (simulated).
[INFO][13:10:22]: [Server #615782] Selecting client #198 for training.
[INFO][13:10:22]: [Server #615782] Sending the current model to client #198 (simulated).
[INFO][13:10:22]: [Server #615782] Sending 0.26 MB of payload data to client #198 (simulated).
[INFO][13:10:22]: [Server #615782] Selecting client #790 for training.
[INFO][13:10:22]: [Server #615782] Sending the current model to client #790 (simulated).
[INFO][13:10:22]: [Server #615782] Sending 0.26 MB of payload data to client #790 (simulated).
[INFO][13:10:22]: [Client #198] Selected by the server.
[INFO][13:10:22]: [Client #198] Loading its data source...
[INFO][13:10:22]: Data source: FEMNIST
[INFO][13:10:22]: [Client #790] Selected by the server.
[INFO][13:10:22]: [Client #790] Loading its data source...
[INFO][13:10:22]: Data source: FEMNIST
[INFO][13:10:22]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:10:22]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/790.zip.
[INFO][13:10:23]: [Client #198] Dataset size: 165
[INFO][13:10:23]: [Client #198] Sampler: all_inclusive
[INFO][13:10:23]: [Client #198] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:23]: [93m[1m[Client #198] Started training in communication round #3.[0m
2.7%5.4%8.1%10.8%13.4%16.1%18.8%21.5%24.2%26.9%29.6%32.3%34.9%37.6%40.3%43.0%45.7%48.4%51.1%53.8%56.4%59.1%61.8%64.5%67.2%69.9%72.6%75.3%77.9%80.6%83.3%86.0%88.7%91.4%94.1%96.8%99.4%100.0%[INFO][13:10:23]: Decompressing the dataset downloaded.
[INFO][13:10:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/790.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:10:23]: [Client #790] Dataset size: 138
[INFO][13:10:23]: [Client #790] Sampler: all_inclusive
[INFO][13:10:23]: [Client #790] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:23]: [93m[1m[Client #790] Started training in communication round #3.[0m

[INFO][13:10:25]: [Client #198] Loading the dataset.
[INFO][13:10:25]: [Client #790] Loading the dataset.
[INFO][13:10:30]: [Client #790] Epoch: [1/5][0/14]	Loss: 3.707287
[INFO][13:10:30]: [Client #198] Epoch: [1/5][0/17]	Loss: 2.724973
[INFO][13:10:30]: [Client #790] Epoch: [1/5][10/14]	Loss: 3.737823
[INFO][13:10:30]: [Client #198] Epoch: [1/5][10/17]	Loss: 3.160995
[INFO][13:10:30]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:10:30]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][13:10:31]: [Client #198] Woke up.
[INFO][13:10:31]: [Client #198] Epoch: [2/5][0/17]	Loss: 2.901986
[INFO][13:10:31]: [Client #198] Epoch: [2/5][10/17]	Loss: 2.603702
[INFO][13:10:31]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][13:10:31]: [Client #198] Woke up.
[INFO][13:10:31]: [Client #198] Epoch: [3/5][0/17]	Loss: 2.963078
[INFO][13:10:31]: [Client #198] Epoch: [3/5][10/17]	Loss: 2.765612
[INFO][13:10:31]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][13:10:31]: [Client #198] Woke up.
[INFO][13:10:31]: [Client #198] Epoch: [4/5][0/17]	Loss: 1.437791
[INFO][13:10:32]: [Client #198] Epoch: [4/5][10/17]	Loss: 3.647935
[INFO][13:10:32]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][13:10:32]: [Client #198] Woke up.
[INFO][13:10:32]: [Client #198] Epoch: [5/5][0/17]	Loss: 1.935019
[INFO][13:10:32]: [Client #198] Epoch: [5/5][10/17]	Loss: 2.992788
[INFO][13:10:32]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][13:10:32]: [Client #198] Woke up.
[INFO][13:10:32]: [Client #198] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_615874.pth.
[INFO][13:10:33]: [Client #198] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_615874.pth.
[INFO][13:10:33]: [Client #198] Model trained.
[INFO][13:10:33]: [Client #198] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:10:33]: [Server #615782] Received 0.26 MB of payload data from client #198 (simulated).
[INFO][13:10:34]: [Client #790] Woke up.
[INFO][13:10:34]: [Client #790] Epoch: [2/5][0/14]	Loss: 2.934067
[INFO][13:10:34]: [Client #790] Epoch: [2/5][10/14]	Loss: 2.867258
[INFO][13:10:34]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:10:38]: [Client #790] Woke up.
[INFO][13:10:38]: [Client #790] Epoch: [3/5][0/14]	Loss: 3.591941
[INFO][13:10:38]: [Client #790] Epoch: [3/5][10/14]	Loss: 1.848445
[INFO][13:10:38]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:10:42]: [Client #790] Woke up.
[INFO][13:10:42]: [Client #790] Epoch: [4/5][0/14]	Loss: 1.354497
[INFO][13:10:42]: [Client #790] Epoch: [4/5][10/14]	Loss: 2.581787
[INFO][13:10:42]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:10:46]: [Client #790] Woke up.
[INFO][13:10:46]: [Client #790] Epoch: [5/5][0/14]	Loss: 2.177624
[INFO][13:10:46]: [Client #790] Epoch: [5/5][10/14]	Loss: 3.307690
[INFO][13:10:46]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:10:50]: [Client #790] Woke up.
[INFO][13:10:50]: [Client #790] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_790_615875.pth.
[INFO][13:10:51]: [Client #790] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_790_615875.pth.
[INFO][13:10:51]: [Client #790] Model trained.
[INFO][13:10:51]: [Client #790] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:10:51]: [Server #615782] Received 0.26 MB of payload data from client #790 (simulated).
[INFO][13:10:51]: [Server #615782] Selecting client #13 for training.
[INFO][13:10:51]: [Server #615782] Sending the current model to client #13 (simulated).
[INFO][13:10:51]: [Server #615782] Sending 0.26 MB of payload data to client #13 (simulated).
[INFO][13:10:51]: [Server #615782] Selecting client #302 for training.
[INFO][13:10:51]: [Server #615782] Sending the current model to client #302 (simulated).
[INFO][13:10:51]: [Server #615782] Sending 0.26 MB of payload data to client #302 (simulated).
[INFO][13:10:51]: [Client #13] Selected by the server.
[INFO][13:10:51]: [Client #13] Loading its data source...
[INFO][13:10:51]: Data source: FEMNIST
[INFO][13:10:51]: [Client #302] Selected by the server.
[INFO][13:10:51]: [Client #302] Loading its data source...
[INFO][13:10:51]: Data source: FEMNIST
[INFO][13:10:51]: [Client #302] Dataset size: 160
[INFO][13:10:51]: [Client #302] Sampler: all_inclusive
[INFO][13:10:51]: [Client #302] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:51]: [Client #13] Dataset size: 144
[INFO][13:10:51]: [Client #13] Sampler: all_inclusive
[INFO][13:10:51]: [93m[1m[Client #302] Started training in communication round #3.[0m
[INFO][13:10:51]: [Client #13] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:10:51]: [93m[1m[Client #13] Started training in communication round #3.[0m
[INFO][13:10:53]: [Client #13] Loading the dataset.
[INFO][13:10:53]: [Client #302] Loading the dataset.
[INFO][13:10:58]: [Client #302] Epoch: [1/5][0/16]	Loss: 3.730035
[INFO][13:10:58]: [Client #13] Epoch: [1/5][0/15]	Loss: 3.333705
[INFO][13:10:58]: [Client #302] Epoch: [1/5][10/16]	Loss: 3.242315
[INFO][13:10:58]: [Client #13] Epoch: [1/5][10/15]	Loss: 2.761350
[INFO][13:10:58]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][13:10:58]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][13:10:59]: [Client #13] Woke up.
[INFO][13:10:59]: [Client #13] Epoch: [2/5][0/15]	Loss: 3.383620
[INFO][13:10:59]: [Client #13] Epoch: [2/5][10/15]	Loss: 2.716745
[INFO][13:10:59]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][13:10:59]: [Client #13] Woke up.
[INFO][13:10:59]: [Client #13] Epoch: [3/5][0/15]	Loss: 2.479702
[INFO][13:10:59]: [Client #13] Epoch: [3/5][10/15]	Loss: 2.681049
[INFO][13:10:59]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][13:10:59]: [Client #13] Woke up.
[INFO][13:10:59]: [Client #13] Epoch: [4/5][0/15]	Loss: 3.808538
[INFO][13:11:00]: [Client #13] Epoch: [4/5][10/15]	Loss: 3.198572
[INFO][13:11:00]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][13:11:00]: [Client #13] Woke up.
[INFO][13:11:00]: [Client #13] Epoch: [5/5][0/15]	Loss: 3.252750
[INFO][13:11:00]: [Client #13] Epoch: [5/5][10/15]	Loss: 3.040368
[INFO][13:11:00]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][13:11:00]: [Client #13] Woke up.
[INFO][13:11:00]: [Client #13] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_615874.pth.
[INFO][13:11:01]: [Client #13] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_615874.pth.
[INFO][13:11:01]: [Client #13] Model trained.
[INFO][13:11:01]: [Client #13] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:11:01]: [Server #615782] Received 0.26 MB of payload data from client #13 (simulated).
[INFO][13:11:05]: [Client #302] Woke up.
[INFO][13:11:05]: [Client #302] Epoch: [2/5][0/16]	Loss: 2.710287
[INFO][13:11:06]: [Client #302] Epoch: [2/5][10/16]	Loss: 3.164752
[INFO][13:11:06]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][13:11:13]: [Client #302] Woke up.
[INFO][13:11:13]: [Client #302] Epoch: [3/5][0/16]	Loss: 3.522089
[INFO][13:11:13]: [Client #302] Epoch: [3/5][10/16]	Loss: 2.793404
[INFO][13:11:13]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][13:11:20]: [Client #302] Woke up.
[INFO][13:11:20]: [Client #302] Epoch: [4/5][0/16]	Loss: 2.496489
[INFO][13:11:20]: [Client #302] Epoch: [4/5][10/16]	Loss: 2.151554
[INFO][13:11:20]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][13:11:27]: [Client #302] Woke up.
[INFO][13:11:27]: [Client #302] Epoch: [5/5][0/16]	Loss: 2.318103
[INFO][13:11:27]: [Client #302] Epoch: [5/5][10/16]	Loss: 2.395750
[INFO][13:11:27]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][13:11:34]: [Client #302] Woke up.
[INFO][13:11:34]: [Client #302] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_302_615875.pth.
[INFO][13:11:35]: [Client #302] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_302_615875.pth.
[INFO][13:11:35]: [Client #302] Model trained.
[INFO][13:11:35]: [Client #302] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:11:35]: [Server #615782] Received 0.26 MB of payload data from client #302 (simulated).
[INFO][13:11:35]: [Server #615782] Selecting client #22 for training.
[INFO][13:11:35]: [Server #615782] Sending the current model to client #22 (simulated).
[INFO][13:11:35]: [Server #615782] Sending 0.26 MB of payload data to client #22 (simulated).
[INFO][13:11:35]: [Server #615782] Selecting client #998 for training.
[INFO][13:11:35]: [Server #615782] Sending the current model to client #998 (simulated).
[INFO][13:11:35]: [Server #615782] Sending 0.26 MB of payload data to client #998 (simulated).
[INFO][13:11:35]: [Client #998] Selected by the server.
[INFO][13:11:35]: [Client #22] Selected by the server.
[INFO][13:11:35]: [Client #998] Loading its data source...
[INFO][13:11:35]: [Client #22] Loading its data source...
[INFO][13:11:35]: Data source: FEMNIST
[INFO][13:11:35]: Data source: FEMNIST
[INFO][13:11:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:11:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/998.zip.
[INFO][13:11:35]: [Client #22] Dataset size: 161
[INFO][13:11:35]: [Client #22] Sampler: all_inclusive
[INFO][13:11:35]: [Client #22] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:11:35]: [93m[1m[Client #22] Started training in communication round #3.[0m
3.1%6.2%9.3%12.4%15.4%18.5%21.6%24.7%27.8%30.9%34.0%37.1%40.1%43.2%46.3%49.4%52.5%55.6%58.7%61.8%64.8%67.9%71.0%74.1%77.2%80.3%83.4%86.5%89.5%92.6%95.7%98.8%100.0%[INFO][13:11:35]: Decompressing the dataset downloaded.
[INFO][13:11:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/998.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:11:35]: [Client #998] Dataset size: 151
[INFO][13:11:35]: [Client #998] Sampler: all_inclusive
[INFO][13:11:35]: [Client #998] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:11:35]: [93m[1m[Client #998] Started training in communication round #3.[0m

[INFO][13:11:37]: [Client #22] Loading the dataset.
[INFO][13:11:37]: [Client #998] Loading the dataset.
[INFO][13:11:43]: [Client #22] Epoch: [1/5][0/17]	Loss: 3.347578
[INFO][13:11:43]: [Client #998] Epoch: [1/5][0/16]	Loss: 3.589151
[INFO][13:11:43]: [Client #22] Epoch: [1/5][10/17]	Loss: 2.984631
[INFO][13:11:43]: [Client #998] Epoch: [1/5][10/16]	Loss: 3.034280
[INFO][13:11:43]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][13:11:43]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:11:45]: [Client #998] Woke up.
[INFO][13:11:45]: [Client #998] Epoch: [2/5][0/16]	Loss: 3.060668
[INFO][13:11:45]: [Client #998] Epoch: [2/5][10/16]	Loss: 3.154481
[INFO][13:11:45]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][13:11:47]: [Client #998] Woke up.
[INFO][13:11:47]: [Client #998] Epoch: [3/5][0/16]	Loss: 3.383506
[INFO][13:11:47]: [Client #998] Epoch: [3/5][10/16]	Loss: 3.256853
[INFO][13:11:47]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][13:11:49]: [Client #998] Woke up.
[INFO][13:11:49]: [Client #998] Epoch: [4/5][0/16]	Loss: 2.536067
[INFO][13:11:49]: [Client #998] Epoch: [4/5][10/16]	Loss: 3.049047
[INFO][13:11:49]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][13:11:51]: [Client #998] Woke up.
[INFO][13:11:51]: [Client #998] Epoch: [5/5][0/16]	Loss: 3.520273
[INFO][13:11:51]: [Client #998] Epoch: [5/5][10/16]	Loss: 2.954711
[INFO][13:11:51]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][13:11:53]: [Client #998] Woke up.
[INFO][13:11:53]: [Client #998] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_998_615875.pth.
[INFO][13:11:54]: [Client #998] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_998_615875.pth.
[INFO][13:11:54]: [Client #998] Model trained.
[INFO][13:11:54]: [Client #998] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:11:54]: [Server #615782] Received 0.26 MB of payload data from client #998 (simulated).
[INFO][13:12:13]: [Client #22] Woke up.
[INFO][13:12:13]: [Client #22] Epoch: [2/5][0/17]	Loss: 2.721670
[INFO][13:12:13]: [Client #22] Epoch: [2/5][10/17]	Loss: 3.531008
[INFO][13:12:13]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:12:44]: [Client #22] Woke up.
[INFO][13:12:44]: [Client #22] Epoch: [3/5][0/17]	Loss: 3.316269
[INFO][13:12:44]: [Client #22] Epoch: [3/5][10/17]	Loss: 3.101699
[INFO][13:12:44]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:13:15]: [Client #22] Woke up.
[INFO][13:13:15]: [Client #22] Epoch: [4/5][0/17]	Loss: 2.982521
[INFO][13:13:15]: [Client #22] Epoch: [4/5][10/17]	Loss: 1.342540
[INFO][13:13:15]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:13:46]: [Client #22] Woke up.
[INFO][13:13:46]: [Client #22] Epoch: [5/5][0/17]	Loss: 3.043842
[INFO][13:13:46]: [Client #22] Epoch: [5/5][10/17]	Loss: 3.015697
[INFO][13:13:46]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:14:16]: [Client #22] Woke up.
[INFO][13:14:16]: [Client #22] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_615874.pth.
[INFO][13:14:17]: [Client #22] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_615874.pth.
[INFO][13:14:17]: [Client #22] Model trained.
[INFO][13:14:17]: [Client #22] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:14:17]: [Server #615782] Received 0.26 MB of payload data from client #22 (simulated).
[INFO][13:14:17]: [Server #615782] Selecting client #584 for training.
[INFO][13:14:17]: [Server #615782] Sending the current model to client #584 (simulated).
[INFO][13:14:17]: [Server #615782] Sending 0.26 MB of payload data to client #584 (simulated).
[INFO][13:14:17]: [Client #584] Selected by the server.
[INFO][13:14:17]: [Client #584] Loading its data source...
[INFO][13:14:17]: Data source: FEMNIST
[INFO][13:14:17]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:14:17]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/584.zip.
2.4%4.8%7.2%9.6%12.0%14.4%16.8%19.2%21.6%24.0%26.4%28.8%31.2%33.7%36.1%38.5%40.9%43.3%45.7%48.1%50.5%52.9%55.3%57.7%60.1%62.5%64.9%67.3%69.7%72.1%74.5%76.9%79.3%81.7%84.1%86.5%88.9%91.3%93.7%96.2%98.6%100.0%[INFO][13:14:17]: Decompressing the dataset downloaded.
[INFO][13:14:17]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/584.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:14:17]: [Client #584] Dataset size: 156
[INFO][13:14:17]: [Client #584] Sampler: all_inclusive
[INFO][13:14:17]: [Client #584] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:14:17]: [93m[1m[Client #584] Started training in communication round #3.[0m

[INFO][13:14:19]: [Client #584] Loading the dataset.
[INFO][13:14:24]: [Client #584] Epoch: [1/5][0/16]	Loss: 3.120472
[INFO][13:14:25]: [Client #584] Epoch: [1/5][10/16]	Loss: 3.470311
[INFO][13:14:25]: [Client #584] Going to sleep for 0.41 seconds.
[INFO][13:14:25]: [Client #584] Woke up.
[INFO][13:14:25]: [Client #584] Epoch: [2/5][0/16]	Loss: 3.348570
[INFO][13:14:25]: [Client #584] Epoch: [2/5][10/16]	Loss: 4.076417
[INFO][13:14:25]: [Client #584] Going to sleep for 0.41 seconds.
[INFO][13:14:26]: [Client #584] Woke up.
[INFO][13:14:26]: [Client #584] Epoch: [3/5][0/16]	Loss: 2.545189
[INFO][13:14:26]: [Client #584] Epoch: [3/5][10/16]	Loss: 3.297793
[INFO][13:14:26]: [Client #584] Going to sleep for 0.41 seconds.
[INFO][13:14:26]: [Client #584] Woke up.
[INFO][13:14:26]: [Client #584] Epoch: [4/5][0/16]	Loss: 2.822832
[INFO][13:14:26]: [Client #584] Epoch: [4/5][10/16]	Loss: 1.946277
[INFO][13:14:26]: [Client #584] Going to sleep for 0.41 seconds.
[INFO][13:14:27]: [Client #584] Woke up.
[INFO][13:14:27]: [Client #584] Epoch: [5/5][0/16]	Loss: 2.736426
[INFO][13:14:27]: [Client #584] Epoch: [5/5][10/16]	Loss: 2.321083
[INFO][13:14:27]: [Client #584] Going to sleep for 0.41 seconds.
[INFO][13:14:27]: [Client #584] Woke up.
[INFO][13:14:27]: [Client #584] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_584_615874.pth.
[INFO][13:14:28]: [Client #584] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_584_615874.pth.
[INFO][13:14:28]: [Client #584] Model trained.
[INFO][13:14:28]: [Client #584] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:14:28]: [Server #615782] Received 0.26 MB of payload data from client #584 (simulated).
[INFO][13:14:28]: [Server #615782] Adding client #122 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #882 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #13 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #198 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #584 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #824 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #191 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #8 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #755 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #920 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #126 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #723 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #328 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #441 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #322 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #998 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #37 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #607 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #592 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #590 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #790 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #320 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #302 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #69 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #857 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #533 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #254 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #22 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #299 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][13:14:28]: [Server #615782] Aggregating 30 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.07346877 0.         0.         0.         0.
 0.08540633 0.         0.         0.         0.         0.
 0.         0.         0.         0.36204472 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11091435 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04556445 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11557455 0.         0.         0.         0.07778943
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10059396 0.
 0.         0.         0.         0.         0.         0.1140518
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.02696226 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.02080447 0.
 0.         0.09615697 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07377004 0.         0.23267865 0.         0.
 0.         0.         0.         0.10456923 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10553891 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14849389 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09777334 0.         0.         0.         0.
 0.         0.10720599 0.         0.07983635 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09767984 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07763681 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14704168 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06459749 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1150326  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10579514 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03950194
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08241415
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19319596 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15157763 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.07346877 0.         0.         0.         0.
 0.08540633 0.         0.         0.         0.         0.
 0.         0.         0.         0.36204472 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11091435 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04556445 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11557455 0.         0.         0.         0.07778943
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10059396 0.
 0.         0.         0.         0.         0.         0.1140518
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.02696226 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.02080447 0.
 0.         0.09615697 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07377004 0.         0.23267865 0.         0.
 0.         0.         0.         0.10456923 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10553891 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14849389 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09777334 0.         0.         0.         0.
 0.         0.10720599 0.         0.07983635 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09767984 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07763681 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14704168 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06459749 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1150326  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10579514 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03950194
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08241415
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19319596 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15157763 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.03333333 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03395445 0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.001      0.03416149
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.05656805 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.001      0.001      0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0212766  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03881657 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.05652174 0.001
 0.001      0.001      0.02284735 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03229814 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.0310559  0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02084821 0.001      0.001      0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.02056262 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02199058 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02313294 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0212766  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02441811 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.001      0.001      0.001      0.001      0.01670713 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02857143 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02284735 0.001      0.001      0.001      0.001
 0.001      0.03431953 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.001      0.02184778
 0.001      0.001      0.001      0.001      0.001      0.03064182
 0.001      0.02256176 0.001      0.03739645 0.001      0.001
 0.001      0.001      0.001      0.001      0.02141939 0.01925466
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.01742111 0.001      0.02213337 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02256176 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03126294 0.001      0.001     ][INFO][13:15:12]: [Server #615782] Global model accuracy: 23.41%

[INFO][13:15:12]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_3.pth.
[INFO][13:15:12]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_3.pth.
[INFO][13:15:12]: [93m[1m
[Server #615782] Starting round 4/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.6009e+00  1e+03  1e+00  1e+00
 1:  7.5249e+00  6.6020e+00  1e+01  1e-02  1e-02
 2:  7.6002e+00  6.6912e+00  1e+00  9e-05  9e-05
 3:  7.6009e+00  7.5207e+00  8e-02  4e-07  4e-07
 4:  7.6009e+00  7.6000e+00  9e-04  4e-09  4e-09
 5:  7.6009e+00  7.6008e+00  8e-05  3e-10  3e-10
 6:  7.6009e+00  7.6008e+00  7e-05  2e-10  2e-10
 7:  7.6009e+00  7.6008e+00  7e-05  5e-09  7e-10
 8:  7.6009e+00  7.6008e+00  5e-05  4e-09  6e-10
 9:  7.6009e+00  7.6008e+00  4e-05  9e-09  1e-09
10:  7.6008e+00  7.6008e+00  7e-06  3e-08  4e-09
Optimal solution found.
The calculated probability is:  [1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08512158e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08510226e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08367694e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08502331e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.86462585e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08501655e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08509721e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08504911e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08501308e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.44870850e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.34703836e-04 1.08516876e-04
 1.08516876e-04 1.08506470e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08511275e-04
 1.08516876e-04 1.08403869e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08503947e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08505112e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 8.91389535e-01 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08506649e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08505049e-04 1.08516876e-04 1.08510571e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08506928e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08510007e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08481111e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08513382e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08501610e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08505207e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.70694601e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08514293e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08474356e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08516876e-04 1.08516876e-04 1.08516876e-04
 1.08516876e-04 1.08493849e-04 1.08516876e-04 1.08516876e-04][INFO][13:15:15]: [Server #615782] Selected clients: [533 735 235 730 725 330 845 428 866 658 582 200 529 895 305 872 909 684
 900  75 879 190 851 668 344 151 636 849 823 629 957 590 197 429 337 992
 380 993 518 172  74 370 123 635 414 991 931 149 395 459]
[INFO][13:15:15]: [Server #615782] Selecting client #533 for training.
[INFO][13:15:15]: [Server #615782] Sending the current model to client #533 (simulated).
[INFO][13:15:15]: [Server #615782] Sending 0.26 MB of payload data to client #533 (simulated).
[INFO][13:15:15]: [Server #615782] Selecting client #735 for training.
[INFO][13:15:15]: [Server #615782] Sending the current model to client #735 (simulated).
[INFO][13:15:15]: [Server #615782] Sending 0.26 MB of payload data to client #735 (simulated).
[INFO][13:15:15]: [Client #533] Selected by the server.
[INFO][13:15:15]: [Client #533] Loading its data source...
[INFO][13:15:15]: Data source: FEMNIST
[INFO][13:15:15]: [Client #735] Selected by the server.
[INFO][13:15:15]: [Client #735] Loading its data source...
[INFO][13:15:15]: Data source: FEMNIST
[INFO][13:15:15]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:15:15]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/735.zip.
[INFO][13:15:15]: [Client #533] Dataset size: 273
[INFO][13:15:15]: [Client #533] Sampler: all_inclusive
[INFO][13:15:15]: [Client #533] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:15:15]: [93m[1m[Client #533] Started training in communication round #4.[0m
2.5%5.1%7.6%10.2%12.7%15.3%17.8%20.3%22.9%25.4%28.0%30.5%33.1%35.6%38.1%40.7%43.2%45.8%48.3%50.9%53.4%55.9%58.5%61.0%63.6%66.1%68.7%71.2%73.7%76.3%78.8%81.4%83.9%86.5%89.0%91.5%94.1%96.6%99.2%100.0%[INFO][13:15:15]: Decompressing the dataset downloaded.
[INFO][13:15:15]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/735.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:15:15]: [Client #735] Dataset size: 162
[INFO][13:15:15]: [Client #735] Sampler: all_inclusive
[INFO][13:15:15]: [Client #735] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:15:15]: [93m[1m[Client #735] Started training in communication round #4.[0m

[INFO][13:15:17]: [Client #533] Loading the dataset.
[INFO][13:15:17]: [Client #735] Loading the dataset.
[INFO][13:15:23]: [Client #533] Epoch: [1/5][0/28]	Loss: 2.954247
[INFO][13:15:23]: [Client #735] Epoch: [1/5][0/17]	Loss: 3.229601
[INFO][13:15:23]: [Client #533] Epoch: [1/5][10/28]	Loss: 3.420039
[INFO][13:15:23]: [Client #735] Epoch: [1/5][10/17]	Loss: 1.920138
[INFO][13:15:23]: [Client #735] Going to sleep for 2.34 seconds.
[INFO][13:15:23]: [Client #533] Epoch: [1/5][20/28]	Loss: 2.419173
[INFO][13:15:23]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:15:25]: [Client #735] Woke up.
[INFO][13:15:25]: [Client #735] Epoch: [2/5][0/17]	Loss: 2.484600
[INFO][13:15:25]: [Client #735] Epoch: [2/5][10/17]	Loss: 1.889373
[INFO][13:15:25]: [Client #735] Going to sleep for 2.34 seconds.
[INFO][13:15:28]: [Client #735] Woke up.
[INFO][13:15:28]: [Client #735] Epoch: [3/5][0/17]	Loss: 1.811934
[INFO][13:15:28]: [Client #735] Epoch: [3/5][10/17]	Loss: 3.013438
[INFO][13:15:28]: [Client #735] Going to sleep for 2.34 seconds.
[INFO][13:15:30]: [Client #735] Woke up.
[INFO][13:15:30]: [Client #735] Epoch: [4/5][0/17]	Loss: 2.839204
[INFO][13:15:30]: [Client #735] Epoch: [4/5][10/17]	Loss: 2.457276
[INFO][13:15:30]: [Client #735] Going to sleep for 2.34 seconds.
[INFO][13:15:33]: [Client #735] Woke up.
[INFO][13:15:33]: [Client #735] Epoch: [5/5][0/17]	Loss: 1.643986
[INFO][13:15:33]: [Client #735] Epoch: [5/5][10/17]	Loss: 2.829474
[INFO][13:15:33]: [Client #735] Going to sleep for 2.34 seconds.
[INFO][13:15:35]: [Client #735] Woke up.
[INFO][13:15:35]: [Client #735] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_735_615875.pth.
[INFO][13:15:36]: [Client #735] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_735_615875.pth.
[INFO][13:15:36]: [Client #735] Model trained.
[INFO][13:15:36]: [Client #735] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:15:36]: [Server #615782] Received 0.26 MB of payload data from client #735 (simulated).
[INFO][13:15:59]: [Client #533] Woke up.
[INFO][13:15:59]: [Client #533] Epoch: [2/5][0/28]	Loss: 3.227684
[INFO][13:15:59]: [Client #533] Epoch: [2/5][10/28]	Loss: 3.012739
[INFO][13:15:59]: [Client #533] Epoch: [2/5][20/28]	Loss: 2.660735
[INFO][13:15:59]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:16:35]: [Client #533] Woke up.
[INFO][13:16:35]: [Client #533] Epoch: [3/5][0/28]	Loss: 3.483110
[INFO][13:16:35]: [Client #533] Epoch: [3/5][10/28]	Loss: 3.180080
[INFO][13:16:35]: [Client #533] Epoch: [3/5][20/28]	Loss: 2.302606
[INFO][13:16:35]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:17:11]: [Client #533] Woke up.
[INFO][13:17:11]: [Client #533] Epoch: [4/5][0/28]	Loss: 3.267729
[INFO][13:17:11]: [Client #533] Epoch: [4/5][10/28]	Loss: 2.066877
[INFO][13:17:11]: [Client #533] Epoch: [4/5][20/28]	Loss: 2.791932
[INFO][13:17:11]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:17:47]: [Client #533] Woke up.
[INFO][13:17:47]: [Client #533] Epoch: [5/5][0/28]	Loss: 3.923751
[INFO][13:17:47]: [Client #533] Epoch: [5/5][10/28]	Loss: 2.368228
[INFO][13:17:47]: [Client #533] Epoch: [5/5][20/28]	Loss: 1.913161
[INFO][13:17:47]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:18:23]: [Client #533] Woke up.
[INFO][13:18:23]: [Client #533] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615874.pth.
[INFO][13:18:24]: [Client #533] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615874.pth.
[INFO][13:18:24]: [Client #533] Model trained.
[INFO][13:18:24]: [Client #533] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:18:24]: [Server #615782] Received 0.26 MB of payload data from client #533 (simulated).
[INFO][13:18:24]: [Server #615782] Selecting client #235 for training.
[INFO][13:18:24]: [Server #615782] Sending the current model to client #235 (simulated).
[INFO][13:18:24]: [Server #615782] Sending 0.26 MB of payload data to client #235 (simulated).
[INFO][13:18:24]: [Server #615782] Selecting client #730 for training.
[INFO][13:18:24]: [Server #615782] Sending the current model to client #730 (simulated).
[INFO][13:18:24]: [Server #615782] Sending 0.26 MB of payload data to client #730 (simulated).
[INFO][13:18:24]: [Client #235] Selected by the server.
[INFO][13:18:24]: [Client #235] Loading its data source...
[INFO][13:18:24]: Data source: FEMNIST
[INFO][13:18:24]: [Client #730] Selected by the server.
[INFO][13:18:24]: [Client #730] Loading its data source...
[INFO][13:18:24]: Data source: FEMNIST
[INFO][13:18:24]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:18:24]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/730.zip.
[INFO][13:18:24]: [Client #235] Dataset size: 140
[INFO][13:18:24]: [Client #235] Sampler: all_inclusive
[INFO][13:18:24]: [Client #235] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:18:24]: [93m[1m[Client #235] Started training in communication round #4.[0m
3.7%7.4%11.1%14.8%18.5%22.2%25.9%29.6%33.3%37.0%40.8%44.5%48.2%51.9%55.6%59.3%63.0%66.7%70.4%74.1%77.8%81.5%85.2%88.9%92.6%96.3%100.0%[INFO][13:18:24]: Decompressing the dataset downloaded.
[INFO][13:18:24]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/730.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:18:24]: [Client #730] Dataset size: 148
[INFO][13:18:24]: [Client #730] Sampler: all_inclusive
[INFO][13:18:24]: [Client #730] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:18:24]: [93m[1m[Client #730] Started training in communication round #4.[0m

[INFO][13:18:26]: [Client #235] Loading the dataset.
[INFO][13:18:26]: [Client #730] Loading the dataset.
[INFO][13:18:31]: [Client #730] Epoch: [1/5][0/15]	Loss: 3.036657
[INFO][13:18:31]: [Client #235] Epoch: [1/5][0/14]	Loss: 2.892786
[INFO][13:18:32]: [Client #730] Epoch: [1/5][10/15]	Loss: 3.223607
[INFO][13:18:32]: [Client #235] Epoch: [1/5][10/14]	Loss: 2.439823
[INFO][13:18:32]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][13:18:32]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:18:33]: [Client #235] Woke up.
[INFO][13:18:33]: [Client #235] Epoch: [2/5][0/14]	Loss: 2.321002
[INFO][13:18:33]: [Client #235] Epoch: [2/5][10/14]	Loss: 3.451177
[INFO][13:18:33]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][13:18:34]: [Client #235] Woke up.
[INFO][13:18:34]: [Client #235] Epoch: [3/5][0/14]	Loss: 2.234340
[INFO][13:18:34]: [Client #235] Epoch: [3/5][10/14]	Loss: 2.276576
[INFO][13:18:34]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][13:18:35]: [Client #235] Woke up.
[INFO][13:18:35]: [Client #235] Epoch: [4/5][0/14]	Loss: 1.733257
[INFO][13:18:35]: [Client #235] Epoch: [4/5][10/14]	Loss: 2.037513
[INFO][13:18:35]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][13:18:36]: [Client #235] Woke up.
[INFO][13:18:36]: [Client #235] Epoch: [5/5][0/14]	Loss: 2.091575
[INFO][13:18:36]: [Client #235] Epoch: [5/5][10/14]	Loss: 2.391786
[INFO][13:18:36]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][13:18:37]: [Client #235] Woke up.
[INFO][13:18:37]: [Client #235] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_615874.pth.
[INFO][13:18:38]: [Client #235] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_615874.pth.
[INFO][13:18:38]: [Client #235] Model trained.
[INFO][13:18:38]: [Client #235] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:18:38]: [Server #615782] Received 0.26 MB of payload data from client #235 (simulated).
[INFO][13:18:48]: [Client #730] Woke up.
[INFO][13:18:48]: [Client #730] Epoch: [2/5][0/15]	Loss: 2.575556
[INFO][13:18:48]: [Client #730] Epoch: [2/5][10/15]	Loss: 1.853921
[INFO][13:18:48]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:19:05]: [Client #730] Woke up.
[INFO][13:19:05]: [Client #730] Epoch: [3/5][0/15]	Loss: 2.006799
[INFO][13:19:05]: [Client #730] Epoch: [3/5][10/15]	Loss: 2.012834
[INFO][13:19:05]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:19:21]: [Client #730] Woke up.
[INFO][13:19:21]: [Client #730] Epoch: [4/5][0/15]	Loss: 2.685672
[INFO][13:19:21]: [Client #730] Epoch: [4/5][10/15]	Loss: 2.754932
[INFO][13:19:21]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:19:38]: [Client #730] Woke up.
[INFO][13:19:38]: [Client #730] Epoch: [5/5][0/15]	Loss: 2.206561
[INFO][13:19:38]: [Client #730] Epoch: [5/5][10/15]	Loss: 3.204995
[INFO][13:19:38]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:19:55]: [Client #730] Woke up.
[INFO][13:19:55]: [Client #730] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615875.pth.
[INFO][13:19:55]: [Client #730] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615875.pth.
[INFO][13:19:55]: [Client #730] Model trained.
[INFO][13:19:55]: [Client #730] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:19:55]: [Server #615782] Received 0.26 MB of payload data from client #730 (simulated).
[INFO][13:19:55]: [Server #615782] Selecting client #725 for training.
[INFO][13:19:55]: [Server #615782] Sending the current model to client #725 (simulated).
[INFO][13:19:55]: [Server #615782] Sending 0.26 MB of payload data to client #725 (simulated).
[INFO][13:19:55]: [Server #615782] Selecting client #330 for training.
[INFO][13:19:55]: [Server #615782] Sending the current model to client #330 (simulated).
[INFO][13:19:55]: [Server #615782] Sending 0.26 MB of payload data to client #330 (simulated).
[INFO][13:19:55]: [Client #725] Selected by the server.
[INFO][13:19:55]: [Client #725] Loading its data source...
[INFO][13:19:55]: Data source: FEMNIST
[INFO][13:19:55]: [Client #330] Selected by the server.
[INFO][13:19:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:19:55]: [Client #330] Loading its data source...
[INFO][13:19:55]: Data source: FEMNIST
[INFO][13:19:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/725.zip.
[INFO][13:19:55]: [Client #330] Dataset size: 153
[INFO][13:19:55]: [Client #330] Sampler: all_inclusive
[INFO][13:19:55]: [Client #330] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:19:55]: [93m[1m[Client #330] Started training in communication round #4.[0m
2.4%4.9%7.3%9.7%12.2%14.6%17.0%19.5%21.9%24.3%26.8%29.2%31.7%34.1%36.5%39.0%41.4%43.8%46.3%48.7%51.1%53.6%56.0%58.4%60.9%63.3%65.7%68.2%70.6%73.0%75.5%77.9%80.4%82.8%85.2%87.7%90.1%92.5%95.0%97.4%99.8%100.0%[INFO][13:19:55]: Decompressing the dataset downloaded.
[INFO][13:19:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/725.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:19:56]: [Client #725] Dataset size: 152
[INFO][13:19:56]: [Client #725] Sampler: all_inclusive
[INFO][13:19:56]: [Client #725] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:19:56]: [93m[1m[Client #725] Started training in communication round #4.[0m

[INFO][13:19:57]: [Client #330] Loading the dataset.
[INFO][13:19:57]: [Client #725] Loading the dataset.
[INFO][13:20:03]: [Client #330] Epoch: [1/5][0/16]	Loss: 3.462158
[INFO][13:20:03]: [Client #725] Epoch: [1/5][0/16]	Loss: 3.183974
[INFO][13:20:03]: [Client #330] Epoch: [1/5][10/16]	Loss: 3.901950
[INFO][13:20:03]: [Client #725] Epoch: [1/5][10/16]	Loss: 2.870886
[INFO][13:20:03]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][13:20:03]: [Client #725] Going to sleep for 1.02 seconds.
[INFO][13:20:04]: [Client #725] Woke up.
[INFO][13:20:04]: [Client #725] Epoch: [2/5][0/16]	Loss: 2.452599
[INFO][13:20:04]: [Client #725] Epoch: [2/5][10/16]	Loss: 2.716220
[INFO][13:20:04]: [Client #725] Going to sleep for 1.02 seconds.
[INFO][13:20:05]: [Client #330] Woke up.
[INFO][13:20:05]: [Client #330] Epoch: [2/5][0/16]	Loss: 2.782884
[INFO][13:20:05]: [Client #330] Epoch: [2/5][10/16]	Loss: 2.157355
[INFO][13:20:05]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][13:20:05]: [Client #725] Woke up.
[INFO][13:20:05]: [Client #725] Epoch: [3/5][0/16]	Loss: 3.130231
[INFO][13:20:05]: [Client #725] Epoch: [3/5][10/16]	Loss: 2.917514
[INFO][13:20:05]: [Client #725] Going to sleep for 1.02 seconds.
[INFO][13:20:06]: [Client #725] Woke up.
[INFO][13:20:06]: [Client #725] Epoch: [4/5][0/16]	Loss: 1.606888
[INFO][13:20:06]: [Client #725] Epoch: [4/5][10/16]	Loss: 2.461341
[INFO][13:20:06]: [Client #725] Going to sleep for 1.02 seconds.
[INFO][13:20:07]: [Client #330] Woke up.
[INFO][13:20:07]: [Client #330] Epoch: [3/5][0/16]	Loss: 2.529596
[INFO][13:20:07]: [Client #330] Epoch: [3/5][10/16]	Loss: 3.239666
[INFO][13:20:07]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][13:20:07]: [Client #725] Woke up.
[INFO][13:20:07]: [Client #725] Epoch: [5/5][0/16]	Loss: 2.018155
[INFO][13:20:08]: [Client #725] Epoch: [5/5][10/16]	Loss: 2.664042
[INFO][13:20:08]: [Client #725] Going to sleep for 1.02 seconds.
[INFO][13:20:09]: [Client #725] Woke up.
[INFO][13:20:09]: [Client #725] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_725_615874.pth.
[INFO][13:20:09]: [Client #330] Woke up.
[INFO][13:20:09]: [Client #330] Epoch: [4/5][0/16]	Loss: 1.661593
[INFO][13:20:09]: [Client #330] Epoch: [4/5][10/16]	Loss: 2.957822
[INFO][13:20:09]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][13:20:09]: [Client #725] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_725_615874.pth.
[INFO][13:20:09]: [Client #725] Model trained.
[INFO][13:20:09]: [Client #725] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:20:09]: [Server #615782] Received 0.26 MB of payload data from client #725 (simulated).
[INFO][13:20:11]: [Client #330] Woke up.
[INFO][13:20:11]: [Client #330] Epoch: [5/5][0/16]	Loss: 2.460418
[INFO][13:20:11]: [Client #330] Epoch: [5/5][10/16]	Loss: 2.819581
[INFO][13:20:11]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][13:20:13]: [Client #330] Woke up.
[INFO][13:20:13]: [Client #330] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_615875.pth.
[INFO][13:20:14]: [Client #330] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_615875.pth.
[INFO][13:20:14]: [Client #330] Model trained.
[INFO][13:20:14]: [Client #330] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:20:14]: [Server #615782] Received 0.26 MB of payload data from client #330 (simulated).
[INFO][13:20:14]: [Server #615782] Selecting client #845 for training.
[INFO][13:20:14]: [Server #615782] Sending the current model to client #845 (simulated).
[INFO][13:20:14]: [Server #615782] Sending 0.26 MB of payload data to client #845 (simulated).
[INFO][13:20:14]: [Server #615782] Selecting client #428 for training.
[INFO][13:20:14]: [Server #615782] Sending the current model to client #428 (simulated).
[INFO][13:20:14]: [Server #615782] Sending 0.26 MB of payload data to client #428 (simulated).
[INFO][13:20:14]: [Client #428] Selected by the server.
[INFO][13:20:14]: [Client #428] Loading its data source...
[INFO][13:20:14]: [Client #845] Selected by the server.
[INFO][13:20:14]: Data source: FEMNIST
[INFO][13:20:14]: [Client #845] Loading its data source...
[INFO][13:20:14]: Data source: FEMNIST
[INFO][13:20:14]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:20:14]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/845.zip.
[INFO][13:20:14]: [Client #428] Dataset size: 159
[INFO][13:20:14]: [Client #428] Sampler: all_inclusive
[INFO][13:20:14]: [Client #428] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:20:14]: [93m[1m[Client #428] Started training in communication round #4.[0m
3.4%6.7%10.1%13.5%16.9%20.2%23.6%27.0%30.3%33.7%37.1%40.5%43.8%47.2%50.6%53.9%57.3%60.7%64.1%67.4%70.8%74.2%77.5%80.9%84.3%87.7%91.0%94.4%97.8%100.0%[INFO][13:20:14]: Decompressing the dataset downloaded.
[INFO][13:20:14]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/845.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:20:14]: [Client #845] Dataset size: 140
[INFO][13:20:14]: [Client #845] Sampler: all_inclusive
[INFO][13:20:14]: [Client #845] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:20:14]: [93m[1m[Client #845] Started training in communication round #4.[0m

[INFO][13:20:16]: [Client #428] Loading the dataset.
[INFO][13:20:16]: [Client #845] Loading the dataset.
[INFO][13:20:21]: [Client #428] Epoch: [1/5][0/16]	Loss: 3.464612
[INFO][13:20:21]: [Client #428] Epoch: [1/5][10/16]	Loss: 1.849244
[INFO][13:20:21]: [Client #845] Epoch: [1/5][0/14]	Loss: 2.784878
[INFO][13:20:21]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][13:20:21]: [Client #845] Epoch: [1/5][10/14]	Loss: 3.092087
[INFO][13:20:21]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][13:20:24]: [Client #428] Woke up.
[INFO][13:20:24]: [Client #428] Epoch: [2/5][0/16]	Loss: 3.352085
[INFO][13:20:24]: [Client #428] Epoch: [2/5][10/16]	Loss: 2.527512
[INFO][13:20:25]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][13:20:25]: [Client #845] Woke up.
[INFO][13:20:25]: [Client #845] Epoch: [2/5][0/14]	Loss: 2.690707
[INFO][13:20:26]: [Client #845] Epoch: [2/5][10/14]	Loss: 3.164503
[INFO][13:20:26]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][13:20:28]: [Client #428] Woke up.
[INFO][13:20:28]: [Client #428] Epoch: [3/5][0/16]	Loss: 2.747351
[INFO][13:20:28]: [Client #428] Epoch: [3/5][10/16]	Loss: 3.841553
[INFO][13:20:28]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][13:20:30]: [Client #845] Woke up.
[INFO][13:20:30]: [Client #845] Epoch: [3/5][0/14]	Loss: 2.980570
[INFO][13:20:30]: [Client #845] Epoch: [3/5][10/14]	Loss: 1.987931
[INFO][13:20:30]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][13:20:31]: [Client #428] Woke up.
[INFO][13:20:31]: [Client #428] Epoch: [4/5][0/16]	Loss: 2.548639
[INFO][13:20:31]: [Client #428] Epoch: [4/5][10/16]	Loss: 2.459857
[INFO][13:20:31]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][13:20:34]: [Client #845] Woke up.
[INFO][13:20:34]: [Client #845] Epoch: [4/5][0/14]	Loss: 2.834651
[INFO][13:20:34]: [Client #845] Epoch: [4/5][10/14]	Loss: 3.044013
[INFO][13:20:34]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][13:20:34]: [Client #428] Woke up.
[INFO][13:20:34]: [Client #428] Epoch: [5/5][0/16]	Loss: 2.808188
[INFO][13:20:34]: [Client #428] Epoch: [5/5][10/16]	Loss: 3.049583
[INFO][13:20:34]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][13:20:37]: [Client #428] Woke up.
[INFO][13:20:37]: [Client #428] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_615875.pth.
[INFO][13:20:38]: [Client #845] Woke up.
[INFO][13:20:38]: [Client #845] Epoch: [5/5][0/14]	Loss: 2.468092
[INFO][13:20:38]: [Client #428] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_615875.pth.
[INFO][13:20:38]: [Client #845] Epoch: [5/5][10/14]	Loss: 1.751321
[INFO][13:20:38]: [Client #428] Model trained.
[INFO][13:20:38]: [Client #428] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:20:38]: [Server #615782] Received 0.26 MB of payload data from client #428 (simulated).
[INFO][13:20:38]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][13:20:42]: [Client #845] Woke up.
[INFO][13:20:42]: [Client #845] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_845_615874.pth.
[INFO][13:20:43]: [Client #845] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_845_615874.pth.
[INFO][13:20:43]: [Client #845] Model trained.
[INFO][13:20:43]: [Client #845] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:20:43]: [Server #615782] Received 0.26 MB of payload data from client #845 (simulated).
[INFO][13:20:43]: [Server #615782] Selecting client #866 for training.
[INFO][13:20:43]: [Server #615782] Sending the current model to client #866 (simulated).
[INFO][13:20:43]: [Server #615782] Sending 0.26 MB of payload data to client #866 (simulated).
[INFO][13:20:43]: [Server #615782] Selecting client #658 for training.
[INFO][13:20:43]: [Server #615782] Sending the current model to client #658 (simulated).
[INFO][13:20:43]: [Server #615782] Sending 0.26 MB of payload data to client #658 (simulated).
[INFO][13:20:43]: [Client #866] Selected by the server.
[INFO][13:20:43]: [Client #866] Loading its data source...
[INFO][13:20:43]: Data source: FEMNIST
[INFO][13:20:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:20:43]: [Client #658] Selected by the server.
[INFO][13:20:43]: [Client #658] Loading its data source...
[INFO][13:20:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/866.zip.
[INFO][13:20:43]: Data source: FEMNIST
[INFO][13:20:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:20:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/658.zip.
3.4%6.7%10.1%13.5%16.8%20.2%23.6%26.9%30.3%33.7%37.0%40.4%43.8%47.1%50.5%53.9%57.2%1.8%3.6%5.4%60.6%64.0%67.3%70.7%74.1%77.4%80.8%84.2%87.5%90.9%94.3%97.6%100.0%[INFO][13:20:43]: Decompressing the dataset downloaded.
[INFO][13:20:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/658.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
7.3%9.1%10.9%12.7%14.5%16.3%18.2%20.0%21.8%23.6%25.4%27.2%29.0%30.9%32.7%34.5%36.3%38.1%39.9%41.8%43.6%45.4%47.2%49.0%50.8%52.6%54.5%56.3%58.1%59.9%61.7%63.5%65.4%67.2%69.0%70.8%72.6%74.4%76.2%78.1%79.9%81.7%83.5%85.3%87.1%89.0%90.8%92.6%94.4%96.2%98.0%99.9%100.0%[INFO][13:20:43]: Decompressing the dataset downloaded.
[INFO][13:20:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/866.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:20:43]: [Client #658] Dataset size: 158
[INFO][13:20:43]: [Client #658] Sampler: all_inclusive
[INFO][13:20:43]: [Client #658] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:20:43]: [93m[1m[Client #658] Started training in communication round #4.[0m

[INFO][13:20:43]: [Client #866] Dataset size: 228
[INFO][13:20:43]: [Client #866] Sampler: all_inclusive
[INFO][13:20:43]: [Client #866] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:20:43]: [93m[1m[Client #866] Started training in communication round #4.[0m

[INFO][13:20:45]: [Client #658] Loading the dataset.
[INFO][13:20:45]: [Client #866] Loading the dataset.
[INFO][13:20:50]: [Client #866] Epoch: [1/5][0/23]	Loss: 3.223680
[INFO][13:20:50]: [Client #658] Epoch: [1/5][0/16]	Loss: 2.534828
[INFO][13:20:50]: [Client #866] Epoch: [1/5][10/23]	Loss: 3.189600
[INFO][13:20:51]: [Client #658] Epoch: [1/5][10/16]	Loss: 3.357304
[INFO][13:20:51]: [Client #866] Epoch: [1/5][20/23]	Loss: 3.486931
[INFO][13:20:51]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][13:20:51]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][13:20:51]: [Client #658] Woke up.
[INFO][13:20:51]: [Client #658] Epoch: [2/5][0/16]	Loss: 2.769999
[INFO][13:20:51]: [Client #658] Epoch: [2/5][10/16]	Loss: 2.072363
[INFO][13:20:51]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][13:20:51]: [Client #658] Woke up.
[INFO][13:20:51]: [Client #658] Epoch: [3/5][0/16]	Loss: 2.610077
[INFO][13:20:51]: [Client #658] Epoch: [3/5][10/16]	Loss: 4.045059
[INFO][13:20:51]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][13:20:51]: [Client #658] Woke up.
[INFO][13:20:51]: [Client #658] Epoch: [4/5][0/16]	Loss: 2.275398
[INFO][13:20:51]: [Client #658] Epoch: [4/5][10/16]	Loss: 3.890031
[INFO][13:20:51]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][13:20:51]: [Client #658] Woke up.
[INFO][13:20:51]: [Client #658] Epoch: [5/5][0/16]	Loss: 2.209479
[INFO][13:20:51]: [Client #658] Epoch: [5/5][10/16]	Loss: 2.860096
[INFO][13:20:51]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][13:20:51]: [Client #658] Woke up.
[INFO][13:20:51]: [Client #658] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615875.pth.
[INFO][13:20:52]: [Client #658] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615875.pth.
[INFO][13:20:52]: [Client #658] Model trained.
[INFO][13:20:52]: [Client #658] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:20:52]: [Server #615782] Received 0.26 MB of payload data from client #658 (simulated).
[INFO][13:20:54]: [Client #866] Woke up.
[INFO][13:20:54]: [Client #866] Epoch: [2/5][0/23]	Loss: 3.276646
[INFO][13:20:54]: [Client #866] Epoch: [2/5][10/23]	Loss: 2.552788
[INFO][13:20:54]: [Client #866] Epoch: [2/5][20/23]	Loss: 2.983604
[INFO][13:20:54]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][13:20:57]: [Client #866] Woke up.
[INFO][13:20:57]: [Client #866] Epoch: [3/5][0/23]	Loss: 2.107159
[INFO][13:20:57]: [Client #866] Epoch: [3/5][10/23]	Loss: 2.551706
[INFO][13:20:57]: [Client #866] Epoch: [3/5][20/23]	Loss: 4.023881
[INFO][13:20:57]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][13:21:00]: [Client #866] Woke up.
[INFO][13:21:00]: [Client #866] Epoch: [4/5][0/23]	Loss: 1.805043
[INFO][13:21:00]: [Client #866] Epoch: [4/5][10/23]	Loss: 2.330374
[INFO][13:21:00]: [Client #866] Epoch: [4/5][20/23]	Loss: 2.963519
[INFO][13:21:00]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][13:21:03]: [Client #866] Woke up.
[INFO][13:21:03]: [Client #866] Epoch: [5/5][0/23]	Loss: 2.494151
[INFO][13:21:03]: [Client #866] Epoch: [5/5][10/23]	Loss: 2.624414
[INFO][13:21:03]: [Client #866] Epoch: [5/5][20/23]	Loss: 1.578737
[INFO][13:21:03]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][13:21:06]: [Client #866] Woke up.
[INFO][13:21:06]: [Client #866] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_866_615874.pth.
[INFO][13:21:07]: [Client #866] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_866_615874.pth.
[INFO][13:21:07]: [Client #866] Model trained.
[INFO][13:21:07]: [Client #866] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:21:07]: [Server #615782] Received 0.26 MB of payload data from client #866 (simulated).
[INFO][13:21:07]: [Server #615782] Selecting client #582 for training.
[INFO][13:21:07]: [Server #615782] Sending the current model to client #582 (simulated).
[INFO][13:21:07]: [Server #615782] Sending 0.26 MB of payload data to client #582 (simulated).
[INFO][13:21:07]: [Server #615782] Selecting client #200 for training.
[INFO][13:21:07]: [Server #615782] Sending the current model to client #200 (simulated).
[INFO][13:21:07]: [Server #615782] Sending 0.26 MB of payload data to client #200 (simulated).
[INFO][13:21:07]: [Client #582] Selected by the server.
[INFO][13:21:07]: [Client #582] Loading its data source...
[INFO][13:21:07]: Data source: FEMNIST
[INFO][13:21:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:21:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/582.zip.
[INFO][13:21:07]: [Client #200] Selected by the server.
[INFO][13:21:07]: [Client #200] Loading its data source...
[INFO][13:21:07]: Data source: FEMNIST
[INFO][13:21:07]: [Client #200] Dataset size: 318
[INFO][13:21:07]: [Client #200] Sampler: all_inclusive
[INFO][13:21:07]: [Client #200] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:21:07]: [93m[1m[Client #200] Started training in communication round #4.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.6%45.1%47.6%50.1%52.6%55.1%57.6%60.1%62.6%65.1%67.6%70.2%72.7%75.2%77.7%80.2%82.7%85.2%87.7%90.2%92.7%95.2%97.7%100.0%[INFO][13:21:07]: Decompressing the dataset downloaded.
[INFO][13:21:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/582.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:21:07]: [Client #582] Dataset size: 144
[INFO][13:21:07]: [Client #582] Sampler: all_inclusive
[INFO][13:21:07]: [Client #582] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:21:07]: [93m[1m[Client #582] Started training in communication round #4.[0m

[INFO][13:21:09]: [Client #200] Loading the dataset.
[INFO][13:21:09]: [Client #582] Loading the dataset.
[INFO][13:21:15]: [Client #200] Epoch: [1/5][0/32]	Loss: 4.212879
[INFO][13:21:15]: [Client #582] Epoch: [1/5][0/15]	Loss: 2.924937
[INFO][13:21:15]: [Client #200] Epoch: [1/5][10/32]	Loss: 3.348335
[INFO][13:21:15]: [Client #582] Epoch: [1/5][10/15]	Loss: 2.528387
[INFO][13:21:15]: [Client #582] Going to sleep for 0.24 seconds.
[INFO][13:21:15]: [Client #200] Epoch: [1/5][20/32]	Loss: 3.830753
[INFO][13:21:15]: [Client #200] Epoch: [1/5][30/32]	Loss: 2.661412
[INFO][13:21:15]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:21:15]: [Client #582] Woke up.
[INFO][13:21:15]: [Client #582] Epoch: [2/5][0/15]	Loss: 2.827567
[INFO][13:21:15]: [Client #582] Epoch: [2/5][10/15]	Loss: 2.995196
[INFO][13:21:15]: [Client #582] Going to sleep for 0.24 seconds.
[INFO][13:21:15]: [Client #582] Woke up.
[INFO][13:21:16]: [Client #582] Epoch: [3/5][0/15]	Loss: 2.322496
[INFO][13:21:16]: [Client #582] Epoch: [3/5][10/15]	Loss: 3.044006
[INFO][13:21:16]: [Client #582] Going to sleep for 0.24 seconds.
[INFO][13:21:16]: [Client #582] Woke up.
[INFO][13:21:16]: [Client #582] Epoch: [4/5][0/15]	Loss: 2.604226
[INFO][13:21:16]: [Client #582] Epoch: [4/5][10/15]	Loss: 2.548500
[INFO][13:21:16]: [Client #582] Going to sleep for 0.24 seconds.
[INFO][13:21:16]: [Client #582] Woke up.
[INFO][13:21:16]: [Client #582] Epoch: [5/5][0/15]	Loss: 2.805686
[INFO][13:21:16]: [Client #582] Epoch: [5/5][10/15]	Loss: 1.612515
[INFO][13:21:16]: [Client #582] Going to sleep for 0.24 seconds.
[INFO][13:21:17]: [Client #582] Woke up.
[INFO][13:21:17]: [Client #582] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_582_615874.pth.
[INFO][13:21:17]: [Client #582] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_582_615874.pth.
[INFO][13:21:17]: [Client #582] Model trained.
[INFO][13:21:17]: [Client #582] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:21:17]: [Server #615782] Received 0.26 MB of payload data from client #582 (simulated).
[INFO][13:21:34]: [Client #200] Woke up.
[INFO][13:21:34]: [Client #200] Epoch: [2/5][0/32]	Loss: 2.811932
[INFO][13:21:34]: [Client #200] Epoch: [2/5][10/32]	Loss: 3.550985
[INFO][13:21:34]: [Client #200] Epoch: [2/5][20/32]	Loss: 2.485572
[INFO][13:21:34]: [Client #200] Epoch: [2/5][30/32]	Loss: 1.852573
[INFO][13:21:34]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:21:53]: [Client #200] Woke up.
[INFO][13:21:53]: [Client #200] Epoch: [3/5][0/32]	Loss: 2.295265
[INFO][13:21:53]: [Client #200] Epoch: [3/5][10/32]	Loss: 2.889266
[INFO][13:21:53]: [Client #200] Epoch: [3/5][20/32]	Loss: 3.047364
[INFO][13:21:53]: [Client #200] Epoch: [3/5][30/32]	Loss: 2.036015
[INFO][13:21:53]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:22:12]: [Client #200] Woke up.
[INFO][13:22:12]: [Client #200] Epoch: [4/5][0/32]	Loss: 2.209436
[INFO][13:22:12]: [Client #200] Epoch: [4/5][10/32]	Loss: 3.734081
[INFO][13:22:12]: [Client #200] Epoch: [4/5][20/32]	Loss: 1.962378
[INFO][13:22:12]: [Client #200] Epoch: [4/5][30/32]	Loss: 0.620073
[INFO][13:22:12]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:22:31]: [Client #200] Woke up.
[INFO][13:22:31]: [Client #200] Epoch: [5/5][0/32]	Loss: 1.552521
[INFO][13:22:31]: [Client #200] Epoch: [5/5][10/32]	Loss: 2.941437
[INFO][13:22:31]: [Client #200] Epoch: [5/5][20/32]	Loss: 2.052644
[INFO][13:22:31]: [Client #200] Epoch: [5/5][30/32]	Loss: 3.206408
[INFO][13:22:31]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:22:50]: [Client #200] Woke up.
[INFO][13:22:50]: [Client #200] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][13:22:50]: [Client #200] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][13:22:50]: [Client #200] Model trained.
[INFO][13:22:50]: [Client #200] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:22:50]: [Server #615782] Received 0.26 MB of payload data from client #200 (simulated).
[INFO][13:22:50]: [Server #615782] Selecting client #529 for training.
[INFO][13:22:50]: [Server #615782] Sending the current model to client #529 (simulated).
[INFO][13:22:50]: [Server #615782] Sending 0.26 MB of payload data to client #529 (simulated).
[INFO][13:22:50]: [Server #615782] Selecting client #895 for training.
[INFO][13:22:50]: [Server #615782] Sending the current model to client #895 (simulated).
[INFO][13:22:50]: [Server #615782] Sending 0.26 MB of payload data to client #895 (simulated).
[INFO][13:22:50]: [Client #529] Selected by the server.
[INFO][13:22:50]: [Client #529] Loading its data source...
[INFO][13:22:50]: Data source: FEMNIST
[INFO][13:22:50]: [Client #895] Selected by the server.
[INFO][13:22:50]: [Client #895] Loading its data source...
[INFO][13:22:50]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:22:50]: Data source: FEMNIST
[INFO][13:22:50]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/529.zip.
[INFO][13:22:51]: [Client #895] Dataset size: 135
[INFO][13:22:51]: [Client #895] Sampler: all_inclusive
[INFO][13:22:51]: [Client #895] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:22:51]: [93m[1m[Client #895] Started training in communication round #4.[0m
3.6%7.1%10.7%14.3%17.9%21.4%25.0%28.6%32.1%35.7%39.3%42.9%46.4%50.0%53.6%57.1%60.7%64.3%67.9%71.4%75.0%78.6%82.1%85.7%89.3%92.9%96.4%100.0%100.0%[INFO][13:22:51]: Decompressing the dataset downloaded.
[INFO][13:22:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/529.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:22:51]: [Client #529] Dataset size: 162
[INFO][13:22:51]: [Client #529] Sampler: all_inclusive
[INFO][13:22:51]: [Client #529] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:22:51]: [93m[1m[Client #529] Started training in communication round #4.[0m

[INFO][13:22:53]: [Client #895] Loading the dataset.
[INFO][13:22:53]: [Client #529] Loading the dataset.
[INFO][13:22:58]: [Client #895] Epoch: [1/5][0/14]	Loss: 2.933108
[INFO][13:22:58]: [Client #529] Epoch: [1/5][0/17]	Loss: 2.541524
[INFO][13:22:58]: [Client #895] Epoch: [1/5][10/14]	Loss: 2.762854
[INFO][13:22:59]: [Client #895] Going to sleep for 47.74 seconds.
[INFO][13:22:59]: [Client #529] Epoch: [1/5][10/17]	Loss: 2.384322
[INFO][13:22:59]: [Client #529] Going to sleep for 0.82 seconds.
[INFO][13:22:59]: [Client #529] Woke up.
[INFO][13:22:59]: [Client #529] Epoch: [2/5][0/17]	Loss: 2.659185
[INFO][13:23:00]: [Client #529] Epoch: [2/5][10/17]	Loss: 3.804673
[INFO][13:23:00]: [Client #529] Going to sleep for 0.82 seconds.
[INFO][13:23:00]: [Client #529] Woke up.
[INFO][13:23:00]: [Client #529] Epoch: [3/5][0/17]	Loss: 2.813093
[INFO][13:23:00]: [Client #529] Epoch: [3/5][10/17]	Loss: 2.402213
[INFO][13:23:01]: [Client #529] Going to sleep for 0.82 seconds.
[INFO][13:23:01]: [Client #529] Woke up.
[INFO][13:23:01]: [Client #529] Epoch: [4/5][0/17]	Loss: 3.343234
[INFO][13:23:01]: [Client #529] Epoch: [4/5][10/17]	Loss: 2.329059
[INFO][13:23:02]: [Client #529] Going to sleep for 0.82 seconds.
[INFO][13:23:02]: [Client #529] Woke up.
[INFO][13:23:02]: [Client #529] Epoch: [5/5][0/17]	Loss: 3.145505
[INFO][13:23:02]: [Client #529] Epoch: [5/5][10/17]	Loss: 2.365715
[INFO][13:23:02]: [Client #529] Going to sleep for 0.82 seconds.
[INFO][13:23:03]: [Client #529] Woke up.
[INFO][13:23:03]: [Client #529] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_529_615874.pth.
[INFO][13:23:04]: [Client #529] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_529_615874.pth.
[INFO][13:23:04]: [Client #529] Model trained.
[INFO][13:23:04]: [Client #529] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:23:04]: [Server #615782] Received 0.26 MB of payload data from client #529 (simulated).
[INFO][13:23:46]: [Client #895] Woke up.
[INFO][13:23:46]: [Client #895] Epoch: [2/5][0/14]	Loss: 1.771840
[INFO][13:23:47]: [Client #895] Epoch: [2/5][10/14]	Loss: 2.113038
[INFO][13:23:47]: [Client #895] Going to sleep for 47.74 seconds.
[INFO][13:24:34]: [Client #895] Woke up.
[INFO][13:24:34]: [Client #895] Epoch: [3/5][0/14]	Loss: 2.288120
[INFO][13:24:35]: [Client #895] Epoch: [3/5][10/14]	Loss: 1.206492
[INFO][13:24:35]: [Client #895] Going to sleep for 47.74 seconds.
[INFO][13:25:22]: [Client #895] Woke up.
[INFO][13:25:22]: [Client #895] Epoch: [4/5][0/14]	Loss: 2.420729
[INFO][13:25:23]: [Client #895] Epoch: [4/5][10/14]	Loss: 2.017199
[INFO][13:25:23]: [Client #895] Going to sleep for 47.74 seconds.
[INFO][13:26:10]: [Client #895] Woke up.
[INFO][13:26:10]: [Client #895] Epoch: [5/5][0/14]	Loss: 1.124444
[INFO][13:26:11]: [Client #895] Epoch: [5/5][10/14]	Loss: 2.738282
[INFO][13:26:11]: [Client #895] Going to sleep for 47.74 seconds.
[INFO][13:26:58]: [Client #895] Woke up.
[INFO][13:26:58]: [Client #895] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_895_615875.pth.
[INFO][13:26:59]: [Client #895] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_895_615875.pth.
[INFO][13:26:59]: [Client #895] Model trained.
[INFO][13:26:59]: [Client #895] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:26:59]: [Server #615782] Received 0.26 MB of payload data from client #895 (simulated).
[INFO][13:26:59]: [Server #615782] Selecting client #305 for training.
[INFO][13:26:59]: [Server #615782] Sending the current model to client #305 (simulated).
[INFO][13:26:59]: [Server #615782] Sending 0.26 MB of payload data to client #305 (simulated).
[INFO][13:26:59]: [Server #615782] Selecting client #872 for training.
[INFO][13:26:59]: [Server #615782] Sending the current model to client #872 (simulated).
[INFO][13:26:59]: [Server #615782] Sending 0.26 MB of payload data to client #872 (simulated).
[INFO][13:26:59]: [Client #872] Selected by the server.
[INFO][13:26:59]: [Client #305] Selected by the server.
[INFO][13:26:59]: [Client #872] Loading its data source...
[INFO][13:26:59]: [Client #305] Loading its data source...
[INFO][13:26:59]: Data source: FEMNIST
[INFO][13:26:59]: Data source: FEMNIST
[INFO][13:26:59]: [Client #872] Dataset size: 158
[INFO][13:26:59]: [Client #872] Sampler: all_inclusive
[INFO][13:26:59]: [Client #872] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:26:59]: [93m[1m[Client #872] Started training in communication round #4.[0m
[INFO][13:26:59]: [Client #305] Dataset size: 157
[INFO][13:26:59]: [Client #305] Sampler: all_inclusive
[INFO][13:26:59]: [Client #305] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:26:59]: [93m[1m[Client #305] Started training in communication round #4.[0m
[INFO][13:27:01]: [Client #872] Loading the dataset.
[INFO][13:27:01]: [Client #305] Loading the dataset.
[INFO][13:27:07]: [Client #305] Epoch: [1/5][0/16]	Loss: 2.905084
[INFO][13:27:07]: [Client #872] Epoch: [1/5][0/16]	Loss: 2.986788
[INFO][13:27:07]: [Client #305] Epoch: [1/5][10/16]	Loss: 3.252036
[INFO][13:27:07]: [Client #872] Epoch: [1/5][10/16]	Loss: 1.488177
[INFO][13:27:07]: [Client #305] Going to sleep for 0.19 seconds.
[INFO][13:27:07]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:27:07]: [Client #305] Woke up.
[INFO][13:27:07]: [Client #305] Epoch: [2/5][0/16]	Loss: 2.897712
[INFO][13:27:07]: [Client #872] Woke up.
[INFO][13:27:07]: [Client #872] Epoch: [2/5][0/16]	Loss: 2.403481
[INFO][13:27:07]: [Client #305] Epoch: [2/5][10/16]	Loss: 3.155417
[INFO][13:27:08]: [Client #305] Going to sleep for 0.19 seconds.
[INFO][13:27:08]: [Client #872] Epoch: [2/5][10/16]	Loss: 2.390770
[INFO][13:27:08]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:27:08]: [Client #305] Woke up.
[INFO][13:27:08]: [Client #305] Epoch: [3/5][0/16]	Loss: 2.015567
[INFO][13:27:08]: [Client #305] Epoch: [3/5][10/16]	Loss: 1.982414
[INFO][13:27:08]: [Client #872] Woke up.
[INFO][13:27:08]: [Client #872] Epoch: [3/5][0/16]	Loss: 1.845984
[INFO][13:27:08]: [Client #305] Going to sleep for 0.19 seconds.
[INFO][13:27:08]: [Client #872] Epoch: [3/5][10/16]	Loss: 2.001490
[INFO][13:27:08]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:27:08]: [Client #305] Woke up.
[INFO][13:27:08]: [Client #305] Epoch: [4/5][0/16]	Loss: 2.484514
[INFO][13:27:08]: [Client #305] Epoch: [4/5][10/16]	Loss: 2.685319
[INFO][13:27:08]: [Client #305] Going to sleep for 0.19 seconds.
[INFO][13:27:08]: [Client #872] Woke up.
[INFO][13:27:08]: [Client #872] Epoch: [4/5][0/16]	Loss: 1.919671
[INFO][13:27:08]: [Client #872] Epoch: [4/5][10/16]	Loss: 1.638655
[INFO][13:27:08]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:27:08]: [Client #305] Woke up.
[INFO][13:27:08]: [Client #305] Epoch: [5/5][0/16]	Loss: 2.693958
[INFO][13:27:09]: [Client #305] Epoch: [5/5][10/16]	Loss: 2.256531
[INFO][13:27:09]: [Client #305] Going to sleep for 0.19 seconds.
[INFO][13:27:09]: [Client #872] Woke up.
[INFO][13:27:09]: [Client #872] Epoch: [5/5][0/16]	Loss: 2.842317
[INFO][13:27:09]: [Client #872] Epoch: [5/5][10/16]	Loss: 3.053521
[INFO][13:27:09]: [Client #305] Woke up.
[INFO][13:27:09]: [Client #305] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_305_615874.pth.
[INFO][13:27:09]: [Client #872] Going to sleep for 0.25 seconds.
[INFO][13:27:09]: [Client #872] Woke up.
[INFO][13:27:09]: [Client #872] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_872_615875.pth.
[INFO][13:27:10]: [Client #305] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_305_615874.pth.
[INFO][13:27:10]: [Client #305] Model trained.
[INFO][13:27:10]: [Client #305] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:10]: [Server #615782] Received 0.26 MB of payload data from client #305 (simulated).
[INFO][13:27:10]: [Client #872] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_872_615875.pth.
[INFO][13:27:10]: [Client #872] Model trained.
[INFO][13:27:10]: [Client #872] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:10]: [Server #615782] Received 0.26 MB of payload data from client #872 (simulated).
[INFO][13:27:10]: [Server #615782] Selecting client #909 for training.
[INFO][13:27:10]: [Server #615782] Sending the current model to client #909 (simulated).
[INFO][13:27:10]: [Server #615782] Sending 0.26 MB of payload data to client #909 (simulated).
[INFO][13:27:10]: [Server #615782] Selecting client #684 for training.
[INFO][13:27:10]: [Server #615782] Sending the current model to client #684 (simulated).
[INFO][13:27:10]: [Server #615782] Sending 0.26 MB of payload data to client #684 (simulated).
[INFO][13:27:10]: [Client #909] Selected by the server.
[INFO][13:27:10]: [Client #909] Loading its data source...
[INFO][13:27:10]: [Client #684] Selected by the server.
[INFO][13:27:10]: Data source: FEMNIST
[INFO][13:27:10]: [Client #684] Loading its data source...
[INFO][13:27:10]: Data source: FEMNIST
[INFO][13:27:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:27:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/909.zip.
[INFO][13:27:10]: [Client #684] Dataset size: 135
[INFO][13:27:10]: [Client #684] Sampler: all_inclusive
[INFO][13:27:10]: [Client #684] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:10]: [93m[1m[Client #684] Started training in communication round #4.[0m
3.1%6.1%9.2%12.2%15.3%18.3%21.4%24.4%27.5%30.5%33.6%36.6%39.7%42.7%45.8%48.8%51.9%54.9%58.0%61.0%64.1%67.1%70.2%73.3%76.3%79.4%82.4%85.5%88.5%91.6%94.6%97.7%100.0%[INFO][13:27:10]: Decompressing the dataset downloaded.
[INFO][13:27:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/909.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:27:10]: [Client #909] Dataset size: 150
[INFO][13:27:10]: [Client #909] Sampler: all_inclusive
[INFO][13:27:10]: [Client #909] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:10]: [93m[1m[Client #909] Started training in communication round #4.[0m

[INFO][13:27:12]: [Client #684] Loading the dataset.
[INFO][13:27:12]: [Client #909] Loading the dataset.
[INFO][13:27:18]: [Client #684] Epoch: [1/5][0/14]	Loss: 2.227316
[INFO][13:27:18]: [Client #684] Epoch: [1/5][10/14]	Loss: 1.432157
[INFO][13:27:18]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][13:27:18]: [Client #909] Epoch: [1/5][0/15]	Loss: 3.055328
[INFO][13:27:18]: [Client #909] Epoch: [1/5][10/15]	Loss: 2.218802
[INFO][13:27:18]: [Client #909] Going to sleep for 1.07 seconds.
[INFO][13:27:19]: [Client #909] Woke up.
[INFO][13:27:19]: [Client #909] Epoch: [2/5][0/15]	Loss: 2.204124
[INFO][13:27:19]: [Client #909] Epoch: [2/5][10/15]	Loss: 3.130349
[INFO][13:27:19]: [Client #909] Going to sleep for 1.07 seconds.
[INFO][13:27:20]: [Client #909] Woke up.
[INFO][13:27:20]: [Client #909] Epoch: [3/5][0/15]	Loss: 2.412403
[INFO][13:27:21]: [Client #909] Epoch: [3/5][10/15]	Loss: 2.158195
[INFO][13:27:21]: [Client #909] Going to sleep for 1.07 seconds.
[INFO][13:27:22]: [Client #684] Woke up.
[INFO][13:27:22]: [Client #684] Epoch: [2/5][0/14]	Loss: 2.334093
[INFO][13:27:22]: [Client #909] Woke up.
[INFO][13:27:22]: [Client #684] Epoch: [2/5][10/14]	Loss: 2.602514
[INFO][13:27:22]: [Client #909] Epoch: [4/5][0/15]	Loss: 1.902686
[INFO][13:27:22]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][13:27:22]: [Client #909] Epoch: [4/5][10/15]	Loss: 1.579078
[INFO][13:27:22]: [Client #909] Going to sleep for 1.07 seconds.
[INFO][13:27:23]: [Client #909] Woke up.
[INFO][13:27:23]: [Client #909] Epoch: [5/5][0/15]	Loss: 2.005863
[INFO][13:27:23]: [Client #909] Epoch: [5/5][10/15]	Loss: 1.366058
[INFO][13:27:23]: [Client #909] Going to sleep for 1.07 seconds.
[INFO][13:27:24]: [Client #909] Woke up.
[INFO][13:27:24]: [Client #909] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_909_615874.pth.
[INFO][13:27:25]: [Client #909] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_909_615874.pth.
[INFO][13:27:25]: [Client #909] Model trained.
[INFO][13:27:25]: [Client #909] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:25]: [Server #615782] Received 0.26 MB of payload data from client #909 (simulated).
[INFO][13:27:25]: [Client #684] Woke up.
[INFO][13:27:25]: [Client #684] Epoch: [3/5][0/14]	Loss: 2.898495
[INFO][13:27:25]: [Client #684] Epoch: [3/5][10/14]	Loss: 2.405074
[INFO][13:27:25]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][13:27:29]: [Client #684] Woke up.
[INFO][13:27:29]: [Client #684] Epoch: [4/5][0/14]	Loss: 2.028473
[INFO][13:27:29]: [Client #684] Epoch: [4/5][10/14]	Loss: 2.584305
[INFO][13:27:29]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][13:27:33]: [Client #684] Woke up.
[INFO][13:27:33]: [Client #684] Epoch: [5/5][0/14]	Loss: 1.821681
[INFO][13:27:33]: [Client #684] Epoch: [5/5][10/14]	Loss: 2.268875
[INFO][13:27:33]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][13:27:36]: [Client #684] Woke up.
[INFO][13:27:36]: [Client #684] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615875.pth.
[INFO][13:27:37]: [Client #684] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615875.pth.
[INFO][13:27:37]: [Client #684] Model trained.
[INFO][13:27:37]: [Client #684] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:37]: [Server #615782] Received 0.26 MB of payload data from client #684 (simulated).
[INFO][13:27:37]: [Server #615782] Selecting client #900 for training.
[INFO][13:27:37]: [Server #615782] Sending the current model to client #900 (simulated).
[INFO][13:27:37]: [Server #615782] Sending 0.26 MB of payload data to client #900 (simulated).
[INFO][13:27:37]: [Server #615782] Selecting client #75 for training.
[INFO][13:27:37]: [Server #615782] Sending the current model to client #75 (simulated).
[INFO][13:27:37]: [Server #615782] Sending 0.26 MB of payload data to client #75 (simulated).
[INFO][13:27:37]: [Client #900] Selected by the server.
[INFO][13:27:37]: [Client #900] Loading its data source...
[INFO][13:27:37]: [Client #75] Selected by the server.
[INFO][13:27:37]: Data source: FEMNIST
[INFO][13:27:37]: [Client #75] Loading its data source...
[INFO][13:27:37]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:27:37]: Data source: FEMNIST
[INFO][13:27:37]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/900.zip.
[INFO][13:27:37]: [Client #75] Dataset size: 153
[INFO][13:27:37]: [Client #75] Sampler: all_inclusive
[INFO][13:27:37]: [Client #75] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:37]: [93m[1m[Client #75] Started training in communication round #4.[0m
1.3%2.7%4.0%5.3%6.7%8.0%9.3%10.7%12.0%13.3%14.7%16.0%17.3%18.7%20.0%21.3%22.7%24.0%25.3%26.7%28.0%29.3%30.7%32.0%33.3%34.7%36.0%37.3%38.7%40.0%41.3%42.7%44.0%45.3%46.7%48.0%49.3%50.7%52.0%53.3%54.7%56.0%57.3%58.7%60.0%61.3%62.7%64.0%65.3%66.7%68.0%69.3%70.7%72.0%73.3%74.7%76.0%77.3%78.7%80.0%81.3%82.7%84.0%85.3%86.7%88.0%89.3%90.7%92.0%93.3%94.7%96.0%97.3%98.7%100.0%[INFO][13:27:37]: Decompressing the dataset downloaded.
[INFO][13:27:37]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/900.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:27:37]: [Client #900] Dataset size: 308
[INFO][13:27:37]: [Client #900] Sampler: all_inclusive
[INFO][13:27:37]: [Client #900] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:37]: [93m[1m[Client #900] Started training in communication round #4.[0m

[INFO][13:27:39]: [Client #75] Loading the dataset.
[INFO][13:27:39]: [Client #900] Loading the dataset.
[INFO][13:27:45]: [Client #75] Epoch: [1/5][0/16]	Loss: 2.669067
[INFO][13:27:45]: [Client #900] Epoch: [1/5][0/31]	Loss: 3.279645
[INFO][13:27:45]: [Client #75] Epoch: [1/5][10/16]	Loss: 2.890766
[INFO][13:27:45]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][13:27:45]: [Client #900] Epoch: [1/5][10/31]	Loss: 3.510041
[INFO][13:27:45]: [Client #900] Epoch: [1/5][20/31]	Loss: 2.868414
[INFO][13:27:45]: [Client #900] Epoch: [1/5][30/31]	Loss: 2.548977
[INFO][13:27:45]: [Client #900] Going to sleep for 0.55 seconds.
[INFO][13:27:45]: [Client #75] Woke up.
[INFO][13:27:45]: [Client #75] Epoch: [2/5][0/16]	Loss: 2.902450
[INFO][13:27:45]: [Client #900] Woke up.
[INFO][13:27:45]: [Client #75] Epoch: [2/5][10/16]	Loss: 2.910372
[INFO][13:27:45]: [Client #900] Epoch: [2/5][0/31]	Loss: 3.495362
[INFO][13:27:45]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][13:27:46]: [Client #900] Epoch: [2/5][10/31]	Loss: 2.813519
[INFO][13:27:46]: [Client #900] Epoch: [2/5][20/31]	Loss: 3.374925
[INFO][13:27:46]: [Client #900] Epoch: [2/5][30/31]	Loss: 2.972801
[INFO][13:27:46]: [Client #900] Going to sleep for 0.55 seconds.
[INFO][13:27:46]: [Client #75] Woke up.
[INFO][13:27:46]: [Client #75] Epoch: [3/5][0/16]	Loss: 3.377172
[INFO][13:27:46]: [Client #75] Epoch: [3/5][10/16]	Loss: 2.367931
[INFO][13:27:46]: [Client #900] Woke up.
[INFO][13:27:46]: [Client #900] Epoch: [3/5][0/31]	Loss: 3.323203
[INFO][13:27:46]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][13:27:46]: [Client #900] Epoch: [3/5][10/31]	Loss: 3.056858
[INFO][13:27:46]: [Client #900] Epoch: [3/5][20/31]	Loss: 2.452887
[INFO][13:27:47]: [Client #900] Epoch: [3/5][30/31]	Loss: 2.186257
[INFO][13:27:47]: [Client #900] Going to sleep for 0.55 seconds.
[INFO][13:27:47]: [Client #75] Woke up.
[INFO][13:27:47]: [Client #75] Epoch: [4/5][0/16]	Loss: 2.464399
[INFO][13:27:47]: [Client #75] Epoch: [4/5][10/16]	Loss: 2.455164
[INFO][13:27:47]: [Client #900] Woke up.
[INFO][13:27:47]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][13:27:47]: [Client #900] Epoch: [4/5][0/31]	Loss: 3.039930
[INFO][13:27:47]: [Client #900] Epoch: [4/5][10/31]	Loss: 2.431299
[INFO][13:27:47]: [Client #900] Epoch: [4/5][20/31]	Loss: 2.509938
[INFO][13:27:47]: [Client #900] Epoch: [4/5][30/31]	Loss: 1.836156
[INFO][13:27:47]: [Client #900] Going to sleep for 0.55 seconds.
[INFO][13:27:48]: [Client #75] Woke up.
[INFO][13:27:48]: [Client #75] Epoch: [5/5][0/16]	Loss: 2.942273
[INFO][13:27:48]: [Client #75] Epoch: [5/5][10/16]	Loss: 2.437481
[INFO][13:27:48]: [Client #900] Woke up.
[INFO][13:27:48]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][13:27:48]: [Client #900] Epoch: [5/5][0/31]	Loss: 3.009090
[INFO][13:27:48]: [Client #900] Epoch: [5/5][10/31]	Loss: 1.621886
[INFO][13:27:48]: [Client #900] Epoch: [5/5][20/31]	Loss: 1.936479
[INFO][13:27:48]: [Client #900] Epoch: [5/5][30/31]	Loss: 2.508508
[INFO][13:27:48]: [Client #900] Going to sleep for 0.55 seconds.
[INFO][13:27:49]: [Client #75] Woke up.
[INFO][13:27:49]: [Client #75] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_615875.pth.
[INFO][13:27:49]: [Client #900] Woke up.
[INFO][13:27:49]: [Client #900] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_900_615874.pth.
[INFO][13:27:49]: [Client #75] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_615875.pth.
[INFO][13:27:49]: [Client #75] Model trained.
[INFO][13:27:49]: [Client #75] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:49]: [Server #615782] Received 0.26 MB of payload data from client #75 (simulated).
[INFO][13:27:50]: [Client #900] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_900_615874.pth.
[INFO][13:27:50]: [Client #900] Model trained.
[INFO][13:27:50]: [Client #900] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:27:50]: [Server #615782] Received 0.26 MB of payload data from client #900 (simulated).
[INFO][13:27:50]: [Server #615782] Selecting client #879 for training.
[INFO][13:27:50]: [Server #615782] Sending the current model to client #879 (simulated).
[INFO][13:27:50]: [Server #615782] Sending 0.26 MB of payload data to client #879 (simulated).
[INFO][13:27:50]: [Server #615782] Selecting client #190 for training.
[INFO][13:27:50]: [Server #615782] Sending the current model to client #190 (simulated).
[INFO][13:27:50]: [Server #615782] Sending 0.26 MB of payload data to client #190 (simulated).
[INFO][13:27:50]: [Client #879] Selected by the server.
[INFO][13:27:50]: [Client #879] Loading its data source...
[INFO][13:27:50]: Data source: FEMNIST
[INFO][13:27:50]: [Client #190] Selected by the server.
[INFO][13:27:50]: [Client #190] Loading its data source...
[INFO][13:27:50]: Data source: FEMNIST
[INFO][13:27:50]: [Client #190] Dataset size: 160
[INFO][13:27:50]: [Client #190] Sampler: all_inclusive
[INFO][13:27:50]: [Client #879] Dataset size: 157
[INFO][13:27:50]: [Client #879] Sampler: all_inclusive
[INFO][13:27:50]: [Client #190] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:50]: [Client #879] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:27:50]: [93m[1m[Client #190] Started training in communication round #4.[0m
[INFO][13:27:50]: [93m[1m[Client #879] Started training in communication round #4.[0m
[INFO][13:27:52]: [Client #879] Loading the dataset.
[INFO][13:27:52]: [Client #190] Loading the dataset.
[INFO][13:27:57]: [Client #190] Epoch: [1/5][0/16]	Loss: 2.938331
[INFO][13:27:57]: [Client #879] Epoch: [1/5][0/16]	Loss: 3.216732
[INFO][13:27:57]: [Client #190] Epoch: [1/5][10/16]	Loss: 2.607197
[INFO][13:27:57]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][13:27:57]: [Client #879] Epoch: [1/5][10/16]	Loss: 2.085550
[INFO][13:27:57]: [Client #879] Going to sleep for 2.37 seconds.
[INFO][13:28:00]: [Client #879] Woke up.
[INFO][13:28:00]: [Client #879] Epoch: [2/5][0/16]	Loss: 3.151648
[INFO][13:28:00]: [Client #879] Epoch: [2/5][10/16]	Loss: 3.332493
[INFO][13:28:00]: [Client #879] Going to sleep for 2.37 seconds.
[INFO][13:28:02]: [Client #879] Woke up.
[INFO][13:28:02]: [Client #879] Epoch: [3/5][0/16]	Loss: 2.389953
[INFO][13:28:02]: [Client #879] Epoch: [3/5][10/16]	Loss: 1.966263
[INFO][13:28:03]: [Client #879] Going to sleep for 2.37 seconds.
[INFO][13:28:05]: [Client #879] Woke up.
[INFO][13:28:05]: [Client #879] Epoch: [4/5][0/16]	Loss: 1.241511
[INFO][13:28:05]: [Client #879] Epoch: [4/5][10/16]	Loss: 3.160648
[INFO][13:28:05]: [Client #879] Going to sleep for 2.37 seconds.
[INFO][13:28:07]: [Client #879] Woke up.
[INFO][13:28:07]: [Client #879] Epoch: [5/5][0/16]	Loss: 1.211244
[INFO][13:28:08]: [Client #879] Epoch: [5/5][10/16]	Loss: 2.500216
[INFO][13:28:08]: [Client #879] Going to sleep for 2.37 seconds.
[INFO][13:28:10]: [Client #190] Woke up.
[INFO][13:28:10]: [Client #190] Epoch: [2/5][0/16]	Loss: 2.512456
[INFO][13:28:10]: [Client #190] Epoch: [2/5][10/16]	Loss: 3.783653
[INFO][13:28:10]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][13:28:10]: [Client #879] Woke up.
[INFO][13:28:10]: [Client #879] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_879_615874.pth.
[INFO][13:28:11]: [Client #879] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_879_615874.pth.
[INFO][13:28:11]: [Client #879] Model trained.
[INFO][13:28:11]: [Client #879] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:28:11]: [Server #615782] Received 0.26 MB of payload data from client #879 (simulated).
[INFO][13:28:22]: [Client #190] Woke up.
[INFO][13:28:22]: [Client #190] Epoch: [3/5][0/16]	Loss: 2.302960
[INFO][13:28:22]: [Client #190] Epoch: [3/5][10/16]	Loss: 2.684863
[INFO][13:28:22]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][13:28:35]: [Client #190] Woke up.
[INFO][13:28:35]: [Client #190] Epoch: [4/5][0/16]	Loss: 2.455161
[INFO][13:28:35]: [Client #190] Epoch: [4/5][10/16]	Loss: 1.771408
[INFO][13:28:35]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][13:28:47]: [Client #190] Woke up.
[INFO][13:28:47]: [Client #190] Epoch: [5/5][0/16]	Loss: 2.227173
[INFO][13:28:47]: [Client #190] Epoch: [5/5][10/16]	Loss: 3.186573
[INFO][13:28:47]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][13:29:00]: [Client #190] Woke up.
[INFO][13:29:00]: [Client #190] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_615875.pth.
[INFO][13:29:00]: [Client #190] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_615875.pth.
[INFO][13:29:00]: [Client #190] Model trained.
[INFO][13:29:00]: [Client #190] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:29:00]: [Server #615782] Received 0.26 MB of payload data from client #190 (simulated).
[INFO][13:29:00]: [Server #615782] Selecting client #851 for training.
[INFO][13:29:00]: [Server #615782] Sending the current model to client #851 (simulated).
[INFO][13:29:00]: [Server #615782] Sending 0.26 MB of payload data to client #851 (simulated).
[INFO][13:29:00]: [Server #615782] Selecting client #668 for training.
[INFO][13:29:00]: [Server #615782] Sending the current model to client #668 (simulated).
[INFO][13:29:00]: [Server #615782] Sending 0.26 MB of payload data to client #668 (simulated).
[INFO][13:29:00]: [Client #851] Selected by the server.
[INFO][13:29:00]: [Client #668] Selected by the server.
[INFO][13:29:00]: [Client #851] Loading its data source...
[INFO][13:29:00]: [Client #668] Loading its data source...
[INFO][13:29:00]: Data source: FEMNIST
[INFO][13:29:00]: Data source: FEMNIST
[INFO][13:29:00]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:29:00]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/851.zip.
[INFO][13:29:00]: [Client #668] Dataset size: 142
[INFO][13:29:00]: [Client #668] Sampler: all_inclusive
[INFO][13:29:00]: [Client #668] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:29:00]: [93m[1m[Client #668] Started training in communication round #4.[0m
4.0%7.9%11.9%15.8%19.8%23.7%27.7%31.6%35.6%39.5%43.5%47.4%51.4%55.3%59.3%63.3%67.2%71.2%75.1%79.1%83.0%87.0%90.9%94.9%98.8%100.0%[INFO][13:29:00]: Decompressing the dataset downloaded.
[INFO][13:29:00]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/851.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:29:00]: [Client #851] Dataset size: 97
[INFO][13:29:00]: [Client #851] Sampler: all_inclusive
[INFO][13:29:00]: [Client #851] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:29:00]: [93m[1m[Client #851] Started training in communication round #4.[0m

[INFO][13:29:02]: [Client #668] Loading the dataset.
[INFO][13:29:02]: [Client #851] Loading the dataset.
[INFO][13:29:08]: [Client #851] Epoch: [1/5][0/10]	Loss: 2.207556
[INFO][13:29:08]: [Client #668] Epoch: [1/5][0/15]	Loss: 2.449234
[INFO][13:29:08]: [Client #851] Going to sleep for 6.13 seconds.
[INFO][13:29:08]: [Client #668] Epoch: [1/5][10/15]	Loss: 3.229779
[INFO][13:29:08]: [Client #668] Going to sleep for 0.21 seconds.
[INFO][13:29:08]: [Client #668] Woke up.
[INFO][13:29:08]: [Client #668] Epoch: [2/5][0/15]	Loss: 3.018185
[INFO][13:29:08]: [Client #668] Epoch: [2/5][10/15]	Loss: 3.235994
[INFO][13:29:08]: [Client #668] Going to sleep for 0.21 seconds.
[INFO][13:29:08]: [Client #668] Woke up.
[INFO][13:29:08]: [Client #668] Epoch: [3/5][0/15]	Loss: 2.895555
[INFO][13:29:09]: [Client #668] Epoch: [3/5][10/15]	Loss: 2.471459
[INFO][13:29:09]: [Client #668] Going to sleep for 0.21 seconds.
[INFO][13:29:09]: [Client #668] Woke up.
[INFO][13:29:09]: [Client #668] Epoch: [4/5][0/15]	Loss: 2.362470
[INFO][13:29:09]: [Client #668] Epoch: [4/5][10/15]	Loss: 1.815893
[INFO][13:29:09]: [Client #668] Going to sleep for 0.21 seconds.
[INFO][13:29:09]: [Client #668] Woke up.
[INFO][13:29:09]: [Client #668] Epoch: [5/5][0/15]	Loss: 2.407201
[INFO][13:29:09]: [Client #668] Epoch: [5/5][10/15]	Loss: 3.147476
[INFO][13:29:09]: [Client #668] Going to sleep for 0.21 seconds.
[INFO][13:29:10]: [Client #668] Woke up.
[INFO][13:29:10]: [Client #668] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_668_615875.pth.
[INFO][13:29:10]: [Client #668] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_668_615875.pth.
[INFO][13:29:10]: [Client #668] Model trained.
[INFO][13:29:10]: [Client #668] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:29:10]: [Server #615782] Received 0.26 MB of payload data from client #668 (simulated).
[INFO][13:29:14]: [Client #851] Woke up.
[INFO][13:29:14]: [Client #851] Epoch: [2/5][0/10]	Loss: 2.498777
[INFO][13:29:14]: [Client #851] Going to sleep for 6.13 seconds.
[INFO][13:29:20]: [Client #851] Woke up.
[INFO][13:29:20]: [Client #851] Epoch: [3/5][0/10]	Loss: 3.122732
[INFO][13:29:20]: [Client #851] Going to sleep for 6.13 seconds.
[INFO][13:29:26]: [Client #851] Woke up.
[INFO][13:29:26]: [Client #851] Epoch: [4/5][0/10]	Loss: 1.718377
[INFO][13:29:26]: [Client #851] Going to sleep for 6.13 seconds.
[INFO][13:29:33]: [Client #851] Woke up.
[INFO][13:29:33]: [Client #851] Epoch: [5/5][0/10]	Loss: 2.214864
[INFO][13:29:33]: [Client #851] Going to sleep for 6.13 seconds.
[INFO][13:29:39]: [Client #851] Woke up.
[INFO][13:29:39]: [Client #851] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_851_615874.pth.
[INFO][13:29:39]: [Client #851] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_851_615874.pth.
[INFO][13:29:39]: [Client #851] Model trained.
[INFO][13:29:39]: [Client #851] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:29:39]: [Server #615782] Received 0.26 MB of payload data from client #851 (simulated).
[INFO][13:29:39]: [Server #615782] Selecting client #344 for training.
[INFO][13:29:39]: [Server #615782] Sending the current model to client #344 (simulated).
[INFO][13:29:39]: [Server #615782] Sending 0.26 MB of payload data to client #344 (simulated).
[INFO][13:29:39]: [Server #615782] Selecting client #151 for training.
[INFO][13:29:39]: [Server #615782] Sending the current model to client #151 (simulated).
[INFO][13:29:40]: [Server #615782] Sending 0.26 MB of payload data to client #151 (simulated).
[INFO][13:29:40]: [Client #344] Selected by the server.
[INFO][13:29:40]: [Client #344] Loading its data source...
[INFO][13:29:40]: Data source: FEMNIST
[INFO][13:29:40]: [Client #151] Selected by the server.
[INFO][13:29:40]: [Client #151] Loading its data source...
[INFO][13:29:40]: Data source: FEMNIST
[INFO][13:29:40]: [Client #344] Dataset size: 153
[INFO][13:29:40]: [Client #344] Sampler: all_inclusive
[INFO][13:29:40]: [Client #344] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:29:40]: [93m[1m[Client #344] Started training in communication round #4.[0m
[INFO][13:29:40]: [Client #151] Dataset size: 162
[INFO][13:29:40]: [Client #151] Sampler: all_inclusive
[INFO][13:29:40]: [Client #151] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:29:40]: [93m[1m[Client #151] Started training in communication round #4.[0m
[INFO][13:29:42]: [Client #151] Loading the dataset.
[INFO][13:29:42]: [Client #344] Loading the dataset.
[INFO][13:29:47]: [Client #151] Epoch: [1/5][0/17]	Loss: 3.088849
[INFO][13:29:47]: [Client #344] Epoch: [1/5][0/16]	Loss: 2.582148
[INFO][13:29:47]: [Client #151] Epoch: [1/5][10/17]	Loss: 3.591984
[INFO][13:29:47]: [Client #344] Epoch: [1/5][10/16]	Loss: 3.243999
[INFO][13:29:47]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][13:29:47]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][13:29:48]: [Client #151] Woke up.
[INFO][13:29:48]: [Client #151] Epoch: [2/5][0/17]	Loss: 2.903879
[INFO][13:29:48]: [Client #151] Epoch: [2/5][10/17]	Loss: 2.590966
[INFO][13:29:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][13:29:48]: [Client #151] Woke up.
[INFO][13:29:48]: [Client #151] Epoch: [3/5][0/17]	Loss: 2.779614
[INFO][13:29:48]: [Client #151] Epoch: [3/5][10/17]	Loss: 3.546253
[INFO][13:29:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][13:29:48]: [Client #151] Woke up.
[INFO][13:29:48]: [Client #151] Epoch: [4/5][0/17]	Loss: 2.530788
[INFO][13:29:48]: [Client #151] Epoch: [4/5][10/17]	Loss: 2.715913
[INFO][13:29:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][13:29:48]: [Client #151] Woke up.
[INFO][13:29:48]: [Client #151] Epoch: [5/5][0/17]	Loss: 2.133619
[INFO][13:29:48]: [Client #151] Epoch: [5/5][10/17]	Loss: 1.348647
[INFO][13:29:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][13:29:48]: [Client #151] Woke up.
[INFO][13:29:48]: [Client #151] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_615875.pth.
[INFO][13:29:49]: [Client #151] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_615875.pth.
[INFO][13:29:49]: [Client #151] Model trained.
[INFO][13:29:49]: [Client #151] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:29:49]: [Server #615782] Received 0.26 MB of payload data from client #151 (simulated).
[INFO][13:29:53]: [Client #344] Woke up.
[INFO][13:29:53]: [Client #344] Epoch: [2/5][0/16]	Loss: 2.200047
[INFO][13:29:53]: [Client #344] Epoch: [2/5][10/16]	Loss: 2.178455
[INFO][13:29:53]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][13:29:59]: [Client #344] Woke up.
[INFO][13:29:59]: [Client #344] Epoch: [3/5][0/16]	Loss: 2.531952
[INFO][13:29:59]: [Client #344] Epoch: [3/5][10/16]	Loss: 2.722624
[INFO][13:29:59]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][13:30:05]: [Client #344] Woke up.
[INFO][13:30:05]: [Client #344] Epoch: [4/5][0/16]	Loss: 2.953483
[INFO][13:30:05]: [Client #344] Epoch: [4/5][10/16]	Loss: 2.892387
[INFO][13:30:06]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][13:30:11]: [Client #344] Woke up.
[INFO][13:30:11]: [Client #344] Epoch: [5/5][0/16]	Loss: 2.534825
[INFO][13:30:11]: [Client #344] Epoch: [5/5][10/16]	Loss: 2.478053
[INFO][13:30:12]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][13:30:17]: [Client #344] Woke up.
[INFO][13:30:17]: [Client #344] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_344_615874.pth.
[INFO][13:30:18]: [Client #344] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_344_615874.pth.
[INFO][13:30:18]: [Client #344] Model trained.
[INFO][13:30:18]: [Client #344] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:30:18]: [Server #615782] Received 0.26 MB of payload data from client #344 (simulated).
[INFO][13:30:18]: [Server #615782] Selecting client #636 for training.
[INFO][13:30:18]: [Server #615782] Sending the current model to client #636 (simulated).
[INFO][13:30:18]: [Server #615782] Sending 0.26 MB of payload data to client #636 (simulated).
[INFO][13:30:18]: [Server #615782] Selecting client #849 for training.
[INFO][13:30:18]: [Server #615782] Sending the current model to client #849 (simulated).
[INFO][13:30:18]: [Server #615782] Sending 0.26 MB of payload data to client #849 (simulated).
[INFO][13:30:18]: [Client #636] Selected by the server.
[INFO][13:30:18]: [Client #636] Loading its data source...
[INFO][13:30:18]: Data source: FEMNIST
[INFO][13:30:18]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:30:18]: [Client #849] Selected by the server.
[INFO][13:30:18]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/636.zip.
[INFO][13:30:18]: [Client #849] Loading its data source...
[INFO][13:30:18]: Data source: FEMNIST
[INFO][13:30:18]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:30:18]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/849.zip.
2.4%4.8%7.3%9.7%12.1%14.5%16.9%19.4%21.8%24.2%26.6%29.0%31.5%33.9%36.3%38.7%41.1%43.6%46.0%48.4%50.8%53.2%55.7%58.1%60.5%62.9%65.3%67.8%70.2%72.6%75.0%77.4%79.9%82.3%84.7%87.1%89.5%92.0%94.4%96.8%99.2%100.0%[INFO][13:30:18]: Decompressing the dataset downloaded.
[INFO][13:30:18]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/849.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
2.5%4.9%7.4%9.8%12.3%14.8%17.2%19.7%22.1%24.6%27.1%29.5%32.0%34.4%36.9%39.4%41.8%[INFO][13:30:18]: [Client #849] Dataset size: 162
[INFO][13:30:18]: [Client #849] Sampler: all_inclusive
[INFO][13:30:18]: [Client #849] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:18]: [93m[1m[Client #849] Started training in communication round #4.[0m

44.3%46.7%49.2%51.7%54.1%56.6%59.0%61.5%64.0%66.4%68.9%71.4%73.8%76.3%78.7%81.2%83.7%86.1%88.6%91.0%93.5%96.0%98.4%100.0%[INFO][13:30:18]: Decompressing the dataset downloaded.
[INFO][13:30:18]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/636.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:30:18]: [Client #636] Dataset size: 138
[INFO][13:30:18]: [Client #636] Sampler: all_inclusive
[INFO][13:30:18]: [Client #636] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:18]: [93m[1m[Client #636] Started training in communication round #4.[0m

[INFO][13:30:20]: [Client #849] Loading the dataset.
[INFO][13:30:20]: [Client #636] Loading the dataset.
[INFO][13:30:26]: [Client #849] Epoch: [1/5][0/17]	Loss: 2.931744
[INFO][13:30:26]: [Client #636] Epoch: [1/5][0/14]	Loss: 3.179487
[INFO][13:30:26]: [Client #849] Epoch: [1/5][10/17]	Loss: 3.630381
[INFO][13:30:26]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][13:30:26]: [Client #636] Epoch: [1/5][10/14]	Loss: 2.940245
[INFO][13:30:26]: [Client #636] Going to sleep for 0.06 seconds.
[INFO][13:30:26]: [Client #636] Woke up.
[INFO][13:30:26]: [Client #636] Epoch: [2/5][0/14]	Loss: 1.320603
[INFO][13:30:26]: [Client #636] Epoch: [2/5][10/14]	Loss: 2.676171
[INFO][13:30:26]: [Client #636] Going to sleep for 0.06 seconds.
[INFO][13:30:26]: [Client #636] Woke up.
[INFO][13:30:26]: [Client #636] Epoch: [3/5][0/14]	Loss: 3.664661
[INFO][13:30:27]: [Client #636] Epoch: [3/5][10/14]	Loss: 1.920580
[INFO][13:30:27]: [Client #636] Going to sleep for 0.06 seconds.
[INFO][13:30:27]: [Client #636] Woke up.
[INFO][13:30:27]: [Client #636] Epoch: [4/5][0/14]	Loss: 1.557661
[INFO][13:30:27]: [Client #636] Epoch: [4/5][10/14]	Loss: 2.781159
[INFO][13:30:27]: [Client #636] Going to sleep for 0.06 seconds.
[INFO][13:30:27]: [Client #636] Woke up.
[INFO][13:30:27]: [Client #636] Epoch: [5/5][0/14]	Loss: 2.004522
[INFO][13:30:27]: [Client #636] Epoch: [5/5][10/14]	Loss: 3.092244
[INFO][13:30:27]: [Client #636] Going to sleep for 0.06 seconds.
[INFO][13:30:27]: [Client #636] Woke up.
[INFO][13:30:27]: [Client #636] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_636_615874.pth.
[INFO][13:30:27]: [Client #849] Woke up.
[INFO][13:30:27]: [Client #849] Epoch: [2/5][0/17]	Loss: 3.335833
[INFO][13:30:27]: [Client #849] Epoch: [2/5][10/17]	Loss: 2.502747
[INFO][13:30:27]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][13:30:28]: [Client #636] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_636_615874.pth.
[INFO][13:30:28]: [Client #636] Model trained.
[INFO][13:30:28]: [Client #636] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:30:28]: [Server #615782] Received 0.26 MB of payload data from client #636 (simulated).
[INFO][13:30:28]: [Client #849] Woke up.
[INFO][13:30:28]: [Client #849] Epoch: [3/5][0/17]	Loss: 2.351053
[INFO][13:30:29]: [Client #849] Epoch: [3/5][10/17]	Loss: 2.382981
[INFO][13:30:29]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][13:30:30]: [Client #849] Woke up.
[INFO][13:30:30]: [Client #849] Epoch: [4/5][0/17]	Loss: 3.102061
[INFO][13:30:30]: [Client #849] Epoch: [4/5][10/17]	Loss: 1.703373
[INFO][13:30:30]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][13:30:31]: [Client #849] Woke up.
[INFO][13:30:31]: [Client #849] Epoch: [5/5][0/17]	Loss: 2.277443
[INFO][13:30:31]: [Client #849] Epoch: [5/5][10/17]	Loss: 2.054318
[INFO][13:30:31]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][13:30:32]: [Client #849] Woke up.
[INFO][13:30:32]: [Client #849] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_849_615875.pth.
[INFO][13:30:33]: [Client #849] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_849_615875.pth.
[INFO][13:30:33]: [Client #849] Model trained.
[INFO][13:30:33]: [Client #849] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:30:33]: [Server #615782] Received 0.26 MB of payload data from client #849 (simulated).
[INFO][13:30:33]: [Server #615782] Selecting client #823 for training.
[INFO][13:30:33]: [Server #615782] Sending the current model to client #823 (simulated).
[INFO][13:30:33]: [Server #615782] Sending 0.26 MB of payload data to client #823 (simulated).
[INFO][13:30:33]: [Server #615782] Selecting client #629 for training.
[INFO][13:30:33]: [Server #615782] Sending the current model to client #629 (simulated).
[INFO][13:30:33]: [Server #615782] Sending 0.26 MB of payload data to client #629 (simulated).
[INFO][13:30:33]: [Client #629] Selected by the server.
[INFO][13:30:33]: [Client #823] Selected by the server.
[INFO][13:30:33]: [Client #629] Loading its data source...
[INFO][13:30:33]: Data source: FEMNIST
[INFO][13:30:33]: [Client #823] Loading its data source...
[INFO][13:30:33]: Data source: FEMNIST
[INFO][13:30:33]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:30:33]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:30:33]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/629.zip.
[INFO][13:30:33]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/823.zip.
2.2%2.4%4.8%7.1%9.5%11.9%14.3%16.7%19.1%21.4%23.8%26.2%28.6%31.0%33.4%35.7%38.1%4.4%6.6%8.7%10.9%13.1%15.3%17.5%19.7%21.9%24.0%26.2%28.4%30.6%32.8%35.0%37.2%39.3%41.5%43.7%45.9%48.1%50.3%52.5%54.6%56.8%59.0%61.2%63.4%65.6%67.8%70.0%72.1%74.3%76.5%78.7%80.9%83.1%85.3%87.4%89.6%91.8%94.0%96.2%98.4%100.0%[INFO][13:30:33]: Decompressing the dataset downloaded.
[INFO][13:30:33]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/823.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
40.5%42.9%45.3%47.7%50.0%52.4%54.8%57.2%59.6%62.0%64.3%66.7%69.1%71.5%73.9%76.3%78.6%81.0%83.4%85.8%88.2%90.6%92.9%95.3%97.7%100.0%[INFO][13:30:33]: Decompressing the dataset downloaded.
[INFO][13:30:33]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/629.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:30:33]: [Client #823] Dataset size: 160
[INFO][13:30:33]: [Client #823] Sampler: all_inclusive
[INFO][13:30:33]: [Client #823] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:33]: [Client #629] Dataset size: 141
[INFO][13:30:33]: [Client #629] Sampler: all_inclusive
[INFO][13:30:33]: [93m[1m[Client #823] Started training in communication round #4.[0m

[INFO][13:30:33]: [Client #629] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:33]: [93m[1m[Client #629] Started training in communication round #4.[0m

[INFO][13:30:35]: [Client #629] Loading the dataset.
[INFO][13:30:35]: [Client #823] Loading the dataset.
[INFO][13:30:41]: [Client #629] Epoch: [1/5][0/15]	Loss: 4.232113
[INFO][13:30:41]: [Client #823] Epoch: [1/5][0/16]	Loss: 2.743101
[INFO][13:30:41]: [Client #629] Epoch: [1/5][10/15]	Loss: 2.284829
[INFO][13:30:41]: [Client #629] Going to sleep for 1.76 seconds.
[INFO][13:30:41]: [Client #823] Epoch: [1/5][10/16]	Loss: 3.367636
[INFO][13:30:41]: [Client #823] Going to sleep for 2.25 seconds.
[INFO][13:30:42]: [Client #629] Woke up.
[INFO][13:30:42]: [Client #629] Epoch: [2/5][0/15]	Loss: 2.210330
[INFO][13:30:43]: [Client #629] Epoch: [2/5][10/15]	Loss: 2.102604
[INFO][13:30:43]: [Client #629] Going to sleep for 1.76 seconds.
[INFO][13:30:43]: [Client #823] Woke up.
[INFO][13:30:43]: [Client #823] Epoch: [2/5][0/16]	Loss: 1.882911
[INFO][13:30:43]: [Client #823] Epoch: [2/5][10/16]	Loss: 3.006713
[INFO][13:30:43]: [Client #823] Going to sleep for 2.25 seconds.
[INFO][13:30:44]: [Client #629] Woke up.
[INFO][13:30:44]: [Client #629] Epoch: [3/5][0/15]	Loss: 1.455590
[INFO][13:30:44]: [Client #629] Epoch: [3/5][10/15]	Loss: 2.655778
[INFO][13:30:45]: [Client #629] Going to sleep for 1.76 seconds.
[INFO][13:30:45]: [Client #823] Woke up.
[INFO][13:30:45]: [Client #823] Epoch: [3/5][0/16]	Loss: 2.530973
[INFO][13:30:46]: [Client #823] Epoch: [3/5][10/16]	Loss: 3.274632
[INFO][13:30:46]: [Client #823] Going to sleep for 2.25 seconds.
[INFO][13:30:46]: [Client #629] Woke up.
[INFO][13:30:46]: [Client #629] Epoch: [4/5][0/15]	Loss: 2.486101
[INFO][13:30:46]: [Client #629] Epoch: [4/5][10/15]	Loss: 2.469022
[INFO][13:30:46]: [Client #629] Going to sleep for 1.76 seconds.
[INFO][13:30:48]: [Client #823] Woke up.
[INFO][13:30:48]: [Client #823] Epoch: [4/5][0/16]	Loss: 2.020530
[INFO][13:30:48]: [Client #823] Epoch: [4/5][10/16]	Loss: 1.957122
[INFO][13:30:48]: [Client #823] Going to sleep for 2.25 seconds.
[INFO][13:30:48]: [Client #629] Woke up.
[INFO][13:30:48]: [Client #629] Epoch: [5/5][0/15]	Loss: 2.369407
[INFO][13:30:48]: [Client #629] Epoch: [5/5][10/15]	Loss: 2.045959
[INFO][13:30:48]: [Client #629] Going to sleep for 1.76 seconds.
[INFO][13:30:50]: [Client #629] Woke up.
[INFO][13:30:50]: [Client #629] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_629_615875.pth.
[INFO][13:30:50]: [Client #823] Woke up.
[INFO][13:30:50]: [Client #823] Epoch: [5/5][0/16]	Loss: 2.421163
[INFO][13:30:50]: [Client #823] Epoch: [5/5][10/16]	Loss: 2.189153
[INFO][13:30:50]: [Client #823] Going to sleep for 2.25 seconds.
[INFO][13:30:51]: [Client #629] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_629_615875.pth.
[INFO][13:30:51]: [Client #629] Model trained.
[INFO][13:30:51]: [Client #629] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:30:51]: [Server #615782] Received 0.26 MB of payload data from client #629 (simulated).
[INFO][13:30:53]: [Client #823] Woke up.
[INFO][13:30:53]: [Client #823] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_823_615874.pth.
[INFO][13:30:53]: [Client #823] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_823_615874.pth.
[INFO][13:30:53]: [Client #823] Model trained.
[INFO][13:30:53]: [Client #823] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:30:53]: [Server #615782] Received 0.26 MB of payload data from client #823 (simulated).
[INFO][13:30:53]: [Server #615782] Selecting client #957 for training.
[INFO][13:30:53]: [Server #615782] Sending the current model to client #957 (simulated).
[INFO][13:30:53]: [Server #615782] Sending 0.26 MB of payload data to client #957 (simulated).
[INFO][13:30:53]: [Server #615782] Selecting client #590 for training.
[INFO][13:30:53]: [Server #615782] Sending the current model to client #590 (simulated).
[INFO][13:30:53]: [Server #615782] Sending 0.26 MB of payload data to client #590 (simulated).
[INFO][13:30:53]: [Client #957] Selected by the server.
[INFO][13:30:53]: [Client #957] Loading its data source...
[INFO][13:30:53]: Data source: FEMNIST
[INFO][13:30:53]: [Client #590] Selected by the server.
[INFO][13:30:53]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:30:53]: [Client #590] Loading its data source...
[INFO][13:30:53]: Data source: FEMNIST
[INFO][13:30:53]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/957.zip.
[INFO][13:30:53]: [Client #590] Dataset size: 153
[INFO][13:30:53]: [Client #590] Sampler: all_inclusive
[INFO][13:30:53]: [Client #590] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:53]: [93m[1m[Client #590] Started training in communication round #4.[0m
3.3%6.6%9.9%13.2%16.5%19.7%23.0%26.3%29.6%32.9%36.2%39.5%42.8%46.1%49.4%52.6%55.9%59.2%62.5%65.8%69.1%72.4%75.7%79.0%82.3%85.5%88.8%92.1%95.4%98.7%100.0%[INFO][13:30:54]: Decompressing the dataset downloaded.
[INFO][13:30:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/957.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:30:54]: [Client #957] Dataset size: 153
[INFO][13:30:54]: [Client #957] Sampler: all_inclusive
[INFO][13:30:54]: [Client #957] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:30:54]: [93m[1m[Client #957] Started training in communication round #4.[0m

[INFO][13:30:56]: [Client #590] Loading the dataset.
[INFO][13:30:56]: [Client #957] Loading the dataset.
[INFO][13:31:01]: [Client #590] Epoch: [1/5][0/16]	Loss: 2.372176
[INFO][13:31:01]: [Client #957] Epoch: [1/5][0/16]	Loss: 2.807759
[INFO][13:31:01]: [Client #590] Epoch: [1/5][10/16]	Loss: 2.009237
[INFO][13:31:01]: [Client #957] Epoch: [1/5][10/16]	Loss: 2.689938
[INFO][13:31:01]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:31:01]: [Client #957] Going to sleep for 1.87 seconds.
[INFO][13:31:03]: [Client #957] Woke up.
[INFO][13:31:03]: [Client #957] Epoch: [2/5][0/16]	Loss: 2.964986
[INFO][13:31:03]: [Client #957] Epoch: [2/5][10/16]	Loss: 1.894721
[INFO][13:31:03]: [Client #957] Going to sleep for 1.87 seconds.
[INFO][13:31:05]: [Client #590] Woke up.
[INFO][13:31:05]: [Client #590] Epoch: [2/5][0/16]	Loss: 2.020059
[INFO][13:31:05]: [Client #590] Epoch: [2/5][10/16]	Loss: 3.891606
[INFO][13:31:05]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:31:05]: [Client #957] Woke up.
[INFO][13:31:05]: [Client #957] Epoch: [3/5][0/16]	Loss: 3.087924
[INFO][13:31:05]: [Client #957] Epoch: [3/5][10/16]	Loss: 3.456634
[INFO][13:31:06]: [Client #957] Going to sleep for 1.87 seconds.
[INFO][13:31:07]: [Client #957] Woke up.
[INFO][13:31:07]: [Client #957] Epoch: [4/5][0/16]	Loss: 2.578059
[INFO][13:31:08]: [Client #957] Epoch: [4/5][10/16]	Loss: 2.690765
[INFO][13:31:08]: [Client #957] Going to sleep for 1.87 seconds.
[INFO][13:31:08]: [Client #590] Woke up.
[INFO][13:31:08]: [Client #590] Epoch: [3/5][0/16]	Loss: 2.549578
[INFO][13:31:08]: [Client #590] Epoch: [3/5][10/16]	Loss: 2.282159
[INFO][13:31:08]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:31:09]: [Client #957] Woke up.
[INFO][13:31:09]: [Client #957] Epoch: [5/5][0/16]	Loss: 2.516307
[INFO][13:31:10]: [Client #957] Epoch: [5/5][10/16]	Loss: 2.832148
[INFO][13:31:10]: [Client #957] Going to sleep for 1.87 seconds.
[INFO][13:31:11]: [Client #957] Woke up.
[INFO][13:31:11]: [Client #957] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_957_615874.pth.
[INFO][13:31:12]: [Client #590] Woke up.
[INFO][13:31:12]: [Client #590] Epoch: [4/5][0/16]	Loss: 1.571009
[INFO][13:31:12]: [Client #590] Epoch: [4/5][10/16]	Loss: 2.821851
[INFO][13:31:12]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:31:12]: [Client #957] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_957_615874.pth.
[INFO][13:31:12]: [Client #957] Model trained.
[INFO][13:31:12]: [Client #957] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:12]: [Server #615782] Received 0.26 MB of payload data from client #957 (simulated).
[INFO][13:31:15]: [Client #590] Woke up.
[INFO][13:31:15]: [Client #590] Epoch: [5/5][0/16]	Loss: 1.789326
[INFO][13:31:15]: [Client #590] Epoch: [5/5][10/16]	Loss: 2.392759
[INFO][13:31:15]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][13:31:19]: [Client #590] Woke up.
[INFO][13:31:19]: [Client #590] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615875.pth.
[INFO][13:31:19]: [Client #590] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615875.pth.
[INFO][13:31:19]: [Client #590] Model trained.
[INFO][13:31:19]: [Client #590] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:19]: [Server #615782] Received 0.26 MB of payload data from client #590 (simulated).
[INFO][13:31:19]: [Server #615782] Selecting client #197 for training.
[INFO][13:31:19]: [Server #615782] Sending the current model to client #197 (simulated).
[INFO][13:31:19]: [Server #615782] Sending 0.26 MB of payload data to client #197 (simulated).
[INFO][13:31:19]: [Server #615782] Selecting client #429 for training.
[INFO][13:31:19]: [Server #615782] Sending the current model to client #429 (simulated).
[INFO][13:31:19]: [Server #615782] Sending 0.26 MB of payload data to client #429 (simulated).
[INFO][13:31:19]: [Client #197] Selected by the server.
[INFO][13:31:19]: [Client #197] Loading its data source...
[INFO][13:31:19]: [Client #429] Selected by the server.
[INFO][13:31:19]: Data source: FEMNIST
[INFO][13:31:19]: [Client #429] Loading its data source...
[INFO][13:31:19]: Data source: FEMNIST
[INFO][13:31:19]: [Client #197] Dataset size: 155
[INFO][13:31:19]: [Client #197] Sampler: all_inclusive
[INFO][13:31:19]: [Client #197] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:19]: [93m[1m[Client #197] Started training in communication round #4.[0m
[INFO][13:31:19]: [Client #429] Dataset size: 167
[INFO][13:31:19]: [Client #429] Sampler: all_inclusive
[INFO][13:31:19]: [Client #429] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:19]: [93m[1m[Client #429] Started training in communication round #4.[0m
[INFO][13:31:21]: [Client #197] Loading the dataset.
[INFO][13:31:21]: [Client #429] Loading the dataset.
[INFO][13:31:27]: [Client #429] Epoch: [1/5][0/17]	Loss: 3.592618
[INFO][13:31:27]: [Client #197] Epoch: [1/5][0/16]	Loss: 2.938636
[INFO][13:31:27]: [Client #429] Epoch: [1/5][10/17]	Loss: 2.705560
[INFO][13:31:27]: [Client #197] Epoch: [1/5][10/16]	Loss: 3.173099
[INFO][13:31:27]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][13:31:27]: [Client #197] Going to sleep for 0.01 seconds.
[INFO][13:31:27]: [Client #197] Woke up.
[INFO][13:31:27]: [Client #197] Epoch: [2/5][0/16]	Loss: 2.469974
[INFO][13:31:27]: [Client #197] Epoch: [2/5][10/16]	Loss: 1.882333
[INFO][13:31:27]: [Client #197] Going to sleep for 0.01 seconds.
[INFO][13:31:27]: [Client #197] Woke up.
[INFO][13:31:27]: [Client #197] Epoch: [3/5][0/16]	Loss: 2.483155
[INFO][13:31:27]: [Client #197] Epoch: [3/5][10/16]	Loss: 2.753766
[INFO][13:31:28]: [Client #197] Going to sleep for 0.01 seconds.
[INFO][13:31:28]: [Client #197] Woke up.
[INFO][13:31:28]: [Client #197] Epoch: [4/5][0/16]	Loss: 1.979798
[INFO][13:31:28]: [Client #197] Epoch: [4/5][10/16]	Loss: 2.284634
[INFO][13:31:28]: [Client #197] Going to sleep for 0.01 seconds.
[INFO][13:31:28]: [Client #197] Woke up.
[INFO][13:31:28]: [Client #197] Epoch: [5/5][0/16]	Loss: 2.146227
[INFO][13:31:28]: [Client #197] Epoch: [5/5][10/16]	Loss: 2.378919
[INFO][13:31:28]: [Client #197] Going to sleep for 0.01 seconds.
[INFO][13:31:28]: [Client #197] Woke up.
[INFO][13:31:28]: [Client #429] Woke up.
[INFO][13:31:28]: [Client #197] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_197_615874.pth.
[INFO][13:31:28]: [Client #429] Epoch: [2/5][0/17]	Loss: 2.843886
[INFO][13:31:28]: [Client #429] Epoch: [2/5][10/17]	Loss: 2.646986
[INFO][13:31:28]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][13:31:28]: [Client #197] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_197_615874.pth.
[INFO][13:31:28]: [Client #197] Model trained.
[INFO][13:31:29]: [Client #197] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:29]: [Server #615782] Received 0.26 MB of payload data from client #197 (simulated).
[INFO][13:31:29]: [Client #429] Woke up.
[INFO][13:31:29]: [Client #429] Epoch: [3/5][0/17]	Loss: 3.088420
[INFO][13:31:29]: [Client #429] Epoch: [3/5][10/17]	Loss: 2.141675
[INFO][13:31:29]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][13:31:29]: [Client #429] Woke up.
[INFO][13:31:29]: [Client #429] Epoch: [4/5][0/17]	Loss: 2.015360
[INFO][13:31:30]: [Client #429] Epoch: [4/5][10/17]	Loss: 2.244528
[INFO][13:31:30]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][13:31:30]: [Client #429] Woke up.
[INFO][13:31:30]: [Client #429] Epoch: [5/5][0/17]	Loss: 2.275558
[INFO][13:31:30]: [Client #429] Epoch: [5/5][10/17]	Loss: 1.891496
[INFO][13:31:30]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][13:31:31]: [Client #429] Woke up.
[INFO][13:31:31]: [Client #429] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_429_615875.pth.
[INFO][13:31:32]: [Client #429] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_429_615875.pth.
[INFO][13:31:32]: [Client #429] Model trained.
[INFO][13:31:32]: [Client #429] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:32]: [Server #615782] Received 0.26 MB of payload data from client #429 (simulated).
[INFO][13:31:32]: [Server #615782] Selecting client #337 for training.
[INFO][13:31:32]: [Server #615782] Sending the current model to client #337 (simulated).
[INFO][13:31:32]: [Server #615782] Sending 0.26 MB of payload data to client #337 (simulated).
[INFO][13:31:32]: [Server #615782] Selecting client #992 for training.
[INFO][13:31:32]: [Server #615782] Sending the current model to client #992 (simulated).
[INFO][13:31:32]: [Server #615782] Sending 0.26 MB of payload data to client #992 (simulated).
[INFO][13:31:32]: [Client #337] Selected by the server.
[INFO][13:31:32]: [Client #992] Selected by the server.
[INFO][13:31:32]: [Client #337] Loading its data source...
[INFO][13:31:32]: [Client #992] Loading its data source...
[INFO][13:31:32]: Data source: FEMNIST
[INFO][13:31:32]: Data source: FEMNIST
[INFO][13:31:32]: [Client #992] Dataset size: 145
[INFO][13:31:32]: [Client #992] Sampler: all_inclusive
[INFO][13:31:32]: [Client #992] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:32]: [93m[1m[Client #992] Started training in communication round #4.[0m
[INFO][13:31:32]: [Client #337] Dataset size: 155
[INFO][13:31:32]: [Client #337] Sampler: all_inclusive
[INFO][13:31:32]: [Client #337] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:32]: [93m[1m[Client #337] Started training in communication round #4.[0m
[INFO][13:31:34]: [Client #992] Loading the dataset.
[INFO][13:31:34]: [Client #337] Loading the dataset.
[INFO][13:31:39]: [Client #992] Epoch: [1/5][0/15]	Loss: 3.416721
[INFO][13:31:39]: [Client #337] Epoch: [1/5][0/16]	Loss: 2.466910
[INFO][13:31:39]: [Client #992] Epoch: [1/5][10/15]	Loss: 2.320288
[INFO][13:31:39]: [Client #337] Epoch: [1/5][10/16]	Loss: 3.072211
[INFO][13:31:39]: [Client #992] Going to sleep for 0.40 seconds.
[INFO][13:31:39]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][13:31:40]: [Client #992] Woke up.
[INFO][13:31:40]: [Client #992] Epoch: [2/5][0/15]	Loss: 1.705651
[INFO][13:31:40]: [Client #992] Epoch: [2/5][10/15]	Loss: 2.307260
[INFO][13:31:40]: [Client #337] Woke up.
[INFO][13:31:40]: [Client #992] Going to sleep for 0.40 seconds.
[INFO][13:31:40]: [Client #337] Epoch: [2/5][0/16]	Loss: 2.532001
[INFO][13:31:40]: [Client #337] Epoch: [2/5][10/16]	Loss: 2.026139
[INFO][13:31:40]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][13:31:40]: [Client #992] Woke up.
[INFO][13:31:40]: [Client #992] Epoch: [3/5][0/15]	Loss: 1.882075
[INFO][13:31:40]: [Client #992] Epoch: [3/5][10/15]	Loss: 2.270149
[INFO][13:31:40]: [Client #992] Going to sleep for 0.40 seconds.
[INFO][13:31:40]: [Client #337] Woke up.
[INFO][13:31:40]: [Client #337] Epoch: [3/5][0/16]	Loss: 2.280606
[INFO][13:31:41]: [Client #337] Epoch: [3/5][10/16]	Loss: 2.429480
[INFO][13:31:41]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][13:31:41]: [Client #992] Woke up.
[INFO][13:31:41]: [Client #992] Epoch: [4/5][0/15]	Loss: 2.441790
[INFO][13:31:41]: [Client #992] Epoch: [4/5][10/15]	Loss: 2.367442
[INFO][13:31:41]: [Client #992] Going to sleep for 0.40 seconds.
[INFO][13:31:41]: [Client #337] Woke up.
[INFO][13:31:41]: [Client #337] Epoch: [4/5][0/16]	Loss: 2.817973
[INFO][13:31:41]: [Client #337] Epoch: [4/5][10/16]	Loss: 2.163279
[INFO][13:31:41]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][13:31:41]: [Client #992] Woke up.
[INFO][13:31:41]: [Client #992] Epoch: [5/5][0/15]	Loss: 3.016383
[INFO][13:31:41]: [Client #992] Epoch: [5/5][10/15]	Loss: 1.683479
[INFO][13:31:41]: [Client #992] Going to sleep for 0.40 seconds.
[INFO][13:31:42]: [Client #337] Woke up.
[INFO][13:31:42]: [Client #337] Epoch: [5/5][0/16]	Loss: 2.494102
[INFO][13:31:42]: [Client #337] Epoch: [5/5][10/16]	Loss: 2.209654
[INFO][13:31:42]: [Client #992] Woke up.
[INFO][13:31:42]: [Client #992] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_992_615875.pth.
[INFO][13:31:42]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][13:31:42]: [Client #337] Woke up.
[INFO][13:31:42]: [Client #337] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_337_615874.pth.
[INFO][13:31:42]: [Client #992] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_992_615875.pth.
[INFO][13:31:42]: [Client #992] Model trained.
[INFO][13:31:42]: [Client #992] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:42]: [Server #615782] Received 0.26 MB of payload data from client #992 (simulated).
[INFO][13:31:43]: [Client #337] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_337_615874.pth.
[INFO][13:31:43]: [Client #337] Model trained.
[INFO][13:31:43]: [Client #337] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:43]: [Server #615782] Received 0.26 MB of payload data from client #337 (simulated).
[INFO][13:31:43]: [Server #615782] Selecting client #380 for training.
[INFO][13:31:43]: [Server #615782] Sending the current model to client #380 (simulated).
[INFO][13:31:43]: [Server #615782] Sending 0.26 MB of payload data to client #380 (simulated).
[INFO][13:31:43]: [Server #615782] Selecting client #993 for training.
[INFO][13:31:43]: [Server #615782] Sending the current model to client #993 (simulated).
[INFO][13:31:43]: [Server #615782] Sending 0.26 MB of payload data to client #993 (simulated).
[INFO][13:31:43]: [Client #380] Selected by the server.
[INFO][13:31:43]: [Client #380] Loading its data source...
[INFO][13:31:43]: Data source: FEMNIST
[INFO][13:31:43]: [Client #993] Selected by the server.
[INFO][13:31:43]: [Client #993] Loading its data source...
[INFO][13:31:43]: Data source: FEMNIST
[INFO][13:31:43]: [Client #993] Dataset size: 158
[INFO][13:31:43]: [Client #993] Sampler: all_inclusive
[INFO][13:31:43]: [Client #993] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:43]: [93m[1m[Client #993] Started training in communication round #4.[0m
[INFO][13:31:43]: [Client #380] Dataset size: 159
[INFO][13:31:43]: [Client #380] Sampler: all_inclusive
[INFO][13:31:43]: [Client #380] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:43]: [93m[1m[Client #380] Started training in communication round #4.[0m
[INFO][13:31:45]: [Client #380] Loading the dataset.
[INFO][13:31:45]: [Client #993] Loading the dataset.
[INFO][13:31:51]: [Client #380] Epoch: [1/5][0/16]	Loss: 2.584904
[INFO][13:31:51]: [Client #993] Epoch: [1/5][0/16]	Loss: 3.507653
[INFO][13:31:51]: [Client #380] Epoch: [1/5][10/16]	Loss: 2.772088
[INFO][13:31:51]: [Client #993] Epoch: [1/5][10/16]	Loss: 2.328580
[INFO][13:31:51]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][13:31:51]: [Client #993] Going to sleep for 1.12 seconds.
[INFO][13:31:51]: [Client #380] Woke up.
[INFO][13:31:51]: [Client #380] Epoch: [2/5][0/16]	Loss: 3.151250
[INFO][13:31:51]: [Client #380] Epoch: [2/5][10/16]	Loss: 2.800330
[INFO][13:31:51]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][13:31:52]: [Client #380] Woke up.
[INFO][13:31:52]: [Client #380] Epoch: [3/5][0/16]	Loss: 2.258062
[INFO][13:31:52]: [Client #380] Epoch: [3/5][10/16]	Loss: 2.068753
[INFO][13:31:52]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][13:31:52]: [Client #380] Woke up.
[INFO][13:31:52]: [Client #380] Epoch: [4/5][0/16]	Loss: 2.072592
[INFO][13:31:52]: [Client #380] Epoch: [4/5][10/16]	Loss: 1.844240
[INFO][13:31:52]: [Client #993] Woke up.
[INFO][13:31:52]: [Client #993] Epoch: [2/5][0/16]	Loss: 2.346876
[INFO][13:31:52]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][13:31:52]: [Client #993] Epoch: [2/5][10/16]	Loss: 2.728101
[INFO][13:31:52]: [Client #993] Going to sleep for 1.12 seconds.
[INFO][13:31:53]: [Client #380] Woke up.
[INFO][13:31:53]: [Client #380] Epoch: [5/5][0/16]	Loss: 2.369219
[INFO][13:31:53]: [Client #380] Epoch: [5/5][10/16]	Loss: 2.695678
[INFO][13:31:53]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][13:31:53]: [Client #380] Woke up.
[INFO][13:31:53]: [Client #380] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_615874.pth.
[INFO][13:31:54]: [Client #993] Woke up.
[INFO][13:31:54]: [Client #993] Epoch: [3/5][0/16]	Loss: 2.239003
[INFO][13:31:54]: [Client #380] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_615874.pth.
[INFO][13:31:54]: [Client #993] Epoch: [3/5][10/16]	Loss: 1.736773
[INFO][13:31:54]: [Client #380] Model trained.
[INFO][13:31:54]: [Client #380] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:54]: [Server #615782] Received 0.26 MB of payload data from client #380 (simulated).
[INFO][13:31:54]: [Client #993] Going to sleep for 1.12 seconds.
[INFO][13:31:55]: [Client #993] Woke up.
[INFO][13:31:55]: [Client #993] Epoch: [4/5][0/16]	Loss: 2.084602
[INFO][13:31:55]: [Client #993] Epoch: [4/5][10/16]	Loss: 1.998920
[INFO][13:31:55]: [Client #993] Going to sleep for 1.12 seconds.
[INFO][13:31:56]: [Client #993] Woke up.
[INFO][13:31:56]: [Client #993] Epoch: [5/5][0/16]	Loss: 1.193230
[INFO][13:31:56]: [Client #993] Epoch: [5/5][10/16]	Loss: 1.083482
[INFO][13:31:56]: [Client #993] Going to sleep for 1.12 seconds.
[INFO][13:31:57]: [Client #993] Woke up.
[INFO][13:31:57]: [Client #993] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_993_615875.pth.
[INFO][13:31:58]: [Client #993] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_993_615875.pth.
[INFO][13:31:58]: [Client #993] Model trained.
[INFO][13:31:58]: [Client #993] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:31:58]: [Server #615782] Received 0.26 MB of payload data from client #993 (simulated).
[INFO][13:31:58]: [Server #615782] Selecting client #518 for training.
[INFO][13:31:58]: [Server #615782] Sending the current model to client #518 (simulated).
[INFO][13:31:58]: [Server #615782] Sending 0.26 MB of payload data to client #518 (simulated).
[INFO][13:31:58]: [Server #615782] Selecting client #172 for training.
[INFO][13:31:58]: [Server #615782] Sending the current model to client #172 (simulated).
[INFO][13:31:58]: [Server #615782] Sending 0.26 MB of payload data to client #172 (simulated).
[INFO][13:31:58]: [Client #172] Selected by the server.
[INFO][13:31:58]: [Client #518] Selected by the server.
[INFO][13:31:58]: [Client #172] Loading its data source...
[INFO][13:31:58]: [Client #518] Loading its data source...
[INFO][13:31:58]: Data source: FEMNIST
[INFO][13:31:58]: Data source: FEMNIST
[INFO][13:31:58]: [Client #518] Dataset size: 161
[INFO][13:31:58]: [Client #518] Sampler: all_inclusive
[INFO][13:31:58]: [Client #518] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:58]: [93m[1m[Client #518] Started training in communication round #4.[0m
[INFO][13:31:58]: [Client #172] Dataset size: 164
[INFO][13:31:58]: [Client #172] Sampler: all_inclusive
[INFO][13:31:58]: [Client #172] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:31:58]: [93m[1m[Client #172] Started training in communication round #4.[0m
[INFO][13:32:00]: [Client #518] Loading the dataset.
[INFO][13:32:00]: [Client #172] Loading the dataset.
[INFO][13:32:06]: [Client #172] Epoch: [1/5][0/17]	Loss: 2.612134
[INFO][13:32:06]: [Client #518] Epoch: [1/5][0/17]	Loss: 2.914352
[INFO][13:32:06]: [Client #518] Epoch: [1/5][10/17]	Loss: 3.630406
[INFO][13:32:06]: [Client #172] Epoch: [1/5][10/17]	Loss: 2.900001
[INFO][13:32:06]: [Client #518] Going to sleep for 0.21 seconds.
[INFO][13:32:06]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][13:32:06]: [Client #518] Woke up.
[INFO][13:32:06]: [Client #518] Epoch: [2/5][0/17]	Loss: 2.344644
[INFO][13:32:06]: [Client #518] Epoch: [2/5][10/17]	Loss: 2.340552
[INFO][13:32:06]: [Client #518] Going to sleep for 0.21 seconds.
[INFO][13:32:06]: [Client #518] Woke up.
[INFO][13:32:06]: [Client #518] Epoch: [3/5][0/17]	Loss: 2.575562
[INFO][13:32:06]: [Client #518] Epoch: [3/5][10/17]	Loss: 2.418302
[INFO][13:32:06]: [Client #518] Going to sleep for 0.21 seconds.
[INFO][13:32:07]: [Client #518] Woke up.
[INFO][13:32:07]: [Client #518] Epoch: [4/5][0/17]	Loss: 2.539758
[INFO][13:32:07]: [Client #518] Epoch: [4/5][10/17]	Loss: 1.762914
[INFO][13:32:07]: [Client #518] Going to sleep for 0.21 seconds.
[INFO][13:32:07]: [Client #518] Woke up.
[INFO][13:32:07]: [Client #518] Epoch: [5/5][0/17]	Loss: 1.698453
[INFO][13:32:07]: [Client #518] Epoch: [5/5][10/17]	Loss: 2.779031
[INFO][13:32:07]: [Client #518] Going to sleep for 0.21 seconds.
[INFO][13:32:07]: [Client #518] Woke up.
[INFO][13:32:07]: [Client #518] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_518_615874.pth.
[INFO][13:32:08]: [Client #518] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_518_615874.pth.
[INFO][13:32:08]: [Client #518] Model trained.
[INFO][13:32:08]: [Client #518] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:32:08]: [Server #615782] Received 0.26 MB of payload data from client #518 (simulated).
[INFO][13:33:06]: [Client #172] Woke up.
[INFO][13:33:06]: [Client #172] Epoch: [2/5][0/17]	Loss: 2.239652
[INFO][13:33:06]: [Client #172] Epoch: [2/5][10/17]	Loss: 3.414369
[INFO][13:33:06]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][13:34:06]: [Client #172] Woke up.
[INFO][13:34:06]: [Client #172] Epoch: [3/5][0/17]	Loss: 3.236860
[INFO][13:34:06]: [Client #172] Epoch: [3/5][10/17]	Loss: 2.926475
[INFO][13:34:06]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][13:35:06]: [Client #172] Woke up.
[INFO][13:35:06]: [Client #172] Epoch: [4/5][0/17]	Loss: 0.995622
[INFO][13:35:06]: [Client #172] Epoch: [4/5][10/17]	Loss: 2.665885
[INFO][13:35:07]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][13:36:07]: [Client #172] Woke up.
[INFO][13:36:07]: [Client #172] Epoch: [5/5][0/17]	Loss: 2.063806
[INFO][13:36:07]: [Client #172] Epoch: [5/5][10/17]	Loss: 2.134877
[INFO][13:36:07]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][13:37:07]: [Client #172] Woke up.
[INFO][13:37:07]: [Client #172] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615875.pth.
[INFO][13:37:08]: [Client #172] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615875.pth.
[INFO][13:37:08]: [Client #172] Model trained.
[INFO][13:37:08]: [Client #172] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:37:08]: [Server #615782] Received 0.26 MB of payload data from client #172 (simulated).
[INFO][13:37:08]: [Server #615782] Selecting client #74 for training.
[INFO][13:37:08]: [Server #615782] Sending the current model to client #74 (simulated).
[INFO][13:37:08]: [Server #615782] Sending 0.26 MB of payload data to client #74 (simulated).
[INFO][13:37:08]: [Server #615782] Selecting client #370 for training.
[INFO][13:37:08]: [Server #615782] Sending the current model to client #370 (simulated).
[INFO][13:37:08]: [Server #615782] Sending 0.26 MB of payload data to client #370 (simulated).
[INFO][13:37:08]: [Client #74] Selected by the server.
[INFO][13:37:08]: [Client #370] Selected by the server.
[INFO][13:37:08]: [Client #74] Loading its data source...
[INFO][13:37:08]: [Client #370] Loading its data source...
[INFO][13:37:08]: Data source: FEMNIST
[INFO][13:37:08]: Data source: FEMNIST
[INFO][13:37:08]: [Client #370] Dataset size: 161
[INFO][13:37:08]: [Client #370] Sampler: all_inclusive
[INFO][13:37:08]: [Client #370] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:37:08]: [Client #74] Dataset size: 164
[INFO][13:37:08]: [Client #74] Sampler: all_inclusive
[INFO][13:37:08]: [93m[1m[Client #370] Started training in communication round #4.[0m
[INFO][13:37:08]: [Client #74] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:37:08]: [93m[1m[Client #74] Started training in communication round #4.[0m
[INFO][13:37:10]: [Client #74] Loading the dataset.
[INFO][13:37:10]: [Client #370] Loading the dataset.
[INFO][13:37:15]: [Client #370] Epoch: [1/5][0/17]	Loss: 2.093407
[INFO][13:37:15]: [Client #74] Epoch: [1/5][0/17]	Loss: 2.299680
[INFO][13:37:15]: [Client #370] Epoch: [1/5][10/17]	Loss: 2.259925
[INFO][13:37:15]: [Client #74] Epoch: [1/5][10/17]	Loss: 3.352288
[INFO][13:37:15]: [Client #370] Going to sleep for 0.16 seconds.
[INFO][13:37:15]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][13:37:15]: [Client #370] Woke up.
[INFO][13:37:15]: [Client #370] Epoch: [2/5][0/17]	Loss: 3.063328
[INFO][13:37:16]: [Client #370] Epoch: [2/5][10/17]	Loss: 2.587348
[INFO][13:37:16]: [Client #370] Going to sleep for 0.16 seconds.
[INFO][13:37:16]: [Client #370] Woke up.
[INFO][13:37:16]: [Client #370] Epoch: [3/5][0/17]	Loss: 2.381011
[INFO][13:37:16]: [Client #370] Epoch: [3/5][10/17]	Loss: 2.450904
[INFO][13:37:16]: [Client #370] Going to sleep for 0.16 seconds.
[INFO][13:37:16]: [Client #370] Woke up.
[INFO][13:37:16]: [Client #370] Epoch: [4/5][0/17]	Loss: 2.892067
[INFO][13:37:16]: [Client #370] Epoch: [4/5][10/17]	Loss: 2.043090
[INFO][13:37:16]: [Client #370] Going to sleep for 0.16 seconds.
[INFO][13:37:16]: [Client #370] Woke up.
[INFO][13:37:16]: [Client #370] Epoch: [5/5][0/17]	Loss: 2.430948
[INFO][13:37:16]: [Client #370] Epoch: [5/5][10/17]	Loss: 2.636360
[INFO][13:37:16]: [Client #370] Going to sleep for 0.16 seconds.
[INFO][13:37:17]: [Client #370] Woke up.
[INFO][13:37:17]: [Client #370] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_370_615875.pth.
[INFO][13:37:17]: [Client #370] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_370_615875.pth.
[INFO][13:37:17]: [Client #370] Model trained.
[INFO][13:37:17]: [Client #370] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:37:17]: [Server #615782] Received 0.26 MB of payload data from client #370 (simulated).
[INFO][13:37:20]: [Client #74] Woke up.
[INFO][13:37:20]: [Client #74] Epoch: [2/5][0/17]	Loss: 3.332388
[INFO][13:37:20]: [Client #74] Epoch: [2/5][10/17]	Loss: 3.348429
[INFO][13:37:20]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][13:37:24]: [Client #74] Woke up.
[INFO][13:37:24]: [Client #74] Epoch: [3/5][0/17]	Loss: 3.130610
[INFO][13:37:24]: [Client #74] Epoch: [3/5][10/17]	Loss: 2.641496
[INFO][13:37:24]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][13:37:28]: [Client #74] Woke up.
[INFO][13:37:28]: [Client #74] Epoch: [4/5][0/17]	Loss: 2.232564
[INFO][13:37:28]: [Client #74] Epoch: [4/5][10/17]	Loss: 1.996340
[INFO][13:37:28]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][13:37:33]: [Client #74] Woke up.
[INFO][13:37:33]: [Client #74] Epoch: [5/5][0/17]	Loss: 2.621165
[INFO][13:37:33]: [Client #74] Epoch: [5/5][10/17]	Loss: 2.381664
[INFO][13:37:33]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][13:37:37]: [Client #74] Woke up.
[INFO][13:37:37]: [Client #74] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_615874.pth.
[INFO][13:37:38]: [Client #74] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_615874.pth.
[INFO][13:37:38]: [Client #74] Model trained.
[INFO][13:37:38]: [Client #74] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:37:38]: [Server #615782] Received 0.26 MB of payload data from client #74 (simulated).
[INFO][13:37:38]: [Server #615782] Selecting client #123 for training.
[INFO][13:37:38]: [Server #615782] Sending the current model to client #123 (simulated).
[INFO][13:37:38]: [Server #615782] Sending 0.26 MB of payload data to client #123 (simulated).
[INFO][13:37:38]: [Server #615782] Selecting client #635 for training.
[INFO][13:37:38]: [Server #615782] Sending the current model to client #635 (simulated).
[INFO][13:37:38]: [Server #615782] Sending 0.26 MB of payload data to client #635 (simulated).
[INFO][13:37:38]: [Client #123] Selected by the server.
[INFO][13:37:38]: [Client #123] Loading its data source...
[INFO][13:37:38]: Data source: FEMNIST
[INFO][13:37:38]: [Client #635] Selected by the server.
[INFO][13:37:38]: [Client #635] Loading its data source...
[INFO][13:37:38]: Data source: FEMNIST
[INFO][13:37:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:37:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/635.zip.
[INFO][13:37:38]: [Client #123] Dataset size: 349
[INFO][13:37:38]: [Client #123] Sampler: all_inclusive
[INFO][13:37:38]: [Client #123] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:37:38]: [93m[1m[Client #123] Started training in communication round #4.[0m
2.4%4.8%7.2%9.6%12.0%14.3%16.7%19.1%21.5%23.9%26.3%28.7%31.1%33.5%35.9%38.2%40.6%43.0%45.4%47.8%50.2%52.6%55.0%57.4%59.8%62.2%64.5%66.9%69.3%71.7%74.1%76.5%78.9%81.3%83.7%86.1%88.4%90.8%93.2%95.6%98.0%100.0%[INFO][13:37:38]: Decompressing the dataset downloaded.
[INFO][13:37:38]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/635.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:37:38]: [Client #635] Dataset size: 156
[INFO][13:37:38]: [Client #635] Sampler: all_inclusive
[INFO][13:37:38]: [Client #635] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:37:38]: [93m[1m[Client #635] Started training in communication round #4.[0m

[INFO][13:37:40]: [Client #123] Loading the dataset.
[INFO][13:37:40]: [Client #635] Loading the dataset.
[INFO][13:37:45]: [Client #123] Epoch: [1/5][0/35]	Loss: 4.107718
[INFO][13:37:45]: [Client #635] Epoch: [1/5][0/16]	Loss: 3.093557
[INFO][13:37:45]: [Client #123] Epoch: [1/5][10/35]	Loss: 3.726760
[INFO][13:37:45]: [Client #635] Epoch: [1/5][10/16]	Loss: 1.834988
[INFO][13:37:45]: [Client #123] Epoch: [1/5][20/35]	Loss: 3.319238
[INFO][13:37:45]: [Client #635] Going to sleep for 3.59 seconds.
[INFO][13:37:45]: [Client #123] Epoch: [1/5][30/35]	Loss: 3.560794
[INFO][13:37:45]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][13:37:46]: [Client #123] Woke up.
[INFO][13:37:46]: [Client #123] Epoch: [2/5][0/35]	Loss: 3.076008
[INFO][13:37:46]: [Client #123] Epoch: [2/5][10/35]	Loss: 3.717417
[INFO][13:37:46]: [Client #123] Epoch: [2/5][20/35]	Loss: 3.341904
[INFO][13:37:46]: [Client #123] Epoch: [2/5][30/35]	Loss: 2.203445
[INFO][13:37:46]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][13:37:46]: [Client #123] Woke up.
[INFO][13:37:46]: [Client #123] Epoch: [3/5][0/35]	Loss: 1.893945
[INFO][13:37:46]: [Client #123] Epoch: [3/5][10/35]	Loss: 2.685277
[INFO][13:37:46]: [Client #123] Epoch: [3/5][20/35]	Loss: 2.887378
[INFO][13:37:46]: [Client #123] Epoch: [3/5][30/35]	Loss: 2.804256
[INFO][13:37:46]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][13:37:46]: [Client #123] Woke up.
[INFO][13:37:46]: [Client #123] Epoch: [4/5][0/35]	Loss: 2.191774
[INFO][13:37:46]: [Client #123] Epoch: [4/5][10/35]	Loss: 1.397606
[INFO][13:37:46]: [Client #123] Epoch: [4/5][20/35]	Loss: 3.204538
[INFO][13:37:46]: [Client #123] Epoch: [4/5][30/35]	Loss: 2.404359
[INFO][13:37:46]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][13:37:46]: [Client #123] Woke up.
[INFO][13:37:46]: [Client #123] Epoch: [5/5][0/35]	Loss: 1.542032
[INFO][13:37:47]: [Client #123] Epoch: [5/5][10/35]	Loss: 1.462828
[INFO][13:37:47]: [Client #123] Epoch: [5/5][20/35]	Loss: 2.432981
[INFO][13:37:47]: [Client #123] Epoch: [5/5][30/35]	Loss: 1.796738
[INFO][13:37:47]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][13:37:47]: [Client #123] Woke up.
[INFO][13:37:47]: [Client #123] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_615874.pth.
[INFO][13:37:47]: [Client #123] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_615874.pth.
[INFO][13:37:47]: [Client #123] Model trained.
[INFO][13:37:47]: [Client #123] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:37:47]: [Server #615782] Received 0.26 MB of payload data from client #123 (simulated).
[INFO][13:37:49]: [Client #635] Woke up.
[INFO][13:37:49]: [Client #635] Epoch: [2/5][0/16]	Loss: 2.907578
[INFO][13:37:49]: [Client #635] Epoch: [2/5][10/16]	Loss: 2.524257
[INFO][13:37:49]: [Client #635] Going to sleep for 3.59 seconds.
[INFO][13:37:53]: [Client #635] Woke up.
[INFO][13:37:53]: [Client #635] Epoch: [3/5][0/16]	Loss: 1.495912
[INFO][13:37:53]: [Client #635] Epoch: [3/5][10/16]	Loss: 1.662290
[INFO][13:37:53]: [Client #635] Going to sleep for 3.59 seconds.
[INFO][13:37:56]: [Client #635] Woke up.
[INFO][13:37:56]: [Client #635] Epoch: [4/5][0/16]	Loss: 1.083395
[INFO][13:37:57]: [Client #635] Epoch: [4/5][10/16]	Loss: 2.075498
[INFO][13:37:57]: [Client #635] Going to sleep for 3.59 seconds.
[INFO][13:38:00]: [Client #635] Woke up.
[INFO][13:38:00]: [Client #635] Epoch: [5/5][0/16]	Loss: 1.845245
[INFO][13:38:00]: [Client #635] Epoch: [5/5][10/16]	Loss: 2.434068
[INFO][13:38:00]: [Client #635] Going to sleep for 3.59 seconds.
[INFO][13:38:04]: [Client #635] Woke up.
[INFO][13:38:04]: [Client #635] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_635_615875.pth.
[INFO][13:38:05]: [Client #635] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_635_615875.pth.
[INFO][13:38:05]: [Client #635] Model trained.
[INFO][13:38:05]: [Client #635] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:38:05]: [Server #615782] Received 0.26 MB of payload data from client #635 (simulated).
[INFO][13:38:05]: [Server #615782] Selecting client #414 for training.
[INFO][13:38:05]: [Server #615782] Sending the current model to client #414 (simulated).
[INFO][13:38:05]: [Server #615782] Sending 0.26 MB of payload data to client #414 (simulated).
[INFO][13:38:05]: [Server #615782] Selecting client #991 for training.
[INFO][13:38:05]: [Server #615782] Sending the current model to client #991 (simulated).
[INFO][13:38:05]: [Server #615782] Sending 0.26 MB of payload data to client #991 (simulated).
[INFO][13:38:05]: [Client #414] Selected by the server.
[INFO][13:38:05]: [Client #991] Selected by the server.
[INFO][13:38:05]: [Client #991] Loading its data source...
[INFO][13:38:05]: [Client #414] Loading its data source...
[INFO][13:38:05]: Data source: FEMNIST
[INFO][13:38:05]: Data source: FEMNIST
[INFO][13:38:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:38:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/991.zip.
[INFO][13:38:05]: [Client #414] Dataset size: 153
[INFO][13:38:05]: [Client #414] Sampler: all_inclusive
[INFO][13:38:05]: [Client #414] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:05]: [93m[1m[Client #414] Started training in communication round #4.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.0%27.5%30.0%32.5%35.0%37.5%40.0%42.5%45.0%47.5%50.0%52.5%55.0%57.5%60.0%62.5%65.0%67.5%70.0%72.5%75.0%77.5%80.0%82.6%85.1%87.6%90.1%92.6%95.1%97.6%100.0%[INFO][13:38:05]: Decompressing the dataset downloaded.
[INFO][13:38:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/991.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:38:05]: [Client #991] Dataset size: 162
[INFO][13:38:05]: [Client #991] Sampler: all_inclusive
[INFO][13:38:05]: [Client #991] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:05]: [93m[1m[Client #991] Started training in communication round #4.[0m

[INFO][13:38:07]: [Client #414] Loading the dataset.
[INFO][13:38:07]: [Client #991] Loading the dataset.
[INFO][13:38:13]: [Client #414] Epoch: [1/5][0/16]	Loss: 2.499135
[INFO][13:38:13]: [Client #991] Epoch: [1/5][0/17]	Loss: 2.688779
[INFO][13:38:13]: [Client #414] Epoch: [1/5][10/16]	Loss: 2.866876
[INFO][13:38:13]: [Client #991] Epoch: [1/5][10/17]	Loss: 1.795664
[INFO][13:38:13]: [Client #414] Going to sleep for 2.30 seconds.
[INFO][13:38:13]: [Client #991] Going to sleep for 4.33 seconds.
[INFO][13:38:15]: [Client #414] Woke up.
[INFO][13:38:15]: [Client #414] Epoch: [2/5][0/16]	Loss: 2.705905
[INFO][13:38:15]: [Client #414] Epoch: [2/5][10/16]	Loss: 3.032535
[INFO][13:38:15]: [Client #414] Going to sleep for 2.30 seconds.
[INFO][13:38:17]: [Client #991] Woke up.
[INFO][13:38:17]: [Client #991] Epoch: [2/5][0/17]	Loss: 3.046498
[INFO][13:38:17]: [Client #991] Epoch: [2/5][10/17]	Loss: 2.726626
[INFO][13:38:17]: [Client #991] Going to sleep for 4.33 seconds.
[INFO][13:38:17]: [Client #414] Woke up.
[INFO][13:38:17]: [Client #414] Epoch: [3/5][0/16]	Loss: 3.021200
[INFO][13:38:18]: [Client #414] Epoch: [3/5][10/16]	Loss: 2.540236
[INFO][13:38:18]: [Client #414] Going to sleep for 2.30 seconds.
[INFO][13:38:20]: [Client #414] Woke up.
[INFO][13:38:20]: [Client #414] Epoch: [4/5][0/16]	Loss: 2.271594
[INFO][13:38:20]: [Client #414] Epoch: [4/5][10/16]	Loss: 2.520268
[INFO][13:38:20]: [Client #414] Going to sleep for 2.30 seconds.
[INFO][13:38:22]: [Client #991] Woke up.
[INFO][13:38:22]: [Client #991] Epoch: [3/5][0/17]	Loss: 1.188401
[INFO][13:38:22]: [Client #991] Epoch: [3/5][10/17]	Loss: 2.591292
[INFO][13:38:22]: [Client #991] Going to sleep for 4.33 seconds.
[INFO][13:38:22]: [Client #414] Woke up.
[INFO][13:38:22]: [Client #414] Epoch: [5/5][0/16]	Loss: 1.922354
[INFO][13:38:22]: [Client #414] Epoch: [5/5][10/16]	Loss: 2.658990
[INFO][13:38:23]: [Client #414] Going to sleep for 2.30 seconds.
[INFO][13:38:25]: [Client #414] Woke up.
[INFO][13:38:25]: [Client #414] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_414_615874.pth.
[INFO][13:38:25]: [Client #414] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_414_615874.pth.
[INFO][13:38:25]: [Client #414] Model trained.
[INFO][13:38:25]: [Client #414] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:38:25]: [Server #615782] Received 0.26 MB of payload data from client #414 (simulated).
[INFO][13:38:26]: [Client #991] Woke up.
[INFO][13:38:26]: [Client #991] Epoch: [4/5][0/17]	Loss: 2.123360
[INFO][13:38:26]: [Client #991] Epoch: [4/5][10/17]	Loss: 2.540247
[INFO][13:38:26]: [Client #991] Going to sleep for 4.33 seconds.
[INFO][13:38:31]: [Client #991] Woke up.
[INFO][13:38:31]: [Client #991] Epoch: [5/5][0/17]	Loss: 3.177293
[INFO][13:38:31]: [Client #991] Epoch: [5/5][10/17]	Loss: 2.277478
[INFO][13:38:31]: [Client #991] Going to sleep for 4.33 seconds.
[INFO][13:38:35]: [Client #991] Woke up.
[INFO][13:38:35]: [Client #991] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_991_615875.pth.
[INFO][13:38:36]: [Client #991] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_991_615875.pth.
[INFO][13:38:36]: [Client #991] Model trained.
[INFO][13:38:36]: [Client #991] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:38:36]: [Server #615782] Received 0.26 MB of payload data from client #991 (simulated).
[INFO][13:38:36]: [Server #615782] Selecting client #931 for training.
[INFO][13:38:36]: [Server #615782] Sending the current model to client #931 (simulated).
[INFO][13:38:36]: [Server #615782] Sending 0.26 MB of payload data to client #931 (simulated).
[INFO][13:38:36]: [Server #615782] Selecting client #149 for training.
[INFO][13:38:36]: [Server #615782] Sending the current model to client #149 (simulated).
[INFO][13:38:36]: [Server #615782] Sending 0.26 MB of payload data to client #149 (simulated).
[INFO][13:38:36]: [Client #149] Selected by the server.
[INFO][13:38:36]: [Client #931] Selected by the server.
[INFO][13:38:36]: [Client #149] Loading its data source...
[INFO][13:38:36]: [Client #931] Loading its data source...
[INFO][13:38:36]: Data source: FEMNIST
[INFO][13:38:36]: Data source: FEMNIST
[INFO][13:38:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:38:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/931.zip.
[INFO][13:38:36]: [Client #149] Dataset size: 148
[INFO][13:38:36]: [Client #149] Sampler: all_inclusive
[INFO][13:38:36]: [Client #149] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:36]: [93m[1m[Client #149] Started training in communication round #4.[0m
2.9%5.8%8.8%11.7%14.6%17.5%20.5%23.4%26.3%29.2%32.1%35.1%38.0%40.9%43.8%46.8%49.7%52.6%55.5%58.4%61.4%64.3%67.2%70.1%73.1%76.0%78.9%81.8%84.8%87.7%90.6%93.5%96.4%99.4%100.0%[INFO][13:38:36]: Decompressing the dataset downloaded.
[INFO][13:38:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/931.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:38:36]: [Client #931] Dataset size: 135
[INFO][13:38:36]: [Client #931] Sampler: all_inclusive
[INFO][13:38:36]: [Client #931] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:36]: [93m[1m[Client #931] Started training in communication round #4.[0m

[INFO][13:38:38]: [Client #149] Loading the dataset.
[INFO][13:38:38]: [Client #931] Loading the dataset.
[INFO][13:38:43]: [Client #931] Epoch: [1/5][0/14]	Loss: 3.269381
[INFO][13:38:43]: [Client #149] Epoch: [1/5][0/15]	Loss: 3.092359
[INFO][13:38:43]: [Client #931] Epoch: [1/5][10/14]	Loss: 1.636710
[INFO][13:38:43]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][13:38:43]: [Client #149] Epoch: [1/5][10/15]	Loss: 2.831544
[INFO][13:38:43]: [Client #931] Woke up.
[INFO][13:38:43]: [Client #149] Going to sleep for 1.27 seconds.
[INFO][13:38:43]: [Client #931] Epoch: [2/5][0/14]	Loss: 2.030957
[INFO][13:38:44]: [Client #931] Epoch: [2/5][10/14]	Loss: 2.809001
[INFO][13:38:44]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][13:38:44]: [Client #931] Woke up.
[INFO][13:38:44]: [Client #931] Epoch: [3/5][0/14]	Loss: 2.667594
[INFO][13:38:44]: [Client #931] Epoch: [3/5][10/14]	Loss: 1.546514
[INFO][13:38:44]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][13:38:44]: [Client #931] Woke up.
[INFO][13:38:44]: [Client #931] Epoch: [4/5][0/14]	Loss: 2.510718
[INFO][13:38:44]: [Client #931] Epoch: [4/5][10/14]	Loss: 2.155492
[INFO][13:38:44]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][13:38:44]: [Client #931] Woke up.
[INFO][13:38:44]: [Client #931] Epoch: [5/5][0/14]	Loss: 2.069103
[INFO][13:38:44]: [Client #931] Epoch: [5/5][10/14]	Loss: 1.717413
[INFO][13:38:44]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][13:38:44]: [Client #931] Woke up.
[INFO][13:38:44]: [Client #931] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_931_615874.pth.
[INFO][13:38:45]: [Client #149] Woke up.
[INFO][13:38:45]: [Client #149] Epoch: [2/5][0/15]	Loss: 1.358674
[INFO][13:38:45]: [Client #149] Epoch: [2/5][10/15]	Loss: 2.664602
[INFO][13:38:45]: [Client #149] Going to sleep for 1.27 seconds.
[INFO][13:38:45]: [Client #931] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_931_615874.pth.
[INFO][13:38:45]: [Client #931] Model trained.
[INFO][13:38:45]: [Client #931] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:38:45]: [Server #615782] Received 0.26 MB of payload data from client #931 (simulated).
[INFO][13:38:46]: [Client #149] Woke up.
[INFO][13:38:46]: [Client #149] Epoch: [3/5][0/15]	Loss: 1.622743
[INFO][13:38:46]: [Client #149] Epoch: [3/5][10/15]	Loss: 2.337552
[INFO][13:38:46]: [Client #149] Going to sleep for 1.27 seconds.
[INFO][13:38:48]: [Client #149] Woke up.
[INFO][13:38:48]: [Client #149] Epoch: [4/5][0/15]	Loss: 1.655244
[INFO][13:38:48]: [Client #149] Epoch: [4/5][10/15]	Loss: 2.491809
[INFO][13:38:48]: [Client #149] Going to sleep for 1.27 seconds.
[INFO][13:38:49]: [Client #149] Woke up.
[INFO][13:38:49]: [Client #149] Epoch: [5/5][0/15]	Loss: 1.654729
[INFO][13:38:49]: [Client #149] Epoch: [5/5][10/15]	Loss: 1.623226
[INFO][13:38:49]: [Client #149] Going to sleep for 1.27 seconds.
[INFO][13:38:50]: [Client #149] Woke up.
[INFO][13:38:50]: [Client #149] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_149_615875.pth.
[INFO][13:38:51]: [Client #149] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_149_615875.pth.
[INFO][13:38:51]: [Client #149] Model trained.
[INFO][13:38:51]: [Client #149] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:38:51]: [Server #615782] Received 0.26 MB of payload data from client #149 (simulated).
[INFO][13:38:51]: [Server #615782] Selecting client #395 for training.
[INFO][13:38:51]: [Server #615782] Sending the current model to client #395 (simulated).
[INFO][13:38:51]: [Server #615782] Sending 0.26 MB of payload data to client #395 (simulated).
[INFO][13:38:51]: [Server #615782] Selecting client #459 for training.
[INFO][13:38:51]: [Server #615782] Sending the current model to client #459 (simulated).
[INFO][13:38:51]: [Server #615782] Sending 0.26 MB of payload data to client #459 (simulated).
[INFO][13:38:51]: [Client #395] Selected by the server.
[INFO][13:38:51]: [Client #395] Loading its data source...
[INFO][13:38:51]: [Client #459] Selected by the server.
[INFO][13:38:51]: Data source: FEMNIST
[INFO][13:38:51]: [Client #459] Loading its data source...
[INFO][13:38:51]: Data source: FEMNIST
[INFO][13:38:51]: [Client #459] Dataset size: 165
[INFO][13:38:51]: [Client #459] Sampler: all_inclusive
[INFO][13:38:51]: [Client #395] Dataset size: 153
[INFO][13:38:51]: [Client #395] Sampler: all_inclusive
[INFO][13:38:51]: [Client #459] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:51]: [Client #395] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:38:51]: [93m[1m[Client #395] Started training in communication round #4.[0m
[INFO][13:38:51]: [93m[1m[Client #459] Started training in communication round #4.[0m
[INFO][13:38:53]: [Client #459] Loading the dataset.
[INFO][13:38:53]: [Client #395] Loading the dataset.
[INFO][13:38:59]: [Client #395] Epoch: [1/5][0/16]	Loss: 2.812058
[INFO][13:38:59]: [Client #459] Epoch: [1/5][0/17]	Loss: 2.340921
[INFO][13:38:59]: [Client #395] Epoch: [1/5][10/16]	Loss: 3.381873
[INFO][13:38:59]: [Client #459] Epoch: [1/5][10/17]	Loss: 2.898286
[INFO][13:38:59]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][13:38:59]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:39:00]: [Client #459] Woke up.
[INFO][13:39:00]: [Client #459] Epoch: [2/5][0/17]	Loss: 2.838158
[INFO][13:39:00]: [Client #459] Epoch: [2/5][10/17]	Loss: 1.948053
[INFO][13:39:00]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:39:00]: [Client #459] Woke up.
[INFO][13:39:00]: [Client #459] Epoch: [3/5][0/17]	Loss: 3.297678
[INFO][13:39:00]: [Client #459] Epoch: [3/5][10/17]	Loss: 2.034086
[INFO][13:39:00]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:39:01]: [Client #459] Woke up.
[INFO][13:39:01]: [Client #459] Epoch: [4/5][0/17]	Loss: 2.489616
[INFO][13:39:01]: [Client #459] Epoch: [4/5][10/17]	Loss: 1.821320
[INFO][13:39:01]: [Client #395] Woke up.
[INFO][13:39:01]: [Client #395] Epoch: [2/5][0/16]	Loss: 3.108580
[INFO][13:39:01]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:39:01]: [Client #395] Epoch: [2/5][10/16]	Loss: 2.023495
[INFO][13:39:01]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][13:39:01]: [Client #459] Woke up.
[INFO][13:39:01]: [Client #459] Epoch: [5/5][0/17]	Loss: 2.269488
[INFO][13:39:01]: [Client #459] Epoch: [5/5][10/17]	Loss: 2.434182
[INFO][13:39:01]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:39:02]: [Client #459] Woke up.
[INFO][13:39:02]: [Client #459] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_615875.pth.
[INFO][13:39:02]: [Client #459] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_615875.pth.
[INFO][13:39:02]: [Client #459] Model trained.
[INFO][13:39:02]: [Client #459] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:39:02]: [Server #615782] Received 0.26 MB of payload data from client #459 (simulated).
[INFO][13:39:03]: [Client #395] Woke up.
[INFO][13:39:03]: [Client #395] Epoch: [3/5][0/16]	Loss: 2.775084
[INFO][13:39:03]: [Client #395] Epoch: [3/5][10/16]	Loss: 2.885612
[INFO][13:39:03]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][13:39:04]: [Client #395] Woke up.
[INFO][13:39:04]: [Client #395] Epoch: [4/5][0/16]	Loss: 2.025840
[INFO][13:39:04]: [Client #395] Epoch: [4/5][10/16]	Loss: 3.043301
[INFO][13:39:04]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][13:39:06]: [Client #395] Woke up.
[INFO][13:39:06]: [Client #395] Epoch: [5/5][0/16]	Loss: 2.274999
[INFO][13:39:06]: [Client #395] Epoch: [5/5][10/16]	Loss: 2.381156
[INFO][13:39:06]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][13:39:07]: [Client #395] Woke up.
[INFO][13:39:07]: [Client #395] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_395_615874.pth.
[INFO][13:39:08]: [Client #395] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_395_615874.pth.
[INFO][13:39:08]: [Client #395] Model trained.
[INFO][13:39:08]: [Client #395] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:39:08]: [Server #615782] Received 0.26 MB of payload data from client #395 (simulated).
[INFO][13:39:08]: [Server #615782] Adding client #931 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #658 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #197 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #636 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #151 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #370 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #123 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #582 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #518 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #668 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #305 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #380 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #872 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #992 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #459 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #337 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #900 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #429 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #75 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #529 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #235 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #725 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #849 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #909 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Adding client #993 to the list of clients for aggregation.
[INFO][13:39:08]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09530599 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.48349592 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13112869 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09825697 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07152872 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08517858 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09507535 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.37466252 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09755238 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09811293 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11309809 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12464014 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.22035889 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07288315
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06545488
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1452405  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12665908 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11855646 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13934522 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09606    0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.31136549
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11314333 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06143518 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09383333 0.09750912 0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09530599 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.48349592 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13112869 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09825697 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07152872 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08517858 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09507535 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.37466252 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09755238 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09811293 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11309809 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12464014 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.22035889 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07288315
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06545488
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1452405  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12665908 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11855646 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13934522 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09606    0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.31136549
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11314333 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06143518 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09383333 0.09750912 0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.03333333 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03395445 0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.001      0.001
 0.001      0.001      0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03416149
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.05656805 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.001      0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0212766  0.001
 0.001      0.001      0.03932316 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03881657 0.001      0.001      0.001
 0.001      0.03836988 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.05652174 0.001
 0.001      0.001      0.02284735 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.0310559  0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02084821 0.001      0.001      0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.02056262 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03288847
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02199058 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0212766  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02441811 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.001      0.001      0.001      0.001      0.01670713 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02857143 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02284735 0.001      0.001      0.001      0.001
 0.001      0.03431953 0.0386082  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.001      0.02184778
 0.001      0.001      0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.001      0.03739645 0.001      0.001
 0.001      0.001      0.001      0.001      0.02141939 0.01925466
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.001
 0.001      0.01742111 0.001      0.02213337 0.001      0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0321735  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02256176 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.001      0.001     ][INFO][13:39:52]: [Server #615782] Global model accuracy: 30.20%

[INFO][13:39:52]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_4.pth.
[INFO][13:39:52]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_4.pth.
[INFO][13:39:52]: [93m[1m
[Server #615782] Starting round 5/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5756e+00  1e+03  1e+00  1e+00
 1:  7.4998e+00  6.5767e+00  1e+01  1e-02  1e-02
 2:  7.5749e+00  6.6680e+00  1e+00  9e-05  9e-05
 3:  7.5756e+00  7.4975e+00  8e-02  4e-07  4e-07
 4:  7.5756e+00  7.5748e+00  8e-04  4e-09  4e-09
 5:  7.5756e+00  7.5756e+00  8e-06  4e-11  4e-11
 6:  7.5756e+00  7.5756e+00  8e-08  4e-13  4e-13
Optimal solution found.
The calculated probability is:  [0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102502 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00092967 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102413 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102495 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102544 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102515
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.001025   0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00101243 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102492 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102481 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102452 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102432 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102109 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.0010254  0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102551 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102386 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102461
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.0010246  0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102392 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102496 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00099266 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102474 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102556 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102512 0.00102493 0.00102581 0.00102581 0.00102581 0.00102581
 0.00102581 0.00102581 0.00102581][INFO][13:39:54]: [Server #615782] Selected clients: [558 778 486 419 261 912  22 818 187 683 354 974 121 186 890 580 307   1
 227 143 204 897 873 698 469]
[INFO][13:39:54]: [Server #615782] Selecting client #558 for training.
[INFO][13:39:54]: [Server #615782] Sending the current model to client #558 (simulated).
[INFO][13:39:54]: [Server #615782] Sending 0.26 MB of payload data to client #558 (simulated).
[INFO][13:39:54]: [Server #615782] Selecting client #778 for training.
[INFO][13:39:54]: [Server #615782] Sending the current model to client #778 (simulated).
[INFO][13:39:54]: [Server #615782] Sending 0.26 MB of payload data to client #778 (simulated).
[INFO][13:39:54]: [Client #558] Selected by the server.
[INFO][13:39:54]: [Client #558] Loading its data source...
[INFO][13:39:54]: Data source: FEMNIST
[INFO][13:39:54]: [Client #778] Selected by the server.
[INFO][13:39:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:39:54]: [Client #778] Loading its data source...
[INFO][13:39:54]: Data source: FEMNIST
[INFO][13:39:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/558.zip.
[INFO][13:39:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:39:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/778.zip.
1.9%3.8%5.7%7.6%9.5%11.4%13.2%15.1%17.0%18.9%20.8%22.7%24.6%26.5%28.4%30.3%32.2%2.4%4.7%7.1%34.1%36.0%37.9%39.7%41.6%43.5%45.4%47.3%49.2%51.1%53.0%54.9%56.8%58.7%60.6%62.5%64.4%66.2%68.1%70.0%71.9%73.8%75.7%77.6%79.5%81.4%83.3%85.2%87.1%89.0%90.8%92.7%94.6%96.5%98.4%100.0%[INFO][13:39:54]: Decompressing the dataset downloaded.
[INFO][13:39:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/778.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
9.4%11.8%14.1%16.5%18.8%21.2%23.5%25.9%28.2%30.6%32.9%35.3%37.6%40.0%42.3%44.7%47.0%49.4%51.7%54.1%56.4%58.8%61.1%63.5%65.8%68.2%70.5%72.9%75.2%77.6%79.9%82.3%84.6%87.0%89.3%91.7%94.0%96.4%98.7%100.0%[INFO][13:39:54]: Decompressing the dataset downloaded.
[INFO][13:39:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/558.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:39:54]: [Client #558] Dataset size: 149
[INFO][13:39:54]: [Client #558] Sampler: all_inclusive
[INFO][13:39:54]: [Client #558] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:39:54]: [Client #778] Dataset size: 278
[INFO][13:39:54]: [Client #778] Sampler: all_inclusive
[INFO][13:39:54]: [93m[1m[Client #558] Started training in communication round #5.[0m

[INFO][13:39:54]: [Client #778] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:39:54]: [93m[1m[Client #778] Started training in communication round #5.[0m

[INFO][13:39:56]: [Client #778] Loading the dataset.
[INFO][13:39:56]: [Client #558] Loading the dataset.
[INFO][13:40:01]: [Client #558] Epoch: [1/5][0/15]	Loss: 2.287105
[INFO][13:40:02]: [Client #778] Epoch: [1/5][0/28]	Loss: 3.264896
[INFO][13:40:02]: [Client #558] Epoch: [1/5][10/15]	Loss: 2.305614
[INFO][13:40:02]: [Client #778] Epoch: [1/5][10/28]	Loss: 3.067825
[INFO][13:40:02]: [Client #558] Going to sleep for 2.07 seconds.
[INFO][13:40:02]: [Client #778] Epoch: [1/5][20/28]	Loss: 3.016346
[INFO][13:40:02]: [Client #778] Going to sleep for 0.21 seconds.
[INFO][13:40:02]: [Client #778] Woke up.
[INFO][13:40:02]: [Client #778] Epoch: [2/5][0/28]	Loss: 3.575147
[INFO][13:40:02]: [Client #778] Epoch: [2/5][10/28]	Loss: 3.067317
[INFO][13:40:02]: [Client #778] Epoch: [2/5][20/28]	Loss: 3.294048
[INFO][13:40:02]: [Client #778] Going to sleep for 0.21 seconds.
[INFO][13:40:02]: [Client #778] Woke up.
[INFO][13:40:02]: [Client #778] Epoch: [3/5][0/28]	Loss: 2.300264
[INFO][13:40:03]: [Client #778] Epoch: [3/5][10/28]	Loss: 1.925268
[INFO][13:40:03]: [Client #778] Epoch: [3/5][20/28]	Loss: 3.111937
[INFO][13:40:03]: [Client #778] Going to sleep for 0.21 seconds.
[INFO][13:40:03]: [Client #778] Woke up.
[INFO][13:40:03]: [Client #778] Epoch: [4/5][0/28]	Loss: 2.626072
[INFO][13:40:03]: [Client #778] Epoch: [4/5][10/28]	Loss: 3.203085
[INFO][13:40:03]: [Client #778] Epoch: [4/5][20/28]	Loss: 2.966827
[INFO][13:40:03]: [Client #778] Going to sleep for 0.21 seconds.
[INFO][13:40:03]: [Client #778] Woke up.
[INFO][13:40:03]: [Client #778] Epoch: [5/5][0/28]	Loss: 2.099980
[INFO][13:40:03]: [Client #778] Epoch: [5/5][10/28]	Loss: 2.090170
[INFO][13:40:04]: [Client #778] Epoch: [5/5][20/28]	Loss: 2.170324
[INFO][13:40:04]: [Client #778] Going to sleep for 0.21 seconds.
[INFO][13:40:04]: [Client #558] Woke up.
[INFO][13:40:04]: [Client #558] Epoch: [2/5][0/15]	Loss: 2.092922
[INFO][13:40:04]: [Client #558] Epoch: [2/5][10/15]	Loss: 2.980846
[INFO][13:40:04]: [Client #778] Woke up.
[INFO][13:40:04]: [Client #778] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_778_615875.pth.
[INFO][13:40:04]: [Client #558] Going to sleep for 2.07 seconds.
[INFO][13:40:05]: [Client #778] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_778_615875.pth.
[INFO][13:40:05]: [Client #778] Model trained.
[INFO][13:40:05]: [Client #778] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:40:05]: [Server #615782] Received 0.26 MB of payload data from client #778 (simulated).
[INFO][13:40:06]: [Client #558] Woke up.
[INFO][13:40:06]: [Client #558] Epoch: [3/5][0/15]	Loss: 1.642340
[INFO][13:40:06]: [Client #558] Epoch: [3/5][10/15]	Loss: 2.014278
[INFO][13:40:06]: [Client #558] Going to sleep for 2.07 seconds.
[INFO][13:40:08]: [Client #558] Woke up.
[INFO][13:40:08]: [Client #558] Epoch: [4/5][0/15]	Loss: 1.227375
[INFO][13:40:08]: [Client #558] Epoch: [4/5][10/15]	Loss: 2.484045
[INFO][13:40:08]: [Client #558] Going to sleep for 2.07 seconds.
[INFO][13:40:10]: [Client #558] Woke up.
[INFO][13:40:10]: [Client #558] Epoch: [5/5][0/15]	Loss: 1.223476
[INFO][13:40:10]: [Client #558] Epoch: [5/5][10/15]	Loss: 1.495050
[INFO][13:40:10]: [Client #558] Going to sleep for 2.07 seconds.
[INFO][13:40:13]: [Client #558] Woke up.
[INFO][13:40:13]: [Client #558] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_558_615874.pth.
[INFO][13:40:13]: [Client #558] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_558_615874.pth.
[INFO][13:40:13]: [Client #558] Model trained.
[INFO][13:40:13]: [Client #558] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:40:13]: [Server #615782] Received 0.26 MB of payload data from client #558 (simulated).
[INFO][13:40:13]: [Server #615782] Selecting client #486 for training.
[INFO][13:40:13]: [Server #615782] Sending the current model to client #486 (simulated).
[INFO][13:40:13]: [Server #615782] Sending 0.26 MB of payload data to client #486 (simulated).
[INFO][13:40:13]: [Server #615782] Selecting client #419 for training.
[INFO][13:40:13]: [Server #615782] Sending the current model to client #419 (simulated).
[INFO][13:40:13]: [Server #615782] Sending 0.26 MB of payload data to client #419 (simulated).
[INFO][13:40:13]: [Client #486] Selected by the server.
[INFO][13:40:13]: [Client #486] Loading its data source...
[INFO][13:40:13]: Data source: FEMNIST
[INFO][13:40:13]: [Client #419] Selected by the server.
[INFO][13:40:13]: [Client #419] Loading its data source...
[INFO][13:40:13]: Data source: FEMNIST
[INFO][13:40:13]: [Client #419] Dataset size: 145
[INFO][13:40:13]: [Client #419] Sampler: all_inclusive
[INFO][13:40:13]: [Client #419] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:40:13]: [93m[1m[Client #419] Started training in communication round #5.[0m
[INFO][13:40:13]: [Client #486] Dataset size: 160
[INFO][13:40:13]: [Client #486] Sampler: all_inclusive
[INFO][13:40:13]: [Client #486] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:40:13]: [93m[1m[Client #486] Started training in communication round #5.[0m
[INFO][13:40:15]: [Client #486] Loading the dataset.
[INFO][13:40:15]: [Client #419] Loading the dataset.
[INFO][13:40:21]: [Client #486] Epoch: [1/5][0/16]	Loss: 2.127056
[INFO][13:40:21]: [Client #419] Epoch: [1/5][0/15]	Loss: 3.290009
[INFO][13:40:21]: [Client #486] Epoch: [1/5][10/16]	Loss: 1.905784
[INFO][13:40:21]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][13:40:21]: [Client #419] Epoch: [1/5][10/15]	Loss: 2.706313
[INFO][13:40:21]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][13:40:23]: [Client #486] Woke up.
[INFO][13:40:23]: [Client #486] Epoch: [2/5][0/16]	Loss: 1.802301
[INFO][13:40:23]: [Client #486] Epoch: [2/5][10/16]	Loss: 2.984514
[INFO][13:40:23]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][13:40:24]: [Client #486] Woke up.
[INFO][13:40:24]: [Client #486] Epoch: [3/5][0/16]	Loss: 2.146177
[INFO][13:40:24]: [Client #486] Epoch: [3/5][10/16]	Loss: 2.050130
[INFO][13:40:25]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][13:40:26]: [Client #419] Woke up.
[INFO][13:40:26]: [Client #419] Epoch: [2/5][0/15]	Loss: 1.513689
[INFO][13:40:26]: [Client #419] Epoch: [2/5][10/15]	Loss: 1.286970
[INFO][13:40:26]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][13:40:26]: [Client #486] Woke up.
[INFO][13:40:26]: [Client #486] Epoch: [4/5][0/16]	Loss: 2.218939
[INFO][13:40:26]: [Client #486] Epoch: [4/5][10/16]	Loss: 1.641108
[INFO][13:40:26]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][13:40:28]: [Client #486] Woke up.
[INFO][13:40:28]: [Client #486] Epoch: [5/5][0/16]	Loss: 1.785264
[INFO][13:40:28]: [Client #486] Epoch: [5/5][10/16]	Loss: 1.663180
[INFO][13:40:28]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][13:40:30]: [Client #486] Woke up.
[INFO][13:40:30]: [Client #486] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_615874.pth.
[INFO][13:40:30]: [Client #419] Woke up.
[INFO][13:40:30]: [Client #419] Epoch: [3/5][0/15]	Loss: 2.690233
[INFO][13:40:31]: [Client #419] Epoch: [3/5][10/15]	Loss: 2.159511
[INFO][13:40:31]: [Client #486] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_615874.pth.
[INFO][13:40:31]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][13:40:31]: [Client #486] Model trained.
[INFO][13:40:31]: [Client #486] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:40:31]: [Server #615782] Received 0.26 MB of payload data from client #486 (simulated).
[INFO][13:40:35]: [Client #419] Woke up.
[INFO][13:40:35]: [Client #419] Epoch: [4/5][0/15]	Loss: 2.064409
[INFO][13:40:35]: [Client #419] Epoch: [4/5][10/15]	Loss: 3.046680
[INFO][13:40:35]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][13:40:40]: [Client #419] Woke up.
[INFO][13:40:40]: [Client #419] Epoch: [5/5][0/15]	Loss: 2.868928
[INFO][13:40:40]: [Client #419] Epoch: [5/5][10/15]	Loss: 2.085769
[INFO][13:40:40]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][13:40:45]: [Client #419] Woke up.
[INFO][13:40:45]: [Client #419] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_615875.pth.
[INFO][13:40:46]: [Client #419] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_615875.pth.
[INFO][13:40:46]: [Client #419] Model trained.
[INFO][13:40:46]: [Client #419] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:40:46]: [Server #615782] Received 0.26 MB of payload data from client #419 (simulated).
[INFO][13:40:46]: [Server #615782] Selecting client #261 for training.
[INFO][13:40:46]: [Server #615782] Sending the current model to client #261 (simulated).
[INFO][13:40:46]: [Server #615782] Sending 0.26 MB of payload data to client #261 (simulated).
[INFO][13:40:46]: [Server #615782] Selecting client #912 for training.
[INFO][13:40:46]: [Server #615782] Sending the current model to client #912 (simulated).
[INFO][13:40:46]: [Server #615782] Sending 0.26 MB of payload data to client #912 (simulated).
[INFO][13:40:46]: [Client #261] Selected by the server.
[INFO][13:40:46]: [Client #912] Selected by the server.
[INFO][13:40:46]: [Client #261] Loading its data source...
[INFO][13:40:46]: [Client #912] Loading its data source...
[INFO][13:40:46]: Data source: FEMNIST
[INFO][13:40:46]: Data source: FEMNIST
[INFO][13:40:46]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:40:46]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/912.zip.
[INFO][13:40:46]: [Client #261] Dataset size: 162
[INFO][13:40:46]: [Client #261] Sampler: all_inclusive
[INFO][13:40:46]: [Client #261] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:40:46]: [93m[1m[Client #261] Started training in communication round #5.[0m
2.7%5.5%8.2%10.9%13.7%16.4%19.1%21.9%24.6%27.4%30.1%32.8%35.6%38.3%41.0%43.8%46.5%49.2%52.0%54.7%57.4%60.2%62.9%65.6%68.4%71.1%73.8%76.6%79.3%82.1%84.8%87.5%90.3%93.0%95.7%98.5%100.0%[INFO][13:40:46]: Decompressing the dataset downloaded.
[INFO][13:40:46]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/912.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:40:46]: [Client #912] Dataset size: 147
[INFO][13:40:46]: [Client #912] Sampler: all_inclusive
[INFO][13:40:46]: [Client #912] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:40:46]: [93m[1m[Client #912] Started training in communication round #5.[0m

[INFO][13:40:48]: [Client #261] Loading the dataset.
[INFO][13:40:48]: [Client #912] Loading the dataset.
[INFO][13:40:53]: [Client #261] Epoch: [1/5][0/17]	Loss: 3.198304
[INFO][13:40:53]: [Client #912] Epoch: [1/5][0/15]	Loss: 1.560932
[INFO][13:40:53]: [Client #261] Epoch: [1/5][10/17]	Loss: 4.132014
[INFO][13:40:53]: [Client #912] Epoch: [1/5][10/15]	Loss: 2.258429
[INFO][13:40:53]: [Client #912] Going to sleep for 0.22 seconds.
[INFO][13:40:53]: [Client #261] Going to sleep for 3.00 seconds.
[INFO][13:40:54]: [Client #912] Woke up.
[INFO][13:40:54]: [Client #912] Epoch: [2/5][0/15]	Loss: 2.448498
[INFO][13:40:54]: [Client #912] Epoch: [2/5][10/15]	Loss: 1.104226
[INFO][13:40:54]: [Client #912] Going to sleep for 0.22 seconds.
[INFO][13:40:54]: [Client #912] Woke up.
[INFO][13:40:54]: [Client #912] Epoch: [3/5][0/15]	Loss: 2.922351
[INFO][13:40:54]: [Client #912] Epoch: [3/5][10/15]	Loss: 2.532128
[INFO][13:40:54]: [Client #912] Going to sleep for 0.22 seconds.
[INFO][13:40:54]: [Client #912] Woke up.
[INFO][13:40:54]: [Client #912] Epoch: [4/5][0/15]	Loss: 1.343027
[INFO][13:40:54]: [Client #912] Epoch: [4/5][10/15]	Loss: 2.743464
[INFO][13:40:54]: [Client #912] Going to sleep for 0.22 seconds.
[INFO][13:40:55]: [Client #912] Woke up.
[INFO][13:40:55]: [Client #912] Epoch: [5/5][0/15]	Loss: 0.660363
[INFO][13:40:55]: [Client #912] Epoch: [5/5][10/15]	Loss: 2.031424
[INFO][13:40:55]: [Client #912] Going to sleep for 0.22 seconds.
[INFO][13:40:55]: [Client #912] Woke up.
[INFO][13:40:55]: [Client #912] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_912_615875.pth.
[INFO][13:40:56]: [Client #912] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_912_615875.pth.
[INFO][13:40:56]: [Client #912] Model trained.
[INFO][13:40:56]: [Client #912] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:40:56]: [Server #615782] Received 0.26 MB of payload data from client #912 (simulated).
[INFO][13:40:56]: [Client #261] Woke up.
[INFO][13:40:56]: [Client #261] Epoch: [2/5][0/17]	Loss: 2.379416
[INFO][13:40:56]: [Client #261] Epoch: [2/5][10/17]	Loss: 3.874673
[INFO][13:40:57]: [Client #261] Going to sleep for 3.00 seconds.
[INFO][13:41:00]: [Client #261] Woke up.
[INFO][13:41:00]: [Client #261] Epoch: [3/5][0/17]	Loss: 2.946453
[INFO][13:41:00]: [Client #261] Epoch: [3/5][10/17]	Loss: 2.368590
[INFO][13:41:00]: [Client #261] Going to sleep for 3.00 seconds.
[INFO][13:41:03]: [Client #261] Woke up.
[INFO][13:41:03]: [Client #261] Epoch: [4/5][0/17]	Loss: 3.582469
[INFO][13:41:03]: [Client #261] Epoch: [4/5][10/17]	Loss: 2.371460
[INFO][13:41:03]: [Client #261] Going to sleep for 3.00 seconds.
[INFO][13:41:06]: [Client #261] Woke up.
[INFO][13:41:06]: [Client #261] Epoch: [5/5][0/17]	Loss: 2.429175
[INFO][13:41:06]: [Client #261] Epoch: [5/5][10/17]	Loss: 2.903973
[INFO][13:41:06]: [Client #261] Going to sleep for 3.00 seconds.
[INFO][13:41:09]: [Client #261] Woke up.
[INFO][13:41:09]: [Client #261] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_261_615874.pth.
[INFO][13:41:10]: [Client #261] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_261_615874.pth.
[INFO][13:41:10]: [Client #261] Model trained.
[INFO][13:41:10]: [Client #261] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:41:10]: [Server #615782] Received 0.26 MB of payload data from client #261 (simulated).
[INFO][13:41:10]: [Server #615782] Selecting client #22 for training.
[INFO][13:41:10]: [Server #615782] Sending the current model to client #22 (simulated).
[INFO][13:41:10]: [Server #615782] Sending 0.26 MB of payload data to client #22 (simulated).
[INFO][13:41:10]: [Server #615782] Selecting client #818 for training.
[INFO][13:41:10]: [Server #615782] Sending the current model to client #818 (simulated).
[INFO][13:41:10]: [Server #615782] Sending 0.26 MB of payload data to client #818 (simulated).
[INFO][13:41:10]: [Client #22] Selected by the server.
[INFO][13:41:10]: [Client #22] Loading its data source...
[INFO][13:41:10]: Data source: FEMNIST
[INFO][13:41:10]: [Client #818] Selected by the server.
[INFO][13:41:10]: [Client #818] Loading its data source...
[INFO][13:41:10]: Data source: FEMNIST
[INFO][13:41:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:41:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/818.zip.
[INFO][13:41:10]: [Client #22] Dataset size: 161
[INFO][13:41:10]: [Client #22] Sampler: all_inclusive
[INFO][13:41:10]: [Client #22] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:41:10]: [93m[1m[Client #22] Started training in communication round #5.[0m
2.9%5.8%8.8%11.7%14.6%17.5%20.4%23.4%26.3%29.2%32.1%35.0%38.0%40.9%43.8%46.7%49.6%52.5%55.5%58.4%61.3%64.2%67.1%70.1%73.0%75.9%78.8%81.7%84.7%87.6%90.5%93.4%96.3%99.3%100.0%[INFO][13:41:10]: Decompressing the dataset downloaded.
[INFO][13:41:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/818.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:41:10]: [Client #818] Dataset size: 165
[INFO][13:41:10]: [Client #818] Sampler: all_inclusive
[INFO][13:41:10]: [Client #818] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:41:10]: [93m[1m[Client #818] Started training in communication round #5.[0m

[INFO][13:41:12]: [Client #22] Loading the dataset.
[INFO][13:41:12]: [Client #818] Loading the dataset.
[INFO][13:41:18]: [Client #22] Epoch: [1/5][0/17]	Loss: 2.485816
[INFO][13:41:18]: [Client #818] Epoch: [1/5][0/17]	Loss: 3.070784
[INFO][13:41:18]: [Client #22] Epoch: [1/5][10/17]	Loss: 3.103270
[INFO][13:41:18]: [Client #818] Epoch: [1/5][10/17]	Loss: 1.993832
[INFO][13:41:18]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:41:18]: [Client #818] Going to sleep for 0.17 seconds.
[INFO][13:41:18]: [Client #818] Woke up.
[INFO][13:41:18]: [Client #818] Epoch: [2/5][0/17]	Loss: 1.414882
[INFO][13:41:18]: [Client #818] Epoch: [2/5][10/17]	Loss: 2.583364
[INFO][13:41:18]: [Client #818] Going to sleep for 0.17 seconds.
[INFO][13:41:18]: [Client #818] Woke up.
[INFO][13:41:18]: [Client #818] Epoch: [3/5][0/17]	Loss: 2.485198
[INFO][13:41:18]: [Client #818] Epoch: [3/5][10/17]	Loss: 2.213834
[INFO][13:41:18]: [Client #818] Going to sleep for 0.17 seconds.
[INFO][13:41:19]: [Client #818] Woke up.
[INFO][13:41:19]: [Client #818] Epoch: [4/5][0/17]	Loss: 3.014682
[INFO][13:41:19]: [Client #818] Epoch: [4/5][10/17]	Loss: 2.920796
[INFO][13:41:19]: [Client #818] Going to sleep for 0.17 seconds.
[INFO][13:41:19]: [Client #818] Woke up.
[INFO][13:41:19]: [Client #818] Epoch: [5/5][0/17]	Loss: 1.552902
[INFO][13:41:19]: [Client #818] Epoch: [5/5][10/17]	Loss: 0.902665
[INFO][13:41:19]: [Client #818] Going to sleep for 0.17 seconds.
[INFO][13:41:19]: [Client #818] Woke up.
[INFO][13:41:19]: [Client #818] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_818_615875.pth.
[INFO][13:41:20]: [Client #818] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_818_615875.pth.
[INFO][13:41:20]: [Client #818] Model trained.
[INFO][13:41:20]: [Client #818] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:41:20]: [Server #615782] Received 0.26 MB of payload data from client #818 (simulated).
[INFO][13:41:48]: [Client #22] Woke up.
[INFO][13:41:48]: [Client #22] Epoch: [2/5][0/17]	Loss: 2.932149
[INFO][13:41:48]: [Client #22] Epoch: [2/5][10/17]	Loss: 2.886290
[INFO][13:41:49]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:42:19]: [Client #22] Woke up.
[INFO][13:42:19]: [Client #22] Epoch: [3/5][0/17]	Loss: 1.933000
[INFO][13:42:19]: [Client #22] Epoch: [3/5][10/17]	Loss: 1.733728
[INFO][13:42:19]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:42:50]: [Client #22] Woke up.
[INFO][13:42:50]: [Client #22] Epoch: [4/5][0/17]	Loss: 1.912565
[INFO][13:42:50]: [Client #22] Epoch: [4/5][10/17]	Loss: 2.905094
[INFO][13:42:50]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:43:21]: [Client #22] Woke up.
[INFO][13:43:21]: [Client #22] Epoch: [5/5][0/17]	Loss: 2.634988
[INFO][13:43:21]: [Client #22] Epoch: [5/5][10/17]	Loss: 2.196201
[INFO][13:43:21]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][13:43:51]: [Client #22] Woke up.
[INFO][13:43:52]: [Client #22] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_615874.pth.
[INFO][13:43:52]: [Client #22] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_615874.pth.
[INFO][13:43:52]: [Client #22] Model trained.
[INFO][13:43:52]: [Client #22] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:43:52]: [Server #615782] Received 0.26 MB of payload data from client #22 (simulated).
[INFO][13:43:52]: [Server #615782] Selecting client #187 for training.
[INFO][13:43:52]: [Server #615782] Sending the current model to client #187 (simulated).
[INFO][13:43:52]: [Server #615782] Sending 0.26 MB of payload data to client #187 (simulated).
[INFO][13:43:52]: [Server #615782] Selecting client #683 for training.
[INFO][13:43:52]: [Server #615782] Sending the current model to client #683 (simulated).
[INFO][13:43:52]: [Server #615782] Sending 0.26 MB of payload data to client #683 (simulated).
[INFO][13:43:52]: [Client #187] Selected by the server.
[INFO][13:43:52]: [Client #187] Loading its data source...
[INFO][13:43:52]: Data source: FEMNIST
[INFO][13:43:52]: [Client #683] Selected by the server.
[INFO][13:43:52]: [Client #683] Loading its data source...
[INFO][13:43:52]: Data source: FEMNIST
[INFO][13:43:52]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:43:52]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/683.zip.
[INFO][13:43:52]: [Client #187] Dataset size: 164
[INFO][13:43:52]: [Client #187] Sampler: all_inclusive
[INFO][13:43:52]: [Client #187] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:43:52]: [93m[1m[Client #187] Started training in communication round #5.[0m
2.6%5.1%7.7%10.2%12.8%15.3%17.9%20.5%23.0%25.6%28.1%30.7%33.3%35.8%38.4%40.9%43.5%46.0%48.6%51.2%53.7%56.3%58.8%61.4%64.0%66.5%69.1%71.6%74.2%76.7%79.3%81.9%84.4%87.0%89.5%92.1%94.7%97.2%99.8%100.0%[INFO][13:43:52]: Decompressing the dataset downloaded.
[INFO][13:43:52]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/683.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:43:52]: [Client #683] Dataset size: 158
[INFO][13:43:52]: [Client #683] Sampler: all_inclusive
[INFO][13:43:52]: [Client #683] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:43:53]: [93m[1m[Client #683] Started training in communication round #5.[0m

[INFO][13:43:54]: [Client #187] Loading the dataset.
[INFO][13:43:54]: [Client #683] Loading the dataset.
[INFO][13:44:00]: [Client #683] Epoch: [1/5][0/16]	Loss: 2.368330
[INFO][13:44:00]: [Client #187] Epoch: [1/5][0/17]	Loss: 2.772562
[INFO][13:44:00]: [Client #683] Epoch: [1/5][10/16]	Loss: 3.829926
[INFO][13:44:00]: [Client #683] Going to sleep for 2.41 seconds.
[INFO][13:44:00]: [Client #187] Epoch: [1/5][10/17]	Loss: 3.027812
[INFO][13:44:00]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][13:44:00]: [Client #187] Woke up.
[INFO][13:44:00]: [Client #187] Epoch: [2/5][0/17]	Loss: 2.968357
[INFO][13:44:00]: [Client #187] Epoch: [2/5][10/17]	Loss: 2.884751
[INFO][13:44:00]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][13:44:01]: [Client #187] Woke up.
[INFO][13:44:01]: [Client #187] Epoch: [3/5][0/17]	Loss: 2.473317
[INFO][13:44:01]: [Client #187] Epoch: [3/5][10/17]	Loss: 1.945798
[INFO][13:44:01]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][13:44:01]: [Client #187] Woke up.
[INFO][13:44:01]: [Client #187] Epoch: [4/5][0/17]	Loss: 0.940755
[INFO][13:44:01]: [Client #187] Epoch: [4/5][10/17]	Loss: 2.065179
[INFO][13:44:01]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][13:44:01]: [Client #187] Woke up.
[INFO][13:44:01]: [Client #187] Epoch: [5/5][0/17]	Loss: 2.324206
[INFO][13:44:02]: [Client #187] Epoch: [5/5][10/17]	Loss: 1.787777
[INFO][13:44:02]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][13:44:02]: [Client #187] Woke up.
[INFO][13:44:02]: [Client #187] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_187_615874.pth.
[INFO][13:44:02]: [Client #683] Woke up.
[INFO][13:44:02]: [Client #683] Epoch: [2/5][0/16]	Loss: 2.023054
[INFO][13:44:02]: [Client #683] Epoch: [2/5][10/16]	Loss: 2.079196
[INFO][13:44:02]: [Client #187] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_187_615874.pth.
[INFO][13:44:02]: [Client #187] Model trained.
[INFO][13:44:02]: [Client #187] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:44:02]: [Server #615782] Received 0.26 MB of payload data from client #187 (simulated).
[INFO][13:44:02]: [Client #683] Going to sleep for 2.41 seconds.
[INFO][13:44:05]: [Client #683] Woke up.
[INFO][13:44:05]: [Client #683] Epoch: [3/5][0/16]	Loss: 1.631457
[INFO][13:44:05]: [Client #683] Epoch: [3/5][10/16]	Loss: 1.732115
[INFO][13:44:05]: [Client #683] Going to sleep for 2.41 seconds.
[INFO][13:44:07]: [Client #683] Woke up.
[INFO][13:44:07]: [Client #683] Epoch: [4/5][0/16]	Loss: 1.625219
[INFO][13:44:08]: [Client #683] Epoch: [4/5][10/16]	Loss: 1.758120
[INFO][13:44:08]: [Client #683] Going to sleep for 2.41 seconds.
[INFO][13:44:10]: [Client #683] Woke up.
[INFO][13:44:10]: [Client #683] Epoch: [5/5][0/16]	Loss: 1.661580
[INFO][13:44:10]: [Client #683] Epoch: [5/5][10/16]	Loss: 1.322242
[INFO][13:44:10]: [Client #683] Going to sleep for 2.41 seconds.
[INFO][13:44:13]: [Client #683] Woke up.
[INFO][13:44:13]: [Client #683] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_683_615875.pth.
[INFO][13:44:13]: [Client #683] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_683_615875.pth.
[INFO][13:44:13]: [Client #683] Model trained.
[INFO][13:44:13]: [Client #683] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:44:13]: [Server #615782] Received 0.26 MB of payload data from client #683 (simulated).
[INFO][13:44:13]: [Server #615782] Selecting client #354 for training.
[INFO][13:44:13]: [Server #615782] Sending the current model to client #354 (simulated).
[INFO][13:44:13]: [Server #615782] Sending 0.26 MB of payload data to client #354 (simulated).
[INFO][13:44:13]: [Server #615782] Selecting client #974 for training.
[INFO][13:44:13]: [Server #615782] Sending the current model to client #974 (simulated).
[INFO][13:44:13]: [Server #615782] Sending 0.26 MB of payload data to client #974 (simulated).
[INFO][13:44:13]: [Client #354] Selected by the server.
[INFO][13:44:13]: [Client #974] Selected by the server.
[INFO][13:44:13]: [Client #974] Loading its data source...
[INFO][13:44:13]: [Client #354] Loading its data source...
[INFO][13:44:13]: Data source: FEMNIST
[INFO][13:44:13]: Data source: FEMNIST
[INFO][13:44:13]: [Client #974] Dataset size: 158
[INFO][13:44:13]: [Client #974] Sampler: all_inclusive
[INFO][13:44:13]: [Client #974] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:44:13]: [93m[1m[Client #974] Started training in communication round #5.[0m
[INFO][13:44:13]: [Client #354] Dataset size: 150
[INFO][13:44:13]: [Client #354] Sampler: all_inclusive
[INFO][13:44:13]: [Client #354] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:44:13]: [93m[1m[Client #354] Started training in communication round #5.[0m
[INFO][13:44:15]: [Client #354] Loading the dataset.
[INFO][13:44:15]: [Client #974] Loading the dataset.
[INFO][13:44:21]: [Client #354] Epoch: [1/5][0/15]	Loss: 2.681067
[INFO][13:44:21]: [Client #974] Epoch: [1/5][0/16]	Loss: 2.311443
[INFO][13:44:21]: [Client #354] Epoch: [1/5][10/15]	Loss: 2.639072
[INFO][13:44:21]: [Client #974] Epoch: [1/5][10/16]	Loss: 1.279939
[INFO][13:44:21]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][13:44:21]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][13:44:21]: [Client #354] Woke up.
[INFO][13:44:21]: [Client #354] Epoch: [2/5][0/15]	Loss: 3.240162
[INFO][13:44:21]: [Client #354] Epoch: [2/5][10/15]	Loss: 2.890563
[INFO][13:44:21]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][13:44:22]: [Client #354] Woke up.
[INFO][13:44:22]: [Client #354] Epoch: [3/5][0/15]	Loss: 2.425198
[INFO][13:44:22]: [Client #354] Epoch: [3/5][10/15]	Loss: 2.379533
[INFO][13:44:22]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][13:44:22]: [Client #354] Woke up.
[INFO][13:44:22]: [Client #354] Epoch: [4/5][0/15]	Loss: 2.973763
[INFO][13:44:22]: [Client #354] Epoch: [4/5][10/15]	Loss: 2.661260
[INFO][13:44:22]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][13:44:23]: [Client #354] Woke up.
[INFO][13:44:23]: [Client #354] Epoch: [5/5][0/15]	Loss: 2.755862
[INFO][13:44:23]: [Client #354] Epoch: [5/5][10/15]	Loss: 2.139799
[INFO][13:44:23]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][13:44:23]: [Client #354] Woke up.
[INFO][13:44:23]: [Client #354] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_354_615874.pth.
[INFO][13:44:24]: [Client #354] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_354_615874.pth.
[INFO][13:44:24]: [Client #354] Model trained.
[INFO][13:44:24]: [Client #354] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:44:24]: [Server #615782] Received 0.26 MB of payload data from client #354 (simulated).
[INFO][13:44:28]: [Client #974] Woke up.
[INFO][13:44:28]: [Client #974] Epoch: [2/5][0/16]	Loss: 2.380355
[INFO][13:44:28]: [Client #974] Epoch: [2/5][10/16]	Loss: 2.793566
[INFO][13:44:28]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][13:44:35]: [Client #974] Woke up.
[INFO][13:44:35]: [Client #974] Epoch: [3/5][0/16]	Loss: 2.232705
[INFO][13:44:35]: [Client #974] Epoch: [3/5][10/16]	Loss: 3.067250
[INFO][13:44:35]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][13:44:43]: [Client #974] Woke up.
[INFO][13:44:43]: [Client #974] Epoch: [4/5][0/16]	Loss: 1.742055
[INFO][13:44:43]: [Client #974] Epoch: [4/5][10/16]	Loss: 2.873762
[INFO][13:44:43]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][13:44:50]: [Client #974] Woke up.
[INFO][13:44:50]: [Client #974] Epoch: [5/5][0/16]	Loss: 2.300968
[INFO][13:44:50]: [Client #974] Epoch: [5/5][10/16]	Loss: 1.886413
[INFO][13:44:50]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][13:44:57]: [Client #974] Woke up.
[INFO][13:44:57]: [Client #974] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][13:44:58]: [Client #974] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][13:44:58]: [Client #974] Model trained.
[INFO][13:44:58]: [Client #974] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:44:58]: [Server #615782] Received 0.26 MB of payload data from client #974 (simulated).
[INFO][13:44:58]: [Server #615782] Selecting client #121 for training.
[INFO][13:44:58]: [Server #615782] Sending the current model to client #121 (simulated).
[INFO][13:44:58]: [Server #615782] Sending 0.26 MB of payload data to client #121 (simulated).
[INFO][13:44:58]: [Server #615782] Selecting client #186 for training.
[INFO][13:44:58]: [Server #615782] Sending the current model to client #186 (simulated).
[INFO][13:44:58]: [Server #615782] Sending 0.26 MB of payload data to client #186 (simulated).
[INFO][13:44:58]: [Client #121] Selected by the server.
[INFO][13:44:58]: [Client #186] Selected by the server.
[INFO][13:44:58]: [Client #121] Loading its data source...
[INFO][13:44:58]: [Client #186] Loading its data source...
[INFO][13:44:58]: Data source: FEMNIST
[INFO][13:44:58]: Data source: FEMNIST
[INFO][13:44:58]: [Client #121] Dataset size: 159
[INFO][13:44:58]: [Client #121] Sampler: all_inclusive
[INFO][13:44:58]: [Client #121] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:44:58]: [93m[1m[Client #121] Started training in communication round #5.[0m
[INFO][13:44:58]: [Client #186] Dataset size: 133
[INFO][13:44:58]: [Client #186] Sampler: all_inclusive
[INFO][13:44:58]: [Client #186] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:44:58]: [93m[1m[Client #186] Started training in communication round #5.[0m
[INFO][13:45:00]: [Client #121] Loading the dataset.
[INFO][13:45:00]: [Client #186] Loading the dataset.
[INFO][13:45:05]: [Client #121] Epoch: [1/5][0/16]	Loss: 1.604939
[INFO][13:45:05]: [Client #186] Epoch: [1/5][0/14]	Loss: 2.040982
[INFO][13:45:05]: [Client #121] Epoch: [1/5][10/16]	Loss: 3.210611
[INFO][13:45:05]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][13:45:05]: [Client #186] Epoch: [1/5][10/14]	Loss: 3.164301
[INFO][13:45:05]: [Client #121] Woke up.
[INFO][13:45:05]: [Client #121] Epoch: [2/5][0/16]	Loss: 3.128929
[INFO][13:45:05]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][13:45:06]: [Client #121] Epoch: [2/5][10/16]	Loss: 2.627472
[INFO][13:45:06]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][13:45:06]: [Client #121] Woke up.
[INFO][13:45:06]: [Client #121] Epoch: [3/5][0/16]	Loss: 1.668195
[INFO][13:45:06]: [Client #121] Epoch: [3/5][10/16]	Loss: 3.461612
[INFO][13:45:06]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][13:45:06]: [Client #121] Woke up.
[INFO][13:45:06]: [Client #121] Epoch: [4/5][0/16]	Loss: 2.129888
[INFO][13:45:06]: [Client #121] Epoch: [4/5][10/16]	Loss: 1.708848
[INFO][13:45:06]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][13:45:06]: [Client #121] Woke up.
[INFO][13:45:06]: [Client #121] Epoch: [5/5][0/16]	Loss: 2.069510
[INFO][13:45:06]: [Client #121] Epoch: [5/5][10/16]	Loss: 2.272913
[INFO][13:45:06]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][13:45:06]: [Client #121] Woke up.
[INFO][13:45:06]: [Client #121] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_121_615874.pth.
[INFO][13:45:07]: [Client #121] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_121_615874.pth.
[INFO][13:45:07]: [Client #121] Model trained.
[INFO][13:45:07]: [Client #121] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:07]: [Server #615782] Received 0.26 MB of payload data from client #121 (simulated).
[INFO][13:45:10]: [Client #186] Woke up.
[INFO][13:45:10]: [Client #186] Epoch: [2/5][0/14]	Loss: 2.470073
[INFO][13:45:10]: [Client #186] Epoch: [2/5][10/14]	Loss: 2.961680
[INFO][13:45:10]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][13:45:14]: [Client #186] Woke up.
[INFO][13:45:14]: [Client #186] Epoch: [3/5][0/14]	Loss: 1.652694
[INFO][13:45:14]: [Client #186] Epoch: [3/5][10/14]	Loss: 2.501962
[INFO][13:45:14]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][13:45:18]: [Client #186] Woke up.
[INFO][13:45:18]: [Client #186] Epoch: [4/5][0/14]	Loss: 2.369342
[INFO][13:45:18]: [Client #186] Epoch: [4/5][10/14]	Loss: 3.021177
[INFO][13:45:18]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][13:45:22]: [Client #186] Woke up.
[INFO][13:45:22]: [Client #186] Epoch: [5/5][0/14]	Loss: 2.802562
[INFO][13:45:22]: [Client #186] Epoch: [5/5][10/14]	Loss: 1.818294
[INFO][13:45:22]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][13:45:27]: [Client #186] Woke up.
[INFO][13:45:27]: [Client #186] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615875.pth.
[INFO][13:45:27]: [Client #186] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615875.pth.
[INFO][13:45:27]: [Client #186] Model trained.
[INFO][13:45:27]: [Client #186] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:27]: [Server #615782] Received 0.26 MB of payload data from client #186 (simulated).
[INFO][13:45:27]: [Server #615782] Selecting client #890 for training.
[INFO][13:45:27]: [Server #615782] Sending the current model to client #890 (simulated).
[INFO][13:45:27]: [Server #615782] Sending 0.26 MB of payload data to client #890 (simulated).
[INFO][13:45:27]: [Server #615782] Selecting client #580 for training.
[INFO][13:45:27]: [Server #615782] Sending the current model to client #580 (simulated).
[INFO][13:45:27]: [Server #615782] Sending 0.26 MB of payload data to client #580 (simulated).
[INFO][13:45:27]: [Client #890] Selected by the server.
[INFO][13:45:27]: [Client #890] Loading its data source...
[INFO][13:45:27]: Data source: FEMNIST
[INFO][13:45:27]: [Client #580] Selected by the server.
[INFO][13:45:27]: [Client #580] Loading its data source...
[INFO][13:45:27]: Data source: FEMNIST
[INFO][13:45:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:45:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/580.zip.
[INFO][13:45:27]: [Client #890] Dataset size: 161
[INFO][13:45:27]: [Client #890] Sampler: all_inclusive
[INFO][13:45:27]: [Client #890] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:27]: [93m[1m[Client #890] Started training in communication round #5.[0m
5.4%10.8%16.2%21.6%27.0%32.4%37.8%43.2%48.6%54.0%59.4%64.8%70.2%75.6%81.1%86.5%91.9%97.3%100.0%[INFO][13:45:28]: Decompressing the dataset downloaded.
[INFO][13:45:28]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/580.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:45:28]: [Client #580] Dataset size: 89
[INFO][13:45:28]: [Client #580] Sampler: all_inclusive
[INFO][13:45:28]: [Client #580] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:28]: [93m[1m[Client #580] Started training in communication round #5.[0m

[INFO][13:45:29]: [Client #890] Loading the dataset.
[INFO][13:45:30]: [Client #580] Loading the dataset.
[INFO][13:45:35]: [Client #890] Epoch: [1/5][0/17]	Loss: 1.882034
[INFO][13:45:35]: [Client #580] Epoch: [1/5][0/9]	Loss: 3.381412
[INFO][13:45:35]: [Client #890] Epoch: [1/5][10/17]	Loss: 1.858423
[INFO][13:45:35]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][13:45:35]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][13:45:36]: [Client #580] Woke up.
[INFO][13:45:36]: [Client #580] Epoch: [2/5][0/9]	Loss: 1.993821
[INFO][13:45:36]: [Client #890] Woke up.
[INFO][13:45:36]: [Client #890] Epoch: [2/5][0/17]	Loss: 2.463444
[INFO][13:45:36]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][13:45:36]: [Client #890] Epoch: [2/5][10/17]	Loss: 2.220360
[INFO][13:45:36]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][13:45:37]: [Client #580] Woke up.
[INFO][13:45:37]: [Client #580] Epoch: [3/5][0/9]	Loss: 1.522033
[INFO][13:45:37]: [Client #890] Woke up.
[INFO][13:45:37]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][13:45:37]: [Client #890] Epoch: [3/5][0/17]	Loss: 1.510683
[INFO][13:45:37]: [Client #890] Epoch: [3/5][10/17]	Loss: 2.921752
[INFO][13:45:37]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][13:45:37]: [Client #580] Woke up.
[INFO][13:45:37]: [Client #580] Epoch: [4/5][0/9]	Loss: 1.986917
[INFO][13:45:37]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][13:45:37]: [Client #890] Woke up.
[INFO][13:45:37]: [Client #890] Epoch: [4/5][0/17]	Loss: 3.025684
[INFO][13:45:37]: [Client #890] Epoch: [4/5][10/17]	Loss: 2.386607
[INFO][13:45:37]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][13:45:38]: [Client #580] Woke up.
[INFO][13:45:38]: [Client #580] Epoch: [5/5][0/9]	Loss: 2.684067
[INFO][13:45:38]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][13:45:38]: [Client #890] Woke up.
[INFO][13:45:38]: [Client #890] Epoch: [5/5][0/17]	Loss: 1.600153
[INFO][13:45:38]: [Client #890] Epoch: [5/5][10/17]	Loss: 2.649632
[INFO][13:45:38]: [Client #890] Going to sleep for 0.54 seconds.
[INFO][13:45:38]: [Client #580] Woke up.
[INFO][13:45:38]: [Client #580] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_580_615875.pth.
[INFO][13:45:39]: [Client #890] Woke up.
[INFO][13:45:39]: [Client #890] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_890_615874.pth.
[INFO][13:45:39]: [Client #580] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_580_615875.pth.
[INFO][13:45:39]: [Client #580] Model trained.
[INFO][13:45:39]: [Client #580] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:39]: [Server #615782] Received 0.26 MB of payload data from client #580 (simulated).
[INFO][13:45:39]: [Client #890] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_890_615874.pth.
[INFO][13:45:39]: [Client #890] Model trained.
[INFO][13:45:39]: [Client #890] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:39]: [Server #615782] Received 0.26 MB of payload data from client #890 (simulated).
[INFO][13:45:39]: [Server #615782] Selecting client #307 for training.
[INFO][13:45:39]: [Server #615782] Sending the current model to client #307 (simulated).
[INFO][13:45:39]: [Server #615782] Sending 0.26 MB of payload data to client #307 (simulated).
[INFO][13:45:39]: [Server #615782] Selecting client #1 for training.
[INFO][13:45:39]: [Server #615782] Sending the current model to client #1 (simulated).
[INFO][13:45:39]: [Server #615782] Sending 0.26 MB of payload data to client #1 (simulated).
[INFO][13:45:39]: [Client #307] Selected by the server.
[INFO][13:45:39]: [Client #307] Loading its data source...
[INFO][13:45:39]: [Client #1] Selected by the server.
[INFO][13:45:39]: Data source: FEMNIST
[INFO][13:45:39]: [Client #1] Loading its data source...
[INFO][13:45:39]: Data source: FEMNIST
[INFO][13:45:40]: [Client #307] Dataset size: 162
[INFO][13:45:40]: [Client #307] Sampler: all_inclusive
[INFO][13:45:40]: [Client #1] Dataset size: 221
[INFO][13:45:40]: [Client #1] Sampler: all_inclusive
[INFO][13:45:40]: [Client #307] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:40]: [Client #1] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:40]: [93m[1m[Client #307] Started training in communication round #5.[0m
[INFO][13:45:40]: [93m[1m[Client #1] Started training in communication round #5.[0m
[INFO][13:45:42]: [Client #307] Loading the dataset.
[INFO][13:45:42]: [Client #1] Loading the dataset.
[INFO][13:45:47]: [Client #307] Epoch: [1/5][0/17]	Loss: 2.613630
[INFO][13:45:47]: [Client #1] Epoch: [1/5][0/23]	Loss: 2.443135
[INFO][13:45:47]: [Client #307] Epoch: [1/5][10/17]	Loss: 2.436121
[INFO][13:45:47]: [Client #1] Epoch: [1/5][10/23]	Loss: 3.093869
[INFO][13:45:47]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][13:45:48]: [Client #1] Epoch: [1/5][20/23]	Loss: 2.694442
[INFO][13:45:48]: [Client #1] Going to sleep for 0.72 seconds.
[INFO][13:45:48]: [Client #307] Woke up.
[INFO][13:45:48]: [Client #307] Epoch: [2/5][0/17]	Loss: 2.617640
[INFO][13:45:48]: [Client #307] Epoch: [2/5][10/17]	Loss: 2.707627
[INFO][13:45:48]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][13:45:48]: [Client #1] Woke up.
[INFO][13:45:48]: [Client #1] Epoch: [2/5][0/23]	Loss: 3.623709
[INFO][13:45:48]: [Client #1] Epoch: [2/5][10/23]	Loss: 2.606106
[INFO][13:45:48]: [Client #1] Epoch: [2/5][20/23]	Loss: 2.872903
[INFO][13:45:48]: [Client #1] Going to sleep for 0.72 seconds.
[INFO][13:45:49]: [Client #307] Woke up.
[INFO][13:45:49]: [Client #307] Epoch: [3/5][0/17]	Loss: 2.928890
[INFO][13:45:49]: [Client #307] Epoch: [3/5][10/17]	Loss: 3.169751
[INFO][13:45:49]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][13:45:49]: [Client #1] Woke up.
[INFO][13:45:49]: [Client #1] Epoch: [3/5][0/23]	Loss: 2.036198
[INFO][13:45:49]: [Client #1] Epoch: [3/5][10/23]	Loss: 2.463485
[INFO][13:45:49]: [Client #307] Woke up.
[INFO][13:45:49]: [Client #1] Epoch: [3/5][20/23]	Loss: 2.228415
[INFO][13:45:49]: [Client #307] Epoch: [4/5][0/17]	Loss: 2.150133
[INFO][13:45:49]: [Client #1] Going to sleep for 0.72 seconds.
[INFO][13:45:49]: [Client #307] Epoch: [4/5][10/17]	Loss: 2.197582
[INFO][13:45:49]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][13:45:50]: [Client #307] Woke up.
[INFO][13:45:50]: [Client #307] Epoch: [5/5][0/17]	Loss: 3.504643
[INFO][13:45:50]: [Client #1] Woke up.
[INFO][13:45:50]: [Client #1] Epoch: [4/5][0/23]	Loss: 1.868163
[INFO][13:45:50]: [Client #307] Epoch: [5/5][10/17]	Loss: 3.203853
[INFO][13:45:50]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][13:45:50]: [Client #1] Epoch: [4/5][10/23]	Loss: 1.781509
[INFO][13:45:50]: [Client #1] Epoch: [4/5][20/23]	Loss: 2.208746
[INFO][13:45:50]: [Client #1] Going to sleep for 0.72 seconds.
[INFO][13:45:51]: [Client #307] Woke up.
[INFO][13:45:51]: [Client #307] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_615874.pth.
[INFO][13:45:51]: [Client #1] Woke up.
[INFO][13:45:51]: [Client #1] Epoch: [5/5][0/23]	Loss: 2.465506
[INFO][13:45:51]: [Client #1] Epoch: [5/5][10/23]	Loss: 2.534669
[INFO][13:45:51]: [Client #1] Epoch: [5/5][20/23]	Loss: 3.486917
[INFO][13:45:51]: [Client #1] Going to sleep for 0.72 seconds.
[INFO][13:45:51]: [Client #307] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_615874.pth.
[INFO][13:45:51]: [Client #307] Model trained.
[INFO][13:45:51]: [Client #307] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:51]: [Server #615782] Received 0.26 MB of payload data from client #307 (simulated).
[INFO][13:45:52]: [Client #1] Woke up.
[INFO][13:45:52]: [Client #1] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_1_615875.pth.
[INFO][13:45:53]: [Client #1] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_1_615875.pth.
[INFO][13:45:53]: [Client #1] Model trained.
[INFO][13:45:53]: [Client #1] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:45:53]: [Server #615782] Received 0.26 MB of payload data from client #1 (simulated).
[INFO][13:45:53]: [Server #615782] Selecting client #227 for training.
[INFO][13:45:53]: [Server #615782] Sending the current model to client #227 (simulated).
[INFO][13:45:53]: [Server #615782] Sending 0.26 MB of payload data to client #227 (simulated).
[INFO][13:45:53]: [Server #615782] Selecting client #143 for training.
[INFO][13:45:53]: [Server #615782] Sending the current model to client #143 (simulated).
[INFO][13:45:53]: [Server #615782] Sending 0.26 MB of payload data to client #143 (simulated).
[INFO][13:45:53]: [Client #227] Selected by the server.
[INFO][13:45:53]: [Client #143] Selected by the server.
[INFO][13:45:53]: [Client #143] Loading its data source...
[INFO][13:45:53]: [Client #227] Loading its data source...
[INFO][13:45:53]: Data source: FEMNIST
[INFO][13:45:53]: Data source: FEMNIST
[INFO][13:45:53]: [Client #143] Dataset size: 156
[INFO][13:45:53]: [Client #143] Sampler: all_inclusive
[INFO][13:45:53]: [Client #227] Dataset size: 154
[INFO][13:45:53]: [Client #227] Sampler: all_inclusive
[INFO][13:45:53]: [Client #143] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:53]: [93m[1m[Client #143] Started training in communication round #5.[0m
[INFO][13:45:53]: [Client #227] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:45:53]: [93m[1m[Client #227] Started training in communication round #5.[0m
[INFO][13:45:55]: [Client #143] Loading the dataset.
[INFO][13:45:55]: [Client #227] Loading the dataset.
[INFO][13:46:00]: [Client #143] Epoch: [1/5][0/16]	Loss: 3.381276
[INFO][13:46:00]: [Client #227] Epoch: [1/5][0/16]	Loss: 2.019294
[INFO][13:46:00]: [Client #143] Epoch: [1/5][10/16]	Loss: 1.768169
[INFO][13:46:00]: [Client #227] Epoch: [1/5][10/16]	Loss: 1.834261
[INFO][13:46:00]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][13:46:00]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][13:46:00]: [Client #143] Woke up.
[INFO][13:46:00]: [Client #143] Epoch: [2/5][0/16]	Loss: 2.829995
[INFO][13:46:00]: [Client #143] Epoch: [2/5][10/16]	Loss: 1.489250
[INFO][13:46:00]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][13:46:00]: [Client #143] Woke up.
[INFO][13:46:00]: [Client #143] Epoch: [3/5][0/16]	Loss: 2.557116
[INFO][13:46:01]: [Client #143] Epoch: [3/5][10/16]	Loss: 2.339852
[INFO][13:46:01]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][13:46:01]: [Client #143] Woke up.
[INFO][13:46:01]: [Client #143] Epoch: [4/5][0/16]	Loss: 1.451184
[INFO][13:46:01]: [Client #143] Epoch: [4/5][10/16]	Loss: 1.374477
[INFO][13:46:01]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][13:46:01]: [Client #143] Woke up.
[INFO][13:46:01]: [Client #143] Epoch: [5/5][0/16]	Loss: 0.685203
[INFO][13:46:01]: [Client #143] Epoch: [5/5][10/16]	Loss: 1.236571
[INFO][13:46:01]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][13:46:01]: [Client #143] Woke up.
[INFO][13:46:01]: [Client #143] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_615875.pth.
[INFO][13:46:02]: [Client #227] Woke up.
[INFO][13:46:02]: [Client #227] Epoch: [2/5][0/16]	Loss: 1.668386
[INFO][13:46:02]: [Client #227] Epoch: [2/5][10/16]	Loss: 2.461380
[INFO][13:46:02]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][13:46:02]: [Client #143] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_615875.pth.
[INFO][13:46:02]: [Client #143] Model trained.
[INFO][13:46:02]: [Client #143] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:46:02]: [Server #615782] Received 0.26 MB of payload data from client #143 (simulated).
[INFO][13:46:03]: [Client #227] Woke up.
[INFO][13:46:03]: [Client #227] Epoch: [3/5][0/16]	Loss: 2.825950
[INFO][13:46:03]: [Client #227] Epoch: [3/5][10/16]	Loss: 1.572252
[INFO][13:46:03]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][13:46:05]: [Client #227] Woke up.
[INFO][13:46:05]: [Client #227] Epoch: [4/5][0/16]	Loss: 1.669365
[INFO][13:46:05]: [Client #227] Epoch: [4/5][10/16]	Loss: 2.427825
[INFO][13:46:05]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][13:46:06]: [Client #227] Woke up.
[INFO][13:46:06]: [Client #227] Epoch: [5/5][0/16]	Loss: 2.627064
[INFO][13:46:06]: [Client #227] Epoch: [5/5][10/16]	Loss: 2.375749
[INFO][13:46:06]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][13:46:08]: [Client #227] Woke up.
[INFO][13:46:08]: [Client #227] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_227_615874.pth.
[INFO][13:46:08]: [Client #227] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_227_615874.pth.
[INFO][13:46:08]: [Client #227] Model trained.
[INFO][13:46:08]: [Client #227] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:46:08]: [Server #615782] Received 0.26 MB of payload data from client #227 (simulated).
[INFO][13:46:08]: [Server #615782] Selecting client #204 for training.
[INFO][13:46:08]: [Server #615782] Sending the current model to client #204 (simulated).
[INFO][13:46:08]: [Server #615782] Sending 0.26 MB of payload data to client #204 (simulated).
[INFO][13:46:08]: [Server #615782] Selecting client #897 for training.
[INFO][13:46:08]: [Server #615782] Sending the current model to client #897 (simulated).
[INFO][13:46:08]: [Server #615782] Sending 0.26 MB of payload data to client #897 (simulated).
[INFO][13:46:08]: [Client #204] Selected by the server.
[INFO][13:46:08]: [Client #204] Loading its data source...
[INFO][13:46:08]: Data source: FEMNIST
[INFO][13:46:08]: [Client #897] Selected by the server.
[INFO][13:46:08]: [Client #897] Loading its data source...
[INFO][13:46:08]: Data source: FEMNIST
[INFO][13:46:08]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:46:08]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/897.zip.
[INFO][13:46:08]: [Client #204] Dataset size: 155
[INFO][13:46:08]: [Client #204] Sampler: all_inclusive
[INFO][13:46:08]: [Client #204] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:46:08]: [93m[1m[Client #204] Started training in communication round #5.[0m
3.3%6.6%9.9%13.2%16.5%19.8%23.1%26.4%29.7%33.0%36.3%39.6%42.9%46.2%49.5%52.8%56.1%59.4%62.7%66.0%69.3%72.6%75.9%79.2%82.5%85.8%89.1%92.4%95.7%99.0%100.0%[INFO][13:46:09]: Decompressing the dataset downloaded.
[INFO][13:46:09]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/897.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:46:09]: [Client #897] Dataset size: 157
[INFO][13:46:09]: [Client #897] Sampler: all_inclusive
[INFO][13:46:09]: [Client #897] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:46:09]: [93m[1m[Client #897] Started training in communication round #5.[0m

[INFO][13:46:10]: [Client #204] Loading the dataset.
[INFO][13:46:11]: [Client #897] Loading the dataset.
[INFO][13:46:16]: [Client #897] Epoch: [1/5][0/16]	Loss: 2.012421
[INFO][13:46:16]: [Client #204] Epoch: [1/5][0/16]	Loss: 1.305166
[INFO][13:46:16]: [Client #897] Epoch: [1/5][10/16]	Loss: 2.339164
[INFO][13:46:16]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][13:46:16]: [Client #204] Epoch: [1/5][10/16]	Loss: 2.152005
[INFO][13:46:16]: [Client #204] Going to sleep for 1.79 seconds.
[INFO][13:46:18]: [Client #204] Woke up.
[INFO][13:46:18]: [Client #204] Epoch: [2/5][0/16]	Loss: 2.550968
[INFO][13:46:18]: [Client #204] Epoch: [2/5][10/16]	Loss: 1.565180
[INFO][13:46:18]: [Client #204] Going to sleep for 1.79 seconds.
[INFO][13:46:20]: [Client #897] Woke up.
[INFO][13:46:20]: [Client #897] Epoch: [2/5][0/16]	Loss: 2.105352
[INFO][13:46:20]: [Client #897] Epoch: [2/5][10/16]	Loss: 2.715498
[INFO][13:46:20]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][13:46:20]: [Client #204] Woke up.
[INFO][13:46:20]: [Client #204] Epoch: [3/5][0/16]	Loss: 3.138356
[INFO][13:46:20]: [Client #204] Epoch: [3/5][10/16]	Loss: 1.967355
[INFO][13:46:20]: [Client #204] Going to sleep for 1.79 seconds.
[INFO][13:46:22]: [Client #204] Woke up.
[INFO][13:46:22]: [Client #204] Epoch: [4/5][0/16]	Loss: 2.639421
[INFO][13:46:22]: [Client #204] Epoch: [4/5][10/16]	Loss: 2.288653
[INFO][13:46:22]: [Client #204] Going to sleep for 1.79 seconds.
[INFO][13:46:23]: [Client #897] Woke up.
[INFO][13:46:23]: [Client #897] Epoch: [3/5][0/16]	Loss: 1.618814
[INFO][13:46:23]: [Client #897] Epoch: [3/5][10/16]	Loss: 2.811927
[INFO][13:46:23]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][13:46:24]: [Client #204] Woke up.
[INFO][13:46:24]: [Client #204] Epoch: [5/5][0/16]	Loss: 1.953415
[INFO][13:46:24]: [Client #204] Epoch: [5/5][10/16]	Loss: 1.276672
[INFO][13:46:24]: [Client #204] Going to sleep for 1.79 seconds.
[INFO][13:46:26]: [Client #204] Woke up.
[INFO][13:46:26]: [Client #204] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_204_615874.pth.
[INFO][13:46:26]: [Client #204] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_204_615874.pth.
[INFO][13:46:26]: [Client #204] Model trained.
[INFO][13:46:26]: [Client #204] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:46:26]: [Server #615782] Received 0.26 MB of payload data from client #204 (simulated).
[INFO][13:46:27]: [Client #897] Woke up.
[INFO][13:46:27]: [Client #897] Epoch: [4/5][0/16]	Loss: 2.505544
[INFO][13:46:27]: [Client #897] Epoch: [4/5][10/16]	Loss: 1.555354
[INFO][13:46:27]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][13:46:30]: [Client #897] Woke up.
[INFO][13:46:30]: [Client #897] Epoch: [5/5][0/16]	Loss: 2.047155
[INFO][13:46:30]: [Client #897] Epoch: [5/5][10/16]	Loss: 2.646111
[INFO][13:46:30]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][13:46:34]: [Client #897] Woke up.
[INFO][13:46:34]: [Client #897] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_897_615875.pth.
[INFO][13:46:35]: [Client #897] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_897_615875.pth.
[INFO][13:46:35]: [Client #897] Model trained.
[INFO][13:46:35]: [Client #897] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:46:35]: [Server #615782] Received 0.26 MB of payload data from client #897 (simulated).
[INFO][13:46:35]: [Server #615782] Selecting client #873 for training.
[INFO][13:46:35]: [Server #615782] Sending the current model to client #873 (simulated).
[INFO][13:46:35]: [Server #615782] Sending 0.26 MB of payload data to client #873 (simulated).
[INFO][13:46:35]: [Server #615782] Selecting client #698 for training.
[INFO][13:46:35]: [Server #615782] Sending the current model to client #698 (simulated).
[INFO][13:46:35]: [Server #615782] Sending 0.26 MB of payload data to client #698 (simulated).
[INFO][13:46:35]: [Client #698] Selected by the server.
[INFO][13:46:35]: [Client #873] Selected by the server.
[INFO][13:46:35]: [Client #698] Loading its data source...
[INFO][13:46:35]: Data source: FEMNIST
[INFO][13:46:35]: [Client #873] Loading its data source...
[INFO][13:46:35]: Data source: FEMNIST
[INFO][13:46:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:46:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:46:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/698.zip.
[INFO][13:46:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/873.zip.
3.3%6.6%9.9%13.2%16.5%19.8%23.1%26.4%29.7%33.0%36.3%39.6%42.9%46.2%49.5%52.8%56.1%2.8%5.6%8.4%11.2%14.0%16.8%19.6%22.4%25.2%28.0%30.8%33.6%36.4%39.2%42.0%44.8%47.6%50.4%53.2%56.0%58.8%61.6%64.4%67.2%70.0%72.8%75.6%78.4%81.2%84.0%86.7%89.5%92.3%95.1%97.9%100.0%[INFO][13:46:35]: Decompressing the dataset downloaded.
[INFO][13:46:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/873.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
59.4%62.7%66.0%69.3%72.6%75.9%79.2%82.5%85.8%89.1%92.4%95.7%99.0%100.0%[INFO][13:46:35]: Decompressing the dataset downloaded.
[INFO][13:46:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/698.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:46:35]: [Client #873] Dataset size: 150
[INFO][13:46:35]: [Client #873] Sampler: all_inclusive
[INFO][13:46:35]: [Client #873] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:46:35]: [93m[1m[Client #873] Started training in communication round #5.[0m

[INFO][13:46:35]: [Client #698] Dataset size: 159
[INFO][13:46:35]: [Client #698] Sampler: all_inclusive
[INFO][13:46:35]: [Client #698] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:46:35]: [93m[1m[Client #698] Started training in communication round #5.[0m

[INFO][13:46:37]: [Client #698] Loading the dataset.
[INFO][13:46:37]: [Client #873] Loading the dataset.
[INFO][13:46:42]: [Client #698] Epoch: [1/5][0/16]	Loss: 2.640916
[INFO][13:46:42]: [Client #873] Epoch: [1/5][0/15]	Loss: 2.603105
[INFO][13:46:42]: [Client #698] Epoch: [1/5][10/16]	Loss: 1.998407
[INFO][13:46:42]: [Client #873] Epoch: [1/5][10/15]	Loss: 1.527766
[INFO][13:46:42]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][13:46:42]: [Client #873] Going to sleep for 0.73 seconds.
[INFO][13:46:43]: [Client #873] Woke up.
[INFO][13:46:43]: [Client #873] Epoch: [2/5][0/15]	Loss: 2.962420
[INFO][13:46:43]: [Client #873] Epoch: [2/5][10/15]	Loss: 2.994900
[INFO][13:46:43]: [Client #873] Going to sleep for 0.73 seconds.
[INFO][13:46:44]: [Client #873] Woke up.
[INFO][13:46:44]: [Client #873] Epoch: [3/5][0/15]	Loss: 2.000007
[INFO][13:46:44]: [Client #873] Epoch: [3/5][10/15]	Loss: 1.877969
[INFO][13:46:44]: [Client #873] Going to sleep for 0.73 seconds.
[INFO][13:46:45]: [Client #873] Woke up.
[INFO][13:46:45]: [Client #873] Epoch: [4/5][0/15]	Loss: 1.705868
[INFO][13:46:45]: [Client #873] Epoch: [4/5][10/15]	Loss: 1.449216
[INFO][13:46:45]: [Client #873] Going to sleep for 0.73 seconds.
[INFO][13:46:46]: [Client #873] Woke up.
[INFO][13:46:46]: [Client #873] Epoch: [5/5][0/15]	Loss: 1.498794
[INFO][13:46:46]: [Client #873] Epoch: [5/5][10/15]	Loss: 0.650731
[INFO][13:46:46]: [Client #873] Going to sleep for 0.73 seconds.
[INFO][13:46:47]: [Client #873] Woke up.
[INFO][13:46:47]: [Client #873] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_873_615874.pth.
[INFO][13:46:48]: [Client #873] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_873_615874.pth.
[INFO][13:46:48]: [Client #873] Model trained.
[INFO][13:46:48]: [Client #873] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:46:48]: [Server #615782] Received 0.26 MB of payload data from client #873 (simulated).
[INFO][13:46:50]: [Client #698] Woke up.
[INFO][13:46:50]: [Client #698] Epoch: [2/5][0/16]	Loss: 2.746923
[INFO][13:46:50]: [Client #698] Epoch: [2/5][10/16]	Loss: 2.389925
[INFO][13:46:50]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][13:46:58]: [Client #698] Woke up.
[INFO][13:46:58]: [Client #698] Epoch: [3/5][0/16]	Loss: 1.732526
[INFO][13:46:58]: [Client #698] Epoch: [3/5][10/16]	Loss: 3.182271
[INFO][13:46:58]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][13:47:05]: [Client #698] Woke up.
[INFO][13:47:05]: [Client #698] Epoch: [4/5][0/16]	Loss: 2.515115
[INFO][13:47:06]: [Client #698] Epoch: [4/5][10/16]	Loss: 1.608693
[INFO][13:47:06]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][13:47:13]: [Client #698] Woke up.
[INFO][13:47:13]: [Client #698] Epoch: [5/5][0/16]	Loss: 2.131846
[INFO][13:47:13]: [Client #698] Epoch: [5/5][10/16]	Loss: 1.919278
[INFO][13:47:13]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][13:47:21]: [Client #698] Woke up.
[INFO][13:47:21]: [Client #698] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615875.pth.
[INFO][13:47:21]: [Client #698] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615875.pth.
[INFO][13:47:21]: [Client #698] Model trained.
[INFO][13:47:21]: [Client #698] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:47:22]: [Server #615782] Received 0.26 MB of payload data from client #698 (simulated).
[INFO][13:47:22]: [Server #615782] Selecting client #469 for training.
[INFO][13:47:22]: [Server #615782] Sending the current model to client #469 (simulated).
[INFO][13:47:22]: [Server #615782] Sending 0.26 MB of payload data to client #469 (simulated).
[INFO][13:47:22]: [Client #469] Selected by the server.
[INFO][13:47:22]: [Client #469] Loading its data source...
[INFO][13:47:22]: Data source: FEMNIST
[INFO][13:47:22]: [Client #469] Dataset size: 163
[INFO][13:47:22]: [Client #469] Sampler: all_inclusive
[INFO][13:47:22]: [Client #469] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:47:22]: [93m[1m[Client #469] Started training in communication round #5.[0m
[INFO][13:47:23]: [Client #469] Loading the dataset.
[INFO][13:47:29]: [Client #469] Epoch: [1/5][0/17]	Loss: 2.460423
[INFO][13:47:29]: [Client #469] Epoch: [1/5][10/17]	Loss: 1.995941
[INFO][13:47:29]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][13:47:30]: [Client #469] Woke up.
[INFO][13:47:30]: [Client #469] Epoch: [2/5][0/17]	Loss: 2.485440
[INFO][13:47:30]: [Client #469] Epoch: [2/5][10/17]	Loss: 1.813837
[INFO][13:47:30]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][13:47:31]: [Client #469] Woke up.
[INFO][13:47:31]: [Client #469] Epoch: [3/5][0/17]	Loss: 2.234184
[INFO][13:47:31]: [Client #469] Epoch: [3/5][10/17]	Loss: 2.212904
[INFO][13:47:31]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][13:47:33]: [Client #469] Woke up.
[INFO][13:47:33]: [Client #469] Epoch: [4/5][0/17]	Loss: 1.949220
[INFO][13:47:33]: [Client #469] Epoch: [4/5][10/17]	Loss: 2.223579
[INFO][13:47:33]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][13:47:34]: [Client #469] Woke up.
[INFO][13:47:34]: [Client #469] Epoch: [5/5][0/17]	Loss: 1.281540
[INFO][13:47:34]: [Client #469] Epoch: [5/5][10/17]	Loss: 2.029711
[INFO][13:47:34]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][13:47:35]: [Client #469] Woke up.
[INFO][13:47:35]: [Client #469] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_615874.pth.
[INFO][13:47:36]: [Client #469] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_615874.pth.
[INFO][13:47:36]: [Client #469] Model trained.
[INFO][13:47:36]: [Client #469] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:47:36]: [Server #615782] Received 0.26 MB of payload data from client #469 (simulated).
[INFO][13:47:36]: [Server #615782] Adding client #149 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #395 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #629 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #330 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #957 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #823 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #414 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #735 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #879 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #121 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #143 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #866 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #428 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #912 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #818 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #187 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #778 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #354 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #590 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #580 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #307 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #635 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #890 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #684 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #873 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #1 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #845 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #469 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #74 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #991 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #227 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #486 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #204 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #558 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #683 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #344 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #261 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #851 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #897 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #186 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #419 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #974 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #698 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #190 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #730 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #200 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #22 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #533 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #895 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Adding client #172 to the list of clients for aggregation.
[INFO][13:47:36]: [Server #615782] Aggregating 50 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 731, 732, 733, 734, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.40456231 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.25933001 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08138441 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0909719  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09196848 0.
 0.         0.         0.         0.         0.04133571 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09031373 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06827378
 0.14737531 0.         0.         0.0863171  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22157389 0.         0.         0.         0.08772732
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06912227 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16667752 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13054083 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08042254
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06517119 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11348163
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0892471  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08260009
 0.         0.         0.         0.         0.0754519  0.
 0.         0.         0.         0.         0.         0.
 0.         0.10955694 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09360794 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11228607
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16906401 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07512998
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11543609 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10313137 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12102389 0.
 0.         0.         0.         0.         0.05503436 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.074668   0.04827836
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22406095 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19054027 0.         0.
 0.         0.         0.10296295 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.26356748 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06426997 0.         0.         0.         0.
 0.05002004 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07394814 0.
 0.         0.         0.         0.         0.06648862 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12016512 0.         0.         0.         0.
 0.         0.         0.08580749 0.         0.         0.
 0.         0.         0.04336802 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.51660363 0.         0.         0.         0.
 0.05320102 0.         0.12389899 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07958714
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07681265 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09192007 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.038877   0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.40456231 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.25933001 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08138441 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0909719  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09196848 0.
 0.         0.         0.         0.         0.04133571 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09031373 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06827378
 0.14737531 0.         0.         0.0863171  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22157389 0.         0.         0.         0.08772732
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06912227 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16667752 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13054083 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08042254
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06517119 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11348163
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0892471  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08260009
 0.         0.         0.         0.         0.0754519  0.
 0.         0.         0.         0.         0.         0.
 0.         0.10955694 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09360794 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11228607
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16906401 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07512998
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11543609 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10313137 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12102389 0.
 0.         0.         0.         0.         0.05503436 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.074668   0.04827836
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22406095 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19054027 0.         0.
 0.         0.         0.10296295 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.26356748 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06426997 0.         0.         0.         0.
 0.05002004 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07394814 0.
 0.         0.         0.         0.         0.06648862 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12016512 0.         0.         0.         0.
 0.         0.         0.08580749 0.         0.         0.
 0.         0.         0.04336802 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.51660363 0.         0.         0.         0.
 0.05320102 0.         0.12389899 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07958714
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07681265 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09192007 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.038877   0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.001
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03395445 0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.001      0.001
 0.001      0.02014495 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.001      0.001      0.001      0.01916227 0.001
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02014495 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01633706
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03416149
 0.001      0.03906154 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.001
 0.001      0.01879376 0.05656805 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01879376 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0212766  0.001
 0.001      0.001      0.03932316 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03881657 0.001      0.001      0.001
 0.001      0.03836988 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.03353396 0.001
 0.001      0.001      0.02284735 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01830242
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.001
 0.001      0.01879376 0.001      0.0310559  0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02084821 0.001      0.001      0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.02056262 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.001      0.001      0.001      0.001      0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02199058 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01658273
 0.001      0.0212766  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.01953077 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.01817958 0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.001      0.001      0.001      0.001      0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02857143 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.001      0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.001      0.02184778
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.03739645 0.001      0.001
 0.001      0.001      0.0192851  0.001      0.02141939 0.01925466
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.001      0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0321735  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.01879376 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01940794 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.001      0.001     ][INFO][13:48:18]: [Server #615782] Global model accuracy: 32.42%

[INFO][13:48:18]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_5.pth.
[INFO][13:48:18]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_5.pth.
[INFO][13:48:18]: [93m[1m
[Server #615782] Starting round 6/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.6009e+00  1e+03  1e+00  1e+00
 1:  7.5249e+00  6.6020e+00  1e+01  1e-02  1e-02
 2:  7.6002e+00  6.6912e+00  1e+00  9e-05  9e-05
 3:  7.6009e+00  7.5207e+00  8e-02  4e-07  4e-07
 4:  7.6009e+00  7.6000e+00  9e-04  4e-09  4e-09
 5:  7.6009e+00  7.6008e+00  1e-04  5e-10  5e-10
 6:  7.6009e+00  7.6008e+00  1e-04  3e-10  3e-10
 7:  7.6009e+00  7.6008e+00  1e-04  6e-09  1e-09
 8:  7.6009e+00  7.6008e+00  8e-05  6e-09  1e-09
 9:  7.6009e+00  7.6008e+00  5e-05  2e-08  5e-09
10:  7.6008e+00  7.6008e+00  3e-05  3e-08  6e-09
11:  7.6008e+00  7.6008e+00  2e-05  1e-09  3e-10
12:  7.6008e+00  7.6008e+00  1e-05  4e-09  7e-10
13:  7.6008e+00  7.6008e+00  2e-06  2e-09  3e-10
Optimal solution found.
The calculated probability is:  [2.66230835e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66372897e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 4.92759826e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66407785e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66407862e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 3.47650570e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 5.43126833e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66410668e-05 2.66399257e-05 2.66412544e-05
 2.66412544e-05 5.19378231e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 8.14898115e-01
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66408338e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66409966e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66395960e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66402371e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 4.87883178e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 4.21616147e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66405953e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 5.36583223e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 4.99067363e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66409821e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 6.95865242e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66407248e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66405202e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 4.23253336e-04 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66409693e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66410143e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 6.36242537e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 8.34982748e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 3.86653606e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66409378e-05 3.66387628e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66383677e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 1.57600796e-01 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 6.34811337e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66290479e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66409986e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 3.71406691e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 4.57386408e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 4.26630100e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 8.22602087e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66408775e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 3.52934768e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66255281e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 3.80937656e-05 2.66412544e-05
 2.66403937e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66409430e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 4.70398706e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66407746e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 3.41463951e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05
 2.66412544e-05 2.66412544e-05 2.66412544e-05 2.66412544e-05][INFO][13:48:22]: [Server #615782] Selected clients: [453 200 730 588 787 103 533 374 601 958 401 790 641 402 686 413 140 459
 342 223 925 596 745 538 698 930 863 172 270  74 979 242 657  92 216 513
 108 397 534 347 553 399 693 675 684 559 366 619 937 603]
[INFO][13:48:22]: [Server #615782] Selecting client #453 for training.
[INFO][13:48:22]: [Server #615782] Sending the current model to client #453 (simulated).
[INFO][13:48:22]: [Server #615782] Sending 0.26 MB of payload data to client #453 (simulated).
[INFO][13:48:22]: [Server #615782] Selecting client #200 for training.
[INFO][13:48:22]: [Server #615782] Sending the current model to client #200 (simulated).
[INFO][13:48:22]: [Server #615782] Sending 0.26 MB of payload data to client #200 (simulated).
[INFO][13:48:22]: [Client #453] Selected by the server.
[INFO][13:48:22]: [Client #453] Loading its data source...
[INFO][13:48:22]: Data source: FEMNIST
[INFO][13:48:22]: [Client #200] Selected by the server.
[INFO][13:48:22]: [Client #200] Loading its data source...
[INFO][13:48:22]: Data source: FEMNIST
[INFO][13:48:22]: [Client #200] Dataset size: 318
[INFO][13:48:22]: [Client #200] Sampler: all_inclusive
[INFO][13:48:22]: [Client #200] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:48:22]: [93m[1m[Client #200] Started training in communication round #6.[0m
[INFO][13:48:22]: [Client #453] Dataset size: 151
[INFO][13:48:22]: [Client #453] Sampler: all_inclusive
[INFO][13:48:22]: [Client #453] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:48:22]: [93m[1m[Client #453] Started training in communication round #6.[0m
[INFO][13:48:24]: [Client #200] Loading the dataset.
[INFO][13:48:24]: [Client #453] Loading the dataset.
[INFO][13:48:29]: [Client #453] Epoch: [1/5][0/16]	Loss: 1.692945
[INFO][13:48:29]: [Client #200] Epoch: [1/5][0/32]	Loss: 2.493063
[INFO][13:48:29]: [Client #453] Epoch: [1/5][10/16]	Loss: 1.809434
[INFO][13:48:29]: [Client #200] Epoch: [1/5][10/32]	Loss: 2.875513
[INFO][13:48:29]: [Client #453] Going to sleep for 9.62 seconds.
[INFO][13:48:29]: [Client #200] Epoch: [1/5][20/32]	Loss: 3.570252
[INFO][13:48:29]: [Client #200] Epoch: [1/5][30/32]	Loss: 2.572294
[INFO][13:48:29]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:48:39]: [Client #453] Woke up.
[INFO][13:48:39]: [Client #453] Epoch: [2/5][0/16]	Loss: 2.174433
[INFO][13:48:39]: [Client #453] Epoch: [2/5][10/16]	Loss: 1.882445
[INFO][13:48:39]: [Client #453] Going to sleep for 9.62 seconds.
[INFO][13:48:48]: [Client #200] Woke up.
[INFO][13:48:48]: [Client #200] Epoch: [2/5][0/32]	Loss: 1.667363
[INFO][13:48:48]: [Client #200] Epoch: [2/5][10/32]	Loss: 2.367580
[INFO][13:48:48]: [Client #200] Epoch: [2/5][20/32]	Loss: 2.219248
[INFO][13:48:48]: [Client #200] Epoch: [2/5][30/32]	Loss: 3.574102
[INFO][13:48:48]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:48:49]: [Client #453] Woke up.
[INFO][13:48:49]: [Client #453] Epoch: [3/5][0/16]	Loss: 2.247841
[INFO][13:48:49]: [Client #453] Epoch: [3/5][10/16]	Loss: 2.061700
[INFO][13:48:49]: [Client #453] Going to sleep for 9.62 seconds.
[INFO][13:48:58]: [Client #453] Woke up.
[INFO][13:48:58]: [Client #453] Epoch: [4/5][0/16]	Loss: 0.736286
[INFO][13:48:58]: [Client #453] Epoch: [4/5][10/16]	Loss: 2.076795
[INFO][13:48:58]: [Client #453] Going to sleep for 9.62 seconds.
[INFO][13:49:07]: [Client #200] Woke up.
[INFO][13:49:07]: [Client #200] Epoch: [3/5][0/32]	Loss: 1.820703
[INFO][13:49:07]: [Client #200] Epoch: [3/5][10/32]	Loss: 2.507959
[INFO][13:49:07]: [Client #200] Epoch: [3/5][20/32]	Loss: 1.746332
[INFO][13:49:07]: [Client #200] Epoch: [3/5][30/32]	Loss: 2.009108
[INFO][13:49:07]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:49:08]: [Client #453] Woke up.
[INFO][13:49:08]: [Client #453] Epoch: [5/5][0/16]	Loss: 1.970252
[INFO][13:49:08]: [Client #453] Epoch: [5/5][10/16]	Loss: 1.679745
[INFO][13:49:08]: [Client #453] Going to sleep for 9.62 seconds.
[INFO][13:49:18]: [Client #453] Woke up.
[INFO][13:49:18]: [Client #453] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_453_615874.pth.
[INFO][13:49:18]: [Client #453] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_453_615874.pth.
[INFO][13:49:18]: [Client #453] Model trained.
[INFO][13:49:18]: [Client #453] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:49:19]: [Server #615782] Received 0.26 MB of payload data from client #453 (simulated).
[INFO][13:49:26]: [Client #200] Woke up.
[INFO][13:49:26]: [Client #200] Epoch: [4/5][0/32]	Loss: 1.444853
[INFO][13:49:26]: [Client #200] Epoch: [4/5][10/32]	Loss: 1.962579
[INFO][13:49:26]: [Client #200] Epoch: [4/5][20/32]	Loss: 1.656069
[INFO][13:49:26]: [Client #200] Epoch: [4/5][30/32]	Loss: 3.575427
[INFO][13:49:26]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:49:45]: [Client #200] Woke up.
[INFO][13:49:45]: [Client #200] Epoch: [5/5][0/32]	Loss: 1.945302
[INFO][13:49:45]: [Client #200] Epoch: [5/5][10/32]	Loss: 2.068839
[INFO][13:49:45]: [Client #200] Epoch: [5/5][20/32]	Loss: 0.922739
[INFO][13:49:45]: [Client #200] Epoch: [5/5][30/32]	Loss: 1.406073
[INFO][13:49:45]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][13:50:04]: [Client #200] Woke up.
[INFO][13:50:04]: [Client #200] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][13:50:05]: [Client #200] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][13:50:05]: [Client #200] Model trained.
[INFO][13:50:05]: [Client #200] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:50:05]: [Server #615782] Received 0.26 MB of payload data from client #200 (simulated).
[INFO][13:50:05]: [Server #615782] Selecting client #730 for training.
[INFO][13:50:05]: [Server #615782] Sending the current model to client #730 (simulated).
[INFO][13:50:05]: [Server #615782] Sending 0.26 MB of payload data to client #730 (simulated).
[INFO][13:50:05]: [Server #615782] Selecting client #588 for training.
[INFO][13:50:05]: [Server #615782] Sending the current model to client #588 (simulated).
[INFO][13:50:05]: [Server #615782] Sending 0.26 MB of payload data to client #588 (simulated).
[INFO][13:50:05]: [Client #730] Selected by the server.
[INFO][13:50:05]: [Client #588] Selected by the server.
[INFO][13:50:05]: [Client #730] Loading its data source...
[INFO][13:50:05]: [Client #588] Loading its data source...
[INFO][13:50:05]: Data source: FEMNIST
[INFO][13:50:05]: Data source: FEMNIST
[INFO][13:50:05]: [Client #588] Dataset size: 133
[INFO][13:50:05]: [Client #588] Sampler: all_inclusive
[INFO][13:50:05]: [Client #730] Dataset size: 148
[INFO][13:50:05]: [Client #730] Sampler: all_inclusive
[INFO][13:50:05]: [Client #730] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:50:05]: [Client #588] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:50:05]: [93m[1m[Client #730] Started training in communication round #6.[0m
[INFO][13:50:05]: [93m[1m[Client #588] Started training in communication round #6.[0m
[INFO][13:50:06]: [Client #730] Loading the dataset.
[INFO][13:50:07]: [Client #588] Loading the dataset.
[INFO][13:50:12]: [Client #588] Epoch: [1/5][0/14]	Loss: 1.366568
[INFO][13:50:12]: [Client #730] Epoch: [1/5][0/15]	Loss: 2.366588
[INFO][13:50:12]: [Client #588] Epoch: [1/5][10/14]	Loss: 1.503025
[INFO][13:50:12]: [Client #588] Going to sleep for 0.55 seconds.
[INFO][13:50:12]: [Client #730] Epoch: [1/5][10/15]	Loss: 2.618953
[INFO][13:50:12]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:50:13]: [Client #588] Woke up.
[INFO][13:50:13]: [Client #588] Epoch: [2/5][0/14]	Loss: 1.259059
[INFO][13:50:13]: [Client #588] Epoch: [2/5][10/14]	Loss: 3.912464
[INFO][13:50:13]: [Client #588] Going to sleep for 0.55 seconds.
[INFO][13:50:13]: [Client #588] Woke up.
[INFO][13:50:13]: [Client #588] Epoch: [3/5][0/14]	Loss: 1.930339
[INFO][13:50:13]: [Client #588] Epoch: [3/5][10/14]	Loss: 2.056384
[INFO][13:50:13]: [Client #588] Going to sleep for 0.55 seconds.
[INFO][13:50:14]: [Client #588] Woke up.
[INFO][13:50:14]: [Client #588] Epoch: [4/5][0/14]	Loss: 1.089841
[INFO][13:50:14]: [Client #588] Epoch: [4/5][10/14]	Loss: 1.511541
[INFO][13:50:14]: [Client #588] Going to sleep for 0.55 seconds.
[INFO][13:50:15]: [Client #588] Woke up.
[INFO][13:50:15]: [Client #588] Epoch: [5/5][0/14]	Loss: 1.847417
[INFO][13:50:15]: [Client #588] Epoch: [5/5][10/14]	Loss: 1.911356
[INFO][13:50:15]: [Client #588] Going to sleep for 0.55 seconds.
[INFO][13:50:15]: [Client #588] Woke up.
[INFO][13:50:15]: [Client #588] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_588_615875.pth.
[INFO][13:50:16]: [Client #588] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_588_615875.pth.
[INFO][13:50:16]: [Client #588] Model trained.
[INFO][13:50:16]: [Client #588] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:50:16]: [Server #615782] Received 0.26 MB of payload data from client #588 (simulated).
[INFO][13:50:29]: [Client #730] Woke up.
[INFO][13:50:29]: [Client #730] Epoch: [2/5][0/15]	Loss: 2.777869
[INFO][13:50:29]: [Client #730] Epoch: [2/5][10/15]	Loss: 2.375217
[INFO][13:50:29]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:50:45]: [Client #730] Woke up.
[INFO][13:50:45]: [Client #730] Epoch: [3/5][0/15]	Loss: 1.735958
[INFO][13:50:45]: [Client #730] Epoch: [3/5][10/15]	Loss: 1.761203
[INFO][13:50:45]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:51:02]: [Client #730] Woke up.
[INFO][13:51:02]: [Client #730] Epoch: [4/5][0/15]	Loss: 2.949893
[INFO][13:51:02]: [Client #730] Epoch: [4/5][10/15]	Loss: 2.054715
[INFO][13:51:02]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:51:19]: [Client #730] Woke up.
[INFO][13:51:19]: [Client #730] Epoch: [5/5][0/15]	Loss: 1.449382
[INFO][13:51:19]: [Client #730] Epoch: [5/5][10/15]	Loss: 2.169860
[INFO][13:51:19]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][13:51:35]: [Client #730] Woke up.
[INFO][13:51:35]: [Client #730] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615874.pth.
[INFO][13:51:36]: [Client #730] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615874.pth.
[INFO][13:51:36]: [Client #730] Model trained.
[INFO][13:51:36]: [Client #730] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:51:36]: [Server #615782] Received 0.26 MB of payload data from client #730 (simulated).
[INFO][13:51:36]: [Server #615782] Selecting client #787 for training.
[INFO][13:51:36]: [Server #615782] Sending the current model to client #787 (simulated).
[INFO][13:51:36]: [Server #615782] Sending 0.26 MB of payload data to client #787 (simulated).
[INFO][13:51:36]: [Server #615782] Selecting client #103 for training.
[INFO][13:51:36]: [Server #615782] Sending the current model to client #103 (simulated).
[INFO][13:51:36]: [Server #615782] Sending 0.26 MB of payload data to client #103 (simulated).
[INFO][13:51:36]: [Client #787] Selected by the server.
[INFO][13:51:36]: [Client #787] Loading its data source...
[INFO][13:51:36]: Data source: FEMNIST
[INFO][13:51:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:51:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/787.zip.
[INFO][13:51:36]: [Client #103] Selected by the server.
[INFO][13:51:36]: [Client #103] Loading its data source...
[INFO][13:51:36]: Data source: FEMNIST
[INFO][13:51:36]: [Client #103] Dataset size: 159
[INFO][13:51:36]: [Client #103] Sampler: all_inclusive
[INFO][13:51:36]: [Client #103] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:51:36]: [93m[1m[Client #103] Started training in communication round #6.[0m
2.5%4.9%7.4%9.8%12.3%14.7%17.2%19.7%22.1%24.6%27.0%29.5%32.0%34.4%36.9%39.3%41.8%44.2%46.7%49.2%51.6%54.1%56.5%59.0%61.5%63.9%66.4%68.8%71.3%73.7%76.2%78.7%81.1%83.6%86.0%88.5%91.0%93.4%95.9%98.3%100.0%[INFO][13:51:36]: Decompressing the dataset downloaded.
[INFO][13:51:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/787.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:51:36]: [Client #787] Dataset size: 163
[INFO][13:51:36]: [Client #787] Sampler: all_inclusive
[INFO][13:51:36]: [Client #787] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:51:36]: [93m[1m[Client #787] Started training in communication round #6.[0m

[INFO][13:51:38]: [Client #103] Loading the dataset.
[INFO][13:51:38]: [Client #787] Loading the dataset.
[INFO][13:51:44]: [Client #787] Epoch: [1/5][0/17]	Loss: 2.036521
[INFO][13:51:44]: [Client #103] Epoch: [1/5][0/16]	Loss: 2.008816
[INFO][13:51:44]: [Client #787] Epoch: [1/5][10/17]	Loss: 1.852545
[INFO][13:51:44]: [Client #103] Epoch: [1/5][10/16]	Loss: 1.974048
[INFO][13:51:44]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][13:51:44]: [Client #103] Going to sleep for 7.77 seconds.
[INFO][13:51:50]: [Client #787] Woke up.
[INFO][13:51:50]: [Client #787] Epoch: [2/5][0/17]	Loss: 1.518769
[INFO][13:51:50]: [Client #787] Epoch: [2/5][10/17]	Loss: 3.246884
[INFO][13:51:50]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][13:51:51]: [Client #103] Woke up.
[INFO][13:51:52]: [Client #103] Epoch: [2/5][0/16]	Loss: 1.881585
[INFO][13:51:52]: [Client #103] Epoch: [2/5][10/16]	Loss: 2.262308
[INFO][13:51:52]: [Client #103] Going to sleep for 7.77 seconds.
[INFO][13:51:56]: [Client #787] Woke up.
[INFO][13:51:56]: [Client #787] Epoch: [3/5][0/17]	Loss: 2.551441
[INFO][13:51:56]: [Client #787] Epoch: [3/5][10/17]	Loss: 2.326574
[INFO][13:51:56]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][13:51:59]: [Client #103] Woke up.
[INFO][13:51:59]: [Client #103] Epoch: [3/5][0/16]	Loss: 1.880166
[INFO][13:52:00]: [Client #103] Epoch: [3/5][10/16]	Loss: 2.223429
[INFO][13:52:00]: [Client #103] Going to sleep for 7.77 seconds.
[INFO][13:52:02]: [Client #787] Woke up.
[INFO][13:52:02]: [Client #787] Epoch: [4/5][0/17]	Loss: 2.165001
[INFO][13:52:02]: [Client #787] Epoch: [4/5][10/17]	Loss: 2.628927
[INFO][13:52:02]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][13:52:07]: [Client #103] Woke up.
[INFO][13:52:07]: [Client #103] Epoch: [4/5][0/16]	Loss: 1.667217
[INFO][13:52:07]: [Client #103] Epoch: [4/5][10/16]	Loss: 2.084414
[INFO][13:52:07]: [Client #103] Going to sleep for 7.77 seconds.
[INFO][13:52:08]: [Client #787] Woke up.
[INFO][13:52:08]: [Client #787] Epoch: [5/5][0/17]	Loss: 1.599923
[INFO][13:52:08]: [Client #787] Epoch: [5/5][10/17]	Loss: 2.078411
[INFO][13:52:08]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][13:52:14]: [Client #787] Woke up.
[INFO][13:52:14]: [Client #787] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_787_615874.pth.
[INFO][13:52:15]: [Client #787] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_787_615874.pth.
[INFO][13:52:15]: [Client #787] Model trained.
[INFO][13:52:15]: [Client #787] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:52:15]: [Server #615782] Received 0.26 MB of payload data from client #787 (simulated).
[INFO][13:52:15]: [Client #103] Woke up.
[INFO][13:52:15]: [Client #103] Epoch: [5/5][0/16]	Loss: 1.197787
[INFO][13:52:15]: [Client #103] Epoch: [5/5][10/16]	Loss: 1.398042
[INFO][13:52:15]: [Client #103] Going to sleep for 7.77 seconds.
[INFO][13:52:23]: [Client #103] Woke up.
[INFO][13:52:23]: [Client #103] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_103_615875.pth.
[INFO][13:52:24]: [Client #103] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_103_615875.pth.
[INFO][13:52:24]: [Client #103] Model trained.
[INFO][13:52:24]: [Client #103] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:52:24]: [Server #615782] Received 0.26 MB of payload data from client #103 (simulated).
[INFO][13:52:24]: [Server #615782] Selecting client #533 for training.
[INFO][13:52:24]: [Server #615782] Sending the current model to client #533 (simulated).
[INFO][13:52:24]: [Server #615782] Sending 0.26 MB of payload data to client #533 (simulated).
[INFO][13:52:24]: [Server #615782] Selecting client #374 for training.
[INFO][13:52:24]: [Server #615782] Sending the current model to client #374 (simulated).
[INFO][13:52:24]: [Server #615782] Sending 0.26 MB of payload data to client #374 (simulated).
[INFO][13:52:24]: [Client #533] Selected by the server.
[INFO][13:52:24]: [Client #374] Selected by the server.
[INFO][13:52:24]: [Client #533] Loading its data source...
[INFO][13:52:24]: [Client #374] Loading its data source...
[INFO][13:52:24]: Data source: FEMNIST
[INFO][13:52:24]: Data source: FEMNIST
[INFO][13:52:24]: [Client #533] Dataset size: 273
[INFO][13:52:24]: [Client #533] Sampler: all_inclusive
[INFO][13:52:24]: [Client #533] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:52:24]: [93m[1m[Client #533] Started training in communication round #6.[0m
[INFO][13:52:24]: [Client #374] Dataset size: 155
[INFO][13:52:24]: [Client #374] Sampler: all_inclusive
[INFO][13:52:24]: [Client #374] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:52:24]: [93m[1m[Client #374] Started training in communication round #6.[0m
[INFO][13:52:26]: [Client #533] Loading the dataset.
[INFO][13:52:26]: [Client #374] Loading the dataset.
[INFO][13:52:32]: [Client #533] Epoch: [1/5][0/28]	Loss: 2.315093
[INFO][13:52:32]: [Client #374] Epoch: [1/5][0/16]	Loss: 2.148906
[INFO][13:52:32]: [Client #533] Epoch: [1/5][10/28]	Loss: 3.791613
[INFO][13:52:32]: [Client #374] Epoch: [1/5][10/16]	Loss: 1.769374
[INFO][13:52:32]: [Client #533] Epoch: [1/5][20/28]	Loss: 2.782858
[INFO][13:52:32]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][13:52:32]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:52:35]: [Client #374] Woke up.
[INFO][13:52:35]: [Client #374] Epoch: [2/5][0/16]	Loss: 2.128594
[INFO][13:52:35]: [Client #374] Epoch: [2/5][10/16]	Loss: 2.849750
[INFO][13:52:35]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][13:52:38]: [Client #374] Woke up.
[INFO][13:52:38]: [Client #374] Epoch: [3/5][0/16]	Loss: 1.583027
[INFO][13:52:38]: [Client #374] Epoch: [3/5][10/16]	Loss: 2.148503
[INFO][13:52:38]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][13:52:41]: [Client #374] Woke up.
[INFO][13:52:41]: [Client #374] Epoch: [4/5][0/16]	Loss: 2.368653
[INFO][13:52:41]: [Client #374] Epoch: [4/5][10/16]	Loss: 1.999012
[INFO][13:52:41]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][13:52:44]: [Client #374] Woke up.
[INFO][13:52:44]: [Client #374] Epoch: [5/5][0/16]	Loss: 2.076301
[INFO][13:52:44]: [Client #374] Epoch: [5/5][10/16]	Loss: 1.548509
[INFO][13:52:44]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][13:52:47]: [Client #374] Woke up.
[INFO][13:52:47]: [Client #374] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_374_615875.pth.
[INFO][13:52:48]: [Client #374] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_374_615875.pth.
[INFO][13:52:48]: [Client #374] Model trained.
[INFO][13:52:48]: [Client #374] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:52:48]: [Server #615782] Received 0.26 MB of payload data from client #374 (simulated).
[INFO][13:53:08]: [Client #533] Woke up.
[INFO][13:53:08]: [Client #533] Epoch: [2/5][0/28]	Loss: 2.890944
[INFO][13:53:08]: [Client #533] Epoch: [2/5][10/28]	Loss: 3.085769
[INFO][13:53:08]: [Client #533] Epoch: [2/5][20/28]	Loss: 2.187126
[INFO][13:53:08]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:53:44]: [Client #533] Woke up.
[INFO][13:53:44]: [Client #533] Epoch: [3/5][0/28]	Loss: 2.360602
[INFO][13:53:44]: [Client #533] Epoch: [3/5][10/28]	Loss: 2.523192
[INFO][13:53:44]: [Client #533] Epoch: [3/5][20/28]	Loss: 1.444520
[INFO][13:53:44]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:54:20]: [Client #533] Woke up.
[INFO][13:54:20]: [Client #533] Epoch: [4/5][0/28]	Loss: 1.846488
[INFO][13:54:20]: [Client #533] Epoch: [4/5][10/28]	Loss: 2.845231
[INFO][13:54:20]: [Client #533] Epoch: [4/5][20/28]	Loss: 1.379645
[INFO][13:54:20]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:54:56]: [Client #533] Woke up.
[INFO][13:54:56]: [Client #533] Epoch: [5/5][0/28]	Loss: 2.570765
[INFO][13:54:56]: [Client #533] Epoch: [5/5][10/28]	Loss: 1.632130
[INFO][13:54:57]: [Client #533] Epoch: [5/5][20/28]	Loss: 1.966493
[INFO][13:54:57]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][13:55:32]: [Client #533] Woke up.
[INFO][13:55:32]: [Client #533] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615874.pth.
[INFO][13:55:33]: [Client #533] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615874.pth.
[INFO][13:55:33]: [Client #533] Model trained.
[INFO][13:55:33]: [Client #533] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:55:33]: [Server #615782] Received 0.26 MB of payload data from client #533 (simulated).
[INFO][13:55:33]: [Server #615782] Selecting client #601 for training.
[INFO][13:55:33]: [Server #615782] Sending the current model to client #601 (simulated).
[INFO][13:55:33]: [Server #615782] Sending 0.26 MB of payload data to client #601 (simulated).
[INFO][13:55:33]: [Server #615782] Selecting client #958 for training.
[INFO][13:55:33]: [Server #615782] Sending the current model to client #958 (simulated).
[INFO][13:55:33]: [Server #615782] Sending 0.26 MB of payload data to client #958 (simulated).
[INFO][13:55:33]: [Client #601] Selected by the server.
[INFO][13:55:33]: [Client #601] Loading its data source...
[INFO][13:55:33]: Data source: FEMNIST
[INFO][13:55:33]: [Client #958] Selected by the server.
[INFO][13:55:33]: [Client #958] Loading its data source...
[INFO][13:55:33]: Data source: FEMNIST
[INFO][13:55:33]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:55:33]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/958.zip.
[INFO][13:55:33]: [Client #601] Dataset size: 146
[INFO][13:55:33]: [Client #601] Sampler: all_inclusive
[INFO][13:55:33]: [Client #601] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:55:33]: [93m[1m[Client #601] Started training in communication round #6.[0m
2.8%5.5%8.3%11.0%13.8%16.5%19.3%22.0%24.8%27.6%30.3%33.1%35.8%38.6%41.3%44.1%46.9%49.6%52.4%55.1%57.9%60.6%63.4%66.1%68.9%71.7%74.4%77.2%79.9%82.7%85.4%88.2%91.0%93.7%96.5%99.2%100.0%[INFO][13:55:33]: Decompressing the dataset downloaded.
[INFO][13:55:33]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/958.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:55:33]: [Client #958] Dataset size: 159
[INFO][13:55:33]: [Client #958] Sampler: all_inclusive
[INFO][13:55:33]: [Client #958] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:55:33]: [93m[1m[Client #958] Started training in communication round #6.[0m

[INFO][13:55:35]: [Client #601] Loading the dataset.
[INFO][13:55:35]: [Client #958] Loading the dataset.
[INFO][13:55:41]: [Client #958] Epoch: [1/5][0/16]	Loss: 1.871124
[INFO][13:55:41]: [Client #601] Epoch: [1/5][0/15]	Loss: 2.269784
[INFO][13:55:41]: [Client #958] Epoch: [1/5][10/16]	Loss: 1.808586
[INFO][13:55:41]: [Client #601] Epoch: [1/5][10/15]	Loss: 3.168230
[INFO][13:55:41]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][13:55:41]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][13:55:42]: [Client #958] Woke up.
[INFO][13:55:42]: [Client #958] Epoch: [2/5][0/16]	Loss: 1.326651
[INFO][13:55:42]: [Client #958] Epoch: [2/5][10/16]	Loss: 1.494598
[INFO][13:55:42]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][13:55:43]: [Client #958] Woke up.
[INFO][13:55:43]: [Client #958] Epoch: [3/5][0/16]	Loss: 2.658227
[INFO][13:55:43]: [Client #958] Epoch: [3/5][10/16]	Loss: 1.887672
[INFO][13:55:43]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][13:55:43]: [Client #601] Woke up.
[INFO][13:55:43]: [Client #601] Epoch: [2/5][0/15]	Loss: 2.420274
[INFO][13:55:43]: [Client #601] Epoch: [2/5][10/15]	Loss: 2.047935
[INFO][13:55:43]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][13:55:44]: [Client #958] Woke up.
[INFO][13:55:44]: [Client #958] Epoch: [4/5][0/16]	Loss: 1.604309
[INFO][13:55:44]: [Client #958] Epoch: [4/5][10/16]	Loss: 1.420982
[INFO][13:55:44]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][13:55:44]: [Client #958] Woke up.
[INFO][13:55:44]: [Client #958] Epoch: [5/5][0/16]	Loss: 1.682944
[INFO][13:55:45]: [Client #958] Epoch: [5/5][10/16]	Loss: 1.682282
[INFO][13:55:45]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][13:55:45]: [Client #958] Woke up.
[INFO][13:55:45]: [Client #958] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_958_615875.pth.
[INFO][13:55:46]: [Client #601] Woke up.
[INFO][13:55:46]: [Client #601] Epoch: [3/5][0/15]	Loss: 1.793895
[INFO][13:55:46]: [Client #601] Epoch: [3/5][10/15]	Loss: 2.700354
[INFO][13:55:46]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][13:55:46]: [Client #958] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_958_615875.pth.
[INFO][13:55:46]: [Client #958] Model trained.
[INFO][13:55:46]: [Client #958] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:55:46]: [Server #615782] Received 0.26 MB of payload data from client #958 (simulated).
[INFO][13:55:48]: [Client #601] Woke up.
[INFO][13:55:48]: [Client #601] Epoch: [4/5][0/15]	Loss: 1.122076
[INFO][13:55:48]: [Client #601] Epoch: [4/5][10/15]	Loss: 2.721760
[INFO][13:55:48]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][13:55:50]: [Client #601] Woke up.
[INFO][13:55:50]: [Client #601] Epoch: [5/5][0/15]	Loss: 1.899919
[INFO][13:55:50]: [Client #601] Epoch: [5/5][10/15]	Loss: 2.713655
[INFO][13:55:50]: [Client #601] Going to sleep for 2.07 seconds.
[INFO][13:55:52]: [Client #601] Woke up.
[INFO][13:55:52]: [Client #601] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_601_615874.pth.
[INFO][13:55:53]: [Client #601] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_601_615874.pth.
[INFO][13:55:53]: [Client #601] Model trained.
[INFO][13:55:53]: [Client #601] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:55:53]: [Server #615782] Received 0.26 MB of payload data from client #601 (simulated).
[INFO][13:55:53]: [Server #615782] Selecting client #401 for training.
[INFO][13:55:53]: [Server #615782] Sending the current model to client #401 (simulated).
[INFO][13:55:53]: [Server #615782] Sending 0.26 MB of payload data to client #401 (simulated).
[INFO][13:55:53]: [Server #615782] Selecting client #790 for training.
[INFO][13:55:53]: [Server #615782] Sending the current model to client #790 (simulated).
[INFO][13:55:53]: [Server #615782] Sending 0.26 MB of payload data to client #790 (simulated).
[INFO][13:55:53]: [Client #401] Selected by the server.
[INFO][13:55:53]: [Client #401] Loading its data source...
[INFO][13:55:53]: Data source: FEMNIST
[INFO][13:55:53]: [Client #790] Selected by the server.
[INFO][13:55:53]: [Client #790] Loading its data source...
[INFO][13:55:53]: Data source: FEMNIST
[INFO][13:55:53]: [Client #790] Dataset size: 138
[INFO][13:55:53]: [Client #790] Sampler: all_inclusive
[INFO][13:55:53]: [Client #790] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:55:53]: [93m[1m[Client #790] Started training in communication round #6.[0m
[INFO][13:55:53]: [Client #401] Dataset size: 151
[INFO][13:55:53]: [Client #401] Sampler: all_inclusive
[INFO][13:55:53]: [Client #401] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:55:53]: [93m[1m[Client #401] Started training in communication round #6.[0m
[INFO][13:55:55]: [Client #790] Loading the dataset.
[INFO][13:55:55]: [Client #401] Loading the dataset.
[INFO][13:56:00]: [Client #401] Epoch: [1/5][0/16]	Loss: 3.095187
[INFO][13:56:00]: [Client #790] Epoch: [1/5][0/14]	Loss: 1.074583
[INFO][13:56:00]: [Client #401] Epoch: [1/5][10/16]	Loss: 2.137185
[INFO][13:56:01]: [Client #790] Epoch: [1/5][10/14]	Loss: 2.243384
[INFO][13:56:01]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][13:56:01]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:56:04]: [Client #790] Woke up.
[INFO][13:56:04]: [Client #790] Epoch: [2/5][0/14]	Loss: 2.380127
[INFO][13:56:04]: [Client #790] Epoch: [2/5][10/14]	Loss: 1.665833
[INFO][13:56:04]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:56:08]: [Client #790] Woke up.
[INFO][13:56:08]: [Client #790] Epoch: [3/5][0/14]	Loss: 2.145569
[INFO][13:56:08]: [Client #790] Epoch: [3/5][10/14]	Loss: 2.145241
[INFO][13:56:08]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:56:12]: [Client #790] Woke up.
[INFO][13:56:12]: [Client #790] Epoch: [4/5][0/14]	Loss: 1.662953
[INFO][13:56:12]: [Client #790] Epoch: [4/5][10/14]	Loss: 1.197287
[INFO][13:56:12]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:56:16]: [Client #790] Woke up.
[INFO][13:56:16]: [Client #790] Epoch: [5/5][0/14]	Loss: 1.524995
[INFO][13:56:16]: [Client #790] Epoch: [5/5][10/14]	Loss: 1.560932
[INFO][13:56:16]: [Client #790] Going to sleep for 3.83 seconds.
[INFO][13:56:20]: [Client #790] Woke up.
[INFO][13:56:20]: [Client #790] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_790_615875.pth.
[INFO][13:56:21]: [Client #790] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_790_615875.pth.
[INFO][13:56:21]: [Client #790] Model trained.
[INFO][13:56:21]: [Client #790] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:56:21]: [Server #615782] Received 0.26 MB of payload data from client #790 (simulated).
[INFO][13:56:24]: [Client #401] Woke up.
[INFO][13:56:24]: [Client #401] Epoch: [2/5][0/16]	Loss: 2.459493
[INFO][13:56:24]: [Client #401] Epoch: [2/5][10/16]	Loss: 2.735860
[INFO][13:56:24]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][13:56:48]: [Client #401] Woke up.
[INFO][13:56:48]: [Client #401] Epoch: [3/5][0/16]	Loss: 2.606619
[INFO][13:56:48]: [Client #401] Epoch: [3/5][10/16]	Loss: 3.605874
[INFO][13:56:48]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][13:57:12]: [Client #401] Woke up.
[INFO][13:57:12]: [Client #401] Epoch: [4/5][0/16]	Loss: 2.664384
[INFO][13:57:12]: [Client #401] Epoch: [4/5][10/16]	Loss: 2.566942
[INFO][13:57:12]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][13:57:36]: [Client #401] Woke up.
[INFO][13:57:36]: [Client #401] Epoch: [5/5][0/16]	Loss: 1.025588
[INFO][13:57:36]: [Client #401] Epoch: [5/5][10/16]	Loss: 1.577040
[INFO][13:57:36]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][13:58:00]: [Client #401] Woke up.
[INFO][13:58:00]: [Client #401] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_615874.pth.
[INFO][13:58:01]: [Client #401] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_615874.pth.
[INFO][13:58:01]: [Client #401] Model trained.
[INFO][13:58:01]: [Client #401] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:58:01]: [Server #615782] Received 0.26 MB of payload data from client #401 (simulated).
[INFO][13:58:01]: [Server #615782] Selecting client #641 for training.
[INFO][13:58:01]: [Server #615782] Sending the current model to client #641 (simulated).
[INFO][13:58:01]: [Server #615782] Sending 0.26 MB of payload data to client #641 (simulated).
[INFO][13:58:01]: [Server #615782] Selecting client #402 for training.
[INFO][13:58:01]: [Server #615782] Sending the current model to client #402 (simulated).
[INFO][13:58:01]: [Server #615782] Sending 0.26 MB of payload data to client #402 (simulated).
[INFO][13:58:01]: [Client #641] Selected by the server.
[INFO][13:58:01]: [Client #641] Loading its data source...
[INFO][13:58:01]: Data source: FEMNIST
[INFO][13:58:01]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][13:58:01]: [Client #402] Selected by the server.
[INFO][13:58:01]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/641.zip.
[INFO][13:58:01]: [Client #402] Loading its data source...
[INFO][13:58:01]: Data source: FEMNIST
[INFO][13:58:01]: [Client #402] Dataset size: 165
[INFO][13:58:01]: [Client #402] Sampler: all_inclusive
[INFO][13:58:01]: [Client #402] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:58:01]: [93m[1m[Client #402] Started training in communication round #6.[0m
2.4%4.7%7.1%9.5%11.8%14.2%16.6%19.0%21.3%23.7%26.1%28.4%30.8%33.2%35.5%37.9%40.3%42.7%45.0%47.4%49.8%52.1%54.5%56.9%59.2%61.6%64.0%66.4%68.7%71.1%73.5%75.8%78.2%80.6%82.9%85.3%87.7%90.0%92.4%94.8%97.2%99.5%100.0%[INFO][13:58:01]: Decompressing the dataset downloaded.
[INFO][13:58:01]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/641.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][13:58:01]: [Client #641] Dataset size: 162
[INFO][13:58:01]: [Client #641] Sampler: all_inclusive
[INFO][13:58:01]: [Client #641] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:58:01]: [93m[1m[Client #641] Started training in communication round #6.[0m

[INFO][13:58:03]: [Client #402] Loading the dataset.
[INFO][13:58:03]: [Client #641] Loading the dataset.
[INFO][13:58:08]: [Client #402] Epoch: [1/5][0/17]	Loss: 2.577038
[INFO][13:58:08]: [Client #641] Epoch: [1/5][0/17]	Loss: 1.345114
[INFO][13:58:08]: [Client #402] Epoch: [1/5][10/17]	Loss: 1.635602
[INFO][13:58:08]: [Client #402] Going to sleep for 4.10 seconds.
[INFO][13:58:08]: [Client #641] Epoch: [1/5][10/17]	Loss: 1.007469
[INFO][13:58:08]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][13:58:08]: [Client #641] Woke up.
[INFO][13:58:08]: [Client #641] Epoch: [2/5][0/17]	Loss: 1.113128
[INFO][13:58:08]: [Client #641] Epoch: [2/5][10/17]	Loss: 1.927658
[INFO][13:58:09]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][13:58:09]: [Client #641] Woke up.
[INFO][13:58:09]: [Client #641] Epoch: [3/5][0/17]	Loss: 3.288537
[INFO][13:58:09]: [Client #641] Epoch: [3/5][10/17]	Loss: 1.836153
[INFO][13:58:09]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][13:58:09]: [Client #641] Woke up.
[INFO][13:58:09]: [Client #641] Epoch: [4/5][0/17]	Loss: 1.716576
[INFO][13:58:09]: [Client #641] Epoch: [4/5][10/17]	Loss: 1.752225
[INFO][13:58:09]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][13:58:09]: [Client #641] Woke up.
[INFO][13:58:09]: [Client #641] Epoch: [5/5][0/17]	Loss: 1.959434
[INFO][13:58:09]: [Client #641] Epoch: [5/5][10/17]	Loss: 0.890751
[INFO][13:58:09]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][13:58:09]: [Client #641] Woke up.
[INFO][13:58:09]: [Client #641] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_641_615874.pth.
[INFO][13:58:10]: [Client #641] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_641_615874.pth.
[INFO][13:58:10]: [Client #641] Model trained.
[INFO][13:58:10]: [Client #641] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:58:10]: [Server #615782] Received 0.26 MB of payload data from client #641 (simulated).
[INFO][13:58:12]: [Client #402] Woke up.
[INFO][13:58:12]: [Client #402] Epoch: [2/5][0/17]	Loss: 1.552739
[INFO][13:58:12]: [Client #402] Epoch: [2/5][10/17]	Loss: 2.195253
[INFO][13:58:13]: [Client #402] Going to sleep for 4.10 seconds.
[INFO][13:58:17]: [Client #402] Woke up.
[INFO][13:58:17]: [Client #402] Epoch: [3/5][0/17]	Loss: 1.405517
[INFO][13:58:17]: [Client #402] Epoch: [3/5][10/17]	Loss: 2.830696
[INFO][13:58:17]: [Client #402] Going to sleep for 4.10 seconds.
[INFO][13:58:21]: [Client #402] Woke up.
[INFO][13:58:21]: [Client #402] Epoch: [4/5][0/17]	Loss: 2.242067
[INFO][13:58:21]: [Client #402] Epoch: [4/5][10/17]	Loss: 2.055439
[INFO][13:58:21]: [Client #402] Going to sleep for 4.10 seconds.
[INFO][13:58:25]: [Client #402] Woke up.
[INFO][13:58:25]: [Client #402] Epoch: [5/5][0/17]	Loss: 1.948427
[INFO][13:58:25]: [Client #402] Epoch: [5/5][10/17]	Loss: 2.427237
[INFO][13:58:25]: [Client #402] Going to sleep for 4.10 seconds.
[INFO][13:58:29]: [Client #402] Woke up.
[INFO][13:58:29]: [Client #402] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_402_615875.pth.
[INFO][13:58:30]: [Client #402] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_402_615875.pth.
[INFO][13:58:30]: [Client #402] Model trained.
[INFO][13:58:30]: [Client #402] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:58:30]: [Server #615782] Received 0.26 MB of payload data from client #402 (simulated).
[INFO][13:58:30]: [Server #615782] Selecting client #686 for training.
[INFO][13:58:30]: [Server #615782] Sending the current model to client #686 (simulated).
[INFO][13:58:30]: [Server #615782] Sending 0.26 MB of payload data to client #686 (simulated).
[INFO][13:58:30]: [Server #615782] Selecting client #413 for training.
[INFO][13:58:30]: [Server #615782] Sending the current model to client #413 (simulated).
[INFO][13:58:30]: [Server #615782] Sending 0.26 MB of payload data to client #413 (simulated).
[INFO][13:58:30]: [Client #686] Selected by the server.
[INFO][13:58:30]: [Client #413] Selected by the server.
[INFO][13:58:30]: [Client #413] Loading its data source...
[INFO][13:58:30]: [Client #686] Loading its data source...
[INFO][13:58:30]: Data source: FEMNIST
[INFO][13:58:30]: Data source: FEMNIST
[INFO][13:58:30]: [Client #686] Dataset size: 149
[INFO][13:58:30]: [Client #686] Sampler: all_inclusive
[INFO][13:58:30]: [Client #413] Dataset size: 159
[INFO][13:58:30]: [Client #413] Sampler: all_inclusive
[INFO][13:58:30]: [Client #686] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:58:30]: [Client #413] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:58:30]: [93m[1m[Client #686] Started training in communication round #6.[0m
[INFO][13:58:30]: [93m[1m[Client #413] Started training in communication round #6.[0m
[INFO][13:58:32]: [Client #413] Loading the dataset.
[INFO][13:58:32]: [Client #686] Loading the dataset.
[INFO][13:58:38]: [Client #686] Epoch: [1/5][0/15]	Loss: 2.691041
[INFO][13:58:38]: [Client #686] Epoch: [1/5][10/15]	Loss: 2.518088
[INFO][13:58:38]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][13:58:38]: [Client #413] Epoch: [1/5][0/16]	Loss: 2.397438
[INFO][13:58:38]: [Client #413] Epoch: [1/5][10/16]	Loss: 2.697859
[INFO][13:58:38]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][13:58:41]: [Client #686] Woke up.
[INFO][13:58:41]: [Client #686] Epoch: [2/5][0/15]	Loss: 1.821547
[INFO][13:58:41]: [Client #686] Epoch: [2/5][10/15]	Loss: 2.027939
[INFO][13:58:41]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][13:58:42]: [Client #413] Woke up.
[INFO][13:58:42]: [Client #413] Epoch: [2/5][0/16]	Loss: 2.248081
[INFO][13:58:42]: [Client #413] Epoch: [2/5][10/16]	Loss: 2.282310
[INFO][13:58:42]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][13:58:45]: [Client #686] Woke up.
[INFO][13:58:45]: [Client #686] Epoch: [3/5][0/15]	Loss: 1.693077
[INFO][13:58:45]: [Client #686] Epoch: [3/5][10/15]	Loss: 2.699480
[INFO][13:58:45]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][13:58:46]: [Client #413] Woke up.
[INFO][13:58:46]: [Client #413] Epoch: [3/5][0/16]	Loss: 2.083863
[INFO][13:58:46]: [Client #413] Epoch: [3/5][10/16]	Loss: 2.073823
[INFO][13:58:46]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][13:58:48]: [Client #686] Woke up.
[INFO][13:58:48]: [Client #686] Epoch: [4/5][0/15]	Loss: 1.612076
[INFO][13:58:48]: [Client #686] Epoch: [4/5][10/15]	Loss: 1.893118
[INFO][13:58:48]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][13:58:50]: [Client #413] Woke up.
[INFO][13:58:50]: [Client #413] Epoch: [4/5][0/16]	Loss: 1.651796
[INFO][13:58:50]: [Client #413] Epoch: [4/5][10/16]	Loss: 3.320839
[INFO][13:58:50]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][13:58:52]: [Client #686] Woke up.
[INFO][13:58:52]: [Client #686] Epoch: [5/5][0/15]	Loss: 1.303189
[INFO][13:58:52]: [Client #686] Epoch: [5/5][10/15]	Loss: 1.944502
[INFO][13:58:52]: [Client #686] Going to sleep for 3.35 seconds.
[INFO][13:58:55]: [Client #413] Woke up.
[INFO][13:58:55]: [Client #413] Epoch: [5/5][0/16]	Loss: 1.673636
[INFO][13:58:55]: [Client #413] Epoch: [5/5][10/16]	Loss: 2.157335
[INFO][13:58:55]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][13:58:55]: [Client #686] Woke up.
[INFO][13:58:55]: [Client #686] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_686_615874.pth.
[INFO][13:58:56]: [Client #686] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_686_615874.pth.
[INFO][13:58:56]: [Client #686] Model trained.
[INFO][13:58:56]: [Client #686] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:58:56]: [Server #615782] Received 0.26 MB of payload data from client #686 (simulated).
[INFO][13:58:59]: [Client #413] Woke up.
[INFO][13:58:59]: [Client #413] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_413_615875.pth.
[INFO][13:58:59]: [Client #413] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_413_615875.pth.
[INFO][13:58:59]: [Client #413] Model trained.
[INFO][13:58:59]: [Client #413] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:58:59]: [Server #615782] Received 0.26 MB of payload data from client #413 (simulated).
[INFO][13:58:59]: [Server #615782] Selecting client #140 for training.
[INFO][13:58:59]: [Server #615782] Sending the current model to client #140 (simulated).
[INFO][13:58:59]: [Server #615782] Sending 0.26 MB of payload data to client #140 (simulated).
[INFO][13:58:59]: [Server #615782] Selecting client #459 for training.
[INFO][13:58:59]: [Server #615782] Sending the current model to client #459 (simulated).
[INFO][13:58:59]: [Server #615782] Sending 0.26 MB of payload data to client #459 (simulated).
[INFO][13:58:59]: [Client #140] Selected by the server.
[INFO][13:58:59]: [Client #459] Selected by the server.
[INFO][13:58:59]: [Client #140] Loading its data source...
[INFO][13:58:59]: [Client #459] Loading its data source...
[INFO][13:58:59]: Data source: FEMNIST
[INFO][13:58:59]: Data source: FEMNIST
[INFO][13:58:59]: [Client #459] Dataset size: 165
[INFO][13:58:59]: [Client #459] Sampler: all_inclusive
[INFO][13:58:59]: [Client #459] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:58:59]: [93m[1m[Client #459] Started training in communication round #6.[0m
[INFO][13:59:00]: [Client #140] Dataset size: 152
[INFO][13:59:00]: [Client #140] Sampler: all_inclusive
[INFO][13:59:00]: [Client #140] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:59:00]: [93m[1m[Client #140] Started training in communication round #6.[0m
[INFO][13:59:01]: [Client #140] Loading the dataset.
[INFO][13:59:02]: [Client #459] Loading the dataset.
[INFO][13:59:07]: [Client #140] Epoch: [1/5][0/16]	Loss: 1.269079
[INFO][13:59:07]: [Client #459] Epoch: [1/5][0/17]	Loss: 2.211181
[INFO][13:59:07]: [Client #140] Epoch: [1/5][10/16]	Loss: 1.603862
[INFO][13:59:07]: [Client #459] Epoch: [1/5][10/17]	Loss: 1.172500
[INFO][13:59:07]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][13:59:07]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:59:07]: [Client #459] Woke up.
[INFO][13:59:07]: [Client #459] Epoch: [2/5][0/17]	Loss: 2.172840
[INFO][13:59:08]: [Client #459] Epoch: [2/5][10/17]	Loss: 0.903287
[INFO][13:59:08]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:59:08]: [Client #459] Woke up.
[INFO][13:59:08]: [Client #459] Epoch: [3/5][0/17]	Loss: 2.088708
[INFO][13:59:08]: [Client #459] Epoch: [3/5][10/17]	Loss: 0.746776
[INFO][13:59:08]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:59:08]: [Client #459] Woke up.
[INFO][13:59:08]: [Client #459] Epoch: [4/5][0/17]	Loss: 1.918326
[INFO][13:59:08]: [Client #459] Epoch: [4/5][10/17]	Loss: 1.229487
[INFO][13:59:09]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:59:09]: [Client #459] Woke up.
[INFO][13:59:09]: [Client #459] Epoch: [5/5][0/17]	Loss: 1.137504
[INFO][13:59:09]: [Client #459] Epoch: [5/5][10/17]	Loss: 1.123645
[INFO][13:59:09]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][13:59:09]: [Client #459] Woke up.
[INFO][13:59:09]: [Client #459] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_615875.pth.
[INFO][13:59:10]: [Client #459] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_615875.pth.
[INFO][13:59:10]: [Client #140] Woke up.
[INFO][13:59:10]: [Client #459] Model trained.
[INFO][13:59:10]: [Client #459] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:59:10]: [Server #615782] Received 0.26 MB of payload data from client #459 (simulated).
[INFO][13:59:10]: [Client #140] Epoch: [2/5][0/16]	Loss: 1.544303
[INFO][13:59:10]: [Client #140] Epoch: [2/5][10/16]	Loss: 1.095123
[INFO][13:59:10]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][13:59:13]: [Client #140] Woke up.
[INFO][13:59:13]: [Client #140] Epoch: [3/5][0/16]	Loss: 2.777820
[INFO][13:59:13]: [Client #140] Epoch: [3/5][10/16]	Loss: 2.311150
[INFO][13:59:13]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][13:59:16]: [Client #140] Woke up.
[INFO][13:59:16]: [Client #140] Epoch: [4/5][0/16]	Loss: 1.488611
[INFO][13:59:16]: [Client #140] Epoch: [4/5][10/16]	Loss: 2.033852
[INFO][13:59:16]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][13:59:19]: [Client #140] Woke up.
[INFO][13:59:19]: [Client #140] Epoch: [5/5][0/16]	Loss: 1.911570
[INFO][13:59:19]: [Client #140] Epoch: [5/5][10/16]	Loss: 0.311522
[INFO][13:59:19]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][13:59:22]: [Client #140] Woke up.
[INFO][13:59:22]: [Client #140] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_615874.pth.
[INFO][13:59:23]: [Client #140] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_615874.pth.
[INFO][13:59:23]: [Client #140] Model trained.
[INFO][13:59:23]: [Client #140] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:59:23]: [Server #615782] Received 0.26 MB of payload data from client #140 (simulated).
[INFO][13:59:23]: [Server #615782] Selecting client #342 for training.
[INFO][13:59:23]: [Server #615782] Sending the current model to client #342 (simulated).
[INFO][13:59:23]: [Server #615782] Sending 0.26 MB of payload data to client #342 (simulated).
[INFO][13:59:23]: [Server #615782] Selecting client #223 for training.
[INFO][13:59:23]: [Server #615782] Sending the current model to client #223 (simulated).
[INFO][13:59:23]: [Server #615782] Sending 0.26 MB of payload data to client #223 (simulated).
[INFO][13:59:23]: [Client #342] Selected by the server.
[INFO][13:59:23]: [Client #342] Loading its data source...
[INFO][13:59:23]: Data source: FEMNIST
[INFO][13:59:23]: [Client #223] Selected by the server.
[INFO][13:59:23]: [Client #223] Loading its data source...
[INFO][13:59:23]: Data source: FEMNIST
[INFO][13:59:23]: [Client #342] Dataset size: 163
[INFO][13:59:23]: [Client #342] Sampler: all_inclusive
[INFO][13:59:23]: [Client #342] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:59:23]: [93m[1m[Client #342] Started training in communication round #6.[0m
[INFO][13:59:23]: [Client #223] Dataset size: 317
[INFO][13:59:23]: [Client #223] Sampler: all_inclusive
[INFO][13:59:23]: [Client #223] Received 0.26 MB of payload data from the server (simulated).
[INFO][13:59:23]: [93m[1m[Client #223] Started training in communication round #6.[0m
[INFO][13:59:25]: [Client #342] Loading the dataset.
[INFO][13:59:25]: [Client #223] Loading the dataset.
[INFO][13:59:31]: [Client #223] Epoch: [1/5][0/32]	Loss: 1.822290
[INFO][13:59:31]: [Client #342] Epoch: [1/5][0/17]	Loss: 2.586520
[INFO][13:59:31]: [Client #223] Epoch: [1/5][10/32]	Loss: 3.244004
[INFO][13:59:31]: [Client #342] Epoch: [1/5][10/17]	Loss: 2.185295
[INFO][13:59:31]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][13:59:31]: [Client #223] Epoch: [1/5][20/32]	Loss: 1.730644
[INFO][13:59:31]: [Client #223] Epoch: [1/5][30/32]	Loss: 2.617886
[INFO][13:59:31]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][13:59:31]: [Client #223] Woke up.
[INFO][13:59:31]: [Client #223] Epoch: [2/5][0/32]	Loss: 2.427107
[INFO][13:59:31]: [Client #223] Epoch: [2/5][10/32]	Loss: 1.796033
[INFO][13:59:31]: [Client #223] Epoch: [2/5][20/32]	Loss: 1.888674
[INFO][13:59:31]: [Client #223] Epoch: [2/5][30/32]	Loss: 2.150675
[INFO][13:59:31]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][13:59:31]: [Client #223] Woke up.
[INFO][13:59:32]: [Client #223] Epoch: [3/5][0/32]	Loss: 2.026996
[INFO][13:59:32]: [Client #223] Epoch: [3/5][10/32]	Loss: 1.385994
[INFO][13:59:32]: [Client #223] Epoch: [3/5][20/32]	Loss: 0.948115
[INFO][13:59:32]: [Client #223] Epoch: [3/5][30/32]	Loss: 1.435111
[INFO][13:59:32]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][13:59:32]: [Client #223] Woke up.
[INFO][13:59:32]: [Client #223] Epoch: [4/5][0/32]	Loss: 1.551614
[INFO][13:59:32]: [Client #223] Epoch: [4/5][10/32]	Loss: 2.105892
[INFO][13:59:32]: [Client #223] Epoch: [4/5][20/32]	Loss: 2.314776
[INFO][13:59:32]: [Client #223] Epoch: [4/5][30/32]	Loss: 1.069975
[INFO][13:59:32]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][13:59:32]: [Client #223] Woke up.
[INFO][13:59:32]: [Client #223] Epoch: [5/5][0/32]	Loss: 2.331520
[INFO][13:59:32]: [Client #223] Epoch: [5/5][10/32]	Loss: 1.402561
[INFO][13:59:32]: [Client #223] Epoch: [5/5][20/32]	Loss: 2.126671
[INFO][13:59:33]: [Client #223] Epoch: [5/5][30/32]	Loss: 1.564945
[INFO][13:59:33]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][13:59:33]: [Client #223] Woke up.
[INFO][13:59:33]: [Client #223] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_223_615875.pth.
[INFO][13:59:33]: [Client #223] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_223_615875.pth.
[INFO][13:59:33]: [Client #223] Model trained.
[INFO][13:59:33]: [Client #223] Sent 0.26 MB of payload data to the server (simulated).
[INFO][13:59:33]: [Server #615782] Received 0.26 MB of payload data from client #223 (simulated).
[INFO][13:59:50]: [Client #342] Woke up.
[INFO][13:59:50]: [Client #342] Epoch: [2/5][0/17]	Loss: 1.468379
[INFO][13:59:50]: [Client #342] Epoch: [2/5][10/17]	Loss: 2.638430
[INFO][13:59:50]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:00:09]: [Client #342] Woke up.
[INFO][14:00:09]: [Client #342] Epoch: [3/5][0/17]	Loss: 1.895445
[INFO][14:00:09]: [Client #342] Epoch: [3/5][10/17]	Loss: 2.273597
[INFO][14:00:09]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:00:28]: [Client #342] Woke up.
[INFO][14:00:28]: [Client #342] Epoch: [4/5][0/17]	Loss: 2.258028
[INFO][14:00:28]: [Client #342] Epoch: [4/5][10/17]	Loss: 2.217373
[INFO][14:00:28]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:00:47]: [Client #342] Woke up.
[INFO][14:00:47]: [Client #342] Epoch: [5/5][0/17]	Loss: 2.286382
[INFO][14:00:48]: [Client #342] Epoch: [5/5][10/17]	Loss: 2.571737
[INFO][14:00:48]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:01:07]: [Client #342] Woke up.
[INFO][14:01:07]: [Client #342] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615874.pth.
[INFO][14:01:07]: [Client #342] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615874.pth.
[INFO][14:01:07]: [Client #342] Model trained.
[INFO][14:01:07]: [Client #342] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:07]: [Server #615782] Received 0.26 MB of payload data from client #342 (simulated).
[INFO][14:01:07]: [Server #615782] Selecting client #925 for training.
[INFO][14:01:07]: [Server #615782] Sending the current model to client #925 (simulated).
[INFO][14:01:07]: [Server #615782] Sending 0.26 MB of payload data to client #925 (simulated).
[INFO][14:01:07]: [Server #615782] Selecting client #596 for training.
[INFO][14:01:07]: [Server #615782] Sending the current model to client #596 (simulated).
[INFO][14:01:07]: [Server #615782] Sending 0.26 MB of payload data to client #596 (simulated).
[INFO][14:01:07]: [Client #925] Selected by the server.
[INFO][14:01:07]: [Client #925] Loading its data source...
[INFO][14:01:07]: Data source: FEMNIST
[INFO][14:01:07]: [Client #596] Selected by the server.
[INFO][14:01:07]: [Client #596] Loading its data source...
[INFO][14:01:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:01:07]: Data source: FEMNIST
[INFO][14:01:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/925.zip.
[INFO][14:01:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:01:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/596.zip.
2.6%5.2%7.8%10.4%13.0%15.6%18.2%2.2%20.8%23.4%26.0%28.6%31.2%33.8%36.4%39.0%41.6%44.2%46.8%49.4%52.0%54.6%57.2%59.8%62.4%65.0%67.6%70.2%72.8%75.4%78.0%80.6%83.2%85.8%88.4%91.0%93.6%96.2%98.8%100.0%4.5%6.7%8.9%11.2%13.4%15.7%17.9%20.1%[INFO][14:01:08]: Decompressing the dataset downloaded.
22.4%24.6%26.8%[INFO][14:01:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/925.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
29.1%31.3%33.6%35.8%38.0%40.3%42.5%44.7%47.0%49.2%51.5%53.7%55.9%58.2%60.4%62.6%64.9%67.1%69.4%71.6%73.8%76.1%78.3%80.5%82.8%85.0%87.3%89.5%91.7%94.0%96.2%98.4%100.0%[INFO][14:01:08]: Decompressing the dataset downloaded.
[INFO][14:01:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/596.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:01:08]: [Client #925] Dataset size: 154
[INFO][14:01:08]: [Client #925] Sampler: all_inclusive
[INFO][14:01:08]: [Client #925] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:08]: [Client #596] Dataset size: 162
[INFO][14:01:08]: [Client #596] Sampler: all_inclusive
[INFO][14:01:08]: [93m[1m[Client #925] Started training in communication round #6.[0m

[INFO][14:01:08]: [Client #596] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:08]: [93m[1m[Client #596] Started training in communication round #6.[0m

[INFO][14:01:10]: [Client #925] Loading the dataset.
[INFO][14:01:10]: [Client #596] Loading the dataset.
[INFO][14:01:15]: [Client #925] Epoch: [1/5][0/16]	Loss: 1.787773
[INFO][14:01:15]: [Client #596] Epoch: [1/5][0/17]	Loss: 2.204842
[INFO][14:01:16]: [Client #925] Epoch: [1/5][10/16]	Loss: 1.348370
[INFO][14:01:16]: [Client #596] Epoch: [1/5][10/17]	Loss: 1.903164
[INFO][14:01:16]: [Client #925] Going to sleep for 0.91 seconds.
[INFO][14:01:16]: [Client #596] Going to sleep for 0.25 seconds.
[INFO][14:01:16]: [Client #596] Woke up.
[INFO][14:01:16]: [Client #596] Epoch: [2/5][0/17]	Loss: 1.572457
[INFO][14:01:16]: [Client #596] Epoch: [2/5][10/17]	Loss: 1.328687
[INFO][14:01:16]: [Client #596] Going to sleep for 0.25 seconds.
[INFO][14:01:16]: [Client #596] Woke up.
[INFO][14:01:16]: [Client #596] Epoch: [3/5][0/17]	Loss: 2.441624
[INFO][14:01:16]: [Client #596] Epoch: [3/5][10/17]	Loss: 1.742226
[INFO][14:01:16]: [Client #596] Going to sleep for 0.25 seconds.
[INFO][14:01:16]: [Client #925] Woke up.
[INFO][14:01:16]: [Client #925] Epoch: [2/5][0/16]	Loss: 2.010455
[INFO][14:01:17]: [Client #925] Epoch: [2/5][10/16]	Loss: 0.996022
[INFO][14:01:17]: [Client #925] Going to sleep for 0.91 seconds.
[INFO][14:01:17]: [Client #596] Woke up.
[INFO][14:01:17]: [Client #596] Epoch: [4/5][0/17]	Loss: 4.359941
[INFO][14:01:17]: [Client #596] Epoch: [4/5][10/17]	Loss: 2.887886
[INFO][14:01:17]: [Client #596] Going to sleep for 0.25 seconds.
[INFO][14:01:17]: [Client #596] Woke up.
[INFO][14:01:17]: [Client #596] Epoch: [5/5][0/17]	Loss: 1.971666
[INFO][14:01:17]: [Client #596] Epoch: [5/5][10/17]	Loss: 2.150859
[INFO][14:01:17]: [Client #596] Going to sleep for 0.25 seconds.
[INFO][14:01:17]: [Client #596] Woke up.
[INFO][14:01:17]: [Client #596] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_596_615875.pth.
[INFO][14:01:18]: [Client #925] Woke up.
[INFO][14:01:18]: [Client #925] Epoch: [3/5][0/16]	Loss: 1.974447
[INFO][14:01:18]: [Client #925] Epoch: [3/5][10/16]	Loss: 2.104017
[INFO][14:01:18]: [Client #925] Going to sleep for 0.91 seconds.
[INFO][14:01:18]: [Client #596] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_596_615875.pth.
[INFO][14:01:18]: [Client #596] Model trained.
[INFO][14:01:18]: [Client #596] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:18]: [Server #615782] Received 0.26 MB of payload data from client #596 (simulated).
[INFO][14:01:19]: [Client #925] Woke up.
[INFO][14:01:19]: [Client #925] Epoch: [4/5][0/16]	Loss: 2.289978
[INFO][14:01:19]: [Client #925] Epoch: [4/5][10/16]	Loss: 1.377320
[INFO][14:01:19]: [Client #925] Going to sleep for 0.91 seconds.
[INFO][14:01:20]: [Client #925] Woke up.
[INFO][14:01:20]: [Client #925] Epoch: [5/5][0/16]	Loss: 1.762099
[INFO][14:01:20]: [Client #925] Epoch: [5/5][10/16]	Loss: 1.883179
[INFO][14:01:20]: [Client #925] Going to sleep for 0.91 seconds.
[INFO][14:01:21]: [Client #925] Woke up.
[INFO][14:01:21]: [Client #925] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_925_615874.pth.
[INFO][14:01:21]: [Client #925] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_925_615874.pth.
[INFO][14:01:21]: [Client #925] Model trained.
[INFO][14:01:21]: [Client #925] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:21]: [Server #615782] Received 0.26 MB of payload data from client #925 (simulated).
[INFO][14:01:21]: [Server #615782] Selecting client #745 for training.
[INFO][14:01:21]: [Server #615782] Sending the current model to client #745 (simulated).
[INFO][14:01:21]: [Server #615782] Sending 0.26 MB of payload data to client #745 (simulated).
[INFO][14:01:21]: [Server #615782] Selecting client #538 for training.
[INFO][14:01:21]: [Server #615782] Sending the current model to client #538 (simulated).
[INFO][14:01:21]: [Server #615782] Sending 0.26 MB of payload data to client #538 (simulated).
[INFO][14:01:21]: [Client #745] Selected by the server.
[INFO][14:01:21]: [Client #745] Loading its data source...
[INFO][14:01:21]: Data source: FEMNIST
[INFO][14:01:21]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:01:21]: [Client #538] Selected by the server.
[INFO][14:01:21]: [Client #538] Loading its data source...
[INFO][14:01:21]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/745.zip.
[INFO][14:01:21]: Data source: FEMNIST
[INFO][14:01:21]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:01:21]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/538.zip.
4.4%8.8%13.2%17.6%22.0%26.4%30.7%35.1%3.3%6.5%9.8%13.1%16.4%19.6%22.9%26.2%29.5%32.7%36.0%39.3%42.6%45.8%49.1%52.4%55.6%39.5%43.9%48.3%52.7%57.1%61.5%65.9%70.3%74.7%79.1%83.5%87.9%92.2%96.6%100.0%[INFO][14:01:22]: Decompressing the dataset downloaded.
[INFO][14:01:22]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/745.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
58.9%62.2%65.5%68.7%72.0%75.3%78.6%81.8%85.1%88.4%91.7%94.9%98.2%100.0%[INFO][14:01:22]: Decompressing the dataset downloaded.
[INFO][14:01:22]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/538.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:01:22]: [Client #745] Dataset size: 70
[INFO][14:01:22]: [Client #745] Sampler: all_inclusive
[INFO][14:01:22]: [Client #745] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:22]: [93m[1m[Client #745] Started training in communication round #6.[0m

[INFO][14:01:22]: [Client #538] Dataset size: 157
[INFO][14:01:22]: [Client #538] Sampler: all_inclusive
[INFO][14:01:22]: [Client #538] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:22]: [93m[1m[Client #538] Started training in communication round #6.[0m

[INFO][14:01:24]: [Client #745] Loading the dataset.
[INFO][14:01:24]: [Client #538] Loading the dataset.
[INFO][14:01:29]: [Client #745] Epoch: [1/5][0/7]	Loss: 2.124316
[INFO][14:01:29]: [Client #538] Epoch: [1/5][0/16]	Loss: 2.632940
[INFO][14:01:30]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:01:30]: [Client #745] Woke up.
[INFO][14:01:30]: [Client #745] Epoch: [2/5][0/7]	Loss: 1.404427
[INFO][14:01:30]: [Client #538] Epoch: [1/5][10/16]	Loss: 2.042645
[INFO][14:01:30]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:01:30]: [Client #745] Woke up.
[INFO][14:01:30]: [Client #745] Epoch: [3/5][0/7]	Loss: 1.074933
[INFO][14:01:30]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:01:30]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:01:30]: [Client #745] Woke up.
[INFO][14:01:30]: [Client #745] Epoch: [4/5][0/7]	Loss: 1.690905
[INFO][14:01:30]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:01:30]: [Client #745] Woke up.
[INFO][14:01:30]: [Client #745] Epoch: [5/5][0/7]	Loss: 0.502645
[INFO][14:01:30]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:01:30]: [Client #745] Woke up.
[INFO][14:01:30]: [Client #745] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_745_615874.pth.
[INFO][14:01:31]: [Client #538] Woke up.
[INFO][14:01:31]: [Client #538] Epoch: [2/5][0/16]	Loss: 1.522318
[INFO][14:01:31]: [Client #745] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_745_615874.pth.
[INFO][14:01:31]: [Client #745] Model trained.
[INFO][14:01:31]: [Client #745] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:31]: [Server #615782] Received 0.26 MB of payload data from client #745 (simulated).
[INFO][14:01:31]: [Client #538] Epoch: [2/5][10/16]	Loss: 2.122746
[INFO][14:01:31]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:01:32]: [Client #538] Woke up.
[INFO][14:01:32]: [Client #538] Epoch: [3/5][0/16]	Loss: 2.787262
[INFO][14:01:32]: [Client #538] Epoch: [3/5][10/16]	Loss: 2.685895
[INFO][14:01:32]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:01:33]: [Client #538] Woke up.
[INFO][14:01:33]: [Client #538] Epoch: [4/5][0/16]	Loss: 2.323252
[INFO][14:01:33]: [Client #538] Epoch: [4/5][10/16]	Loss: 2.321186
[INFO][14:01:33]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:01:34]: [Client #538] Woke up.
[INFO][14:01:34]: [Client #538] Epoch: [5/5][0/16]	Loss: 1.924412
[INFO][14:01:34]: [Client #538] Epoch: [5/5][10/16]	Loss: 2.206483
[INFO][14:01:34]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:01:35]: [Client #538] Woke up.
[INFO][14:01:35]: [Client #538] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_538_615875.pth.
[INFO][14:01:35]: [Client #538] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_538_615875.pth.
[INFO][14:01:35]: [Client #538] Model trained.
[INFO][14:01:35]: [Client #538] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:35]: [Server #615782] Received 0.26 MB of payload data from client #538 (simulated).
[INFO][14:01:35]: [Server #615782] Selecting client #698 for training.
[INFO][14:01:35]: [Server #615782] Sending the current model to client #698 (simulated).
[INFO][14:01:35]: [Server #615782] Sending 0.26 MB of payload data to client #698 (simulated).
[INFO][14:01:35]: [Server #615782] Selecting client #930 for training.
[INFO][14:01:35]: [Server #615782] Sending the current model to client #930 (simulated).
[INFO][14:01:35]: [Server #615782] Sending 0.26 MB of payload data to client #930 (simulated).
[INFO][14:01:35]: [Client #698] Selected by the server.
[INFO][14:01:35]: [Client #698] Loading its data source...
[INFO][14:01:35]: [Client #930] Selected by the server.
[INFO][14:01:35]: Data source: FEMNIST
[INFO][14:01:35]: [Client #930] Loading its data source...
[INFO][14:01:35]: Data source: FEMNIST
[INFO][14:01:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:01:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/930.zip.
[INFO][14:01:36]: [Client #698] Dataset size: 159
[INFO][14:01:36]: [Client #698] Sampler: all_inclusive
[INFO][14:01:36]: [Client #698] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:36]: [93m[1m[Client #698] Started training in communication round #6.[0m
2.6%5.1%7.7%10.3%12.9%15.4%18.0%20.6%23.2%25.7%28.3%30.9%33.5%36.0%38.6%41.2%43.8%46.3%48.9%51.5%54.1%56.6%59.2%61.8%64.4%66.9%69.5%72.1%74.7%77.2%79.8%82.4%85.0%87.5%90.1%92.7%95.3%97.8%100.0%[INFO][14:01:36]: Decompressing the dataset downloaded.
[INFO][14:01:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/930.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:01:36]: [Client #930] Dataset size: 151
[INFO][14:01:36]: [Client #930] Sampler: all_inclusive
[INFO][14:01:36]: [Client #930] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:01:36]: [93m[1m[Client #930] Started training in communication round #6.[0m

[INFO][14:01:37]: [Client #698] Loading the dataset.
[INFO][14:01:38]: [Client #930] Loading the dataset.
[INFO][14:01:43]: [Client #930] Epoch: [1/5][0/16]	Loss: 2.668884
[INFO][14:01:43]: [Client #698] Epoch: [1/5][0/16]	Loss: 2.619475
[INFO][14:01:43]: [Client #930] Epoch: [1/5][10/16]	Loss: 3.190449
[INFO][14:01:43]: [Client #698] Epoch: [1/5][10/16]	Loss: 2.834756
[INFO][14:01:43]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:01:43]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:01:44]: [Client #930] Woke up.
[INFO][14:01:44]: [Client #930] Epoch: [2/5][0/16]	Loss: 2.228556
[INFO][14:01:44]: [Client #930] Epoch: [2/5][10/16]	Loss: 2.201837
[INFO][14:01:44]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:01:44]: [Client #930] Woke up.
[INFO][14:01:44]: [Client #930] Epoch: [3/5][0/16]	Loss: 2.361118
[INFO][14:01:44]: [Client #930] Epoch: [3/5][10/16]	Loss: 2.265532
[INFO][14:01:44]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:01:45]: [Client #930] Woke up.
[INFO][14:01:45]: [Client #930] Epoch: [4/5][0/16]	Loss: 2.932027
[INFO][14:01:45]: [Client #930] Epoch: [4/5][10/16]	Loss: 2.074848
[INFO][14:01:45]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:01:45]: [Client #930] Woke up.
[INFO][14:01:45]: [Client #930] Epoch: [5/5][0/16]	Loss: 1.790165
[INFO][14:01:45]: [Client #930] Epoch: [5/5][10/16]	Loss: 1.762941
[INFO][14:01:45]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:01:46]: [Client #930] Woke up.
[INFO][14:01:46]: [Client #930] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_930_615875.pth.
[INFO][14:01:47]: [Client #930] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_930_615875.pth.
[INFO][14:01:47]: [Client #930] Model trained.
[INFO][14:01:47]: [Client #930] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:01:47]: [Server #615782] Received 0.26 MB of payload data from client #930 (simulated).
[INFO][14:01:51]: [Client #698] Woke up.
[INFO][14:01:51]: [Client #698] Epoch: [2/5][0/16]	Loss: 3.429425
[INFO][14:01:51]: [Client #698] Epoch: [2/5][10/16]	Loss: 1.768191
[INFO][14:01:51]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:01:59]: [Client #698] Woke up.
[INFO][14:01:59]: [Client #698] Epoch: [3/5][0/16]	Loss: 1.475863
[INFO][14:01:59]: [Client #698] Epoch: [3/5][10/16]	Loss: 2.610132
[INFO][14:01:59]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:02:06]: [Client #698] Woke up.
[INFO][14:02:06]: [Client #698] Epoch: [4/5][0/16]	Loss: 2.211609
[INFO][14:02:06]: [Client #698] Epoch: [4/5][10/16]	Loss: 2.497708
[INFO][14:02:06]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:02:14]: [Client #698] Woke up.
[INFO][14:02:14]: [Client #698] Epoch: [5/5][0/16]	Loss: 2.014672
[INFO][14:02:14]: [Client #698] Epoch: [5/5][10/16]	Loss: 2.777093
[INFO][14:02:14]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:02:22]: [Client #698] Woke up.
[INFO][14:02:22]: [Client #698] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615874.pth.
[INFO][14:02:22]: [Client #698] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615874.pth.
[INFO][14:02:22]: [Client #698] Model trained.
[INFO][14:02:22]: [Client #698] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:02:22]: [Server #615782] Received 0.26 MB of payload data from client #698 (simulated).
[INFO][14:02:22]: [Server #615782] Selecting client #863 for training.
[INFO][14:02:22]: [Server #615782] Sending the current model to client #863 (simulated).
[INFO][14:02:22]: [Server #615782] Sending 0.26 MB of payload data to client #863 (simulated).
[INFO][14:02:22]: [Server #615782] Selecting client #172 for training.
[INFO][14:02:22]: [Server #615782] Sending the current model to client #172 (simulated).
[INFO][14:02:22]: [Server #615782] Sending 0.26 MB of payload data to client #172 (simulated).
[INFO][14:02:22]: [Client #863] Selected by the server.
[INFO][14:02:22]: [Client #863] Loading its data source...
[INFO][14:02:22]: Data source: FEMNIST
[INFO][14:02:22]: [Client #172] Selected by the server.
[INFO][14:02:22]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:02:22]: [Client #172] Loading its data source...
[INFO][14:02:22]: Data source: FEMNIST
[INFO][14:02:22]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/863.zip.
[INFO][14:02:22]: [Client #172] Dataset size: 164
[INFO][14:02:22]: [Client #172] Sampler: all_inclusive
[INFO][14:02:22]: [Client #172] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:02:22]: [93m[1m[Client #172] Started training in communication round #6.[0m
2.4%4.8%7.3%9.7%12.1%14.5%17.0%19.4%21.8%24.2%26.7%29.1%31.5%33.9%36.4%38.8%41.2%43.6%46.1%48.5%50.9%53.3%55.8%58.2%60.6%63.0%65.5%67.9%70.3%72.7%75.1%77.6%80.0%82.4%84.8%87.3%89.7%92.1%94.5%97.0%99.4%100.0%[INFO][14:02:23]: Decompressing the dataset downloaded.
[INFO][14:02:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/863.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:02:23]: [Client #863] Dataset size: 143
[INFO][14:02:23]: [Client #863] Sampler: all_inclusive
[INFO][14:02:23]: [Client #863] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:02:23]: [93m[1m[Client #863] Started training in communication round #6.[0m

[INFO][14:02:25]: [Client #172] Loading the dataset.
[INFO][14:02:25]: [Client #863] Loading the dataset.
[INFO][14:02:30]: [Client #172] Epoch: [1/5][0/17]	Loss: 1.920075
[INFO][14:02:30]: [Client #863] Epoch: [1/5][0/15]	Loss: 1.959227
[INFO][14:02:31]: [Client #172] Epoch: [1/5][10/17]	Loss: 1.675397
[INFO][14:02:31]: [Client #863] Epoch: [1/5][10/15]	Loss: 3.431181
[INFO][14:02:31]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][14:02:31]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][14:02:31]: [Client #863] Woke up.
[INFO][14:02:31]: [Client #863] Epoch: [2/5][0/15]	Loss: 2.960791
[INFO][14:02:31]: [Client #863] Epoch: [2/5][10/15]	Loss: 2.910246
[INFO][14:02:31]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][14:02:32]: [Client #863] Woke up.
[INFO][14:02:32]: [Client #863] Epoch: [3/5][0/15]	Loss: 2.083209
[INFO][14:02:32]: [Client #863] Epoch: [3/5][10/15]	Loss: 3.048763
[INFO][14:02:32]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][14:02:33]: [Client #863] Woke up.
[INFO][14:02:33]: [Client #863] Epoch: [4/5][0/15]	Loss: 2.062548
[INFO][14:02:33]: [Client #863] Epoch: [4/5][10/15]	Loss: 1.043186
[INFO][14:02:33]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][14:02:34]: [Client #863] Woke up.
[INFO][14:02:34]: [Client #863] Epoch: [5/5][0/15]	Loss: 3.156738
[INFO][14:02:34]: [Client #863] Epoch: [5/5][10/15]	Loss: 1.195917
[INFO][14:02:34]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][14:02:35]: [Client #863] Woke up.
[INFO][14:02:35]: [Client #863] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_863_615874.pth.
[INFO][14:02:36]: [Client #863] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_863_615874.pth.
[INFO][14:02:36]: [Client #863] Model trained.
[INFO][14:02:36]: [Client #863] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:02:36]: [Server #615782] Received 0.26 MB of payload data from client #863 (simulated).
[INFO][14:03:31]: [Client #172] Woke up.
[INFO][14:03:31]: [Client #172] Epoch: [2/5][0/17]	Loss: 1.950751
[INFO][14:03:31]: [Client #172] Epoch: [2/5][10/17]	Loss: 2.088732
[INFO][14:03:31]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][14:04:31]: [Client #172] Woke up.
[INFO][14:04:31]: [Client #172] Epoch: [3/5][0/17]	Loss: 2.470361
[INFO][14:04:31]: [Client #172] Epoch: [3/5][10/17]	Loss: 1.257557
[INFO][14:04:31]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][14:05:31]: [Client #172] Woke up.
[INFO][14:05:31]: [Client #172] Epoch: [4/5][0/17]	Loss: 1.814601
[INFO][14:05:31]: [Client #172] Epoch: [4/5][10/17]	Loss: 1.553174
[INFO][14:05:31]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][14:06:31]: [Client #172] Woke up.
[INFO][14:06:32]: [Client #172] Epoch: [5/5][0/17]	Loss: 1.292575
[INFO][14:06:32]: [Client #172] Epoch: [5/5][10/17]	Loss: 2.395487
[INFO][14:06:32]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][14:07:32]: [Client #172] Woke up.
[INFO][14:07:32]: [Client #172] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615875.pth.
[INFO][14:07:32]: [Client #172] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615875.pth.
[INFO][14:07:32]: [Client #172] Model trained.
[INFO][14:07:32]: [Client #172] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:07:32]: [Server #615782] Received 0.26 MB of payload data from client #172 (simulated).
[INFO][14:07:32]: [Server #615782] Selecting client #270 for training.
[INFO][14:07:32]: [Server #615782] Sending the current model to client #270 (simulated).
[INFO][14:07:32]: [Server #615782] Sending 0.26 MB of payload data to client #270 (simulated).
[INFO][14:07:32]: [Server #615782] Selecting client #74 for training.
[INFO][14:07:32]: [Server #615782] Sending the current model to client #74 (simulated).
[INFO][14:07:32]: [Server #615782] Sending 0.26 MB of payload data to client #74 (simulated).
[INFO][14:07:33]: [Client #270] Selected by the server.
[INFO][14:07:33]: [Client #74] Selected by the server.
[INFO][14:07:33]: [Client #74] Loading its data source...
[INFO][14:07:33]: [Client #270] Loading its data source...
[INFO][14:07:33]: Data source: FEMNIST
[INFO][14:07:33]: Data source: FEMNIST
[INFO][14:07:33]: [Client #74] Dataset size: 164
[INFO][14:07:33]: [Client #74] Sampler: all_inclusive
[INFO][14:07:33]: [Client #74] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:07:33]: [93m[1m[Client #74] Started training in communication round #6.[0m
[INFO][14:07:33]: [Client #270] Dataset size: 160
[INFO][14:07:33]: [Client #270] Sampler: all_inclusive
[INFO][14:07:33]: [Client #270] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:07:33]: [93m[1m[Client #270] Started training in communication round #6.[0m
[INFO][14:07:35]: [Client #270] Loading the dataset.
[INFO][14:07:35]: [Client #74] Loading the dataset.
[INFO][14:07:40]: [Client #270] Epoch: [1/5][0/16]	Loss: 2.375884
[INFO][14:07:40]: [Client #74] Epoch: [1/5][0/17]	Loss: 2.514482
[INFO][14:07:40]: [Client #270] Epoch: [1/5][10/16]	Loss: 2.979389
[INFO][14:07:41]: [Client #270] Going to sleep for 0.70 seconds.
[INFO][14:07:41]: [Client #74] Epoch: [1/5][10/17]	Loss: 2.926538
[INFO][14:07:41]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][14:07:41]: [Client #270] Woke up.
[INFO][14:07:41]: [Client #270] Epoch: [2/5][0/16]	Loss: 2.667819
[INFO][14:07:41]: [Client #270] Epoch: [2/5][10/16]	Loss: 2.107777
[INFO][14:07:41]: [Client #270] Going to sleep for 0.70 seconds.
[INFO][14:07:42]: [Client #270] Woke up.
[INFO][14:07:42]: [Client #270] Epoch: [3/5][0/16]	Loss: 2.823252
[INFO][14:07:42]: [Client #270] Epoch: [3/5][10/16]	Loss: 2.855468
[INFO][14:07:42]: [Client #270] Going to sleep for 0.70 seconds.
[INFO][14:07:43]: [Client #270] Woke up.
[INFO][14:07:43]: [Client #270] Epoch: [4/5][0/16]	Loss: 2.770406
[INFO][14:07:43]: [Client #270] Epoch: [4/5][10/16]	Loss: 2.050482
[INFO][14:07:43]: [Client #270] Going to sleep for 0.70 seconds.
[INFO][14:07:44]: [Client #270] Woke up.
[INFO][14:07:44]: [Client #270] Epoch: [5/5][0/16]	Loss: 2.165359
[INFO][14:07:44]: [Client #270] Epoch: [5/5][10/16]	Loss: 2.388708
[INFO][14:07:44]: [Client #270] Going to sleep for 0.70 seconds.
[INFO][14:07:45]: [Client #270] Woke up.
[INFO][14:07:45]: [Client #270] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_270_615874.pth.
[INFO][14:07:45]: [Client #74] Woke up.
[INFO][14:07:45]: [Client #74] Epoch: [2/5][0/17]	Loss: 1.988384
[INFO][14:07:45]: [Client #74] Epoch: [2/5][10/17]	Loss: 1.821226
[INFO][14:07:45]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][14:07:45]: [Client #270] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_270_615874.pth.
[INFO][14:07:45]: [Client #270] Model trained.
[INFO][14:07:45]: [Client #270] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:07:45]: [Server #615782] Received 0.26 MB of payload data from client #270 (simulated).
[INFO][14:07:49]: [Client #74] Woke up.
[INFO][14:07:49]: [Client #74] Epoch: [3/5][0/17]	Loss: 1.785815
[INFO][14:07:49]: [Client #74] Epoch: [3/5][10/17]	Loss: 1.675572
[INFO][14:07:49]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][14:07:54]: [Client #74] Woke up.
[INFO][14:07:54]: [Client #74] Epoch: [4/5][0/17]	Loss: 0.909337
[INFO][14:07:54]: [Client #74] Epoch: [4/5][10/17]	Loss: 1.775564
[INFO][14:07:54]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][14:07:58]: [Client #74] Woke up.
[INFO][14:07:58]: [Client #74] Epoch: [5/5][0/17]	Loss: 1.824645
[INFO][14:07:58]: [Client #74] Epoch: [5/5][10/17]	Loss: 1.791321
[INFO][14:07:58]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][14:08:02]: [Client #74] Woke up.
[INFO][14:08:02]: [Client #74] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_615875.pth.
[INFO][14:08:03]: [Client #74] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_615875.pth.
[INFO][14:08:03]: [Client #74] Model trained.
[INFO][14:08:03]: [Client #74] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:08:03]: [Server #615782] Received 0.26 MB of payload data from client #74 (simulated).
[INFO][14:08:03]: [Server #615782] Selecting client #979 for training.
[INFO][14:08:03]: [Server #615782] Sending the current model to client #979 (simulated).
[INFO][14:08:03]: [Server #615782] Sending 0.26 MB of payload data to client #979 (simulated).
[INFO][14:08:03]: [Server #615782] Selecting client #242 for training.
[INFO][14:08:03]: [Server #615782] Sending the current model to client #242 (simulated).
[INFO][14:08:03]: [Server #615782] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][14:08:03]: [Client #979] Selected by the server.
[INFO][14:08:03]: [Client #242] Selected by the server.
[INFO][14:08:03]: [Client #979] Loading its data source...
[INFO][14:08:03]: [Client #242] Loading its data source...
[INFO][14:08:03]: Data source: FEMNIST
[INFO][14:08:03]: Data source: FEMNIST
[INFO][14:08:03]: [Client #979] Dataset size: 162
[INFO][14:08:03]: [Client #979] Sampler: all_inclusive
[INFO][14:08:03]: [Client #979] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:08:03]: [93m[1m[Client #979] Started training in communication round #6.[0m
[INFO][14:08:03]: [Client #242] Dataset size: 146
[INFO][14:08:03]: [Client #242] Sampler: all_inclusive
[INFO][14:08:03]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:08:03]: [93m[1m[Client #242] Started training in communication round #6.[0m
[INFO][14:08:05]: [Client #242] Loading the dataset.
[INFO][14:08:05]: [Client #979] Loading the dataset.
[INFO][14:08:11]: [Client #979] Epoch: [1/5][0/17]	Loss: 3.207703
[INFO][14:08:11]: [Client #242] Epoch: [1/5][0/15]	Loss: 2.764231
[INFO][14:08:11]: [Client #979] Epoch: [1/5][10/17]	Loss: 2.669095
[INFO][14:08:11]: [Client #242] Epoch: [1/5][10/15]	Loss: 1.882727
[INFO][14:08:11]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][14:08:11]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][14:08:11]: [Client #979] Woke up.
[INFO][14:08:11]: [Client #979] Epoch: [2/5][0/17]	Loss: 2.396936
[INFO][14:08:11]: [Client #979] Epoch: [2/5][10/17]	Loss: 2.381858
[INFO][14:08:11]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][14:08:12]: [Client #979] Woke up.
[INFO][14:08:12]: [Client #979] Epoch: [3/5][0/17]	Loss: 2.901869
[INFO][14:08:12]: [Client #979] Epoch: [3/5][10/17]	Loss: 1.992595
[INFO][14:08:12]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][14:08:12]: [Client #979] Woke up.
[INFO][14:08:12]: [Client #979] Epoch: [4/5][0/17]	Loss: 1.554862
[INFO][14:08:12]: [Client #979] Epoch: [4/5][10/17]	Loss: 2.053680
[INFO][14:08:12]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][14:08:13]: [Client #979] Woke up.
[INFO][14:08:13]: [Client #979] Epoch: [5/5][0/17]	Loss: 2.826947
[INFO][14:08:13]: [Client #979] Epoch: [5/5][10/17]	Loss: 1.594056
[INFO][14:08:13]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][14:08:13]: [Client #979] Woke up.
[INFO][14:08:13]: [Client #979] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_979_615874.pth.
[INFO][14:08:14]: [Client #979] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_979_615874.pth.
[INFO][14:08:14]: [Client #979] Model trained.
[INFO][14:08:14]: [Client #979] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:08:14]: [Server #615782] Received 0.26 MB of payload data from client #979 (simulated).
[INFO][14:08:19]: [Client #242] Woke up.
[INFO][14:08:19]: [Client #242] Epoch: [2/5][0/15]	Loss: 2.209353
[INFO][14:08:20]: [Client #242] Epoch: [2/5][10/15]	Loss: 1.755362
[INFO][14:08:20]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][14:08:28]: [Client #242] Woke up.
[INFO][14:08:28]: [Client #242] Epoch: [3/5][0/15]	Loss: 1.451195
[INFO][14:08:28]: [Client #242] Epoch: [3/5][10/15]	Loss: 2.513623
[INFO][14:08:28]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][14:08:36]: [Client #242] Woke up.
[INFO][14:08:36]: [Client #242] Epoch: [4/5][0/15]	Loss: 1.566108
[INFO][14:08:36]: [Client #242] Epoch: [4/5][10/15]	Loss: 1.434504
[INFO][14:08:36]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][14:08:45]: [Client #242] Woke up.
[INFO][14:08:45]: [Client #242] Epoch: [5/5][0/15]	Loss: 0.648272
[INFO][14:08:45]: [Client #242] Epoch: [5/5][10/15]	Loss: 2.574386
[INFO][14:08:45]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][14:08:53]: [Client #242] Woke up.
[INFO][14:08:53]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][14:08:54]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][14:08:54]: [Client #242] Model trained.
[INFO][14:08:54]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:08:54]: [Server #615782] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][14:08:54]: [Server #615782] Selecting client #657 for training.
[INFO][14:08:54]: [Server #615782] Sending the current model to client #657 (simulated).
[INFO][14:08:54]: [Server #615782] Sending 0.26 MB of payload data to client #657 (simulated).
[INFO][14:08:54]: [Server #615782] Selecting client #92 for training.
[INFO][14:08:54]: [Server #615782] Sending the current model to client #92 (simulated).
[INFO][14:08:54]: [Server #615782] Sending 0.26 MB of payload data to client #92 (simulated).
[INFO][14:08:54]: [Client #92] Selected by the server.
[INFO][14:08:54]: [Client #657] Selected by the server.
[INFO][14:08:54]: [Client #92] Loading its data source...
[INFO][14:08:54]: Data source: FEMNIST
[INFO][14:08:54]: [Client #657] Loading its data source...
[INFO][14:08:54]: Data source: FEMNIST
[INFO][14:08:54]: [Client #657] Dataset size: 154
[INFO][14:08:54]: [Client #657] Sampler: all_inclusive
[INFO][14:08:54]: [Client #657] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:08:54]: [93m[1m[Client #657] Started training in communication round #6.[0m
[INFO][14:08:54]: [Client #92] Dataset size: 163
[INFO][14:08:54]: [Client #92] Sampler: all_inclusive
[INFO][14:08:54]: [Client #92] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:08:54]: [93m[1m[Client #92] Started training in communication round #6.[0m
[INFO][14:08:56]: [Client #657] Loading the dataset.
[INFO][14:08:56]: [Client #92] Loading the dataset.
[INFO][14:09:02]: [Client #657] Epoch: [1/5][0/16]	Loss: 1.898926
[INFO][14:09:02]: [Client #92] Epoch: [1/5][0/17]	Loss: 1.734455
[INFO][14:09:02]: [Client #657] Epoch: [1/5][10/16]	Loss: 2.837724
[INFO][14:09:02]: [Client #92] Epoch: [1/5][10/17]	Loss: 1.932184
[INFO][14:09:02]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][14:09:02]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][14:09:03]: [Client #657] Woke up.
[INFO][14:09:03]: [Client #657] Epoch: [2/5][0/16]	Loss: 1.561952
[INFO][14:09:03]: [Client #657] Epoch: [2/5][10/16]	Loss: 2.361364
[INFO][14:09:03]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][14:09:05]: [Client #657] Woke up.
[INFO][14:09:05]: [Client #657] Epoch: [3/5][0/16]	Loss: 1.998130
[INFO][14:09:05]: [Client #657] Epoch: [3/5][10/16]	Loss: 1.940299
[INFO][14:09:05]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][14:09:06]: [Client #657] Woke up.
[INFO][14:09:06]: [Client #657] Epoch: [4/5][0/16]	Loss: 1.092116
[INFO][14:09:06]: [Client #657] Epoch: [4/5][10/16]	Loss: 2.398033
[INFO][14:09:06]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][14:09:08]: [Client #657] Woke up.
[INFO][14:09:08]: [Client #657] Epoch: [5/5][0/16]	Loss: 1.378664
[INFO][14:09:08]: [Client #657] Epoch: [5/5][10/16]	Loss: 2.989907
[INFO][14:09:08]: [Client #657] Going to sleep for 1.34 seconds.
[INFO][14:09:09]: [Client #657] Woke up.
[INFO][14:09:09]: [Client #657] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_657_615874.pth.
[INFO][14:09:10]: [Client #657] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_657_615874.pth.
[INFO][14:09:10]: [Client #657] Model trained.
[INFO][14:09:10]: [Client #657] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:09:10]: [Server #615782] Received 0.26 MB of payload data from client #657 (simulated).
[INFO][14:09:21]: [Client #92] Woke up.
[INFO][14:09:21]: [Client #92] Epoch: [2/5][0/17]	Loss: 2.032012
[INFO][14:09:21]: [Client #92] Epoch: [2/5][10/17]	Loss: 1.941672
[INFO][14:09:21]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][14:09:40]: [Client #92] Woke up.
[INFO][14:09:40]: [Client #92] Epoch: [3/5][0/17]	Loss: 1.495720
[INFO][14:09:40]: [Client #92] Epoch: [3/5][10/17]	Loss: 1.096083
[INFO][14:09:40]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][14:09:59]: [Client #92] Woke up.
[INFO][14:09:59]: [Client #92] Epoch: [4/5][0/17]	Loss: 1.253201
[INFO][14:09:59]: [Client #92] Epoch: [4/5][10/17]	Loss: 2.074335
[INFO][14:09:59]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][14:10:18]: [Client #92] Woke up.
[INFO][14:10:18]: [Client #92] Epoch: [5/5][0/17]	Loss: 2.814051
[INFO][14:10:18]: [Client #92] Epoch: [5/5][10/17]	Loss: 1.868568
[INFO][14:10:18]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][14:10:37]: [Client #92] Woke up.
[INFO][14:10:37]: [Client #92] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_92_615875.pth.
[INFO][14:10:38]: [Client #92] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_92_615875.pth.
[INFO][14:10:38]: [Client #92] Model trained.
[INFO][14:10:38]: [Client #92] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:10:38]: [Server #615782] Received 0.26 MB of payload data from client #92 (simulated).
[INFO][14:10:38]: [Server #615782] Selecting client #216 for training.
[INFO][14:10:38]: [Server #615782] Sending the current model to client #216 (simulated).
[INFO][14:10:38]: [Server #615782] Sending 0.26 MB of payload data to client #216 (simulated).
[INFO][14:10:38]: [Server #615782] Selecting client #513 for training.
[INFO][14:10:38]: [Server #615782] Sending the current model to client #513 (simulated).
[INFO][14:10:38]: [Server #615782] Sending 0.26 MB of payload data to client #513 (simulated).
[INFO][14:10:38]: [Client #216] Selected by the server.
[INFO][14:10:38]: [Client #513] Selected by the server.
[INFO][14:10:38]: [Client #513] Loading its data source...
[INFO][14:10:38]: [Client #216] Loading its data source...
[INFO][14:10:38]: Data source: FEMNIST
[INFO][14:10:38]: Data source: FEMNIST
[INFO][14:10:38]: [Client #513] Dataset size: 164
[INFO][14:10:38]: [Client #513] Sampler: all_inclusive
[INFO][14:10:38]: [Client #513] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:10:38]: [93m[1m[Client #513] Started training in communication round #6.[0m
[INFO][14:10:38]: [Client #216] Dataset size: 162
[INFO][14:10:38]: [Client #216] Sampler: all_inclusive
[INFO][14:10:38]: [Client #216] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:10:38]: [93m[1m[Client #216] Started training in communication round #6.[0m
[INFO][14:10:40]: [Client #513] Loading the dataset.
[INFO][14:10:40]: [Client #216] Loading the dataset.
[INFO][14:10:45]: [Client #513] Epoch: [1/5][0/17]	Loss: 2.239163
[INFO][14:10:45]: [Client #513] Epoch: [1/5][10/17]	Loss: 1.353792
[INFO][14:10:45]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][14:10:45]: [Client #216] Epoch: [1/5][0/17]	Loss: 2.765466
[INFO][14:10:45]: [Client #513] Woke up.
[INFO][14:10:45]: [Client #513] Epoch: [2/5][0/17]	Loss: 2.198351
[INFO][14:10:45]: [Client #216] Epoch: [1/5][10/17]	Loss: 1.407986
[INFO][14:10:46]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][14:10:46]: [Client #513] Epoch: [2/5][10/17]	Loss: 1.353644
[INFO][14:10:46]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][14:10:46]: [Client #513] Woke up.
[INFO][14:10:46]: [Client #513] Epoch: [3/5][0/17]	Loss: 1.469355
[INFO][14:10:46]: [Client #513] Epoch: [3/5][10/17]	Loss: 2.554780
[INFO][14:10:46]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][14:10:46]: [Client #513] Woke up.
[INFO][14:10:46]: [Client #513] Epoch: [4/5][0/17]	Loss: 1.839138
[INFO][14:10:46]: [Client #513] Epoch: [4/5][10/17]	Loss: 1.996257
[INFO][14:10:46]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][14:10:46]: [Client #513] Woke up.
[INFO][14:10:46]: [Client #513] Epoch: [5/5][0/17]	Loss: 1.576272
[INFO][14:10:46]: [Client #513] Epoch: [5/5][10/17]	Loss: 2.284211
[INFO][14:10:46]: [Client #513] Going to sleep for 0.06 seconds.
[INFO][14:10:46]: [Client #513] Woke up.
[INFO][14:10:46]: [Client #513] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_513_615875.pth.
[INFO][14:10:47]: [Client #216] Woke up.
[INFO][14:10:47]: [Client #216] Epoch: [2/5][0/17]	Loss: 1.915303
[INFO][14:10:47]: [Client #216] Epoch: [2/5][10/17]	Loss: 2.458014
[INFO][14:10:47]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][14:10:47]: [Client #513] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_513_615875.pth.
[INFO][14:10:47]: [Client #513] Model trained.
[INFO][14:10:47]: [Client #513] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:10:47]: [Server #615782] Received 0.26 MB of payload data from client #513 (simulated).
[INFO][14:10:48]: [Client #216] Woke up.
[INFO][14:10:48]: [Client #216] Epoch: [3/5][0/17]	Loss: 1.656571
[INFO][14:10:48]: [Client #216] Epoch: [3/5][10/17]	Loss: 2.086735
[INFO][14:10:48]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][14:10:49]: [Client #216] Woke up.
[INFO][14:10:49]: [Client #216] Epoch: [4/5][0/17]	Loss: 1.989162
[INFO][14:10:49]: [Client #216] Epoch: [4/5][10/17]	Loss: 1.999007
[INFO][14:10:49]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][14:10:50]: [Client #216] Woke up.
[INFO][14:10:50]: [Client #216] Epoch: [5/5][0/17]	Loss: 0.646693
[INFO][14:10:50]: [Client #216] Epoch: [5/5][10/17]	Loss: 1.966680
[INFO][14:10:50]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][14:10:51]: [Client #216] Woke up.
[INFO][14:10:51]: [Client #216] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_216_615874.pth.
[INFO][14:10:52]: [Client #216] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_216_615874.pth.
[INFO][14:10:52]: [Client #216] Model trained.
[INFO][14:10:52]: [Client #216] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:10:52]: [Server #615782] Received 0.26 MB of payload data from client #216 (simulated).
[INFO][14:10:52]: [Server #615782] Selecting client #108 for training.
[INFO][14:10:52]: [Server #615782] Sending the current model to client #108 (simulated).
[INFO][14:10:52]: [Server #615782] Sending 0.26 MB of payload data to client #108 (simulated).
[INFO][14:10:52]: [Server #615782] Selecting client #397 for training.
[INFO][14:10:52]: [Server #615782] Sending the current model to client #397 (simulated).
[INFO][14:10:52]: [Server #615782] Sending 0.26 MB of payload data to client #397 (simulated).
[INFO][14:10:52]: [Client #108] Selected by the server.
[INFO][14:10:52]: [Client #108] Loading its data source...
[INFO][14:10:52]: Data source: FEMNIST
[INFO][14:10:52]: [Client #397] Selected by the server.
[INFO][14:10:52]: [Client #397] Loading its data source...
[INFO][14:10:52]: Data source: FEMNIST
[INFO][14:10:52]: [Client #397] Dataset size: 164
[INFO][14:10:52]: [Client #397] Sampler: all_inclusive
[INFO][14:10:52]: [Client #397] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:10:52]: [93m[1m[Client #397] Started training in communication round #6.[0m
[INFO][14:10:52]: [Client #108] Dataset size: 153
[INFO][14:10:52]: [Client #108] Sampler: all_inclusive
[INFO][14:10:52]: [Client #108] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:10:52]: [93m[1m[Client #108] Started training in communication round #6.[0m
[INFO][14:10:54]: [Client #108] Loading the dataset.
[INFO][14:10:54]: [Client #397] Loading the dataset.
[INFO][14:10:59]: [Client #397] Epoch: [1/5][0/17]	Loss: 2.086763
[INFO][14:10:59]: [Client #108] Epoch: [1/5][0/16]	Loss: 2.498935
[INFO][14:11:00]: [Client #397] Epoch: [1/5][10/17]	Loss: 1.575256
[INFO][14:11:00]: [Client #108] Epoch: [1/5][10/16]	Loss: 2.915612
[INFO][14:11:00]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][14:11:00]: [Client #108] Going to sleep for 13.17 seconds.
[INFO][14:11:00]: [Client #397] Woke up.
[INFO][14:11:00]: [Client #397] Epoch: [2/5][0/17]	Loss: 1.520474
[INFO][14:11:00]: [Client #397] Epoch: [2/5][10/17]	Loss: 1.136844
[INFO][14:11:00]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][14:11:01]: [Client #397] Woke up.
[INFO][14:11:01]: [Client #397] Epoch: [3/5][0/17]	Loss: 1.586116
[INFO][14:11:01]: [Client #397] Epoch: [3/5][10/17]	Loss: 1.356969
[INFO][14:11:01]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][14:11:02]: [Client #397] Woke up.
[INFO][14:11:02]: [Client #397] Epoch: [4/5][0/17]	Loss: 1.459802
[INFO][14:11:02]: [Client #397] Epoch: [4/5][10/17]	Loss: 2.060433
[INFO][14:11:02]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][14:11:02]: [Client #397] Woke up.
[INFO][14:11:02]: [Client #397] Epoch: [5/5][0/17]	Loss: 2.284110
[INFO][14:11:03]: [Client #397] Epoch: [5/5][10/17]	Loss: 1.843302
[INFO][14:11:03]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][14:11:03]: [Client #397] Woke up.
[INFO][14:11:03]: [Client #397] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_615875.pth.
[INFO][14:11:04]: [Client #397] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_615875.pth.
[INFO][14:11:04]: [Client #397] Model trained.
[INFO][14:11:04]: [Client #397] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:11:04]: [Server #615782] Received 0.26 MB of payload data from client #397 (simulated).
[INFO][14:11:13]: [Client #108] Woke up.
[INFO][14:11:13]: [Client #108] Epoch: [2/5][0/16]	Loss: 1.595594
[INFO][14:11:13]: [Client #108] Epoch: [2/5][10/16]	Loss: 1.876907
[INFO][14:11:13]: [Client #108] Going to sleep for 13.17 seconds.
[INFO][14:11:26]: [Client #108] Woke up.
[INFO][14:11:26]: [Client #108] Epoch: [3/5][0/16]	Loss: 1.667118
[INFO][14:11:26]: [Client #108] Epoch: [3/5][10/16]	Loss: 1.911351
[INFO][14:11:26]: [Client #108] Going to sleep for 13.17 seconds.
[INFO][14:11:39]: [Client #108] Woke up.
[INFO][14:11:39]: [Client #108] Epoch: [4/5][0/16]	Loss: 1.240990
[INFO][14:11:40]: [Client #108] Epoch: [4/5][10/16]	Loss: 2.059398
[INFO][14:11:40]: [Client #108] Going to sleep for 13.17 seconds.
[INFO][14:11:53]: [Client #108] Woke up.
[INFO][14:11:53]: [Client #108] Epoch: [5/5][0/16]	Loss: 2.107278
[INFO][14:11:53]: [Client #108] Epoch: [5/5][10/16]	Loss: 0.994695
[INFO][14:11:53]: [Client #108] Going to sleep for 13.17 seconds.
[INFO][14:12:06]: [Client #108] Woke up.
[INFO][14:12:06]: [Client #108] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_108_615874.pth.
[INFO][14:12:07]: [Client #108] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_108_615874.pth.
[INFO][14:12:07]: [Client #108] Model trained.
[INFO][14:12:07]: [Client #108] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:12:07]: [Server #615782] Received 0.26 MB of payload data from client #108 (simulated).
[INFO][14:12:07]: [Server #615782] Selecting client #534 for training.
[INFO][14:12:07]: [Server #615782] Sending the current model to client #534 (simulated).
[INFO][14:12:07]: [Server #615782] Sending 0.26 MB of payload data to client #534 (simulated).
[INFO][14:12:07]: [Server #615782] Selecting client #347 for training.
[INFO][14:12:07]: [Server #615782] Sending the current model to client #347 (simulated).
[INFO][14:12:07]: [Server #615782] Sending 0.26 MB of payload data to client #347 (simulated).
[INFO][14:12:07]: [Client #534] Selected by the server.
[INFO][14:12:07]: [Client #534] Loading its data source...
[INFO][14:12:07]: Data source: FEMNIST
[INFO][14:12:07]: [Client #347] Selected by the server.
[INFO][14:12:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:12:07]: [Client #347] Loading its data source...
[INFO][14:12:07]: Data source: FEMNIST
[INFO][14:12:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/534.zip.
[INFO][14:12:07]: [Client #347] Dataset size: 154
[INFO][14:12:07]: [Client #347] Sampler: all_inclusive
[INFO][14:12:07]: [Client #347] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:07]: [93m[1m[Client #347] Started training in communication round #6.[0m
3.4%6.8%10.2%13.7%17.1%20.5%23.9%27.3%30.7%34.1%37.6%41.0%44.4%47.8%51.2%54.6%58.0%61.5%64.9%68.3%71.7%75.1%78.5%81.9%85.4%88.8%92.2%95.6%99.0%100.0%[INFO][14:12:07]: Decompressing the dataset downloaded.
[INFO][14:12:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/534.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:12:07]: [Client #534] Dataset size: 135
[INFO][14:12:07]: [Client #534] Sampler: all_inclusive
[INFO][14:12:07]: [Client #534] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:07]: [93m[1m[Client #534] Started training in communication round #6.[0m

[INFO][14:12:09]: [Client #347] Loading the dataset.
[INFO][14:12:09]: [Client #534] Loading the dataset.
[INFO][14:12:14]: [Client #534] Epoch: [1/5][0/14]	Loss: 2.862489
[INFO][14:12:14]: [Client #347] Epoch: [1/5][0/16]	Loss: 2.593707
[INFO][14:12:14]: [Client #534] Epoch: [1/5][10/14]	Loss: 3.371382
[INFO][14:12:14]: [Client #534] Going to sleep for 3.30 seconds.
[INFO][14:12:14]: [Client #347] Epoch: [1/5][10/16]	Loss: 2.308929
[INFO][14:12:14]: [Client #347] Going to sleep for 2.37 seconds.
[INFO][14:12:17]: [Client #347] Woke up.
[INFO][14:12:17]: [Client #347] Epoch: [2/5][0/16]	Loss: 2.206041
[INFO][14:12:17]: [Client #347] Epoch: [2/5][10/16]	Loss: 0.891044
[INFO][14:12:17]: [Client #347] Going to sleep for 2.37 seconds.
[INFO][14:12:18]: [Client #534] Woke up.
[INFO][14:12:18]: [Client #534] Epoch: [2/5][0/14]	Loss: 1.673099
[INFO][14:12:18]: [Client #534] Epoch: [2/5][10/14]	Loss: 1.560836
[INFO][14:12:18]: [Client #534] Going to sleep for 3.30 seconds.
[INFO][14:12:19]: [Client #347] Woke up.
[INFO][14:12:19]: [Client #347] Epoch: [3/5][0/16]	Loss: 1.964436
[INFO][14:12:19]: [Client #347] Epoch: [3/5][10/16]	Loss: 2.947348
[INFO][14:12:19]: [Client #347] Going to sleep for 2.37 seconds.
[INFO][14:12:21]: [Client #534] Woke up.
[INFO][14:12:21]: [Client #534] Epoch: [3/5][0/14]	Loss: 1.564957
[INFO][14:12:21]: [Client #534] Epoch: [3/5][10/14]	Loss: 2.443939
[INFO][14:12:21]: [Client #534] Going to sleep for 3.30 seconds.
[INFO][14:12:22]: [Client #347] Woke up.
[INFO][14:12:22]: [Client #347] Epoch: [4/5][0/16]	Loss: 2.035189
[INFO][14:12:22]: [Client #347] Epoch: [4/5][10/16]	Loss: 1.506793
[INFO][14:12:22]: [Client #347] Going to sleep for 2.37 seconds.
[INFO][14:12:24]: [Client #347] Woke up.
[INFO][14:12:24]: [Client #347] Epoch: [5/5][0/16]	Loss: 2.032742
[INFO][14:12:24]: [Client #347] Epoch: [5/5][10/16]	Loss: 1.751082
[INFO][14:12:25]: [Client #347] Going to sleep for 2.37 seconds.
[INFO][14:12:25]: [Client #534] Woke up.
[INFO][14:12:25]: [Client #534] Epoch: [4/5][0/14]	Loss: 2.646648
[INFO][14:12:25]: [Client #534] Epoch: [4/5][10/14]	Loss: 1.922206
[INFO][14:12:25]: [Client #534] Going to sleep for 3.30 seconds.
[INFO][14:12:27]: [Client #347] Woke up.
[INFO][14:12:27]: [Client #347] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_347_615875.pth.
[INFO][14:12:28]: [Client #347] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_347_615875.pth.
[INFO][14:12:28]: [Client #347] Model trained.
[INFO][14:12:28]: [Client #347] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:12:28]: [Server #615782] Received 0.26 MB of payload data from client #347 (simulated).
[INFO][14:12:28]: [Client #534] Woke up.
[INFO][14:12:28]: [Client #534] Epoch: [5/5][0/14]	Loss: 1.576219
[INFO][14:12:28]: [Client #534] Epoch: [5/5][10/14]	Loss: 2.658688
[INFO][14:12:28]: [Client #534] Going to sleep for 3.30 seconds.
[INFO][14:12:31]: [Client #534] Woke up.
[INFO][14:12:31]: [Client #534] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_534_615874.pth.
[INFO][14:12:32]: [Client #534] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_534_615874.pth.
[INFO][14:12:32]: [Client #534] Model trained.
[INFO][14:12:32]: [Client #534] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:12:32]: [Server #615782] Received 0.26 MB of payload data from client #534 (simulated).
[INFO][14:12:32]: [Server #615782] Selecting client #553 for training.
[INFO][14:12:32]: [Server #615782] Sending the current model to client #553 (simulated).
[INFO][14:12:32]: [Server #615782] Sending 0.26 MB of payload data to client #553 (simulated).
[INFO][14:12:32]: [Server #615782] Selecting client #399 for training.
[INFO][14:12:32]: [Server #615782] Sending the current model to client #399 (simulated).
[INFO][14:12:32]: [Server #615782] Sending 0.26 MB of payload data to client #399 (simulated).
[INFO][14:12:32]: [Client #553] Selected by the server.
[INFO][14:12:32]: [Client #553] Loading its data source...
[INFO][14:12:32]: Data source: FEMNIST
[INFO][14:12:32]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:12:32]: [Client #399] Selected by the server.
[INFO][14:12:32]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/553.zip.
[INFO][14:12:32]: [Client #399] Loading its data source...
[INFO][14:12:32]: Data source: FEMNIST
[INFO][14:12:32]: [Client #399] Dataset size: 155
[INFO][14:12:32]: [Client #399] Sampler: all_inclusive
[INFO][14:12:32]: [Client #399] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:32]: [93m[1m[Client #399] Started training in communication round #6.[0m
2.9%5.8%8.7%11.6%14.6%17.5%20.4%23.3%26.2%29.1%32.0%34.9%37.8%40.7%43.7%46.6%49.5%52.4%55.3%58.2%61.1%64.0%66.9%69.8%72.8%75.7%78.6%81.5%84.4%87.3%90.2%93.1%96.0%99.0%100.0%[INFO][14:12:32]: Decompressing the dataset downloaded.
[INFO][14:12:32]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/553.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:12:32]: [Client #553] Dataset size: 164
[INFO][14:12:32]: [Client #553] Sampler: all_inclusive
[INFO][14:12:32]: [Client #553] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:32]: [93m[1m[Client #553] Started training in communication round #6.[0m

[INFO][14:12:34]: [Client #399] Loading the dataset.
[INFO][14:12:34]: [Client #553] Loading the dataset.
[INFO][14:12:40]: [Client #553] Epoch: [1/5][0/17]	Loss: 1.940179
[INFO][14:12:40]: [Client #399] Epoch: [1/5][0/16]	Loss: 2.737637
[INFO][14:12:40]: [Client #553] Epoch: [1/5][10/17]	Loss: 1.398867
[INFO][14:12:40]: [Client #399] Epoch: [1/5][10/16]	Loss: 2.714144
[INFO][14:12:40]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][14:12:40]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][14:12:41]: [Client #399] Woke up.
[INFO][14:12:41]: [Client #399] Epoch: [2/5][0/16]	Loss: 2.488491
[INFO][14:12:41]: [Client #399] Epoch: [2/5][10/16]	Loss: 2.072512
[INFO][14:12:41]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][14:12:42]: [Client #399] Woke up.
[INFO][14:12:42]: [Client #399] Epoch: [3/5][0/16]	Loss: 3.000701
[INFO][14:12:43]: [Client #399] Epoch: [3/5][10/16]	Loss: 2.495479
[INFO][14:12:43]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][14:12:43]: [Client #553] Woke up.
[INFO][14:12:43]: [Client #553] Epoch: [2/5][0/17]	Loss: 2.425375
[INFO][14:12:43]: [Client #553] Epoch: [2/5][10/17]	Loss: 2.226169
[INFO][14:12:43]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][14:12:44]: [Client #399] Woke up.
[INFO][14:12:44]: [Client #399] Epoch: [4/5][0/16]	Loss: 1.739933
[INFO][14:12:44]: [Client #399] Epoch: [4/5][10/16]	Loss: 1.650791
[INFO][14:12:44]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][14:12:45]: [Client #399] Woke up.
[INFO][14:12:45]: [Client #399] Epoch: [5/5][0/16]	Loss: 1.216273
[INFO][14:12:45]: [Client #399] Epoch: [5/5][10/16]	Loss: 1.568566
[INFO][14:12:45]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][14:12:46]: [Client #399] Woke up.
[INFO][14:12:46]: [Client #399] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_399_615875.pth.
[INFO][14:12:47]: [Client #553] Woke up.
[INFO][14:12:47]: [Client #553] Epoch: [3/5][0/17]	Loss: 1.562610
[INFO][14:12:47]: [Client #553] Epoch: [3/5][10/17]	Loss: 2.170230
[INFO][14:12:47]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][14:12:47]: [Client #399] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_399_615875.pth.
[INFO][14:12:47]: [Client #399] Model trained.
[INFO][14:12:47]: [Client #399] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:12:47]: [Server #615782] Received 0.26 MB of payload data from client #399 (simulated).
[INFO][14:12:50]: [Client #553] Woke up.
[INFO][14:12:50]: [Client #553] Epoch: [4/5][0/17]	Loss: 1.883482
[INFO][14:12:50]: [Client #553] Epoch: [4/5][10/17]	Loss: 1.398726
[INFO][14:12:50]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][14:12:53]: [Client #553] Woke up.
[INFO][14:12:53]: [Client #553] Epoch: [5/5][0/17]	Loss: 1.791880
[INFO][14:12:53]: [Client #553] Epoch: [5/5][10/17]	Loss: 0.887804
[INFO][14:12:53]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][14:12:56]: [Client #553] Woke up.
[INFO][14:12:56]: [Client #553] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615874.pth.
[INFO][14:12:57]: [Client #553] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615874.pth.
[INFO][14:12:57]: [Client #553] Model trained.
[INFO][14:12:57]: [Client #553] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:12:57]: [Server #615782] Received 0.26 MB of payload data from client #553 (simulated).
[INFO][14:12:57]: [Server #615782] Selecting client #693 for training.
[INFO][14:12:57]: [Server #615782] Sending the current model to client #693 (simulated).
[INFO][14:12:57]: [Server #615782] Sending 0.26 MB of payload data to client #693 (simulated).
[INFO][14:12:57]: [Server #615782] Selecting client #675 for training.
[INFO][14:12:57]: [Server #615782] Sending the current model to client #675 (simulated).
[INFO][14:12:57]: [Server #615782] Sending 0.26 MB of payload data to client #675 (simulated).
[INFO][14:12:57]: [Client #693] Selected by the server.
[INFO][14:12:57]: [Client #693] Loading its data source...
[INFO][14:12:57]: Data source: FEMNIST
[INFO][14:12:57]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:12:57]: [Client #675] Selected by the server.
[INFO][14:12:57]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/693.zip.
[INFO][14:12:57]: [Client #675] Loading its data source...
[INFO][14:12:57]: Data source: FEMNIST
[INFO][14:12:57]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:12:57]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/675.zip.
2.4%4.8%7.3%9.7%12.1%14.5%16.9%19.4%21.8%24.2%26.6%29.0%31.5%33.9%36.3%38.7%41.1%3.1%6.2%9.3%43.6%12.4%15.6%18.7%21.8%24.9%28.0%31.1%34.2%37.3%40.5%43.6%46.7%49.8%52.9%56.0%59.1%62.2%65.3%68.5%71.6%74.7%77.8%80.9%84.0%87.1%90.2%93.4%96.5%99.6%100.0%[INFO][14:12:57]: Decompressing the dataset downloaded.
[INFO][14:12:57]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/693.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
46.0%48.4%50.8%53.2%55.6%58.1%60.5%62.9%65.3%67.7%70.2%72.6%75.0%77.4%79.8%82.3%84.7%87.1%89.5%91.9%94.4%96.8%99.2%100.0%[INFO][14:12:57]: Decompressing the dataset downloaded.
[INFO][14:12:57]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/675.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:12:57]: [Client #693] Dataset size: 146
[INFO][14:12:57]: [Client #693] Sampler: all_inclusive
[INFO][14:12:57]: [Client #675] Dataset size: 158
[INFO][14:12:57]: [Client #693] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:57]: [Client #675] Sampler: all_inclusive
[INFO][14:12:57]: [Client #675] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:12:57]: [93m[1m[Client #675] Started training in communication round #6.[0m

[INFO][14:12:57]: [93m[1m[Client #693] Started training in communication round #6.[0m

[INFO][14:12:59]: [Client #675] Loading the dataset.
[INFO][14:12:59]: [Client #693] Loading the dataset.
[INFO][14:13:05]: [Client #675] Epoch: [1/5][0/16]	Loss: 2.650297
[INFO][14:13:05]: [Client #693] Epoch: [1/5][0/15]	Loss: 2.631061
[INFO][14:13:05]: [Client #675] Epoch: [1/5][10/16]	Loss: 2.142143
[INFO][14:13:05]: [Client #693] Epoch: [1/5][10/15]	Loss: 2.552261
[INFO][14:13:05]: [Client #675] Going to sleep for 2.53 seconds.
[INFO][14:13:05]: [Client #693] Going to sleep for 8.65 seconds.
[INFO][14:13:07]: [Client #675] Woke up.
[INFO][14:13:07]: [Client #675] Epoch: [2/5][0/16]	Loss: 2.169423
[INFO][14:13:07]: [Client #675] Epoch: [2/5][10/16]	Loss: 1.913880
[INFO][14:13:07]: [Client #675] Going to sleep for 2.53 seconds.
[INFO][14:13:10]: [Client #675] Woke up.
[INFO][14:13:10]: [Client #675] Epoch: [3/5][0/16]	Loss: 1.820169
[INFO][14:13:10]: [Client #675] Epoch: [3/5][10/16]	Loss: 1.683845
[INFO][14:13:10]: [Client #675] Going to sleep for 2.53 seconds.
[INFO][14:13:13]: [Client #675] Woke up.
[INFO][14:13:13]: [Client #675] Epoch: [4/5][0/16]	Loss: 2.194068
[INFO][14:13:13]: [Client #675] Epoch: [4/5][10/16]	Loss: 1.858615
[INFO][14:13:13]: [Client #675] Going to sleep for 2.53 seconds.
[INFO][14:13:13]: [Client #693] Woke up.
[INFO][14:13:13]: [Client #693] Epoch: [2/5][0/15]	Loss: 2.409743
[INFO][14:13:14]: [Client #693] Epoch: [2/5][10/15]	Loss: 1.487380
[INFO][14:13:14]: [Client #693] Going to sleep for 8.65 seconds.
[INFO][14:13:15]: [Client #675] Woke up.
[INFO][14:13:15]: [Client #675] Epoch: [5/5][0/16]	Loss: 1.474096
[INFO][14:13:15]: [Client #675] Epoch: [5/5][10/16]	Loss: 3.066684
[INFO][14:13:15]: [Client #675] Going to sleep for 2.53 seconds.
[INFO][14:13:18]: [Client #675] Woke up.
[INFO][14:13:18]: [Client #675] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_675_615875.pth.
[INFO][14:13:19]: [Client #675] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_675_615875.pth.
[INFO][14:13:19]: [Client #675] Model trained.
[INFO][14:13:19]: [Client #675] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:13:19]: [Server #615782] Received 0.26 MB of payload data from client #675 (simulated).
[INFO][14:13:22]: [Client #693] Woke up.
[INFO][14:13:22]: [Client #693] Epoch: [3/5][0/15]	Loss: 2.092624
[INFO][14:13:22]: [Client #693] Epoch: [3/5][10/15]	Loss: 1.522452
[INFO][14:13:22]: [Client #693] Going to sleep for 8.65 seconds.
[INFO][14:13:31]: [Client #693] Woke up.
[INFO][14:13:31]: [Client #693] Epoch: [4/5][0/15]	Loss: 1.892540
[INFO][14:13:31]: [Client #693] Epoch: [4/5][10/15]	Loss: 1.834015
[INFO][14:13:31]: [Client #693] Going to sleep for 8.65 seconds.
[INFO][14:13:40]: [Client #693] Woke up.
[INFO][14:13:40]: [Client #693] Epoch: [5/5][0/15]	Loss: 2.132145
[INFO][14:13:40]: [Client #693] Epoch: [5/5][10/15]	Loss: 1.516570
[INFO][14:13:40]: [Client #693] Going to sleep for 8.65 seconds.
[INFO][14:13:49]: [Client #693] Woke up.
[INFO][14:13:49]: [Client #693] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_693_615874.pth.
[INFO][14:13:49]: [Client #693] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_693_615874.pth.
[INFO][14:13:49]: [Client #693] Model trained.
[INFO][14:13:49]: [Client #693] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:13:49]: [Server #615782] Received 0.26 MB of payload data from client #693 (simulated).
[INFO][14:13:49]: [Server #615782] Selecting client #684 for training.
[INFO][14:13:49]: [Server #615782] Sending the current model to client #684 (simulated).
[INFO][14:13:49]: [Server #615782] Sending 0.26 MB of payload data to client #684 (simulated).
[INFO][14:13:49]: [Server #615782] Selecting client #559 for training.
[INFO][14:13:49]: [Server #615782] Sending the current model to client #559 (simulated).
[INFO][14:13:49]: [Server #615782] Sending 0.26 MB of payload data to client #559 (simulated).
[INFO][14:13:49]: [Client #684] Selected by the server.
[INFO][14:13:49]: [Client #684] Loading its data source...
[INFO][14:13:49]: [Client #559] Selected by the server.
[INFO][14:13:49]: Data source: FEMNIST
[INFO][14:13:49]: [Client #559] Loading its data source...
[INFO][14:13:49]: Data source: FEMNIST
[INFO][14:13:49]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:13:49]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/559.zip.
[INFO][14:13:49]: [Client #684] Dataset size: 135
[INFO][14:13:49]: [Client #684] Sampler: all_inclusive
[INFO][14:13:49]: [Client #684] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:13:49]: [93m[1m[Client #684] Started training in communication round #6.[0m
3.2%6.3%9.5%12.7%15.8%19.0%22.2%25.3%28.5%31.7%34.8%38.0%41.2%44.4%47.5%50.7%53.9%57.0%60.2%63.4%66.5%69.7%72.9%76.0%79.2%82.4%85.5%88.7%91.9%95.0%98.2%100.0%[INFO][14:13:50]: Decompressing the dataset downloaded.
[INFO][14:13:50]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/559.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:13:50]: [Client #559] Dataset size: 152
[INFO][14:13:50]: [Client #559] Sampler: all_inclusive
[INFO][14:13:50]: [Client #559] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:13:50]: [93m[1m[Client #559] Started training in communication round #6.[0m

[INFO][14:13:51]: [Client #684] Loading the dataset.
[INFO][14:13:51]: [Client #559] Loading the dataset.
[INFO][14:13:57]: [Client #684] Epoch: [1/5][0/14]	Loss: 1.256921
[INFO][14:13:57]: [Client #684] Epoch: [1/5][10/14]	Loss: 1.205890
[INFO][14:13:57]: [Client #559] Epoch: [1/5][0/16]	Loss: 2.362553
[INFO][14:13:57]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][14:13:57]: [Client #559] Epoch: [1/5][10/16]	Loss: 1.850759
[INFO][14:13:57]: [Client #559] Going to sleep for 3.35 seconds.
[INFO][14:14:00]: [Client #559] Woke up.
[INFO][14:14:00]: [Client #559] Epoch: [2/5][0/16]	Loss: 1.355200
[INFO][14:14:00]: [Client #684] Woke up.
[INFO][14:14:00]: [Client #684] Epoch: [2/5][0/14]	Loss: 1.880491
[INFO][14:14:00]: [Client #559] Epoch: [2/5][10/16]	Loss: 1.532888
[INFO][14:14:01]: [Client #559] Going to sleep for 3.35 seconds.
[INFO][14:14:01]: [Client #684] Epoch: [2/5][10/14]	Loss: 1.232885
[INFO][14:14:01]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][14:14:04]: [Client #559] Woke up.
[INFO][14:14:04]: [Client #559] Epoch: [3/5][0/16]	Loss: 2.135652
[INFO][14:14:04]: [Client #559] Epoch: [3/5][10/16]	Loss: 1.569124
[INFO][14:14:04]: [Client #559] Going to sleep for 3.35 seconds.
[INFO][14:14:04]: [Client #684] Woke up.
[INFO][14:14:04]: [Client #684] Epoch: [3/5][0/14]	Loss: 0.795916
[INFO][14:14:04]: [Client #684] Epoch: [3/5][10/14]	Loss: 3.201185
[INFO][14:14:04]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][14:14:07]: [Client #559] Woke up.
[INFO][14:14:07]: [Client #559] Epoch: [4/5][0/16]	Loss: 1.409011
[INFO][14:14:07]: [Client #559] Epoch: [4/5][10/16]	Loss: 1.817078
[INFO][14:14:08]: [Client #559] Going to sleep for 3.35 seconds.
[INFO][14:14:08]: [Client #684] Woke up.
[INFO][14:14:08]: [Client #684] Epoch: [4/5][0/14]	Loss: 1.181910
[INFO][14:14:08]: [Client #684] Epoch: [4/5][10/14]	Loss: 1.816721
[INFO][14:14:08]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][14:14:11]: [Client #559] Woke up.
[INFO][14:14:11]: [Client #559] Epoch: [5/5][0/16]	Loss: 1.210037
[INFO][14:14:11]: [Client #559] Epoch: [5/5][10/16]	Loss: 3.053818
[INFO][14:14:11]: [Client #559] Going to sleep for 3.35 seconds.
[INFO][14:14:12]: [Client #684] Woke up.
[INFO][14:14:12]: [Client #684] Epoch: [5/5][0/14]	Loss: 1.406037
[INFO][14:14:12]: [Client #684] Epoch: [5/5][10/14]	Loss: 1.338373
[INFO][14:14:12]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][14:14:14]: [Client #559] Woke up.
[INFO][14:14:14]: [Client #559] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_559_615875.pth.
[INFO][14:14:15]: [Client #559] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_559_615875.pth.
[INFO][14:14:15]: [Client #559] Model trained.
[INFO][14:14:15]: [Client #559] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:15]: [Server #615782] Received 0.26 MB of payload data from client #559 (simulated).
[INFO][14:14:15]: [Client #684] Woke up.
[INFO][14:14:15]: [Client #684] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615874.pth.
[INFO][14:14:16]: [Client #684] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615874.pth.
[INFO][14:14:16]: [Client #684] Model trained.
[INFO][14:14:16]: [Client #684] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:16]: [Server #615782] Received 0.26 MB of payload data from client #684 (simulated).
[INFO][14:14:16]: [Server #615782] Selecting client #366 for training.
[INFO][14:14:16]: [Server #615782] Sending the current model to client #366 (simulated).
[INFO][14:14:16]: [Server #615782] Sending 0.26 MB of payload data to client #366 (simulated).
[INFO][14:14:16]: [Server #615782] Selecting client #619 for training.
[INFO][14:14:16]: [Server #615782] Sending the current model to client #619 (simulated).
[INFO][14:14:16]: [Server #615782] Sending 0.26 MB of payload data to client #619 (simulated).
[INFO][14:14:16]: [Client #366] Selected by the server.
[INFO][14:14:16]: [Client #366] Loading its data source...
[INFO][14:14:16]: Data source: FEMNIST
[INFO][14:14:16]: [Client #619] Selected by the server.
[INFO][14:14:16]: [Client #619] Loading its data source...
[INFO][14:14:16]: Data source: FEMNIST
[INFO][14:14:16]: [Client #619] Dataset size: 144
[INFO][14:14:16]: [Client #619] Sampler: all_inclusive
[INFO][14:14:16]: [Client #619] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:14:16]: [93m[1m[Client #619] Started training in communication round #6.[0m
[INFO][14:14:16]: [Client #366] Dataset size: 162
[INFO][14:14:16]: [Client #366] Sampler: all_inclusive
[INFO][14:14:16]: [Client #366] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:14:16]: [93m[1m[Client #366] Started training in communication round #6.[0m
[INFO][14:14:18]: [Client #619] Loading the dataset.
[INFO][14:14:18]: [Client #366] Loading the dataset.
[INFO][14:14:23]: [Client #366] Epoch: [1/5][0/17]	Loss: 2.447309
[INFO][14:14:23]: [Client #619] Epoch: [1/5][0/15]	Loss: 2.323663
[INFO][14:14:24]: [Client #366] Epoch: [1/5][10/17]	Loss: 1.675310
[INFO][14:14:24]: [Client #619] Epoch: [1/5][10/15]	Loss: 2.832508
[INFO][14:14:24]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][14:14:24]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][14:14:24]: [Client #619] Woke up.
[INFO][14:14:24]: [Client #619] Epoch: [2/5][0/15]	Loss: 2.333566
[INFO][14:14:24]: [Client #619] Epoch: [2/5][10/15]	Loss: 1.906366
[INFO][14:14:25]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][14:14:25]: [Client #619] Woke up.
[INFO][14:14:25]: [Client #619] Epoch: [3/5][0/15]	Loss: 1.757059
[INFO][14:14:25]: [Client #366] Woke up.
[INFO][14:14:25]: [Client #366] Epoch: [2/5][0/17]	Loss: 1.206969
[INFO][14:14:25]: [Client #619] Epoch: [3/5][10/15]	Loss: 3.141288
[INFO][14:14:25]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][14:14:25]: [Client #366] Epoch: [2/5][10/17]	Loss: 2.259479
[INFO][14:14:25]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][14:14:26]: [Client #619] Woke up.
[INFO][14:14:26]: [Client #619] Epoch: [4/5][0/15]	Loss: 2.155946
[INFO][14:14:26]: [Client #619] Epoch: [4/5][10/15]	Loss: 1.916448
[INFO][14:14:26]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][14:14:27]: [Client #619] Woke up.
[INFO][14:14:27]: [Client #619] Epoch: [5/5][0/15]	Loss: 1.742517
[INFO][14:14:27]: [Client #619] Epoch: [5/5][10/15]	Loss: 1.537824
[INFO][14:14:27]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][14:14:27]: [Client #366] Woke up.
[INFO][14:14:27]: [Client #366] Epoch: [3/5][0/17]	Loss: 1.453230
[INFO][14:14:27]: [Client #366] Epoch: [3/5][10/17]	Loss: 2.801342
[INFO][14:14:27]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][14:14:28]: [Client #619] Woke up.
[INFO][14:14:28]: [Client #619] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615875.pth.
[INFO][14:14:29]: [Client #619] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615875.pth.
[INFO][14:14:29]: [Client #619] Model trained.
[INFO][14:14:29]: [Client #619] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:29]: [Server #615782] Received 0.26 MB of payload data from client #619 (simulated).
[INFO][14:14:29]: [Client #366] Woke up.
[INFO][14:14:29]: [Client #366] Epoch: [4/5][0/17]	Loss: 1.840007
[INFO][14:14:29]: [Client #366] Epoch: [4/5][10/17]	Loss: 1.788392
[INFO][14:14:29]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][14:14:31]: [Client #366] Woke up.
[INFO][14:14:31]: [Client #366] Epoch: [5/5][0/17]	Loss: 3.261627
[INFO][14:14:31]: [Client #366] Epoch: [5/5][10/17]	Loss: 2.141392
[INFO][14:14:31]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][14:14:33]: [Client #366] Woke up.
[INFO][14:14:33]: [Client #366] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_615874.pth.
[INFO][14:14:34]: [Client #366] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_615874.pth.
[INFO][14:14:34]: [Client #366] Model trained.
[INFO][14:14:34]: [Client #366] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:34]: [Server #615782] Received 0.26 MB of payload data from client #366 (simulated).
[INFO][14:14:34]: [Server #615782] Selecting client #937 for training.
[INFO][14:14:34]: [Server #615782] Sending the current model to client #937 (simulated).
[INFO][14:14:34]: [Server #615782] Sending 0.26 MB of payload data to client #937 (simulated).
[INFO][14:14:34]: [Server #615782] Selecting client #603 for training.
[INFO][14:14:34]: [Server #615782] Sending the current model to client #603 (simulated).
[INFO][14:14:34]: [Server #615782] Sending 0.26 MB of payload data to client #603 (simulated).
[INFO][14:14:34]: [Client #937] Selected by the server.
[INFO][14:14:34]: [Client #937] Loading its data source...
[INFO][14:14:34]: Data source: FEMNIST
[INFO][14:14:34]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:14:34]: [Client #603] Selected by the server.
[INFO][14:14:34]: [Client #603] Loading its data source...
[INFO][14:14:34]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/937.zip.
[INFO][14:14:34]: Data source: FEMNIST
[INFO][14:14:34]: [Client #603] Dataset size: 153
[INFO][14:14:34]: [Client #603] Sampler: all_inclusive
[INFO][14:14:34]: [Client #603] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:14:34]: [93m[1m[Client #603] Started training in communication round #6.[0m
3.1%6.2%9.2%12.3%15.4%18.5%21.6%24.6%27.7%30.8%33.9%37.0%40.0%43.1%46.2%49.3%52.4%55.4%58.5%61.6%64.7%67.8%70.9%73.9%77.0%80.1%83.2%86.3%89.3%92.4%95.5%98.6%100.0%[INFO][14:14:34]: Decompressing the dataset downloaded.
[INFO][14:14:34]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/937.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:14:34]: [Client #937] Dataset size: 145
[INFO][14:14:34]: [Client #937] Sampler: all_inclusive
[INFO][14:14:34]: [Client #937] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:14:34]: [93m[1m[Client #937] Started training in communication round #6.[0m

[INFO][14:14:36]: [Client #603] Loading the dataset.
[INFO][14:14:36]: [Client #937] Loading the dataset.
[INFO][14:14:41]: [Client #603] Epoch: [1/5][0/16]	Loss: 2.808202
[INFO][14:14:41]: [Client #603] Epoch: [1/5][10/16]	Loss: 2.049806
[INFO][14:14:41]: [Client #937] Epoch: [1/5][0/15]	Loss: 2.826610
[INFO][14:14:41]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:14:41]: [Client #937] Epoch: [1/5][10/15]	Loss: 3.164431
[INFO][14:14:41]: [Client #603] Woke up.
[INFO][14:14:41]: [Client #603] Epoch: [2/5][0/16]	Loss: 1.494973
[INFO][14:14:41]: [Client #937] Going to sleep for 0.12 seconds.
[INFO][14:14:41]: [Client #603] Epoch: [2/5][10/16]	Loss: 2.213923
[INFO][14:14:41]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:14:41]: [Client #937] Woke up.
[INFO][14:14:41]: [Client #937] Epoch: [2/5][0/15]	Loss: 1.470026
[INFO][14:14:42]: [Client #603] Woke up.
[INFO][14:14:42]: [Client #603] Epoch: [3/5][0/16]	Loss: 2.197791
[INFO][14:14:42]: [Client #937] Epoch: [2/5][10/15]	Loss: 2.025776
[INFO][14:14:42]: [Client #937] Going to sleep for 0.12 seconds.
[INFO][14:14:42]: [Client #603] Epoch: [3/5][10/16]	Loss: 1.842487
[INFO][14:14:42]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:14:42]: [Client #937] Woke up.
[INFO][14:14:42]: [Client #937] Epoch: [3/5][0/15]	Loss: 2.528365
[INFO][14:14:42]: [Client #603] Woke up.
[INFO][14:14:42]: [Client #603] Epoch: [4/5][0/16]	Loss: 1.529811
[INFO][14:14:42]: [Client #937] Epoch: [3/5][10/15]	Loss: 1.382217
[INFO][14:14:42]: [Client #937] Going to sleep for 0.12 seconds.
[INFO][14:14:42]: [Client #603] Epoch: [4/5][10/16]	Loss: 1.819714
[INFO][14:14:42]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:14:42]: [Client #937] Woke up.
[INFO][14:14:42]: [Client #937] Epoch: [4/5][0/15]	Loss: 2.205082
[INFO][14:14:42]: [Client #603] Woke up.
[INFO][14:14:42]: [Client #603] Epoch: [5/5][0/16]	Loss: 1.801600
[INFO][14:14:42]: [Client #937] Epoch: [4/5][10/15]	Loss: 2.180323
[INFO][14:14:42]: [Client #937] Going to sleep for 0.12 seconds.
[INFO][14:14:42]: [Client #603] Epoch: [5/5][10/16]	Loss: 0.703246
[INFO][14:14:42]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:14:42]: [Client #937] Woke up.
[INFO][14:14:42]: [Client #603] Woke up.
[INFO][14:14:42]: [Client #603] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615875.pth.
[INFO][14:14:42]: [Client #937] Epoch: [5/5][0/15]	Loss: 1.809423
[INFO][14:14:42]: [Client #937] Epoch: [5/5][10/15]	Loss: 0.909711
[INFO][14:14:42]: [Client #937] Going to sleep for 0.12 seconds.
[INFO][14:14:42]: [Client #937] Woke up.
[INFO][14:14:42]: [Client #937] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_937_615874.pth.
[INFO][14:14:43]: [Client #603] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615875.pth.
[INFO][14:14:43]: [Client #603] Model trained.
[INFO][14:14:43]: [Client #603] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:43]: [Server #615782] Received 0.26 MB of payload data from client #603 (simulated).
[INFO][14:14:43]: [Client #937] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_937_615874.pth.
[INFO][14:14:43]: [Client #937] Model trained.
[INFO][14:14:43]: [Client #937] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:14:43]: [Server #615782] Received 0.26 MB of payload data from client #937 (simulated).
[INFO][14:14:43]: [Server #615782] Adding client #745 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #641 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #513 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #603 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #937 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #223 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #596 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #459 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #979 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #930 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #588 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #397 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #958 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #619 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #270 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #863 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #925 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #538 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #216 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #399 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #657 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #366 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #601 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #347 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Adding client #675 to the list of clients for aggregation.
[INFO][14:14:43]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.26435245
 0.         0.         0.         0.         0.         0.
 0.28197447 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11564027
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09766904 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1516368
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08540641 0.         0.10808132 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07240384 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.17342506 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09118968 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0910343
 0.         0.         0.         0.         0.         0.
 0.         0.11613452 0.         0.         0.         0.
 0.10421464 0.         0.1139375  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.103827   0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1266866  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08646094 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07976926 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05238045 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07811994 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09022773 0.         0.         0.         0.         0.21171464
 0.         0.         0.         0.         0.         0.
 0.12390655 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07689819 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12174422 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.26435245
 0.         0.         0.         0.         0.         0.
 0.28197447 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11564027
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09766904 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1516368
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08540641 0.         0.10808132 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07240384 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.17342506 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09118968 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0910343
 0.         0.         0.         0.         0.         0.
 0.         0.11613452 0.         0.         0.         0.
 0.10421464 0.         0.1139375  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.103827   0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1266866  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08646094 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07976926 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05238045 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07811994 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09022773 0.         0.         0.         0.         0.21171464
 0.         0.         0.         0.         0.         0.
 0.12390655 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07689819 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12174422 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.001
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03395445 0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.001      0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.001      0.001
 0.001      0.02014495 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.001      0.001      0.001      0.01916227 0.001
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02014495 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01633706
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03416149
 0.001      0.03906154 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.001      0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.001
 0.001      0.01879376 0.05656805 0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0212766  0.001
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.001
 0.001      0.03836988 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.03353396 0.001
 0.001      0.001      0.02284735 0.03968655 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01830242
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.001      0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.03867543 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.001      0.001      0.001      0.001      0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01658273
 0.001      0.0212766  0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.01953077 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.01817958 0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01769464 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.001      0.001      0.001      0.001      0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02857143 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.001      0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.03614762 0.02184778
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.03739645 0.001      0.001
 0.001      0.001      0.0192851  0.001      0.02141939 0.01925466
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.001      0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.001      0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03816987
 0.0321735  0.001      0.001      0.001      0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.01879376 0.04019211 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01940794 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.001      0.001     ][INFO][14:15:26]: [Server #615782] Global model accuracy: 37.40%

[INFO][14:15:26]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_6.pth.
[INFO][14:15:26]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_6.pth.
[INFO][14:15:26]: [93m[1m
[Server #615782] Starting round 7/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5756e+00  1e+03  1e+00  1e+00
 1:  7.4998e+00  6.5767e+00  1e+01  1e-02  1e-02
 2:  7.5749e+00  6.6680e+00  1e+00  9e-05  9e-05
 3:  7.5756e+00  7.4975e+00  8e-02  4e-07  4e-07
 4:  7.5756e+00  7.5748e+00  8e-04  4e-09  4e-09
 5:  7.5756e+00  7.5756e+00  8e-06  4e-11  4e-11
 6:  7.5756e+00  7.5756e+00  8e-08  4e-13  4e-13
Optimal solution found.
The calculated probability is:  [0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00101808 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00099328
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102428 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102476 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102319 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102489 0.00102571 0.00102454 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102511 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102233 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102485
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.0010251
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102423 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102474 0.00102571 0.00102444 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102478 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102395 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102497 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102505 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102566 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102519 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.0010249
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102145 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102436
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102509 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102408
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571 0.00102571
 0.00102571 0.00102571 0.00102571][INFO][14:15:27]: [Server #615782] Selected clients: [981 443 745  37 769 520   6 279 538 772  52 552 806 652 934  73 278 922
 603 838 899 974 999 142  71]
[INFO][14:15:27]: [Server #615782] Selecting client #981 for training.
[INFO][14:15:27]: [Server #615782] Sending the current model to client #981 (simulated).
[INFO][14:15:27]: [Server #615782] Sending 0.26 MB of payload data to client #981 (simulated).
[INFO][14:15:27]: [Server #615782] Selecting client #443 for training.
[INFO][14:15:27]: [Server #615782] Sending the current model to client #443 (simulated).
[INFO][14:15:27]: [Server #615782] Sending 0.26 MB of payload data to client #443 (simulated).
[INFO][14:15:27]: [Client #981] Selected by the server.
[INFO][14:15:27]: [Client #981] Loading its data source...
[INFO][14:15:27]: Data source: FEMNIST
[INFO][14:15:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:15:27]: [Client #443] Selected by the server.
[INFO][14:15:27]: [Client #443] Loading its data source...
[INFO][14:15:27]: Data source: FEMNIST
[INFO][14:15:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/981.zip.
[INFO][14:15:27]: [Client #443] Dataset size: 164
[INFO][14:15:27]: [Client #443] Sampler: all_inclusive
[INFO][14:15:27]: [Client #443] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:15:27]: [93m[1m[Client #443] Started training in communication round #7.[0m
2.6%5.1%7.7%10.3%12.8%15.4%17.9%20.5%23.1%25.6%28.2%30.8%33.3%35.9%38.5%41.0%43.6%46.2%48.7%51.3%53.8%56.4%59.0%61.5%64.1%66.7%69.2%71.8%74.4%76.9%79.5%82.1%84.6%87.2%89.7%92.3%94.9%97.4%100.0%[INFO][14:15:28]: Decompressing the dataset downloaded.
[INFO][14:15:28]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/981.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:15:28]: [Client #981] Dataset size: 162
[INFO][14:15:28]: [Client #981] Sampler: all_inclusive
[INFO][14:15:28]: [Client #981] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:15:28]: [93m[1m[Client #981] Started training in communication round #7.[0m

[INFO][14:15:29]: [Client #443] Loading the dataset.
[INFO][14:15:30]: [Client #981] Loading the dataset.
[INFO][14:15:35]: [Client #443] Epoch: [1/5][0/17]	Loss: 1.134934
[INFO][14:15:35]: [Client #443] Epoch: [1/5][10/17]	Loss: 2.185229
[INFO][14:15:35]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][14:15:35]: [Client #981] Epoch: [1/5][0/17]	Loss: 2.537618
[INFO][14:15:35]: [Client #981] Epoch: [1/5][10/17]	Loss: 1.521394
[INFO][14:15:35]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][14:15:35]: [Client #981] Woke up.
[INFO][14:15:35]: [Client #981] Epoch: [2/5][0/17]	Loss: 1.207532
[INFO][14:15:35]: [Client #981] Epoch: [2/5][10/17]	Loss: 1.335671
[INFO][14:15:35]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][14:15:36]: [Client #981] Woke up.
[INFO][14:15:36]: [Client #981] Epoch: [3/5][0/17]	Loss: 1.487579
[INFO][14:15:36]: [Client #981] Epoch: [3/5][10/17]	Loss: 1.703424
[INFO][14:15:36]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][14:15:36]: [Client #981] Woke up.
[INFO][14:15:36]: [Client #981] Epoch: [4/5][0/17]	Loss: 1.917629
[INFO][14:15:36]: [Client #981] Epoch: [4/5][10/17]	Loss: 2.108994
[INFO][14:15:36]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][14:15:36]: [Client #443] Woke up.
[INFO][14:15:36]: [Client #443] Epoch: [2/5][0/17]	Loss: 1.020296
[INFO][14:15:36]: [Client #981] Woke up.
[INFO][14:15:36]: [Client #443] Epoch: [2/5][10/17]	Loss: 2.156803
[INFO][14:15:36]: [Client #981] Epoch: [5/5][0/17]	Loss: 1.989189
[INFO][14:15:36]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][14:15:36]: [Client #981] Epoch: [5/5][10/17]	Loss: 1.516212
[INFO][14:15:36]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][14:15:37]: [Client #981] Woke up.
[INFO][14:15:37]: [Client #981] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][14:15:37]: [Client #981] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][14:15:37]: [Client #981] Model trained.
[INFO][14:15:37]: [Client #981] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:15:37]: [Server #615782] Received 0.26 MB of payload data from client #981 (simulated).
[INFO][14:15:37]: [Client #443] Woke up.
[INFO][14:15:37]: [Client #443] Epoch: [3/5][0/17]	Loss: 1.263348
[INFO][14:15:38]: [Client #443] Epoch: [3/5][10/17]	Loss: 1.191901
[INFO][14:15:38]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][14:15:39]: [Client #443] Woke up.
[INFO][14:15:39]: [Client #443] Epoch: [4/5][0/17]	Loss: 1.513973
[INFO][14:15:39]: [Client #443] Epoch: [4/5][10/17]	Loss: 2.052392
[INFO][14:15:39]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][14:15:40]: [Client #443] Woke up.
[INFO][14:15:40]: [Client #443] Epoch: [5/5][0/17]	Loss: 1.469900
[INFO][14:15:40]: [Client #443] Epoch: [5/5][10/17]	Loss: 2.270522
[INFO][14:15:40]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][14:15:41]: [Client #443] Woke up.
[INFO][14:15:41]: [Client #443] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_615875.pth.
[INFO][14:15:42]: [Client #443] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_615875.pth.
[INFO][14:15:42]: [Client #443] Model trained.
[INFO][14:15:42]: [Client #443] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:15:42]: [Server #615782] Received 0.26 MB of payload data from client #443 (simulated).
[INFO][14:15:42]: [Server #615782] Selecting client #745 for training.
[INFO][14:15:42]: [Server #615782] Sending the current model to client #745 (simulated).
[INFO][14:15:42]: [Server #615782] Sending 0.26 MB of payload data to client #745 (simulated).
[INFO][14:15:42]: [Server #615782] Selecting client #37 for training.
[INFO][14:15:42]: [Server #615782] Sending the current model to client #37 (simulated).
[INFO][14:15:42]: [Server #615782] Sending 0.26 MB of payload data to client #37 (simulated).
[INFO][14:15:42]: [Client #37] Selected by the server.
[INFO][14:15:42]: [Client #745] Selected by the server.
[INFO][14:15:42]: [Client #37] Loading its data source...
[INFO][14:15:42]: [Client #745] Loading its data source...
[INFO][14:15:42]: Data source: FEMNIST
[INFO][14:15:42]: Data source: FEMNIST
[INFO][14:15:42]: [Client #745] Dataset size: 70
[INFO][14:15:42]: [Client #745] Sampler: all_inclusive
[INFO][14:15:42]: [Client #745] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:15:42]: [93m[1m[Client #745] Started training in communication round #7.[0m
[INFO][14:15:42]: [Client #37] Dataset size: 164
[INFO][14:15:42]: [Client #37] Sampler: all_inclusive
[INFO][14:15:42]: [Client #37] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:15:42]: [93m[1m[Client #37] Started training in communication round #7.[0m
[INFO][14:15:44]: [Client #37] Loading the dataset.
[INFO][14:15:44]: [Client #745] Loading the dataset.
[INFO][14:15:49]: [Client #745] Epoch: [1/5][0/7]	Loss: 0.772406
[INFO][14:15:49]: [Client #37] Epoch: [1/5][0/17]	Loss: 1.893793
[INFO][14:15:49]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:15:49]: [Client #745] Woke up.
[INFO][14:15:49]: [Client #745] Epoch: [2/5][0/7]	Loss: 1.555476
[INFO][14:15:50]: [Client #37] Epoch: [1/5][10/17]	Loss: 2.099407
[INFO][14:15:50]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:15:50]: [Client #745] Woke up.
[INFO][14:15:50]: [Client #745] Epoch: [3/5][0/7]	Loss: 0.612814
[INFO][14:15:50]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][14:15:50]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:15:50]: [Client #745] Woke up.
[INFO][14:15:50]: [Client #745] Epoch: [4/5][0/7]	Loss: 1.696992
[INFO][14:15:50]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:15:50]: [Client #745] Woke up.
[INFO][14:15:50]: [Client #745] Epoch: [5/5][0/7]	Loss: 0.647870
[INFO][14:15:50]: [Client #745] Going to sleep for 0.01 seconds.
[INFO][14:15:50]: [Client #745] Woke up.
[INFO][14:15:50]: [Client #745] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_745_615874.pth.
[INFO][14:15:50]: [Client #745] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_745_615874.pth.
[INFO][14:15:50]: [Client #745] Model trained.
[INFO][14:15:50]: [Client #745] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:15:50]: [Server #615782] Received 0.26 MB of payload data from client #745 (simulated).
[INFO][14:15:52]: [Client #37] Woke up.
[INFO][14:15:52]: [Client #37] Epoch: [2/5][0/17]	Loss: 1.603151
[INFO][14:15:52]: [Client #37] Epoch: [2/5][10/17]	Loss: 1.706429
[INFO][14:15:52]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][14:15:54]: [Client #37] Woke up.
[INFO][14:15:54]: [Client #37] Epoch: [3/5][0/17]	Loss: 1.263564
[INFO][14:15:54]: [Client #37] Epoch: [3/5][10/17]	Loss: 0.932089
[INFO][14:15:54]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][14:15:56]: [Client #37] Woke up.
[INFO][14:15:56]: [Client #37] Epoch: [4/5][0/17]	Loss: 1.836977
[INFO][14:15:57]: [Client #37] Epoch: [4/5][10/17]	Loss: 1.664976
[INFO][14:15:57]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][14:15:59]: [Client #37] Woke up.
[INFO][14:15:59]: [Client #37] Epoch: [5/5][0/17]	Loss: 1.753684
[INFO][14:15:59]: [Client #37] Epoch: [5/5][10/17]	Loss: 3.158794
[INFO][14:15:59]: [Client #37] Going to sleep for 2.19 seconds.
[INFO][14:16:01]: [Client #37] Woke up.
[INFO][14:16:01]: [Client #37] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_37_615875.pth.
[INFO][14:16:02]: [Client #37] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_37_615875.pth.
[INFO][14:16:02]: [Client #37] Model trained.
[INFO][14:16:02]: [Client #37] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:16:02]: [Server #615782] Received 0.26 MB of payload data from client #37 (simulated).
[INFO][14:16:02]: [Server #615782] Selecting client #769 for training.
[INFO][14:16:02]: [Server #615782] Sending the current model to client #769 (simulated).
[INFO][14:16:02]: [Server #615782] Sending 0.26 MB of payload data to client #769 (simulated).
[INFO][14:16:02]: [Server #615782] Selecting client #520 for training.
[INFO][14:16:02]: [Server #615782] Sending the current model to client #520 (simulated).
[INFO][14:16:02]: [Server #615782] Sending 0.26 MB of payload data to client #520 (simulated).
[INFO][14:16:02]: [Client #769] Selected by the server.
[INFO][14:16:02]: [Client #520] Selected by the server.
[INFO][14:16:02]: [Client #769] Loading its data source...
[INFO][14:16:02]: [Client #520] Loading its data source...
[INFO][14:16:02]: Data source: FEMNIST
[INFO][14:16:02]: Data source: FEMNIST
[INFO][14:16:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:16:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:16:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/769.zip.
[INFO][14:16:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/520.zip.
2.6%5.2%7.8%10.4%12.9%15.5%18.1%20.7%23.3%25.9%28.5%31.1%33.6%36.2%38.8%41.4%44.0%46.6%49.2%51.8%54.3%56.9%59.5%62.1%64.7%2.9%5.7%8.6%11.4%14.3%17.1%20.0%22.8%25.7%28.5%31.4%34.2%37.1%39.9%42.8%45.6%67.3%69.9%72.5%75.0%77.6%80.2%82.8%85.4%88.0%90.6%93.2%95.8%98.3%100.0%[INFO][14:16:02]: Decompressing the dataset downloaded.
[INFO][14:16:02]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/769.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
48.5%51.3%54.2%57.0%59.9%62.7%65.6%68.5%71.3%74.2%77.0%79.9%82.7%85.6%88.4%91.3%94.1%97.0%99.8%100.0%[INFO][14:16:02]: Decompressing the dataset downloaded.
[INFO][14:16:02]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/520.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:16:02]: [Client #769] Dataset size: 150
[INFO][14:16:02]: [Client #769] Sampler: all_inclusive
[INFO][14:16:02]: [Client #769] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:16:02]: [93m[1m[Client #769] Started training in communication round #7.[0m

[INFO][14:16:02]: [Client #520] Dataset size: 153
[INFO][14:16:02]: [Client #520] Sampler: all_inclusive
[INFO][14:16:02]: [Client #520] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:16:02]: [93m[1m[Client #520] Started training in communication round #7.[0m

[INFO][14:16:04]: [Client #769] Loading the dataset.
[INFO][14:16:04]: [Client #520] Loading the dataset.
[INFO][14:16:10]: [Client #769] Epoch: [1/5][0/15]	Loss: 1.732084
[INFO][14:16:10]: [Client #520] Epoch: [1/5][0/16]	Loss: 2.105821
[INFO][14:16:10]: [Client #769] Epoch: [1/5][10/15]	Loss: 1.816816
[INFO][14:16:10]: [Client #769] Going to sleep for 3.87 seconds.
[INFO][14:16:10]: [Client #520] Epoch: [1/5][10/16]	Loss: 2.723053
[INFO][14:16:10]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:16:14]: [Client #769] Woke up.
[INFO][14:16:14]: [Client #769] Epoch: [2/5][0/15]	Loss: 1.876547
[INFO][14:16:14]: [Client #769] Epoch: [2/5][10/15]	Loss: 1.739256
[INFO][14:16:14]: [Client #769] Going to sleep for 3.87 seconds.
[INFO][14:16:18]: [Client #769] Woke up.
[INFO][14:16:18]: [Client #769] Epoch: [3/5][0/15]	Loss: 1.428496
[INFO][14:16:18]: [Client #769] Epoch: [3/5][10/15]	Loss: 2.200940
[INFO][14:16:18]: [Client #769] Going to sleep for 3.87 seconds.
[INFO][14:16:22]: [Client #769] Woke up.
[INFO][14:16:22]: [Client #769] Epoch: [4/5][0/15]	Loss: 1.432531
[INFO][14:16:22]: [Client #769] Epoch: [4/5][10/15]	Loss: 2.304578
[INFO][14:16:22]: [Client #769] Going to sleep for 3.87 seconds.
[INFO][14:16:26]: [Client #769] Woke up.
[INFO][14:16:26]: [Client #769] Epoch: [5/5][0/15]	Loss: 1.764416
[INFO][14:16:26]: [Client #769] Epoch: [5/5][10/15]	Loss: 0.718968
[INFO][14:16:26]: [Client #769] Going to sleep for 3.87 seconds.
[INFO][14:16:30]: [Client #769] Woke up.
[INFO][14:16:30]: [Client #769] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_769_615874.pth.
[INFO][14:16:30]: [Client #769] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_769_615874.pth.
[INFO][14:16:30]: [Client #769] Model trained.
[INFO][14:16:30]: [Client #769] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:16:30]: [Server #615782] Received 0.26 MB of payload data from client #769 (simulated).
[INFO][14:17:10]: [Client #520] Woke up.
[INFO][14:17:10]: [Client #520] Epoch: [2/5][0/16]	Loss: 1.797517
[INFO][14:17:10]: [Client #520] Epoch: [2/5][10/16]	Loss: 2.326456
[INFO][14:17:10]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:18:10]: [Client #520] Woke up.
[INFO][14:18:10]: [Client #520] Epoch: [3/5][0/16]	Loss: 2.158737
[INFO][14:18:10]: [Client #520] Epoch: [3/5][10/16]	Loss: 2.171828
[INFO][14:18:10]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:19:10]: [Client #520] Woke up.
[INFO][14:19:11]: [Client #520] Epoch: [4/5][0/16]	Loss: 1.177762
[INFO][14:19:11]: [Client #520] Epoch: [4/5][10/16]	Loss: 0.810899
[INFO][14:19:11]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:20:11]: [Client #520] Woke up.
[INFO][14:20:11]: [Client #520] Epoch: [5/5][0/16]	Loss: 2.360325
[INFO][14:20:11]: [Client #520] Epoch: [5/5][10/16]	Loss: 2.245504
[INFO][14:20:11]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:21:11]: [Client #520] Woke up.
[INFO][14:21:11]: [Client #520] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615875.pth.
[INFO][14:21:12]: [Client #520] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615875.pth.
[INFO][14:21:12]: [Client #520] Model trained.
[INFO][14:21:12]: [Client #520] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:12]: [Server #615782] Received 0.26 MB of payload data from client #520 (simulated).
[INFO][14:21:12]: [Server #615782] Selecting client #6 for training.
[INFO][14:21:12]: [Server #615782] Sending the current model to client #6 (simulated).
[INFO][14:21:12]: [Server #615782] Sending 0.26 MB of payload data to client #6 (simulated).
[INFO][14:21:12]: [Server #615782] Selecting client #279 for training.
[INFO][14:21:12]: [Server #615782] Sending the current model to client #279 (simulated).
[INFO][14:21:12]: [Server #615782] Sending 0.26 MB of payload data to client #279 (simulated).
[INFO][14:21:12]: [Client #6] Selected by the server.
[INFO][14:21:12]: [Client #6] Loading its data source...
[INFO][14:21:12]: [Client #279] Selected by the server.
[INFO][14:21:12]: Data source: FEMNIST
[INFO][14:21:12]: [Client #279] Loading its data source...
[INFO][14:21:12]: Data source: FEMNIST
[INFO][14:21:12]: [Client #279] Dataset size: 148
[INFO][14:21:12]: [Client #279] Sampler: all_inclusive
[INFO][14:21:12]: [Client #279] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:12]: [93m[1m[Client #279] Started training in communication round #7.[0m
[INFO][14:21:12]: [Client #6] Dataset size: 163
[INFO][14:21:12]: [Client #6] Sampler: all_inclusive
[INFO][14:21:12]: [Client #6] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:12]: [93m[1m[Client #6] Started training in communication round #7.[0m
[INFO][14:21:14]: [Client #6] Loading the dataset.
[INFO][14:21:14]: [Client #279] Loading the dataset.
[INFO][14:21:19]: [Client #6] Epoch: [1/5][0/17]	Loss: 1.698438
[INFO][14:21:19]: [Client #279] Epoch: [1/5][0/15]	Loss: 2.407981
[INFO][14:21:19]: [Client #6] Epoch: [1/5][10/17]	Loss: 1.998407
[INFO][14:21:19]: [Client #279] Epoch: [1/5][10/15]	Loss: 1.268511
[INFO][14:21:19]: [Client #6] Going to sleep for 0.10 seconds.
[INFO][14:21:19]: [Client #279] Going to sleep for 0.52 seconds.
[INFO][14:21:20]: [Client #6] Woke up.
[INFO][14:21:20]: [Client #6] Epoch: [2/5][0/17]	Loss: 3.744696
[INFO][14:21:20]: [Client #6] Epoch: [2/5][10/17]	Loss: 1.836948
[INFO][14:21:20]: [Client #6] Going to sleep for 0.10 seconds.
[INFO][14:21:20]: [Client #6] Woke up.
[INFO][14:21:20]: [Client #6] Epoch: [3/5][0/17]	Loss: 1.472475
[INFO][14:21:20]: [Client #6] Epoch: [3/5][10/17]	Loss: 3.229717
[INFO][14:21:20]: [Client #6] Going to sleep for 0.10 seconds.
[INFO][14:21:20]: [Client #279] Woke up.
[INFO][14:21:20]: [Client #279] Epoch: [2/5][0/15]	Loss: 1.889216
[INFO][14:21:20]: [Client #6] Woke up.
[INFO][14:21:20]: [Client #6] Epoch: [4/5][0/17]	Loss: 1.553958
[INFO][14:21:20]: [Client #279] Epoch: [2/5][10/15]	Loss: 0.797279
[INFO][14:21:20]: [Client #279] Going to sleep for 0.52 seconds.
[INFO][14:21:20]: [Client #6] Epoch: [4/5][10/17]	Loss: 1.990481
[INFO][14:21:20]: [Client #6] Going to sleep for 0.10 seconds.
[INFO][14:21:20]: [Client #6] Woke up.
[INFO][14:21:20]: [Client #6] Epoch: [5/5][0/17]	Loss: 1.456733
[INFO][14:21:20]: [Client #6] Epoch: [5/5][10/17]	Loss: 1.116349
[INFO][14:21:20]: [Client #6] Going to sleep for 0.10 seconds.
[INFO][14:21:21]: [Client #6] Woke up.
[INFO][14:21:21]: [Client #6] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_6_615874.pth.
[INFO][14:21:21]: [Client #279] Woke up.
[INFO][14:21:21]: [Client #279] Epoch: [3/5][0/15]	Loss: 2.070823
[INFO][14:21:21]: [Client #279] Epoch: [3/5][10/15]	Loss: 1.870953
[INFO][14:21:21]: [Client #279] Going to sleep for 0.52 seconds.
[INFO][14:21:21]: [Client #6] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_6_615874.pth.
[INFO][14:21:21]: [Client #6] Model trained.
[INFO][14:21:21]: [Client #6] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:21]: [Server #615782] Received 0.26 MB of payload data from client #6 (simulated).
[INFO][14:21:21]: [Client #279] Woke up.
[INFO][14:21:21]: [Client #279] Epoch: [4/5][0/15]	Loss: 1.168107
[INFO][14:21:21]: [Client #279] Epoch: [4/5][10/15]	Loss: 1.004065
[INFO][14:21:21]: [Client #279] Going to sleep for 0.52 seconds.
[INFO][14:21:22]: [Client #279] Woke up.
[INFO][14:21:22]: [Client #279] Epoch: [5/5][0/15]	Loss: 1.669914
[INFO][14:21:22]: [Client #279] Epoch: [5/5][10/15]	Loss: 1.067333
[INFO][14:21:22]: [Client #279] Going to sleep for 0.52 seconds.
[INFO][14:21:23]: [Client #279] Woke up.
[INFO][14:21:23]: [Client #279] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_279_615875.pth.
[INFO][14:21:23]: [Client #279] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_279_615875.pth.
[INFO][14:21:23]: [Client #279] Model trained.
[INFO][14:21:23]: [Client #279] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:23]: [Server #615782] Received 0.26 MB of payload data from client #279 (simulated).
[INFO][14:21:23]: [Server #615782] Selecting client #538 for training.
[INFO][14:21:23]: [Server #615782] Sending the current model to client #538 (simulated).
[INFO][14:21:23]: [Server #615782] Sending 0.26 MB of payload data to client #538 (simulated).
[INFO][14:21:23]: [Server #615782] Selecting client #772 for training.
[INFO][14:21:23]: [Server #615782] Sending the current model to client #772 (simulated).
[INFO][14:21:23]: [Server #615782] Sending 0.26 MB of payload data to client #772 (simulated).
[INFO][14:21:23]: [Client #772] Selected by the server.
[INFO][14:21:23]: [Client #772] Loading its data source...
[INFO][14:21:23]: [Client #538] Selected by the server.
[INFO][14:21:23]: Data source: FEMNIST
[INFO][14:21:23]: [Client #538] Loading its data source...
[INFO][14:21:23]: Data source: FEMNIST
[INFO][14:21:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:21:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/772.zip.
[INFO][14:21:23]: [Client #538] Dataset size: 157
[INFO][14:21:23]: [Client #538] Sampler: all_inclusive
[INFO][14:21:23]: [Client #538] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:23]: [93m[1m[Client #538] Started training in communication round #7.[0m
2.8%5.6%8.4%11.2%14.0%16.8%19.5%22.3%25.1%27.9%30.7%33.5%36.3%39.1%41.9%44.7%47.5%50.3%53.0%55.8%58.6%61.4%64.2%67.0%69.8%72.6%75.4%78.2%81.0%83.8%86.5%89.3%92.1%94.9%97.7%100.0%[INFO][14:21:24]: Decompressing the dataset downloaded.
[INFO][14:21:24]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/772.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:21:24]: [Client #772] Dataset size: 156
[INFO][14:21:24]: [Client #772] Sampler: all_inclusive
[INFO][14:21:24]: [Client #772] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:24]: [93m[1m[Client #772] Started training in communication round #7.[0m

[INFO][14:21:25]: [Client #538] Loading the dataset.
[INFO][14:21:25]: [Client #772] Loading the dataset.
[INFO][14:21:31]: [Client #538] Epoch: [1/5][0/16]	Loss: 1.679600
[INFO][14:21:31]: [Client #538] Epoch: [1/5][10/16]	Loss: 1.661640
[INFO][14:21:31]: [Client #772] Epoch: [1/5][0/16]	Loss: 2.934608
[INFO][14:21:31]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:21:31]: [Client #772] Epoch: [1/5][10/16]	Loss: 1.557055
[INFO][14:21:31]: [Client #772] Going to sleep for 2.29 seconds.
[INFO][14:21:32]: [Client #538] Woke up.
[INFO][14:21:32]: [Client #538] Epoch: [2/5][0/16]	Loss: 2.123927
[INFO][14:21:32]: [Client #538] Epoch: [2/5][10/16]	Loss: 1.513517
[INFO][14:21:32]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:21:33]: [Client #538] Woke up.
[INFO][14:21:33]: [Client #538] Epoch: [3/5][0/16]	Loss: 2.294383
[INFO][14:21:33]: [Client #538] Epoch: [3/5][10/16]	Loss: 1.133226
[INFO][14:21:33]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:21:33]: [Client #772] Woke up.
[INFO][14:21:33]: [Client #772] Epoch: [2/5][0/16]	Loss: 1.246034
[INFO][14:21:33]: [Client #772] Epoch: [2/5][10/16]	Loss: 3.042347
[INFO][14:21:33]: [Client #772] Going to sleep for 2.29 seconds.
[INFO][14:21:34]: [Client #538] Woke up.
[INFO][14:21:34]: [Client #538] Epoch: [4/5][0/16]	Loss: 1.826847
[INFO][14:21:34]: [Client #538] Epoch: [4/5][10/16]	Loss: 2.845971
[INFO][14:21:34]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:21:35]: [Client #538] Woke up.
[INFO][14:21:35]: [Client #538] Epoch: [5/5][0/16]	Loss: 2.052654
[INFO][14:21:35]: [Client #538] Epoch: [5/5][10/16]	Loss: 1.864510
[INFO][14:21:35]: [Client #538] Going to sleep for 0.91 seconds.
[INFO][14:21:36]: [Client #772] Woke up.
[INFO][14:21:36]: [Client #772] Epoch: [3/5][0/16]	Loss: 1.527818
[INFO][14:21:36]: [Client #772] Epoch: [3/5][10/16]	Loss: 2.526962
[INFO][14:21:36]: [Client #772] Going to sleep for 2.29 seconds.
[INFO][14:21:36]: [Client #538] Woke up.
[INFO][14:21:36]: [Client #538] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_538_615874.pth.
[INFO][14:21:37]: [Client #538] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_538_615874.pth.
[INFO][14:21:37]: [Client #538] Model trained.
[INFO][14:21:37]: [Client #538] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:37]: [Server #615782] Received 0.26 MB of payload data from client #538 (simulated).
[INFO][14:21:38]: [Client #772] Woke up.
[INFO][14:21:38]: [Client #772] Epoch: [4/5][0/16]	Loss: 0.745423
[INFO][14:21:38]: [Client #772] Epoch: [4/5][10/16]	Loss: 3.235196
[INFO][14:21:38]: [Client #772] Going to sleep for 2.29 seconds.
[INFO][14:21:41]: [Client #772] Woke up.
[INFO][14:21:41]: [Client #772] Epoch: [5/5][0/16]	Loss: 2.335123
[INFO][14:21:41]: [Client #772] Epoch: [5/5][10/16]	Loss: 1.927912
[INFO][14:21:41]: [Client #772] Going to sleep for 2.29 seconds.
[INFO][14:21:43]: [Client #772] Woke up.
[INFO][14:21:43]: [Client #772] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_772_615875.pth.
[INFO][14:21:44]: [Client #772] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_772_615875.pth.
[INFO][14:21:44]: [Client #772] Model trained.
[INFO][14:21:44]: [Client #772] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:44]: [Server #615782] Received 0.26 MB of payload data from client #772 (simulated).
[INFO][14:21:44]: [Server #615782] Selecting client #52 for training.
[INFO][14:21:44]: [Server #615782] Sending the current model to client #52 (simulated).
[INFO][14:21:44]: [Server #615782] Sending 0.26 MB of payload data to client #52 (simulated).
[INFO][14:21:44]: [Server #615782] Selecting client #552 for training.
[INFO][14:21:44]: [Server #615782] Sending the current model to client #552 (simulated).
[INFO][14:21:44]: [Server #615782] Sending 0.26 MB of payload data to client #552 (simulated).
[INFO][14:21:44]: [Client #552] Selected by the server.
[INFO][14:21:44]: [Client #52] Selected by the server.
[INFO][14:21:44]: [Client #552] Loading its data source...
[INFO][14:21:44]: Data source: FEMNIST
[INFO][14:21:44]: [Client #52] Loading its data source...
[INFO][14:21:44]: Data source: FEMNIST
[INFO][14:21:44]: [Client #552] Dataset size: 150
[INFO][14:21:44]: [Client #552] Sampler: all_inclusive
[INFO][14:21:44]: [Client #552] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:44]: [93m[1m[Client #552] Started training in communication round #7.[0m
[INFO][14:21:44]: [Client #52] Dataset size: 162
[INFO][14:21:44]: [Client #52] Sampler: all_inclusive
[INFO][14:21:44]: [Client #52] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:21:44]: [93m[1m[Client #52] Started training in communication round #7.[0m
[INFO][14:21:46]: [Client #552] Loading the dataset.
[INFO][14:21:46]: [Client #52] Loading the dataset.
[INFO][14:21:51]: [Client #552] Epoch: [1/5][0/15]	Loss: 1.871557
[INFO][14:21:51]: [Client #52] Epoch: [1/5][0/17]	Loss: 1.774547
[INFO][14:21:51]: [Client #552] Epoch: [1/5][10/15]	Loss: 3.697446
[INFO][14:21:51]: [Client #52] Epoch: [1/5][10/17]	Loss: 1.913985
[INFO][14:21:51]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][14:21:51]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][14:21:52]: [Client #552] Woke up.
[INFO][14:21:52]: [Client #552] Epoch: [2/5][0/15]	Loss: 1.639692
[INFO][14:21:52]: [Client #552] Epoch: [2/5][10/15]	Loss: 0.720228
[INFO][14:21:53]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][14:21:53]: [Client #52] Woke up.
[INFO][14:21:53]: [Client #52] Epoch: [2/5][0/17]	Loss: 2.369617
[INFO][14:21:54]: [Client #52] Epoch: [2/5][10/17]	Loss: 2.213122
[INFO][14:21:54]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][14:21:54]: [Client #552] Woke up.
[INFO][14:21:54]: [Client #552] Epoch: [3/5][0/15]	Loss: 1.041835
[INFO][14:21:54]: [Client #552] Epoch: [3/5][10/15]	Loss: 1.409296
[INFO][14:21:54]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][14:21:55]: [Client #552] Woke up.
[INFO][14:21:55]: [Client #552] Epoch: [4/5][0/15]	Loss: 2.306196
[INFO][14:21:55]: [Client #552] Epoch: [4/5][10/15]	Loss: 1.186926
[INFO][14:21:55]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][14:21:56]: [Client #52] Woke up.
[INFO][14:21:56]: [Client #52] Epoch: [3/5][0/17]	Loss: 1.599749
[INFO][14:21:56]: [Client #52] Epoch: [3/5][10/17]	Loss: 1.748471
[INFO][14:21:56]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][14:21:56]: [Client #552] Woke up.
[INFO][14:21:56]: [Client #552] Epoch: [5/5][0/15]	Loss: 0.917570
[INFO][14:21:56]: [Client #552] Epoch: [5/5][10/15]	Loss: 2.818274
[INFO][14:21:56]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][14:21:57]: [Client #552] Woke up.
[INFO][14:21:57]: [Client #552] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_552_615875.pth.
[INFO][14:21:58]: [Client #52] Woke up.
[INFO][14:21:58]: [Client #52] Epoch: [4/5][0/17]	Loss: 1.265813
[INFO][14:21:58]: [Client #552] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_552_615875.pth.
[INFO][14:21:58]: [Client #552] Model trained.
[INFO][14:21:58]: [Client #552] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:21:58]: [Server #615782] Received 0.26 MB of payload data from client #552 (simulated).
[INFO][14:21:58]: [Client #52] Epoch: [4/5][10/17]	Loss: 2.898755
[INFO][14:21:58]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][14:22:00]: [Client #52] Woke up.
[INFO][14:22:00]: [Client #52] Epoch: [5/5][0/17]	Loss: 1.088471
[INFO][14:22:00]: [Client #52] Epoch: [5/5][10/17]	Loss: 1.047441
[INFO][14:22:00]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][14:22:02]: [Client #52] Woke up.
[INFO][14:22:02]: [Client #52] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_52_615874.pth.
[INFO][14:22:03]: [Client #52] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_52_615874.pth.
[INFO][14:22:03]: [Client #52] Model trained.
[INFO][14:22:03]: [Client #52] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:22:03]: [Server #615782] Received 0.26 MB of payload data from client #52 (simulated).
[INFO][14:22:03]: [Server #615782] Selecting client #806 for training.
[INFO][14:22:03]: [Server #615782] Sending the current model to client #806 (simulated).
[INFO][14:22:03]: [Server #615782] Sending 0.26 MB of payload data to client #806 (simulated).
[INFO][14:22:03]: [Server #615782] Selecting client #652 for training.
[INFO][14:22:03]: [Server #615782] Sending the current model to client #652 (simulated).
[INFO][14:22:03]: [Server #615782] Sending 0.26 MB of payload data to client #652 (simulated).
[INFO][14:22:03]: [Client #806] Selected by the server.
[INFO][14:22:03]: [Client #806] Loading its data source...
[INFO][14:22:03]: Data source: FEMNIST
[INFO][14:22:03]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:22:03]: [Client #652] Selected by the server.
[INFO][14:22:03]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/806.zip.
[INFO][14:22:03]: [Client #652] Loading its data source...
[INFO][14:22:03]: Data source: FEMNIST
[INFO][14:22:03]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:22:03]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/652.zip.
2.5%2.6%5.2%7.8%10.4%13.0%15.6%18.2%20.8%4.9%7.4%9.8%12.3%14.7%17.2%19.6%22.1%24.5%27.0%29.5%31.9%34.4%36.8%39.3%41.7%44.2%46.6%49.1%51.6%54.0%56.5%58.9%61.4%63.8%66.3%68.7%71.2%73.6%23.4%76.1%78.6%26.0%81.0%83.5%28.6%31.2%85.9%33.8%88.4%36.4%90.8%39.0%93.3%41.6%95.7%98.2%44.2%46.8%49.5%52.1%54.7%57.3%59.9%62.5%65.1%67.7%70.3%72.9%75.5%78.1%80.7%83.3%85.9%88.5%91.1%93.7%96.3%98.9%100.0%[INFO][14:22:03]: Decompressing the dataset downloaded.
100.0%[INFO][14:22:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/806.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:22:03]: Decompressing the dataset downloaded.
[INFO][14:22:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/652.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:22:03]: [Client #806] Dataset size: 153
[INFO][14:22:03]: [Client #806] Sampler: all_inclusive
[INFO][14:22:03]: [Client #652] Dataset size: 164
[INFO][14:22:03]: [Client #652] Sampler: all_inclusive
[INFO][14:22:03]: [Client #806] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:22:03]: [Client #652] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:22:03]: [93m[1m[Client #806] Started training in communication round #7.[0m

[INFO][14:22:03]: [93m[1m[Client #652] Started training in communication round #7.[0m

[INFO][14:22:05]: [Client #806] Loading the dataset.
[INFO][14:22:05]: [Client #652] Loading the dataset.
[INFO][14:22:11]: [Client #806] Epoch: [1/5][0/16]	Loss: 2.166717
[INFO][14:22:11]: [Client #652] Epoch: [1/5][0/17]	Loss: 2.366082
[INFO][14:22:11]: [Client #806] Epoch: [1/5][10/16]	Loss: 1.793410
[INFO][14:22:11]: [Client #806] Going to sleep for 11.80 seconds.
[INFO][14:22:11]: [Client #652] Epoch: [1/5][10/17]	Loss: 2.104469
[INFO][14:22:11]: [Client #652] Going to sleep for 0.12 seconds.
[INFO][14:22:12]: [Client #652] Woke up.
[INFO][14:22:12]: [Client #652] Epoch: [2/5][0/17]	Loss: 1.105168
[INFO][14:22:12]: [Client #652] Epoch: [2/5][10/17]	Loss: 0.782787
[INFO][14:22:12]: [Client #652] Going to sleep for 0.12 seconds.
[INFO][14:22:12]: [Client #652] Woke up.
[INFO][14:22:12]: [Client #652] Epoch: [3/5][0/17]	Loss: 2.239147
[INFO][14:22:12]: [Client #652] Epoch: [3/5][10/17]	Loss: 1.626444
[INFO][14:22:12]: [Client #652] Going to sleep for 0.12 seconds.
[INFO][14:22:12]: [Client #652] Woke up.
[INFO][14:22:12]: [Client #652] Epoch: [4/5][0/17]	Loss: 1.375919
[INFO][14:22:12]: [Client #652] Epoch: [4/5][10/17]	Loss: 1.162082
[INFO][14:22:12]: [Client #652] Going to sleep for 0.12 seconds.
[INFO][14:22:12]: [Client #652] Woke up.
[INFO][14:22:12]: [Client #652] Epoch: [5/5][0/17]	Loss: 1.238028
[INFO][14:22:13]: [Client #652] Epoch: [5/5][10/17]	Loss: 1.519682
[INFO][14:22:13]: [Client #652] Going to sleep for 0.12 seconds.
[INFO][14:22:13]: [Client #652] Woke up.
[INFO][14:22:13]: [Client #652] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_652_615875.pth.
[INFO][14:22:13]: [Client #652] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_652_615875.pth.
[INFO][14:22:13]: [Client #652] Model trained.
[INFO][14:22:13]: [Client #652] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:22:13]: [Server #615782] Received 0.26 MB of payload data from client #652 (simulated).
[INFO][14:22:23]: [Client #806] Woke up.
[INFO][14:22:23]: [Client #806] Epoch: [2/5][0/16]	Loss: 1.580859
[INFO][14:22:23]: [Client #806] Epoch: [2/5][10/16]	Loss: 1.751936
[INFO][14:22:23]: [Client #806] Going to sleep for 11.80 seconds.
[INFO][14:22:35]: [Client #806] Woke up.
[INFO][14:22:35]: [Client #806] Epoch: [3/5][0/16]	Loss: 1.315869
[INFO][14:22:35]: [Client #806] Epoch: [3/5][10/16]	Loss: 2.180832
[INFO][14:22:35]: [Client #806] Going to sleep for 11.80 seconds.
[INFO][14:22:47]: [Client #806] Woke up.
[INFO][14:22:47]: [Client #806] Epoch: [4/5][0/16]	Loss: 1.343026
[INFO][14:22:47]: [Client #806] Epoch: [4/5][10/16]	Loss: 0.862549
[INFO][14:22:47]: [Client #806] Going to sleep for 11.80 seconds.
[INFO][14:22:59]: [Client #806] Woke up.
[INFO][14:22:59]: [Client #806] Epoch: [5/5][0/16]	Loss: 1.211288
[INFO][14:22:59]: [Client #806] Epoch: [5/5][10/16]	Loss: 0.662608
[INFO][14:22:59]: [Client #806] Going to sleep for 11.80 seconds.
[INFO][14:23:11]: [Client #806] Woke up.
[INFO][14:23:11]: [Client #806] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_806_615874.pth.
[INFO][14:23:12]: [Client #806] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_806_615874.pth.
[INFO][14:23:12]: [Client #806] Model trained.
[INFO][14:23:12]: [Client #806] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:12]: [Server #615782] Received 0.26 MB of payload data from client #806 (simulated).
[INFO][14:23:12]: [Server #615782] Selecting client #934 for training.
[INFO][14:23:12]: [Server #615782] Sending the current model to client #934 (simulated).
[INFO][14:23:12]: [Server #615782] Sending 0.26 MB of payload data to client #934 (simulated).
[INFO][14:23:12]: [Server #615782] Selecting client #73 for training.
[INFO][14:23:12]: [Server #615782] Sending the current model to client #73 (simulated).
[INFO][14:23:12]: [Server #615782] Sending 0.26 MB of payload data to client #73 (simulated).
[INFO][14:23:12]: [Client #934] Selected by the server.
[INFO][14:23:12]: [Client #934] Loading its data source...
[INFO][14:23:12]: Data source: FEMNIST
[INFO][14:23:12]: [Client #73] Selected by the server.
[INFO][14:23:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:23:12]: [Client #73] Loading its data source...
[INFO][14:23:12]: Data source: FEMNIST
[INFO][14:23:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/934.zip.
[INFO][14:23:12]: [Client #73] Dataset size: 155
[INFO][14:23:12]: [Client #73] Sampler: all_inclusive
[INFO][14:23:12]: [Client #73] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:12]: [93m[1m[Client #73] Started training in communication round #7.[0m
3.2%6.4%9.6%12.8%16.0%19.2%22.4%25.6%28.8%32.0%35.2%38.4%41.6%44.8%48.0%51.2%54.4%57.6%60.8%64.0%67.2%70.4%73.6%76.8%80.0%83.2%86.4%89.6%92.8%96.0%99.2%100.0%[INFO][14:23:12]: Decompressing the dataset downloaded.
[INFO][14:23:12]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/934.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:23:12]: [Client #934] Dataset size: 162
[INFO][14:23:12]: [Client #934] Sampler: all_inclusive
[INFO][14:23:12]: [Client #934] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:12]: [93m[1m[Client #934] Started training in communication round #7.[0m

[INFO][14:23:14]: [Client #73] Loading the dataset.
[INFO][14:23:14]: [Client #934] Loading the dataset.
[INFO][14:23:19]: [Client #73] Epoch: [1/5][0/16]	Loss: 2.573222
[INFO][14:23:19]: [Client #934] Epoch: [1/5][0/17]	Loss: 2.605351
[INFO][14:23:19]: [Client #73] Epoch: [1/5][10/16]	Loss: 2.360708
[INFO][14:23:19]: [Client #73] Going to sleep for 0.16 seconds.
[INFO][14:23:19]: [Client #934] Epoch: [1/5][10/17]	Loss: 1.319886
[INFO][14:23:19]: [Client #934] Going to sleep for 0.41 seconds.
[INFO][14:23:20]: [Client #73] Woke up.
[INFO][14:23:20]: [Client #73] Epoch: [2/5][0/16]	Loss: 1.860846
[INFO][14:23:20]: [Client #73] Epoch: [2/5][10/16]	Loss: 0.913926
[INFO][14:23:20]: [Client #73] Going to sleep for 0.16 seconds.
[INFO][14:23:20]: [Client #73] Woke up.
[INFO][14:23:20]: [Client #73] Epoch: [3/5][0/16]	Loss: 1.863996
[INFO][14:23:20]: [Client #934] Woke up.
[INFO][14:23:20]: [Client #934] Epoch: [2/5][0/17]	Loss: 2.247099
[INFO][14:23:20]: [Client #73] Epoch: [3/5][10/16]	Loss: 1.840891
[INFO][14:23:20]: [Client #73] Going to sleep for 0.16 seconds.
[INFO][14:23:20]: [Client #934] Epoch: [2/5][10/17]	Loss: 2.093234
[INFO][14:23:20]: [Client #934] Going to sleep for 0.41 seconds.
[INFO][14:23:20]: [Client #73] Woke up.
[INFO][14:23:20]: [Client #73] Epoch: [4/5][0/16]	Loss: 2.360859
[INFO][14:23:20]: [Client #73] Epoch: [4/5][10/16]	Loss: 1.284643
[INFO][14:23:20]: [Client #73] Going to sleep for 0.16 seconds.
[INFO][14:23:20]: [Client #73] Woke up.
[INFO][14:23:20]: [Client #934] Woke up.
[INFO][14:23:20]: [Client #73] Epoch: [5/5][0/16]	Loss: 0.478238
[INFO][14:23:20]: [Client #934] Epoch: [3/5][0/17]	Loss: 1.857474
[INFO][14:23:21]: [Client #73] Epoch: [5/5][10/16]	Loss: 1.248905
[INFO][14:23:21]: [Client #934] Epoch: [3/5][10/17]	Loss: 1.565576
[INFO][14:23:21]: [Client #73] Going to sleep for 0.16 seconds.
[INFO][14:23:21]: [Client #934] Going to sleep for 0.41 seconds.
[INFO][14:23:21]: [Client #73] Woke up.
[INFO][14:23:21]: [Client #73] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_73_615875.pth.
[INFO][14:23:21]: [Client #934] Woke up.
[INFO][14:23:21]: [Client #934] Epoch: [4/5][0/17]	Loss: 1.957822
[INFO][14:23:21]: [Client #934] Epoch: [4/5][10/17]	Loss: 1.416308
[INFO][14:23:21]: [Client #934] Going to sleep for 0.41 seconds.
[INFO][14:23:21]: [Client #73] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_73_615875.pth.
[INFO][14:23:21]: [Client #73] Model trained.
[INFO][14:23:21]: [Client #73] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:21]: [Server #615782] Received 0.26 MB of payload data from client #73 (simulated).
[INFO][14:23:22]: [Client #934] Woke up.
[INFO][14:23:22]: [Client #934] Epoch: [5/5][0/17]	Loss: 2.626801
[INFO][14:23:22]: [Client #934] Epoch: [5/5][10/17]	Loss: 1.083961
[INFO][14:23:22]: [Client #934] Going to sleep for 0.41 seconds.
[INFO][14:23:22]: [Client #934] Woke up.
[INFO][14:23:22]: [Client #934] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_934_615874.pth.
[INFO][14:23:23]: [Client #934] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_934_615874.pth.
[INFO][14:23:23]: [Client #934] Model trained.
[INFO][14:23:23]: [Client #934] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:23]: [Server #615782] Received 0.26 MB of payload data from client #934 (simulated).
[INFO][14:23:23]: [Server #615782] Selecting client #278 for training.
[INFO][14:23:23]: [Server #615782] Sending the current model to client #278 (simulated).
[INFO][14:23:23]: [Server #615782] Sending 0.26 MB of payload data to client #278 (simulated).
[INFO][14:23:23]: [Server #615782] Selecting client #922 for training.
[INFO][14:23:23]: [Server #615782] Sending the current model to client #922 (simulated).
[INFO][14:23:23]: [Server #615782] Sending 0.26 MB of payload data to client #922 (simulated).
[INFO][14:23:23]: [Client #278] Selected by the server.
[INFO][14:23:23]: [Client #278] Loading its data source...
[INFO][14:23:23]: Data source: FEMNIST
[INFO][14:23:23]: [Client #922] Selected by the server.
[INFO][14:23:23]: [Client #922] Loading its data source...
[INFO][14:23:23]: Data source: FEMNIST
[INFO][14:23:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:23:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/922.zip.
[INFO][14:23:23]: [Client #278] Dataset size: 196
[INFO][14:23:23]: [Client #278] Sampler: all_inclusive
[INFO][14:23:23]: [Client #278] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:23]: [93m[1m[Client #278] Started training in communication round #7.[0m
1.6%3.2%4.8%6.4%8.0%9.6%11.2%12.8%14.4%16.0%17.5%19.1%20.7%22.3%23.9%25.5%27.1%28.7%30.3%31.9%33.5%35.1%36.7%38.3%39.9%41.5%43.1%44.7%46.3%47.9%49.5%51.0%52.6%54.2%55.8%57.4%59.0%60.6%62.2%63.8%65.4%67.0%68.6%70.2%71.8%73.4%75.0%76.6%78.2%79.8%81.4%83.0%84.5%86.1%87.7%89.3%90.9%92.5%94.1%95.7%97.3%98.9%100.0%[INFO][14:23:23]: Decompressing the dataset downloaded.
[INFO][14:23:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/922.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:23:23]: [Client #922] Dataset size: 258
[INFO][14:23:23]: [Client #922] Sampler: all_inclusive
[INFO][14:23:23]: [Client #922] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:23]: [93m[1m[Client #922] Started training in communication round #7.[0m

[INFO][14:23:25]: [Client #278] Loading the dataset.
[INFO][14:23:25]: [Client #922] Loading the dataset.
[INFO][14:23:30]: [Client #278] Epoch: [1/5][0/20]	Loss: 1.740600
[INFO][14:23:30]: [Client #922] Epoch: [1/5][0/26]	Loss: 3.254149
[INFO][14:23:30]: [Client #278] Epoch: [1/5][10/20]	Loss: 3.173670
[INFO][14:23:31]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][14:23:31]: [Client #922] Epoch: [1/5][10/26]	Loss: 3.141743
[INFO][14:23:31]: [Client #922] Epoch: [1/5][20/26]	Loss: 1.675234
[INFO][14:23:31]: [Client #922] Going to sleep for 0.59 seconds.
[INFO][14:23:31]: [Client #922] Woke up.
[INFO][14:23:31]: [Client #922] Epoch: [2/5][0/26]	Loss: 2.339017
[INFO][14:23:31]: [Client #278] Woke up.
[INFO][14:23:31]: [Client #278] Epoch: [2/5][0/20]	Loss: 1.963502
[INFO][14:23:31]: [Client #922] Epoch: [2/5][10/26]	Loss: 1.544222
[INFO][14:23:31]: [Client #278] Epoch: [2/5][10/20]	Loss: 1.570222
[INFO][14:23:31]: [Client #922] Epoch: [2/5][20/26]	Loss: 2.623127
[INFO][14:23:31]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][14:23:31]: [Client #922] Going to sleep for 0.59 seconds.
[INFO][14:23:32]: [Client #922] Woke up.
[INFO][14:23:32]: [Client #922] Epoch: [3/5][0/26]	Loss: 2.449389
[INFO][14:23:32]: [Client #922] Epoch: [3/5][10/26]	Loss: 2.420359
[INFO][14:23:32]: [Client #278] Woke up.
[INFO][14:23:32]: [Client #278] Epoch: [3/5][0/20]	Loss: 1.594403
[INFO][14:23:32]: [Client #922] Epoch: [3/5][20/26]	Loss: 2.961192
[INFO][14:23:32]: [Client #922] Going to sleep for 0.59 seconds.
[INFO][14:23:32]: [Client #278] Epoch: [3/5][10/20]	Loss: 1.967890
[INFO][14:23:32]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][14:23:33]: [Client #922] Woke up.
[INFO][14:23:33]: [Client #922] Epoch: [4/5][0/26]	Loss: 2.759606
[INFO][14:23:33]: [Client #922] Epoch: [4/5][10/26]	Loss: 2.452247
[INFO][14:23:33]: [Client #922] Epoch: [4/5][20/26]	Loss: 1.625842
[INFO][14:23:33]: [Client #922] Going to sleep for 0.59 seconds.
[INFO][14:23:33]: [Client #278] Woke up.
[INFO][14:23:33]: [Client #278] Epoch: [4/5][0/20]	Loss: 1.966857
[INFO][14:23:33]: [Client #278] Epoch: [4/5][10/20]	Loss: 1.818935
[INFO][14:23:33]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][14:23:34]: [Client #922] Woke up.
[INFO][14:23:34]: [Client #922] Epoch: [5/5][0/26]	Loss: 2.006267
[INFO][14:23:34]: [Client #922] Epoch: [5/5][10/26]	Loss: 1.770620
[INFO][14:23:34]: [Client #922] Epoch: [5/5][20/26]	Loss: 2.841045
[INFO][14:23:34]: [Client #922] Going to sleep for 0.59 seconds.
[INFO][14:23:34]: [Client #278] Woke up.
[INFO][14:23:34]: [Client #278] Epoch: [5/5][0/20]	Loss: 2.998179
[INFO][14:23:34]: [Client #278] Epoch: [5/5][10/20]	Loss: 1.524401
[INFO][14:23:34]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][14:23:34]: [Client #922] Woke up.
[INFO][14:23:34]: [Client #922] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_922_615875.pth.
[INFO][14:23:35]: [Client #278] Woke up.
[INFO][14:23:35]: [Client #278] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_278_615874.pth.
[INFO][14:23:35]: [Client #922] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_922_615875.pth.
[INFO][14:23:35]: [Client #922] Model trained.
[INFO][14:23:35]: [Client #922] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:35]: [Server #615782] Received 0.26 MB of payload data from client #922 (simulated).
[INFO][14:23:36]: [Client #278] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_278_615874.pth.
[INFO][14:23:36]: [Client #278] Model trained.
[INFO][14:23:36]: [Client #278] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:36]: [Server #615782] Received 0.26 MB of payload data from client #278 (simulated).
[INFO][14:23:36]: [Server #615782] Selecting client #603 for training.
[INFO][14:23:36]: [Server #615782] Sending the current model to client #603 (simulated).
[INFO][14:23:36]: [Server #615782] Sending 0.26 MB of payload data to client #603 (simulated).
[INFO][14:23:36]: [Server #615782] Selecting client #838 for training.
[INFO][14:23:36]: [Server #615782] Sending the current model to client #838 (simulated).
[INFO][14:23:36]: [Server #615782] Sending 0.26 MB of payload data to client #838 (simulated).
[INFO][14:23:36]: [Client #603] Selected by the server.
[INFO][14:23:36]: [Client #603] Loading its data source...
[INFO][14:23:36]: Data source: FEMNIST
[INFO][14:23:36]: [Client #838] Selected by the server.
[INFO][14:23:36]: [Client #838] Loading its data source...
[INFO][14:23:36]: Data source: FEMNIST
[INFO][14:23:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:23:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/838.zip.
[INFO][14:23:36]: [Client #603] Dataset size: 153
[INFO][14:23:36]: [Client #603] Sampler: all_inclusive
[INFO][14:23:36]: [Client #603] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:36]: [93m[1m[Client #603] Started training in communication round #7.[0m
2.6%5.1%7.7%10.3%12.9%15.4%18.0%20.6%23.2%25.7%28.3%30.9%33.5%36.0%38.6%41.2%43.8%46.3%48.9%51.5%54.1%56.6%59.2%61.8%64.4%66.9%69.5%72.1%74.7%77.2%79.8%82.4%85.0%87.5%90.1%92.7%95.3%97.8%100.0%[INFO][14:23:36]: Decompressing the dataset downloaded.
[INFO][14:23:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/838.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:23:36]: [Client #838] Dataset size: 164
[INFO][14:23:36]: [Client #838] Sampler: all_inclusive
[INFO][14:23:36]: [Client #838] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:36]: [93m[1m[Client #838] Started training in communication round #7.[0m

[INFO][14:23:38]: [Client #603] Loading the dataset.
[INFO][14:23:38]: [Client #838] Loading the dataset.
[INFO][14:23:43]: [Client #603] Epoch: [1/5][0/16]	Loss: 1.574426
[INFO][14:23:43]: [Client #838] Epoch: [1/5][0/17]	Loss: 1.624670
[INFO][14:23:43]: [Client #838] Epoch: [1/5][10/17]	Loss: 1.433073
[INFO][14:23:43]: [Client #603] Epoch: [1/5][10/16]	Loss: 1.983814
[INFO][14:23:43]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:23:43]: [Client #838] Going to sleep for 0.86 seconds.
[INFO][14:23:43]: [Client #603] Woke up.
[INFO][14:23:43]: [Client #603] Epoch: [2/5][0/16]	Loss: 1.845900
[INFO][14:23:43]: [Client #603] Epoch: [2/5][10/16]	Loss: 2.153451
[INFO][14:23:44]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:23:44]: [Client #603] Woke up.
[INFO][14:23:44]: [Client #603] Epoch: [3/5][0/16]	Loss: 1.917631
[INFO][14:23:44]: [Client #603] Epoch: [3/5][10/16]	Loss: 1.910435
[INFO][14:23:44]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:23:44]: [Client #603] Woke up.
[INFO][14:23:44]: [Client #603] Epoch: [4/5][0/16]	Loss: 1.958277
[INFO][14:23:44]: [Client #603] Epoch: [4/5][10/16]	Loss: 1.032236
[INFO][14:23:44]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:23:44]: [Client #603] Woke up.
[INFO][14:23:44]: [Client #603] Epoch: [5/5][0/16]	Loss: 1.823884
[INFO][14:23:44]: [Client #838] Woke up.
[INFO][14:23:44]: [Client #603] Epoch: [5/5][10/16]	Loss: 2.487615
[INFO][14:23:44]: [Client #838] Epoch: [2/5][0/17]	Loss: 1.391652
[INFO][14:23:44]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][14:23:44]: [Client #838] Epoch: [2/5][10/17]	Loss: 2.808629
[INFO][14:23:44]: [Client #603] Woke up.
[INFO][14:23:44]: [Client #603] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615874.pth.
[INFO][14:23:44]: [Client #838] Going to sleep for 0.86 seconds.
[INFO][14:23:45]: [Client #603] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615874.pth.
[INFO][14:23:45]: [Client #603] Model trained.
[INFO][14:23:45]: [Client #603] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:45]: [Server #615782] Received 0.26 MB of payload data from client #603 (simulated).
[INFO][14:23:45]: [Client #838] Woke up.
[INFO][14:23:45]: [Client #838] Epoch: [3/5][0/17]	Loss: 2.488416
[INFO][14:23:45]: [Client #838] Epoch: [3/5][10/17]	Loss: 0.846489
[INFO][14:23:45]: [Client #838] Going to sleep for 0.86 seconds.
[INFO][14:23:46]: [Client #838] Woke up.
[INFO][14:23:46]: [Client #838] Epoch: [4/5][0/17]	Loss: 1.180503
[INFO][14:23:46]: [Client #838] Epoch: [4/5][10/17]	Loss: 2.463759
[INFO][14:23:46]: [Client #838] Going to sleep for 0.86 seconds.
[INFO][14:23:47]: [Client #838] Woke up.
[INFO][14:23:47]: [Client #838] Epoch: [5/5][0/17]	Loss: 1.335658
[INFO][14:23:47]: [Client #838] Epoch: [5/5][10/17]	Loss: 1.692044
[INFO][14:23:47]: [Client #838] Going to sleep for 0.86 seconds.
[INFO][14:23:48]: [Client #838] Woke up.
[INFO][14:23:48]: [Client #838] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_838_615875.pth.
[INFO][14:23:49]: [Client #838] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_838_615875.pth.
[INFO][14:23:49]: [Client #838] Model trained.
[INFO][14:23:49]: [Client #838] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:23:49]: [Server #615782] Received 0.26 MB of payload data from client #838 (simulated).
[INFO][14:23:49]: [Server #615782] Selecting client #899 for training.
[INFO][14:23:49]: [Server #615782] Sending the current model to client #899 (simulated).
[INFO][14:23:49]: [Server #615782] Sending 0.26 MB of payload data to client #899 (simulated).
[INFO][14:23:49]: [Server #615782] Selecting client #974 for training.
[INFO][14:23:49]: [Server #615782] Sending the current model to client #974 (simulated).
[INFO][14:23:49]: [Server #615782] Sending 0.26 MB of payload data to client #974 (simulated).
[INFO][14:23:49]: [Client #974] Selected by the server.
[INFO][14:23:49]: [Client #899] Selected by the server.
[INFO][14:23:49]: [Client #974] Loading its data source...
[INFO][14:23:49]: Data source: FEMNIST
[INFO][14:23:49]: [Client #899] Loading its data source...
[INFO][14:23:49]: Data source: FEMNIST
[INFO][14:23:49]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:23:49]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/899.zip.
[INFO][14:23:49]: [Client #974] Dataset size: 158
[INFO][14:23:49]: [Client #974] Sampler: all_inclusive
[INFO][14:23:49]: [Client #974] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:49]: [93m[1m[Client #974] Started training in communication round #7.[0m
2.4%4.7%7.1%9.4%11.8%14.2%16.5%18.9%21.2%23.6%25.9%28.3%30.7%33.0%35.4%37.7%40.1%42.5%44.8%47.2%49.5%51.9%54.3%56.6%59.0%61.3%63.7%66.0%68.4%70.8%73.1%75.5%77.8%80.2%82.6%84.9%87.3%89.6%92.0%94.4%96.7%99.1%100.0%[INFO][14:23:49]: Decompressing the dataset downloaded.
[INFO][14:23:49]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/899.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:23:49]: [Client #899] Dataset size: 153
[INFO][14:23:49]: [Client #899] Sampler: all_inclusive
[INFO][14:23:49]: [Client #899] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:23:49]: [93m[1m[Client #899] Started training in communication round #7.[0m

[INFO][14:23:51]: [Client #974] Loading the dataset.
[INFO][14:23:51]: [Client #899] Loading the dataset.
[INFO][14:23:56]: [Client #974] Epoch: [1/5][0/16]	Loss: 1.918521
[INFO][14:23:56]: [Client #974] Epoch: [1/5][10/16]	Loss: 1.694330
[INFO][14:23:56]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][14:23:56]: [Client #899] Epoch: [1/5][0/16]	Loss: 2.247169
[INFO][14:23:57]: [Client #899] Epoch: [1/5][10/16]	Loss: 2.067553
[INFO][14:23:57]: [Client #899] Going to sleep for 8.02 seconds.
[INFO][14:24:04]: [Client #974] Woke up.
[INFO][14:24:04]: [Client #974] Epoch: [2/5][0/16]	Loss: 1.658328
[INFO][14:24:04]: [Client #974] Epoch: [2/5][10/16]	Loss: 2.246129
[INFO][14:24:04]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][14:24:05]: [Client #899] Woke up.
[INFO][14:24:05]: [Client #899] Epoch: [2/5][0/16]	Loss: 0.968571
[INFO][14:24:05]: [Client #899] Epoch: [2/5][10/16]	Loss: 1.790544
[INFO][14:24:05]: [Client #899] Going to sleep for 8.02 seconds.
[INFO][14:24:11]: [Client #974] Woke up.
[INFO][14:24:11]: [Client #974] Epoch: [3/5][0/16]	Loss: 0.846610
[INFO][14:24:11]: [Client #974] Epoch: [3/5][10/16]	Loss: 2.533517
[INFO][14:24:11]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][14:24:13]: [Client #899] Woke up.
[INFO][14:24:13]: [Client #899] Epoch: [3/5][0/16]	Loss: 1.056772
[INFO][14:24:13]: [Client #899] Epoch: [3/5][10/16]	Loss: 2.297308
[INFO][14:24:13]: [Client #899] Going to sleep for 8.02 seconds.
[INFO][14:24:18]: [Client #974] Woke up.
[INFO][14:24:18]: [Client #974] Epoch: [4/5][0/16]	Loss: 1.005416
[INFO][14:24:18]: [Client #974] Epoch: [4/5][10/16]	Loss: 2.459000
[INFO][14:24:18]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][14:24:21]: [Client #899] Woke up.
[INFO][14:24:21]: [Client #899] Epoch: [4/5][0/16]	Loss: 1.422567
[INFO][14:24:21]: [Client #899] Epoch: [4/5][10/16]	Loss: 1.695785
[INFO][14:24:21]: [Client #899] Going to sleep for 8.02 seconds.
[INFO][14:24:25]: [Client #974] Woke up.
[INFO][14:24:25]: [Client #974] Epoch: [5/5][0/16]	Loss: 1.951702
[INFO][14:24:26]: [Client #974] Epoch: [5/5][10/16]	Loss: 2.086066
[INFO][14:24:26]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][14:24:29]: [Client #899] Woke up.
[INFO][14:24:29]: [Client #899] Epoch: [5/5][0/16]	Loss: 1.783792
[INFO][14:24:29]: [Client #899] Epoch: [5/5][10/16]	Loss: 1.476135
[INFO][14:24:29]: [Client #899] Going to sleep for 8.02 seconds.
[INFO][14:24:33]: [Client #974] Woke up.
[INFO][14:24:33]: [Client #974] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][14:24:33]: [Client #974] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][14:24:33]: [Client #974] Model trained.
[INFO][14:24:33]: [Client #974] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:24:33]: [Server #615782] Received 0.26 MB of payload data from client #974 (simulated).
[INFO][14:24:37]: [Client #899] Woke up.
[INFO][14:24:37]: [Client #899] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_899_615874.pth.
[INFO][14:24:38]: [Client #899] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_899_615874.pth.
[INFO][14:24:38]: [Client #899] Model trained.
[INFO][14:24:38]: [Client #899] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:24:38]: [Server #615782] Received 0.26 MB of payload data from client #899 (simulated).
[INFO][14:24:38]: [Server #615782] Selecting client #999 for training.
[INFO][14:24:38]: [Server #615782] Sending the current model to client #999 (simulated).
[INFO][14:24:38]: [Server #615782] Sending 0.26 MB of payload data to client #999 (simulated).
[INFO][14:24:38]: [Server #615782] Selecting client #142 for training.
[INFO][14:24:38]: [Server #615782] Sending the current model to client #142 (simulated).
[INFO][14:24:38]: [Server #615782] Sending 0.26 MB of payload data to client #142 (simulated).
[INFO][14:24:38]: [Client #999] Selected by the server.
[INFO][14:24:38]: [Client #999] Loading its data source...
[INFO][14:24:38]: Data source: FEMNIST
[INFO][14:24:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:24:38]: [Client #142] Selected by the server.
[INFO][14:24:38]: [Client #142] Loading its data source...
[INFO][14:24:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/999.zip.
[INFO][14:24:38]: Data source: FEMNIST
[INFO][14:24:38]: [Client #142] Dataset size: 159
[INFO][14:24:38]: [Client #142] Sampler: all_inclusive
[INFO][14:24:38]: [Client #142] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:24:38]: [93m[1m[Client #142] Started training in communication round #7.[0m
3.8%7.5%11.3%15.1%18.9%22.6%26.4%30.2%33.9%37.7%41.5%45.2%49.0%52.8%56.6%60.3%64.1%67.9%71.6%75.4%79.2%82.9%86.7%90.5%94.3%98.0%100.0%[INFO][14:24:38]: Decompressing the dataset downloaded.
[INFO][14:24:38]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/999.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:24:38]: [Client #999] Dataset size: 105
[INFO][14:24:38]: [Client #999] Sampler: all_inclusive
[INFO][14:24:38]: [Client #999] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:24:38]: [93m[1m[Client #999] Started training in communication round #7.[0m

[INFO][14:24:40]: [Client #142] Loading the dataset.
[INFO][14:24:40]: [Client #999] Loading the dataset.
[INFO][14:24:46]: [Client #142] Epoch: [1/5][0/16]	Loss: 2.561644
[INFO][14:24:46]: [Client #999] Epoch: [1/5][0/11]	Loss: 3.254458
[INFO][14:24:46]: [Client #142] Epoch: [1/5][10/16]	Loss: 0.512374
[INFO][14:24:46]: [Client #999] Epoch: [1/5][10/11]	Loss: 3.451415
[INFO][14:24:46]: [Client #999] Going to sleep for 0.48 seconds.
[INFO][14:24:46]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][14:24:46]: [Client #142] Woke up.
[INFO][14:24:46]: [Client #142] Epoch: [2/5][0/16]	Loss: 1.410285
[INFO][14:24:46]: [Client #142] Epoch: [2/5][10/16]	Loss: 1.912650
[INFO][14:24:46]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][14:24:46]: [Client #142] Woke up.
[INFO][14:24:46]: [Client #999] Woke up.
[INFO][14:24:46]: [Client #142] Epoch: [3/5][0/16]	Loss: 1.848168
[INFO][14:24:46]: [Client #999] Epoch: [2/5][0/11]	Loss: 1.500858
[INFO][14:24:46]: [Client #999] Epoch: [2/5][10/11]	Loss: 2.705690
[INFO][14:24:46]: [Client #999] Going to sleep for 0.48 seconds.
[INFO][14:24:46]: [Client #142] Epoch: [3/5][10/16]	Loss: 0.806810
[INFO][14:24:46]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][14:24:46]: [Client #142] Woke up.
[INFO][14:24:46]: [Client #142] Epoch: [4/5][0/16]	Loss: 1.475488
[INFO][14:24:47]: [Client #142] Epoch: [4/5][10/16]	Loss: 1.715649
[INFO][14:24:47]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][14:24:47]: [Client #999] Woke up.
[INFO][14:24:47]: [Client #142] Woke up.
[INFO][14:24:47]: [Client #999] Epoch: [3/5][0/11]	Loss: 1.520823
[INFO][14:24:47]: [Client #142] Epoch: [5/5][0/16]	Loss: 1.193983
[INFO][14:24:47]: [Client #999] Epoch: [3/5][10/11]	Loss: 1.785052
[INFO][14:24:47]: [Client #999] Going to sleep for 0.48 seconds.
[INFO][14:24:47]: [Client #142] Epoch: [5/5][10/16]	Loss: 1.658195
[INFO][14:24:47]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][14:24:47]: [Client #142] Woke up.
[INFO][14:24:47]: [Client #142] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_615875.pth.
[INFO][14:24:47]: [Client #999] Woke up.
[INFO][14:24:47]: [Client #999] Epoch: [4/5][0/11]	Loss: 2.774123
[INFO][14:24:47]: [Client #999] Epoch: [4/5][10/11]	Loss: 2.211993
[INFO][14:24:47]: [Client #999] Going to sleep for 0.48 seconds.
[INFO][14:24:48]: [Client #142] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_615875.pth.
[INFO][14:24:48]: [Client #142] Model trained.
[INFO][14:24:48]: [Client #142] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:24:48]: [Server #615782] Received 0.26 MB of payload data from client #142 (simulated).
[INFO][14:24:48]: [Client #999] Woke up.
[INFO][14:24:48]: [Client #999] Epoch: [5/5][0/11]	Loss: 1.078533
[INFO][14:24:48]: [Client #999] Epoch: [5/5][10/11]	Loss: 1.467635
[INFO][14:24:48]: [Client #999] Going to sleep for 0.48 seconds.
[INFO][14:24:49]: [Client #999] Woke up.
[INFO][14:24:49]: [Client #999] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_999_615874.pth.
[INFO][14:24:49]: [Client #999] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_999_615874.pth.
[INFO][14:24:49]: [Client #999] Model trained.
[INFO][14:24:49]: [Client #999] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:24:49]: [Server #615782] Received 0.26 MB of payload data from client #999 (simulated).
[INFO][14:24:49]: [Server #615782] Selecting client #71 for training.
[INFO][14:24:49]: [Server #615782] Sending the current model to client #71 (simulated).
[INFO][14:24:49]: [Server #615782] Sending 0.26 MB of payload data to client #71 (simulated).
[INFO][14:24:49]: [Client #71] Selected by the server.
[INFO][14:24:49]: [Client #71] Loading its data source...
[INFO][14:24:49]: Data source: FEMNIST
[INFO][14:24:49]: [Client #71] Dataset size: 144
[INFO][14:24:49]: [Client #71] Sampler: all_inclusive
[INFO][14:24:49]: [Client #71] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:24:49]: [93m[1m[Client #71] Started training in communication round #7.[0m
[INFO][14:24:51]: [Client #71] Loading the dataset.
[INFO][14:24:56]: [Client #71] Epoch: [1/5][0/15]	Loss: 1.887046
[INFO][14:24:56]: [Client #71] Epoch: [1/5][10/15]	Loss: 2.000729
[INFO][14:24:56]: [Client #71] Going to sleep for 9.35 seconds.
[INFO][14:25:06]: [Client #71] Woke up.
[INFO][14:25:06]: [Client #71] Epoch: [2/5][0/15]	Loss: 2.440490
[INFO][14:25:06]: [Client #71] Epoch: [2/5][10/15]	Loss: 1.877179
[INFO][14:25:06]: [Client #71] Going to sleep for 9.35 seconds.
[INFO][14:25:15]: [Client #71] Woke up.
[INFO][14:25:15]: [Client #71] Epoch: [3/5][0/15]	Loss: 1.653991
[INFO][14:25:15]: [Client #71] Epoch: [3/5][10/15]	Loss: 2.687451
[INFO][14:25:15]: [Client #71] Going to sleep for 9.35 seconds.
[INFO][14:25:25]: [Client #71] Woke up.
[INFO][14:25:25]: [Client #71] Epoch: [4/5][0/15]	Loss: 0.872853
[INFO][14:25:25]: [Client #71] Epoch: [4/5][10/15]	Loss: 1.246845
[INFO][14:25:25]: [Client #71] Going to sleep for 9.35 seconds.
[INFO][14:25:34]: [Client #71] Woke up.
[INFO][14:25:34]: [Client #71] Epoch: [5/5][0/15]	Loss: 1.653859
[INFO][14:25:34]: [Client #71] Epoch: [5/5][10/15]	Loss: 2.676762
[INFO][14:25:34]: [Client #71] Going to sleep for 9.35 seconds.
[INFO][14:25:44]: [Client #71] Woke up.
[INFO][14:25:44]: [Client #71] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_71_615874.pth.
[INFO][14:25:44]: [Client #71] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_71_615874.pth.
[INFO][14:25:44]: [Client #71] Model trained.
[INFO][14:25:44]: [Client #71] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:25:44]: [Server #615782] Received 0.26 MB of payload data from client #71 (simulated).
[INFO][14:25:44]: [Server #615782] Adding client #140 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #374 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #553 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #534 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #559 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #686 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #684 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #790 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #402 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #413 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #745 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #74 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #603 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #6 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #981 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #73 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #142 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #652 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #934 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #999 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #279 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #922 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #278 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #838 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #538 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #552 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #443 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #787 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #52 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #37 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #772 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #698 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #103 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #769 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #242 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #693 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #453 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #974 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #899 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #108 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #71 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #806 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #730 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #200 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #92 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #342 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #401 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #533 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Adding client #172 to the list of clients for aggregation.
[INFO][14:25:44]: [Server #615782] Aggregating 49 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 687, 688, 689, 690, 691, 692, 694, 695, 696, 697, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 788, 789, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.12040324
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1308193  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13575057 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08859556 0.
 0.09761766 0.06944006 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09939314 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06162981 0.         0.         0.         0.         0.18828969
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07303194 0.         0.08483769 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09182067 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.24619288 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13879731 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11302118 0.09992439 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09930894
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05419763 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15152472 0.05216699
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09104228 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08322626 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11664821 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21945205 0.08904561
 0.         0.         0.         0.11109503 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06829513
 0.07981403 0.         0.         0.         0.         0.
 0.09834617 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08862764 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07948039 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05039048
 0.         0.13569197 0.         0.         0.         0.
 0.         0.         0.08297386 0.         0.         0.
 0.         0.16608674 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.28170745 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06128622 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08028589 0.         0.         0.11733045 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07287027 0.         0.         0.05908995 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08887637 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09858133 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13230049 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.32683515 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14795685 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07326596 0.         0.         0.         0.
 0.         0.         0.15515826 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0737114  0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.12040324
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1308193  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13575057 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08859556 0.
 0.09761766 0.06944006 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09939314 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06162981 0.         0.         0.         0.         0.18828969
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07303194 0.         0.08483769 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09182067 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.24619288 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13879731 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11302118 0.09992439 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09930894
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05419763 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15152472 0.05216699
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09104228 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08322626 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11664821 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21945205 0.08904561
 0.         0.         0.         0.11109503 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06829513
 0.07981403 0.         0.         0.         0.         0.
 0.09834617 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08862764 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07948039 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05039048
 0.         0.13569197 0.         0.         0.         0.
 0.         0.         0.08297386 0.         0.         0.
 0.         0.16608674 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.28170745 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06128622 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08028589 0.         0.         0.11733045 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07287027 0.         0.         0.05908995 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08887637 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09858133 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13230049 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.32683515 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14795685 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07326596 0.         0.         0.         0.
 0.         0.         0.15515826 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0737114  0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02077264 0.02313294 0.001      0.02213337 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.001      0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02064598 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.001
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01633706
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03416149
 0.001      0.04027866 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.001      0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.01849272 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.01879376 0.05656805 0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.001      0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.02077264 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.001      0.0212766  0.001
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.001
 0.001      0.03836988 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.03457885 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.001      0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.001      0.001      0.001      0.001      0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.001      0.0188727  0.001      0.001      0.001      0.001
 0.001      0.001      0.01849272 0.03313609 0.001      0.001
 0.001      0.02013933 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.01874604 0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03621302 0.001      0.001      0.001      0.001      0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01937935 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.001      0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.03614762 0.02184778
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.03739645 0.001      0.001
 0.001      0.001      0.0192851  0.001      0.02141939 0.01925466
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03816987
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02241896 0.03147929 0.001
 0.001      0.001      0.01879376 0.04019211 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][14:26:27]: [Server #615782] Global model accuracy: 39.68%

[INFO][14:26:27]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_7.pth.
[INFO][14:26:27]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_7.pth.
[INFO][14:26:27]: [93m[1m
[Server #615782] Starting round 8/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  1e-04  6e-10  6e-10
 6:  7.5999e+00  7.5998e+00  1e-04  4e-10  4e-10
 7:  7.5999e+00  7.5998e+00  1e-04  7e-09  2e-09
 8:  7.5999e+00  7.5998e+00  1e-04  7e-09  2e-09
 9:  7.5998e+00  7.5998e+00  6e-05  5e-08  1e-08
10:  7.5998e+00  7.5998e+00  5e-05  3e-09  9e-10
11:  7.5998e+00  7.5998e+00  3e-05  1e-08  3e-09
12:  7.5998e+00  7.5998e+00  6e-06  1e-08  2e-09
Optimal solution found.
The calculated probability is:  [5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53354437e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53351279e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53350298e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53363786e-05 5.53370628e-05
 5.53361004e-05 8.22356377e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 1.03724261e-04
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 7.79971304e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 3.94774575e-04
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 8.43403765e-05
 5.53370628e-05 5.53362979e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 9.73218031e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 2.46764131e-01
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 1.56612176e-04 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53350000e-05 5.53361434e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 1.03648575e-04 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 7.43439460e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 1.86635236e-04 7.34035118e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 9.67072977e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53362796e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 1.21884694e-04 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 1.74758461e-03
 9.51653704e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53357839e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53366216e-05 8.86155802e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 1.02791138e-04 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53362898e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53363485e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 7.25999740e-05 5.53370628e-05
 1.50644305e-04 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 9.07560404e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 2.37690874e-04 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 6.94937196e-01 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53369854e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53364531e-05
 5.53370628e-05 5.53370628e-05 5.53356545e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 8.42432082e-05 5.53370628e-05 5.53370628e-05
 7.67098719e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53362855e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53359640e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53353404e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53071885e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53346478e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53364995e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53344070e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53370628e-05 5.53370628e-05 5.53370628e-05
 5.53370628e-05 5.53368110e-05 5.53370628e-05][INFO][14:26:30]: [Server #615782] Selected clients: [200 730 577 950 883 531 382 698 464 591 990 763 342  93 186 533 425 791
 930 179 853 956 958  40  61]
[INFO][14:26:30]: [Server #615782] Selecting client #200 for training.
[INFO][14:26:30]: [Server #615782] Sending the current model to client #200 (simulated).
[INFO][14:26:30]: [Server #615782] Sending 0.26 MB of payload data to client #200 (simulated).
[INFO][14:26:30]: [Server #615782] Selecting client #730 for training.
[INFO][14:26:30]: [Server #615782] Sending the current model to client #730 (simulated).
[INFO][14:26:30]: [Server #615782] Sending 0.26 MB of payload data to client #730 (simulated).
[INFO][14:26:30]: [Client #200] Selected by the server.
[INFO][14:26:30]: [Client #200] Loading its data source...
[INFO][14:26:30]: Data source: FEMNIST
[INFO][14:26:30]: [Client #730] Selected by the server.
[INFO][14:26:30]: [Client #730] Loading its data source...
[INFO][14:26:30]: Data source: FEMNIST
[INFO][14:26:30]: [Client #730] Dataset size: 148
[INFO][14:26:30]: [Client #730] Sampler: all_inclusive
[INFO][14:26:30]: [Client #730] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:26:30]: [93m[1m[Client #730] Started training in communication round #8.[0m
[INFO][14:26:31]: [Client #200] Dataset size: 318
[INFO][14:26:31]: [Client #200] Sampler: all_inclusive
[INFO][14:26:31]: [Client #200] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:26:31]: [93m[1m[Client #200] Started training in communication round #8.[0m
[INFO][14:26:32]: [Client #200] Loading the dataset.
[INFO][14:26:32]: [Client #730] Loading the dataset.
[INFO][14:26:38]: [Client #730] Epoch: [1/5][0/15]	Loss: 2.406153
[INFO][14:26:38]: [Client #200] Epoch: [1/5][0/32]	Loss: 2.361842
[INFO][14:26:38]: [Client #730] Epoch: [1/5][10/15]	Loss: 1.744588
[INFO][14:26:38]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][14:26:38]: [Client #200] Epoch: [1/5][10/32]	Loss: 2.669786
[INFO][14:26:38]: [Client #200] Epoch: [1/5][20/32]	Loss: 1.199849
[INFO][14:26:38]: [Client #200] Epoch: [1/5][30/32]	Loss: 1.448725
[INFO][14:26:38]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][14:26:54]: [Client #730] Woke up.
[INFO][14:26:55]: [Client #730] Epoch: [2/5][0/15]	Loss: 1.513982
[INFO][14:26:55]: [Client #730] Epoch: [2/5][10/15]	Loss: 2.373967
[INFO][14:26:55]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][14:26:57]: [Client #200] Woke up.
[INFO][14:26:57]: [Client #200] Epoch: [2/5][0/32]	Loss: 1.965916
[INFO][14:26:57]: [Client #200] Epoch: [2/5][10/32]	Loss: 1.756990
[INFO][14:26:57]: [Client #200] Epoch: [2/5][20/32]	Loss: 1.331599
[INFO][14:26:57]: [Client #200] Epoch: [2/5][30/32]	Loss: 1.922619
[INFO][14:26:57]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][14:27:11]: [Client #730] Woke up.
[INFO][14:27:11]: [Client #730] Epoch: [3/5][0/15]	Loss: 1.866898
[INFO][14:27:11]: [Client #730] Epoch: [3/5][10/15]	Loss: 2.206942
[INFO][14:27:11]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][14:27:16]: [Client #200] Woke up.
[INFO][14:27:16]: [Client #200] Epoch: [3/5][0/32]	Loss: 1.928402
[INFO][14:27:16]: [Client #200] Epoch: [3/5][10/32]	Loss: 1.794730
[INFO][14:27:16]: [Client #200] Epoch: [3/5][20/32]	Loss: 1.726249
[INFO][14:27:16]: [Client #200] Epoch: [3/5][30/32]	Loss: 1.604684
[INFO][14:27:16]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][14:27:28]: [Client #730] Woke up.
[INFO][14:27:28]: [Client #730] Epoch: [4/5][0/15]	Loss: 1.706574
[INFO][14:27:28]: [Client #730] Epoch: [4/5][10/15]	Loss: 1.951483
[INFO][14:27:28]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][14:27:35]: [Client #200] Woke up.
[INFO][14:27:35]: [Client #200] Epoch: [4/5][0/32]	Loss: 1.598022
[INFO][14:27:35]: [Client #200] Epoch: [4/5][10/32]	Loss: 1.994941
[INFO][14:27:35]: [Client #200] Epoch: [4/5][20/32]	Loss: 1.303453
[INFO][14:27:35]: [Client #200] Epoch: [4/5][30/32]	Loss: 2.328932
[INFO][14:27:35]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][14:27:44]: [Client #730] Woke up.
[INFO][14:27:44]: [Client #730] Epoch: [5/5][0/15]	Loss: 0.799850
[INFO][14:27:44]: [Client #730] Epoch: [5/5][10/15]	Loss: 1.886275
[INFO][14:27:44]: [Client #730] Going to sleep for 16.47 seconds.
[INFO][14:27:54]: [Client #200] Woke up.
[INFO][14:27:54]: [Client #200] Epoch: [5/5][0/32]	Loss: 0.981767
[INFO][14:27:54]: [Client #200] Epoch: [5/5][10/32]	Loss: 1.648044
[INFO][14:27:54]: [Client #200] Epoch: [5/5][20/32]	Loss: 1.161822
[INFO][14:27:54]: [Client #200] Epoch: [5/5][30/32]	Loss: 1.566381
[INFO][14:27:54]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][14:28:01]: [Client #730] Woke up.
[INFO][14:28:01]: [Client #730] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615875.pth.
[INFO][14:28:02]: [Client #730] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_730_615875.pth.
[INFO][14:28:02]: [Client #730] Model trained.
[INFO][14:28:02]: [Client #730] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:28:02]: [Server #615782] Received 0.26 MB of payload data from client #730 (simulated).
[INFO][14:28:12]: [Client #200] Woke up.
[INFO][14:28:13]: [Client #200] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615874.pth.
[INFO][14:28:13]: [Client #200] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615874.pth.
[INFO][14:28:13]: [Client #200] Model trained.
[INFO][14:28:13]: [Client #200] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:28:13]: [Server #615782] Received 0.26 MB of payload data from client #200 (simulated).
[INFO][14:28:13]: [Server #615782] Selecting client #577 for training.
[INFO][14:28:13]: [Server #615782] Sending the current model to client #577 (simulated).
[INFO][14:28:13]: [Server #615782] Sending 0.26 MB of payload data to client #577 (simulated).
[INFO][14:28:13]: [Server #615782] Selecting client #950 for training.
[INFO][14:28:13]: [Server #615782] Sending the current model to client #950 (simulated).
[INFO][14:28:13]: [Server #615782] Sending 0.26 MB of payload data to client #950 (simulated).
[INFO][14:28:13]: [Client #577] Selected by the server.
[INFO][14:28:13]: [Client #577] Loading its data source...
[INFO][14:28:13]: Data source: FEMNIST
[INFO][14:28:13]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:28:13]: [Client #950] Selected by the server.
[INFO][14:28:13]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/577.zip.
[INFO][14:28:13]: [Client #950] Loading its data source...
[INFO][14:28:13]: Data source: FEMNIST
[INFO][14:28:13]: [Client #950] Dataset size: 137
[INFO][14:28:13]: [Client #950] Sampler: all_inclusive
[INFO][14:28:13]: [Client #950] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:28:13]: [93m[1m[Client #950] Started training in communication round #8.[0m
2.5%5.0%7.6%10.1%12.6%15.1%17.6%20.2%22.7%25.2%27.7%30.3%32.8%35.3%37.8%40.3%42.9%45.4%47.9%50.4%52.9%55.5%58.0%60.5%63.0%65.5%68.1%70.6%73.1%75.6%78.2%80.7%83.2%85.7%88.2%90.8%93.3%95.8%98.3%100.0%[INFO][14:28:13]: Decompressing the dataset downloaded.
[INFO][14:28:13]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/577.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:28:14]: [Client #577] Dataset size: 142
[INFO][14:28:14]: [Client #577] Sampler: all_inclusive
[INFO][14:28:14]: [Client #577] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:28:14]: [93m[1m[Client #577] Started training in communication round #8.[0m

[INFO][14:28:15]: [Client #950] Loading the dataset.
[INFO][14:28:15]: [Client #577] Loading the dataset.
[INFO][14:28:21]: [Client #950] Epoch: [1/5][0/14]	Loss: 1.336945
[INFO][14:28:21]: [Client #950] Epoch: [1/5][10/14]	Loss: 1.562185
[INFO][14:28:21]: [Client #577] Epoch: [1/5][0/15]	Loss: 2.515901
[INFO][14:28:21]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][14:28:21]: [Client #577] Epoch: [1/5][10/15]	Loss: 1.450190
[INFO][14:28:21]: [Client #577] Going to sleep for 0.38 seconds.
[INFO][14:28:21]: [Client #577] Woke up.
[INFO][14:28:21]: [Client #577] Epoch: [2/5][0/15]	Loss: 1.645173
[INFO][14:28:21]: [Client #577] Epoch: [2/5][10/15]	Loss: 2.406662
[INFO][14:28:21]: [Client #577] Going to sleep for 0.38 seconds.
[INFO][14:28:22]: [Client #950] Woke up.
[INFO][14:28:22]: [Client #950] Epoch: [2/5][0/14]	Loss: 1.966571
[INFO][14:28:22]: [Client #950] Epoch: [2/5][10/14]	Loss: 2.046638
[INFO][14:28:22]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][14:28:22]: [Client #577] Woke up.
[INFO][14:28:22]: [Client #577] Epoch: [3/5][0/15]	Loss: 0.712081
[INFO][14:28:22]: [Client #577] Epoch: [3/5][10/15]	Loss: 1.987984
[INFO][14:28:22]: [Client #577] Going to sleep for 0.38 seconds.
[INFO][14:28:22]: [Client #950] Woke up.
[INFO][14:28:22]: [Client #950] Epoch: [3/5][0/14]	Loss: 3.503215
[INFO][14:28:22]: [Client #577] Woke up.
[INFO][14:28:22]: [Client #577] Epoch: [4/5][0/15]	Loss: 1.796265
[INFO][14:28:22]: [Client #950] Epoch: [3/5][10/14]	Loss: 1.915334
[INFO][14:28:22]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][14:28:22]: [Client #577] Epoch: [4/5][10/15]	Loss: 1.763662
[INFO][14:28:22]: [Client #577] Going to sleep for 0.38 seconds.
[INFO][14:28:23]: [Client #577] Woke up.
[INFO][14:28:23]: [Client #577] Epoch: [5/5][0/15]	Loss: 1.418692
[INFO][14:28:23]: [Client #577] Epoch: [5/5][10/15]	Loss: 1.132892
[INFO][14:28:23]: [Client #577] Going to sleep for 0.38 seconds.
[INFO][14:28:23]: [Client #950] Woke up.
[INFO][14:28:23]: [Client #950] Epoch: [4/5][0/14]	Loss: 2.098976
[INFO][14:28:23]: [Client #950] Epoch: [4/5][10/14]	Loss: 2.558214
[INFO][14:28:23]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][14:28:23]: [Client #577] Woke up.
[INFO][14:28:23]: [Client #577] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_577_615874.pth.
[INFO][14:28:24]: [Client #950] Woke up.
[INFO][14:28:24]: [Client #950] Epoch: [5/5][0/14]	Loss: 1.353952
[INFO][14:28:24]: [Client #950] Epoch: [5/5][10/14]	Loss: 1.693133
[INFO][14:28:24]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][14:28:24]: [Client #577] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_577_615874.pth.
[INFO][14:28:24]: [Client #577] Model trained.
[INFO][14:28:24]: [Client #577] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:28:24]: [Server #615782] Received 0.26 MB of payload data from client #577 (simulated).
[INFO][14:28:25]: [Client #950] Woke up.
[INFO][14:28:25]: [Client #950] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_950_615875.pth.
[INFO][14:28:25]: [Client #950] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_950_615875.pth.
[INFO][14:28:25]: [Client #950] Model trained.
[INFO][14:28:25]: [Client #950] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:28:25]: [Server #615782] Received 0.26 MB of payload data from client #950 (simulated).
[INFO][14:28:25]: [Server #615782] Selecting client #883 for training.
[INFO][14:28:25]: [Server #615782] Sending the current model to client #883 (simulated).
[INFO][14:28:25]: [Server #615782] Sending 0.26 MB of payload data to client #883 (simulated).
[INFO][14:28:25]: [Server #615782] Selecting client #531 for training.
[INFO][14:28:25]: [Server #615782] Sending the current model to client #531 (simulated).
[INFO][14:28:25]: [Server #615782] Sending 0.26 MB of payload data to client #531 (simulated).
[INFO][14:28:25]: [Client #883] Selected by the server.
[INFO][14:28:25]: [Client #531] Selected by the server.
[INFO][14:28:25]: [Client #883] Loading its data source...
[INFO][14:28:25]: [Client #531] Loading its data source...
[INFO][14:28:25]: Data source: FEMNIST
[INFO][14:28:25]: Data source: FEMNIST
[INFO][14:28:25]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:28:25]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/883.zip.
[INFO][14:28:25]: [Client #531] Dataset size: 162
[INFO][14:28:25]: [Client #531] Sampler: all_inclusive
[INFO][14:28:25]: [Client #531] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:28:25]: [93m[1m[Client #531] Started training in communication round #8.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.1%22.6%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.6%45.1%47.6%50.1%52.6%55.2%57.7%60.2%62.7%65.2%67.7%70.2%72.7%75.2%77.7%80.2%82.7%85.2%87.7%90.2%92.8%95.3%97.8%100.0%[INFO][14:28:26]: Decompressing the dataset downloaded.
[INFO][14:28:26]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/883.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:28:26]: [Client #883] Dataset size: 159
[INFO][14:28:26]: [Client #883] Sampler: all_inclusive
[INFO][14:28:26]: [Client #883] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:28:26]: [93m[1m[Client #883] Started training in communication round #8.[0m

[INFO][14:28:27]: [Client #531] Loading the dataset.
[INFO][14:28:28]: [Client #883] Loading the dataset.
[INFO][14:28:33]: [Client #531] Epoch: [1/5][0/17]	Loss: 2.119424
[INFO][14:28:33]: [Client #883] Epoch: [1/5][0/16]	Loss: 2.679451
[INFO][14:28:33]: [Client #531] Epoch: [1/5][10/17]	Loss: 2.681072
[INFO][14:28:33]: [Client #883] Epoch: [1/5][10/16]	Loss: 1.702691
[INFO][14:28:33]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:28:33]: [Client #883] Going to sleep for 2.95 seconds.
[INFO][14:28:36]: [Client #883] Woke up.
[INFO][14:28:36]: [Client #883] Epoch: [2/5][0/16]	Loss: 2.109433
[INFO][14:28:36]: [Client #883] Epoch: [2/5][10/16]	Loss: 3.043191
[INFO][14:28:36]: [Client #883] Going to sleep for 2.95 seconds.
[INFO][14:28:39]: [Client #883] Woke up.
[INFO][14:28:39]: [Client #883] Epoch: [3/5][0/16]	Loss: 2.393977
[INFO][14:28:39]: [Client #883] Epoch: [3/5][10/16]	Loss: 2.201048
[INFO][14:28:39]: [Client #883] Going to sleep for 2.95 seconds.
[INFO][14:28:42]: [Client #883] Woke up.
[INFO][14:28:42]: [Client #883] Epoch: [4/5][0/16]	Loss: 1.004805
[INFO][14:28:42]: [Client #883] Epoch: [4/5][10/16]	Loss: 1.221505
[INFO][14:28:42]: [Client #883] Going to sleep for 2.95 seconds.
[INFO][14:28:45]: [Client #883] Woke up.
[INFO][14:28:45]: [Client #883] Epoch: [5/5][0/16]	Loss: 1.217372
[INFO][14:28:45]: [Client #883] Epoch: [5/5][10/16]	Loss: 1.433915
[INFO][14:28:46]: [Client #883] Going to sleep for 2.95 seconds.
[INFO][14:28:48]: [Client #883] Woke up.
[INFO][14:28:48]: [Client #883] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_883_615874.pth.
[INFO][14:28:49]: [Client #883] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_883_615874.pth.
[INFO][14:28:49]: [Client #883] Model trained.
[INFO][14:28:49]: [Client #883] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:28:49]: [Server #615782] Received 0.26 MB of payload data from client #883 (simulated).
[INFO][14:29:13]: [Client #531] Woke up.
[INFO][14:29:13]: [Client #531] Epoch: [2/5][0/17]	Loss: 1.915246
[INFO][14:29:13]: [Client #531] Epoch: [2/5][10/17]	Loss: 1.421258
[INFO][14:29:13]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:29:53]: [Client #531] Woke up.
[INFO][14:29:53]: [Client #531] Epoch: [3/5][0/17]	Loss: 2.241424
[INFO][14:29:53]: [Client #531] Epoch: [3/5][10/17]	Loss: 1.416410
[INFO][14:29:53]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:30:32]: [Client #531] Woke up.
[INFO][14:30:33]: [Client #531] Epoch: [4/5][0/17]	Loss: 1.580773
[INFO][14:30:33]: [Client #531] Epoch: [4/5][10/17]	Loss: 1.171216
[INFO][14:30:33]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:31:12]: [Client #531] Woke up.
[INFO][14:31:12]: [Client #531] Epoch: [5/5][0/17]	Loss: 1.874804
[INFO][14:31:12]: [Client #531] Epoch: [5/5][10/17]	Loss: 1.695434
[INFO][14:31:13]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:31:52]: [Client #531] Woke up.
[INFO][14:31:52]: [Client #531] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][14:31:53]: [Client #531] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][14:31:53]: [Client #531] Model trained.
[INFO][14:31:53]: [Client #531] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:31:53]: [Server #615782] Received 0.26 MB of payload data from client #531 (simulated).
[INFO][14:31:53]: [Server #615782] Selecting client #382 for training.
[INFO][14:31:53]: [Server #615782] Sending the current model to client #382 (simulated).
[INFO][14:31:53]: [Server #615782] Sending 0.26 MB of payload data to client #382 (simulated).
[INFO][14:31:53]: [Server #615782] Selecting client #698 for training.
[INFO][14:31:53]: [Server #615782] Sending the current model to client #698 (simulated).
[INFO][14:31:53]: [Server #615782] Sending 0.26 MB of payload data to client #698 (simulated).
[INFO][14:31:53]: [Client #382] Selected by the server.
[INFO][14:31:53]: [Client #698] Selected by the server.
[INFO][14:31:53]: [Client #382] Loading its data source...
[INFO][14:31:53]: [Client #698] Loading its data source...
[INFO][14:31:53]: Data source: FEMNIST
[INFO][14:31:53]: Data source: FEMNIST
[INFO][14:31:53]: [Client #698] Dataset size: 159
[INFO][14:31:53]: [Client #698] Sampler: all_inclusive
[INFO][14:31:53]: [Client #698] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:31:53]: [93m[1m[Client #698] Started training in communication round #8.[0m
[INFO][14:31:53]: [Client #382] Dataset size: 165
[INFO][14:31:53]: [Client #382] Sampler: all_inclusive
[INFO][14:31:53]: [Client #382] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:31:53]: [93m[1m[Client #382] Started training in communication round #8.[0m
[INFO][14:31:55]: [Client #698] Loading the dataset.
[INFO][14:31:55]: [Client #382] Loading the dataset.
[INFO][14:32:01]: [Client #382] Epoch: [1/5][0/17]	Loss: 1.933039
[INFO][14:32:01]: [Client #698] Epoch: [1/5][0/16]	Loss: 2.593333
[INFO][14:32:01]: [Client #382] Epoch: [1/5][10/17]	Loss: 2.678532
[INFO][14:32:01]: [Client #698] Epoch: [1/5][10/16]	Loss: 2.775026
[INFO][14:32:01]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][14:32:01]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:32:02]: [Client #382] Woke up.
[INFO][14:32:02]: [Client #382] Epoch: [2/5][0/17]	Loss: 1.744227
[INFO][14:32:02]: [Client #382] Epoch: [2/5][10/17]	Loss: 1.609374
[INFO][14:32:02]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][14:32:04]: [Client #382] Woke up.
[INFO][14:32:04]: [Client #382] Epoch: [3/5][0/17]	Loss: 1.349460
[INFO][14:32:04]: [Client #382] Epoch: [3/5][10/17]	Loss: 2.508904
[INFO][14:32:04]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][14:32:05]: [Client #382] Woke up.
[INFO][14:32:05]: [Client #382] Epoch: [4/5][0/17]	Loss: 2.101573
[INFO][14:32:05]: [Client #382] Epoch: [4/5][10/17]	Loss: 2.093735
[INFO][14:32:05]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][14:32:07]: [Client #382] Woke up.
[INFO][14:32:07]: [Client #382] Epoch: [5/5][0/17]	Loss: 0.929807
[INFO][14:32:07]: [Client #382] Epoch: [5/5][10/17]	Loss: 1.081891
[INFO][14:32:07]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][14:32:08]: [Client #382] Woke up.
[INFO][14:32:08]: [Client #382] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_382_615874.pth.
[INFO][14:32:08]: [Client #698] Woke up.
[INFO][14:32:08]: [Client #698] Epoch: [2/5][0/16]	Loss: 2.325607
[INFO][14:32:08]: [Client #698] Epoch: [2/5][10/16]	Loss: 2.348206
[INFO][14:32:08]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:32:09]: [Client #382] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_382_615874.pth.
[INFO][14:32:09]: [Client #382] Model trained.
[INFO][14:32:09]: [Client #382] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:32:09]: [Server #615782] Received 0.26 MB of payload data from client #382 (simulated).
[INFO][14:32:16]: [Client #698] Woke up.
[INFO][14:32:16]: [Client #698] Epoch: [3/5][0/16]	Loss: 2.945349
[INFO][14:32:16]: [Client #698] Epoch: [3/5][10/16]	Loss: 1.808560
[INFO][14:32:16]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:32:24]: [Client #698] Woke up.
[INFO][14:32:24]: [Client #698] Epoch: [4/5][0/16]	Loss: 1.881045
[INFO][14:32:24]: [Client #698] Epoch: [4/5][10/16]	Loss: 2.499218
[INFO][14:32:24]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:32:31]: [Client #698] Woke up.
[INFO][14:32:31]: [Client #698] Epoch: [5/5][0/16]	Loss: 1.338407
[INFO][14:32:31]: [Client #698] Epoch: [5/5][10/16]	Loss: 2.045017
[INFO][14:32:32]: [Client #698] Going to sleep for 7.55 seconds.
[INFO][14:32:39]: [Client #698] Woke up.
[INFO][14:32:39]: [Client #698] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615875.pth.
[INFO][14:32:40]: [Client #698] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_698_615875.pth.
[INFO][14:32:40]: [Client #698] Model trained.
[INFO][14:32:40]: [Client #698] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:32:40]: [Server #615782] Received 0.26 MB of payload data from client #698 (simulated).
[INFO][14:32:40]: [Server #615782] Selecting client #464 for training.
[INFO][14:32:40]: [Server #615782] Sending the current model to client #464 (simulated).
[INFO][14:32:40]: [Server #615782] Sending 0.26 MB of payload data to client #464 (simulated).
[INFO][14:32:40]: [Server #615782] Selecting client #591 for training.
[INFO][14:32:40]: [Server #615782] Sending the current model to client #591 (simulated).
[INFO][14:32:40]: [Server #615782] Sending 0.26 MB of payload data to client #591 (simulated).
[INFO][14:32:40]: [Client #464] Selected by the server.
[INFO][14:32:40]: [Client #591] Selected by the server.
[INFO][14:32:40]: [Client #591] Loading its data source...
[INFO][14:32:40]: [Client #464] Loading its data source...
[INFO][14:32:40]: Data source: FEMNIST
[INFO][14:32:40]: Data source: FEMNIST
[INFO][14:32:40]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:32:40]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:32:40]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/591.zip.
[INFO][14:32:40]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/464.zip.
2.2%4.4%6.7%8.9%11.1%13.3%15.5%2.4%4.9%7.3%9.8%12.2%14.6%17.1%19.5%22.0%24.4%26.9%29.3%31.7%34.2%36.6%39.1%41.5%17.8%20.0%22.2%24.4%26.7%28.9%31.1%33.3%35.5%37.8%40.0%42.2%44.4%46.6%48.9%51.1%53.3%55.5%57.7%60.0%62.2%64.4%66.6%68.9%71.1%73.3%75.5%77.7%80.0%82.2%84.4%86.6%88.8%91.1%93.3%95.5%97.7%99.9%100.0%[INFO][14:32:40]: Decompressing the dataset downloaded.
[INFO][14:32:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/591.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
43.9%46.4%48.8%51.3%53.7%56.2%58.6%61.0%63.5%65.9%68.4%70.8%73.2%75.7%78.1%80.6%83.0%85.5%87.9%90.3%92.8%95.2%97.7%100.0%[INFO][14:32:40]: Decompressing the dataset downloaded.
[INFO][14:32:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/464.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:32:40]: [Client #591] Dataset size: 158
[INFO][14:32:40]: [Client #591] Sampler: all_inclusive
[INFO][14:32:40]: [Client #591] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:32:40]: [93m[1m[Client #591] Started training in communication round #8.[0m

[INFO][14:32:40]: [Client #464] Dataset size: 150
[INFO][14:32:40]: [Client #464] Sampler: all_inclusive
[INFO][14:32:40]: [Client #464] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:32:40]: [93m[1m[Client #464] Started training in communication round #8.[0m

[INFO][14:32:42]: [Client #591] Loading the dataset.
[INFO][14:32:42]: [Client #464] Loading the dataset.
[INFO][14:32:48]: [Client #591] Epoch: [1/5][0/16]	Loss: 0.871611
[INFO][14:32:48]: [Client #464] Epoch: [1/5][0/15]	Loss: 1.014641
[INFO][14:32:48]: [Client #591] Epoch: [1/5][10/16]	Loss: 1.206616
[INFO][14:32:48]: [Client #464] Epoch: [1/5][10/15]	Loss: 2.581115
[INFO][14:32:48]: [Client #591] Going to sleep for 0.45 seconds.
[INFO][14:32:48]: [Client #464] Going to sleep for 0.36 seconds.
[INFO][14:32:48]: [Client #464] Woke up.
[INFO][14:32:48]: [Client #464] Epoch: [2/5][0/15]	Loss: 1.968261
[INFO][14:32:48]: [Client #591] Woke up.
[INFO][14:32:48]: [Client #591] Epoch: [2/5][0/16]	Loss: 1.277355
[INFO][14:32:48]: [Client #464] Epoch: [2/5][10/15]	Loss: 1.312243
[INFO][14:32:48]: [Client #464] Going to sleep for 0.36 seconds.
[INFO][14:32:48]: [Client #591] Epoch: [2/5][10/16]	Loss: 0.961797
[INFO][14:32:48]: [Client #591] Going to sleep for 0.45 seconds.
[INFO][14:32:49]: [Client #464] Woke up.
[INFO][14:32:49]: [Client #464] Epoch: [3/5][0/15]	Loss: 1.510987
[INFO][14:32:49]: [Client #464] Epoch: [3/5][10/15]	Loss: 1.997080
[INFO][14:32:49]: [Client #464] Going to sleep for 0.36 seconds.
[INFO][14:32:49]: [Client #591] Woke up.
[INFO][14:32:49]: [Client #591] Epoch: [3/5][0/16]	Loss: 1.492185
[INFO][14:32:49]: [Client #591] Epoch: [3/5][10/16]	Loss: 1.931051
[INFO][14:32:49]: [Client #591] Going to sleep for 0.45 seconds.
[INFO][14:32:49]: [Client #464] Woke up.
[INFO][14:32:49]: [Client #464] Epoch: [4/5][0/15]	Loss: 1.313918
[INFO][14:32:49]: [Client #464] Epoch: [4/5][10/15]	Loss: 1.282494
[INFO][14:32:49]: [Client #464] Going to sleep for 0.36 seconds.
[INFO][14:32:49]: [Client #591] Woke up.
[INFO][14:32:49]: [Client #591] Epoch: [4/5][0/16]	Loss: 1.298725
[INFO][14:32:49]: [Client #591] Epoch: [4/5][10/16]	Loss: 2.035758
[INFO][14:32:49]: [Client #591] Going to sleep for 0.45 seconds.
[INFO][14:32:50]: [Client #464] Woke up.
[INFO][14:32:50]: [Client #464] Epoch: [5/5][0/15]	Loss: 0.988623
[INFO][14:32:50]: [Client #464] Epoch: [5/5][10/15]	Loss: 1.386469
[INFO][14:32:50]: [Client #464] Going to sleep for 0.36 seconds.
[INFO][14:32:50]: [Client #591] Woke up.
[INFO][14:32:50]: [Client #591] Epoch: [5/5][0/16]	Loss: 0.762091
[INFO][14:32:50]: [Client #591] Epoch: [5/5][10/16]	Loss: 1.485775
[INFO][14:32:50]: [Client #464] Woke up.
[INFO][14:32:50]: [Client #591] Going to sleep for 0.45 seconds.
[INFO][14:32:50]: [Client #464] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_464_615874.pth.
[INFO][14:32:51]: [Client #591] Woke up.
[INFO][14:32:51]: [Client #591] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_591_615875.pth.
[INFO][14:32:51]: [Client #464] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_464_615874.pth.
[INFO][14:32:51]: [Client #464] Model trained.
[INFO][14:32:51]: [Client #464] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:32:51]: [Server #615782] Received 0.26 MB of payload data from client #464 (simulated).
[INFO][14:32:51]: [Client #591] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_591_615875.pth.
[INFO][14:32:51]: [Client #591] Model trained.
[INFO][14:32:51]: [Client #591] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:32:51]: [Server #615782] Received 0.26 MB of payload data from client #591 (simulated).
[INFO][14:32:51]: [Server #615782] Selecting client #990 for training.
[INFO][14:32:51]: [Server #615782] Sending the current model to client #990 (simulated).
[INFO][14:32:51]: [Server #615782] Sending 0.26 MB of payload data to client #990 (simulated).
[INFO][14:32:51]: [Server #615782] Selecting client #763 for training.
[INFO][14:32:51]: [Server #615782] Sending the current model to client #763 (simulated).
[INFO][14:32:51]: [Server #615782] Sending 0.26 MB of payload data to client #763 (simulated).
[INFO][14:32:51]: [Client #763] Selected by the server.
[INFO][14:32:51]: [Client #990] Selected by the server.
[INFO][14:32:51]: [Client #763] Loading its data source...
[INFO][14:32:51]: [Client #990] Loading its data source...
[INFO][14:32:51]: Data source: FEMNIST
[INFO][14:32:51]: Data source: FEMNIST
[INFO][14:32:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:32:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/990.zip.
[INFO][14:32:51]: [Client #763] Dataset size: 153
[INFO][14:32:51]: [Client #763] Sampler: all_inclusive
[INFO][14:32:51]: [Client #763] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:32:51]: [93m[1m[Client #763] Started training in communication round #8.[0m
4.6%9.3%13.9%18.6%23.2%27.8%32.5%37.1%41.8%46.4%51.0%55.7%60.3%65.0%69.6%74.2%78.9%83.5%88.2%92.8%97.4%100.0%[INFO][14:32:51]: Decompressing the dataset downloaded.
[INFO][14:32:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/990.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:32:51]: [Client #990] Dataset size: 98
[INFO][14:32:51]: [Client #990] Sampler: all_inclusive
[INFO][14:32:51]: [Client #990] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:32:51]: [93m[1m[Client #990] Started training in communication round #8.[0m

[INFO][14:32:53]: [Client #763] Loading the dataset.
[INFO][14:32:53]: [Client #990] Loading the dataset.
[INFO][14:32:59]: [Client #763] Epoch: [1/5][0/16]	Loss: 3.377478
[INFO][14:32:59]: [Client #763] Epoch: [1/5][10/16]	Loss: 3.239803
[INFO][14:32:59]: [Client #990] Epoch: [1/5][0/10]	Loss: 2.378177
[INFO][14:32:59]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][14:32:59]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][14:33:00]: [Client #763] Woke up.
[INFO][14:33:00]: [Client #763] Epoch: [2/5][0/16]	Loss: 2.163876
[INFO][14:33:00]: [Client #763] Epoch: [2/5][10/16]	Loss: 3.177553
[INFO][14:33:00]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][14:33:00]: [Client #763] Woke up.
[INFO][14:33:00]: [Client #763] Epoch: [3/5][0/16]	Loss: 1.578616
[INFO][14:33:00]: [Client #763] Epoch: [3/5][10/16]	Loss: 2.561410
[INFO][14:33:00]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][14:33:01]: [Client #763] Woke up.
[INFO][14:33:01]: [Client #763] Epoch: [4/5][0/16]	Loss: 1.031523
[INFO][14:33:01]: [Client #763] Epoch: [4/5][10/16]	Loss: 1.731010
[INFO][14:33:01]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][14:33:01]: [Client #763] Woke up.
[INFO][14:33:01]: [Client #763] Epoch: [5/5][0/16]	Loss: 2.068806
[INFO][14:33:01]: [Client #763] Epoch: [5/5][10/16]	Loss: 1.513752
[INFO][14:33:01]: [Client #763] Going to sleep for 0.42 seconds.
[INFO][14:33:02]: [Client #763] Woke up.
[INFO][14:33:02]: [Client #763] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_763_615875.pth.
[INFO][14:33:03]: [Client #763] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_763_615875.pth.
[INFO][14:33:03]: [Client #763] Model trained.
[INFO][14:33:03]: [Client #763] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:33:03]: [Server #615782] Received 0.26 MB of payload data from client #763 (simulated).
[INFO][14:33:19]: [Client #990] Woke up.
[INFO][14:33:19]: [Client #990] Epoch: [2/5][0/10]	Loss: 1.399643
[INFO][14:33:19]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][14:33:38]: [Client #990] Woke up.
[INFO][14:33:38]: [Client #990] Epoch: [3/5][0/10]	Loss: 1.964735
[INFO][14:33:39]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][14:33:58]: [Client #990] Woke up.
[INFO][14:33:58]: [Client #990] Epoch: [4/5][0/10]	Loss: 1.874222
[INFO][14:33:58]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][14:34:18]: [Client #990] Woke up.
[INFO][14:34:18]: [Client #990] Epoch: [5/5][0/10]	Loss: 1.177058
[INFO][14:34:18]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][14:34:37]: [Client #990] Woke up.
[INFO][14:34:37]: [Client #990] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615874.pth.
[INFO][14:34:38]: [Client #990] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615874.pth.
[INFO][14:34:38]: [Client #990] Model trained.
[INFO][14:34:38]: [Client #990] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:34:38]: [Server #615782] Received 0.26 MB of payload data from client #990 (simulated).
[INFO][14:34:38]: [Server #615782] Selecting client #342 for training.
[INFO][14:34:38]: [Server #615782] Sending the current model to client #342 (simulated).
[INFO][14:34:38]: [Server #615782] Sending 0.26 MB of payload data to client #342 (simulated).
[INFO][14:34:38]: [Server #615782] Selecting client #93 for training.
[INFO][14:34:38]: [Server #615782] Sending the current model to client #93 (simulated).
[INFO][14:34:38]: [Server #615782] Sending 0.26 MB of payload data to client #93 (simulated).
[INFO][14:34:38]: [Client #342] Selected by the server.
[INFO][14:34:38]: [Client #342] Loading its data source...
[INFO][14:34:38]: Data source: FEMNIST
[INFO][14:34:38]: [Client #93] Selected by the server.
[INFO][14:34:38]: [Client #93] Loading its data source...
[INFO][14:34:38]: Data source: FEMNIST
[INFO][14:34:38]: [Client #342] Dataset size: 163
[INFO][14:34:38]: [Client #342] Sampler: all_inclusive
[INFO][14:34:38]: [Client #342] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:34:38]: [93m[1m[Client #342] Started training in communication round #8.[0m
[INFO][14:34:38]: [Client #93] Dataset size: 156
[INFO][14:34:38]: [Client #93] Sampler: all_inclusive
[INFO][14:34:38]: [Client #93] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:34:38]: [93m[1m[Client #93] Started training in communication round #8.[0m
[INFO][14:34:40]: [Client #342] Loading the dataset.
[INFO][14:34:40]: [Client #93] Loading the dataset.
[INFO][14:34:46]: [Client #342] Epoch: [1/5][0/17]	Loss: 1.524056
[INFO][14:34:46]: [Client #93] Epoch: [1/5][0/16]	Loss: 1.716990
[INFO][14:34:46]: [Client #342] Epoch: [1/5][10/17]	Loss: 3.150499
[INFO][14:34:46]: [Client #93] Epoch: [1/5][10/16]	Loss: 2.480767
[INFO][14:34:46]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:34:46]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][14:34:47]: [Client #93] Woke up.
[INFO][14:34:47]: [Client #93] Epoch: [2/5][0/16]	Loss: 1.267894
[INFO][14:34:47]: [Client #93] Epoch: [2/5][10/16]	Loss: 1.927822
[INFO][14:34:47]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][14:34:48]: [Client #93] Woke up.
[INFO][14:34:48]: [Client #93] Epoch: [3/5][0/16]	Loss: 0.999771
[INFO][14:34:48]: [Client #93] Epoch: [3/5][10/16]	Loss: 1.628647
[INFO][14:34:48]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][14:34:49]: [Client #93] Woke up.
[INFO][14:34:49]: [Client #93] Epoch: [4/5][0/16]	Loss: 2.209435
[INFO][14:34:49]: [Client #93] Epoch: [4/5][10/16]	Loss: 1.768194
[INFO][14:34:49]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][14:34:50]: [Client #93] Woke up.
[INFO][14:34:50]: [Client #93] Epoch: [5/5][0/16]	Loss: 1.368875
[INFO][14:34:50]: [Client #93] Epoch: [5/5][10/16]	Loss: 1.137773
[INFO][14:34:50]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][14:34:51]: [Client #93] Woke up.
[INFO][14:34:51]: [Client #93] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_615875.pth.
[INFO][14:34:51]: [Client #93] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_615875.pth.
[INFO][14:34:51]: [Client #93] Model trained.
[INFO][14:34:51]: [Client #93] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:34:51]: [Server #615782] Received 0.26 MB of payload data from client #93 (simulated).
[INFO][14:35:05]: [Client #342] Woke up.
[INFO][14:35:05]: [Client #342] Epoch: [2/5][0/17]	Loss: 1.608466
[INFO][14:35:05]: [Client #342] Epoch: [2/5][10/17]	Loss: 3.026531
[INFO][14:35:05]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:35:24]: [Client #342] Woke up.
[INFO][14:35:24]: [Client #342] Epoch: [3/5][0/17]	Loss: 1.922782
[INFO][14:35:24]: [Client #342] Epoch: [3/5][10/17]	Loss: 1.829382
[INFO][14:35:24]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:35:43]: [Client #342] Woke up.
[INFO][14:35:43]: [Client #342] Epoch: [4/5][0/17]	Loss: 0.944291
[INFO][14:35:44]: [Client #342] Epoch: [4/5][10/17]	Loss: 1.588730
[INFO][14:35:44]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:36:03]: [Client #342] Woke up.
[INFO][14:36:03]: [Client #342] Epoch: [5/5][0/17]	Loss: 1.350574
[INFO][14:36:03]: [Client #342] Epoch: [5/5][10/17]	Loss: 2.495863
[INFO][14:36:03]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][14:36:22]: [Client #342] Woke up.
[INFO][14:36:22]: [Client #342] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615874.pth.
[INFO][14:36:22]: [Client #342] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615874.pth.
[INFO][14:36:22]: [Client #342] Model trained.
[INFO][14:36:23]: [Client #342] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:36:23]: [Server #615782] Received 0.26 MB of payload data from client #342 (simulated).
[INFO][14:36:23]: [Server #615782] Selecting client #186 for training.
[INFO][14:36:23]: [Server #615782] Sending the current model to client #186 (simulated).
[INFO][14:36:23]: [Server #615782] Sending 0.26 MB of payload data to client #186 (simulated).
[INFO][14:36:23]: [Server #615782] Selecting client #533 for training.
[INFO][14:36:23]: [Server #615782] Sending the current model to client #533 (simulated).
[INFO][14:36:23]: [Server #615782] Sending 0.26 MB of payload data to client #533 (simulated).
[INFO][14:36:23]: [Client #186] Selected by the server.
[INFO][14:36:23]: [Client #186] Loading its data source...
[INFO][14:36:23]: Data source: FEMNIST
[INFO][14:36:23]: [Client #533] Selected by the server.
[INFO][14:36:23]: [Client #533] Loading its data source...
[INFO][14:36:23]: Data source: FEMNIST
[INFO][14:36:23]: [Client #186] Dataset size: 133
[INFO][14:36:23]: [Client #186] Sampler: all_inclusive
[INFO][14:36:23]: [Client #186] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:36:23]: [93m[1m[Client #186] Started training in communication round #8.[0m
[INFO][14:36:23]: [Client #533] Dataset size: 273
[INFO][14:36:23]: [Client #533] Sampler: all_inclusive
[INFO][14:36:23]: [Client #533] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:36:23]: [93m[1m[Client #533] Started training in communication round #8.[0m
[INFO][14:36:25]: [Client #533] Loading the dataset.
[INFO][14:36:25]: [Client #186] Loading the dataset.
[INFO][14:36:30]: [Client #533] Epoch: [1/5][0/28]	Loss: 2.681333
[INFO][14:36:31]: [Client #186] Epoch: [1/5][0/14]	Loss: 2.952023
[INFO][14:36:31]: [Client #533] Epoch: [1/5][10/28]	Loss: 1.673959
[INFO][14:36:31]: [Client #186] Epoch: [1/5][10/14]	Loss: 2.606627
[INFO][14:36:31]: [Client #533] Epoch: [1/5][20/28]	Loss: 2.728183
[INFO][14:36:31]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][14:36:31]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][14:36:35]: [Client #186] Woke up.
[INFO][14:36:35]: [Client #186] Epoch: [2/5][0/14]	Loss: 0.999727
[INFO][14:36:35]: [Client #186] Epoch: [2/5][10/14]	Loss: 1.701737
[INFO][14:36:35]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][14:36:39]: [Client #186] Woke up.
[INFO][14:36:39]: [Client #186] Epoch: [3/5][0/14]	Loss: 0.956958
[INFO][14:36:39]: [Client #186] Epoch: [3/5][10/14]	Loss: 2.088972
[INFO][14:36:39]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][14:36:43]: [Client #186] Woke up.
[INFO][14:36:43]: [Client #186] Epoch: [4/5][0/14]	Loss: 1.463728
[INFO][14:36:43]: [Client #186] Epoch: [4/5][10/14]	Loss: 2.391644
[INFO][14:36:43]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][14:36:48]: [Client #186] Woke up.
[INFO][14:36:48]: [Client #186] Epoch: [5/5][0/14]	Loss: 1.831103
[INFO][14:36:48]: [Client #186] Epoch: [5/5][10/14]	Loss: 0.989293
[INFO][14:36:48]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][14:36:52]: [Client #186] Woke up.
[INFO][14:36:52]: [Client #186] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615874.pth.
[INFO][14:36:52]: [Client #186] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615874.pth.
[INFO][14:36:52]: [Client #186] Model trained.
[INFO][14:36:52]: [Client #186] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:36:52]: [Server #615782] Received 0.26 MB of payload data from client #186 (simulated).
[INFO][14:37:06]: [Client #533] Woke up.
[INFO][14:37:07]: [Client #533] Epoch: [2/5][0/28]	Loss: 2.200645
[INFO][14:37:07]: [Client #533] Epoch: [2/5][10/28]	Loss: 1.946872
[INFO][14:37:07]: [Client #533] Epoch: [2/5][20/28]	Loss: 2.058769
[INFO][14:37:07]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][14:37:43]: [Client #533] Woke up.
[INFO][14:37:43]: [Client #533] Epoch: [3/5][0/28]	Loss: 0.994332
[INFO][14:37:43]: [Client #533] Epoch: [3/5][10/28]	Loss: 1.262593
[INFO][14:37:43]: [Client #533] Epoch: [3/5][20/28]	Loss: 2.698364
[INFO][14:37:43]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][14:38:19]: [Client #533] Woke up.
[INFO][14:38:19]: [Client #533] Epoch: [4/5][0/28]	Loss: 1.616093
[INFO][14:38:19]: [Client #533] Epoch: [4/5][10/28]	Loss: 2.030512
[INFO][14:38:19]: [Client #533] Epoch: [4/5][20/28]	Loss: 1.875748
[INFO][14:38:19]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][14:38:55]: [Client #533] Woke up.
[INFO][14:38:55]: [Client #533] Epoch: [5/5][0/28]	Loss: 2.523337
[INFO][14:38:55]: [Client #533] Epoch: [5/5][10/28]	Loss: 1.793123
[INFO][14:38:55]: [Client #533] Epoch: [5/5][20/28]	Loss: 1.779451
[INFO][14:38:55]: [Client #533] Going to sleep for 35.75 seconds.
[INFO][14:39:31]: [Client #533] Woke up.
[INFO][14:39:31]: [Client #533] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615875.pth.
[INFO][14:39:32]: [Client #533] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_533_615875.pth.
[INFO][14:39:32]: [Client #533] Model trained.
[INFO][14:39:32]: [Client #533] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:39:32]: [Server #615782] Received 0.26 MB of payload data from client #533 (simulated).
[INFO][14:39:32]: [Server #615782] Selecting client #425 for training.
[INFO][14:39:32]: [Server #615782] Sending the current model to client #425 (simulated).
[INFO][14:39:32]: [Server #615782] Sending 0.26 MB of payload data to client #425 (simulated).
[INFO][14:39:32]: [Server #615782] Selecting client #791 for training.
[INFO][14:39:32]: [Server #615782] Sending the current model to client #791 (simulated).
[INFO][14:39:32]: [Server #615782] Sending 0.26 MB of payload data to client #791 (simulated).
[INFO][14:39:32]: [Client #425] Selected by the server.
[INFO][14:39:32]: [Client #791] Selected by the server.
[INFO][14:39:32]: [Client #791] Loading its data source...
[INFO][14:39:32]: [Client #425] Loading its data source...
[INFO][14:39:32]: Data source: FEMNIST
[INFO][14:39:32]: Data source: FEMNIST
[INFO][14:39:32]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:39:32]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/791.zip.
[INFO][14:39:32]: [Client #425] Dataset size: 152
[INFO][14:39:32]: [Client #425] Sampler: all_inclusive
[INFO][14:39:32]: [Client #425] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:32]: [93m[1m[Client #425] Started training in communication round #8.[0m
2.7%5.3%8.0%10.7%13.3%16.0%18.7%21.3%24.0%26.7%29.3%32.0%34.7%37.3%40.0%42.7%45.3%48.0%50.7%53.3%56.0%58.7%61.3%64.0%66.7%69.3%72.0%74.7%77.3%80.0%82.7%85.3%88.0%90.7%93.3%96.0%98.7%100.0%[INFO][14:39:32]: Decompressing the dataset downloaded.
[INFO][14:39:32]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/791.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:39:32]: [Client #791] Dataset size: 164
[INFO][14:39:32]: [Client #791] Sampler: all_inclusive
[INFO][14:39:32]: [Client #791] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:32]: [93m[1m[Client #791] Started training in communication round #8.[0m

[INFO][14:39:34]: [Client #425] Loading the dataset.
[INFO][14:39:34]: [Client #791] Loading the dataset.
[INFO][14:39:39]: [Client #425] Epoch: [1/5][0/16]	Loss: 1.897233
[INFO][14:39:39]: [Client #425] Epoch: [1/5][10/16]	Loss: 2.397278
[INFO][14:39:39]: [Client #791] Epoch: [1/5][0/17]	Loss: 2.344056
[INFO][14:39:39]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][14:39:39]: [Client #791] Epoch: [1/5][10/17]	Loss: 2.140738
[INFO][14:39:40]: [Client #791] Going to sleep for 0.76 seconds.
[INFO][14:39:40]: [Client #425] Woke up.
[INFO][14:39:40]: [Client #425] Epoch: [2/5][0/16]	Loss: 2.317292
[INFO][14:39:40]: [Client #791] Woke up.
[INFO][14:39:40]: [Client #791] Epoch: [2/5][0/17]	Loss: 1.780362
[INFO][14:39:40]: [Client #425] Epoch: [2/5][10/16]	Loss: 1.392501
[INFO][14:39:40]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][14:39:40]: [Client #791] Epoch: [2/5][10/17]	Loss: 1.144193
[INFO][14:39:40]: [Client #791] Going to sleep for 0.76 seconds.
[INFO][14:39:41]: [Client #791] Woke up.
[INFO][14:39:41]: [Client #791] Epoch: [3/5][0/17]	Loss: 1.177367
[INFO][14:39:41]: [Client #425] Woke up.
[INFO][14:39:41]: [Client #425] Epoch: [3/5][0/16]	Loss: 1.396298
[INFO][14:39:41]: [Client #791] Epoch: [3/5][10/17]	Loss: 2.212618
[INFO][14:39:41]: [Client #425] Epoch: [3/5][10/16]	Loss: 0.660925
[INFO][14:39:41]: [Client #791] Going to sleep for 0.76 seconds.
[INFO][14:39:41]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][14:39:42]: [Client #791] Woke up.
[INFO][14:39:42]: [Client #791] Epoch: [4/5][0/17]	Loss: 1.275099
[INFO][14:39:42]: [Client #791] Epoch: [4/5][10/17]	Loss: 1.239595
[INFO][14:39:42]: [Client #425] Woke up.
[INFO][14:39:42]: [Client #425] Epoch: [4/5][0/16]	Loss: 0.717092
[INFO][14:39:42]: [Client #791] Going to sleep for 0.76 seconds.
[INFO][14:39:42]: [Client #425] Epoch: [4/5][10/16]	Loss: 1.352444
[INFO][14:39:42]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][14:39:43]: [Client #791] Woke up.
[INFO][14:39:43]: [Client #791] Epoch: [5/5][0/17]	Loss: 1.094281
[INFO][14:39:43]: [Client #791] Epoch: [5/5][10/17]	Loss: 2.394206
[INFO][14:39:43]: [Client #791] Going to sleep for 0.76 seconds.
[INFO][14:39:43]: [Client #425] Woke up.
[INFO][14:39:43]: [Client #425] Epoch: [5/5][0/16]	Loss: 2.489186
[INFO][14:39:43]: [Client #425] Epoch: [5/5][10/16]	Loss: 2.192378
[INFO][14:39:43]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][14:39:44]: [Client #791] Woke up.
[INFO][14:39:44]: [Client #791] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_791_615875.pth.
[INFO][14:39:44]: [Client #425] Woke up.
[INFO][14:39:44]: [Client #425] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_425_615874.pth.
[INFO][14:39:45]: [Client #791] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_791_615875.pth.
[INFO][14:39:45]: [Client #791] Model trained.
[INFO][14:39:45]: [Client #791] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:39:45]: [Server #615782] Received 0.26 MB of payload data from client #791 (simulated).
[INFO][14:39:45]: [Client #425] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_425_615874.pth.
[INFO][14:39:45]: [Client #425] Model trained.
[INFO][14:39:45]: [Client #425] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:39:45]: [Server #615782] Received 0.26 MB of payload data from client #425 (simulated).
[INFO][14:39:45]: [Server #615782] Selecting client #930 for training.
[INFO][14:39:45]: [Server #615782] Sending the current model to client #930 (simulated).
[INFO][14:39:45]: [Server #615782] Sending 0.26 MB of payload data to client #930 (simulated).
[INFO][14:39:45]: [Server #615782] Selecting client #179 for training.
[INFO][14:39:45]: [Server #615782] Sending the current model to client #179 (simulated).
[INFO][14:39:45]: [Server #615782] Sending 0.26 MB of payload data to client #179 (simulated).
[INFO][14:39:45]: [Client #930] Selected by the server.
[INFO][14:39:45]: [Client #930] Loading its data source...
[INFO][14:39:45]: Data source: FEMNIST
[INFO][14:39:45]: [Client #179] Selected by the server.
[INFO][14:39:45]: [Client #179] Loading its data source...
[INFO][14:39:45]: Data source: FEMNIST
[INFO][14:39:45]: [Client #930] Dataset size: 151
[INFO][14:39:45]: [Client #930] Sampler: all_inclusive
[INFO][14:39:45]: [Client #930] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:45]: [93m[1m[Client #930] Started training in communication round #8.[0m
[INFO][14:39:45]: [Client #179] Dataset size: 159
[INFO][14:39:45]: [Client #179] Sampler: all_inclusive
[INFO][14:39:45]: [Client #179] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:45]: [93m[1m[Client #179] Started training in communication round #8.[0m
[INFO][14:39:47]: [Client #930] Loading the dataset.
[INFO][14:39:47]: [Client #179] Loading the dataset.
[INFO][14:39:52]: [Client #930] Epoch: [1/5][0/16]	Loss: 2.011258
[INFO][14:39:53]: [Client #930] Epoch: [1/5][10/16]	Loss: 1.679721
[INFO][14:39:53]: [Client #179] Epoch: [1/5][0/16]	Loss: 1.239586
[INFO][14:39:53]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:39:53]: [Client #179] Epoch: [1/5][10/16]	Loss: 1.672604
[INFO][14:39:53]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][14:39:53]: [Client #179] Woke up.
[INFO][14:39:53]: [Client #179] Epoch: [2/5][0/16]	Loss: 1.856988
[INFO][14:39:53]: [Client #179] Epoch: [2/5][10/16]	Loss: 1.884650
[INFO][14:39:53]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][14:39:53]: [Client #930] Woke up.
[INFO][14:39:53]: [Client #179] Woke up.
[INFO][14:39:53]: [Client #930] Epoch: [2/5][0/16]	Loss: 1.078864
[INFO][14:39:53]: [Client #179] Epoch: [3/5][0/16]	Loss: 1.130826
[INFO][14:39:53]: [Client #930] Epoch: [2/5][10/16]	Loss: 2.111603
[INFO][14:39:53]: [Client #179] Epoch: [3/5][10/16]	Loss: 1.033086
[INFO][14:39:53]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:39:53]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][14:39:53]: [Client #179] Woke up.
[INFO][14:39:53]: [Client #179] Epoch: [4/5][0/16]	Loss: 1.928967
[INFO][14:39:53]: [Client #179] Epoch: [4/5][10/16]	Loss: 2.152758
[INFO][14:39:53]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][14:39:53]: [Client #179] Woke up.
[INFO][14:39:53]: [Client #179] Epoch: [5/5][0/16]	Loss: 2.198460
[INFO][14:39:53]: [Client #930] Woke up.
[INFO][14:39:53]: [Client #930] Epoch: [3/5][0/16]	Loss: 0.909422
[INFO][14:39:53]: [Client #179] Epoch: [5/5][10/16]	Loss: 1.796532
[INFO][14:39:54]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][14:39:54]: [Client #930] Epoch: [3/5][10/16]	Loss: 1.662859
[INFO][14:39:54]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:39:54]: [Client #179] Woke up.
[INFO][14:39:54]: [Client #179] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_179_615875.pth.
[INFO][14:39:54]: [Client #930] Woke up.
[INFO][14:39:54]: [Client #930] Epoch: [4/5][0/16]	Loss: 1.652138
[INFO][14:39:54]: [Client #930] Epoch: [4/5][10/16]	Loss: 1.628025
[INFO][14:39:54]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:39:54]: [Client #179] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_179_615875.pth.
[INFO][14:39:54]: [Client #179] Model trained.
[INFO][14:39:54]: [Client #179] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:39:54]: [Server #615782] Received 0.26 MB of payload data from client #179 (simulated).
[INFO][14:39:54]: [Client #930] Woke up.
[INFO][14:39:54]: [Client #930] Epoch: [5/5][0/16]	Loss: 1.397155
[INFO][14:39:55]: [Client #930] Epoch: [5/5][10/16]	Loss: 2.175863
[INFO][14:39:55]: [Client #930] Going to sleep for 0.37 seconds.
[INFO][14:39:55]: [Client #930] Woke up.
[INFO][14:39:55]: [Client #930] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_930_615874.pth.
[INFO][14:39:56]: [Client #930] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_930_615874.pth.
[INFO][14:39:56]: [Client #930] Model trained.
[INFO][14:39:56]: [Client #930] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:39:56]: [Server #615782] Received 0.26 MB of payload data from client #930 (simulated).
[INFO][14:39:56]: [Server #615782] Selecting client #853 for training.
[INFO][14:39:56]: [Server #615782] Sending the current model to client #853 (simulated).
[INFO][14:39:56]: [Server #615782] Sending 0.26 MB of payload data to client #853 (simulated).
[INFO][14:39:56]: [Server #615782] Selecting client #956 for training.
[INFO][14:39:56]: [Server #615782] Sending the current model to client #956 (simulated).
[INFO][14:39:56]: [Server #615782] Sending 0.26 MB of payload data to client #956 (simulated).
[INFO][14:39:56]: [Client #853] Selected by the server.
[INFO][14:39:56]: [Client #853] Loading its data source...
[INFO][14:39:56]: Data source: FEMNIST
[INFO][14:39:56]: [Client #956] Selected by the server.
[INFO][14:39:56]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:39:56]: [Client #956] Loading its data source...
[INFO][14:39:56]: Data source: FEMNIST
[INFO][14:39:56]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/853.zip.
[INFO][14:39:56]: [Client #956] Dataset size: 164
[INFO][14:39:56]: [Client #956] Sampler: all_inclusive
[INFO][14:39:56]: [Client #956] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:56]: [93m[1m[Client #956] Started training in communication round #8.[0m
2.6%5.2%7.8%10.4%13.0%15.6%18.2%20.8%23.4%26.0%28.6%31.2%33.8%36.5%39.1%41.7%44.3%46.9%49.5%52.1%54.7%57.3%59.9%62.5%65.1%67.7%70.3%72.9%75.5%78.1%80.7%83.3%85.9%88.5%91.1%93.7%96.3%98.9%100.0%[INFO][14:39:56]: Decompressing the dataset downloaded.
[INFO][14:39:56]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/853.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:39:56]: [Client #853] Dataset size: 157
[INFO][14:39:56]: [Client #853] Sampler: all_inclusive
[INFO][14:39:56]: [Client #853] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:39:56]: [93m[1m[Client #853] Started training in communication round #8.[0m

[INFO][14:39:58]: [Client #956] Loading the dataset.
[INFO][14:39:58]: [Client #853] Loading the dataset.
[INFO][14:40:03]: [Client #853] Epoch: [1/5][0/16]	Loss: 1.649201
[INFO][14:40:03]: [Client #956] Epoch: [1/5][0/17]	Loss: 2.135065
[INFO][14:40:03]: [Client #853] Epoch: [1/5][10/16]	Loss: 2.082899
[INFO][14:40:03]: [Client #956] Epoch: [1/5][10/17]	Loss: 1.968729
[INFO][14:40:03]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][14:40:03]: [Client #956] Going to sleep for 0.13 seconds.
[INFO][14:40:03]: [Client #956] Woke up.
[INFO][14:40:03]: [Client #956] Epoch: [2/5][0/17]	Loss: 1.428369
[INFO][14:40:04]: [Client #956] Epoch: [2/5][10/17]	Loss: 1.821660
[INFO][14:40:04]: [Client #956] Going to sleep for 0.13 seconds.
[INFO][14:40:04]: [Client #956] Woke up.
[INFO][14:40:04]: [Client #956] Epoch: [3/5][0/17]	Loss: 1.227270
[INFO][14:40:04]: [Client #956] Epoch: [3/5][10/17]	Loss: 3.799147
[INFO][14:40:04]: [Client #956] Going to sleep for 0.13 seconds.
[INFO][14:40:04]: [Client #956] Woke up.
[INFO][14:40:04]: [Client #956] Epoch: [4/5][0/17]	Loss: 1.550392
[INFO][14:40:04]: [Client #956] Epoch: [4/5][10/17]	Loss: 1.851500
[INFO][14:40:04]: [Client #956] Going to sleep for 0.13 seconds.
[INFO][14:40:04]: [Client #956] Woke up.
[INFO][14:40:04]: [Client #956] Epoch: [5/5][0/17]	Loss: 0.959441
[INFO][14:40:04]: [Client #956] Epoch: [5/5][10/17]	Loss: 1.301217
[INFO][14:40:04]: [Client #956] Going to sleep for 0.13 seconds.
[INFO][14:40:05]: [Client #956] Woke up.
[INFO][14:40:05]: [Client #956] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_956_615875.pth.
[INFO][14:40:05]: [Client #853] Woke up.
[INFO][14:40:05]: [Client #853] Epoch: [2/5][0/16]	Loss: 1.996032
[INFO][14:40:05]: [Client #853] Epoch: [2/5][10/16]	Loss: 1.815490
[INFO][14:40:05]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][14:40:05]: [Client #956] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_956_615875.pth.
[INFO][14:40:05]: [Client #956] Model trained.
[INFO][14:40:05]: [Client #956] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:40:05]: [Server #615782] Received 0.26 MB of payload data from client #956 (simulated).
[INFO][14:40:07]: [Client #853] Woke up.
[INFO][14:40:07]: [Client #853] Epoch: [3/5][0/16]	Loss: 2.194814
[INFO][14:40:07]: [Client #853] Epoch: [3/5][10/16]	Loss: 2.168511
[INFO][14:40:07]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][14:40:09]: [Client #853] Woke up.
[INFO][14:40:09]: [Client #853] Epoch: [4/5][0/16]	Loss: 1.167786
[INFO][14:40:09]: [Client #853] Epoch: [4/5][10/16]	Loss: 3.887537
[INFO][14:40:09]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][14:40:11]: [Client #853] Woke up.
[INFO][14:40:11]: [Client #853] Epoch: [5/5][0/16]	Loss: 1.758144
[INFO][14:40:11]: [Client #853] Epoch: [5/5][10/16]	Loss: 2.075890
[INFO][14:40:11]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][14:40:13]: [Client #853] Woke up.
[INFO][14:40:13]: [Client #853] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_853_615874.pth.
[INFO][14:40:13]: [Client #853] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_853_615874.pth.
[INFO][14:40:13]: [Client #853] Model trained.
[INFO][14:40:13]: [Client #853] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:40:13]: [Server #615782] Received 0.26 MB of payload data from client #853 (simulated).
[INFO][14:40:13]: [Server #615782] Selecting client #958 for training.
[INFO][14:40:13]: [Server #615782] Sending the current model to client #958 (simulated).
[INFO][14:40:13]: [Server #615782] Sending 0.26 MB of payload data to client #958 (simulated).
[INFO][14:40:13]: [Server #615782] Selecting client #40 for training.
[INFO][14:40:13]: [Server #615782] Sending the current model to client #40 (simulated).
[INFO][14:40:13]: [Server #615782] Sending 0.26 MB of payload data to client #40 (simulated).
[INFO][14:40:13]: [Client #958] Selected by the server.
[INFO][14:40:13]: [Client #958] Loading its data source...
[INFO][14:40:13]: Data source: FEMNIST
[INFO][14:40:13]: [Client #40] Selected by the server.
[INFO][14:40:13]: [Client #40] Loading its data source...
[INFO][14:40:13]: Data source: FEMNIST
[INFO][14:40:13]: [Client #958] Dataset size: 159
[INFO][14:40:13]: [Client #958] Sampler: all_inclusive
[INFO][14:40:13]: [Client #40] Dataset size: 155
[INFO][14:40:13]: [Client #40] Sampler: all_inclusive
[INFO][14:40:13]: [Client #958] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:40:13]: [Client #40] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:40:13]: [93m[1m[Client #958] Started training in communication round #8.[0m
[INFO][14:40:13]: [93m[1m[Client #40] Started training in communication round #8.[0m
[INFO][14:40:15]: [Client #40] Loading the dataset.
[INFO][14:40:15]: [Client #958] Loading the dataset.
[INFO][14:40:21]: [Client #958] Epoch: [1/5][0/16]	Loss: 1.127224
[INFO][14:40:21]: [Client #40] Epoch: [1/5][0/16]	Loss: 1.391523
[INFO][14:40:21]: [Client #958] Epoch: [1/5][10/16]	Loss: 0.951434
[INFO][14:40:21]: [Client #40] Epoch: [1/5][10/16]	Loss: 0.994211
[INFO][14:40:21]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][14:40:21]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][14:40:22]: [Client #958] Woke up.
[INFO][14:40:22]: [Client #958] Epoch: [2/5][0/16]	Loss: 1.261158
[INFO][14:40:22]: [Client #958] Epoch: [2/5][10/16]	Loss: 2.048394
[INFO][14:40:22]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][14:40:22]: [Client #958] Woke up.
[INFO][14:40:22]: [Client #958] Epoch: [3/5][0/16]	Loss: 1.330670
[INFO][14:40:22]: [Client #958] Epoch: [3/5][10/16]	Loss: 1.805996
[INFO][14:40:23]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][14:40:23]: [Client #958] Woke up.
[INFO][14:40:23]: [Client #958] Epoch: [4/5][0/16]	Loss: 1.482148
[INFO][14:40:23]: [Client #958] Epoch: [4/5][10/16]	Loss: 1.559760
[INFO][14:40:23]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][14:40:24]: [Client #40] Woke up.
[INFO][14:40:24]: [Client #40] Epoch: [2/5][0/16]	Loss: 2.137633
[INFO][14:40:24]: [Client #40] Epoch: [2/5][10/16]	Loss: 1.306407
[INFO][14:40:24]: [Client #958] Woke up.
[INFO][14:40:24]: [Client #958] Epoch: [5/5][0/16]	Loss: 0.940946
[INFO][14:40:24]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][14:40:24]: [Client #958] Epoch: [5/5][10/16]	Loss: 2.210582
[INFO][14:40:24]: [Client #958] Going to sleep for 0.67 seconds.
[INFO][14:40:25]: [Client #958] Woke up.
[INFO][14:40:25]: [Client #958] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_958_615874.pth.
[INFO][14:40:25]: [Client #958] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_958_615874.pth.
[INFO][14:40:25]: [Client #958] Model trained.
[INFO][14:40:25]: [Client #958] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:40:25]: [Server #615782] Received 0.26 MB of payload data from client #958 (simulated).
[INFO][14:40:27]: [Client #40] Woke up.
[INFO][14:40:27]: [Client #40] Epoch: [3/5][0/16]	Loss: 0.803455
[INFO][14:40:27]: [Client #40] Epoch: [3/5][10/16]	Loss: 1.401536
[INFO][14:40:27]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][14:40:30]: [Client #40] Woke up.
[INFO][14:40:30]: [Client #40] Epoch: [4/5][0/16]	Loss: 1.442071
[INFO][14:40:30]: [Client #40] Epoch: [4/5][10/16]	Loss: 2.116431
[INFO][14:40:30]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][14:40:33]: [Client #40] Woke up.
[INFO][14:40:33]: [Client #40] Epoch: [5/5][0/16]	Loss: 0.471125
[INFO][14:40:33]: [Client #40] Epoch: [5/5][10/16]	Loss: 1.397702
[INFO][14:40:33]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][14:40:36]: [Client #40] Woke up.
[INFO][14:40:36]: [Client #40] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615875.pth.
[INFO][14:40:37]: [Client #40] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615875.pth.
[INFO][14:40:37]: [Client #40] Model trained.
[INFO][14:40:37]: [Client #40] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:40:37]: [Server #615782] Received 0.26 MB of payload data from client #40 (simulated).
[INFO][14:40:37]: [Server #615782] Selecting client #61 for training.
[INFO][14:40:37]: [Server #615782] Sending the current model to client #61 (simulated).
[INFO][14:40:37]: [Server #615782] Sending 0.26 MB of payload data to client #61 (simulated).
[INFO][14:40:37]: [Client #61] Selected by the server.
[INFO][14:40:37]: [Client #61] Loading its data source...
[INFO][14:40:37]: Data source: FEMNIST
[INFO][14:40:37]: [Client #61] Dataset size: 153
[INFO][14:40:37]: [Client #61] Sampler: all_inclusive
[INFO][14:40:37]: [Client #61] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:40:37]: [93m[1m[Client #61] Started training in communication round #8.[0m
[INFO][14:40:39]: [Client #61] Loading the dataset.
[INFO][14:40:44]: [Client #61] Epoch: [1/5][0/16]	Loss: 0.859349
[INFO][14:40:44]: [Client #61] Epoch: [1/5][10/16]	Loss: 1.504253
[INFO][14:40:44]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][14:40:45]: [Client #61] Woke up.
[INFO][14:40:45]: [Client #61] Epoch: [2/5][0/16]	Loss: 1.239022
[INFO][14:40:45]: [Client #61] Epoch: [2/5][10/16]	Loss: 2.765566
[INFO][14:40:45]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][14:40:45]: [Client #61] Woke up.
[INFO][14:40:45]: [Client #61] Epoch: [3/5][0/16]	Loss: 1.552097
[INFO][14:40:45]: [Client #61] Epoch: [3/5][10/16]	Loss: 1.656533
[INFO][14:40:45]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][14:40:45]: [Client #61] Woke up.
[INFO][14:40:45]: [Client #61] Epoch: [4/5][0/16]	Loss: 1.960833
[INFO][14:40:45]: [Client #61] Epoch: [4/5][10/16]	Loss: 0.895063
[INFO][14:40:45]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][14:40:45]: [Client #61] Woke up.
[INFO][14:40:45]: [Client #61] Epoch: [5/5][0/16]	Loss: 1.027900
[INFO][14:40:45]: [Client #61] Epoch: [5/5][10/16]	Loss: 0.937373
[INFO][14:40:46]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][14:40:46]: [Client #61] Woke up.
[INFO][14:40:46]: [Client #61] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_61_615874.pth.
[INFO][14:40:47]: [Client #61] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_61_615874.pth.
[INFO][14:40:47]: [Client #61] Model trained.
[INFO][14:40:47]: [Client #61] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:40:47]: [Server #615782] Received 0.26 MB of payload data from client #61 (simulated).
[INFO][14:40:47]: [Server #615782] Adding client #179 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #61 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #956 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #577 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #930 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #464 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #591 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #763 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #950 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #958 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #791 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #93 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #425 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #382 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #853 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #520 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #883 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #40 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #186 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #698 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #730 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #200 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #342 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #990 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Adding client #533 to the list of clients for aggregation.
[INFO][14:40:47]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07913288 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10395982 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11411065 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09958694 0.
 0.         0.         0.         0.         0.         0.12115819
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26269649 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12804492
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16293534 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1131138  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09528111 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12484945 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17589284 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15785559 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08344764 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19571781 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.22059149 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.17880239 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11474113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14427388 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07389607 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.38799367
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07854896 0.         0.         0.         0.
 0.         0.10468418 0.         0.08713419 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06146976
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07913288 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10395982 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11411065 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09958694 0.
 0.         0.         0.         0.         0.         0.12115819
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26269649 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12804492
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16293534 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1131138  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09528111 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12484945 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17589284 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15785559 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08344764 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19571781 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.22059149 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.17880239 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11474113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14427388 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07389607 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.38799367
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07854896 0.         0.         0.         0.
 0.         0.10468418 0.         0.08713419 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06146976
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.001      0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.001
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.03750919 0.001      0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.001
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.001      0.03898014 0.001
 0.001      0.001      0.001      0.001      0.001      0.03260603
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03416149
 0.001      0.07796028 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.0591716  0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.001      0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.01849272 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.03996077
 0.001      0.01879376 0.05656805 0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.02077264 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.001      0.0212766  0.001
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.001      0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.001
 0.001      0.03836988 0.001      0.03750919 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.001      0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.001      0.001      0.001      0.001      0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.001      0.0188727  0.001      0.001      0.001      0.001
 0.001      0.001      0.01849272 0.03313609 0.001      0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.001      0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01937935 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03848983 0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.03614762 0.02184778
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.03739645 0.001      0.001
 0.001      0.001      0.0192851  0.001      0.02141939 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.0240255
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][14:41:30]: [Server #615782] Global model accuracy: 44.45%

[INFO][14:41:30]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_8.pth.
[INFO][14:41:30]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_8.pth.
[INFO][14:41:30]: [93m[1m
[Server #615782] Starting round 9/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  7e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  6e-05  4e-09  5e-10
 8:  7.5999e+00  7.5998e+00  4e-05  3e-09  4e-10
 9:  7.5999e+00  7.5998e+00  3e-05  7e-09  9e-10
10:  7.5998e+00  7.5998e+00  5e-06  2e-08  2e-09
Optimal solution found.
The calculated probability is:  [9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39358454e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39294896e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39255305e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39296303e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39290765e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.35144504e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39181738e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39003854e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39268489e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39325096e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.06244000e-01
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.38024366e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39140325e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39343956e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.38851742e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.38791401e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.38987983e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39232244e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39133750e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39366136e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.37328452e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39379925e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39269023e-05 9.39451709e-05
 9.39332734e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39429213e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05 9.39451709e-05
 9.39451709e-05 9.39451709e-05 9.39451709e-05][INFO][14:41:32]: [Server #615782] Selected clients: [ 62 520 695 881 633 211 345 161 444  85 166 198 692 575 874 245 631  35
 516 864 985  10 253 224  48]
[INFO][14:41:32]: [Server #615782] Selecting client #62 for training.
[INFO][14:41:32]: [Server #615782] Sending the current model to client #62 (simulated).
[INFO][14:41:32]: [Server #615782] Sending 0.26 MB of payload data to client #62 (simulated).
[INFO][14:41:32]: [Server #615782] Selecting client #520 for training.
[INFO][14:41:32]: [Server #615782] Sending the current model to client #520 (simulated).
[INFO][14:41:32]: [Server #615782] Sending 0.26 MB of payload data to client #520 (simulated).
[INFO][14:41:32]: [Client #62] Selected by the server.
[INFO][14:41:32]: [Client #62] Loading its data source...
[INFO][14:41:32]: Data source: FEMNIST
[INFO][14:41:32]: [Client #520] Selected by the server.
[INFO][14:41:32]: [Client #520] Loading its data source...
[INFO][14:41:32]: Data source: FEMNIST
[INFO][14:41:32]: [Client #520] Dataset size: 153
[INFO][14:41:32]: [Client #520] Sampler: all_inclusive
[INFO][14:41:32]: [Client #520] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:41:32]: [Client #62] Dataset size: 156
[INFO][14:41:32]: [Client #62] Sampler: all_inclusive
[INFO][14:41:32]: [93m[1m[Client #520] Started training in communication round #9.[0m
[INFO][14:41:32]: [Client #62] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:41:32]: [93m[1m[Client #62] Started training in communication round #9.[0m
[INFO][14:41:34]: [Client #62] Loading the dataset.
[INFO][14:41:34]: [Client #520] Loading the dataset.
[INFO][14:41:40]: [Client #520] Epoch: [1/5][0/16]	Loss: 1.803334
[INFO][14:41:40]: [Client #62] Epoch: [1/5][0/16]	Loss: 1.271680
[INFO][14:41:40]: [Client #520] Epoch: [1/5][10/16]	Loss: 0.986398
[INFO][14:41:40]: [Client #62] Epoch: [1/5][10/16]	Loss: 3.570436
[INFO][14:41:40]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:41:40]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][14:41:41]: [Client #62] Woke up.
[INFO][14:41:41]: [Client #62] Epoch: [2/5][0/16]	Loss: 1.502138
[INFO][14:41:41]: [Client #62] Epoch: [2/5][10/16]	Loss: 2.347891
[INFO][14:41:41]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][14:41:41]: [Client #62] Woke up.
[INFO][14:41:41]: [Client #62] Epoch: [3/5][0/16]	Loss: 2.059466
[INFO][14:41:42]: [Client #62] Epoch: [3/5][10/16]	Loss: 1.272894
[INFO][14:41:42]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][14:41:42]: [Client #62] Woke up.
[INFO][14:41:42]: [Client #62] Epoch: [4/5][0/16]	Loss: 1.402989
[INFO][14:41:42]: [Client #62] Epoch: [4/5][10/16]	Loss: 2.169681
[INFO][14:41:42]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][14:41:43]: [Client #62] Woke up.
[INFO][14:41:43]: [Client #62] Epoch: [5/5][0/16]	Loss: 1.476620
[INFO][14:41:43]: [Client #62] Epoch: [5/5][10/16]	Loss: 1.699425
[INFO][14:41:43]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][14:41:44]: [Client #62] Woke up.
[INFO][14:41:44]: [Client #62] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_62_615874.pth.
[INFO][14:41:45]: [Client #62] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_62_615874.pth.
[INFO][14:41:45]: [Client #62] Model trained.
[INFO][14:41:45]: [Client #62] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:41:45]: [Server #615782] Received 0.26 MB of payload data from client #62 (simulated).
[INFO][14:42:40]: [Client #520] Woke up.
[INFO][14:42:40]: [Client #520] Epoch: [2/5][0/16]	Loss: 1.457156
[INFO][14:42:40]: [Client #520] Epoch: [2/5][10/16]	Loss: 1.417565
[INFO][14:42:40]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:43:40]: [Client #520] Woke up.
[INFO][14:43:40]: [Client #520] Epoch: [3/5][0/16]	Loss: 1.592410
[INFO][14:43:40]: [Client #520] Epoch: [3/5][10/16]	Loss: 1.589964
[INFO][14:43:40]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:44:40]: [Client #520] Woke up.
[INFO][14:44:41]: [Client #520] Epoch: [4/5][0/16]	Loss: 0.882191
[INFO][14:44:41]: [Client #520] Epoch: [4/5][10/16]	Loss: 1.861606
[INFO][14:44:41]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:45:41]: [Client #520] Woke up.
[INFO][14:45:41]: [Client #520] Epoch: [5/5][0/16]	Loss: 1.302251
[INFO][14:45:41]: [Client #520] Epoch: [5/5][10/16]	Loss: 1.227745
[INFO][14:45:41]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][14:46:41]: [Client #520] Woke up.
[INFO][14:46:41]: [Client #520] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615875.pth.
[INFO][14:46:42]: [Client #520] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615875.pth.
[INFO][14:46:42]: [Client #520] Model trained.
[INFO][14:46:42]: [Client #520] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:46:42]: [Server #615782] Received 0.26 MB of payload data from client #520 (simulated).
[INFO][14:46:42]: [Server #615782] Selecting client #695 for training.
[INFO][14:46:42]: [Server #615782] Sending the current model to client #695 (simulated).
[INFO][14:46:42]: [Server #615782] Sending 0.26 MB of payload data to client #695 (simulated).
[INFO][14:46:42]: [Server #615782] Selecting client #881 for training.
[INFO][14:46:42]: [Server #615782] Sending the current model to client #881 (simulated).
[INFO][14:46:42]: [Server #615782] Sending 0.26 MB of payload data to client #881 (simulated).
[INFO][14:46:42]: [Client #695] Selected by the server.
[INFO][14:46:42]: [Client #881] Selected by the server.
[INFO][14:46:42]: [Client #695] Loading its data source...
[INFO][14:46:42]: [Client #881] Loading its data source...
[INFO][14:46:42]: Data source: FEMNIST
[INFO][14:46:42]: Data source: FEMNIST
[INFO][14:46:42]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:46:42]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/695.zip.
[INFO][14:46:42]: [Client #881] Dataset size: 150
[INFO][14:46:42]: [Client #881] Sampler: all_inclusive
[INFO][14:46:42]: [Client #881] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:46:42]: [93m[1m[Client #881] Started training in communication round #9.[0m
2.6%5.1%7.7%10.3%12.8%15.4%18.0%20.5%23.1%25.7%28.2%30.8%33.4%35.9%38.5%41.1%43.6%46.2%48.8%51.3%53.9%56.5%59.0%61.6%64.2%66.7%69.3%71.9%74.4%77.0%79.6%82.1%84.7%87.3%89.8%92.4%95.0%97.5%100.0%[INFO][14:46:42]: Decompressing the dataset downloaded.
[INFO][14:46:42]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/695.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:46:42]: [Client #695] Dataset size: 155
[INFO][14:46:42]: [Client #695] Sampler: all_inclusive
[INFO][14:46:42]: [Client #695] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:46:42]: [93m[1m[Client #695] Started training in communication round #9.[0m

[INFO][14:46:44]: [Client #881] Loading the dataset.
[INFO][14:46:44]: [Client #695] Loading the dataset.
[INFO][14:46:49]: [Client #695] Epoch: [1/5][0/16]	Loss: 1.333508
[INFO][14:46:49]: [Client #881] Epoch: [1/5][0/15]	Loss: 2.164361
[INFO][14:46:49]: [Client #695] Epoch: [1/5][10/16]	Loss: 0.649469
[INFO][14:46:49]: [Client #881] Epoch: [1/5][10/15]	Loss: 0.983846
[INFO][14:46:49]: [Client #695] Going to sleep for 0.14 seconds.
[INFO][14:46:49]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][14:46:50]: [Client #695] Woke up.
[INFO][14:46:50]: [Client #695] Epoch: [2/5][0/16]	Loss: 0.802356
[INFO][14:46:50]: [Client #695] Epoch: [2/5][10/16]	Loss: 0.999595
[INFO][14:46:50]: [Client #695] Going to sleep for 0.14 seconds.
[INFO][14:46:50]: [Client #695] Woke up.
[INFO][14:46:50]: [Client #695] Epoch: [3/5][0/16]	Loss: 1.204912
[INFO][14:46:50]: [Client #695] Epoch: [3/5][10/16]	Loss: 1.200150
[INFO][14:46:50]: [Client #695] Going to sleep for 0.14 seconds.
[INFO][14:46:50]: [Client #881] Woke up.
[INFO][14:46:50]: [Client #881] Epoch: [2/5][0/15]	Loss: 1.486473
[INFO][14:46:50]: [Client #695] Woke up.
[INFO][14:46:50]: [Client #695] Epoch: [4/5][0/16]	Loss: 0.547338
[INFO][14:46:50]: [Client #881] Epoch: [2/5][10/15]	Loss: 0.993775
[INFO][14:46:50]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][14:46:50]: [Client #695] Epoch: [4/5][10/16]	Loss: 2.402390
[INFO][14:46:50]: [Client #695] Going to sleep for 0.14 seconds.
[INFO][14:46:50]: [Client #695] Woke up.
[INFO][14:46:50]: [Client #695] Epoch: [5/5][0/16]	Loss: 2.495614
[INFO][14:46:51]: [Client #695] Epoch: [5/5][10/16]	Loss: 2.518019
[INFO][14:46:51]: [Client #695] Going to sleep for 0.14 seconds.
[INFO][14:46:51]: [Client #695] Woke up.
[INFO][14:46:51]: [Client #695] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_695_615874.pth.
[INFO][14:46:51]: [Client #881] Woke up.
[INFO][14:46:51]: [Client #881] Epoch: [3/5][0/15]	Loss: 0.920828
[INFO][14:46:51]: [Client #881] Epoch: [3/5][10/15]	Loss: 2.149861
[INFO][14:46:51]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][14:46:51]: [Client #695] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_695_615874.pth.
[INFO][14:46:51]: [Client #695] Model trained.
[INFO][14:46:51]: [Client #695] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:46:51]: [Server #615782] Received 0.26 MB of payload data from client #695 (simulated).
[INFO][14:46:52]: [Client #881] Woke up.
[INFO][14:46:52]: [Client #881] Epoch: [4/5][0/15]	Loss: 1.195194
[INFO][14:46:52]: [Client #881] Epoch: [4/5][10/15]	Loss: 1.528574
[INFO][14:46:52]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][14:46:52]: [Client #881] Woke up.
[INFO][14:46:52]: [Client #881] Epoch: [5/5][0/15]	Loss: 1.160632
[INFO][14:46:52]: [Client #881] Epoch: [5/5][10/15]	Loss: 1.016840
[INFO][14:46:52]: [Client #881] Going to sleep for 0.61 seconds.
[INFO][14:46:53]: [Client #881] Woke up.
[INFO][14:46:53]: [Client #881] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_881_615875.pth.
[INFO][14:46:54]: [Client #881] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_881_615875.pth.
[INFO][14:46:54]: [Client #881] Model trained.
[INFO][14:46:54]: [Client #881] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:46:54]: [Server #615782] Received 0.26 MB of payload data from client #881 (simulated).
[INFO][14:46:54]: [Server #615782] Selecting client #633 for training.
[INFO][14:46:54]: [Server #615782] Sending the current model to client #633 (simulated).
[INFO][14:46:54]: [Server #615782] Sending 0.26 MB of payload data to client #633 (simulated).
[INFO][14:46:54]: [Server #615782] Selecting client #211 for training.
[INFO][14:46:54]: [Server #615782] Sending the current model to client #211 (simulated).
[INFO][14:46:54]: [Server #615782] Sending 0.26 MB of payload data to client #211 (simulated).
[INFO][14:46:54]: [Client #633] Selected by the server.
[INFO][14:46:54]: [Client #633] Loading its data source...
[INFO][14:46:54]: [Client #211] Selected by the server.
[INFO][14:46:54]: Data source: FEMNIST
[INFO][14:46:54]: [Client #211] Loading its data source...
[INFO][14:46:54]: Data source: FEMNIST
[INFO][14:46:54]: [Client #633] Dataset size: 270
[INFO][14:46:54]: [Client #633] Sampler: all_inclusive
[INFO][14:46:54]: [Client #633] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:46:54]: [Client #211] Dataset size: 250
[INFO][14:46:54]: [Client #211] Sampler: all_inclusive
[INFO][14:46:54]: [93m[1m[Client #633] Started training in communication round #9.[0m
[INFO][14:46:54]: [Client #211] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:46:54]: [93m[1m[Client #211] Started training in communication round #9.[0m
[INFO][14:46:56]: [Client #633] Loading the dataset.
[INFO][14:46:56]: [Client #211] Loading the dataset.
[INFO][14:47:02]: [Client #633] Epoch: [1/5][0/27]	Loss: 2.484246
[INFO][14:47:02]: [Client #211] Epoch: [1/5][0/25]	Loss: 2.775723
[INFO][14:47:02]: [Client #633] Epoch: [1/5][10/27]	Loss: 2.003793
[INFO][14:47:02]: [Client #211] Epoch: [1/5][10/25]	Loss: 2.300421
[INFO][14:47:02]: [Client #633] Epoch: [1/5][20/27]	Loss: 2.364359
[INFO][14:47:02]: [Client #211] Epoch: [1/5][20/25]	Loss: 1.115953
[INFO][14:47:02]: [Client #633] Going to sleep for 17.28 seconds.
[INFO][14:47:02]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][14:47:03]: [Client #211] Woke up.
[INFO][14:47:03]: [Client #211] Epoch: [2/5][0/25]	Loss: 1.401804
[INFO][14:47:03]: [Client #211] Epoch: [2/5][10/25]	Loss: 1.921181
[INFO][14:47:03]: [Client #211] Epoch: [2/5][20/25]	Loss: 1.358027
[INFO][14:47:03]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][14:47:03]: [Client #211] Woke up.
[INFO][14:47:03]: [Client #211] Epoch: [3/5][0/25]	Loss: 1.614350
[INFO][14:47:04]: [Client #211] Epoch: [3/5][10/25]	Loss: 1.067310
[INFO][14:47:04]: [Client #211] Epoch: [3/5][20/25]	Loss: 1.918476
[INFO][14:47:04]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][14:47:04]: [Client #211] Woke up.
[INFO][14:47:04]: [Client #211] Epoch: [4/5][0/25]	Loss: 1.400203
[INFO][14:47:04]: [Client #211] Epoch: [4/5][10/25]	Loss: 1.968450
[INFO][14:47:05]: [Client #211] Epoch: [4/5][20/25]	Loss: 1.771244
[INFO][14:47:05]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][14:47:05]: [Client #211] Woke up.
[INFO][14:47:05]: [Client #211] Epoch: [5/5][0/25]	Loss: 1.717569
[INFO][14:47:05]: [Client #211] Epoch: [5/5][10/25]	Loss: 1.565786
[INFO][14:47:05]: [Client #211] Epoch: [5/5][20/25]	Loss: 0.793605
[INFO][14:47:05]: [Client #211] Going to sleep for 0.65 seconds.
[INFO][14:47:06]: [Client #211] Woke up.
[INFO][14:47:06]: [Client #211] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_211_615875.pth.
[INFO][14:47:07]: [Client #211] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_211_615875.pth.
[INFO][14:47:07]: [Client #211] Model trained.
[INFO][14:47:07]: [Client #211] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:47:07]: [Server #615782] Received 0.26 MB of payload data from client #211 (simulated).
[INFO][14:47:19]: [Client #633] Woke up.
[INFO][14:47:19]: [Client #633] Epoch: [2/5][0/27]	Loss: 1.898560
[INFO][14:47:19]: [Client #633] Epoch: [2/5][10/27]	Loss: 2.329075
[INFO][14:47:19]: [Client #633] Epoch: [2/5][20/27]	Loss: 1.847135
[INFO][14:47:19]: [Client #633] Going to sleep for 17.28 seconds.
[INFO][14:47:37]: [Client #633] Woke up.
[INFO][14:47:37]: [Client #633] Epoch: [3/5][0/27]	Loss: 1.266296
[INFO][14:47:37]: [Client #633] Epoch: [3/5][10/27]	Loss: 1.808245
[INFO][14:47:37]: [Client #633] Epoch: [3/5][20/27]	Loss: 1.523102
[INFO][14:47:37]: [Client #633] Going to sleep for 17.28 seconds.
[INFO][14:47:54]: [Client #633] Woke up.
[INFO][14:47:54]: [Client #633] Epoch: [4/5][0/27]	Loss: 1.110627
[INFO][14:47:55]: [Client #633] Epoch: [4/5][10/27]	Loss: 2.311953
[INFO][14:47:55]: [Client #633] Epoch: [4/5][20/27]	Loss: 1.659249
[INFO][14:47:55]: [Client #633] Going to sleep for 17.28 seconds.
[INFO][14:48:12]: [Client #633] Woke up.
[INFO][14:48:12]: [Client #633] Epoch: [5/5][0/27]	Loss: 3.217059
[INFO][14:48:12]: [Client #633] Epoch: [5/5][10/27]	Loss: 2.497607
[INFO][14:48:12]: [Client #633] Epoch: [5/5][20/27]	Loss: 1.113672
[INFO][14:48:12]: [Client #633] Going to sleep for 17.28 seconds.
[INFO][14:48:30]: [Client #633] Woke up.
[INFO][14:48:30]: [Client #633] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_633_615874.pth.
[INFO][14:48:30]: [Client #633] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_633_615874.pth.
[INFO][14:48:30]: [Client #633] Model trained.
[INFO][14:48:30]: [Client #633] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:48:30]: [Server #615782] Received 0.26 MB of payload data from client #633 (simulated).
[INFO][14:48:30]: [Server #615782] Selecting client #345 for training.
[INFO][14:48:30]: [Server #615782] Sending the current model to client #345 (simulated).
[INFO][14:48:30]: [Server #615782] Sending 0.26 MB of payload data to client #345 (simulated).
[INFO][14:48:30]: [Server #615782] Selecting client #161 for training.
[INFO][14:48:30]: [Server #615782] Sending the current model to client #161 (simulated).
[INFO][14:48:30]: [Server #615782] Sending 0.26 MB of payload data to client #161 (simulated).
[INFO][14:48:30]: [Client #161] Selected by the server.
[INFO][14:48:30]: [Client #161] Loading its data source...
[INFO][14:48:30]: Data source: FEMNIST
[INFO][14:48:30]: [Client #345] Selected by the server.
[INFO][14:48:30]: [Client #345] Loading its data source...
[INFO][14:48:30]: Data source: FEMNIST
[INFO][14:48:30]: [Client #345] Dataset size: 239
[INFO][14:48:30]: [Client #345] Sampler: all_inclusive
[INFO][14:48:30]: [Client #345] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:31]: [93m[1m[Client #345] Started training in communication round #9.[0m
[INFO][14:48:31]: [Client #161] Dataset size: 153
[INFO][14:48:31]: [Client #161] Sampler: all_inclusive
[INFO][14:48:31]: [Client #161] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:31]: [93m[1m[Client #161] Started training in communication round #9.[0m
[INFO][14:48:32]: [Client #161] Loading the dataset.
[INFO][14:48:32]: [Client #345] Loading the dataset.
[INFO][14:48:38]: [Client #161] Epoch: [1/5][0/16]	Loss: 1.396633
[INFO][14:48:38]: [Client #345] Epoch: [1/5][0/24]	Loss: 1.811281
[INFO][14:48:38]: [Client #161] Epoch: [1/5][10/16]	Loss: 1.417196
[INFO][14:48:38]: [Client #345] Epoch: [1/5][10/24]	Loss: 2.475472
[INFO][14:48:38]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][14:48:38]: [Client #345] Epoch: [1/5][20/24]	Loss: 2.052392
[INFO][14:48:38]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][14:48:38]: [Client #345] Woke up.
[INFO][14:48:38]: [Client #345] Epoch: [2/5][0/24]	Loss: 1.341424
[INFO][14:48:38]: [Client #345] Epoch: [2/5][10/24]	Loss: 2.464756
[INFO][14:48:38]: [Client #161] Woke up.
[INFO][14:48:38]: [Client #161] Epoch: [2/5][0/16]	Loss: 1.194582
[INFO][14:48:39]: [Client #345] Epoch: [2/5][20/24]	Loss: 1.793706
[INFO][14:48:39]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][14:48:39]: [Client #161] Epoch: [2/5][10/16]	Loss: 0.767289
[INFO][14:48:39]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][14:48:39]: [Client #345] Woke up.
[INFO][14:48:39]: [Client #345] Epoch: [3/5][0/24]	Loss: 1.541882
[INFO][14:48:39]: [Client #345] Epoch: [3/5][10/24]	Loss: 1.401350
[INFO][14:48:39]: [Client #345] Epoch: [3/5][20/24]	Loss: 2.040340
[INFO][14:48:39]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][14:48:39]: [Client #161] Woke up.
[INFO][14:48:39]: [Client #161] Epoch: [3/5][0/16]	Loss: 0.183345
[INFO][14:48:39]: [Client #345] Woke up.
[INFO][14:48:39]: [Client #345] Epoch: [4/5][0/24]	Loss: 1.442139
[INFO][14:48:39]: [Client #161] Epoch: [3/5][10/16]	Loss: 1.829725
[INFO][14:48:39]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][14:48:39]: [Client #345] Epoch: [4/5][10/24]	Loss: 2.559582
[INFO][14:48:39]: [Client #345] Epoch: [4/5][20/24]	Loss: 0.978874
[INFO][14:48:39]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][14:48:39]: [Client #345] Woke up.
[INFO][14:48:39]: [Client #345] Epoch: [5/5][0/24]	Loss: 1.612112
[INFO][14:48:39]: [Client #161] Woke up.
[INFO][14:48:39]: [Client #161] Epoch: [4/5][0/16]	Loss: 2.022929
[INFO][14:48:39]: [Client #345] Epoch: [5/5][10/24]	Loss: 0.849986
[INFO][14:48:39]: [Client #161] Epoch: [4/5][10/16]	Loss: 0.731322
[INFO][14:48:39]: [Client #345] Epoch: [5/5][20/24]	Loss: 2.431310
[INFO][14:48:39]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][14:48:39]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][14:48:40]: [Client #345] Woke up.
[INFO][14:48:40]: [Client #345] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_615874.pth.
[INFO][14:48:40]: [Client #161] Woke up.
[INFO][14:48:40]: [Client #161] Epoch: [5/5][0/16]	Loss: 0.955282
[INFO][14:48:40]: [Client #161] Epoch: [5/5][10/16]	Loss: 1.204768
[INFO][14:48:40]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][14:48:40]: [Client #345] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_615874.pth.
[INFO][14:48:40]: [Client #345] Model trained.
[INFO][14:48:40]: [Client #345] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:48:40]: [Server #615782] Received 0.26 MB of payload data from client #345 (simulated).
[INFO][14:48:40]: [Client #161] Woke up.
[INFO][14:48:40]: [Client #161] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_161_615875.pth.
[INFO][14:48:41]: [Client #161] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_161_615875.pth.
[INFO][14:48:41]: [Client #161] Model trained.
[INFO][14:48:41]: [Client #161] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:48:41]: [Server #615782] Received 0.26 MB of payload data from client #161 (simulated).
[INFO][14:48:41]: [Server #615782] Selecting client #444 for training.
[INFO][14:48:41]: [Server #615782] Sending the current model to client #444 (simulated).
[INFO][14:48:41]: [Server #615782] Sending 0.26 MB of payload data to client #444 (simulated).
[INFO][14:48:41]: [Server #615782] Selecting client #85 for training.
[INFO][14:48:41]: [Server #615782] Sending the current model to client #85 (simulated).
[INFO][14:48:41]: [Server #615782] Sending 0.26 MB of payload data to client #85 (simulated).
[INFO][14:48:41]: [Client #444] Selected by the server.
[INFO][14:48:41]: [Client #85] Selected by the server.
[INFO][14:48:41]: [Client #85] Loading its data source...
[INFO][14:48:41]: [Client #444] Loading its data source...
[INFO][14:48:41]: Data source: FEMNIST
[INFO][14:48:41]: Data source: FEMNIST
[INFO][14:48:41]: [Client #444] Dataset size: 274
[INFO][14:48:41]: [Client #444] Sampler: all_inclusive
[INFO][14:48:41]: [Client #85] Dataset size: 155
[INFO][14:48:41]: [Client #85] Sampler: all_inclusive
[INFO][14:48:41]: [Client #444] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:41]: [Client #85] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:41]: [93m[1m[Client #444] Started training in communication round #9.[0m
[INFO][14:48:41]: [93m[1m[Client #85] Started training in communication round #9.[0m
[INFO][14:48:43]: [Client #85] Loading the dataset.
[INFO][14:48:43]: [Client #444] Loading the dataset.
[INFO][14:48:48]: [Client #444] Epoch: [1/5][0/28]	Loss: 2.536946
[INFO][14:48:48]: [Client #85] Epoch: [1/5][0/16]	Loss: 0.739449
[INFO][14:48:49]: [Client #444] Epoch: [1/5][10/28]	Loss: 0.781498
[INFO][14:48:49]: [Client #85] Epoch: [1/5][10/16]	Loss: 2.072109
[INFO][14:48:49]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][14:48:49]: [Client #444] Epoch: [1/5][20/28]	Loss: 1.994994
[INFO][14:48:49]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][14:48:49]: [Client #444] Woke up.
[INFO][14:48:49]: [Client #444] Epoch: [2/5][0/28]	Loss: 1.723662
[INFO][14:48:49]: [Client #444] Epoch: [2/5][10/28]	Loss: 1.275604
[INFO][14:48:49]: [Client #444] Epoch: [2/5][20/28]	Loss: 2.278517
[INFO][14:48:49]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][14:48:49]: [Client #444] Woke up.
[INFO][14:48:49]: [Client #444] Epoch: [3/5][0/28]	Loss: 1.510001
[INFO][14:48:49]: [Client #85] Woke up.
[INFO][14:48:49]: [Client #444] Epoch: [3/5][10/28]	Loss: 0.688468
[INFO][14:48:49]: [Client #85] Epoch: [2/5][0/16]	Loss: 0.426430
[INFO][14:48:49]: [Client #444] Epoch: [3/5][20/28]	Loss: 1.326457
[INFO][14:48:49]: [Client #85] Epoch: [2/5][10/16]	Loss: 1.325156
[INFO][14:48:49]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][14:48:49]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][14:48:49]: [Client #444] Woke up.
[INFO][14:48:49]: [Client #444] Epoch: [4/5][0/28]	Loss: 1.425282
[INFO][14:48:49]: [Client #444] Epoch: [4/5][10/28]	Loss: 0.900946
[INFO][14:48:49]: [Client #444] Epoch: [4/5][20/28]	Loss: 1.509931
[INFO][14:48:49]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][14:48:49]: [Client #444] Woke up.
[INFO][14:48:49]: [Client #444] Epoch: [5/5][0/28]	Loss: 0.560078
[INFO][14:48:49]: [Client #444] Epoch: [5/5][10/28]	Loss: 1.209366
[INFO][14:48:49]: [Client #85] Woke up.
[INFO][14:48:50]: [Client #85] Epoch: [3/5][0/16]	Loss: 1.810345
[INFO][14:48:50]: [Client #444] Epoch: [5/5][20/28]	Loss: 1.209893
[INFO][14:48:50]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][14:48:50]: [Client #444] Woke up.
[INFO][14:48:50]: [Client #444] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_444_615874.pth.
[INFO][14:48:50]: [Client #85] Epoch: [3/5][10/16]	Loss: 0.588923
[INFO][14:48:50]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][14:48:50]: [Client #85] Woke up.
[INFO][14:48:50]: [Client #85] Epoch: [4/5][0/16]	Loss: 1.491546
[INFO][14:48:50]: [Client #85] Epoch: [4/5][10/16]	Loss: 1.634808
[INFO][14:48:50]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][14:48:50]: [Client #444] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_444_615874.pth.
[INFO][14:48:50]: [Client #444] Model trained.
[INFO][14:48:50]: [Client #444] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:48:50]: [Server #615782] Received 0.26 MB of payload data from client #444 (simulated).
[INFO][14:48:51]: [Client #85] Woke up.
[INFO][14:48:51]: [Client #85] Epoch: [5/5][0/16]	Loss: 1.759062
[INFO][14:48:51]: [Client #85] Epoch: [5/5][10/16]	Loss: 1.071240
[INFO][14:48:51]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][14:48:51]: [Client #85] Woke up.
[INFO][14:48:51]: [Client #85] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_615875.pth.
[INFO][14:48:52]: [Client #85] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_615875.pth.
[INFO][14:48:52]: [Client #85] Model trained.
[INFO][14:48:52]: [Client #85] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:48:52]: [Server #615782] Received 0.26 MB of payload data from client #85 (simulated).
[INFO][14:48:52]: [Server #615782] Selecting client #166 for training.
[INFO][14:48:52]: [Server #615782] Sending the current model to client #166 (simulated).
[INFO][14:48:52]: [Server #615782] Sending 0.26 MB of payload data to client #166 (simulated).
[INFO][14:48:52]: [Server #615782] Selecting client #198 for training.
[INFO][14:48:52]: [Server #615782] Sending the current model to client #198 (simulated).
[INFO][14:48:52]: [Server #615782] Sending 0.26 MB of payload data to client #198 (simulated).
[INFO][14:48:52]: [Client #166] Selected by the server.
[INFO][14:48:52]: [Client #198] Selected by the server.
[INFO][14:48:52]: [Client #166] Loading its data source...
[INFO][14:48:52]: [Client #198] Loading its data source...
[INFO][14:48:52]: Data source: FEMNIST
[INFO][14:48:52]: Data source: FEMNIST
[INFO][14:48:52]: [Client #198] Dataset size: 165
[INFO][14:48:52]: [Client #198] Sampler: all_inclusive
[INFO][14:48:52]: [Client #198] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:52]: [93m[1m[Client #198] Started training in communication round #9.[0m
[INFO][14:48:52]: [Client #166] Dataset size: 144
[INFO][14:48:52]: [Client #166] Sampler: all_inclusive
[INFO][14:48:52]: [Client #166] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:48:52]: [93m[1m[Client #166] Started training in communication round #9.[0m
[INFO][14:48:54]: [Client #198] Loading the dataset.
[INFO][14:48:54]: [Client #166] Loading the dataset.
[INFO][14:48:59]: [Client #166] Epoch: [1/5][0/15]	Loss: 1.106111
[INFO][14:48:59]: [Client #198] Epoch: [1/5][0/17]	Loss: 1.576904
[INFO][14:48:59]: [Client #166] Epoch: [1/5][10/15]	Loss: 3.016342
[INFO][14:48:59]: [Client #198] Epoch: [1/5][10/17]	Loss: 0.455196
[INFO][14:48:59]: [Client #166] Going to sleep for 0.02 seconds.
[INFO][14:48:59]: [Client #166] Woke up.
[INFO][14:48:59]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][14:48:59]: [Client #166] Epoch: [2/5][0/15]	Loss: 0.961328
[INFO][14:48:59]: [Client #166] Epoch: [2/5][10/15]	Loss: 1.643292
[INFO][14:48:59]: [Client #166] Going to sleep for 0.02 seconds.
[INFO][14:48:59]: [Client #166] Woke up.
[INFO][14:48:59]: [Client #166] Epoch: [3/5][0/15]	Loss: 0.594447
[INFO][14:49:00]: [Client #166] Epoch: [3/5][10/15]	Loss: 1.256951
[INFO][14:49:00]: [Client #166] Going to sleep for 0.02 seconds.
[INFO][14:49:00]: [Client #198] Woke up.
[INFO][14:49:00]: [Client #166] Woke up.
[INFO][14:49:00]: [Client #198] Epoch: [2/5][0/17]	Loss: 1.036569
[INFO][14:49:00]: [Client #166] Epoch: [4/5][0/15]	Loss: 0.924125
[INFO][14:49:00]: [Client #198] Epoch: [2/5][10/17]	Loss: 1.241377
[INFO][14:49:00]: [Client #166] Epoch: [4/5][10/15]	Loss: 1.134159
[INFO][14:49:00]: [Client #166] Going to sleep for 0.02 seconds.
[INFO][14:49:00]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][14:49:00]: [Client #166] Woke up.
[INFO][14:49:00]: [Client #166] Epoch: [5/5][0/15]	Loss: 0.879212
[INFO][14:49:00]: [Client #166] Epoch: [5/5][10/15]	Loss: 2.020497
[INFO][14:49:00]: [Client #166] Going to sleep for 0.02 seconds.
[INFO][14:49:00]: [Client #166] Woke up.
[INFO][14:49:00]: [Client #166] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_166_615874.pth.
[INFO][14:49:00]: [Client #198] Woke up.
[INFO][14:49:00]: [Client #198] Epoch: [3/5][0/17]	Loss: 1.558036
[INFO][14:49:00]: [Client #198] Epoch: [3/5][10/17]	Loss: 0.686008
[INFO][14:49:00]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][14:49:01]: [Client #198] Woke up.
[INFO][14:49:01]: [Client #198] Epoch: [4/5][0/17]	Loss: 1.316433
[INFO][14:49:01]: [Client #166] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_166_615874.pth.
[INFO][14:49:01]: [Client #166] Model trained.
[INFO][14:49:01]: [Client #166] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:01]: [Server #615782] Received 0.26 MB of payload data from client #166 (simulated).
[INFO][14:49:01]: [Client #198] Epoch: [4/5][10/17]	Loss: 2.818782
[INFO][14:49:01]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][14:49:01]: [Client #198] Woke up.
[INFO][14:49:01]: [Client #198] Epoch: [5/5][0/17]	Loss: 1.164780
[INFO][14:49:01]: [Client #198] Epoch: [5/5][10/17]	Loss: 1.605115
[INFO][14:49:01]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][14:49:01]: [Client #198] Woke up.
[INFO][14:49:01]: [Client #198] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_615875.pth.
[INFO][14:49:02]: [Client #198] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_615875.pth.
[INFO][14:49:02]: [Client #198] Model trained.
[INFO][14:49:02]: [Client #198] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:02]: [Server #615782] Received 0.26 MB of payload data from client #198 (simulated).
[INFO][14:49:02]: [Server #615782] Selecting client #692 for training.
[INFO][14:49:02]: [Server #615782] Sending the current model to client #692 (simulated).
[INFO][14:49:02]: [Server #615782] Sending 0.26 MB of payload data to client #692 (simulated).
[INFO][14:49:02]: [Server #615782] Selecting client #575 for training.
[INFO][14:49:02]: [Server #615782] Sending the current model to client #575 (simulated).
[INFO][14:49:02]: [Server #615782] Sending 0.26 MB of payload data to client #575 (simulated).
[INFO][14:49:02]: [Client #692] Selected by the server.
[INFO][14:49:02]: [Client #692] Loading its data source...
[INFO][14:49:02]: Data source: FEMNIST
[INFO][14:49:02]: [Client #575] Selected by the server.
[INFO][14:49:02]: [Client #575] Loading its data source...
[INFO][14:49:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:49:02]: Data source: FEMNIST
[INFO][14:49:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/692.zip.
[INFO][14:49:02]: [Client #575] Dataset size: 152
[INFO][14:49:02]: [Client #575] Sampler: all_inclusive
[INFO][14:49:02]: [Client #575] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:02]: [93m[1m[Client #575] Started training in communication round #9.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.0%27.5%30.0%32.5%35.0%37.5%40.0%42.5%45.0%47.5%50.0%52.5%55.0%57.5%60.0%62.5%65.0%67.5%70.0%72.5%75.0%77.5%80.0%82.5%85.0%87.5%90.0%92.5%95.0%97.5%100.0%[INFO][14:49:02]: Decompressing the dataset downloaded.
[INFO][14:49:02]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/692.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:49:03]: [Client #692] Dataset size: 164
[INFO][14:49:03]: [Client #692] Sampler: all_inclusive
[INFO][14:49:03]: [Client #692] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:03]: [93m[1m[Client #692] Started training in communication round #9.[0m

[INFO][14:49:04]: [Client #575] Loading the dataset.
[INFO][14:49:04]: [Client #692] Loading the dataset.
[INFO][14:49:10]: [Client #575] Epoch: [1/5][0/16]	Loss: 3.125069
[INFO][14:49:10]: [Client #692] Epoch: [1/5][0/17]	Loss: 0.730579
[INFO][14:49:10]: [Client #575] Epoch: [1/5][10/16]	Loss: 2.706704
[INFO][14:49:10]: [Client #692] Epoch: [1/5][10/17]	Loss: 1.770350
[INFO][14:49:10]: [Client #575] Going to sleep for 2.06 seconds.
[INFO][14:49:10]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][14:49:12]: [Client #575] Woke up.
[INFO][14:49:12]: [Client #575] Epoch: [2/5][0/16]	Loss: 2.240979
[INFO][14:49:12]: [Client #575] Epoch: [2/5][10/16]	Loss: 1.909878
[INFO][14:49:12]: [Client #575] Going to sleep for 2.06 seconds.
[INFO][14:49:13]: [Client #692] Woke up.
[INFO][14:49:13]: [Client #692] Epoch: [2/5][0/17]	Loss: 1.303870
[INFO][14:49:14]: [Client #692] Epoch: [2/5][10/17]	Loss: 1.195549
[INFO][14:49:14]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][14:49:14]: [Client #575] Woke up.
[INFO][14:49:14]: [Client #575] Epoch: [3/5][0/16]	Loss: 1.456445
[INFO][14:49:14]: [Client #575] Epoch: [3/5][10/16]	Loss: 2.116918
[INFO][14:49:14]: [Client #575] Going to sleep for 2.06 seconds.
[INFO][14:49:16]: [Client #575] Woke up.
[INFO][14:49:16]: [Client #575] Epoch: [4/5][0/16]	Loss: 1.670768
[INFO][14:49:17]: [Client #575] Epoch: [4/5][10/16]	Loss: 1.900379
[INFO][14:49:17]: [Client #575] Going to sleep for 2.06 seconds.
[INFO][14:49:17]: [Client #692] Woke up.
[INFO][14:49:17]: [Client #692] Epoch: [3/5][0/17]	Loss: 2.222775
[INFO][14:49:17]: [Client #692] Epoch: [3/5][10/17]	Loss: 1.784370
[INFO][14:49:17]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][14:49:19]: [Client #575] Woke up.
[INFO][14:49:19]: [Client #575] Epoch: [5/5][0/16]	Loss: 2.412132
[INFO][14:49:19]: [Client #575] Epoch: [5/5][10/16]	Loss: 1.513736
[INFO][14:49:19]: [Client #575] Going to sleep for 2.06 seconds.
[INFO][14:49:21]: [Client #692] Woke up.
[INFO][14:49:21]: [Client #692] Epoch: [4/5][0/17]	Loss: 1.187708
[INFO][14:49:21]: [Client #692] Epoch: [4/5][10/17]	Loss: 1.245996
[INFO][14:49:21]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][14:49:21]: [Client #575] Woke up.
[INFO][14:49:21]: [Client #575] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_575_615875.pth.
[INFO][14:49:21]: [Client #575] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_575_615875.pth.
[INFO][14:49:22]: [Client #575] Model trained.
[INFO][14:49:22]: [Client #575] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:22]: [Server #615782] Received 0.26 MB of payload data from client #575 (simulated).
[INFO][14:49:24]: [Client #692] Woke up.
[INFO][14:49:24]: [Client #692] Epoch: [5/5][0/17]	Loss: 0.482439
[INFO][14:49:24]: [Client #692] Epoch: [5/5][10/17]	Loss: 1.238120
[INFO][14:49:24]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][14:49:28]: [Client #692] Woke up.
[INFO][14:49:28]: [Client #692] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_692_615874.pth.
[INFO][14:49:28]: [Client #692] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_692_615874.pth.
[INFO][14:49:28]: [Client #692] Model trained.
[INFO][14:49:28]: [Client #692] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:28]: [Server #615782] Received 0.26 MB of payload data from client #692 (simulated).
[INFO][14:49:28]: [Server #615782] Selecting client #874 for training.
[INFO][14:49:28]: [Server #615782] Sending the current model to client #874 (simulated).
[INFO][14:49:29]: [Server #615782] Sending 0.26 MB of payload data to client #874 (simulated).
[INFO][14:49:29]: [Server #615782] Selecting client #245 for training.
[INFO][14:49:29]: [Server #615782] Sending the current model to client #245 (simulated).
[INFO][14:49:29]: [Server #615782] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][14:49:29]: [Client #874] Selected by the server.
[INFO][14:49:29]: [Client #874] Loading its data source...
[INFO][14:49:29]: Data source: FEMNIST
[INFO][14:49:29]: [Client #245] Selected by the server.
[INFO][14:49:29]: [Client #245] Loading its data source...
[INFO][14:49:29]: Data source: FEMNIST
[INFO][14:49:29]: [Client #874] Dataset size: 158
[INFO][14:49:29]: [Client #874] Sampler: all_inclusive
[INFO][14:49:29]: [Client #874] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:29]: [93m[1m[Client #874] Started training in communication round #9.[0m
[INFO][14:49:29]: [Client #245] Dataset size: 301
[INFO][14:49:29]: [Client #245] Sampler: all_inclusive
[INFO][14:49:29]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:29]: [93m[1m[Client #245] Started training in communication round #9.[0m
[INFO][14:49:31]: [Client #245] Loading the dataset.
[INFO][14:49:31]: [Client #874] Loading the dataset.
[INFO][14:49:38]: [Client #245] Epoch: [1/5][0/31]	Loss: 3.132217
[INFO][14:49:38]: [Client #874] Epoch: [1/5][0/16]	Loss: 0.931386
[INFO][14:49:38]: [Client #245] Epoch: [1/5][10/31]	Loss: 2.193318
[INFO][14:49:38]: [Client #874] Epoch: [1/5][10/16]	Loss: 1.744936
[INFO][14:49:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][14:49:38]: [Client #245] Epoch: [1/5][20/31]	Loss: 2.006843
[INFO][14:49:38]: [Client #245] Epoch: [1/5][30/31]	Loss: 0.528707
[INFO][14:49:38]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][14:49:38]: [Client #874] Woke up.
[INFO][14:49:38]: [Client #874] Epoch: [2/5][0/16]	Loss: 1.238334
[INFO][14:49:38]: [Client #874] Epoch: [2/5][10/16]	Loss: 1.793786
[INFO][14:49:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][14:49:38]: [Client #874] Woke up.
[INFO][14:49:38]: [Client #874] Epoch: [3/5][0/16]	Loss: 1.840962
[INFO][14:49:38]: [Client #874] Epoch: [3/5][10/16]	Loss: 2.070617
[INFO][14:49:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][14:49:38]: [Client #874] Woke up.
[INFO][14:49:38]: [Client #874] Epoch: [4/5][0/16]	Loss: 1.325776
[INFO][14:49:39]: [Client #874] Epoch: [4/5][10/16]	Loss: 1.763387
[INFO][14:49:39]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][14:49:39]: [Client #874] Woke up.
[INFO][14:49:39]: [Client #874] Epoch: [5/5][0/16]	Loss: 1.184332
[INFO][14:49:39]: [Client #874] Epoch: [5/5][10/16]	Loss: 1.194257
[INFO][14:49:39]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][14:49:39]: [Client #874] Woke up.
[INFO][14:49:39]: [Client #874] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615874.pth.
[INFO][14:49:40]: [Client #874] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615874.pth.
[INFO][14:49:40]: [Client #874] Model trained.
[INFO][14:49:40]: [Client #874] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:40]: [Server #615782] Received 0.26 MB of payload data from client #874 (simulated).
[INFO][14:49:42]: [Client #245] Woke up.
[INFO][14:49:42]: [Client #245] Epoch: [2/5][0/31]	Loss: 2.736685
[INFO][14:49:42]: [Client #245] Epoch: [2/5][10/31]	Loss: 3.079048
[INFO][14:49:42]: [Client #245] Epoch: [2/5][20/31]	Loss: 2.208323
[INFO][14:49:42]: [Client #245] Epoch: [2/5][30/31]	Loss: 0.031287
[INFO][14:49:42]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][14:49:46]: [Client #245] Woke up.
[INFO][14:49:46]: [Client #245] Epoch: [3/5][0/31]	Loss: 2.377219
[INFO][14:49:46]: [Client #245] Epoch: [3/5][10/31]	Loss: 1.503252
[INFO][14:49:46]: [Client #245] Epoch: [3/5][20/31]	Loss: 2.179320
[INFO][14:49:46]: [Client #245] Epoch: [3/5][30/31]	Loss: 0.009932
[INFO][14:49:46]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][14:49:50]: [Client #245] Woke up.
[INFO][14:49:50]: [Client #245] Epoch: [4/5][0/31]	Loss: 2.248885
[INFO][14:49:50]: [Client #245] Epoch: [4/5][10/31]	Loss: 2.296538
[INFO][14:49:50]: [Client #245] Epoch: [4/5][20/31]	Loss: 1.153973
[INFO][14:49:50]: [Client #245] Epoch: [4/5][30/31]	Loss: 2.157237
[INFO][14:49:50]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][14:49:54]: [Client #245] Woke up.
[INFO][14:49:54]: [Client #245] Epoch: [5/5][0/31]	Loss: 2.847938
[INFO][14:49:54]: [Client #245] Epoch: [5/5][10/31]	Loss: 3.175656
[INFO][14:49:54]: [Client #245] Epoch: [5/5][20/31]	Loss: 1.691523
[INFO][14:49:54]: [Client #245] Epoch: [5/5][30/31]	Loss: 1.032204
[INFO][14:49:54]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][14:49:58]: [Client #245] Woke up.
[INFO][14:49:58]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_615875.pth.
[INFO][14:49:58]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_615875.pth.
[INFO][14:49:58]: [Client #245] Model trained.
[INFO][14:49:58]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:49:58]: [Server #615782] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][14:49:58]: [Server #615782] Selecting client #631 for training.
[INFO][14:49:58]: [Server #615782] Sending the current model to client #631 (simulated).
[INFO][14:49:58]: [Server #615782] Sending 0.26 MB of payload data to client #631 (simulated).
[INFO][14:49:58]: [Server #615782] Selecting client #35 for training.
[INFO][14:49:58]: [Server #615782] Sending the current model to client #35 (simulated).
[INFO][14:49:58]: [Server #615782] Sending 0.26 MB of payload data to client #35 (simulated).
[INFO][14:49:58]: [Client #631] Selected by the server.
[INFO][14:49:58]: [Client #631] Loading its data source...
[INFO][14:49:58]: Data source: FEMNIST
[INFO][14:49:58]: [Client #35] Selected by the server.
[INFO][14:49:58]: [Client #35] Loading its data source...
[INFO][14:49:58]: Data source: FEMNIST
[INFO][14:49:58]: [Client #631] Dataset size: 145
[INFO][14:49:58]: [Client #631] Sampler: all_inclusive
[INFO][14:49:58]: [Client #35] Dataset size: 147
[INFO][14:49:58]: [Client #35] Sampler: all_inclusive
[INFO][14:49:58]: [Client #631] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:58]: [Client #35] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:49:58]: [93m[1m[Client #631] Started training in communication round #9.[0m
[INFO][14:49:58]: [93m[1m[Client #35] Started training in communication round #9.[0m
[INFO][14:50:00]: [Client #631] Loading the dataset.
[INFO][14:50:01]: [Client #35] Loading the dataset.
[INFO][14:50:08]: [Client #631] Epoch: [1/5][0/15]	Loss: 0.945403
[INFO][14:50:08]: [Client #35] Epoch: [1/5][0/15]	Loss: 1.625343
[INFO][14:50:08]: [Client #35] Epoch: [1/5][10/15]	Loss: 1.810703
[INFO][14:50:08]: [Client #631] Epoch: [1/5][10/15]	Loss: 1.432070
[INFO][14:50:08]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][14:50:08]: [Client #631] Going to sleep for 0.42 seconds.
[INFO][14:50:08]: [Client #631] Woke up.
[INFO][14:50:08]: [Client #631] Epoch: [2/5][0/15]	Loss: 0.604226
[INFO][14:50:09]: [Client #631] Epoch: [2/5][10/15]	Loss: 1.082722
[INFO][14:50:09]: [Client #631] Going to sleep for 0.42 seconds.
[INFO][14:50:09]: [Client #631] Woke up.
[INFO][14:50:09]: [Client #631] Epoch: [3/5][0/15]	Loss: 1.435519
[INFO][14:50:09]: [Client #631] Epoch: [3/5][10/15]	Loss: 1.788700
[INFO][14:50:09]: [Client #631] Going to sleep for 0.42 seconds.
[INFO][14:50:10]: [Client #631] Woke up.
[INFO][14:50:10]: [Client #631] Epoch: [4/5][0/15]	Loss: 1.249313
[INFO][14:50:10]: [Client #631] Epoch: [4/5][10/15]	Loss: 1.337276
[INFO][14:50:10]: [Client #631] Going to sleep for 0.42 seconds.
[INFO][14:50:10]: [Client #631] Woke up.
[INFO][14:50:10]: [Client #631] Epoch: [5/5][0/15]	Loss: 0.599197
[INFO][14:50:10]: [Client #631] Epoch: [5/5][10/15]	Loss: 0.572028
[INFO][14:50:10]: [Client #631] Going to sleep for 0.42 seconds.
[INFO][14:50:10]: [Client #35] Woke up.
[INFO][14:50:10]: [Client #35] Epoch: [2/5][0/15]	Loss: 1.667250
[INFO][14:50:10]: [Client #35] Epoch: [2/5][10/15]	Loss: 1.490608
[INFO][14:50:10]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][14:50:11]: [Client #631] Woke up.
[INFO][14:50:11]: [Client #631] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_631_615874.pth.
[INFO][14:50:11]: [Client #631] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_631_615874.pth.
[INFO][14:50:11]: [Client #631] Model trained.
[INFO][14:50:11]: [Client #631] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:11]: [Server #615782] Received 0.26 MB of payload data from client #631 (simulated).
[INFO][14:50:13]: [Client #35] Woke up.
[INFO][14:50:13]: [Client #35] Epoch: [3/5][0/15]	Loss: 0.929547
[INFO][14:50:13]: [Client #35] Epoch: [3/5][10/15]	Loss: 1.264440
[INFO][14:50:13]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][14:50:15]: [Client #35] Woke up.
[INFO][14:50:15]: [Client #35] Epoch: [4/5][0/15]	Loss: 1.383190
[INFO][14:50:15]: [Client #35] Epoch: [4/5][10/15]	Loss: 1.269742
[INFO][14:50:15]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][14:50:17]: [Client #35] Woke up.
[INFO][14:50:17]: [Client #35] Epoch: [5/5][0/15]	Loss: 1.588163
[INFO][14:50:17]: [Client #35] Epoch: [5/5][10/15]	Loss: 1.474611
[INFO][14:50:17]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][14:50:20]: [Client #35] Woke up.
[INFO][14:50:20]: [Client #35] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_615875.pth.
[INFO][14:50:20]: [Client #35] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_615875.pth.
[INFO][14:50:20]: [Client #35] Model trained.
[INFO][14:50:20]: [Client #35] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:20]: [Server #615782] Received 0.26 MB of payload data from client #35 (simulated).
[INFO][14:50:20]: [Server #615782] Selecting client #516 for training.
[INFO][14:50:20]: [Server #615782] Sending the current model to client #516 (simulated).
[INFO][14:50:20]: [Server #615782] Sending 0.26 MB of payload data to client #516 (simulated).
[INFO][14:50:20]: [Server #615782] Selecting client #864 for training.
[INFO][14:50:20]: [Server #615782] Sending the current model to client #864 (simulated).
[INFO][14:50:20]: [Server #615782] Sending 0.26 MB of payload data to client #864 (simulated).
[INFO][14:50:20]: [Client #864] Selected by the server.
[INFO][14:50:20]: [Client #516] Selected by the server.
[INFO][14:50:20]: [Client #864] Loading its data source...
[INFO][14:50:20]: [Client #516] Loading its data source...
[INFO][14:50:20]: Data source: FEMNIST
[INFO][14:50:20]: Data source: FEMNIST
[INFO][14:50:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:50:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/516.zip.
[INFO][14:50:20]: [Client #864] Dataset size: 153
[INFO][14:50:20]: [Client #864] Sampler: all_inclusive
[INFO][14:50:20]: [Client #864] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:20]: [93m[1m[Client #864] Started training in communication round #9.[0m
3.2%6.4%9.6%12.8%16.0%19.2%22.4%25.5%28.7%31.9%35.1%38.3%41.5%44.7%47.9%51.1%54.3%57.5%60.7%63.9%67.1%70.2%73.4%76.6%79.8%83.0%86.2%89.4%92.6%95.8%99.0%100.0%[INFO][14:50:21]: Decompressing the dataset downloaded.
[INFO][14:50:21]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/516.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:50:21]: [Client #516] Dataset size: 152
[INFO][14:50:21]: [Client #516] Sampler: all_inclusive
[INFO][14:50:21]: [Client #516] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:21]: [93m[1m[Client #516] Started training in communication round #9.[0m

[INFO][14:50:22]: [Client #864] Loading the dataset.
[INFO][14:50:23]: [Client #516] Loading the dataset.
[INFO][14:50:30]: [Client #516] Epoch: [1/5][0/16]	Loss: 1.918750
[INFO][14:50:30]: [Client #864] Epoch: [1/5][0/16]	Loss: 0.173690
[INFO][14:50:30]: [Client #516] Epoch: [1/5][10/16]	Loss: 1.750489
[INFO][14:50:30]: [Client #864] Epoch: [1/5][10/16]	Loss: 0.888033
[INFO][14:50:30]: [Client #516] Going to sleep for 0.99 seconds.
[INFO][14:50:30]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][14:50:31]: [Client #516] Woke up.
[INFO][14:50:31]: [Client #516] Epoch: [2/5][0/16]	Loss: 2.721971
[INFO][14:50:31]: [Client #516] Epoch: [2/5][10/16]	Loss: 1.204815
[INFO][14:50:31]: [Client #516] Going to sleep for 0.99 seconds.
[INFO][14:50:32]: [Client #864] Woke up.
[INFO][14:50:32]: [Client #864] Epoch: [2/5][0/16]	Loss: 0.995205
[INFO][14:50:32]: [Client #864] Epoch: [2/5][10/16]	Loss: 1.138507
[INFO][14:50:32]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][14:50:32]: [Client #516] Woke up.
[INFO][14:50:32]: [Client #516] Epoch: [3/5][0/16]	Loss: 1.888484
[INFO][14:50:33]: [Client #516] Epoch: [3/5][10/16]	Loss: 1.686362
[INFO][14:50:33]: [Client #516] Going to sleep for 0.99 seconds.
[INFO][14:50:33]: [Client #864] Woke up.
[INFO][14:50:33]: [Client #864] Epoch: [3/5][0/16]	Loss: 1.198962
[INFO][14:50:34]: [Client #516] Woke up.
[INFO][14:50:34]: [Client #864] Epoch: [3/5][10/16]	Loss: 1.164841
[INFO][14:50:34]: [Client #516] Epoch: [4/5][0/16]	Loss: 2.080316
[INFO][14:50:34]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][14:50:34]: [Client #516] Epoch: [4/5][10/16]	Loss: 2.806450
[INFO][14:50:34]: [Client #516] Going to sleep for 0.99 seconds.
[INFO][14:50:35]: [Client #516] Woke up.
[INFO][14:50:35]: [Client #516] Epoch: [5/5][0/16]	Loss: 1.436399
[INFO][14:50:35]: [Client #516] Epoch: [5/5][10/16]	Loss: 2.697565
[INFO][14:50:35]: [Client #516] Going to sleep for 0.99 seconds.
[INFO][14:50:35]: [Client #864] Woke up.
[INFO][14:50:35]: [Client #864] Epoch: [4/5][0/16]	Loss: 1.172619
[INFO][14:50:35]: [Client #864] Epoch: [4/5][10/16]	Loss: 2.304600
[INFO][14:50:35]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][14:50:36]: [Client #516] Woke up.
[INFO][14:50:36]: [Client #516] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_516_615874.pth.
[INFO][14:50:37]: [Client #516] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_516_615874.pth.
[INFO][14:50:37]: [Client #516] Model trained.
[INFO][14:50:37]: [Client #516] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:37]: [Server #615782] Received 0.26 MB of payload data from client #516 (simulated).
[INFO][14:50:37]: [Client #864] Woke up.
[INFO][14:50:37]: [Client #864] Epoch: [5/5][0/16]	Loss: 0.478993
[INFO][14:50:37]: [Client #864] Epoch: [5/5][10/16]	Loss: 1.654607
[INFO][14:50:37]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][14:50:38]: [Client #864] Woke up.
[INFO][14:50:38]: [Client #864] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615875.pth.
[INFO][14:50:39]: [Client #864] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615875.pth.
[INFO][14:50:39]: [Client #864] Model trained.
[INFO][14:50:39]: [Client #864] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:39]: [Server #615782] Received 0.26 MB of payload data from client #864 (simulated).
[INFO][14:50:39]: [Server #615782] Selecting client #985 for training.
[INFO][14:50:39]: [Server #615782] Sending the current model to client #985 (simulated).
[INFO][14:50:39]: [Server #615782] Sending 0.26 MB of payload data to client #985 (simulated).
[INFO][14:50:39]: [Server #615782] Selecting client #10 for training.
[INFO][14:50:39]: [Server #615782] Sending the current model to client #10 (simulated).
[INFO][14:50:39]: [Server #615782] Sending 0.26 MB of payload data to client #10 (simulated).
[INFO][14:50:39]: [Client #985] Selected by the server.
[INFO][14:50:39]: [Client #985] Loading its data source...
[INFO][14:50:39]: Data source: FEMNIST
[INFO][14:50:39]: [Client #10] Selected by the server.
[INFO][14:50:39]: [Client #10] Loading its data source...
[INFO][14:50:39]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][14:50:39]: Data source: FEMNIST
[INFO][14:50:39]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/985.zip.
[INFO][14:50:40]: [Client #10] Dataset size: 149
[INFO][14:50:40]: [Client #10] Sampler: all_inclusive
[INFO][14:50:40]: [Client #10] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:40]: [93m[1m[Client #10] Started training in communication round #9.[0m
2.7%5.3%8.0%10.7%13.3%16.0%18.7%21.3%24.0%26.6%29.3%32.0%34.6%37.3%40.0%42.6%45.3%48.0%50.6%53.3%56.0%58.6%61.3%64.0%66.6%69.3%71.9%74.6%77.3%79.9%82.6%85.3%87.9%90.6%93.3%95.9%98.6%100.0%[INFO][14:50:40]: Decompressing the dataset downloaded.
[INFO][14:50:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/985.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][14:50:40]: [Client #985] Dataset size: 137
[INFO][14:50:40]: [Client #985] Sampler: all_inclusive
[INFO][14:50:40]: [Client #985] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:40]: [93m[1m[Client #985] Started training in communication round #9.[0m

[INFO][14:50:42]: [Client #10] Loading the dataset.
[INFO][14:50:42]: [Client #985] Loading the dataset.
[INFO][14:50:49]: [Client #10] Epoch: [1/5][0/15]	Loss: 2.180055
[INFO][14:50:49]: [Client #985] Epoch: [1/5][0/14]	Loss: 1.563748
[INFO][14:50:49]: [Client #10] Epoch: [1/5][10/15]	Loss: 1.506984
[INFO][14:50:49]: [Client #985] Epoch: [1/5][10/14]	Loss: 1.779716
[INFO][14:50:49]: [Client #10] Going to sleep for 1.17 seconds.
[INFO][14:50:49]: [Client #985] Going to sleep for 0.63 seconds.
[INFO][14:50:50]: [Client #985] Woke up.
[INFO][14:50:50]: [Client #985] Epoch: [2/5][0/14]	Loss: 1.272667
[INFO][14:50:50]: [Client #985] Epoch: [2/5][10/14]	Loss: 1.569758
[INFO][14:50:50]: [Client #985] Going to sleep for 0.63 seconds.
[INFO][14:50:50]: [Client #10] Woke up.
[INFO][14:50:50]: [Client #10] Epoch: [2/5][0/15]	Loss: 1.244655
[INFO][14:50:51]: [Client #10] Epoch: [2/5][10/15]	Loss: 1.543848
[INFO][14:50:51]: [Client #10] Going to sleep for 1.17 seconds.
[INFO][14:50:51]: [Client #985] Woke up.
[INFO][14:50:51]: [Client #985] Epoch: [3/5][0/14]	Loss: 0.877254
[INFO][14:50:51]: [Client #985] Epoch: [3/5][10/14]	Loss: 1.768326
[INFO][14:50:51]: [Client #985] Going to sleep for 0.63 seconds.
[INFO][14:50:51]: [Client #985] Woke up.
[INFO][14:50:51]: [Client #985] Epoch: [4/5][0/14]	Loss: 1.780595
[INFO][14:50:52]: [Client #985] Epoch: [4/5][10/14]	Loss: 1.126494
[INFO][14:50:52]: [Client #985] Going to sleep for 0.63 seconds.
[INFO][14:50:52]: [Client #10] Woke up.
[INFO][14:50:52]: [Client #10] Epoch: [3/5][0/15]	Loss: 1.689701
[INFO][14:50:52]: [Client #10] Epoch: [3/5][10/15]	Loss: 1.403868
[INFO][14:50:52]: [Client #10] Going to sleep for 1.17 seconds.
[INFO][14:50:52]: [Client #985] Woke up.
[INFO][14:50:52]: [Client #985] Epoch: [5/5][0/14]	Loss: 0.894274
[INFO][14:50:52]: [Client #985] Epoch: [5/5][10/14]	Loss: 1.343919
[INFO][14:50:52]: [Client #985] Going to sleep for 0.63 seconds.
[INFO][14:50:53]: [Client #985] Woke up.
[INFO][14:50:53]: [Client #985] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_985_615874.pth.
[INFO][14:50:53]: [Client #10] Woke up.
[INFO][14:50:53]: [Client #10] Epoch: [4/5][0/15]	Loss: 0.916616
[INFO][14:50:53]: [Client #10] Epoch: [4/5][10/15]	Loss: 1.654630
[INFO][14:50:53]: [Client #10] Going to sleep for 1.17 seconds.
[INFO][14:50:54]: [Client #985] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_985_615874.pth.
[INFO][14:50:54]: [Client #985] Model trained.
[INFO][14:50:54]: [Client #985] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:54]: [Server #615782] Received 0.26 MB of payload data from client #985 (simulated).
[INFO][14:50:54]: [Client #10] Woke up.
[INFO][14:50:54]: [Client #10] Epoch: [5/5][0/15]	Loss: 1.229801
[INFO][14:50:54]: [Client #10] Epoch: [5/5][10/15]	Loss: 0.775864
[INFO][14:50:54]: [Client #10] Going to sleep for 1.17 seconds.
[INFO][14:50:56]: [Client #10] Woke up.
[INFO][14:50:56]: [Client #10] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_10_615875.pth.
[INFO][14:50:56]: [Client #10] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_10_615875.pth.
[INFO][14:50:56]: [Client #10] Model trained.
[INFO][14:50:56]: [Client #10] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:50:56]: [Server #615782] Received 0.26 MB of payload data from client #10 (simulated).
[INFO][14:50:56]: [Server #615782] Selecting client #253 for training.
[INFO][14:50:56]: [Server #615782] Sending the current model to client #253 (simulated).
[INFO][14:50:56]: [Server #615782] Sending 0.26 MB of payload data to client #253 (simulated).
[INFO][14:50:56]: [Server #615782] Selecting client #224 for training.
[INFO][14:50:56]: [Server #615782] Sending the current model to client #224 (simulated).
[INFO][14:50:56]: [Server #615782] Sending 0.26 MB of payload data to client #224 (simulated).
[INFO][14:50:56]: [Client #224] Selected by the server.
[INFO][14:50:56]: [Client #253] Selected by the server.
[INFO][14:50:56]: [Client #224] Loading its data source...
[INFO][14:50:56]: [Client #253] Loading its data source...
[INFO][14:50:56]: Data source: FEMNIST
[INFO][14:50:56]: Data source: FEMNIST
[INFO][14:50:56]: [Client #224] Dataset size: 163
[INFO][14:50:56]: [Client #224] Sampler: all_inclusive
[INFO][14:50:56]: [Client #224] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:56]: [93m[1m[Client #224] Started training in communication round #9.[0m
[INFO][14:50:56]: [Client #253] Dataset size: 161
[INFO][14:50:56]: [Client #253] Sampler: all_inclusive
[INFO][14:50:56]: [Client #253] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:50:56]: [93m[1m[Client #253] Started training in communication round #9.[0m
[INFO][14:50:58]: [Client #253] Loading the dataset.
[INFO][14:50:58]: [Client #224] Loading the dataset.
[INFO][14:51:05]: [Client #253] Epoch: [1/5][0/17]	Loss: 0.904625
[INFO][14:51:05]: [Client #224] Epoch: [1/5][0/17]	Loss: 0.650490
[INFO][14:51:06]: [Client #253] Epoch: [1/5][10/17]	Loss: 1.750748
[INFO][14:51:06]: [Client #224] Epoch: [1/5][10/17]	Loss: 1.734672
[INFO][14:51:06]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][14:51:06]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][14:51:06]: [Client #253] Woke up.
[INFO][14:51:06]: [Client #253] Epoch: [2/5][0/17]	Loss: 0.837046
[INFO][14:51:06]: [Client #253] Epoch: [2/5][10/17]	Loss: 3.611908
[INFO][14:51:06]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][14:51:07]: [Client #253] Woke up.
[INFO][14:51:07]: [Client #253] Epoch: [3/5][0/17]	Loss: 1.904761
[INFO][14:51:07]: [Client #253] Epoch: [3/5][10/17]	Loss: 1.579987
[INFO][14:51:07]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][14:51:08]: [Client #253] Woke up.
[INFO][14:51:08]: [Client #253] Epoch: [4/5][0/17]	Loss: 2.555793
[INFO][14:51:08]: [Client #253] Epoch: [4/5][10/17]	Loss: 2.859486
[INFO][14:51:08]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][14:51:08]: [Client #253] Woke up.
[INFO][14:51:09]: [Client #253] Epoch: [5/5][0/17]	Loss: 1.226412
[INFO][14:51:09]: [Client #253] Epoch: [5/5][10/17]	Loss: 2.199180
[INFO][14:51:09]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][14:51:09]: [Client #253] Woke up.
[INFO][14:51:09]: [Client #253] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_615874.pth.
[INFO][14:51:10]: [Client #224] Woke up.
[INFO][14:51:10]: [Client #224] Epoch: [2/5][0/17]	Loss: 1.185294
[INFO][14:51:10]: [Client #253] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_615874.pth.
[INFO][14:51:10]: [Client #253] Model trained.
[INFO][14:51:10]: [Client #253] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:51:10]: [Server #615782] Received 0.26 MB of payload data from client #253 (simulated).
[INFO][14:51:10]: [Client #224] Epoch: [2/5][10/17]	Loss: 1.569497
[INFO][14:51:10]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][14:51:14]: [Client #224] Woke up.
[INFO][14:51:14]: [Client #224] Epoch: [3/5][0/17]	Loss: 1.344254
[INFO][14:51:14]: [Client #224] Epoch: [3/5][10/17]	Loss: 1.434915
[INFO][14:51:14]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][14:51:19]: [Client #224] Woke up.
[INFO][14:51:19]: [Client #224] Epoch: [4/5][0/17]	Loss: 1.944948
[INFO][14:51:19]: [Client #224] Epoch: [4/5][10/17]	Loss: 2.116709
[INFO][14:51:19]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][14:51:23]: [Client #224] Woke up.
[INFO][14:51:23]: [Client #224] Epoch: [5/5][0/17]	Loss: 1.064263
[INFO][14:51:23]: [Client #224] Epoch: [5/5][10/17]	Loss: 1.200699
[INFO][14:51:23]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][14:51:27]: [Client #224] Woke up.
[INFO][14:51:27]: [Client #224] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_224_615875.pth.
[INFO][14:51:28]: [Client #224] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_224_615875.pth.
[INFO][14:51:28]: [Client #224] Model trained.
[INFO][14:51:28]: [Client #224] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:51:28]: [Server #615782] Received 0.26 MB of payload data from client #224 (simulated).
[INFO][14:51:28]: [Server #615782] Selecting client #48 for training.
[INFO][14:51:28]: [Server #615782] Sending the current model to client #48 (simulated).
[INFO][14:51:29]: [Server #615782] Sending 0.26 MB of payload data to client #48 (simulated).
[INFO][14:51:29]: [Client #48] Selected by the server.
[INFO][14:51:29]: [Client #48] Loading its data source...
[INFO][14:51:29]: Data source: FEMNIST
[INFO][14:51:29]: [Client #48] Dataset size: 159
[INFO][14:51:29]: [Client #48] Sampler: all_inclusive
[INFO][14:51:29]: [Client #48] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:51:29]: [93m[1m[Client #48] Started training in communication round #9.[0m
[INFO][14:51:30]: [Client #48] Loading the dataset.
[INFO][14:51:37]: [Client #48] Epoch: [1/5][0/16]	Loss: 1.729895
[INFO][14:51:37]: [Client #48] Epoch: [1/5][10/16]	Loss: 1.570372
[INFO][14:51:37]: [Client #48] Going to sleep for 0.42 seconds.
[INFO][14:51:38]: [Client #48] Woke up.
[INFO][14:51:38]: [Client #48] Epoch: [2/5][0/16]	Loss: 1.948244
[INFO][14:51:38]: [Client #48] Epoch: [2/5][10/16]	Loss: 1.531251
[INFO][14:51:38]: [Client #48] Going to sleep for 0.42 seconds.
[INFO][14:51:38]: [Client #48] Woke up.
[INFO][14:51:38]: [Client #48] Epoch: [3/5][0/16]	Loss: 1.085080
[INFO][14:51:38]: [Client #48] Epoch: [3/5][10/16]	Loss: 1.317163
[INFO][14:51:38]: [Client #48] Going to sleep for 0.42 seconds.
[INFO][14:51:39]: [Client #48] Woke up.
[INFO][14:51:39]: [Client #48] Epoch: [4/5][0/16]	Loss: 0.716693
[INFO][14:51:39]: [Client #48] Epoch: [4/5][10/16]	Loss: 2.331963
[INFO][14:51:39]: [Client #48] Going to sleep for 0.42 seconds.
[INFO][14:51:39]: [Client #48] Woke up.
[INFO][14:51:39]: [Client #48] Epoch: [5/5][0/16]	Loss: 0.739107
[INFO][14:51:39]: [Client #48] Epoch: [5/5][10/16]	Loss: 0.562191
[INFO][14:51:39]: [Client #48] Going to sleep for 0.42 seconds.
[INFO][14:51:40]: [Client #48] Woke up.
[INFO][14:51:40]: [Client #48] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_48_615874.pth.
[INFO][14:51:41]: [Client #48] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_48_615874.pth.
[INFO][14:51:41]: [Client #48] Model trained.
[INFO][14:51:41]: [Client #48] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:51:41]: [Server #615782] Received 0.26 MB of payload data from client #48 (simulated).
[INFO][14:51:41]: [Server #615782] Adding client #166 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #444 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #695 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #345 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #161 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #198 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #85 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #874 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #48 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #881 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #62 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #211 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #631 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #253 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #985 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #516 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #10 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #531 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #864 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #575 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #35 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #692 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #245 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #224 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Adding client #633 to the list of clients for aggregation.
[INFO][14:51:41]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1010519  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10069521 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1248973
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08677831 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10691401 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12716852 0.
 0.         0.         0.         0.17445971 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09193884
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1889102  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13877028 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.35958117 0.
 0.         0.         0.         0.         0.         0.
 0.4444926  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.19686562 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.28199077
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12356639
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13526166 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24489826 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10472781 0.         0.19218548 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10054231 0.         0.         0.08660532 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15884549
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10402224 0.         0.
 0.         0.         0.         0.         0.09694657 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11084238 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1010519  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10069521 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1248973
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08677831 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10691401 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12716852 0.
 0.         0.         0.         0.17445971 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09193884
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1889102  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13877028 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.35958117 0.
 0.         0.         0.         0.         0.         0.
 0.4444926  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.19686562 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.28199077
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12356639
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13526166 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24489826 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10472781 0.         0.19218548 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10054231 0.         0.         0.08660532 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15884549
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10402224 0.         0.
 0.         0.         0.         0.         0.09694657 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11084238 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.001
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03511554 0.001      0.001      0.001      0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.001
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.001      0.03898014 0.001
 0.001      0.001      0.001      0.001      0.001      0.03260603
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.0212766  0.01849272 0.001      0.001      0.06819212 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03647485 0.0310559  0.001      0.001      0.001      0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.001      0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.001      0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.001      0.0212766  0.001
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.001      0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03750919 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.0367014  0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.001      0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.001      0.0188727  0.001      0.001      0.001      0.001
 0.001      0.03715451 0.01849272 0.03313609 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.001      0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01937935 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03848983 0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.001      0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.001
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.001      0.001      0.001      0.001      0.0240255
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][14:52:24]: [Server #615782] Global model accuracy: 47.59%

[INFO][14:52:24]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_9.pth.
[INFO][14:52:24]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_9.pth.
[INFO][14:52:24]: [93m[1m
[Server #615782] Starting round 10/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  8e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  7e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  7e-05  4e-09  6e-10
 8:  7.5999e+00  7.5998e+00  5e-05  4e-09  5e-10
 9:  7.5999e+00  7.5998e+00  3e-05  8e-09  1e-09
10:  7.5998e+00  7.5998e+00  6e-06  2e-08  3e-09
Optimal solution found.
The calculated probability is:  [1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00381445e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00381846e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00372598e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00383738e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00378916e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00373431e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00360106e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00381264e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00275805e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00366410e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 9.97786474e-05 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00123768e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00276683e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00079219e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00374793e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 8.99809309e-01 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00320317e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00381239e-04 1.00393411e-04 1.00251471e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00379061e-04 1.00393411e-04
 1.00393411e-04 1.00383899e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00362241e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00379154e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00382249e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00381240e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04 1.00393411e-04
 1.00393411e-04 1.00393411e-04 1.00393411e-04][INFO][14:52:26]: [Server #615782] Selected clients: [102 531 454 442 186 948 494 965 647 485 968 144 634 664 434  60 493 466
 808 257 391 241 688 990 178]
[INFO][14:52:26]: [Server #615782] Selecting client #102 for training.
[INFO][14:52:26]: [Server #615782] Sending the current model to client #102 (simulated).
[INFO][14:52:26]: [Server #615782] Sending 0.26 MB of payload data to client #102 (simulated).
[INFO][14:52:26]: [Server #615782] Selecting client #531 for training.
[INFO][14:52:26]: [Server #615782] Sending the current model to client #531 (simulated).
[INFO][14:52:26]: [Server #615782] Sending 0.26 MB of payload data to client #531 (simulated).
[INFO][14:52:26]: [Client #102] Selected by the server.
[INFO][14:52:26]: [Client #102] Loading its data source...
[INFO][14:52:26]: Data source: FEMNIST
[INFO][14:52:26]: [Client #531] Selected by the server.
[INFO][14:52:26]: [Client #531] Loading its data source...
[INFO][14:52:26]: Data source: FEMNIST
[INFO][14:52:26]: [Client #531] Dataset size: 162
[INFO][14:52:26]: [Client #531] Sampler: all_inclusive
[INFO][14:52:26]: [Client #531] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:52:26]: [93m[1m[Client #531] Started training in communication round #10.[0m
[INFO][14:52:26]: [Client #102] Dataset size: 136
[INFO][14:52:26]: [Client #102] Sampler: all_inclusive
[INFO][14:52:26]: [Client #102] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:52:26]: [93m[1m[Client #102] Started training in communication round #10.[0m
[INFO][14:52:28]: [Client #102] Loading the dataset.
[INFO][14:52:28]: [Client #531] Loading the dataset.
[INFO][14:52:36]: [Client #531] Epoch: [1/5][0/17]	Loss: 2.511197
[INFO][14:52:36]: [Client #102] Epoch: [1/5][0/14]	Loss: 1.510983
[INFO][14:52:36]: [Client #531] Epoch: [1/5][10/17]	Loss: 1.509610
[INFO][14:52:36]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:52:36]: [Client #102] Epoch: [1/5][10/14]	Loss: 1.775540
[INFO][14:52:36]: [Client #102] Going to sleep for 1.11 seconds.
[INFO][14:52:37]: [Client #102] Woke up.
[INFO][14:52:37]: [Client #102] Epoch: [2/5][0/14]	Loss: 1.592630
[INFO][14:52:37]: [Client #102] Epoch: [2/5][10/14]	Loss: 1.281304
[INFO][14:52:37]: [Client #102] Going to sleep for 1.11 seconds.
[INFO][14:52:38]: [Client #102] Woke up.
[INFO][14:52:38]: [Client #102] Epoch: [3/5][0/14]	Loss: 0.788236
[INFO][14:52:38]: [Client #102] Epoch: [3/5][10/14]	Loss: 2.587774
[INFO][14:52:38]: [Client #102] Going to sleep for 1.11 seconds.
[INFO][14:52:40]: [Client #102] Woke up.
[INFO][14:52:40]: [Client #102] Epoch: [4/5][0/14]	Loss: 2.106588
[INFO][14:52:40]: [Client #102] Epoch: [4/5][10/14]	Loss: 1.430397
[INFO][14:52:40]: [Client #102] Going to sleep for 1.11 seconds.
[INFO][14:52:41]: [Client #102] Woke up.
[INFO][14:52:41]: [Client #102] Epoch: [5/5][0/14]	Loss: 2.445441
[INFO][14:52:41]: [Client #102] Epoch: [5/5][10/14]	Loss: 1.859718
[INFO][14:52:41]: [Client #102] Going to sleep for 1.11 seconds.
[INFO][14:52:42]: [Client #102] Woke up.
[INFO][14:52:42]: [Client #102] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_102_615874.pth.
[INFO][14:52:43]: [Client #102] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_102_615874.pth.
[INFO][14:52:43]: [Client #102] Model trained.
[INFO][14:52:43]: [Client #102] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:52:43]: [Server #615782] Received 0.26 MB of payload data from client #102 (simulated).
[INFO][14:53:16]: [Client #531] Woke up.
[INFO][14:53:16]: [Client #531] Epoch: [2/5][0/17]	Loss: 0.820412
[INFO][14:53:16]: [Client #531] Epoch: [2/5][10/17]	Loss: 0.849142
[INFO][14:53:16]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:53:55]: [Client #531] Woke up.
[INFO][14:53:56]: [Client #531] Epoch: [3/5][0/17]	Loss: 1.136862
[INFO][14:53:56]: [Client #531] Epoch: [3/5][10/17]	Loss: 1.857275
[INFO][14:53:56]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:54:35]: [Client #531] Woke up.
[INFO][14:54:35]: [Client #531] Epoch: [4/5][0/17]	Loss: 1.324502
[INFO][14:54:35]: [Client #531] Epoch: [4/5][10/17]	Loss: 1.460549
[INFO][14:54:36]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:55:15]: [Client #531] Woke up.
[INFO][14:55:15]: [Client #531] Epoch: [5/5][0/17]	Loss: 1.163858
[INFO][14:55:15]: [Client #531] Epoch: [5/5][10/17]	Loss: 1.233831
[INFO][14:55:15]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][14:55:55]: [Client #531] Woke up.
[INFO][14:55:55]: [Client #531] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][14:55:56]: [Client #531] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][14:55:56]: [Client #531] Model trained.
[INFO][14:55:56]: [Client #531] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:55:56]: [Server #615782] Received 0.26 MB of payload data from client #531 (simulated).
[INFO][14:55:56]: [Server #615782] Selecting client #454 for training.
[INFO][14:55:56]: [Server #615782] Sending the current model to client #454 (simulated).
[INFO][14:55:56]: [Server #615782] Sending 0.26 MB of payload data to client #454 (simulated).
[INFO][14:55:56]: [Server #615782] Selecting client #442 for training.
[INFO][14:55:56]: [Server #615782] Sending the current model to client #442 (simulated).
[INFO][14:55:56]: [Server #615782] Sending 0.26 MB of payload data to client #442 (simulated).
[INFO][14:55:56]: [Client #442] Selected by the server.
[INFO][14:55:56]: [Client #454] Selected by the server.
[INFO][14:55:56]: [Client #442] Loading its data source...
[INFO][14:55:56]: Data source: FEMNIST
[INFO][14:55:56]: [Client #454] Loading its data source...
[INFO][14:55:56]: Data source: FEMNIST
[INFO][14:55:56]: [Client #454] Dataset size: 147
[INFO][14:55:56]: [Client #454] Sampler: all_inclusive
[INFO][14:55:56]: [Client #454] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:55:56]: [93m[1m[Client #454] Started training in communication round #10.[0m
[INFO][14:55:56]: [Client #442] Dataset size: 149
[INFO][14:55:56]: [Client #442] Sampler: all_inclusive
[INFO][14:55:56]: [Client #442] Received 0.26 MB of payload data from the server (simulated).
[INFO][14:55:56]: [93m[1m[Client #442] Started training in communication round #10.[0m
[INFO][14:55:58]: [Client #442] Loading the dataset.
[INFO][14:55:58]: [Client #454] Loading the dataset.
[INFO][14:56:05]: [Client #442] Epoch: [1/5][0/15]	Loss: 0.729810
[INFO][14:56:05]: [Client #454] Epoch: [1/5][0/15]	Loss: 2.012408
[INFO][14:56:05]: [Client #442] Epoch: [1/5][10/15]	Loss: 1.701935
[INFO][14:56:06]: [Client #442] Going to sleep for 0.01 seconds.
[INFO][14:56:06]: [Client #442] Woke up.
[INFO][14:56:06]: [Client #454] Epoch: [1/5][10/15]	Loss: 1.283643
[INFO][14:56:06]: [Client #442] Epoch: [2/5][0/15]	Loss: 2.208409
[INFO][14:56:06]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][14:56:06]: [Client #442] Epoch: [2/5][10/15]	Loss: 0.995746
[INFO][14:56:06]: [Client #442] Going to sleep for 0.01 seconds.
[INFO][14:56:06]: [Client #442] Woke up.
[INFO][14:56:06]: [Client #442] Epoch: [3/5][0/15]	Loss: 0.714638
[INFO][14:56:06]: [Client #442] Epoch: [3/5][10/15]	Loss: 1.119863
[INFO][14:56:06]: [Client #442] Going to sleep for 0.01 seconds.
[INFO][14:56:06]: [Client #442] Woke up.
[INFO][14:56:06]: [Client #442] Epoch: [4/5][0/15]	Loss: 0.792037
[INFO][14:56:06]: [Client #442] Epoch: [4/5][10/15]	Loss: 2.529116
[INFO][14:56:06]: [Client #442] Going to sleep for 0.01 seconds.
[INFO][14:56:06]: [Client #442] Woke up.
[INFO][14:56:06]: [Client #442] Epoch: [5/5][0/15]	Loss: 1.003280
[INFO][14:56:06]: [Client #442] Epoch: [5/5][10/15]	Loss: 1.488291
[INFO][14:56:06]: [Client #442] Going to sleep for 0.01 seconds.
[INFO][14:56:06]: [Client #442] Woke up.
[INFO][14:56:06]: [Client #442] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_442_615875.pth.
[INFO][14:56:07]: [Client #442] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_442_615875.pth.
[INFO][14:56:07]: [Client #442] Model trained.
[INFO][14:56:07]: [Client #442] Sent 0.26 MB of payload data to the server (simulated).
[INFO][14:56:07]: [Server #615782] Received 0.26 MB of payload data from client #442 (simulated).
[INFO][14:57:06]: [Client #454] Woke up.
[INFO][14:57:06]: [Client #454] Epoch: [2/5][0/15]	Loss: 0.859798
[INFO][14:57:06]: [Client #454] Epoch: [2/5][10/15]	Loss: 1.429754
[INFO][14:57:06]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][14:58:06]: [Client #454] Woke up.
[INFO][14:58:06]: [Client #454] Epoch: [3/5][0/15]	Loss: 0.759309
[INFO][14:58:06]: [Client #454] Epoch: [3/5][10/15]	Loss: 0.661814
[INFO][14:58:06]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][14:59:06]: [Client #454] Woke up.
[INFO][14:59:06]: [Client #454] Epoch: [4/5][0/15]	Loss: 1.013313
[INFO][14:59:06]: [Client #454] Epoch: [4/5][10/15]	Loss: 1.060587
[INFO][14:59:06]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:00:06]: [Client #454] Woke up.
[INFO][15:00:07]: [Client #454] Epoch: [5/5][0/15]	Loss: 0.885379
[INFO][15:00:07]: [Client #454] Epoch: [5/5][10/15]	Loss: 1.986653
[INFO][15:00:07]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:01:07]: [Client #454] Woke up.
[INFO][15:01:07]: [Client #454] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_454_615874.pth.
[INFO][15:01:08]: [Client #454] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_454_615874.pth.
[INFO][15:01:08]: [Client #454] Model trained.
[INFO][15:01:08]: [Client #454] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:01:08]: [Server #615782] Received 0.26 MB of payload data from client #454 (simulated).
[INFO][15:01:08]: [Server #615782] Selecting client #186 for training.
[INFO][15:01:08]: [Server #615782] Sending the current model to client #186 (simulated).
[INFO][15:01:08]: [Server #615782] Sending 0.26 MB of payload data to client #186 (simulated).
[INFO][15:01:08]: [Server #615782] Selecting client #948 for training.
[INFO][15:01:08]: [Server #615782] Sending the current model to client #948 (simulated).
[INFO][15:01:08]: [Server #615782] Sending 0.26 MB of payload data to client #948 (simulated).
[INFO][15:01:08]: [Client #186] Selected by the server.
[INFO][15:01:08]: [Client #186] Loading its data source...
[INFO][15:01:08]: Data source: FEMNIST
[INFO][15:01:08]: [Client #948] Selected by the server.
[INFO][15:01:08]: [Client #948] Loading its data source...
[INFO][15:01:08]: Data source: FEMNIST
[INFO][15:01:08]: [Client #948] Dataset size: 153
[INFO][15:01:08]: [Client #948] Sampler: all_inclusive
[INFO][15:01:08]: [Client #186] Dataset size: 133
[INFO][15:01:08]: [Client #186] Sampler: all_inclusive
[INFO][15:01:08]: [Client #948] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:08]: [Client #186] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:08]: [93m[1m[Client #948] Started training in communication round #10.[0m
[INFO][15:01:08]: [93m[1m[Client #186] Started training in communication round #10.[0m
[INFO][15:01:10]: [Client #948] Loading the dataset.
[INFO][15:01:10]: [Client #186] Loading the dataset.
[INFO][15:01:17]: [Client #948] Epoch: [1/5][0/16]	Loss: 1.591775
[INFO][15:01:17]: [Client #186] Epoch: [1/5][0/14]	Loss: 1.576535
[INFO][15:01:17]: [Client #948] Epoch: [1/5][10/16]	Loss: 2.100857
[INFO][15:01:17]: [Client #186] Epoch: [1/5][10/14]	Loss: 1.813047
[INFO][15:01:17]: [Client #948] Going to sleep for 0.28 seconds.
[INFO][15:01:17]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][15:01:17]: [Client #948] Woke up.
[INFO][15:01:18]: [Client #948] Epoch: [2/5][0/16]	Loss: 1.910027
[INFO][15:01:18]: [Client #948] Epoch: [2/5][10/16]	Loss: 1.378634
[INFO][15:01:18]: [Client #948] Going to sleep for 0.28 seconds.
[INFO][15:01:18]: [Client #948] Woke up.
[INFO][15:01:18]: [Client #948] Epoch: [3/5][0/16]	Loss: 1.411559
[INFO][15:01:18]: [Client #948] Epoch: [3/5][10/16]	Loss: 1.377422
[INFO][15:01:18]: [Client #948] Going to sleep for 0.28 seconds.
[INFO][15:01:18]: [Client #948] Woke up.
[INFO][15:01:18]: [Client #948] Epoch: [4/5][0/16]	Loss: 1.252780
[INFO][15:01:18]: [Client #948] Epoch: [4/5][10/16]	Loss: 1.260701
[INFO][15:01:18]: [Client #948] Going to sleep for 0.28 seconds.
[INFO][15:01:19]: [Client #948] Woke up.
[INFO][15:01:19]: [Client #948] Epoch: [5/5][0/16]	Loss: 1.565801
[INFO][15:01:19]: [Client #948] Epoch: [5/5][10/16]	Loss: 0.762460
[INFO][15:01:19]: [Client #948] Going to sleep for 0.28 seconds.
[INFO][15:01:19]: [Client #948] Woke up.
[INFO][15:01:19]: [Client #948] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_948_615875.pth.
[INFO][15:01:20]: [Client #948] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_948_615875.pth.
[INFO][15:01:20]: [Client #948] Model trained.
[INFO][15:01:20]: [Client #948] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:01:20]: [Server #615782] Received 0.26 MB of payload data from client #948 (simulated).
[INFO][15:01:21]: [Client #186] Woke up.
[INFO][15:01:21]: [Client #186] Epoch: [2/5][0/14]	Loss: 1.240896
[INFO][15:01:21]: [Client #186] Epoch: [2/5][10/14]	Loss: 1.919575
[INFO][15:01:21]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][15:01:26]: [Client #186] Woke up.
[INFO][15:01:26]: [Client #186] Epoch: [3/5][0/14]	Loss: 2.086798
[INFO][15:01:26]: [Client #186] Epoch: [3/5][10/14]	Loss: 1.347048
[INFO][15:01:26]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][15:01:30]: [Client #186] Woke up.
[INFO][15:01:30]: [Client #186] Epoch: [4/5][0/14]	Loss: 0.742944
[INFO][15:01:30]: [Client #186] Epoch: [4/5][10/14]	Loss: 2.605047
[INFO][15:01:30]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][15:01:34]: [Client #186] Woke up.
[INFO][15:01:34]: [Client #186] Epoch: [5/5][0/14]	Loss: 1.153387
[INFO][15:01:34]: [Client #186] Epoch: [5/5][10/14]	Loss: 0.481048
[INFO][15:01:34]: [Client #186] Going to sleep for 4.12 seconds.
[INFO][15:01:38]: [Client #186] Woke up.
[INFO][15:01:38]: [Client #186] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615874.pth.
[INFO][15:01:39]: [Client #186] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_186_615874.pth.
[INFO][15:01:39]: [Client #186] Model trained.
[INFO][15:01:39]: [Client #186] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:01:39]: [Server #615782] Received 0.26 MB of payload data from client #186 (simulated).
[INFO][15:01:39]: [Server #615782] Selecting client #494 for training.
[INFO][15:01:39]: [Server #615782] Sending the current model to client #494 (simulated).
[INFO][15:01:39]: [Server #615782] Sending 0.26 MB of payload data to client #494 (simulated).
[INFO][15:01:39]: [Server #615782] Selecting client #965 for training.
[INFO][15:01:39]: [Server #615782] Sending the current model to client #965 (simulated).
[INFO][15:01:39]: [Server #615782] Sending 0.26 MB of payload data to client #965 (simulated).
[INFO][15:01:39]: [Client #494] Selected by the server.
[INFO][15:01:39]: [Client #494] Loading its data source...
[INFO][15:01:39]: Data source: FEMNIST
[INFO][15:01:39]: [Client #965] Selected by the server.
[INFO][15:01:39]: [Client #965] Loading its data source...
[INFO][15:01:39]: Data source: FEMNIST
[INFO][15:01:39]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:01:39]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/965.zip.
[INFO][15:01:39]: [Client #494] Dataset size: 161
[INFO][15:01:39]: [Client #494] Sampler: all_inclusive
[INFO][15:01:39]: [Client #494] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:39]: [93m[1m[Client #494] Started training in communication round #10.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.0%27.5%30.0%32.5%35.0%37.5%40.0%42.5%45.0%47.5%50.0%52.5%55.0%57.5%60.0%62.4%64.9%67.4%69.9%72.4%74.9%77.4%79.9%82.4%84.9%87.4%89.9%92.4%94.9%97.4%99.9%100.0%[INFO][15:01:39]: Decompressing the dataset downloaded.
[INFO][15:01:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/965.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:01:40]: [Client #965] Dataset size: 137
[INFO][15:01:40]: [Client #965] Sampler: all_inclusive
[INFO][15:01:40]: [Client #965] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:40]: [93m[1m[Client #965] Started training in communication round #10.[0m

[INFO][15:01:41]: [Client #494] Loading the dataset.
[INFO][15:01:42]: [Client #965] Loading the dataset.
[INFO][15:01:49]: [Client #965] Epoch: [1/5][0/14]	Loss: 0.444703
[INFO][15:01:49]: [Client #965] Epoch: [1/5][10/14]	Loss: 0.687672
[INFO][15:01:49]: [Client #494] Epoch: [1/5][0/17]	Loss: 0.812463
[INFO][15:01:49]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][15:01:49]: [Client #965] Woke up.
[INFO][15:01:49]: [Client #965] Epoch: [2/5][0/14]	Loss: 0.773488
[INFO][15:01:49]: [Client #494] Epoch: [1/5][10/17]	Loss: 1.136360
[INFO][15:01:49]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][15:01:49]: [Client #965] Epoch: [2/5][10/14]	Loss: 0.700596
[INFO][15:01:49]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][15:01:49]: [Client #965] Woke up.
[INFO][15:01:49]: [Client #965] Epoch: [3/5][0/14]	Loss: 0.500891
[INFO][15:01:49]: [Client #965] Epoch: [3/5][10/14]	Loss: 1.937859
[INFO][15:01:49]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][15:01:49]: [Client #965] Woke up.
[INFO][15:01:49]: [Client #965] Epoch: [4/5][0/14]	Loss: 0.826440
[INFO][15:01:49]: [Client #494] Woke up.
[INFO][15:01:49]: [Client #965] Epoch: [4/5][10/14]	Loss: 0.999710
[INFO][15:01:49]: [Client #494] Epoch: [2/5][0/17]	Loss: 1.035157
[INFO][15:01:49]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][15:01:49]: [Client #965] Woke up.
[INFO][15:01:49]: [Client #965] Epoch: [5/5][0/14]	Loss: 0.656259
[INFO][15:01:49]: [Client #494] Epoch: [2/5][10/17]	Loss: 1.897241
[INFO][15:01:50]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][15:01:50]: [Client #965] Epoch: [5/5][10/14]	Loss: 1.358689
[INFO][15:01:50]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][15:01:50]: [Client #965] Woke up.
[INFO][15:01:50]: [Client #965] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615875.pth.
[INFO][15:01:50]: [Client #494] Woke up.
[INFO][15:01:50]: [Client #494] Epoch: [3/5][0/17]	Loss: 1.273982
[INFO][15:01:50]: [Client #494] Epoch: [3/5][10/17]	Loss: 1.133174
[INFO][15:01:50]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][15:01:50]: [Client #965] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615875.pth.
[INFO][15:01:50]: [Client #965] Model trained.
[INFO][15:01:50]: [Client #965] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:01:50]: [Server #615782] Received 0.26 MB of payload data from client #965 (simulated).
[INFO][15:01:50]: [Client #494] Woke up.
[INFO][15:01:50]: [Client #494] Epoch: [4/5][0/17]	Loss: 0.575346
[INFO][15:01:50]: [Client #494] Epoch: [4/5][10/17]	Loss: 1.717654
[INFO][15:01:51]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][15:01:51]: [Client #494] Woke up.
[INFO][15:01:51]: [Client #494] Epoch: [5/5][0/17]	Loss: 1.851369
[INFO][15:01:51]: [Client #494] Epoch: [5/5][10/17]	Loss: 2.051264
[INFO][15:01:51]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][15:01:51]: [Client #494] Woke up.
[INFO][15:01:51]: [Client #494] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_615874.pth.
[INFO][15:01:52]: [Client #494] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_615874.pth.
[INFO][15:01:52]: [Client #494] Model trained.
[INFO][15:01:52]: [Client #494] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:01:52]: [Server #615782] Received 0.26 MB of payload data from client #494 (simulated).
[INFO][15:01:52]: [Server #615782] Selecting client #647 for training.
[INFO][15:01:52]: [Server #615782] Sending the current model to client #647 (simulated).
[INFO][15:01:52]: [Server #615782] Sending 0.26 MB of payload data to client #647 (simulated).
[INFO][15:01:52]: [Server #615782] Selecting client #485 for training.
[INFO][15:01:52]: [Server #615782] Sending the current model to client #485 (simulated).
[INFO][15:01:52]: [Server #615782] Sending 0.26 MB of payload data to client #485 (simulated).
[INFO][15:01:52]: [Client #647] Selected by the server.
[INFO][15:01:52]: [Client #647] Loading its data source...
[INFO][15:01:52]: Data source: FEMNIST
[INFO][15:01:52]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:01:52]: [Client #485] Selected by the server.
[INFO][15:01:52]: [Client #485] Loading its data source...
[INFO][15:01:52]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/647.zip.
[INFO][15:01:52]: Data source: FEMNIST
[INFO][15:01:52]: [Client #485] Dataset size: 157
[INFO][15:01:52]: [Client #485] Sampler: all_inclusive
[INFO][15:01:52]: [Client #485] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:52]: [93m[1m[Client #485] Started training in communication round #10.[0m
2.7%5.5%8.2%11.0%13.7%16.5%19.2%22.0%24.7%27.5%30.2%33.0%35.7%38.5%41.2%44.0%46.7%49.5%52.2%54.9%57.7%60.4%63.2%65.9%68.7%71.4%74.2%76.9%79.7%82.4%85.2%87.9%90.7%93.4%96.2%98.9%100.0%[INFO][15:01:52]: Decompressing the dataset downloaded.
[INFO][15:01:52]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/647.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:01:52]: [Client #647] Dataset size: 153
[INFO][15:01:52]: [Client #647] Sampler: all_inclusive
[INFO][15:01:52]: [Client #647] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:01:52]: [93m[1m[Client #647] Started training in communication round #10.[0m

[INFO][15:01:54]: [Client #485] Loading the dataset.
[INFO][15:01:54]: [Client #647] Loading the dataset.
[INFO][15:02:02]: [Client #647] Epoch: [1/5][0/16]	Loss: 1.244515
[INFO][15:02:02]: [Client #485] Epoch: [1/5][0/16]	Loss: 1.720471
[INFO][15:02:02]: [Client #647] Epoch: [1/5][10/16]	Loss: 1.267006
[INFO][15:02:02]: [Client #485] Epoch: [1/5][10/16]	Loss: 1.171947
[INFO][15:02:02]: [Client #647] Going to sleep for 0.26 seconds.
[INFO][15:02:02]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][15:02:02]: [Client #647] Woke up.
[INFO][15:02:02]: [Client #647] Epoch: [2/5][0/16]	Loss: 0.877729
[INFO][15:02:03]: [Client #647] Epoch: [2/5][10/16]	Loss: 1.586431
[INFO][15:02:03]: [Client #647] Going to sleep for 0.26 seconds.
[INFO][15:02:03]: [Client #647] Woke up.
[INFO][15:02:03]: [Client #647] Epoch: [3/5][0/16]	Loss: 1.645872
[INFO][15:02:03]: [Client #647] Epoch: [3/5][10/16]	Loss: 0.792762
[INFO][15:02:03]: [Client #647] Going to sleep for 0.26 seconds.
[INFO][15:02:03]: [Client #485] Woke up.
[INFO][15:02:03]: [Client #485] Epoch: [2/5][0/16]	Loss: 0.559837
[INFO][15:02:03]: [Client #485] Epoch: [2/5][10/16]	Loss: 1.384045
[INFO][15:02:03]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][15:02:03]: [Client #647] Woke up.
[INFO][15:02:03]: [Client #647] Epoch: [4/5][0/16]	Loss: 1.267037
[INFO][15:02:03]: [Client #647] Epoch: [4/5][10/16]	Loss: 1.241309
[INFO][15:02:03]: [Client #647] Going to sleep for 0.26 seconds.
[INFO][15:02:04]: [Client #647] Woke up.
[INFO][15:02:04]: [Client #647] Epoch: [5/5][0/16]	Loss: 1.079337
[INFO][15:02:04]: [Client #647] Epoch: [5/5][10/16]	Loss: 1.198585
[INFO][15:02:04]: [Client #647] Going to sleep for 0.26 seconds.
[INFO][15:02:04]: [Client #485] Woke up.
[INFO][15:02:04]: [Client #485] Epoch: [3/5][0/16]	Loss: 2.169079
[INFO][15:02:04]: [Client #647] Woke up.
[INFO][15:02:04]: [Client #647] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_647_615874.pth.
[INFO][15:02:04]: [Client #485] Epoch: [3/5][10/16]	Loss: 1.142379
[INFO][15:02:04]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][15:02:05]: [Client #647] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_647_615874.pth.
[INFO][15:02:05]: [Client #647] Model trained.
[INFO][15:02:05]: [Client #647] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:05]: [Server #615782] Received 0.26 MB of payload data from client #647 (simulated).
[INFO][15:02:05]: [Client #485] Woke up.
[INFO][15:02:05]: [Client #485] Epoch: [4/5][0/16]	Loss: 0.806460
[INFO][15:02:05]: [Client #485] Epoch: [4/5][10/16]	Loss: 1.887154
[INFO][15:02:05]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][15:02:06]: [Client #485] Woke up.
[INFO][15:02:06]: [Client #485] Epoch: [5/5][0/16]	Loss: 0.973677
[INFO][15:02:06]: [Client #485] Epoch: [5/5][10/16]	Loss: 1.666308
[INFO][15:02:06]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][15:02:07]: [Client #485] Woke up.
[INFO][15:02:07]: [Client #485] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_485_615875.pth.
[INFO][15:02:08]: [Client #485] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_485_615875.pth.
[INFO][15:02:08]: [Client #485] Model trained.
[INFO][15:02:08]: [Client #485] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:08]: [Server #615782] Received 0.26 MB of payload data from client #485 (simulated).
[INFO][15:02:08]: [Server #615782] Selecting client #968 for training.
[INFO][15:02:08]: [Server #615782] Sending the current model to client #968 (simulated).
[INFO][15:02:08]: [Server #615782] Sending 0.26 MB of payload data to client #968 (simulated).
[INFO][15:02:08]: [Server #615782] Selecting client #144 for training.
[INFO][15:02:08]: [Server #615782] Sending the current model to client #144 (simulated).
[INFO][15:02:08]: [Server #615782] Sending 0.26 MB of payload data to client #144 (simulated).
[INFO][15:02:08]: [Client #968] Selected by the server.
[INFO][15:02:08]: [Client #144] Selected by the server.
[INFO][15:02:08]: [Client #968] Loading its data source...
[INFO][15:02:08]: [Client #144] Loading its data source...
[INFO][15:02:08]: Data source: FEMNIST
[INFO][15:02:08]: Data source: FEMNIST
[INFO][15:02:08]: [Client #968] Dataset size: 124
[INFO][15:02:08]: [Client #968] Sampler: all_inclusive
[INFO][15:02:08]: [Client #968] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:08]: [93m[1m[Client #968] Started training in communication round #10.[0m
[INFO][15:02:08]: [Client #144] Dataset size: 152
[INFO][15:02:08]: [Client #144] Sampler: all_inclusive
[INFO][15:02:08]: [Client #144] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:08]: [93m[1m[Client #144] Started training in communication round #10.[0m
[INFO][15:02:10]: [Client #968] Loading the dataset.
[INFO][15:02:10]: [Client #144] Loading the dataset.
[INFO][15:02:18]: [Client #144] Epoch: [1/5][0/16]	Loss: 0.496024
[INFO][15:02:18]: [Client #144] Epoch: [1/5][10/16]	Loss: 2.695034
[INFO][15:02:18]: [Client #968] Epoch: [1/5][0/13]	Loss: 3.426933
[INFO][15:02:18]: [Client #144] Going to sleep for 0.14 seconds.
[INFO][15:02:18]: [Client #968] Epoch: [1/5][10/13]	Loss: 2.143379
[INFO][15:02:18]: [Client #968] Going to sleep for 0.54 seconds.
[INFO][15:02:18]: [Client #144] Woke up.
[INFO][15:02:18]: [Client #144] Epoch: [2/5][0/16]	Loss: 2.163939
[INFO][15:02:18]: [Client #144] Epoch: [2/5][10/16]	Loss: 1.540966
[INFO][15:02:18]: [Client #144] Going to sleep for 0.14 seconds.
[INFO][15:02:18]: [Client #144] Woke up.
[INFO][15:02:18]: [Client #144] Epoch: [3/5][0/16]	Loss: 1.114015
[INFO][15:02:18]: [Client #144] Epoch: [3/5][10/16]	Loss: 1.190950
[INFO][15:02:18]: [Client #144] Going to sleep for 0.14 seconds.
[INFO][15:02:18]: [Client #968] Woke up.
[INFO][15:02:18]: [Client #968] Epoch: [2/5][0/13]	Loss: 1.500257
[INFO][15:02:18]: [Client #144] Woke up.
[INFO][15:02:18]: [Client #144] Epoch: [4/5][0/16]	Loss: 1.297524
[INFO][15:02:18]: [Client #968] Epoch: [2/5][10/13]	Loss: 2.235916
[INFO][15:02:18]: [Client #968] Going to sleep for 0.54 seconds.
[INFO][15:02:18]: [Client #144] Epoch: [4/5][10/16]	Loss: 0.768288
[INFO][15:02:18]: [Client #144] Going to sleep for 0.14 seconds.
[INFO][15:02:19]: [Client #144] Woke up.
[INFO][15:02:19]: [Client #144] Epoch: [5/5][0/16]	Loss: 0.840621
[INFO][15:02:19]: [Client #144] Epoch: [5/5][10/16]	Loss: 1.367938
[INFO][15:02:19]: [Client #144] Going to sleep for 0.14 seconds.
[INFO][15:02:19]: [Client #144] Woke up.
[INFO][15:02:19]: [Client #144] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_144_615875.pth.
[INFO][15:02:19]: [Client #968] Woke up.
[INFO][15:02:19]: [Client #968] Epoch: [3/5][0/13]	Loss: 1.759861
[INFO][15:02:19]: [Client #968] Epoch: [3/5][10/13]	Loss: 1.131885
[INFO][15:02:19]: [Client #968] Going to sleep for 0.54 seconds.
[INFO][15:02:20]: [Client #968] Woke up.
[INFO][15:02:20]: [Client #968] Epoch: [4/5][0/13]	Loss: 2.686012
[INFO][15:02:20]: [Client #144] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_144_615875.pth.
[INFO][15:02:20]: [Client #144] Model trained.
[INFO][15:02:20]: [Client #968] Epoch: [4/5][10/13]	Loss: 1.618254
[INFO][15:02:20]: [Client #968] Going to sleep for 0.54 seconds.
[INFO][15:02:20]: [Client #144] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:20]: [Server #615782] Received 0.26 MB of payload data from client #144 (simulated).
[INFO][15:02:20]: [Client #968] Woke up.
[INFO][15:02:20]: [Client #968] Epoch: [5/5][0/13]	Loss: 1.600913
[INFO][15:02:20]: [Client #968] Epoch: [5/5][10/13]	Loss: 1.408327
[INFO][15:02:20]: [Client #968] Going to sleep for 0.54 seconds.
[INFO][15:02:21]: [Client #968] Woke up.
[INFO][15:02:21]: [Client #968] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_968_615874.pth.
[INFO][15:02:22]: [Client #968] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_968_615874.pth.
[INFO][15:02:22]: [Client #968] Model trained.
[INFO][15:02:22]: [Client #968] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:22]: [Server #615782] Received 0.26 MB of payload data from client #968 (simulated).
[INFO][15:02:22]: [Server #615782] Selecting client #634 for training.
[INFO][15:02:22]: [Server #615782] Sending the current model to client #634 (simulated).
[INFO][15:02:22]: [Server #615782] Sending 0.26 MB of payload data to client #634 (simulated).
[INFO][15:02:22]: [Server #615782] Selecting client #664 for training.
[INFO][15:02:22]: [Server #615782] Sending the current model to client #664 (simulated).
[INFO][15:02:22]: [Server #615782] Sending 0.26 MB of payload data to client #664 (simulated).
[INFO][15:02:22]: [Client #634] Selected by the server.
[INFO][15:02:22]: [Client #634] Loading its data source...
[INFO][15:02:22]: Data source: FEMNIST
[INFO][15:02:22]: [Client #664] Selected by the server.
[INFO][15:02:22]: [Client #664] Loading its data source...
[INFO][15:02:22]: Data source: FEMNIST
[INFO][15:02:22]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:02:22]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/664.zip.
[INFO][15:02:22]: [Client #634] Dataset size: 159
[INFO][15:02:22]: [Client #634] Sampler: all_inclusive
[INFO][15:02:22]: [Client #634] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:22]: [93m[1m[Client #634] Started training in communication round #10.[0m
2.3%4.6%7.0%9.3%11.6%13.9%16.3%18.6%20.9%23.2%25.6%27.9%30.2%32.5%34.9%37.2%39.5%41.8%44.2%46.5%48.8%51.1%53.5%55.8%58.1%60.4%62.8%65.1%67.4%69.7%72.1%74.4%76.7%79.0%81.4%83.7%86.0%88.3%90.7%93.0%95.3%97.6%100.0%100.0%[INFO][15:02:22]: Decompressing the dataset downloaded.
[INFO][15:02:22]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/664.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:02:22]: [Client #664] Dataset size: 149
[INFO][15:02:22]: [Client #664] Sampler: all_inclusive
[INFO][15:02:22]: [Client #664] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:22]: [93m[1m[Client #664] Started training in communication round #10.[0m

[INFO][15:02:24]: [Client #634] Loading the dataset.
[INFO][15:02:24]: [Client #664] Loading the dataset.
[INFO][15:02:31]: [Client #634] Epoch: [1/5][0/16]	Loss: 0.663048
[INFO][15:02:31]: [Client #634] Epoch: [1/5][10/16]	Loss: 1.064393
[INFO][15:02:31]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:02:31]: [Client #664] Epoch: [1/5][0/15]	Loss: 1.743762
[INFO][15:02:31]: [Client #664] Epoch: [1/5][10/15]	Loss: 1.684259
[INFO][15:02:31]: [Client #664] Going to sleep for 1.23 seconds.
[INFO][15:02:32]: [Client #634] Woke up.
[INFO][15:02:32]: [Client #634] Epoch: [2/5][0/16]	Loss: 0.690342
[INFO][15:02:32]: [Client #634] Epoch: [2/5][10/16]	Loss: 0.368859
[INFO][15:02:32]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:02:32]: [Client #664] Woke up.
[INFO][15:02:32]: [Client #664] Epoch: [2/5][0/15]	Loss: 1.742564
[INFO][15:02:33]: [Client #664] Epoch: [2/5][10/15]	Loss: 1.269945
[INFO][15:02:33]: [Client #664] Going to sleep for 1.23 seconds.
[INFO][15:02:33]: [Client #634] Woke up.
[INFO][15:02:33]: [Client #634] Epoch: [3/5][0/16]	Loss: 0.950693
[INFO][15:02:33]: [Client #634] Epoch: [3/5][10/16]	Loss: 0.633675
[INFO][15:02:33]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:02:34]: [Client #634] Woke up.
[INFO][15:02:34]: [Client #634] Epoch: [4/5][0/16]	Loss: 0.755749
[INFO][15:02:34]: [Client #634] Epoch: [4/5][10/16]	Loss: 1.061538
[INFO][15:02:34]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:02:34]: [Client #664] Woke up.
[INFO][15:02:34]: [Client #664] Epoch: [3/5][0/15]	Loss: 1.528915
[INFO][15:02:34]: [Client #664] Epoch: [3/5][10/15]	Loss: 2.214311
[INFO][15:02:34]: [Client #664] Going to sleep for 1.23 seconds.
[INFO][15:02:34]: [Client #634] Woke up.
[INFO][15:02:34]: [Client #634] Epoch: [5/5][0/16]	Loss: 0.362087
[INFO][15:02:35]: [Client #634] Epoch: [5/5][10/16]	Loss: 1.265435
[INFO][15:02:35]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:02:35]: [Client #664] Woke up.
[INFO][15:02:35]: [Client #664] Epoch: [4/5][0/15]	Loss: 0.987418
[INFO][15:02:35]: [Client #664] Epoch: [4/5][10/15]	Loss: 0.936529
[INFO][15:02:35]: [Client #664] Going to sleep for 1.23 seconds.
[INFO][15:02:35]: [Client #634] Woke up.
[INFO][15:02:35]: [Client #634] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_634_615874.pth.
[INFO][15:02:36]: [Client #634] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_634_615874.pth.
[INFO][15:02:36]: [Client #634] Model trained.
[INFO][15:02:36]: [Client #634] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:36]: [Server #615782] Received 0.26 MB of payload data from client #634 (simulated).
[INFO][15:02:37]: [Client #664] Woke up.
[INFO][15:02:37]: [Client #664] Epoch: [5/5][0/15]	Loss: 1.851036
[INFO][15:02:37]: [Client #664] Epoch: [5/5][10/15]	Loss: 1.326207
[INFO][15:02:37]: [Client #664] Going to sleep for 1.23 seconds.
[INFO][15:02:38]: [Client #664] Woke up.
[INFO][15:02:38]: [Client #664] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_664_615875.pth.
[INFO][15:02:39]: [Client #664] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_664_615875.pth.
[INFO][15:02:39]: [Client #664] Model trained.
[INFO][15:02:39]: [Client #664] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:39]: [Server #615782] Received 0.26 MB of payload data from client #664 (simulated).
[INFO][15:02:39]: [Server #615782] Selecting client #434 for training.
[INFO][15:02:39]: [Server #615782] Sending the current model to client #434 (simulated).
[INFO][15:02:39]: [Server #615782] Sending 0.26 MB of payload data to client #434 (simulated).
[INFO][15:02:39]: [Server #615782] Selecting client #60 for training.
[INFO][15:02:39]: [Server #615782] Sending the current model to client #60 (simulated).
[INFO][15:02:39]: [Server #615782] Sending 0.26 MB of payload data to client #60 (simulated).
[INFO][15:02:39]: [Client #60] Selected by the server.
[INFO][15:02:39]: [Client #434] Selected by the server.
[INFO][15:02:39]: [Client #60] Loading its data source...
[INFO][15:02:39]: [Client #434] Loading its data source...
[INFO][15:02:39]: Data source: FEMNIST
[INFO][15:02:39]: Data source: FEMNIST
[INFO][15:02:39]: [Client #60] Dataset size: 162
[INFO][15:02:39]: [Client #60] Sampler: all_inclusive
[INFO][15:02:39]: [Client #60] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:39]: [Client #434] Dataset size: 130
[INFO][15:02:39]: [Client #434] Sampler: all_inclusive
[INFO][15:02:39]: [93m[1m[Client #60] Started training in communication round #10.[0m
[INFO][15:02:39]: [Client #434] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:02:39]: [93m[1m[Client #434] Started training in communication round #10.[0m
[INFO][15:02:41]: [Client #434] Loading the dataset.
[INFO][15:02:41]: [Client #60] Loading the dataset.
[INFO][15:02:48]: [Client #434] Epoch: [1/5][0/13]	Loss: 1.052191
[INFO][15:02:48]: [Client #60] Epoch: [1/5][0/17]	Loss: 1.208359
[INFO][15:02:48]: [Client #434] Epoch: [1/5][10/13]	Loss: 1.946391
[INFO][15:02:48]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][15:02:48]: [Client #60] Epoch: [1/5][10/17]	Loss: 1.221104
[INFO][15:02:48]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][15:02:49]: [Client #434] Woke up.
[INFO][15:02:49]: [Client #434] Epoch: [2/5][0/13]	Loss: 0.861646
[INFO][15:02:49]: [Client #434] Epoch: [2/5][10/13]	Loss: 1.549207
[INFO][15:02:49]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][15:02:50]: [Client #434] Woke up.
[INFO][15:02:50]: [Client #434] Epoch: [3/5][0/13]	Loss: 0.536600
[INFO][15:02:50]: [Client #434] Epoch: [3/5][10/13]	Loss: 1.920602
[INFO][15:02:50]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][15:02:50]: [Client #60] Woke up.
[INFO][15:02:50]: [Client #60] Epoch: [2/5][0/17]	Loss: 1.653010
[INFO][15:02:50]: [Client #60] Epoch: [2/5][10/17]	Loss: 2.975577
[INFO][15:02:50]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][15:02:51]: [Client #434] Woke up.
[INFO][15:02:51]: [Client #434] Epoch: [4/5][0/13]	Loss: 1.235585
[INFO][15:02:51]: [Client #434] Epoch: [4/5][10/13]	Loss: 0.957481
[INFO][15:02:51]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][15:02:52]: [Client #434] Woke up.
[INFO][15:02:52]: [Client #434] Epoch: [5/5][0/13]	Loss: 0.829484
[INFO][15:02:52]: [Client #434] Epoch: [5/5][10/13]	Loss: 0.916831
[INFO][15:02:52]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][15:02:53]: [Client #60] Woke up.
[INFO][15:02:53]: [Client #60] Epoch: [3/5][0/17]	Loss: 1.387935
[INFO][15:02:53]: [Client #434] Woke up.
[INFO][15:02:53]: [Client #434] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_434_615874.pth.
[INFO][15:02:53]: [Client #60] Epoch: [3/5][10/17]	Loss: 2.034633
[INFO][15:02:53]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][15:02:53]: [Client #434] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_434_615874.pth.
[INFO][15:02:53]: [Client #434] Model trained.
[INFO][15:02:53]: [Client #434] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:02:53]: [Server #615782] Received 0.26 MB of payload data from client #434 (simulated).
[INFO][15:02:55]: [Client #60] Woke up.
[INFO][15:02:55]: [Client #60] Epoch: [4/5][0/17]	Loss: 1.133113
[INFO][15:02:55]: [Client #60] Epoch: [4/5][10/17]	Loss: 1.551754
[INFO][15:02:55]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][15:02:58]: [Client #60] Woke up.
[INFO][15:02:58]: [Client #60] Epoch: [5/5][0/17]	Loss: 1.032355
[INFO][15:02:58]: [Client #60] Epoch: [5/5][10/17]	Loss: 1.710378
[INFO][15:02:58]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][15:03:00]: [Client #60] Woke up.
[INFO][15:03:00]: [Client #60] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_60_615875.pth.
[INFO][15:03:01]: [Client #60] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_60_615875.pth.
[INFO][15:03:01]: [Client #60] Model trained.
[INFO][15:03:01]: [Client #60] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:01]: [Server #615782] Received 0.26 MB of payload data from client #60 (simulated).
[INFO][15:03:01]: [Server #615782] Selecting client #493 for training.
[INFO][15:03:01]: [Server #615782] Sending the current model to client #493 (simulated).
[INFO][15:03:01]: [Server #615782] Sending 0.26 MB of payload data to client #493 (simulated).
[INFO][15:03:01]: [Server #615782] Selecting client #466 for training.
[INFO][15:03:01]: [Server #615782] Sending the current model to client #466 (simulated).
[INFO][15:03:01]: [Server #615782] Sending 0.26 MB of payload data to client #466 (simulated).
[INFO][15:03:01]: [Client #493] Selected by the server.
[INFO][15:03:01]: [Client #493] Loading its data source...
[INFO][15:03:01]: Data source: FEMNIST
[INFO][15:03:01]: [Client #466] Selected by the server.
[INFO][15:03:01]: [Client #466] Loading its data source...
[INFO][15:03:01]: Data source: FEMNIST
[INFO][15:03:01]: [Client #493] Dataset size: 152
[INFO][15:03:01]: [Client #493] Sampler: all_inclusive
[INFO][15:03:01]: [Client #493] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:01]: [93m[1m[Client #493] Started training in communication round #10.[0m
[INFO][15:03:01]: [Client #466] Dataset size: 162
[INFO][15:03:01]: [Client #466] Sampler: all_inclusive
[INFO][15:03:01]: [Client #466] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:01]: [93m[1m[Client #466] Started training in communication round #10.[0m
[INFO][15:03:03]: [Client #466] Loading the dataset.
[INFO][15:03:03]: [Client #493] Loading the dataset.
[INFO][15:03:10]: [Client #493] Epoch: [1/5][0/16]	Loss: 1.069869
[INFO][15:03:10]: [Client #466] Epoch: [1/5][0/17]	Loss: 2.144106
[INFO][15:03:10]: [Client #493] Epoch: [1/5][10/16]	Loss: 1.314521
[INFO][15:03:10]: [Client #493] Going to sleep for 0.74 seconds.
[INFO][15:03:10]: [Client #466] Epoch: [1/5][10/17]	Loss: 0.890874
[INFO][15:03:10]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][15:03:11]: [Client #466] Woke up.
[INFO][15:03:11]: [Client #466] Epoch: [2/5][0/17]	Loss: 1.345355
[INFO][15:03:11]: [Client #466] Epoch: [2/5][10/17]	Loss: 2.075726
[INFO][15:03:11]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][15:03:11]: [Client #493] Woke up.
[INFO][15:03:11]: [Client #493] Epoch: [2/5][0/16]	Loss: 1.020921
[INFO][15:03:11]: [Client #493] Epoch: [2/5][10/16]	Loss: 1.201349
[INFO][15:03:11]: [Client #493] Going to sleep for 0.74 seconds.
[INFO][15:03:11]: [Client #466] Woke up.
[INFO][15:03:11]: [Client #466] Epoch: [3/5][0/17]	Loss: 1.040447
[INFO][15:03:11]: [Client #466] Epoch: [3/5][10/17]	Loss: 1.363063
[INFO][15:03:12]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][15:03:12]: [Client #493] Woke up.
[INFO][15:03:12]: [Client #493] Epoch: [3/5][0/16]	Loss: 1.016950
[INFO][15:03:12]: [Client #466] Woke up.
[INFO][15:03:12]: [Client #493] Epoch: [3/5][10/16]	Loss: 2.056757
[INFO][15:03:12]: [Client #466] Epoch: [4/5][0/17]	Loss: 1.441110
[INFO][15:03:12]: [Client #493] Going to sleep for 0.74 seconds.
[INFO][15:03:12]: [Client #466] Epoch: [4/5][10/17]	Loss: 1.213257
[INFO][15:03:12]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][15:03:13]: [Client #466] Woke up.
[INFO][15:03:13]: [Client #466] Epoch: [5/5][0/17]	Loss: 1.367722
[INFO][15:03:13]: [Client #466] Epoch: [5/5][10/17]	Loss: 0.638674
[INFO][15:03:13]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][15:03:13]: [Client #493] Woke up.
[INFO][15:03:13]: [Client #493] Epoch: [4/5][0/16]	Loss: 1.157104
[INFO][15:03:13]: [Client #493] Epoch: [4/5][10/16]	Loss: 1.206432
[INFO][15:03:13]: [Client #493] Going to sleep for 0.74 seconds.
[INFO][15:03:13]: [Client #466] Woke up.
[INFO][15:03:13]: [Client #466] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_615875.pth.
[INFO][15:03:14]: [Client #493] Woke up.
[INFO][15:03:14]: [Client #493] Epoch: [5/5][0/16]	Loss: 1.049160
[INFO][15:03:14]: [Client #493] Epoch: [5/5][10/16]	Loss: 2.170227
[INFO][15:03:14]: [Client #493] Going to sleep for 0.74 seconds.
[INFO][15:03:14]: [Client #466] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_615875.pth.
[INFO][15:03:14]: [Client #466] Model trained.
[INFO][15:03:14]: [Client #466] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:14]: [Server #615782] Received 0.26 MB of payload data from client #466 (simulated).
[INFO][15:03:15]: [Client #493] Woke up.
[INFO][15:03:15]: [Client #493] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_493_615874.pth.
[INFO][15:03:15]: [Client #493] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_493_615874.pth.
[INFO][15:03:15]: [Client #493] Model trained.
[INFO][15:03:15]: [Client #493] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:15]: [Server #615782] Received 0.26 MB of payload data from client #493 (simulated).
[INFO][15:03:15]: [Server #615782] Selecting client #808 for training.
[INFO][15:03:15]: [Server #615782] Sending the current model to client #808 (simulated).
[INFO][15:03:15]: [Server #615782] Sending 0.26 MB of payload data to client #808 (simulated).
[INFO][15:03:15]: [Server #615782] Selecting client #257 for training.
[INFO][15:03:15]: [Server #615782] Sending the current model to client #257 (simulated).
[INFO][15:03:15]: [Server #615782] Sending 0.26 MB of payload data to client #257 (simulated).
[INFO][15:03:15]: [Client #808] Selected by the server.
[INFO][15:03:15]: [Client #808] Loading its data source...
[INFO][15:03:15]: Data source: FEMNIST
[INFO][15:03:15]: [Client #257] Selected by the server.
[INFO][15:03:15]: [Client #257] Loading its data source...
[INFO][15:03:15]: Data source: FEMNIST
[INFO][15:03:15]: [Client #808] Dataset size: 144
[INFO][15:03:15]: [Client #808] Sampler: all_inclusive
[INFO][15:03:15]: [Client #257] Dataset size: 162
[INFO][15:03:15]: [Client #257] Sampler: all_inclusive
[INFO][15:03:15]: [Client #808] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:15]: [Client #257] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:15]: [93m[1m[Client #257] Started training in communication round #10.[0m
[INFO][15:03:16]: [93m[1m[Client #808] Started training in communication round #10.[0m
[INFO][15:03:17]: [Client #808] Loading the dataset.
[INFO][15:03:17]: [Client #257] Loading the dataset.
[INFO][15:03:24]: [Client #257] Epoch: [1/5][0/17]	Loss: 2.725560
[INFO][15:03:24]: [Client #808] Epoch: [1/5][0/15]	Loss: 1.483982
[INFO][15:03:24]: [Client #257] Epoch: [1/5][10/17]	Loss: 1.150804
[INFO][15:03:24]: [Client #808] Epoch: [1/5][10/15]	Loss: 1.892057
[INFO][15:03:24]: [Client #257] Going to sleep for 1.35 seconds.
[INFO][15:03:24]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][15:03:26]: [Client #257] Woke up.
[INFO][15:03:26]: [Client #257] Epoch: [2/5][0/17]	Loss: 1.213252
[INFO][15:03:26]: [Client #257] Epoch: [2/5][10/17]	Loss: 2.289895
[INFO][15:03:26]: [Client #257] Going to sleep for 1.35 seconds.
[INFO][15:03:26]: [Client #808] Woke up.
[INFO][15:03:26]: [Client #808] Epoch: [2/5][0/15]	Loss: 1.382527
[INFO][15:03:26]: [Client #808] Epoch: [2/5][10/15]	Loss: 1.705821
[INFO][15:03:26]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][15:03:27]: [Client #257] Woke up.
[INFO][15:03:27]: [Client #257] Epoch: [3/5][0/17]	Loss: 1.249600
[INFO][15:03:27]: [Client #257] Epoch: [3/5][10/17]	Loss: 0.877872
[INFO][15:03:27]: [Client #257] Going to sleep for 1.35 seconds.
[INFO][15:03:28]: [Client #808] Woke up.
[INFO][15:03:28]: [Client #808] Epoch: [3/5][0/15]	Loss: 0.484991
[INFO][15:03:28]: [Client #808] Epoch: [3/5][10/15]	Loss: 0.275229
[INFO][15:03:28]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][15:03:29]: [Client #257] Woke up.
[INFO][15:03:29]: [Client #257] Epoch: [4/5][0/17]	Loss: 0.805814
[INFO][15:03:29]: [Client #257] Epoch: [4/5][10/17]	Loss: 2.247372
[INFO][15:03:29]: [Client #257] Going to sleep for 1.35 seconds.
[INFO][15:03:29]: [Client #808] Woke up.
[INFO][15:03:29]: [Client #808] Epoch: [4/5][0/15]	Loss: 0.541333
[INFO][15:03:30]: [Client #808] Epoch: [4/5][10/15]	Loss: 0.933644
[INFO][15:03:30]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][15:03:30]: [Client #257] Woke up.
[INFO][15:03:30]: [Client #257] Epoch: [5/5][0/17]	Loss: 1.649602
[INFO][15:03:30]: [Client #257] Epoch: [5/5][10/17]	Loss: 2.001331
[INFO][15:03:30]: [Client #257] Going to sleep for 1.35 seconds.
[INFO][15:03:31]: [Client #808] Woke up.
[INFO][15:03:31]: [Client #808] Epoch: [5/5][0/15]	Loss: 0.368999
[INFO][15:03:31]: [Client #808] Epoch: [5/5][10/15]	Loss: 1.976405
[INFO][15:03:31]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][15:03:32]: [Client #257] Woke up.
[INFO][15:03:32]: [Client #257] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_257_615875.pth.
[INFO][15:03:33]: [Client #257] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_257_615875.pth.
[INFO][15:03:33]: [Client #257] Model trained.
[INFO][15:03:33]: [Client #257] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:33]: [Server #615782] Received 0.26 MB of payload data from client #257 (simulated).
[INFO][15:03:33]: [Client #808] Woke up.
[INFO][15:03:33]: [Client #808] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_808_615874.pth.
[INFO][15:03:33]: [Client #808] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_808_615874.pth.
[INFO][15:03:33]: [Client #808] Model trained.
[INFO][15:03:33]: [Client #808] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:33]: [Server #615782] Received 0.26 MB of payload data from client #808 (simulated).
[INFO][15:03:33]: [Server #615782] Selecting client #391 for training.
[INFO][15:03:33]: [Server #615782] Sending the current model to client #391 (simulated).
[INFO][15:03:33]: [Server #615782] Sending 0.26 MB of payload data to client #391 (simulated).
[INFO][15:03:33]: [Server #615782] Selecting client #241 for training.
[INFO][15:03:33]: [Server #615782] Sending the current model to client #241 (simulated).
[INFO][15:03:33]: [Server #615782] Sending 0.26 MB of payload data to client #241 (simulated).
[INFO][15:03:33]: [Client #391] Selected by the server.
[INFO][15:03:33]: [Client #391] Loading its data source...
[INFO][15:03:33]: Data source: FEMNIST
[INFO][15:03:33]: [Client #241] Selected by the server.
[INFO][15:03:33]: [Client #241] Loading its data source...
[INFO][15:03:33]: Data source: FEMNIST
[INFO][15:03:33]: [Client #241] Dataset size: 149
[INFO][15:03:33]: [Client #241] Sampler: all_inclusive
[INFO][15:03:33]: [Client #391] Dataset size: 155
[INFO][15:03:33]: [Client #391] Sampler: all_inclusive
[INFO][15:03:33]: [Client #241] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:34]: [Client #391] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:34]: [93m[1m[Client #241] Started training in communication round #10.[0m
[INFO][15:03:34]: [93m[1m[Client #391] Started training in communication round #10.[0m
[INFO][15:03:35]: [Client #241] Loading the dataset.
[INFO][15:03:35]: [Client #391] Loading the dataset.
[INFO][15:03:43]: [Client #391] Epoch: [1/5][0/16]	Loss: 1.102419
[INFO][15:03:43]: [Client #241] Epoch: [1/5][0/15]	Loss: 1.212953
[INFO][15:03:43]: [Client #391] Epoch: [1/5][10/16]	Loss: 2.135170
[INFO][15:03:43]: [Client #241] Epoch: [1/5][10/15]	Loss: 1.215887
[INFO][15:03:43]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][15:03:43]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][15:03:43]: [Client #391] Woke up.
[INFO][15:03:43]: [Client #391] Epoch: [2/5][0/16]	Loss: 0.737506
[INFO][15:03:43]: [Client #391] Epoch: [2/5][10/16]	Loss: 0.961449
[INFO][15:03:43]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][15:03:43]: [Client #241] Woke up.
[INFO][15:03:43]: [Client #241] Epoch: [2/5][0/15]	Loss: 2.173951
[INFO][15:03:43]: [Client #241] Epoch: [2/5][10/15]	Loss: 1.628373
[INFO][15:03:43]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][15:03:43]: [Client #391] Woke up.
[INFO][15:03:43]: [Client #391] Epoch: [3/5][0/16]	Loss: 1.232848
[INFO][15:03:44]: [Client #391] Epoch: [3/5][10/16]	Loss: 1.006091
[INFO][15:03:44]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][15:03:44]: [Client #241] Woke up.
[INFO][15:03:44]: [Client #241] Epoch: [3/5][0/15]	Loss: 1.000326
[INFO][15:03:44]: [Client #391] Woke up.
[INFO][15:03:44]: [Client #391] Epoch: [4/5][0/16]	Loss: 1.288255
[INFO][15:03:44]: [Client #241] Epoch: [3/5][10/15]	Loss: 1.480368
[INFO][15:03:44]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][15:03:44]: [Client #391] Epoch: [4/5][10/16]	Loss: 1.218649
[INFO][15:03:44]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][15:03:44]: [Client #391] Woke up.
[INFO][15:03:44]: [Client #391] Epoch: [5/5][0/16]	Loss: 1.212349
[INFO][15:03:44]: [Client #391] Epoch: [5/5][10/16]	Loss: 0.780300
[INFO][15:03:44]: [Client #241] Woke up.
[INFO][15:03:44]: [Client #241] Epoch: [4/5][0/15]	Loss: 1.087269
[INFO][15:03:44]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][15:03:45]: [Client #241] Epoch: [4/5][10/15]	Loss: 0.810152
[INFO][15:03:45]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][15:03:45]: [Client #391] Woke up.
[INFO][15:03:45]: [Client #391] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_615874.pth.
[INFO][15:03:45]: [Client #241] Woke up.
[INFO][15:03:45]: [Client #241] Epoch: [5/5][0/15]	Loss: 0.888913
[INFO][15:03:45]: [Client #241] Epoch: [5/5][10/15]	Loss: 0.881246
[INFO][15:03:45]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][15:03:45]: [Client #391] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_615874.pth.
[INFO][15:03:45]: [Client #391] Model trained.
[INFO][15:03:46]: [Client #391] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:46]: [Server #615782] Received 0.26 MB of payload data from client #391 (simulated).
[INFO][15:03:46]: [Client #241] Woke up.
[INFO][15:03:46]: [Client #241] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_615875.pth.
[INFO][15:03:46]: [Client #241] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_615875.pth.
[INFO][15:03:46]: [Client #241] Model trained.
[INFO][15:03:46]: [Client #241] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:03:46]: [Server #615782] Received 0.26 MB of payload data from client #241 (simulated).
[INFO][15:03:46]: [Server #615782] Selecting client #688 for training.
[INFO][15:03:46]: [Server #615782] Sending the current model to client #688 (simulated).
[INFO][15:03:46]: [Server #615782] Sending 0.26 MB of payload data to client #688 (simulated).
[INFO][15:03:46]: [Server #615782] Selecting client #990 for training.
[INFO][15:03:46]: [Server #615782] Sending the current model to client #990 (simulated).
[INFO][15:03:46]: [Server #615782] Sending 0.26 MB of payload data to client #990 (simulated).
[INFO][15:03:46]: [Client #688] Selected by the server.
[INFO][15:03:46]: [Client #990] Selected by the server.
[INFO][15:03:46]: [Client #688] Loading its data source...
[INFO][15:03:46]: [Client #990] Loading its data source...
[INFO][15:03:46]: Data source: FEMNIST
[INFO][15:03:46]: Data source: FEMNIST
[INFO][15:03:46]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:03:46]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/688.zip.
[INFO][15:03:46]: [Client #990] Dataset size: 98
[INFO][15:03:46]: [Client #990] Sampler: all_inclusive
[INFO][15:03:46]: [Client #990] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:46]: [93m[1m[Client #990] Started training in communication round #10.[0m
2.7%5.4%8.1%10.8%13.6%16.3%19.0%21.7%24.4%27.1%29.8%32.5%35.3%38.0%40.7%43.4%46.1%48.8%51.5%54.2%57.0%59.7%62.4%65.1%67.8%70.5%73.2%75.9%78.6%81.4%84.1%86.8%89.5%92.2%94.9%97.6%100.0%[INFO][15:03:47]: Decompressing the dataset downloaded.
[INFO][15:03:47]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/688.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:03:47]: [Client #688] Dataset size: 153
[INFO][15:03:47]: [Client #688] Sampler: all_inclusive
[INFO][15:03:47]: [Client #688] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:03:47]: [93m[1m[Client #688] Started training in communication round #10.[0m

[INFO][15:03:48]: [Client #990] Loading the dataset.
[INFO][15:03:49]: [Client #688] Loading the dataset.
[INFO][15:03:56]: [Client #688] Epoch: [1/5][0/16]	Loss: 1.657391
[INFO][15:03:56]: [Client #990] Epoch: [1/5][0/10]	Loss: 2.077851
[INFO][15:03:56]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][15:03:56]: [Client #688] Epoch: [1/5][10/16]	Loss: 1.613374
[INFO][15:03:56]: [Client #688] Going to sleep for 1.59 seconds.
[INFO][15:03:58]: [Client #688] Woke up.
[INFO][15:03:58]: [Client #688] Epoch: [2/5][0/16]	Loss: 1.273830
[INFO][15:03:58]: [Client #688] Epoch: [2/5][10/16]	Loss: 1.814353
[INFO][15:03:58]: [Client #688] Going to sleep for 1.59 seconds.
[INFO][15:03:59]: [Client #688] Woke up.
[INFO][15:03:59]: [Client #688] Epoch: [3/5][0/16]	Loss: 0.972435
[INFO][15:03:59]: [Client #688] Epoch: [3/5][10/16]	Loss: 1.919307
[INFO][15:03:59]: [Client #688] Going to sleep for 1.59 seconds.
[INFO][15:04:01]: [Client #688] Woke up.
[INFO][15:04:01]: [Client #688] Epoch: [4/5][0/16]	Loss: 1.066901
[INFO][15:04:01]: [Client #688] Epoch: [4/5][10/16]	Loss: 2.417989
[INFO][15:04:01]: [Client #688] Going to sleep for 1.59 seconds.
[INFO][15:04:03]: [Client #688] Woke up.
[INFO][15:04:03]: [Client #688] Epoch: [5/5][0/16]	Loss: 0.547650
[INFO][15:04:03]: [Client #688] Epoch: [5/5][10/16]	Loss: 1.512976
[INFO][15:04:03]: [Client #688] Going to sleep for 1.59 seconds.
[INFO][15:04:04]: [Client #688] Woke up.
[INFO][15:04:04]: [Client #688] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_688_615874.pth.
[INFO][15:04:05]: [Client #688] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_688_615874.pth.
[INFO][15:04:05]: [Client #688] Model trained.
[INFO][15:04:05]: [Client #688] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:04:05]: [Server #615782] Received 0.26 MB of payload data from client #688 (simulated).
[INFO][15:04:15]: [Client #990] Woke up.
[INFO][15:04:16]: [Client #990] Epoch: [2/5][0/10]	Loss: 1.831531
[INFO][15:04:16]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][15:04:35]: [Client #990] Woke up.
[INFO][15:04:35]: [Client #990] Epoch: [3/5][0/10]	Loss: 1.129153
[INFO][15:04:35]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][15:04:55]: [Client #990] Woke up.
[INFO][15:04:55]: [Client #990] Epoch: [4/5][0/10]	Loss: 1.268412
[INFO][15:04:55]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][15:05:14]: [Client #990] Woke up.
[INFO][15:05:15]: [Client #990] Epoch: [5/5][0/10]	Loss: 1.203504
[INFO][15:05:15]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][15:05:34]: [Client #990] Woke up.
[INFO][15:05:34]: [Client #990] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615875.pth.
[INFO][15:05:35]: [Client #990] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615875.pth.
[INFO][15:05:35]: [Client #990] Model trained.
[INFO][15:05:35]: [Client #990] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:05:35]: [Server #615782] Received 0.26 MB of payload data from client #990 (simulated).
[INFO][15:05:35]: [Server #615782] Selecting client #178 for training.
[INFO][15:05:35]: [Server #615782] Sending the current model to client #178 (simulated).
[INFO][15:05:35]: [Server #615782] Sending 0.26 MB of payload data to client #178 (simulated).
[INFO][15:05:35]: [Client #178] Selected by the server.
[INFO][15:05:35]: [Client #178] Loading its data source...
[INFO][15:05:35]: Data source: FEMNIST
[INFO][15:05:35]: [Client #178] Dataset size: 208
[INFO][15:05:35]: [Client #178] Sampler: all_inclusive
[INFO][15:05:35]: [Client #178] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:05:35]: [93m[1m[Client #178] Started training in communication round #10.[0m
[INFO][15:05:37]: [Client #178] Loading the dataset.
[INFO][15:05:44]: [Client #178] Epoch: [1/5][0/21]	Loss: 1.781977
[INFO][15:05:44]: [Client #178] Epoch: [1/5][10/21]	Loss: 2.291076
[INFO][15:05:45]: [Client #178] Epoch: [1/5][20/21]	Loss: 2.374141
[INFO][15:05:45]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][15:05:45]: [Client #178] Woke up.
[INFO][15:05:45]: [Client #178] Epoch: [2/5][0/21]	Loss: 1.672424
[INFO][15:05:45]: [Client #178] Epoch: [2/5][10/21]	Loss: 0.904683
[INFO][15:05:45]: [Client #178] Epoch: [2/5][20/21]	Loss: 1.748455
[INFO][15:05:45]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][15:05:45]: [Client #178] Woke up.
[INFO][15:05:45]: [Client #178] Epoch: [3/5][0/21]	Loss: 1.919412
[INFO][15:05:46]: [Client #178] Epoch: [3/5][10/21]	Loss: 1.360868
[INFO][15:05:46]: [Client #178] Epoch: [3/5][20/21]	Loss: 1.944857
[INFO][15:05:46]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][15:05:46]: [Client #178] Woke up.
[INFO][15:05:46]: [Client #178] Epoch: [4/5][0/21]	Loss: 1.031656
[INFO][15:05:46]: [Client #178] Epoch: [4/5][10/21]	Loss: 0.742814
[INFO][15:05:46]: [Client #178] Epoch: [4/5][20/21]	Loss: 1.939465
[INFO][15:05:46]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][15:05:47]: [Client #178] Woke up.
[INFO][15:05:47]: [Client #178] Epoch: [5/5][0/21]	Loss: 1.833292
[INFO][15:05:47]: [Client #178] Epoch: [5/5][10/21]	Loss: 1.113332
[INFO][15:05:47]: [Client #178] Epoch: [5/5][20/21]	Loss: 1.564770
[INFO][15:05:47]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][15:05:47]: [Client #178] Woke up.
[INFO][15:05:47]: [Client #178] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_178_615874.pth.
[INFO][15:05:48]: [Client #178] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_178_615874.pth.
[INFO][15:05:48]: [Client #178] Model trained.
[INFO][15:05:48]: [Client #178] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:05:48]: [Server #615782] Received 0.26 MB of payload data from client #178 (simulated).
[INFO][15:05:48]: [Server #615782] Adding client #442 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #965 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #144 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #391 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #948 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #647 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #178 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #494 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #241 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #466 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #968 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #634 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #493 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #434 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #485 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #102 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #664 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #257 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #808 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #688 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #60 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #186 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #990 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #531 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Adding client #520 to the list of clients for aggregation.
[INFO][15:05:48]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1942042
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1115565
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.16924345
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13808094 0.         0.
 0.         0.         0.         0.         0.         0.12137282
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1036727  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1886658  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11443262 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10610669 0.         0.         0.         0.
 0.         0.         0.         0.13544584 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12770667 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09825027 0.
 0.         0.         0.         0.         0.         0.
 0.1365082  0.37486933 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10114689 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16446188 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12076015 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09692627 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10521396 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09951912 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13686274 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11657601
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10329184 0.
 0.         0.1627916  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09553396
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1942042
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1115565
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.16924345
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13808094 0.         0.
 0.         0.         0.         0.         0.         0.12137282
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1036727  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1886658  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11443262 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10610669 0.         0.         0.         0.
 0.         0.         0.         0.13544584 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12770667 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09825027 0.
 0.         0.         0.         0.         0.         0.
 0.1365082  0.37486933 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10114689 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16446188 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12076015 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09692627 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10521396 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09951912 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13686274 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11657601
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10329184 0.
 0.         0.1627916  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09553396
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.001      0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03511554 0.001      0.001      0.001      0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.001      0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.001
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.01849272 0.001      0.001      0.06819212 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03647485 0.0310559  0.001      0.001      0.04316547 0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.001      0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.03463896 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.001      0.0212766  0.001
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.04076739 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04236611 0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.02313294 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.001      0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.03715451 0.01849272 0.03313609 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.001      0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.01937935 0.001      0.0383693  0.001      0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03848983 0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.001      0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.001      0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.001      0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.02213337 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.04076739
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.001      0.001      0.001      0.03650413 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.001      0.001      0.001      0.001      0.02611244
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][15:06:33]: [Server #615782] Global model accuracy: 50.42%

[INFO][15:06:33]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_10.pth.
[INFO][15:06:33]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_10.pth.
[INFO][15:06:33]: [93m[1m
[Server #615782] Starting round 11/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  5e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  5e-05  3e-09  3e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  3e-10
 9:  7.5999e+00  7.5999e+00  2e-05  5e-09  5e-10
10:  7.5999e+00  7.5999e+00  4e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.05946677e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06518156e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06193361e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06070679e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06495268e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06511804e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.05988517e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06454604e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06548202e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06384842e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06369247e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06512314e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06367352e-05
 8.03957004e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 9.19493166e-01 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06157206e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06413906e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06525880e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06506424e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06516903e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06399048e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06451951e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06540689e-05
 8.06691480e-05 8.06691480e-05 8.06384699e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06625469e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05 8.06691480e-05
 8.06691480e-05 8.06691480e-05 8.06691480e-05][INFO][15:06:36]: [Server #615782] Selected clients: [520 184 192 871  88 685 120  11 560 908 862 340  28 802 807 870 671 809
 898 456 508 694 523 828 503]
[INFO][15:06:36]: [Server #615782] Selecting client #520 for training.
[INFO][15:06:36]: [Server #615782] Sending the current model to client #520 (simulated).
[INFO][15:06:36]: [Server #615782] Sending 0.26 MB of payload data to client #520 (simulated).
[INFO][15:06:36]: [Server #615782] Selecting client #184 for training.
[INFO][15:06:36]: [Server #615782] Sending the current model to client #184 (simulated).
[INFO][15:06:36]: [Server #615782] Sending 0.26 MB of payload data to client #184 (simulated).
[INFO][15:06:36]: [Client #520] Selected by the server.
[INFO][15:06:36]: [Client #520] Loading its data source...
[INFO][15:06:36]: Data source: FEMNIST
[INFO][15:06:36]: [Client #184] Selected by the server.
[INFO][15:06:36]: [Client #184] Loading its data source...
[INFO][15:06:36]: Data source: FEMNIST
[INFO][15:06:36]: [Client #520] Dataset size: 153
[INFO][15:06:36]: [Client #520] Sampler: all_inclusive
[INFO][15:06:36]: [Client #520] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:06:36]: [Client #184] Dataset size: 159
[INFO][15:06:36]: [Client #184] Sampler: all_inclusive
[INFO][15:06:36]: [93m[1m[Client #520] Started training in communication round #11.[0m
[INFO][15:06:36]: [Client #184] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:06:36]: [93m[1m[Client #184] Started training in communication round #11.[0m
[INFO][15:06:38]: [Client #184] Loading the dataset.
[INFO][15:06:38]: [Client #520] Loading the dataset.
[INFO][15:06:45]: [Client #184] Epoch: [1/5][0/16]	Loss: 1.157696
[INFO][15:06:45]: [Client #520] Epoch: [1/5][0/16]	Loss: 0.620901
[INFO][15:06:45]: [Client #184] Epoch: [1/5][10/16]	Loss: 0.757506
[INFO][15:06:45]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:06:45]: [Client #520] Epoch: [1/5][10/16]	Loss: 2.965562
[INFO][15:06:45]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][15:06:45]: [Client #184] Woke up.
[INFO][15:06:45]: [Client #184] Epoch: [2/5][0/16]	Loss: 0.500511
[INFO][15:06:45]: [Client #184] Epoch: [2/5][10/16]	Loss: 0.610678
[INFO][15:06:45]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:06:45]: [Client #184] Woke up.
[INFO][15:06:45]: [Client #184] Epoch: [3/5][0/16]	Loss: 0.563070
[INFO][15:06:45]: [Client #184] Epoch: [3/5][10/16]	Loss: 0.991354
[INFO][15:06:46]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:06:46]: [Client #184] Woke up.
[INFO][15:06:46]: [Client #184] Epoch: [4/5][0/16]	Loss: 0.763019
[INFO][15:06:46]: [Client #184] Epoch: [4/5][10/16]	Loss: 1.779461
[INFO][15:06:46]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:06:46]: [Client #184] Woke up.
[INFO][15:06:46]: [Client #184] Epoch: [5/5][0/16]	Loss: 0.435260
[INFO][15:06:46]: [Client #184] Epoch: [5/5][10/16]	Loss: 0.547638
[INFO][15:06:46]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:06:46]: [Client #184] Woke up.
[INFO][15:06:46]: [Client #184] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_615875.pth.
[INFO][15:06:47]: [Client #184] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_615875.pth.
[INFO][15:06:47]: [Client #184] Model trained.
[INFO][15:06:47]: [Client #184] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:06:47]: [Server #615782] Received 0.26 MB of payload data from client #184 (simulated).
[INFO][15:07:45]: [Client #520] Woke up.
[INFO][15:07:45]: [Client #520] Epoch: [2/5][0/16]	Loss: 1.063760
[INFO][15:07:45]: [Client #520] Epoch: [2/5][10/16]	Loss: 1.184268
[INFO][15:07:45]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][15:08:46]: [Client #520] Woke up.
[INFO][15:08:46]: [Client #520] Epoch: [3/5][0/16]	Loss: 0.677352
[INFO][15:08:46]: [Client #520] Epoch: [3/5][10/16]	Loss: 0.551045
[INFO][15:08:46]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][15:09:46]: [Client #520] Woke up.
[INFO][15:09:46]: [Client #520] Epoch: [4/5][0/16]	Loss: 0.968220
[INFO][15:09:46]: [Client #520] Epoch: [4/5][10/16]	Loss: 2.293132
[INFO][15:09:46]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][15:10:46]: [Client #520] Woke up.
[INFO][15:10:46]: [Client #520] Epoch: [5/5][0/16]	Loss: 0.615004
[INFO][15:10:46]: [Client #520] Epoch: [5/5][10/16]	Loss: 1.438258
[INFO][15:10:46]: [Client #520] Going to sleep for 60.00 seconds.
[INFO][15:11:47]: [Client #520] Woke up.
[INFO][15:11:47]: [Client #520] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615874.pth.
[INFO][15:11:47]: [Client #520] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_520_615874.pth.
[INFO][15:11:47]: [Client #520] Model trained.
[INFO][15:11:47]: [Client #520] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:11:47]: [Server #615782] Received 0.26 MB of payload data from client #520 (simulated).
[INFO][15:11:47]: [Server #615782] Selecting client #192 for training.
[INFO][15:11:47]: [Server #615782] Sending the current model to client #192 (simulated).
[INFO][15:11:47]: [Server #615782] Sending 0.26 MB of payload data to client #192 (simulated).
[INFO][15:11:47]: [Server #615782] Selecting client #871 for training.
[INFO][15:11:47]: [Server #615782] Sending the current model to client #871 (simulated).
[INFO][15:11:48]: [Server #615782] Sending 0.26 MB of payload data to client #871 (simulated).
[INFO][15:11:48]: [Client #192] Selected by the server.
[INFO][15:11:48]: [Client #192] Loading its data source...
[INFO][15:11:48]: Data source: FEMNIST
[INFO][15:11:48]: [Client #871] Selected by the server.
[INFO][15:11:48]: [Client #871] Loading its data source...
[INFO][15:11:48]: Data source: FEMNIST
[INFO][15:11:48]: [Client #871] Dataset size: 153
[INFO][15:11:48]: [Client #871] Sampler: all_inclusive
[INFO][15:11:48]: [Client #871] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:11:48]: [93m[1m[Client #871] Started training in communication round #11.[0m
[INFO][15:11:48]: [Client #192] Dataset size: 158
[INFO][15:11:48]: [Client #192] Sampler: all_inclusive
[INFO][15:11:48]: [Client #192] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:11:48]: [93m[1m[Client #192] Started training in communication round #11.[0m
[INFO][15:11:50]: [Client #871] Loading the dataset.
[INFO][15:11:50]: [Client #192] Loading the dataset.
[INFO][15:11:57]: [Client #871] Epoch: [1/5][0/16]	Loss: 0.966057
[INFO][15:11:57]: [Client #871] Epoch: [1/5][10/16]	Loss: 0.941341
[INFO][15:11:57]: [Client #192] Epoch: [1/5][0/16]	Loss: 0.462121
[INFO][15:11:57]: [Client #871] Going to sleep for 0.06 seconds.
[INFO][15:11:57]: [Client #871] Woke up.
[INFO][15:11:57]: [Client #192] Epoch: [1/5][10/16]	Loss: 1.121791
[INFO][15:11:57]: [Client #871] Epoch: [2/5][0/16]	Loss: 0.687783
[INFO][15:11:57]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][15:11:57]: [Client #871] Epoch: [2/5][10/16]	Loss: 1.739106
[INFO][15:11:57]: [Client #192] Woke up.
[INFO][15:11:57]: [Client #871] Going to sleep for 0.06 seconds.
[INFO][15:11:57]: [Client #192] Epoch: [2/5][0/16]	Loss: 0.963271
[INFO][15:11:57]: [Client #871] Woke up.
[INFO][15:11:57]: [Client #871] Epoch: [3/5][0/16]	Loss: 0.202514
[INFO][15:11:57]: [Client #192] Epoch: [2/5][10/16]	Loss: 0.695526
[INFO][15:11:57]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][15:11:57]: [Client #871] Epoch: [3/5][10/16]	Loss: 0.844095
[INFO][15:11:57]: [Client #871] Going to sleep for 0.06 seconds.
[INFO][15:11:57]: [Client #192] Woke up.
[INFO][15:11:57]: [Client #192] Epoch: [3/5][0/16]	Loss: 1.591142
[INFO][15:11:58]: [Client #871] Woke up.
[INFO][15:11:58]: [Client #871] Epoch: [4/5][0/16]	Loss: 1.365938
[INFO][15:11:58]: [Client #192] Epoch: [3/5][10/16]	Loss: 1.965250
[INFO][15:11:58]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][15:11:58]: [Client #871] Epoch: [4/5][10/16]	Loss: 0.574207
[INFO][15:11:58]: [Client #871] Going to sleep for 0.06 seconds.
[INFO][15:11:58]: [Client #192] Woke up.
[INFO][15:11:58]: [Client #192] Epoch: [4/5][0/16]	Loss: 1.171213
[INFO][15:11:58]: [Client #871] Woke up.
[INFO][15:11:58]: [Client #871] Epoch: [5/5][0/16]	Loss: 1.281667
[INFO][15:11:58]: [Client #192] Epoch: [4/5][10/16]	Loss: 1.635042
[INFO][15:11:58]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][15:11:58]: [Client #871] Epoch: [5/5][10/16]	Loss: 0.536963
[INFO][15:11:58]: [Client #871] Going to sleep for 0.06 seconds.
[INFO][15:11:58]: [Client #192] Woke up.
[INFO][15:11:58]: [Client #192] Epoch: [5/5][0/16]	Loss: 0.607534
[INFO][15:11:58]: [Client #871] Woke up.
[INFO][15:11:58]: [Client #871] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_871_615875.pth.
[INFO][15:11:58]: [Client #192] Epoch: [5/5][10/16]	Loss: 1.540380
[INFO][15:11:58]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][15:11:58]: [Client #192] Woke up.
[INFO][15:11:58]: [Client #192] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_615874.pth.
[INFO][15:11:59]: [Client #871] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_871_615875.pth.
[INFO][15:11:59]: [Client #871] Model trained.
[INFO][15:11:59]: [Client #871] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:11:59]: [Server #615782] Received 0.26 MB of payload data from client #871 (simulated).
[INFO][15:11:59]: [Client #192] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_615874.pth.
[INFO][15:11:59]: [Client #192] Model trained.
[INFO][15:11:59]: [Client #192] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:11:59]: [Server #615782] Received 0.26 MB of payload data from client #192 (simulated).
[INFO][15:11:59]: [Server #615782] Selecting client #88 for training.
[INFO][15:11:59]: [Server #615782] Sending the current model to client #88 (simulated).
[INFO][15:11:59]: [Server #615782] Sending 0.26 MB of payload data to client #88 (simulated).
[INFO][15:11:59]: [Server #615782] Selecting client #685 for training.
[INFO][15:11:59]: [Server #615782] Sending the current model to client #685 (simulated).
[INFO][15:11:59]: [Server #615782] Sending 0.26 MB of payload data to client #685 (simulated).
[INFO][15:11:59]: [Client #88] Selected by the server.
[INFO][15:11:59]: [Client #88] Loading its data source...
[INFO][15:11:59]: Data source: FEMNIST
[INFO][15:11:59]: [Client #685] Selected by the server.
[INFO][15:11:59]: [Client #685] Loading its data source...
[INFO][15:11:59]: Data source: FEMNIST
[INFO][15:11:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:11:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/685.zip.
[INFO][15:11:59]: [Client #88] Dataset size: 162
[INFO][15:11:59]: [Client #88] Sampler: all_inclusive
[INFO][15:11:59]: [Client #88] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:11:59]: [93m[1m[Client #88] Started training in communication round #11.[0m
2.5%5.0%7.5%10.0%12.5%15.1%17.6%20.1%22.6%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.6%45.2%47.7%50.2%52.7%55.2%57.7%60.2%62.7%65.2%67.7%70.2%72.8%75.3%77.8%80.3%82.8%85.3%87.8%90.3%92.8%95.3%97.8%100.0%[INFO][15:11:59]: Decompressing the dataset downloaded.
[INFO][15:11:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/685.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:11:59]: [Client #685] Dataset size: 152
[INFO][15:11:59]: [Client #685] Sampler: all_inclusive
[INFO][15:11:59]: [Client #685] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:11:59]: [93m[1m[Client #685] Started training in communication round #11.[0m

[INFO][15:12:01]: [Client #88] Loading the dataset.
[INFO][15:12:01]: [Client #685] Loading the dataset.
[INFO][15:12:09]: [Client #88] Epoch: [1/5][0/17]	Loss: 0.710300
[INFO][15:12:09]: [Client #88] Epoch: [1/5][10/17]	Loss: 0.763631
[INFO][15:12:09]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][15:12:09]: [Client #685] Epoch: [1/5][0/16]	Loss: 1.366642
[INFO][15:12:09]: [Client #685] Epoch: [1/5][10/16]	Loss: 0.877302
[INFO][15:12:09]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][15:12:09]: [Client #685] Woke up.
[INFO][15:12:09]: [Client #685] Epoch: [2/5][0/16]	Loss: 0.170991
[INFO][15:12:10]: [Client #685] Epoch: [2/5][10/16]	Loss: 3.046010
[INFO][15:12:10]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][15:12:10]: [Client #685] Woke up.
[INFO][15:12:10]: [Client #685] Epoch: [3/5][0/16]	Loss: 1.254048
[INFO][15:12:10]: [Client #685] Epoch: [3/5][10/16]	Loss: 1.448940
[INFO][15:12:10]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][15:12:11]: [Client #685] Woke up.
[INFO][15:12:11]: [Client #685] Epoch: [4/5][0/16]	Loss: 0.422530
[INFO][15:12:11]: [Client #685] Epoch: [4/5][10/16]	Loss: 0.922886
[INFO][15:12:11]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][15:12:12]: [Client #685] Woke up.
[INFO][15:12:12]: [Client #685] Epoch: [5/5][0/16]	Loss: 0.631086
[INFO][15:12:12]: [Client #685] Epoch: [5/5][10/16]	Loss: 1.841090
[INFO][15:12:12]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][15:12:12]: [Client #685] Woke up.
[INFO][15:12:12]: [Client #685] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_685_615875.pth.
[INFO][15:12:13]: [Client #685] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_685_615875.pth.
[INFO][15:12:13]: [Client #685] Model trained.
[INFO][15:12:13]: [Client #685] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:12:13]: [Server #615782] Received 0.26 MB of payload data from client #685 (simulated).
[INFO][15:12:36]: [Client #88] Woke up.
[INFO][15:12:36]: [Client #88] Epoch: [2/5][0/17]	Loss: 0.318487
[INFO][15:12:36]: [Client #88] Epoch: [2/5][10/17]	Loss: 1.400531
[INFO][15:12:36]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][15:13:04]: [Client #88] Woke up.
[INFO][15:13:04]: [Client #88] Epoch: [3/5][0/17]	Loss: 0.403335
[INFO][15:13:04]: [Client #88] Epoch: [3/5][10/17]	Loss: 2.361837
[INFO][15:13:04]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][15:13:32]: [Client #88] Woke up.
[INFO][15:13:32]: [Client #88] Epoch: [4/5][0/17]	Loss: 1.434718
[INFO][15:13:32]: [Client #88] Epoch: [4/5][10/17]	Loss: 3.164025
[INFO][15:13:32]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][15:13:59]: [Client #88] Woke up.
[INFO][15:13:59]: [Client #88] Epoch: [5/5][0/17]	Loss: 1.481048
[INFO][15:14:00]: [Client #88] Epoch: [5/5][10/17]	Loss: 0.725380
[INFO][15:14:00]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][15:14:27]: [Client #88] Woke up.
[INFO][15:14:27]: [Client #88] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_615874.pth.
[INFO][15:14:28]: [Client #88] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_615874.pth.
[INFO][15:14:28]: [Client #88] Model trained.
[INFO][15:14:28]: [Client #88] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:14:28]: [Server #615782] Received 0.26 MB of payload data from client #88 (simulated).
[INFO][15:14:28]: [Server #615782] Selecting client #120 for training.
[INFO][15:14:28]: [Server #615782] Sending the current model to client #120 (simulated).
[INFO][15:14:28]: [Server #615782] Sending 0.26 MB of payload data to client #120 (simulated).
[INFO][15:14:28]: [Server #615782] Selecting client #11 for training.
[INFO][15:14:28]: [Server #615782] Sending the current model to client #11 (simulated).
[INFO][15:14:28]: [Server #615782] Sending 0.26 MB of payload data to client #11 (simulated).
[INFO][15:14:28]: [Client #120] Selected by the server.
[INFO][15:14:28]: [Client #120] Loading its data source...
[INFO][15:14:28]: Data source: FEMNIST
[INFO][15:14:28]: [Client #11] Selected by the server.
[INFO][15:14:28]: [Client #11] Loading its data source...
[INFO][15:14:28]: Data source: FEMNIST
[INFO][15:14:28]: [Client #11] Dataset size: 153
[INFO][15:14:28]: [Client #11] Sampler: all_inclusive
[INFO][15:14:28]: [Client #11] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:28]: [93m[1m[Client #11] Started training in communication round #11.[0m
[INFO][15:14:28]: [Client #120] Dataset size: 154
[INFO][15:14:28]: [Client #120] Sampler: all_inclusive
[INFO][15:14:28]: [Client #120] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:28]: [93m[1m[Client #120] Started training in communication round #11.[0m
[INFO][15:14:30]: [Client #11] Loading the dataset.
[INFO][15:14:30]: [Client #120] Loading the dataset.
[INFO][15:14:37]: [Client #11] Epoch: [1/5][0/16]	Loss: 1.528015
[INFO][15:14:38]: [Client #120] Epoch: [1/5][0/16]	Loss: 0.808312
[INFO][15:14:38]: [Client #11] Epoch: [1/5][10/16]	Loss: 0.960004
[INFO][15:14:38]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][15:14:38]: [Client #120] Epoch: [1/5][10/16]	Loss: 1.283328
[INFO][15:14:38]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][15:14:38]: [Client #120] Woke up.
[INFO][15:14:38]: [Client #120] Epoch: [2/5][0/16]	Loss: 2.596286
[INFO][15:14:38]: [Client #120] Epoch: [2/5][10/16]	Loss: 0.936829
[INFO][15:14:38]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][15:14:38]: [Client #120] Woke up.
[INFO][15:14:38]: [Client #120] Epoch: [3/5][0/16]	Loss: 0.725280
[INFO][15:14:38]: [Client #120] Epoch: [3/5][10/16]	Loss: 0.516519
[INFO][15:14:38]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][15:14:38]: [Client #11] Woke up.
[INFO][15:14:38]: [Client #11] Epoch: [2/5][0/16]	Loss: 0.944154
[INFO][15:14:38]: [Client #120] Woke up.
[INFO][15:14:38]: [Client #120] Epoch: [4/5][0/16]	Loss: 2.044070
[INFO][15:14:38]: [Client #11] Epoch: [2/5][10/16]	Loss: 0.515110
[INFO][15:14:38]: [Client #120] Epoch: [4/5][10/16]	Loss: 0.765613
[INFO][15:14:38]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][15:14:39]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][15:14:39]: [Client #120] Woke up.
[INFO][15:14:39]: [Client #120] Epoch: [5/5][0/16]	Loss: 0.579512
[INFO][15:14:39]: [Client #120] Epoch: [5/5][10/16]	Loss: 1.317957
[INFO][15:14:39]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][15:14:39]: [Client #120] Woke up.
[INFO][15:14:39]: [Client #120] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_615874.pth.
[INFO][15:14:39]: [Client #11] Woke up.
[INFO][15:14:39]: [Client #11] Epoch: [3/5][0/16]	Loss: 1.816561
[INFO][15:14:39]: [Client #11] Epoch: [3/5][10/16]	Loss: 1.905612
[INFO][15:14:39]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][15:14:40]: [Client #120] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_615874.pth.
[INFO][15:14:40]: [Client #120] Model trained.
[INFO][15:14:40]: [Client #120] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:14:40]: [Server #615782] Received 0.26 MB of payload data from client #120 (simulated).
[INFO][15:14:40]: [Client #11] Woke up.
[INFO][15:14:40]: [Client #11] Epoch: [4/5][0/16]	Loss: 0.896790
[INFO][15:14:40]: [Client #11] Epoch: [4/5][10/16]	Loss: 0.099675
[INFO][15:14:40]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][15:14:41]: [Client #11] Woke up.
[INFO][15:14:41]: [Client #11] Epoch: [5/5][0/16]	Loss: 1.060266
[INFO][15:14:41]: [Client #11] Epoch: [5/5][10/16]	Loss: 0.739990
[INFO][15:14:41]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][15:14:42]: [Client #11] Woke up.
[INFO][15:14:42]: [Client #11] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_615875.pth.
[INFO][15:14:43]: [Client #11] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_615875.pth.
[INFO][15:14:43]: [Client #11] Model trained.
[INFO][15:14:43]: [Client #11] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:14:43]: [Server #615782] Received 0.26 MB of payload data from client #11 (simulated).
[INFO][15:14:43]: [Server #615782] Selecting client #560 for training.
[INFO][15:14:43]: [Server #615782] Sending the current model to client #560 (simulated).
[INFO][15:14:43]: [Server #615782] Sending 0.26 MB of payload data to client #560 (simulated).
[INFO][15:14:43]: [Server #615782] Selecting client #908 for training.
[INFO][15:14:43]: [Server #615782] Sending the current model to client #908 (simulated).
[INFO][15:14:43]: [Server #615782] Sending 0.26 MB of payload data to client #908 (simulated).
[INFO][15:14:43]: [Client #560] Selected by the server.
[INFO][15:14:43]: [Client #560] Loading its data source...
[INFO][15:14:43]: [Client #908] Selected by the server.
[INFO][15:14:43]: Data source: FEMNIST
[INFO][15:14:43]: [Client #908] Loading its data source...
[INFO][15:14:43]: Data source: FEMNIST
[INFO][15:14:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:14:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/908.zip.
[INFO][15:14:43]: [Client #560] Dataset size: 160
[INFO][15:14:43]: [Client #560] Sampler: all_inclusive
[INFO][15:14:43]: [Client #560] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:43]: [93m[1m[Client #560] Started training in communication round #11.[0m
3.0%6.0%9.1%12.1%15.1%18.1%21.1%24.2%27.2%30.2%33.2%36.2%39.3%42.3%45.3%48.3%51.4%54.4%57.4%60.4%63.4%66.5%69.5%72.5%75.5%78.5%81.6%84.6%87.6%90.6%93.6%96.7%99.7%100.0%[INFO][15:14:43]: Decompressing the dataset downloaded.
[INFO][15:14:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/908.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:14:43]: [Client #908] Dataset size: 162
[INFO][15:14:43]: [Client #908] Sampler: all_inclusive
[INFO][15:14:43]: [Client #908] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:43]: [93m[1m[Client #908] Started training in communication round #11.[0m

[INFO][15:14:45]: [Client #560] Loading the dataset.
[INFO][15:14:45]: [Client #908] Loading the dataset.
[INFO][15:14:52]: [Client #560] Epoch: [1/5][0/16]	Loss: 1.304923
[INFO][15:14:52]: [Client #560] Epoch: [1/5][10/16]	Loss: 1.244414
[INFO][15:14:52]: [Client #560] Going to sleep for 0.15 seconds.
[INFO][15:14:52]: [Client #908] Epoch: [1/5][0/17]	Loss: 1.359777
[INFO][15:14:52]: [Client #908] Epoch: [1/5][10/17]	Loss: 1.135922
[INFO][15:14:52]: [Client #560] Woke up.
[INFO][15:14:52]: [Client #908] Going to sleep for 0.06 seconds.
[INFO][15:14:52]: [Client #560] Epoch: [2/5][0/16]	Loss: 0.333725
[INFO][15:14:52]: [Client #908] Woke up.
[INFO][15:14:52]: [Client #908] Epoch: [2/5][0/17]	Loss: 1.091148
[INFO][15:14:52]: [Client #560] Epoch: [2/5][10/16]	Loss: 1.348860
[INFO][15:14:52]: [Client #560] Going to sleep for 0.15 seconds.
[INFO][15:14:52]: [Client #908] Epoch: [2/5][10/17]	Loss: 0.554994
[INFO][15:14:52]: [Client #908] Going to sleep for 0.06 seconds.
[INFO][15:14:53]: [Client #908] Woke up.
[INFO][15:14:53]: [Client #908] Epoch: [3/5][0/17]	Loss: 1.108055
[INFO][15:14:53]: [Client #560] Woke up.
[INFO][15:14:53]: [Client #560] Epoch: [3/5][0/16]	Loss: 0.649401
[INFO][15:14:53]: [Client #908] Epoch: [3/5][10/17]	Loss: 1.076096
[INFO][15:14:53]: [Client #560] Epoch: [3/5][10/16]	Loss: 1.103773
[INFO][15:14:53]: [Client #908] Going to sleep for 0.06 seconds.
[INFO][15:14:53]: [Client #560] Going to sleep for 0.15 seconds.
[INFO][15:14:53]: [Client #908] Woke up.
[INFO][15:14:53]: [Client #908] Epoch: [4/5][0/17]	Loss: 2.169493
[INFO][15:14:53]: [Client #908] Epoch: [4/5][10/17]	Loss: 1.510533
[INFO][15:14:53]: [Client #560] Woke up.
[INFO][15:14:53]: [Client #560] Epoch: [4/5][0/16]	Loss: 0.992398
[INFO][15:14:53]: [Client #908] Going to sleep for 0.06 seconds.
[INFO][15:14:53]: [Client #908] Woke up.
[INFO][15:14:53]: [Client #560] Epoch: [4/5][10/16]	Loss: 1.227468
[INFO][15:14:53]: [Client #908] Epoch: [5/5][0/17]	Loss: 0.797857
[INFO][15:14:53]: [Client #560] Going to sleep for 0.15 seconds.
[INFO][15:14:53]: [Client #908] Epoch: [5/5][10/17]	Loss: 0.661095
[INFO][15:14:53]: [Client #908] Going to sleep for 0.06 seconds.
[INFO][15:14:53]: [Client #908] Woke up.
[INFO][15:14:53]: [Client #560] Woke up.
[INFO][15:14:53]: [Client #908] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_908_615875.pth.
[INFO][15:14:53]: [Client #560] Epoch: [5/5][0/16]	Loss: 0.862485
[INFO][15:14:53]: [Client #560] Epoch: [5/5][10/16]	Loss: 0.702093
[INFO][15:14:53]: [Client #560] Going to sleep for 0.15 seconds.
[INFO][15:14:53]: [Client #560] Woke up.
[INFO][15:14:53]: [Client #560] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_560_615874.pth.
[INFO][15:14:54]: [Client #908] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_908_615875.pth.
[INFO][15:14:54]: [Client #908] Model trained.
[INFO][15:14:54]: [Client #908] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:14:54]: [Server #615782] Received 0.26 MB of payload data from client #908 (simulated).
[INFO][15:14:54]: [Client #560] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_560_615874.pth.
[INFO][15:14:54]: [Client #560] Model trained.
[INFO][15:14:54]: [Client #560] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:14:54]: [Server #615782] Received 0.26 MB of payload data from client #560 (simulated).
[INFO][15:14:54]: [Server #615782] Selecting client #862 for training.
[INFO][15:14:54]: [Server #615782] Sending the current model to client #862 (simulated).
[INFO][15:14:54]: [Server #615782] Sending 0.26 MB of payload data to client #862 (simulated).
[INFO][15:14:54]: [Server #615782] Selecting client #340 for training.
[INFO][15:14:54]: [Server #615782] Sending the current model to client #340 (simulated).
[INFO][15:14:54]: [Server #615782] Sending 0.26 MB of payload data to client #340 (simulated).
[INFO][15:14:54]: [Client #862] Selected by the server.
[INFO][15:14:54]: [Client #862] Loading its data source...
[INFO][15:14:54]: Data source: FEMNIST
[INFO][15:14:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:14:54]: [Client #340] Selected by the server.
[INFO][15:14:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/862.zip.
[INFO][15:14:54]: [Client #340] Loading its data source...
[INFO][15:14:54]: Data source: FEMNIST
[INFO][15:14:54]: [Client #340] Dataset size: 155
[INFO][15:14:54]: [Client #340] Sampler: all_inclusive
[INFO][15:14:54]: [Client #340] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:54]: [93m[1m[Client #340] Started training in communication round #11.[0m
3.6%7.1%10.7%14.3%17.8%21.4%25.0%28.5%32.1%35.7%39.2%42.8%46.4%49.9%53.5%57.0%60.6%64.2%67.7%71.3%74.9%78.4%82.0%85.6%89.1%92.7%96.3%99.8%100.0%[INFO][15:14:54]: Decompressing the dataset downloaded.
[INFO][15:14:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/862.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:14:54]: [Client #862] Dataset size: 160
[INFO][15:14:54]: [Client #862] Sampler: all_inclusive
[INFO][15:14:54]: [Client #862] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:14:54]: [93m[1m[Client #862] Started training in communication round #11.[0m

[INFO][15:14:56]: [Client #340] Loading the dataset.
[INFO][15:14:56]: [Client #862] Loading the dataset.
[INFO][15:15:04]: [Client #862] Epoch: [1/5][0/16]	Loss: 2.356323
[INFO][15:15:04]: [Client #340] Epoch: [1/5][0/16]	Loss: 1.230037
[INFO][15:15:04]: [Client #862] Epoch: [1/5][10/16]	Loss: 0.634742
[INFO][15:15:04]: [Client #862] Going to sleep for 0.88 seconds.
[INFO][15:15:04]: [Client #340] Epoch: [1/5][10/16]	Loss: 1.646907
[INFO][15:15:04]: [Client #340] Going to sleep for 1.17 seconds.
[INFO][15:15:05]: [Client #862] Woke up.
[INFO][15:15:05]: [Client #862] Epoch: [2/5][0/16]	Loss: 1.648908
[INFO][15:15:05]: [Client #862] Epoch: [2/5][10/16]	Loss: 1.181104
[INFO][15:15:05]: [Client #862] Going to sleep for 0.88 seconds.
[INFO][15:15:05]: [Client #340] Woke up.
[INFO][15:15:05]: [Client #340] Epoch: [2/5][0/16]	Loss: 0.484022
[INFO][15:15:05]: [Client #340] Epoch: [2/5][10/16]	Loss: 2.405715
[INFO][15:15:05]: [Client #340] Going to sleep for 1.17 seconds.
[INFO][15:15:06]: [Client #862] Woke up.
[INFO][15:15:06]: [Client #862] Epoch: [3/5][0/16]	Loss: 1.039559
[INFO][15:15:06]: [Client #862] Epoch: [3/5][10/16]	Loss: 1.248810
[INFO][15:15:06]: [Client #862] Going to sleep for 0.88 seconds.
[INFO][15:15:06]: [Client #340] Woke up.
[INFO][15:15:06]: [Client #340] Epoch: [3/5][0/16]	Loss: 1.393192
[INFO][15:15:06]: [Client #340] Epoch: [3/5][10/16]	Loss: 0.743363
[INFO][15:15:06]: [Client #340] Going to sleep for 1.17 seconds.
[INFO][15:15:07]: [Client #862] Woke up.
[INFO][15:15:07]: [Client #862] Epoch: [4/5][0/16]	Loss: 3.628242
[INFO][15:15:07]: [Client #862] Epoch: [4/5][10/16]	Loss: 1.337831
[INFO][15:15:07]: [Client #862] Going to sleep for 0.88 seconds.
[INFO][15:15:08]: [Client #340] Woke up.
[INFO][15:15:08]: [Client #340] Epoch: [4/5][0/16]	Loss: 1.893254
[INFO][15:15:08]: [Client #862] Woke up.
[INFO][15:15:08]: [Client #862] Epoch: [5/5][0/16]	Loss: 1.959133
[INFO][15:15:08]: [Client #340] Epoch: [4/5][10/16]	Loss: 1.098340
[INFO][15:15:08]: [Client #340] Going to sleep for 1.17 seconds.
[INFO][15:15:08]: [Client #862] Epoch: [5/5][10/16]	Loss: 1.882428
[INFO][15:15:08]: [Client #862] Going to sleep for 0.88 seconds.
[INFO][15:15:09]: [Client #862] Woke up.
[INFO][15:15:09]: [Client #862] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_862_615874.pth.
[INFO][15:15:09]: [Client #340] Woke up.
[INFO][15:15:09]: [Client #340] Epoch: [5/5][0/16]	Loss: 0.230979
[INFO][15:15:09]: [Client #340] Epoch: [5/5][10/16]	Loss: 1.411898
[INFO][15:15:09]: [Client #340] Going to sleep for 1.17 seconds.
[INFO][15:15:09]: [Client #862] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_862_615874.pth.
[INFO][15:15:09]: [Client #862] Model trained.
[INFO][15:15:10]: [Client #862] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:15:10]: [Server #615782] Received 0.26 MB of payload data from client #862 (simulated).
[INFO][15:15:10]: [Client #340] Woke up.
[INFO][15:15:10]: [Client #340] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_340_615875.pth.
[INFO][15:15:11]: [Client #340] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_340_615875.pth.
[INFO][15:15:11]: [Client #340] Model trained.
[INFO][15:15:11]: [Client #340] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:15:11]: [Server #615782] Received 0.26 MB of payload data from client #340 (simulated).
[INFO][15:15:11]: [Server #615782] Selecting client #28 for training.
[INFO][15:15:11]: [Server #615782] Sending the current model to client #28 (simulated).
[INFO][15:15:11]: [Server #615782] Sending 0.26 MB of payload data to client #28 (simulated).
[INFO][15:15:11]: [Server #615782] Selecting client #802 for training.
[INFO][15:15:11]: [Server #615782] Sending the current model to client #802 (simulated).
[INFO][15:15:11]: [Server #615782] Sending 0.26 MB of payload data to client #802 (simulated).
[INFO][15:15:11]: [Client #28] Selected by the server.
[INFO][15:15:11]: [Client #28] Loading its data source...
[INFO][15:15:11]: Data source: FEMNIST
[INFO][15:15:11]: [Client #802] Selected by the server.
[INFO][15:15:11]: [Client #802] Loading its data source...
[INFO][15:15:11]: Data source: FEMNIST
[INFO][15:15:11]: [Client #802] Dataset size: 137
[INFO][15:15:11]: [Client #802] Sampler: all_inclusive
[INFO][15:15:11]: [Client #802] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:15:11]: [93m[1m[Client #802] Started training in communication round #11.[0m
[INFO][15:15:11]: [Client #28] Dataset size: 153
[INFO][15:15:11]: [Client #28] Sampler: all_inclusive
[INFO][15:15:11]: [Client #28] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:15:11]: [93m[1m[Client #28] Started training in communication round #11.[0m
[INFO][15:15:13]: [Client #802] Loading the dataset.
[INFO][15:15:13]: [Client #28] Loading the dataset.
[INFO][15:15:21]: [Client #28] Epoch: [1/5][0/16]	Loss: 1.907836
[INFO][15:15:21]: [Client #802] Epoch: [1/5][0/14]	Loss: 1.436388
[INFO][15:15:21]: [Client #28] Epoch: [1/5][10/16]	Loss: 1.429618
[INFO][15:15:21]: [Client #802] Epoch: [1/5][10/14]	Loss: 1.237871
[INFO][15:15:21]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:15:21]: [Client #802] Going to sleep for 0.23 seconds.
[INFO][15:15:21]: [Client #28] Woke up.
[INFO][15:15:21]: [Client #28] Epoch: [2/5][0/16]	Loss: 1.120306
[INFO][15:15:21]: [Client #28] Epoch: [2/5][10/16]	Loss: 1.082165
[INFO][15:15:21]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:15:21]: [Client #28] Woke up.
[INFO][15:15:21]: [Client #802] Woke up.
[INFO][15:15:21]: [Client #28] Epoch: [3/5][0/16]	Loss: 0.875637
[INFO][15:15:21]: [Client #802] Epoch: [2/5][0/14]	Loss: 1.260559
[INFO][15:15:21]: [Client #28] Epoch: [3/5][10/16]	Loss: 1.187539
[INFO][15:15:21]: [Client #802] Epoch: [2/5][10/14]	Loss: 1.484272
[INFO][15:15:21]: [Client #802] Going to sleep for 0.23 seconds.
[INFO][15:15:21]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:15:21]: [Client #28] Woke up.
[INFO][15:15:21]: [Client #28] Epoch: [4/5][0/16]	Loss: 0.772796
[INFO][15:15:21]: [Client #28] Epoch: [4/5][10/16]	Loss: 2.524144
[INFO][15:15:22]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:15:22]: [Client #802] Woke up.
[INFO][15:15:22]: [Client #28] Woke up.
[INFO][15:15:22]: [Client #802] Epoch: [3/5][0/14]	Loss: 0.324922
[INFO][15:15:22]: [Client #28] Epoch: [5/5][0/16]	Loss: 1.061666
[INFO][15:15:22]: [Client #802] Epoch: [3/5][10/14]	Loss: 0.884938
[INFO][15:15:22]: [Client #802] Going to sleep for 0.23 seconds.
[INFO][15:15:22]: [Client #28] Epoch: [5/5][10/16]	Loss: 2.688489
[INFO][15:15:22]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:15:22]: [Client #28] Woke up.
[INFO][15:15:22]: [Client #28] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_615874.pth.
[INFO][15:15:22]: [Client #802] Woke up.
[INFO][15:15:22]: [Client #802] Epoch: [4/5][0/14]	Loss: 0.912018
[INFO][15:15:22]: [Client #802] Epoch: [4/5][10/14]	Loss: 1.935754
[INFO][15:15:22]: [Client #802] Going to sleep for 0.23 seconds.
[INFO][15:15:22]: [Client #802] Woke up.
[INFO][15:15:22]: [Client #802] Epoch: [5/5][0/14]	Loss: 0.455001
[INFO][15:15:22]: [Client #802] Epoch: [5/5][10/14]	Loss: 1.307521
[INFO][15:15:22]: [Client #802] Going to sleep for 0.23 seconds.
[INFO][15:15:22]: [Client #28] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_615874.pth.
[INFO][15:15:22]: [Client #28] Model trained.
[INFO][15:15:22]: [Client #28] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:15:23]: [Server #615782] Received 0.26 MB of payload data from client #28 (simulated).
[INFO][15:15:23]: [Client #802] Woke up.
[INFO][15:15:23]: [Client #802] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_802_615875.pth.
[INFO][15:15:23]: [Client #802] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_802_615875.pth.
[INFO][15:15:23]: [Client #802] Model trained.
[INFO][15:15:23]: [Client #802] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:15:23]: [Server #615782] Received 0.26 MB of payload data from client #802 (simulated).
[INFO][15:15:23]: [Server #615782] Selecting client #807 for training.
[INFO][15:15:23]: [Server #615782] Sending the current model to client #807 (simulated).
[INFO][15:15:23]: [Server #615782] Sending 0.26 MB of payload data to client #807 (simulated).
[INFO][15:15:23]: [Server #615782] Selecting client #870 for training.
[INFO][15:15:23]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][15:15:23]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][15:15:23]: [Client #807] Selected by the server.
[INFO][15:15:23]: [Client #807] Loading its data source...
[INFO][15:15:23]: [Client #870] Selected by the server.
[INFO][15:15:23]: Data source: FEMNIST
[INFO][15:15:23]: [Client #870] Loading its data source...
[INFO][15:15:23]: Data source: FEMNIST
[INFO][15:15:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:15:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/807.zip.
[INFO][15:15:23]: [Client #870] Dataset size: 148
[INFO][15:15:23]: [Client #870] Sampler: all_inclusive
[INFO][15:15:23]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:15:23]: [93m[1m[Client #870] Started training in communication round #11.[0m
2.7%5.4%8.0%10.7%13.4%16.1%18.7%21.4%24.1%26.8%29.4%32.1%34.8%37.5%40.2%42.8%45.5%48.2%50.9%53.5%56.2%58.9%61.6%64.2%66.9%69.6%72.3%75.0%77.6%80.3%83.0%85.7%88.3%91.0%93.7%96.4%99.1%100.0%[INFO][15:15:24]: Decompressing the dataset downloaded.
[INFO][15:15:24]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/807.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:15:24]: [Client #807] Dataset size: 157
[INFO][15:15:24]: [Client #807] Sampler: all_inclusive
[INFO][15:15:24]: [Client #807] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:15:24]: [93m[1m[Client #807] Started training in communication round #11.[0m

[INFO][15:15:25]: [Client #870] Loading the dataset.
[INFO][15:15:26]: [Client #807] Loading the dataset.
[INFO][15:15:33]: [Client #870] Epoch: [1/5][0/15]	Loss: 0.603166
[INFO][15:15:33]: [Client #807] Epoch: [1/5][0/16]	Loss: 0.924478
[INFO][15:15:33]: [Client #870] Epoch: [1/5][10/15]	Loss: 0.753167
[INFO][15:15:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:15:33]: [Client #807] Epoch: [1/5][10/16]	Loss: 0.204024
[INFO][15:15:33]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][15:15:34]: [Client #807] Woke up.
[INFO][15:15:34]: [Client #807] Epoch: [2/5][0/16]	Loss: 0.591757
[INFO][15:15:34]: [Client #807] Epoch: [2/5][10/16]	Loss: 1.382637
[INFO][15:15:34]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][15:15:34]: [Client #807] Woke up.
[INFO][15:15:34]: [Client #807] Epoch: [3/5][0/16]	Loss: 1.775369
[INFO][15:15:34]: [Client #807] Epoch: [3/5][10/16]	Loss: 0.917983
[INFO][15:15:34]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][15:15:35]: [Client #807] Woke up.
[INFO][15:15:35]: [Client #807] Epoch: [4/5][0/16]	Loss: 0.458538
[INFO][15:15:35]: [Client #807] Epoch: [4/5][10/16]	Loss: 1.627518
[INFO][15:15:35]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][15:15:35]: [Client #807] Woke up.
[INFO][15:15:35]: [Client #807] Epoch: [5/5][0/16]	Loss: 0.765292
[INFO][15:15:35]: [Client #807] Epoch: [5/5][10/16]	Loss: 1.000547
[INFO][15:15:35]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][15:15:36]: [Client #807] Woke up.
[INFO][15:15:36]: [Client #807] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][15:15:36]: [Client #807] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][15:15:36]: [Client #807] Model trained.
[INFO][15:15:36]: [Client #807] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:15:36]: [Server #615782] Received 0.26 MB of payload data from client #807 (simulated).
[INFO][15:16:33]: [Client #870] Woke up.
[INFO][15:16:33]: [Client #870] Epoch: [2/5][0/15]	Loss: 1.154532
[INFO][15:16:33]: [Client #870] Epoch: [2/5][10/15]	Loss: 1.090832
[INFO][15:16:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:17:33]: [Client #870] Woke up.
[INFO][15:17:34]: [Client #870] Epoch: [3/5][0/15]	Loss: 1.946639
[INFO][15:17:34]: [Client #870] Epoch: [3/5][10/15]	Loss: 1.713751
[INFO][15:17:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:18:34]: [Client #870] Woke up.
[INFO][15:18:34]: [Client #870] Epoch: [4/5][0/15]	Loss: 0.722894
[INFO][15:18:34]: [Client #870] Epoch: [4/5][10/15]	Loss: 2.526521
[INFO][15:18:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:19:34]: [Client #870] Woke up.
[INFO][15:19:34]: [Client #870] Epoch: [5/5][0/15]	Loss: 0.139798
[INFO][15:19:34]: [Client #870] Epoch: [5/5][10/15]	Loss: 0.953966
[INFO][15:19:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:20:34]: [Client #870] Woke up.
[INFO][15:20:34]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615875.pth.
[INFO][15:20:35]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615875.pth.
[INFO][15:20:35]: [Client #870] Model trained.
[INFO][15:20:35]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:20:35]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][15:20:35]: [Server #615782] Selecting client #671 for training.
[INFO][15:20:35]: [Server #615782] Sending the current model to client #671 (simulated).
[INFO][15:20:35]: [Server #615782] Sending 0.26 MB of payload data to client #671 (simulated).
[INFO][15:20:35]: [Server #615782] Selecting client #809 for training.
[INFO][15:20:35]: [Server #615782] Sending the current model to client #809 (simulated).
[INFO][15:20:35]: [Server #615782] Sending 0.26 MB of payload data to client #809 (simulated).
[INFO][15:20:35]: [Client #671] Selected by the server.
[INFO][15:20:35]: [Client #671] Loading its data source...
[INFO][15:20:35]: [Client #809] Selected by the server.
[INFO][15:20:35]: Data source: FEMNIST
[INFO][15:20:35]: [Client #809] Loading its data source...
[INFO][15:20:35]: Data source: FEMNIST
[INFO][15:20:35]: [Client #809] Dataset size: 126
[INFO][15:20:35]: [Client #809] Sampler: all_inclusive
[INFO][15:20:35]: [Client #809] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:20:35]: [Client #671] Dataset size: 162
[INFO][15:20:35]: [Client #671] Sampler: all_inclusive
[INFO][15:20:35]: [Client #671] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:20:35]: [93m[1m[Client #809] Started training in communication round #11.[0m
[INFO][15:20:35]: [93m[1m[Client #671] Started training in communication round #11.[0m
[INFO][15:20:37]: [Client #809] Loading the dataset.
[INFO][15:20:37]: [Client #671] Loading the dataset.
[INFO][15:20:45]: [Client #671] Epoch: [1/5][0/17]	Loss: 0.534121
[INFO][15:20:45]: [Client #809] Epoch: [1/5][0/13]	Loss: 1.603200
[INFO][15:20:45]: [Client #671] Epoch: [1/5][10/17]	Loss: 1.130800
[INFO][15:20:45]: [Client #809] Epoch: [1/5][10/13]	Loss: 2.380848
[INFO][15:20:45]: [Client #809] Going to sleep for 2.15 seconds.
[INFO][15:20:45]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][15:20:47]: [Client #809] Woke up.
[INFO][15:20:47]: [Client #809] Epoch: [2/5][0/13]	Loss: 0.921075
[INFO][15:20:47]: [Client #809] Epoch: [2/5][10/13]	Loss: 1.002335
[INFO][15:20:47]: [Client #809] Going to sleep for 2.15 seconds.
[INFO][15:20:49]: [Client #809] Woke up.
[INFO][15:20:49]: [Client #809] Epoch: [3/5][0/13]	Loss: 1.266834
[INFO][15:20:49]: [Client #809] Epoch: [3/5][10/13]	Loss: 1.389028
[INFO][15:20:50]: [Client #809] Going to sleep for 2.15 seconds.
[INFO][15:20:51]: [Client #671] Woke up.
[INFO][15:20:51]: [Client #671] Epoch: [2/5][0/17]	Loss: 1.028659
[INFO][15:20:51]: [Client #671] Epoch: [2/5][10/17]	Loss: 2.161968
[INFO][15:20:51]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][15:20:52]: [Client #809] Woke up.
[INFO][15:20:52]: [Client #809] Epoch: [4/5][0/13]	Loss: 1.682595
[INFO][15:20:52]: [Client #809] Epoch: [4/5][10/13]	Loss: 1.128094
[INFO][15:20:52]: [Client #809] Going to sleep for 2.15 seconds.
[INFO][15:20:54]: [Client #809] Woke up.
[INFO][15:20:54]: [Client #809] Epoch: [5/5][0/13]	Loss: 0.963231
[INFO][15:20:54]: [Client #809] Epoch: [5/5][10/13]	Loss: 0.797545
[INFO][15:20:54]: [Client #809] Going to sleep for 2.15 seconds.
[INFO][15:20:56]: [Client #809] Woke up.
[INFO][15:20:56]: [Client #809] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_809_615875.pth.
[INFO][15:20:57]: [Client #809] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_809_615875.pth.
[INFO][15:20:57]: [Client #809] Model trained.
[INFO][15:20:57]: [Client #809] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:20:57]: [Server #615782] Received 0.26 MB of payload data from client #809 (simulated).
[INFO][15:20:57]: [Client #671] Woke up.
[INFO][15:20:57]: [Client #671] Epoch: [3/5][0/17]	Loss: 1.373864
[INFO][15:20:58]: [Client #671] Epoch: [3/5][10/17]	Loss: 1.792307
[INFO][15:20:58]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][15:21:04]: [Client #671] Woke up.
[INFO][15:21:04]: [Client #671] Epoch: [4/5][0/17]	Loss: 1.812359
[INFO][15:21:04]: [Client #671] Epoch: [4/5][10/17]	Loss: 1.142564
[INFO][15:21:04]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][15:21:10]: [Client #671] Woke up.
[INFO][15:21:10]: [Client #671] Epoch: [5/5][0/17]	Loss: 1.754961
[INFO][15:21:10]: [Client #671] Epoch: [5/5][10/17]	Loss: 1.321188
[INFO][15:21:10]: [Client #671] Going to sleep for 6.15 seconds.
[INFO][15:21:16]: [Client #671] Woke up.
[INFO][15:21:16]: [Client #671] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_671_615874.pth.
[INFO][15:21:17]: [Client #671] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_671_615874.pth.
[INFO][15:21:17]: [Client #671] Model trained.
[INFO][15:21:17]: [Client #671] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:21:17]: [Server #615782] Received 0.26 MB of payload data from client #671 (simulated).
[INFO][15:21:17]: [Server #615782] Selecting client #898 for training.
[INFO][15:21:17]: [Server #615782] Sending the current model to client #898 (simulated).
[INFO][15:21:17]: [Server #615782] Sending 0.26 MB of payload data to client #898 (simulated).
[INFO][15:21:17]: [Server #615782] Selecting client #456 for training.
[INFO][15:21:17]: [Server #615782] Sending the current model to client #456 (simulated).
[INFO][15:21:17]: [Server #615782] Sending 0.26 MB of payload data to client #456 (simulated).
[INFO][15:21:17]: [Client #898] Selected by the server.
[INFO][15:21:17]: [Client #898] Loading its data source...
[INFO][15:21:17]: Data source: FEMNIST
[INFO][15:21:17]: [Client #456] Selected by the server.
[INFO][15:21:17]: [Client #456] Loading its data source...
[INFO][15:21:17]: Data source: FEMNIST
[INFO][15:21:17]: [Client #898] Dataset size: 155
[INFO][15:21:17]: [Client #898] Sampler: all_inclusive
[INFO][15:21:17]: [Client #898] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:17]: [93m[1m[Client #898] Started training in communication round #11.[0m
[INFO][15:21:17]: [Client #456] Dataset size: 207
[INFO][15:21:17]: [Client #456] Sampler: all_inclusive
[INFO][15:21:17]: [Client #456] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:17]: [93m[1m[Client #456] Started training in communication round #11.[0m
[INFO][15:21:19]: [Client #898] Loading the dataset.
[INFO][15:21:20]: [Client #456] Loading the dataset.
[INFO][15:21:27]: [Client #898] Epoch: [1/5][0/16]	Loss: 2.048656
[INFO][15:21:27]: [Client #456] Epoch: [1/5][0/21]	Loss: 1.949117
[INFO][15:21:27]: [Client #898] Epoch: [1/5][10/16]	Loss: 2.475630
[INFO][15:21:27]: [Client #456] Epoch: [1/5][10/21]	Loss: 0.980354
[INFO][15:21:27]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][15:21:27]: [Client #456] Epoch: [1/5][20/21]	Loss: 1.285233
[INFO][15:21:27]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][15:21:28]: [Client #898] Woke up.
[INFO][15:21:28]: [Client #898] Epoch: [2/5][0/16]	Loss: 1.391646
[INFO][15:21:28]: [Client #898] Epoch: [2/5][10/16]	Loss: 1.495547
[INFO][15:21:28]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][15:21:30]: [Client #898] Woke up.
[INFO][15:21:30]: [Client #898] Epoch: [3/5][0/16]	Loss: 0.660057
[INFO][15:21:30]: [Client #898] Epoch: [3/5][10/16]	Loss: 0.795205
[INFO][15:21:30]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][15:21:30]: [Client #456] Woke up.
[INFO][15:21:30]: [Client #456] Epoch: [2/5][0/21]	Loss: 1.936207
[INFO][15:21:30]: [Client #456] Epoch: [2/5][10/21]	Loss: 1.561886
[INFO][15:21:30]: [Client #456] Epoch: [2/5][20/21]	Loss: 2.787282
[INFO][15:21:30]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][15:21:31]: [Client #898] Woke up.
[INFO][15:21:31]: [Client #898] Epoch: [4/5][0/16]	Loss: 1.620246
[INFO][15:21:31]: [Client #898] Epoch: [4/5][10/16]	Loss: 1.580189
[INFO][15:21:31]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][15:21:32]: [Client #898] Woke up.
[INFO][15:21:32]: [Client #898] Epoch: [5/5][0/16]	Loss: 1.421679
[INFO][15:21:33]: [Client #898] Epoch: [5/5][10/16]	Loss: 2.086782
[INFO][15:21:33]: [Client #898] Going to sleep for 1.24 seconds.
[INFO][15:21:33]: [Client #456] Woke up.
[INFO][15:21:33]: [Client #456] Epoch: [3/5][0/21]	Loss: 1.371618
[INFO][15:21:33]: [Client #456] Epoch: [3/5][10/21]	Loss: 0.620639
[INFO][15:21:33]: [Client #456] Epoch: [3/5][20/21]	Loss: 2.280770
[INFO][15:21:33]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][15:21:34]: [Client #898] Woke up.
[INFO][15:21:34]: [Client #898] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_898_615874.pth.
[INFO][15:21:35]: [Client #898] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_898_615874.pth.
[INFO][15:21:35]: [Client #898] Model trained.
[INFO][15:21:35]: [Client #898] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:21:35]: [Server #615782] Received 0.26 MB of payload data from client #898 (simulated).
[INFO][15:21:36]: [Client #456] Woke up.
[INFO][15:21:36]: [Client #456] Epoch: [4/5][0/21]	Loss: 1.151783
[INFO][15:21:36]: [Client #456] Epoch: [4/5][10/21]	Loss: 1.405079
[INFO][15:21:36]: [Client #456] Epoch: [4/5][20/21]	Loss: 0.500537
[INFO][15:21:36]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][15:21:39]: [Client #456] Woke up.
[INFO][15:21:39]: [Client #456] Epoch: [5/5][0/21]	Loss: 0.560067
[INFO][15:21:39]: [Client #456] Epoch: [5/5][10/21]	Loss: 0.960266
[INFO][15:21:39]: [Client #456] Epoch: [5/5][20/21]	Loss: 2.442765
[INFO][15:21:39]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][15:21:42]: [Client #456] Woke up.
[INFO][15:21:42]: [Client #456] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_456_615875.pth.
[INFO][15:21:42]: [Client #456] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_456_615875.pth.
[INFO][15:21:42]: [Client #456] Model trained.
[INFO][15:21:42]: [Client #456] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:21:42]: [Server #615782] Received 0.26 MB of payload data from client #456 (simulated).
[INFO][15:21:42]: [Server #615782] Selecting client #508 for training.
[INFO][15:21:42]: [Server #615782] Sending the current model to client #508 (simulated).
[INFO][15:21:42]: [Server #615782] Sending 0.26 MB of payload data to client #508 (simulated).
[INFO][15:21:42]: [Server #615782] Selecting client #694 for training.
[INFO][15:21:42]: [Server #615782] Sending the current model to client #694 (simulated).
[INFO][15:21:42]: [Server #615782] Sending 0.26 MB of payload data to client #694 (simulated).
[INFO][15:21:42]: [Client #508] Selected by the server.
[INFO][15:21:42]: [Client #508] Loading its data source...
[INFO][15:21:42]: [Client #694] Selected by the server.
[INFO][15:21:42]: Data source: FEMNIST
[INFO][15:21:42]: [Client #694] Loading its data source...
[INFO][15:21:42]: Data source: FEMNIST
[INFO][15:21:42]: [Client #694] Dataset size: 140
[INFO][15:21:42]: [Client #508] Dataset size: 154
[INFO][15:21:42]: [Client #694] Sampler: all_inclusive
[INFO][15:21:42]: [Client #508] Sampler: all_inclusive
[INFO][15:21:42]: [Client #508] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:42]: [Client #694] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:42]: [93m[1m[Client #508] Started training in communication round #11.[0m
[INFO][15:21:42]: [93m[1m[Client #694] Started training in communication round #11.[0m
[INFO][15:21:44]: [Client #694] Loading the dataset.
[INFO][15:21:44]: [Client #508] Loading the dataset.
[INFO][15:21:51]: [Client #694] Epoch: [1/5][0/14]	Loss: 2.620793
[INFO][15:21:51]: [Client #694] Epoch: [1/5][10/14]	Loss: 1.403302
[INFO][15:21:52]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][15:21:52]: [Client #508] Epoch: [1/5][0/16]	Loss: 0.650781
[INFO][15:21:52]: [Client #508] Epoch: [1/5][10/16]	Loss: 0.695384
[INFO][15:21:52]: [Client #508] Going to sleep for 0.23 seconds.
[INFO][15:21:52]: [Client #694] Woke up.
[INFO][15:21:52]: [Client #694] Epoch: [2/5][0/14]	Loss: 1.265749
[INFO][15:21:52]: [Client #508] Woke up.
[INFO][15:21:52]: [Client #508] Epoch: [2/5][0/16]	Loss: 0.647683
[INFO][15:21:52]: [Client #694] Epoch: [2/5][10/14]	Loss: 1.246696
[INFO][15:21:52]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][15:21:52]: [Client #508] Epoch: [2/5][10/16]	Loss: 0.868783
[INFO][15:21:52]: [Client #508] Going to sleep for 0.23 seconds.
[INFO][15:21:52]: [Client #508] Woke up.
[INFO][15:21:52]: [Client #508] Epoch: [3/5][0/16]	Loss: 1.211597
[INFO][15:21:52]: [Client #694] Woke up.
[INFO][15:21:52]: [Client #694] Epoch: [3/5][0/14]	Loss: 0.831140
[INFO][15:21:52]: [Client #508] Epoch: [3/5][10/16]	Loss: 2.194336
[INFO][15:21:52]: [Client #694] Epoch: [3/5][10/14]	Loss: 1.253777
[INFO][15:21:52]: [Client #508] Going to sleep for 0.23 seconds.
[INFO][15:21:52]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][15:21:53]: [Client #508] Woke up.
[INFO][15:21:53]: [Client #508] Epoch: [4/5][0/16]	Loss: 0.909036
[INFO][15:21:53]: [Client #694] Woke up.
[INFO][15:21:53]: [Client #508] Epoch: [4/5][10/16]	Loss: 0.772315
[INFO][15:21:53]: [Client #694] Epoch: [4/5][0/14]	Loss: 1.887988
[INFO][15:21:53]: [Client #508] Going to sleep for 0.23 seconds.
[INFO][15:21:53]: [Client #694] Epoch: [4/5][10/14]	Loss: 0.982732
[INFO][15:21:53]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][15:21:53]: [Client #508] Woke up.
[INFO][15:21:53]: [Client #508] Epoch: [5/5][0/16]	Loss: 1.607704
[INFO][15:21:53]: [Client #508] Epoch: [5/5][10/16]	Loss: 0.563018
[INFO][15:21:53]: [Client #508] Going to sleep for 0.23 seconds.
[INFO][15:21:53]: [Client #694] Woke up.
[INFO][15:21:53]: [Client #694] Epoch: [5/5][0/14]	Loss: 0.700526
[INFO][15:21:53]: [Client #694] Epoch: [5/5][10/14]	Loss: 0.697302
[INFO][15:21:53]: [Client #694] Going to sleep for 0.31 seconds.
[INFO][15:21:53]: [Client #508] Woke up.
[INFO][15:21:53]: [Client #508] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_508_615874.pth.
[INFO][15:21:54]: [Client #694] Woke up.
[INFO][15:21:54]: [Client #694] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_694_615875.pth.
[INFO][15:21:54]: [Client #508] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_508_615874.pth.
[INFO][15:21:54]: [Client #508] Model trained.
[INFO][15:21:54]: [Client #508] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:21:54]: [Server #615782] Received 0.26 MB of payload data from client #508 (simulated).
[INFO][15:21:54]: [Client #694] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_694_615875.pth.
[INFO][15:21:54]: [Client #694] Model trained.
[INFO][15:21:54]: [Client #694] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:21:54]: [Server #615782] Received 0.26 MB of payload data from client #694 (simulated).
[INFO][15:21:54]: [Server #615782] Selecting client #523 for training.
[INFO][15:21:54]: [Server #615782] Sending the current model to client #523 (simulated).
[INFO][15:21:54]: [Server #615782] Sending 0.26 MB of payload data to client #523 (simulated).
[INFO][15:21:54]: [Server #615782] Selecting client #828 for training.
[INFO][15:21:54]: [Server #615782] Sending the current model to client #828 (simulated).
[INFO][15:21:54]: [Server #615782] Sending 0.26 MB of payload data to client #828 (simulated).
[INFO][15:21:54]: [Client #828] Selected by the server.
[INFO][15:21:54]: [Client #523] Selected by the server.
[INFO][15:21:54]: [Client #828] Loading its data source...
[INFO][15:21:54]: [Client #523] Loading its data source...
[INFO][15:21:54]: Data source: FEMNIST
[INFO][15:21:54]: Data source: FEMNIST
[INFO][15:21:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:21:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/828.zip.
[INFO][15:21:54]: [Client #523] Dataset size: 165
[INFO][15:21:54]: [Client #523] Sampler: all_inclusive
[INFO][15:21:54]: [Client #523] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:54]: [93m[1m[Client #523] Started training in communication round #11.[0m
2.8%5.7%8.5%11.3%14.2%17.0%19.8%22.6%25.5%28.3%31.1%34.0%36.8%39.6%42.5%45.3%48.1%51.0%53.8%56.6%59.4%62.3%65.1%67.9%70.8%73.6%76.4%79.3%82.1%84.9%87.8%90.6%93.4%96.2%99.1%100.0%[INFO][15:21:55]: Decompressing the dataset downloaded.
[INFO][15:21:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/828.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:21:55]: [Client #828] Dataset size: 142
[INFO][15:21:55]: [Client #828] Sampler: all_inclusive
[INFO][15:21:55]: [Client #828] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:21:55]: [93m[1m[Client #828] Started training in communication round #11.[0m

[INFO][15:21:56]: [Client #523] Loading the dataset.
[INFO][15:21:56]: [Client #828] Loading the dataset.
[INFO][15:22:03]: [Client #523] Epoch: [1/5][0/17]	Loss: 0.694061
[INFO][15:22:04]: [Client #828] Epoch: [1/5][0/15]	Loss: 1.544013
[INFO][15:22:04]: [Client #523] Epoch: [1/5][10/17]	Loss: 1.049925
[INFO][15:22:04]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][15:22:04]: [Client #828] Epoch: [1/5][10/15]	Loss: 2.361720
[INFO][15:22:04]: [Client #828] Going to sleep for 0.06 seconds.
[INFO][15:22:04]: [Client #828] Woke up.
[INFO][15:22:04]: [Client #828] Epoch: [2/5][0/15]	Loss: 0.816169
[INFO][15:22:04]: [Client #828] Epoch: [2/5][10/15]	Loss: 0.581740
[INFO][15:22:04]: [Client #828] Going to sleep for 0.06 seconds.
[INFO][15:22:04]: [Client #828] Woke up.
[INFO][15:22:04]: [Client #828] Epoch: [3/5][0/15]	Loss: 1.350786
[INFO][15:22:04]: [Client #828] Epoch: [3/5][10/15]	Loss: 1.611691
[INFO][15:22:04]: [Client #828] Going to sleep for 0.06 seconds.
[INFO][15:22:04]: [Client #828] Woke up.
[INFO][15:22:04]: [Client #828] Epoch: [4/5][0/15]	Loss: 1.071868
[INFO][15:22:04]: [Client #828] Epoch: [4/5][10/15]	Loss: 1.675211
[INFO][15:22:04]: [Client #828] Going to sleep for 0.06 seconds.
[INFO][15:22:04]: [Client #828] Woke up.
[INFO][15:22:04]: [Client #828] Epoch: [5/5][0/15]	Loss: 1.663612
[INFO][15:22:04]: [Client #828] Epoch: [5/5][10/15]	Loss: 2.182144
[INFO][15:22:04]: [Client #828] Going to sleep for 0.06 seconds.
[INFO][15:22:05]: [Client #828] Woke up.
[INFO][15:22:05]: [Client #828] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_828_615875.pth.
[INFO][15:22:05]: [Client #828] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_828_615875.pth.
[INFO][15:22:05]: [Client #828] Model trained.
[INFO][15:22:05]: [Client #828] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:22:05]: [Server #615782] Received 0.26 MB of payload data from client #828 (simulated).
[INFO][15:22:44]: [Client #523] Woke up.
[INFO][15:22:44]: [Client #523] Epoch: [2/5][0/17]	Loss: 0.282440
[INFO][15:22:45]: [Client #523] Epoch: [2/5][10/17]	Loss: 1.077898
[INFO][15:22:45]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][15:23:25]: [Client #523] Woke up.
[INFO][15:23:25]: [Client #523] Epoch: [3/5][0/17]	Loss: 1.014646
[INFO][15:23:25]: [Client #523] Epoch: [3/5][10/17]	Loss: 2.286531
[INFO][15:23:26]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][15:24:06]: [Client #523] Woke up.
[INFO][15:24:06]: [Client #523] Epoch: [4/5][0/17]	Loss: 1.026034
[INFO][15:24:06]: [Client #523] Epoch: [4/5][10/17]	Loss: 0.599660
[INFO][15:24:06]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][15:24:47]: [Client #523] Woke up.
[INFO][15:24:47]: [Client #523] Epoch: [5/5][0/17]	Loss: 0.998919
[INFO][15:24:47]: [Client #523] Epoch: [5/5][10/17]	Loss: 0.742525
[INFO][15:24:47]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][15:25:28]: [Client #523] Woke up.
[INFO][15:25:28]: [Client #523] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_523_615874.pth.
[INFO][15:25:29]: [Client #523] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_523_615874.pth.
[INFO][15:25:29]: [Client #523] Model trained.
[INFO][15:25:29]: [Client #523] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:25:29]: [Server #615782] Received 0.26 MB of payload data from client #523 (simulated).
[INFO][15:25:29]: [Server #615782] Selecting client #503 for training.
[INFO][15:25:29]: [Server #615782] Sending the current model to client #503 (simulated).
[INFO][15:25:29]: [Server #615782] Sending 0.26 MB of payload data to client #503 (simulated).
[INFO][15:25:29]: [Client #503] Selected by the server.
[INFO][15:25:29]: [Client #503] Loading its data source...
[INFO][15:25:29]: Data source: FEMNIST
[INFO][15:25:29]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:25:29]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/503.zip.
2.5%5.1%7.6%10.2%12.7%15.3%17.8%20.4%22.9%25.5%28.0%30.6%33.1%35.6%38.2%40.7%43.3%45.8%48.4%50.9%53.5%56.0%58.6%61.1%63.6%66.2%68.7%71.3%73.8%76.4%78.9%81.5%84.0%86.6%89.1%91.7%94.2%96.7%99.3%100.0%[INFO][15:25:29]: Decompressing the dataset downloaded.
[INFO][15:25:29]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/503.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:25:29]: [Client #503] Dataset size: 161
[INFO][15:25:29]: [Client #503] Sampler: all_inclusive
[INFO][15:25:29]: [Client #503] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:25:29]: [93m[1m[Client #503] Started training in communication round #11.[0m

[INFO][15:25:31]: [Client #503] Loading the dataset.
[INFO][15:25:38]: [Client #503] Epoch: [1/5][0/17]	Loss: 1.505653
[INFO][15:25:38]: [Client #503] Epoch: [1/5][10/17]	Loss: 1.126950
[INFO][15:25:38]: [Client #503] Going to sleep for 0.46 seconds.
[INFO][15:25:39]: [Client #503] Woke up.
[INFO][15:25:39]: [Client #503] Epoch: [2/5][0/17]	Loss: 1.077728
[INFO][15:25:39]: [Client #503] Epoch: [2/5][10/17]	Loss: 1.910144
[INFO][15:25:39]: [Client #503] Going to sleep for 0.46 seconds.
[INFO][15:25:39]: [Client #503] Woke up.
[INFO][15:25:39]: [Client #503] Epoch: [3/5][0/17]	Loss: 0.328096
[INFO][15:25:39]: [Client #503] Epoch: [3/5][10/17]	Loss: 1.690771
[INFO][15:25:39]: [Client #503] Going to sleep for 0.46 seconds.
[INFO][15:25:40]: [Client #503] Woke up.
[INFO][15:25:40]: [Client #503] Epoch: [4/5][0/17]	Loss: 0.920037
[INFO][15:25:40]: [Client #503] Epoch: [4/5][10/17]	Loss: 0.816904
[INFO][15:25:40]: [Client #503] Going to sleep for 0.46 seconds.
[INFO][15:25:40]: [Client #503] Woke up.
[INFO][15:25:40]: [Client #503] Epoch: [5/5][0/17]	Loss: 0.632370
[INFO][15:25:41]: [Client #503] Epoch: [5/5][10/17]	Loss: 0.912246
[INFO][15:25:41]: [Client #503] Going to sleep for 0.46 seconds.
[INFO][15:25:41]: [Client #503] Woke up.
[INFO][15:25:41]: [Client #503] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_503_615874.pth.
[INFO][15:25:42]: [Client #503] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_503_615874.pth.
[INFO][15:25:42]: [Client #503] Model trained.
[INFO][15:25:42]: [Client #503] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:25:42]: [Server #615782] Received 0.26 MB of payload data from client #503 (simulated).
[INFO][15:25:42]: [Server #615782] Adding client #828 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #184 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #908 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #28 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #871 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #192 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #560 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #120 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #508 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #694 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #802 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #503 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #807 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #685 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #11 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #862 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #340 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #898 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #809 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #456 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #671 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #454 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #88 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #523 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Adding client #520 to the list of clients for aggregation.
[INFO][15:25:42]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10261677 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11857414 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18177571 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07109998
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09875189 0.         0.
 0.         0.         0.         0.         0.         0.10273611
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0788034  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10469878 0.         0.13429476
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08714977 0.
 0.         0.         0.         0.0915243  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17848853 0.         0.
 0.15085557 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07652006 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21642269 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11621211 0.         0.         0.         0.         0.
 0.         0.         0.         0.11910046 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1407722  0.         0.
 0.         0.         0.08612371 0.         0.10529749 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13463883
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14965296 0.         0.
 0.         0.         0.         0.         0.         0.
 0.12346139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14802941 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10738128 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10261677 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11857414 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18177571 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07109998
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09875189 0.         0.
 0.         0.         0.         0.         0.         0.10273611
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0788034  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10469878 0.         0.13429476
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08714977 0.
 0.         0.         0.         0.0915243  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17848853 0.         0.
 0.15085557 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07652006 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21642269 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11621211 0.         0.         0.         0.         0.
 0.         0.         0.         0.11910046 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1407722  0.         0.
 0.         0.         0.08612371 0.         0.10529749 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13463883
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14965296 0.         0.
 0.         0.         0.         0.         0.         0.
 0.12346139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14802941 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10738128 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.001      0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03936198 0.001      0.001
 0.001      0.001      0.001      0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03511554 0.001      0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04090558 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.01849272 0.001      0.001      0.06819212 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03647485 0.0310559  0.001      0.001      0.04316547 0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.03463896 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03781837 0.0212766  0.05325444
 0.001      0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.001
 0.001      0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.02284735
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04236611 0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.03765491 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.03715451 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.001      0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.001      0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0383693  0.03241574 0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.001      0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03848983 0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.04116285 0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03064182
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.001      0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.001      0.001
 0.01658273 0.01742111 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.001
 0.001      0.03012994 0.001      0.001      0.001      0.04076739
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.001      0.001      0.001      0.03650413 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.001      0.001      0.001      0.001      0.02611244
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][15:26:25]: [Server #615782] Global model accuracy: 51.43%

[INFO][15:26:25]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_11.pth.
[INFO][15:26:25]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_11.pth.
[INFO][15:26:25]: [93m[1m
[Server #615782] Starting round 12/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  6e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  5e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  5e-05  3e-09  3e-10
 8:  7.5999e+00  7.5999e+00  4e-05  3e-09  3e-10
 9:  7.5999e+00  7.5999e+00  2e-05  5e-09  5e-10
10:  7.5999e+00  7.5999e+00  4e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24350138e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24292585e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.23918004e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24438344e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24350112e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24338305e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24417926e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 9.17713383e-01 8.24521883e-05 8.23983688e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24384710e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24383464e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24002492e-05
 8.24521883e-05 8.24521883e-05 8.24090338e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24417438e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.23666114e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24304496e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24328179e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24262765e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24394494e-05 8.24521883e-05
 8.24399233e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24267234e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24122525e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24273299e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24155169e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24311053e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05 8.24521883e-05
 8.24521883e-05 8.24521883e-05 8.24521883e-05][INFO][15:26:27]: [Server #615782] Selected clients: [454 634 457 962 731 405 744 287 314 606 595 880 254 767 942   2 477 658
 843 184 856 363 893  28  86]
[INFO][15:26:27]: [Server #615782] Selecting client #454 for training.
[INFO][15:26:27]: [Server #615782] Sending the current model to client #454 (simulated).
[INFO][15:26:27]: [Server #615782] Sending 0.26 MB of payload data to client #454 (simulated).
[INFO][15:26:27]: [Server #615782] Selecting client #634 for training.
[INFO][15:26:27]: [Server #615782] Sending the current model to client #634 (simulated).
[INFO][15:26:27]: [Server #615782] Sending 0.26 MB of payload data to client #634 (simulated).
[INFO][15:26:27]: [Client #454] Selected by the server.
[INFO][15:26:27]: [Client #454] Loading its data source...
[INFO][15:26:27]: Data source: FEMNIST
[INFO][15:26:27]: [Client #634] Selected by the server.
[INFO][15:26:27]: [Client #634] Loading its data source...
[INFO][15:26:27]: Data source: FEMNIST
[INFO][15:26:28]: [Client #454] Dataset size: 147
[INFO][15:26:28]: [Client #454] Sampler: all_inclusive
[INFO][15:26:28]: [Client #634] Dataset size: 159
[INFO][15:26:28]: [Client #634] Sampler: all_inclusive
[INFO][15:26:28]: [Client #454] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:26:28]: [Client #634] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:26:28]: [93m[1m[Client #454] Started training in communication round #12.[0m
[INFO][15:26:28]: [93m[1m[Client #634] Started training in communication round #12.[0m
[INFO][15:26:30]: [Client #454] Loading the dataset.
[INFO][15:26:30]: [Client #634] Loading the dataset.
[INFO][15:26:36]: [Client #634] Epoch: [1/5][0/16]	Loss: 1.649674
[INFO][15:26:36]: [Client #454] Epoch: [1/5][0/15]	Loss: 0.978630
[INFO][15:26:36]: [Client #634] Epoch: [1/5][10/16]	Loss: 0.792057
[INFO][15:26:37]: [Client #454] Epoch: [1/5][10/15]	Loss: 1.370235
[INFO][15:26:37]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:26:37]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:26:37]: [Client #634] Woke up.
[INFO][15:26:37]: [Client #634] Epoch: [2/5][0/16]	Loss: 1.027267
[INFO][15:26:37]: [Client #634] Epoch: [2/5][10/16]	Loss: 1.195526
[INFO][15:26:37]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:26:38]: [Client #634] Woke up.
[INFO][15:26:38]: [Client #634] Epoch: [3/5][0/16]	Loss: 0.591927
[INFO][15:26:38]: [Client #634] Epoch: [3/5][10/16]	Loss: 2.372321
[INFO][15:26:38]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:26:39]: [Client #634] Woke up.
[INFO][15:26:39]: [Client #634] Epoch: [4/5][0/16]	Loss: 1.826090
[INFO][15:26:39]: [Client #634] Epoch: [4/5][10/16]	Loss: 0.989478
[INFO][15:26:39]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:26:40]: [Client #634] Woke up.
[INFO][15:26:40]: [Client #634] Epoch: [5/5][0/16]	Loss: 0.903158
[INFO][15:26:40]: [Client #634] Epoch: [5/5][10/16]	Loss: 0.694190
[INFO][15:26:40]: [Client #634] Going to sleep for 0.74 seconds.
[INFO][15:26:41]: [Client #634] Woke up.
[INFO][15:26:41]: [Client #634] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_634_615875.pth.
[INFO][15:26:41]: [Client #634] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_634_615875.pth.
[INFO][15:26:41]: [Client #634] Model trained.
[INFO][15:26:41]: [Client #634] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:26:41]: [Server #615782] Received 0.26 MB of payload data from client #634 (simulated).
[INFO][15:27:37]: [Client #454] Woke up.
[INFO][15:27:37]: [Client #454] Epoch: [2/5][0/15]	Loss: 0.635721
[INFO][15:27:37]: [Client #454] Epoch: [2/5][10/15]	Loss: 1.341217
[INFO][15:27:37]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:28:37]: [Client #454] Woke up.
[INFO][15:28:37]: [Client #454] Epoch: [3/5][0/15]	Loss: 1.115364
[INFO][15:28:37]: [Client #454] Epoch: [3/5][10/15]	Loss: 0.500296
[INFO][15:28:37]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:29:37]: [Client #454] Woke up.
[INFO][15:29:37]: [Client #454] Epoch: [4/5][0/15]	Loss: 0.326097
[INFO][15:29:37]: [Client #454] Epoch: [4/5][10/15]	Loss: 1.354033
[INFO][15:29:38]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:30:38]: [Client #454] Woke up.
[INFO][15:30:38]: [Client #454] Epoch: [5/5][0/15]	Loss: 0.827521
[INFO][15:30:38]: [Client #454] Epoch: [5/5][10/15]	Loss: 0.606003
[INFO][15:30:38]: [Client #454] Going to sleep for 60.00 seconds.
[INFO][15:31:38]: [Client #454] Woke up.
[INFO][15:31:38]: [Client #454] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_454_615874.pth.
[INFO][15:31:39]: [Client #454] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_454_615874.pth.
[INFO][15:31:39]: [Client #454] Model trained.
[INFO][15:31:39]: [Client #454] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:31:39]: [Server #615782] Received 0.26 MB of payload data from client #454 (simulated).
[INFO][15:31:39]: [Server #615782] Selecting client #457 for training.
[INFO][15:31:39]: [Server #615782] Sending the current model to client #457 (simulated).
[INFO][15:31:39]: [Server #615782] Sending 0.26 MB of payload data to client #457 (simulated).
[INFO][15:31:39]: [Server #615782] Selecting client #962 for training.
[INFO][15:31:39]: [Server #615782] Sending the current model to client #962 (simulated).
[INFO][15:31:39]: [Server #615782] Sending 0.26 MB of payload data to client #962 (simulated).
[INFO][15:31:39]: [Client #457] Selected by the server.
[INFO][15:31:39]: [Client #457] Loading its data source...
[INFO][15:31:39]: Data source: FEMNIST
[INFO][15:31:39]: [Client #962] Selected by the server.
[INFO][15:31:39]: [Client #962] Loading its data source...
[INFO][15:31:39]: Data source: FEMNIST
[INFO][15:31:39]: [Client #962] Dataset size: 153
[INFO][15:31:39]: [Client #962] Sampler: all_inclusive
[INFO][15:31:39]: [Client #457] Dataset size: 163
[INFO][15:31:39]: [Client #457] Sampler: all_inclusive
[INFO][15:31:39]: [Client #962] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:31:39]: [Client #457] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:31:39]: [93m[1m[Client #962] Started training in communication round #12.[0m
[INFO][15:31:39]: [93m[1m[Client #457] Started training in communication round #12.[0m
[INFO][15:31:41]: [Client #962] Loading the dataset.
[INFO][15:31:41]: [Client #457] Loading the dataset.
[INFO][15:31:48]: [Client #962] Epoch: [1/5][0/16]	Loss: 1.245157
[INFO][15:31:48]: [Client #962] Epoch: [1/5][10/16]	Loss: 1.098444
[INFO][15:31:48]: [Client #457] Epoch: [1/5][0/17]	Loss: 1.145578
[INFO][15:31:48]: [Client #962] Going to sleep for 5.04 seconds.
[INFO][15:31:48]: [Client #457] Epoch: [1/5][10/17]	Loss: 1.032755
[INFO][15:31:48]: [Client #457] Going to sleep for 10.02 seconds.
[INFO][15:31:53]: [Client #962] Woke up.
[INFO][15:31:53]: [Client #962] Epoch: [2/5][0/16]	Loss: 0.865609
[INFO][15:31:53]: [Client #962] Epoch: [2/5][10/16]	Loss: 0.757671
[INFO][15:31:53]: [Client #962] Going to sleep for 5.04 seconds.
[INFO][15:31:58]: [Client #457] Woke up.
[INFO][15:31:58]: [Client #457] Epoch: [2/5][0/17]	Loss: 1.453253
[INFO][15:31:58]: [Client #962] Woke up.
[INFO][15:31:58]: [Client #962] Epoch: [3/5][0/16]	Loss: 1.102758
[INFO][15:31:58]: [Client #457] Epoch: [2/5][10/17]	Loss: 1.225787
[INFO][15:31:58]: [Client #457] Going to sleep for 10.02 seconds.
[INFO][15:31:58]: [Client #962] Epoch: [3/5][10/16]	Loss: 0.681152
[INFO][15:31:58]: [Client #962] Going to sleep for 5.04 seconds.
[INFO][15:32:03]: [Client #962] Woke up.
[INFO][15:32:03]: [Client #962] Epoch: [4/5][0/16]	Loss: 0.871827
[INFO][15:32:03]: [Client #962] Epoch: [4/5][10/16]	Loss: 1.468528
[INFO][15:32:03]: [Client #962] Going to sleep for 5.04 seconds.
[INFO][15:32:08]: [Client #457] Woke up.
[INFO][15:32:08]: [Client #457] Epoch: [3/5][0/17]	Loss: 1.093571
[INFO][15:32:08]: [Client #457] Epoch: [3/5][10/17]	Loss: 1.867584
[INFO][15:32:08]: [Client #457] Going to sleep for 10.02 seconds.
[INFO][15:32:08]: [Client #962] Woke up.
[INFO][15:32:08]: [Client #962] Epoch: [5/5][0/16]	Loss: 1.843008
[INFO][15:32:09]: [Client #962] Epoch: [5/5][10/16]	Loss: 0.674065
[INFO][15:32:09]: [Client #962] Going to sleep for 5.04 seconds.
[INFO][15:32:14]: [Client #962] Woke up.
[INFO][15:32:14]: [Client #962] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_962_615875.pth.
[INFO][15:32:15]: [Client #962] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_962_615875.pth.
[INFO][15:32:15]: [Client #962] Model trained.
[INFO][15:32:15]: [Client #962] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:32:15]: [Server #615782] Received 0.26 MB of payload data from client #962 (simulated).
[INFO][15:32:18]: [Client #457] Woke up.
[INFO][15:32:18]: [Client #457] Epoch: [4/5][0/17]	Loss: 1.033435
[INFO][15:32:18]: [Client #457] Epoch: [4/5][10/17]	Loss: 0.858236
[INFO][15:32:19]: [Client #457] Going to sleep for 10.02 seconds.
[INFO][15:32:29]: [Client #457] Woke up.
[INFO][15:32:29]: [Client #457] Epoch: [5/5][0/17]	Loss: 0.751482
[INFO][15:32:29]: [Client #457] Epoch: [5/5][10/17]	Loss: 0.770133
[INFO][15:32:29]: [Client #457] Going to sleep for 10.02 seconds.
[INFO][15:32:39]: [Client #457] Woke up.
[INFO][15:32:39]: [Client #457] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_457_615874.pth.
[INFO][15:32:39]: [Client #457] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_457_615874.pth.
[INFO][15:32:39]: [Client #457] Model trained.
[INFO][15:32:39]: [Client #457] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:32:39]: [Server #615782] Received 0.26 MB of payload data from client #457 (simulated).
[INFO][15:32:39]: [Server #615782] Selecting client #731 for training.
[INFO][15:32:39]: [Server #615782] Sending the current model to client #731 (simulated).
[INFO][15:32:39]: [Server #615782] Sending 0.26 MB of payload data to client #731 (simulated).
[INFO][15:32:39]: [Server #615782] Selecting client #405 for training.
[INFO][15:32:39]: [Server #615782] Sending the current model to client #405 (simulated).
[INFO][15:32:39]: [Server #615782] Sending 0.26 MB of payload data to client #405 (simulated).
[INFO][15:32:39]: [Client #731] Selected by the server.
[INFO][15:32:39]: [Client #731] Loading its data source...
[INFO][15:32:39]: Data source: FEMNIST
[INFO][15:32:39]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:32:39]: [Client #405] Selected by the server.
[INFO][15:32:39]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/731.zip.
[INFO][15:32:39]: [Client #405] Loading its data source...
[INFO][15:32:39]: Data source: FEMNIST
[INFO][15:32:39]: [Client #405] Dataset size: 159
[INFO][15:32:39]: [Client #405] Sampler: all_inclusive
[INFO][15:32:39]: [Client #405] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:32:39]: [93m[1m[Client #405] Started training in communication round #12.[0m
2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.6%45.1%47.6%50.1%52.6%55.1%57.6%60.1%62.6%65.1%67.6%70.2%72.7%75.2%77.7%80.2%82.7%85.2%87.7%90.2%92.7%95.2%97.7%100.0%[INFO][15:32:40]: Decompressing the dataset downloaded.
[INFO][15:32:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/731.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:32:40]: [Client #731] Dataset size: 156
[INFO][15:32:40]: [Client #731] Sampler: all_inclusive
[INFO][15:32:40]: [Client #731] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:32:40]: [93m[1m[Client #731] Started training in communication round #12.[0m

[INFO][15:32:41]: [Client #405] Loading the dataset.
[INFO][15:32:42]: [Client #731] Loading the dataset.
[INFO][15:32:49]: [Client #405] Epoch: [1/5][0/16]	Loss: 0.899783
[INFO][15:32:49]: [Client #405] Epoch: [1/5][10/16]	Loss: 1.162639
[INFO][15:32:49]: [Client #731] Epoch: [1/5][0/16]	Loss: 1.695260
[INFO][15:32:49]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][15:32:49]: [Client #731] Epoch: [1/5][10/16]	Loss: 1.108497
[INFO][15:32:49]: [Client #731] Going to sleep for 1.07 seconds.
[INFO][15:32:50]: [Client #405] Woke up.
[INFO][15:32:50]: [Client #405] Epoch: [2/5][0/16]	Loss: 0.487155
[INFO][15:32:50]: [Client #405] Epoch: [2/5][10/16]	Loss: 0.590236
[INFO][15:32:50]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][15:32:50]: [Client #731] Woke up.
[INFO][15:32:50]: [Client #731] Epoch: [2/5][0/16]	Loss: 1.522815
[INFO][15:32:50]: [Client #731] Epoch: [2/5][10/16]	Loss: 0.813026
[INFO][15:32:50]: [Client #731] Going to sleep for 1.07 seconds.
[INFO][15:32:51]: [Client #405] Woke up.
[INFO][15:32:51]: [Client #405] Epoch: [3/5][0/16]	Loss: 0.324824
[INFO][15:32:51]: [Client #405] Epoch: [3/5][10/16]	Loss: 0.872307
[INFO][15:32:51]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][15:32:51]: [Client #731] Woke up.
[INFO][15:32:51]: [Client #731] Epoch: [3/5][0/16]	Loss: 1.368018
[INFO][15:32:51]: [Client #731] Epoch: [3/5][10/16]	Loss: 1.061022
[INFO][15:32:51]: [Client #731] Going to sleep for 1.07 seconds.
[INFO][15:32:52]: [Client #405] Woke up.
[INFO][15:32:52]: [Client #405] Epoch: [4/5][0/16]	Loss: 0.300476
[INFO][15:32:52]: [Client #405] Epoch: [4/5][10/16]	Loss: 0.956951
[INFO][15:32:52]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][15:32:52]: [Client #731] Woke up.
[INFO][15:32:52]: [Client #731] Epoch: [4/5][0/16]	Loss: 0.919075
[INFO][15:32:53]: [Client #731] Epoch: [4/5][10/16]	Loss: 2.173580
[INFO][15:32:53]: [Client #731] Going to sleep for 1.07 seconds.
[INFO][15:32:53]: [Client #405] Woke up.
[INFO][15:32:53]: [Client #405] Epoch: [5/5][0/16]	Loss: 0.498663
[INFO][15:32:53]: [Client #405] Epoch: [5/5][10/16]	Loss: 0.086728
[INFO][15:32:53]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][15:32:54]: [Client #731] Woke up.
[INFO][15:32:54]: [Client #731] Epoch: [5/5][0/16]	Loss: 1.008169
[INFO][15:32:54]: [Client #405] Woke up.
[INFO][15:32:54]: [Client #405] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_615875.pth.
[INFO][15:32:54]: [Client #731] Epoch: [5/5][10/16]	Loss: 1.956869
[INFO][15:32:54]: [Client #731] Going to sleep for 1.07 seconds.
[INFO][15:32:54]: [Client #405] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_615875.pth.
[INFO][15:32:54]: [Client #405] Model trained.
[INFO][15:32:54]: [Client #405] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:32:54]: [Server #615782] Received 0.26 MB of payload data from client #405 (simulated).
[INFO][15:32:55]: [Client #731] Woke up.
[INFO][15:32:55]: [Client #731] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_731_615874.pth.
[INFO][15:32:56]: [Client #731] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_731_615874.pth.
[INFO][15:32:56]: [Client #731] Model trained.
[INFO][15:32:56]: [Client #731] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:32:56]: [Server #615782] Received 0.26 MB of payload data from client #731 (simulated).
[INFO][15:32:56]: [Server #615782] Selecting client #744 for training.
[INFO][15:32:56]: [Server #615782] Sending the current model to client #744 (simulated).
[INFO][15:32:56]: [Server #615782] Sending 0.26 MB of payload data to client #744 (simulated).
[INFO][15:32:56]: [Server #615782] Selecting client #287 for training.
[INFO][15:32:56]: [Server #615782] Sending the current model to client #287 (simulated).
[INFO][15:32:56]: [Server #615782] Sending 0.26 MB of payload data to client #287 (simulated).
[INFO][15:32:56]: [Client #744] Selected by the server.
[INFO][15:32:56]: [Client #744] Loading its data source...
[INFO][15:32:56]: Data source: FEMNIST
[INFO][15:32:56]: [Client #287] Selected by the server.
[INFO][15:32:56]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:32:56]: [Client #287] Loading its data source...
[INFO][15:32:56]: Data source: FEMNIST
[INFO][15:32:56]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/744.zip.
[INFO][15:32:56]: [Client #287] Dataset size: 162
[INFO][15:32:56]: [Client #287] Sampler: all_inclusive
[INFO][15:32:56]: [Client #287] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:32:56]: [93m[1m[Client #287] Started training in communication round #12.[0m
1.5%3.0%4.5%6.0%7.5%9.0%10.5%12.0%13.5%15.0%16.5%18.0%19.5%21.0%22.6%24.1%25.6%27.1%28.6%30.1%31.6%33.1%34.6%36.1%37.6%39.1%40.6%42.1%43.6%45.1%46.6%48.1%49.6%51.1%52.6%54.1%55.6%57.1%58.6%60.1%61.6%63.1%64.6%66.2%67.7%69.2%70.7%72.2%73.7%75.2%76.7%78.2%79.7%81.2%82.7%84.2%85.7%87.2%88.7%90.2%91.7%93.2%94.7%96.2%97.7%99.2%100.0%[INFO][15:32:56]: Decompressing the dataset downloaded.
[INFO][15:32:56]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/744.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:32:56]: [Client #744] Dataset size: 268
[INFO][15:32:56]: [Client #744] Sampler: all_inclusive
[INFO][15:32:56]: [Client #744] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:32:56]: [93m[1m[Client #744] Started training in communication round #12.[0m

[INFO][15:32:58]: [Client #287] Loading the dataset.
[INFO][15:32:58]: [Client #744] Loading the dataset.
[INFO][15:33:05]: [Client #744] Epoch: [1/5][0/27]	Loss: 1.259038
[INFO][15:33:05]: [Client #287] Epoch: [1/5][0/17]	Loss: 1.220143
[INFO][15:33:05]: [Client #744] Epoch: [1/5][10/27]	Loss: 1.369110
[INFO][15:33:05]: [Client #287] Epoch: [1/5][10/17]	Loss: 0.520230
[INFO][15:33:05]: [Client #744] Epoch: [1/5][20/27]	Loss: 1.498188
[INFO][15:33:05]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][15:33:05]: [Client #744] Going to sleep for 17.57 seconds.
[INFO][15:33:06]: [Client #287] Woke up.
[INFO][15:33:06]: [Client #287] Epoch: [2/5][0/17]	Loss: 0.382294
[INFO][15:33:06]: [Client #287] Epoch: [2/5][10/17]	Loss: 1.566760
[INFO][15:33:06]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][15:33:08]: [Client #287] Woke up.
[INFO][15:33:08]: [Client #287] Epoch: [3/5][0/17]	Loss: 0.491873
[INFO][15:33:08]: [Client #287] Epoch: [3/5][10/17]	Loss: 0.914119
[INFO][15:33:08]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][15:33:09]: [Client #287] Woke up.
[INFO][15:33:09]: [Client #287] Epoch: [4/5][0/17]	Loss: 0.264342
[INFO][15:33:09]: [Client #287] Epoch: [4/5][10/17]	Loss: 1.093583
[INFO][15:33:09]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][15:33:10]: [Client #287] Woke up.
[INFO][15:33:10]: [Client #287] Epoch: [5/5][0/17]	Loss: 0.668977
[INFO][15:33:10]: [Client #287] Epoch: [5/5][10/17]	Loss: 0.643374
[INFO][15:33:10]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][15:33:11]: [Client #287] Woke up.
[INFO][15:33:11]: [Client #287] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_287_615875.pth.
[INFO][15:33:12]: [Client #287] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_287_615875.pth.
[INFO][15:33:12]: [Client #287] Model trained.
[INFO][15:33:12]: [Client #287] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:33:12]: [Server #615782] Received 0.26 MB of payload data from client #287 (simulated).
[INFO][15:33:23]: [Client #744] Woke up.
[INFO][15:33:23]: [Client #744] Epoch: [2/5][0/27]	Loss: 1.958996
[INFO][15:33:23]: [Client #744] Epoch: [2/5][10/27]	Loss: 1.374083
[INFO][15:33:23]: [Client #744] Epoch: [2/5][20/27]	Loss: 0.873440
[INFO][15:33:23]: [Client #744] Going to sleep for 17.57 seconds.
[INFO][15:33:41]: [Client #744] Woke up.
[INFO][15:33:41]: [Client #744] Epoch: [3/5][0/27]	Loss: 1.688201
[INFO][15:33:41]: [Client #744] Epoch: [3/5][10/27]	Loss: 1.233601
[INFO][15:33:41]: [Client #744] Epoch: [3/5][20/27]	Loss: 0.889061
[INFO][15:33:41]: [Client #744] Going to sleep for 17.57 seconds.
[INFO][15:33:59]: [Client #744] Woke up.
[INFO][15:33:59]: [Client #744] Epoch: [4/5][0/27]	Loss: 1.878027
[INFO][15:33:59]: [Client #744] Epoch: [4/5][10/27]	Loss: 1.623509
[INFO][15:33:59]: [Client #744] Epoch: [4/5][20/27]	Loss: 1.542980
[INFO][15:33:59]: [Client #744] Going to sleep for 17.57 seconds.
[INFO][15:34:17]: [Client #744] Woke up.
[INFO][15:34:17]: [Client #744] Epoch: [5/5][0/27]	Loss: 1.124979
[INFO][15:34:17]: [Client #744] Epoch: [5/5][10/27]	Loss: 1.550855
[INFO][15:34:17]: [Client #744] Epoch: [5/5][20/27]	Loss: 1.098461
[INFO][15:34:17]: [Client #744] Going to sleep for 17.57 seconds.
[INFO][15:34:35]: [Client #744] Woke up.
[INFO][15:34:35]: [Client #744] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_744_615874.pth.
[INFO][15:34:35]: [Client #744] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_744_615874.pth.
[INFO][15:34:35]: [Client #744] Model trained.
[INFO][15:34:35]: [Client #744] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:34:35]: [Server #615782] Received 0.26 MB of payload data from client #744 (simulated).
[INFO][15:34:35]: [Server #615782] Selecting client #314 for training.
[INFO][15:34:35]: [Server #615782] Sending the current model to client #314 (simulated).
[INFO][15:34:35]: [Server #615782] Sending 0.26 MB of payload data to client #314 (simulated).
[INFO][15:34:35]: [Server #615782] Selecting client #606 for training.
[INFO][15:34:35]: [Server #615782] Sending the current model to client #606 (simulated).
[INFO][15:34:35]: [Server #615782] Sending 0.26 MB of payload data to client #606 (simulated).
[INFO][15:34:35]: [Client #314] Selected by the server.
[INFO][15:34:35]: [Client #314] Loading its data source...
[INFO][15:34:35]: Data source: FEMNIST
[INFO][15:34:35]: [Client #606] Selected by the server.
[INFO][15:34:35]: [Client #606] Loading its data source...
[INFO][15:34:35]: Data source: FEMNIST
[INFO][15:34:35]: [Client #314] Dataset size: 122
[INFO][15:34:35]: [Client #314] Sampler: all_inclusive
[INFO][15:34:35]: [Client #606] Dataset size: 160
[INFO][15:34:35]: [Client #606] Sampler: all_inclusive
[INFO][15:34:35]: [Client #314] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:34:35]: [Client #606] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:34:35]: [93m[1m[Client #606] Started training in communication round #12.[0m
[INFO][15:34:35]: [93m[1m[Client #314] Started training in communication round #12.[0m
[INFO][15:34:37]: [Client #314] Loading the dataset.
[INFO][15:34:37]: [Client #606] Loading the dataset.
[INFO][15:34:45]: [Client #314] Epoch: [1/5][0/13]	Loss: 1.673885
[INFO][15:34:45]: [Client #606] Epoch: [1/5][0/16]	Loss: 0.973891
[INFO][15:34:45]: [Client #314] Epoch: [1/5][10/13]	Loss: 1.943269
[INFO][15:34:45]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][15:34:45]: [Client #606] Epoch: [1/5][10/16]	Loss: 1.250843
[INFO][15:34:45]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][15:34:45]: [Client #314] Woke up.
[INFO][15:34:45]: [Client #314] Epoch: [2/5][0/13]	Loss: 1.785961
[INFO][15:34:45]: [Client #314] Epoch: [2/5][10/13]	Loss: 1.564059
[INFO][15:34:45]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][15:34:45]: [Client #314] Woke up.
[INFO][15:34:45]: [Client #314] Epoch: [3/5][0/13]	Loss: 1.126971
[INFO][15:34:45]: [Client #314] Epoch: [3/5][10/13]	Loss: 0.488158
[INFO][15:34:45]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][15:34:45]: [Client #314] Woke up.
[INFO][15:34:45]: [Client #314] Epoch: [4/5][0/13]	Loss: 0.682772
[INFO][15:34:45]: [Client #314] Epoch: [4/5][10/13]	Loss: 1.176427
[INFO][15:34:45]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][15:34:46]: [Client #314] Woke up.
[INFO][15:34:46]: [Client #314] Epoch: [5/5][0/13]	Loss: 1.361296
[INFO][15:34:46]: [Client #314] Epoch: [5/5][10/13]	Loss: 0.604887
[INFO][15:34:46]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][15:34:46]: [Client #314] Woke up.
[INFO][15:34:46]: [Client #314] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_314_615874.pth.
[INFO][15:34:46]: [Client #314] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_314_615874.pth.
[INFO][15:34:46]: [Client #314] Model trained.
[INFO][15:34:46]: [Client #314] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:34:47]: [Server #615782] Received 0.26 MB of payload data from client #314 (simulated).
[INFO][15:34:56]: [Client #606] Woke up.
[INFO][15:34:56]: [Client #606] Epoch: [2/5][0/16]	Loss: 1.264961
[INFO][15:34:56]: [Client #606] Epoch: [2/5][10/16]	Loss: 0.873090
[INFO][15:34:56]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][15:35:07]: [Client #606] Woke up.
[INFO][15:35:07]: [Client #606] Epoch: [3/5][0/16]	Loss: 0.618971
[INFO][15:35:07]: [Client #606] Epoch: [3/5][10/16]	Loss: 2.593676
[INFO][15:35:07]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][15:35:18]: [Client #606] Woke up.
[INFO][15:35:18]: [Client #606] Epoch: [4/5][0/16]	Loss: 1.594597
[INFO][15:35:19]: [Client #606] Epoch: [4/5][10/16]	Loss: 1.031022
[INFO][15:35:19]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][15:35:30]: [Client #606] Woke up.
[INFO][15:35:30]: [Client #606] Epoch: [5/5][0/16]	Loss: 1.225787
[INFO][15:35:30]: [Client #606] Epoch: [5/5][10/16]	Loss: 1.070253
[INFO][15:35:30]: [Client #606] Going to sleep for 11.10 seconds.
[INFO][15:35:41]: [Client #606] Woke up.
[INFO][15:35:41]: [Client #606] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_606_615875.pth.
[INFO][15:35:42]: [Client #606] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_606_615875.pth.
[INFO][15:35:42]: [Client #606] Model trained.
[INFO][15:35:42]: [Client #606] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:35:42]: [Server #615782] Received 0.26 MB of payload data from client #606 (simulated).
[INFO][15:35:42]: [Server #615782] Selecting client #595 for training.
[INFO][15:35:42]: [Server #615782] Sending the current model to client #595 (simulated).
[INFO][15:35:42]: [Server #615782] Sending 0.26 MB of payload data to client #595 (simulated).
[INFO][15:35:42]: [Server #615782] Selecting client #880 for training.
[INFO][15:35:42]: [Server #615782] Sending the current model to client #880 (simulated).
[INFO][15:35:42]: [Server #615782] Sending 0.26 MB of payload data to client #880 (simulated).
[INFO][15:35:42]: [Client #595] Selected by the server.
[INFO][15:35:42]: [Client #880] Selected by the server.
[INFO][15:35:42]: [Client #595] Loading its data source...
[INFO][15:35:42]: Data source: FEMNIST
[INFO][15:35:42]: [Client #880] Loading its data source...
[INFO][15:35:42]: Data source: FEMNIST
[INFO][15:35:42]: [Client #595] Dataset size: 146
[INFO][15:35:42]: [Client #595] Sampler: all_inclusive
[INFO][15:35:42]: [Client #880] Dataset size: 156
[INFO][15:35:42]: [Client #880] Sampler: all_inclusive
[INFO][15:35:42]: [Client #595] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:35:42]: [Client #880] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:35:42]: [93m[1m[Client #880] Started training in communication round #12.[0m
[INFO][15:35:42]: [93m[1m[Client #595] Started training in communication round #12.[0m
[INFO][15:35:44]: [Client #595] Loading the dataset.
[INFO][15:35:44]: [Client #880] Loading the dataset.
[INFO][15:35:51]: [Client #595] Epoch: [1/5][0/15]	Loss: 1.149531
[INFO][15:35:51]: [Client #880] Epoch: [1/5][0/16]	Loss: 1.173603
[INFO][15:35:51]: [Client #595] Epoch: [1/5][10/15]	Loss: 0.720298
[INFO][15:35:51]: [Client #880] Epoch: [1/5][10/16]	Loss: 0.579771
[INFO][15:35:51]: [Client #595] Going to sleep for 0.27 seconds.
[INFO][15:35:51]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][15:35:52]: [Client #595] Woke up.
[INFO][15:35:52]: [Client #595] Epoch: [2/5][0/15]	Loss: 0.825517
[INFO][15:35:52]: [Client #595] Epoch: [2/5][10/15]	Loss: 0.999306
[INFO][15:35:52]: [Client #595] Going to sleep for 0.27 seconds.
[INFO][15:35:52]: [Client #595] Woke up.
[INFO][15:35:52]: [Client #595] Epoch: [3/5][0/15]	Loss: 0.958800
[INFO][15:35:52]: [Client #595] Epoch: [3/5][10/15]	Loss: 1.182538
[INFO][15:35:52]: [Client #595] Going to sleep for 0.27 seconds.
[INFO][15:35:52]: [Client #595] Woke up.
[INFO][15:35:52]: [Client #595] Epoch: [4/5][0/15]	Loss: 1.064001
[INFO][15:35:53]: [Client #595] Epoch: [4/5][10/15]	Loss: 0.889950
[INFO][15:35:53]: [Client #595] Going to sleep for 0.27 seconds.
[INFO][15:35:53]: [Client #595] Woke up.
[INFO][15:35:53]: [Client #595] Epoch: [5/5][0/15]	Loss: 0.673221
[INFO][15:35:53]: [Client #595] Epoch: [5/5][10/15]	Loss: 0.373950
[INFO][15:35:53]: [Client #595] Going to sleep for 0.27 seconds.
[INFO][15:35:53]: [Client #595] Woke up.
[INFO][15:35:53]: [Client #595] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_595_615874.pth.
[INFO][15:35:53]: [Client #880] Woke up.
[INFO][15:35:53]: [Client #880] Epoch: [2/5][0/16]	Loss: 1.059539
[INFO][15:35:53]: [Client #880] Epoch: [2/5][10/16]	Loss: 0.404716
[INFO][15:35:54]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][15:35:54]: [Client #595] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_595_615874.pth.
[INFO][15:35:54]: [Client #595] Model trained.
[INFO][15:35:54]: [Client #595] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:35:54]: [Server #615782] Received 0.26 MB of payload data from client #595 (simulated).
[INFO][15:35:56]: [Client #880] Woke up.
[INFO][15:35:56]: [Client #880] Epoch: [3/5][0/16]	Loss: 1.561472
[INFO][15:35:56]: [Client #880] Epoch: [3/5][10/16]	Loss: 1.394529
[INFO][15:35:56]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][15:35:58]: [Client #880] Woke up.
[INFO][15:35:58]: [Client #880] Epoch: [4/5][0/16]	Loss: 1.229391
[INFO][15:35:58]: [Client #880] Epoch: [4/5][10/16]	Loss: 0.424237
[INFO][15:35:58]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][15:36:00]: [Client #880] Woke up.
[INFO][15:36:00]: [Client #880] Epoch: [5/5][0/16]	Loss: 0.653571
[INFO][15:36:00]: [Client #880] Epoch: [5/5][10/16]	Loss: 1.006457
[INFO][15:36:00]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][15:36:02]: [Client #880] Woke up.
[INFO][15:36:02]: [Client #880] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_880_615875.pth.
[INFO][15:36:03]: [Client #880] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_880_615875.pth.
[INFO][15:36:03]: [Client #880] Model trained.
[INFO][15:36:03]: [Client #880] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:36:03]: [Server #615782] Received 0.26 MB of payload data from client #880 (simulated).
[INFO][15:36:03]: [Server #615782] Selecting client #254 for training.
[INFO][15:36:03]: [Server #615782] Sending the current model to client #254 (simulated).
[INFO][15:36:03]: [Server #615782] Sending 0.26 MB of payload data to client #254 (simulated).
[INFO][15:36:03]: [Server #615782] Selecting client #767 for training.
[INFO][15:36:03]: [Server #615782] Sending the current model to client #767 (simulated).
[INFO][15:36:03]: [Server #615782] Sending 0.26 MB of payload data to client #767 (simulated).
[INFO][15:36:03]: [Client #254] Selected by the server.
[INFO][15:36:03]: [Client #254] Loading its data source...
[INFO][15:36:03]: [Client #767] Selected by the server.
[INFO][15:36:03]: Data source: FEMNIST
[INFO][15:36:03]: [Client #767] Loading its data source...
[INFO][15:36:03]: Data source: FEMNIST
[INFO][15:36:03]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:36:03]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/767.zip.
[INFO][15:36:03]: [Client #254] Dataset size: 150
[INFO][15:36:03]: [Client #254] Sampler: all_inclusive
[INFO][15:36:03]: [Client #254] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:36:03]: [93m[1m[Client #254] Started training in communication round #12.[0m
2.2%4.3%6.5%8.7%10.8%13.0%15.2%17.3%19.5%21.7%23.8%26.0%28.2%30.3%32.5%34.7%36.8%39.0%41.2%43.3%45.5%47.7%49.9%52.0%54.2%56.4%58.5%60.7%62.9%65.0%67.2%69.4%71.5%73.7%75.9%78.0%80.2%82.4%84.5%86.7%88.9%91.0%93.2%95.4%97.5%99.7%100.0%[INFO][15:36:03]: Decompressing the dataset downloaded.
[INFO][15:36:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/767.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:36:03]: [Client #767] Dataset size: 152
[INFO][15:36:03]: [Client #767] Sampler: all_inclusive
[INFO][15:36:03]: [Client #767] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:36:03]: [93m[1m[Client #767] Started training in communication round #12.[0m

[INFO][15:36:05]: [Client #254] Loading the dataset.
[INFO][15:36:05]: [Client #767] Loading the dataset.
[INFO][15:36:12]: [Client #254] Epoch: [1/5][0/15]	Loss: 1.559018
[INFO][15:36:12]: [Client #767] Epoch: [1/5][0/16]	Loss: 1.722061
[INFO][15:36:12]: [Client #767] Epoch: [1/5][10/16]	Loss: 1.068313
[INFO][15:36:12]: [Client #254] Epoch: [1/5][10/15]	Loss: 1.302444
[INFO][15:36:12]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][15:36:12]: [Client #767] Going to sleep for 2.52 seconds.
[INFO][15:36:15]: [Client #767] Woke up.
[INFO][15:36:15]: [Client #767] Epoch: [2/5][0/16]	Loss: 1.618676
[INFO][15:36:15]: [Client #767] Epoch: [2/5][10/16]	Loss: 1.683368
[INFO][15:36:15]: [Client #767] Going to sleep for 2.52 seconds.
[INFO][15:36:18]: [Client #767] Woke up.
[INFO][15:36:18]: [Client #767] Epoch: [3/5][0/16]	Loss: 1.053476
[INFO][15:36:18]: [Client #767] Epoch: [3/5][10/16]	Loss: 0.853673
[INFO][15:36:18]: [Client #767] Going to sleep for 2.52 seconds.
[INFO][15:36:20]: [Client #767] Woke up.
[INFO][15:36:20]: [Client #767] Epoch: [4/5][0/16]	Loss: 0.448841
[INFO][15:36:20]: [Client #767] Epoch: [4/5][10/16]	Loss: 1.920280
[INFO][15:36:20]: [Client #767] Going to sleep for 2.52 seconds.
[INFO][15:36:23]: [Client #767] Woke up.
[INFO][15:36:23]: [Client #767] Epoch: [5/5][0/16]	Loss: 0.885543
[INFO][15:36:23]: [Client #767] Epoch: [5/5][10/16]	Loss: 0.983009
[INFO][15:36:23]: [Client #767] Going to sleep for 2.52 seconds.
[INFO][15:36:26]: [Client #767] Woke up.
[INFO][15:36:26]: [Client #767] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_767_615875.pth.
[INFO][15:36:26]: [Client #767] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_767_615875.pth.
[INFO][15:36:26]: [Client #767] Model trained.
[INFO][15:36:26]: [Client #767] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:36:26]: [Server #615782] Received 0.26 MB of payload data from client #767 (simulated).
[INFO][15:36:50]: [Client #254] Woke up.
[INFO][15:36:50]: [Client #254] Epoch: [2/5][0/15]	Loss: 1.793794
[INFO][15:36:50]: [Client #254] Epoch: [2/5][10/15]	Loss: 1.950149
[INFO][15:36:50]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][15:37:27]: [Client #254] Woke up.
[INFO][15:37:27]: [Client #254] Epoch: [3/5][0/15]	Loss: 2.182659
[INFO][15:37:27]: [Client #254] Epoch: [3/5][10/15]	Loss: 1.163141
[INFO][15:37:27]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][15:38:04]: [Client #254] Woke up.
[INFO][15:38:05]: [Client #254] Epoch: [4/5][0/15]	Loss: 1.898997
[INFO][15:38:05]: [Client #254] Epoch: [4/5][10/15]	Loss: 1.833248
[INFO][15:38:05]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][15:38:42]: [Client #254] Woke up.
[INFO][15:38:42]: [Client #254] Epoch: [5/5][0/15]	Loss: 1.501971
[INFO][15:38:42]: [Client #254] Epoch: [5/5][10/15]	Loss: 1.226072
[INFO][15:38:42]: [Client #254] Going to sleep for 37.14 seconds.
[INFO][15:39:19]: [Client #254] Woke up.
[INFO][15:39:19]: [Client #254] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_254_615874.pth.
[INFO][15:39:20]: [Client #254] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_254_615874.pth.
[INFO][15:39:20]: [Client #254] Model trained.
[INFO][15:39:20]: [Client #254] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:39:20]: [Server #615782] Received 0.26 MB of payload data from client #254 (simulated).
[INFO][15:39:20]: [Server #615782] Selecting client #942 for training.
[INFO][15:39:20]: [Server #615782] Sending the current model to client #942 (simulated).
[INFO][15:39:20]: [Server #615782] Sending 0.26 MB of payload data to client #942 (simulated).
[INFO][15:39:20]: [Server #615782] Selecting client #2 for training.
[INFO][15:39:20]: [Server #615782] Sending the current model to client #2 (simulated).
[INFO][15:39:20]: [Server #615782] Sending 0.26 MB of payload data to client #2 (simulated).
[INFO][15:39:20]: [Client #942] Selected by the server.
[INFO][15:39:20]: [Client #942] Loading its data source...
[INFO][15:39:20]: Data source: FEMNIST
[INFO][15:39:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:39:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/942.zip.
[INFO][15:39:20]: [Client #2] Selected by the server.
[INFO][15:39:20]: [Client #2] Loading its data source...
[INFO][15:39:20]: Data source: FEMNIST
[INFO][15:39:20]: [Client #2] Dataset size: 153
[INFO][15:39:20]: [Client #2] Sampler: all_inclusive
[INFO][15:39:20]: [Client #2] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:39:20]: [93m[1m[Client #2] Started training in communication round #12.[0m
5.0%10.0%15.0%20.0%25.0%30.0%35.0%40.0%45.0%50.0%55.0%60.0%65.0%70.0%75.0%80.0%85.0%90.0%95.0%100.0%100.0%[INFO][15:39:20]: Decompressing the dataset downloaded.
[INFO][15:39:20]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/942.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:39:20]: [Client #942] Dataset size: 98
[INFO][15:39:20]: [Client #942] Sampler: all_inclusive
[INFO][15:39:20]: [Client #942] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:39:20]: [93m[1m[Client #942] Started training in communication round #12.[0m

[INFO][15:39:22]: [Client #2] Loading the dataset.
[INFO][15:39:22]: [Client #942] Loading the dataset.
[INFO][15:39:29]: [Client #2] Epoch: [1/5][0/16]	Loss: 0.484596
[INFO][15:39:29]: [Client #942] Epoch: [1/5][0/10]	Loss: 1.654834
[INFO][15:39:29]: [Client #2] Epoch: [1/5][10/16]	Loss: 0.794842
[INFO][15:39:29]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][15:39:29]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][15:39:29]: [Client #942] Woke up.
[INFO][15:39:29]: [Client #942] Epoch: [2/5][0/10]	Loss: 0.657525
[INFO][15:39:29]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][15:39:30]: [Client #942] Woke up.
[INFO][15:39:30]: [Client #942] Epoch: [3/5][0/10]	Loss: 0.764203
[INFO][15:39:30]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][15:39:30]: [Client #942] Woke up.
[INFO][15:39:30]: [Client #942] Epoch: [4/5][0/10]	Loss: 1.654694
[INFO][15:39:30]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][15:39:30]: [Client #942] Woke up.
[INFO][15:39:30]: [Client #942] Epoch: [5/5][0/10]	Loss: 0.903880
[INFO][15:39:30]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][15:39:30]: [Client #942] Woke up.
[INFO][15:39:30]: [Client #942] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_942_615874.pth.
[INFO][15:39:31]: [Client #942] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_942_615874.pth.
[INFO][15:39:31]: [Client #942] Model trained.
[INFO][15:39:31]: [Client #942] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:39:31]: [Server #615782] Received 0.26 MB of payload data from client #942 (simulated).
[INFO][15:39:32]: [Client #2] Woke up.
[INFO][15:39:32]: [Client #2] Epoch: [2/5][0/16]	Loss: 1.498844
[INFO][15:39:32]: [Client #2] Epoch: [2/5][10/16]	Loss: 0.341050
[INFO][15:39:32]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][15:39:35]: [Client #2] Woke up.
[INFO][15:39:35]: [Client #2] Epoch: [3/5][0/16]	Loss: 0.887623
[INFO][15:39:35]: [Client #2] Epoch: [3/5][10/16]	Loss: 0.895666
[INFO][15:39:35]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][15:39:37]: [Client #2] Woke up.
[INFO][15:39:37]: [Client #2] Epoch: [4/5][0/16]	Loss: 0.862755
[INFO][15:39:37]: [Client #2] Epoch: [4/5][10/16]	Loss: 0.664071
[INFO][15:39:37]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][15:39:40]: [Client #2] Woke up.
[INFO][15:39:40]: [Client #2] Epoch: [5/5][0/16]	Loss: 0.467536
[INFO][15:39:40]: [Client #2] Epoch: [5/5][10/16]	Loss: 0.690659
[INFO][15:39:40]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][15:39:43]: [Client #2] Woke up.
[INFO][15:39:43]: [Client #2] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_2_615875.pth.
[INFO][15:39:43]: [Client #2] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_2_615875.pth.
[INFO][15:39:43]: [Client #2] Model trained.
[INFO][15:39:43]: [Client #2] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:39:43]: [Server #615782] Received 0.26 MB of payload data from client #2 (simulated).
[INFO][15:39:43]: [Server #615782] Selecting client #477 for training.
[INFO][15:39:43]: [Server #615782] Sending the current model to client #477 (simulated).
[INFO][15:39:43]: [Server #615782] Sending 0.26 MB of payload data to client #477 (simulated).
[INFO][15:39:43]: [Server #615782] Selecting client #658 for training.
[INFO][15:39:43]: [Server #615782] Sending the current model to client #658 (simulated).
[INFO][15:39:44]: [Server #615782] Sending 0.26 MB of payload data to client #658 (simulated).
[INFO][15:39:44]: [Client #477] Selected by the server.
[INFO][15:39:44]: [Client #477] Loading its data source...
[INFO][15:39:44]: Data source: FEMNIST
[INFO][15:39:44]: [Client #658] Selected by the server.
[INFO][15:39:44]: [Client #658] Loading its data source...
[INFO][15:39:44]: Data source: FEMNIST
[INFO][15:39:44]: [Client #658] Dataset size: 158
[INFO][15:39:44]: [Client #658] Sampler: all_inclusive
[INFO][15:39:44]: [Client #658] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:39:44]: [93m[1m[Client #658] Started training in communication round #12.[0m
[INFO][15:39:44]: [Client #477] Dataset size: 144
[INFO][15:39:44]: [Client #477] Sampler: all_inclusive
[INFO][15:39:44]: [Client #477] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:39:44]: [93m[1m[Client #477] Started training in communication round #12.[0m
[INFO][15:39:46]: [Client #477] Loading the dataset.
[INFO][15:39:46]: [Client #658] Loading the dataset.
[INFO][15:39:53]: [Client #477] Epoch: [1/5][0/15]	Loss: 1.407713
[INFO][15:39:53]: [Client #477] Epoch: [1/5][10/15]	Loss: 1.404003
[INFO][15:39:53]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][15:39:53]: [Client #658] Epoch: [1/5][0/16]	Loss: 2.182457
[INFO][15:39:53]: [Client #658] Epoch: [1/5][10/16]	Loss: 1.941836
[INFO][15:39:53]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][15:39:53]: [Client #658] Woke up.
[INFO][15:39:53]: [Client #658] Epoch: [2/5][0/16]	Loss: 1.823528
[INFO][15:39:53]: [Client #658] Epoch: [2/5][10/16]	Loss: 1.400954
[INFO][15:39:53]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][15:39:53]: [Client #658] Woke up.
[INFO][15:39:53]: [Client #658] Epoch: [3/5][0/16]	Loss: 0.985538
[INFO][15:39:54]: [Client #658] Epoch: [3/5][10/16]	Loss: 1.682387
[INFO][15:39:54]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][15:39:54]: [Client #658] Woke up.
[INFO][15:39:54]: [Client #658] Epoch: [4/5][0/16]	Loss: 1.282966
[INFO][15:39:54]: [Client #658] Epoch: [4/5][10/16]	Loss: 1.142508
[INFO][15:39:54]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][15:39:54]: [Client #658] Woke up.
[INFO][15:39:54]: [Client #658] Epoch: [5/5][0/16]	Loss: 0.635243
[INFO][15:39:54]: [Client #658] Epoch: [5/5][10/16]	Loss: 0.724216
[INFO][15:39:54]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][15:39:54]: [Client #658] Woke up.
[INFO][15:39:54]: [Client #658] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615875.pth.
[INFO][15:39:55]: [Client #658] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615875.pth.
[INFO][15:39:55]: [Client #658] Model trained.
[INFO][15:39:55]: [Client #658] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:39:55]: [Server #615782] Received 0.26 MB of payload data from client #658 (simulated).
[INFO][15:39:55]: [Client #477] Woke up.
[INFO][15:39:55]: [Client #477] Epoch: [2/5][0/15]	Loss: 0.794042
[INFO][15:39:55]: [Client #477] Epoch: [2/5][10/15]	Loss: 0.636057
[INFO][15:39:56]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][15:39:58]: [Client #477] Woke up.
[INFO][15:39:58]: [Client #477] Epoch: [3/5][0/15]	Loss: 1.485476
[INFO][15:39:58]: [Client #477] Epoch: [3/5][10/15]	Loss: 1.094179
[INFO][15:39:58]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][15:40:01]: [Client #477] Woke up.
[INFO][15:40:01]: [Client #477] Epoch: [4/5][0/15]	Loss: 1.154094
[INFO][15:40:01]: [Client #477] Epoch: [4/5][10/15]	Loss: 1.182749
[INFO][15:40:01]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][15:40:03]: [Client #477] Woke up.
[INFO][15:40:03]: [Client #477] Epoch: [5/5][0/15]	Loss: 1.038415
[INFO][15:40:03]: [Client #477] Epoch: [5/5][10/15]	Loss: 1.011649
[INFO][15:40:04]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][15:40:06]: [Client #477] Woke up.
[INFO][15:40:06]: [Client #477] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_477_615874.pth.
[INFO][15:40:07]: [Client #477] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_477_615874.pth.
[INFO][15:40:07]: [Client #477] Model trained.
[INFO][15:40:07]: [Client #477] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:40:07]: [Server #615782] Received 0.26 MB of payload data from client #477 (simulated).
[INFO][15:40:07]: [Server #615782] Selecting client #843 for training.
[INFO][15:40:07]: [Server #615782] Sending the current model to client #843 (simulated).
[INFO][15:40:07]: [Server #615782] Sending 0.26 MB of payload data to client #843 (simulated).
[INFO][15:40:07]: [Server #615782] Selecting client #184 for training.
[INFO][15:40:07]: [Server #615782] Sending the current model to client #184 (simulated).
[INFO][15:40:07]: [Server #615782] Sending 0.26 MB of payload data to client #184 (simulated).
[INFO][15:40:07]: [Client #843] Selected by the server.
[INFO][15:40:07]: [Client #843] Loading its data source...
[INFO][15:40:07]: Data source: FEMNIST
[INFO][15:40:07]: [Client #184] Selected by the server.
[INFO][15:40:07]: [Client #184] Loading its data source...
[INFO][15:40:07]: Data source: FEMNIST
[INFO][15:40:07]: [Client #184] Dataset size: 159
[INFO][15:40:07]: [Client #184] Sampler: all_inclusive
[INFO][15:40:07]: [Client #843] Dataset size: 162
[INFO][15:40:07]: [Client #843] Sampler: all_inclusive
[INFO][15:40:07]: [Client #843] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:40:07]: [Client #184] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:40:07]: [93m[1m[Client #184] Started training in communication round #12.[0m
[INFO][15:40:07]: [93m[1m[Client #843] Started training in communication round #12.[0m
[INFO][15:40:09]: [Client #184] Loading the dataset.
[INFO][15:40:09]: [Client #843] Loading the dataset.
[INFO][15:40:16]: [Client #843] Epoch: [1/5][0/17]	Loss: 2.411802
[INFO][15:40:16]: [Client #184] Epoch: [1/5][0/16]	Loss: 1.665700
[INFO][15:40:16]: [Client #843] Epoch: [1/5][10/17]	Loss: 1.815212
[INFO][15:40:16]: [Client #184] Epoch: [1/5][10/16]	Loss: 1.899062
[INFO][15:40:16]: [Client #843] Going to sleep for 0.35 seconds.
[INFO][15:40:16]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:40:16]: [Client #184] Woke up.
[INFO][15:40:16]: [Client #184] Epoch: [2/5][0/16]	Loss: 1.050306
[INFO][15:40:16]: [Client #184] Epoch: [2/5][10/16]	Loss: 1.048292
[INFO][15:40:16]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:40:16]: [Client #184] Woke up.
[INFO][15:40:16]: [Client #184] Epoch: [3/5][0/16]	Loss: 0.884632
[INFO][15:40:16]: [Client #843] Woke up.
[INFO][15:40:16]: [Client #843] Epoch: [2/5][0/17]	Loss: 1.269280
[INFO][15:40:16]: [Client #184] Epoch: [3/5][10/16]	Loss: 1.267509
[INFO][15:40:16]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:40:16]: [Client #843] Epoch: [2/5][10/17]	Loss: 1.403351
[INFO][15:40:16]: [Client #843] Going to sleep for 0.35 seconds.
[INFO][15:40:16]: [Client #184] Woke up.
[INFO][15:40:16]: [Client #184] Epoch: [4/5][0/16]	Loss: 1.872584
[INFO][15:40:16]: [Client #184] Epoch: [4/5][10/16]	Loss: 0.847638
[INFO][15:40:16]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:40:17]: [Client #184] Woke up.
[INFO][15:40:17]: [Client #184] Epoch: [5/5][0/16]	Loss: 1.353524
[INFO][15:40:17]: [Client #184] Epoch: [5/5][10/16]	Loss: 1.320391
[INFO][15:40:17]: [Client #843] Woke up.
[INFO][15:40:17]: [Client #843] Epoch: [3/5][0/17]	Loss: 1.589349
[INFO][15:40:17]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][15:40:17]: [Client #184] Woke up.
[INFO][15:40:17]: [Client #184] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_615875.pth.
[INFO][15:40:17]: [Client #843] Epoch: [3/5][10/17]	Loss: 0.901819
[INFO][15:40:17]: [Client #843] Going to sleep for 0.35 seconds.
[INFO][15:40:17]: [Client #843] Woke up.
[INFO][15:40:17]: [Client #843] Epoch: [4/5][0/17]	Loss: 2.003961
[INFO][15:40:17]: [Client #843] Epoch: [4/5][10/17]	Loss: 1.305740
[INFO][15:40:17]: [Client #843] Going to sleep for 0.35 seconds.
[INFO][15:40:17]: [Client #184] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_615875.pth.
[INFO][15:40:17]: [Client #184] Model trained.
[INFO][15:40:17]: [Client #184] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:40:18]: [Server #615782] Received 0.26 MB of payload data from client #184 (simulated).
[INFO][15:40:18]: [Client #843] Woke up.
[INFO][15:40:18]: [Client #843] Epoch: [5/5][0/17]	Loss: 1.126813
[INFO][15:40:18]: [Client #843] Epoch: [5/5][10/17]	Loss: 1.732863
[INFO][15:40:18]: [Client #843] Going to sleep for 0.35 seconds.
[INFO][15:40:18]: [Client #843] Woke up.
[INFO][15:40:18]: [Client #843] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_843_615874.pth.
[INFO][15:40:19]: [Client #843] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_843_615874.pth.
[INFO][15:40:19]: [Client #843] Model trained.
[INFO][15:40:19]: [Client #843] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:40:19]: [Server #615782] Received 0.26 MB of payload data from client #843 (simulated).
[INFO][15:40:19]: [Server #615782] Selecting client #856 for training.
[INFO][15:40:19]: [Server #615782] Sending the current model to client #856 (simulated).
[INFO][15:40:19]: [Server #615782] Sending 0.26 MB of payload data to client #856 (simulated).
[INFO][15:40:19]: [Server #615782] Selecting client #363 for training.
[INFO][15:40:19]: [Server #615782] Sending the current model to client #363 (simulated).
[INFO][15:40:19]: [Server #615782] Sending 0.26 MB of payload data to client #363 (simulated).
[INFO][15:40:19]: [Client #856] Selected by the server.
[INFO][15:40:19]: [Client #856] Loading its data source...
[INFO][15:40:19]: Data source: FEMNIST
[INFO][15:40:19]: [Client #363] Selected by the server.
[INFO][15:40:19]: [Client #363] Loading its data source...
[INFO][15:40:19]: Data source: FEMNIST
[INFO][15:40:19]: [Client #856] Dataset size: 154
[INFO][15:40:19]: [Client #856] Sampler: all_inclusive
[INFO][15:40:19]: [Client #363] Dataset size: 162
[INFO][15:40:19]: [Client #363] Sampler: all_inclusive
[INFO][15:40:19]: [Client #856] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:40:19]: [Client #363] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:40:19]: [93m[1m[Client #856] Started training in communication round #12.[0m
[INFO][15:40:19]: [93m[1m[Client #363] Started training in communication round #12.[0m
[INFO][15:40:21]: [Client #856] Loading the dataset.
[INFO][15:40:21]: [Client #363] Loading the dataset.
[INFO][15:40:28]: [Client #856] Epoch: [1/5][0/16]	Loss: 0.740239
[INFO][15:40:28]: [Client #363] Epoch: [1/5][0/17]	Loss: 1.463322
[INFO][15:40:28]: [Client #363] Epoch: [1/5][10/17]	Loss: 1.113577
[INFO][15:40:28]: [Client #856] Epoch: [1/5][10/16]	Loss: 1.383557
[INFO][15:40:28]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:40:28]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][15:40:37]: [Client #363] Woke up.
[INFO][15:40:37]: [Client #363] Epoch: [2/5][0/17]	Loss: 0.493187
[INFO][15:40:37]: [Client #363] Epoch: [2/5][10/17]	Loss: 1.174434
[INFO][15:40:37]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][15:40:46]: [Client #363] Woke up.
[INFO][15:40:46]: [Client #363] Epoch: [3/5][0/17]	Loss: 0.188317
[INFO][15:40:47]: [Client #363] Epoch: [3/5][10/17]	Loss: 1.064095
[INFO][15:40:47]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][15:40:56]: [Client #363] Woke up.
[INFO][15:40:56]: [Client #363] Epoch: [4/5][0/17]	Loss: 1.277449
[INFO][15:40:56]: [Client #363] Epoch: [4/5][10/17]	Loss: 0.610284
[INFO][15:40:56]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][15:41:05]: [Client #363] Woke up.
[INFO][15:41:05]: [Client #363] Epoch: [5/5][0/17]	Loss: 1.151041
[INFO][15:41:05]: [Client #363] Epoch: [5/5][10/17]	Loss: 1.595431
[INFO][15:41:05]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][15:41:14]: [Client #363] Woke up.
[INFO][15:41:14]: [Client #363] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_615875.pth.
[INFO][15:41:15]: [Client #363] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_615875.pth.
[INFO][15:41:15]: [Client #363] Model trained.
[INFO][15:41:15]: [Client #363] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:41:15]: [Server #615782] Received 0.26 MB of payload data from client #363 (simulated).
[INFO][15:41:28]: [Client #856] Woke up.
[INFO][15:41:28]: [Client #856] Epoch: [2/5][0/16]	Loss: 0.702376
[INFO][15:41:28]: [Client #856] Epoch: [2/5][10/16]	Loss: 1.995401
[INFO][15:41:28]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:42:28]: [Client #856] Woke up.
[INFO][15:42:29]: [Client #856] Epoch: [3/5][0/16]	Loss: 1.309500
[INFO][15:42:29]: [Client #856] Epoch: [3/5][10/16]	Loss: 1.542963
[INFO][15:42:29]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:43:29]: [Client #856] Woke up.
[INFO][15:43:29]: [Client #856] Epoch: [4/5][0/16]	Loss: 0.786229
[INFO][15:43:29]: [Client #856] Epoch: [4/5][10/16]	Loss: 0.592918
[INFO][15:43:29]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:44:29]: [Client #856] Woke up.
[INFO][15:44:29]: [Client #856] Epoch: [5/5][0/16]	Loss: 0.751107
[INFO][15:44:29]: [Client #856] Epoch: [5/5][10/16]	Loss: 0.392713
[INFO][15:44:29]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:45:29]: [Client #856] Woke up.
[INFO][15:45:29]: [Client #856] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][15:45:30]: [Client #856] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][15:45:30]: [Client #856] Model trained.
[INFO][15:45:30]: [Client #856] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:45:30]: [Server #615782] Received 0.26 MB of payload data from client #856 (simulated).
[INFO][15:45:30]: [Server #615782] Selecting client #893 for training.
[INFO][15:45:30]: [Server #615782] Sending the current model to client #893 (simulated).
[INFO][15:45:30]: [Server #615782] Sending 0.26 MB of payload data to client #893 (simulated).
[INFO][15:45:30]: [Server #615782] Selecting client #28 for training.
[INFO][15:45:30]: [Server #615782] Sending the current model to client #28 (simulated).
[INFO][15:45:30]: [Server #615782] Sending 0.26 MB of payload data to client #28 (simulated).
[INFO][15:45:30]: [Client #893] Selected by the server.
[INFO][15:45:30]: [Client #893] Loading its data source...
[INFO][15:45:30]: Data source: FEMNIST
[INFO][15:45:30]: [Client #28] Selected by the server.
[INFO][15:45:30]: [Client #28] Loading its data source...
[INFO][15:45:30]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:45:30]: Data source: FEMNIST
[INFO][15:45:30]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/893.zip.
[INFO][15:45:30]: [Client #28] Dataset size: 153
[INFO][15:45:30]: [Client #28] Sampler: all_inclusive
[INFO][15:45:30]: [Client #28] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:45:30]: [93m[1m[Client #28] Started training in communication round #12.[0m
2.7%5.3%8.0%10.6%13.3%15.9%18.6%21.3%23.9%26.6%29.2%31.9%34.5%37.2%39.9%42.5%45.2%47.8%50.5%53.1%55.8%58.4%61.1%63.8%66.4%69.1%71.7%74.4%77.0%79.7%82.4%85.0%87.7%90.3%93.0%95.6%98.3%100.0%[INFO][15:45:30]: Decompressing the dataset downloaded.
[INFO][15:45:30]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/893.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:45:30]: [Client #893] Dataset size: 137
[INFO][15:45:30]: [Client #893] Sampler: all_inclusive
[INFO][15:45:30]: [Client #893] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:45:30]: [93m[1m[Client #893] Started training in communication round #12.[0m

[INFO][15:45:32]: [Client #28] Loading the dataset.
[INFO][15:45:32]: [Client #893] Loading the dataset.
[INFO][15:45:39]: [Client #28] Epoch: [1/5][0/16]	Loss: 1.538732
[INFO][15:45:39]: [Client #28] Epoch: [1/5][10/16]	Loss: 1.201963
[INFO][15:45:39]: [Client #893] Epoch: [1/5][0/14]	Loss: 1.874773
[INFO][15:45:39]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:45:39]: [Client #28] Woke up.
[INFO][15:45:39]: [Client #28] Epoch: [2/5][0/16]	Loss: 1.074512
[INFO][15:45:39]: [Client #893] Epoch: [1/5][10/14]	Loss: 2.637714
[INFO][15:45:39]: [Client #893] Going to sleep for 0.62 seconds.
[INFO][15:45:39]: [Client #28] Epoch: [2/5][10/16]	Loss: 0.174734
[INFO][15:45:39]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:45:39]: [Client #28] Woke up.
[INFO][15:45:40]: [Client #28] Epoch: [3/5][0/16]	Loss: 0.613223
[INFO][15:45:40]: [Client #28] Epoch: [3/5][10/16]	Loss: 0.597139
[INFO][15:45:40]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:45:40]: [Client #28] Woke up.
[INFO][15:45:40]: [Client #28] Epoch: [4/5][0/16]	Loss: 0.997615
[INFO][15:45:40]: [Client #28] Epoch: [4/5][10/16]	Loss: 0.708263
[INFO][15:45:40]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:45:40]: [Client #28] Woke up.
[INFO][15:45:40]: [Client #28] Epoch: [5/5][0/16]	Loss: 1.357013
[INFO][15:45:40]: [Client #28] Epoch: [5/5][10/16]	Loss: 2.306901
[INFO][15:45:40]: [Client #893] Woke up.
[INFO][15:45:40]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][15:45:40]: [Client #893] Epoch: [2/5][0/14]	Loss: 0.957462
[INFO][15:45:40]: [Client #28] Woke up.
[INFO][15:45:40]: [Client #28] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_615875.pth.
[INFO][15:45:40]: [Client #893] Epoch: [2/5][10/14]	Loss: 1.351357
[INFO][15:45:40]: [Client #893] Going to sleep for 0.62 seconds.
[INFO][15:45:41]: [Client #28] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_615875.pth.
[INFO][15:45:41]: [Client #28] Model trained.
[INFO][15:45:41]: [Client #893] Woke up.
[INFO][15:45:41]: [Client #893] Epoch: [3/5][0/14]	Loss: 0.428126
[INFO][15:45:41]: [Client #28] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:45:41]: [Server #615782] Received 0.26 MB of payload data from client #28 (simulated).
[INFO][15:45:41]: [Client #893] Epoch: [3/5][10/14]	Loss: 0.766610
[INFO][15:45:41]: [Client #893] Going to sleep for 0.62 seconds.
[INFO][15:45:41]: [Client #893] Woke up.
[INFO][15:45:42]: [Client #893] Epoch: [4/5][0/14]	Loss: 1.156565
[INFO][15:45:42]: [Client #893] Epoch: [4/5][10/14]	Loss: 1.369141
[INFO][15:45:42]: [Client #893] Going to sleep for 0.62 seconds.
[INFO][15:45:42]: [Client #893] Woke up.
[INFO][15:45:42]: [Client #893] Epoch: [5/5][0/14]	Loss: 0.642978
[INFO][15:45:42]: [Client #893] Epoch: [5/5][10/14]	Loss: 0.909002
[INFO][15:45:42]: [Client #893] Going to sleep for 0.62 seconds.
[INFO][15:45:43]: [Client #893] Woke up.
[INFO][15:45:43]: [Client #893] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_893_615874.pth.
[INFO][15:45:44]: [Client #893] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_893_615874.pth.
[INFO][15:45:44]: [Client #893] Model trained.
[INFO][15:45:44]: [Client #893] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:45:44]: [Server #615782] Received 0.26 MB of payload data from client #893 (simulated).
[INFO][15:45:44]: [Server #615782] Selecting client #86 for training.
[INFO][15:45:44]: [Server #615782] Sending the current model to client #86 (simulated).
[INFO][15:45:44]: [Server #615782] Sending 0.26 MB of payload data to client #86 (simulated).
[INFO][15:45:44]: [Client #86] Selected by the server.
[INFO][15:45:44]: [Client #86] Loading its data source...
[INFO][15:45:44]: Data source: FEMNIST
[INFO][15:45:44]: [Client #86] Dataset size: 158
[INFO][15:45:44]: [Client #86] Sampler: all_inclusive
[INFO][15:45:44]: [Client #86] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:45:44]: [93m[1m[Client #86] Started training in communication round #12.[0m
[INFO][15:45:46]: [Client #86] Loading the dataset.
[INFO][15:45:53]: [Client #86] Epoch: [1/5][0/16]	Loss: 0.812816
[INFO][15:45:53]: [Client #86] Epoch: [1/5][10/16]	Loss: 0.580075
[INFO][15:45:54]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][15:46:02]: [Client #86] Woke up.
[INFO][15:46:02]: [Client #86] Epoch: [2/5][0/16]	Loss: 0.286267
[INFO][15:46:02]: [Client #86] Epoch: [2/5][10/16]	Loss: 0.703780
[INFO][15:46:02]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][15:46:11]: [Client #86] Woke up.
[INFO][15:46:11]: [Client #86] Epoch: [3/5][0/16]	Loss: 0.824300
[INFO][15:46:11]: [Client #86] Epoch: [3/5][10/16]	Loss: 1.405943
[INFO][15:46:11]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][15:46:20]: [Client #86] Woke up.
[INFO][15:46:20]: [Client #86] Epoch: [4/5][0/16]	Loss: 1.174786
[INFO][15:46:20]: [Client #86] Epoch: [4/5][10/16]	Loss: 0.409390
[INFO][15:46:20]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][15:46:28]: [Client #86] Woke up.
[INFO][15:46:28]: [Client #86] Epoch: [5/5][0/16]	Loss: 2.019538
[INFO][15:46:29]: [Client #86] Epoch: [5/5][10/16]	Loss: 0.628428
[INFO][15:46:29]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][15:46:37]: [Client #86] Woke up.
[INFO][15:46:37]: [Client #86] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_86_615874.pth.
[INFO][15:46:38]: [Client #86] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_86_615874.pth.
[INFO][15:46:38]: [Client #86] Model trained.
[INFO][15:46:38]: [Client #86] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:46:38]: [Server #615782] Received 0.26 MB of payload data from client #86 (simulated).
[INFO][15:46:38]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #942 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #28 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #184 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #658 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #314 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #843 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #595 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #893 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #634 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #405 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #731 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #287 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #880 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #767 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #477 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #2 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #962 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #86 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #363 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #457 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #606 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #744 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #254 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Adding client #454 to the list of clients for aggregation.
[INFO][15:46:38]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.09496258 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0931547  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12059167 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13498343 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13502281 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12561796 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17308259 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1363463  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09633959 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08575006 0.         0.
 0.08654765 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08281823 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10984891 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10308312
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08634016 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12326518 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13540738 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.22871068
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15249954 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.20795029 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11054116
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12012206 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15683873 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08256478
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14730258 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.09496258 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0931547  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12059167 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13498343 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13502281 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12561796 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17308259 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1363463  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09633959 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08575006 0.         0.
 0.08654765 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08281823 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10984891 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10308312
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08634016 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12326518 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13540738 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.22871068
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15249954 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.20795029 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11054116
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12012206 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15683873 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08256478
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14730258 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.001      0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.001      0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03511554 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.001      0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.01849272 0.001      0.001      0.06819212 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03647485 0.03861004 0.001      0.001      0.04316547 0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.001      0.01879376
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.001
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05680473 0.03463896 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.03706564 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.001
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.02077264 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.001
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.03715451 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0383693  0.03241574 0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.0171969  0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03848983 0.001      0.001      0.001      0.03188406 0.001
 0.001      0.001      0.001      0.04116285 0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03809524
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.04015444 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.01742111 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.001      0.04076739
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03650413 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.001      0.001      0.001      0.001      0.02611244
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][15:47:22]: [Server #615782] Global model accuracy: 53.88%

[INFO][15:47:22]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_12.pth.
[INFO][15:47:23]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_12.pth.
[INFO][15:47:23]: [93m[1m
[Server #615782] Starting round 13/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  6e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  5e-05  3e-09  4e-10
 8:  7.5999e+00  7.5998e+00  4e-05  3e-09  3e-10
 9:  7.5999e+00  7.5998e+00  3e-05  5e-09  6e-10
10:  7.5999e+00  7.5998e+00  4e-06  1e-08  2e-09
Optimal solution found.
The calculated probability is:  [8.55763068e-05 8.55617174e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55622675e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55512199e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55444779e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55479616e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55476904e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55454964e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55425956e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55600907e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55653250e-05 8.55763068e-05 8.55763068e-05
 8.55625524e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55664769e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55585309e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55575074e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55632818e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55500955e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55454746e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.53173648e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55391820e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.54979298e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 9.14595681e-01 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55520408e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55444051e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55717816e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55412111e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05 8.55763068e-05
 8.55763068e-05 8.55763068e-05 8.55763068e-05][INFO][15:47:25]: [Server #615782] Selected clients: [870 433 692 119 902 480 947 553  85 202 853 705 896 329 528 650 594 231
 426 248 845 987  67 713 330]
[INFO][15:47:25]: [Server #615782] Selecting client #870 for training.
[INFO][15:47:25]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][15:47:25]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][15:47:25]: [Server #615782] Selecting client #433 for training.
[INFO][15:47:25]: [Server #615782] Sending the current model to client #433 (simulated).
[INFO][15:47:26]: [Server #615782] Sending 0.26 MB of payload data to client #433 (simulated).
[INFO][15:47:26]: [Client #870] Selected by the server.
[INFO][15:47:26]: [Client #870] Loading its data source...
[INFO][15:47:26]: Data source: FEMNIST
[INFO][15:47:26]: [Client #433] Selected by the server.
[INFO][15:47:26]: [Client #433] Loading its data source...
[INFO][15:47:26]: Data source: FEMNIST
[INFO][15:47:26]: [Client #870] Dataset size: 148
[INFO][15:47:26]: [Client #870] Sampler: all_inclusive
[INFO][15:47:26]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:47:26]: [93m[1m[Client #870] Started training in communication round #13.[0m
[INFO][15:47:26]: [Client #433] Dataset size: 240
[INFO][15:47:26]: [Client #433] Sampler: all_inclusive
[INFO][15:47:26]: [Client #433] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:47:26]: [93m[1m[Client #433] Started training in communication round #13.[0m
[INFO][15:47:28]: [Client #870] Loading the dataset.
[INFO][15:47:28]: [Client #433] Loading the dataset.
[INFO][15:47:35]: [Client #870] Epoch: [1/5][0/15]	Loss: 1.324419
[INFO][15:47:35]: [Client #433] Epoch: [1/5][0/24]	Loss: 2.062582
[INFO][15:47:35]: [Client #870] Epoch: [1/5][10/15]	Loss: 1.491315
[INFO][15:47:35]: [Client #433] Epoch: [1/5][10/24]	Loss: 1.521580
[INFO][15:47:35]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:47:35]: [Client #433] Epoch: [1/5][20/24]	Loss: 2.334492
[INFO][15:47:35]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][15:47:36]: [Client #433] Woke up.
[INFO][15:47:36]: [Client #433] Epoch: [2/5][0/24]	Loss: 0.987317
[INFO][15:47:36]: [Client #433] Epoch: [2/5][10/24]	Loss: 1.791436
[INFO][15:47:36]: [Client #433] Epoch: [2/5][20/24]	Loss: 1.794819
[INFO][15:47:36]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][15:47:37]: [Client #433] Woke up.
[INFO][15:47:37]: [Client #433] Epoch: [3/5][0/24]	Loss: 1.537565
[INFO][15:47:37]: [Client #433] Epoch: [3/5][10/24]	Loss: 1.834056
[INFO][15:47:38]: [Client #433] Epoch: [3/5][20/24]	Loss: 0.978924
[INFO][15:47:38]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][15:47:38]: [Client #433] Woke up.
[INFO][15:47:39]: [Client #433] Epoch: [4/5][0/24]	Loss: 1.448285
[INFO][15:47:39]: [Client #433] Epoch: [4/5][10/24]	Loss: 1.396200
[INFO][15:47:39]: [Client #433] Epoch: [4/5][20/24]	Loss: 1.207601
[INFO][15:47:39]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][15:47:40]: [Client #433] Woke up.
[INFO][15:47:40]: [Client #433] Epoch: [5/5][0/24]	Loss: 1.647308
[INFO][15:47:40]: [Client #433] Epoch: [5/5][10/24]	Loss: 2.254408
[INFO][15:47:40]: [Client #433] Epoch: [5/5][20/24]	Loss: 2.142716
[INFO][15:47:40]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][15:47:41]: [Client #433] Woke up.
[INFO][15:47:41]: [Client #433] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_615875.pth.
[INFO][15:47:41]: [Client #433] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_615875.pth.
[INFO][15:47:41]: [Client #433] Model trained.
[INFO][15:47:41]: [Client #433] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:47:41]: [Server #615782] Received 0.26 MB of payload data from client #433 (simulated).
[INFO][15:48:35]: [Client #870] Woke up.
[INFO][15:48:35]: [Client #870] Epoch: [2/5][0/15]	Loss: 0.795538
[INFO][15:48:35]: [Client #870] Epoch: [2/5][10/15]	Loss: 2.199291
[INFO][15:48:36]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:49:36]: [Client #870] Woke up.
[INFO][15:49:36]: [Client #870] Epoch: [3/5][0/15]	Loss: 0.888336
[INFO][15:49:36]: [Client #870] Epoch: [3/5][10/15]	Loss: 0.255671
[INFO][15:49:36]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:50:36]: [Client #870] Woke up.
[INFO][15:50:36]: [Client #870] Epoch: [4/5][0/15]	Loss: 0.163686
[INFO][15:50:36]: [Client #870] Epoch: [4/5][10/15]	Loss: 0.878621
[INFO][15:50:36]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:51:36]: [Client #870] Woke up.
[INFO][15:51:36]: [Client #870] Epoch: [5/5][0/15]	Loss: 0.950087
[INFO][15:51:36]: [Client #870] Epoch: [5/5][10/15]	Loss: 0.541035
[INFO][15:51:36]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][15:52:36]: [Client #870] Woke up.
[INFO][15:52:37]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][15:52:37]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][15:52:37]: [Client #870] Model trained.
[INFO][15:52:37]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:52:37]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][15:52:37]: [Server #615782] Selecting client #692 for training.
[INFO][15:52:37]: [Server #615782] Sending the current model to client #692 (simulated).
[INFO][15:52:37]: [Server #615782] Sending 0.26 MB of payload data to client #692 (simulated).
[INFO][15:52:37]: [Server #615782] Selecting client #119 for training.
[INFO][15:52:37]: [Server #615782] Sending the current model to client #119 (simulated).
[INFO][15:52:37]: [Server #615782] Sending 0.26 MB of payload data to client #119 (simulated).
[INFO][15:52:37]: [Client #692] Selected by the server.
[INFO][15:52:37]: [Client #692] Loading its data source...
[INFO][15:52:37]: Data source: FEMNIST
[INFO][15:52:37]: [Client #119] Selected by the server.
[INFO][15:52:37]: [Client #119] Loading its data source...
[INFO][15:52:37]: Data source: FEMNIST
[INFO][15:52:37]: [Client #119] Dataset size: 162
[INFO][15:52:37]: [Client #119] Sampler: all_inclusive
[INFO][15:52:37]: [Client #692] Dataset size: 164
[INFO][15:52:37]: [Client #692] Sampler: all_inclusive
[INFO][15:52:37]: [Client #692] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:52:37]: [Client #119] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:52:37]: [93m[1m[Client #692] Started training in communication round #13.[0m
[INFO][15:52:37]: [93m[1m[Client #119] Started training in communication round #13.[0m
[INFO][15:52:39]: [Client #119] Loading the dataset.
[INFO][15:52:39]: [Client #692] Loading the dataset.
[INFO][15:52:46]: [Client #119] Epoch: [1/5][0/17]	Loss: 0.986081
[INFO][15:52:46]: [Client #692] Epoch: [1/5][0/17]	Loss: 0.353738
[INFO][15:52:46]: [Client #119] Epoch: [1/5][10/17]	Loss: 1.254172
[INFO][15:52:46]: [Client #692] Epoch: [1/5][10/17]	Loss: 1.005762
[INFO][15:52:47]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][15:52:47]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][15:52:49]: [Client #119] Woke up.
[INFO][15:52:49]: [Client #119] Epoch: [2/5][0/17]	Loss: 0.678665
[INFO][15:52:49]: [Client #119] Epoch: [2/5][10/17]	Loss: 0.117912
[INFO][15:52:49]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][15:52:50]: [Client #692] Woke up.
[INFO][15:52:50]: [Client #692] Epoch: [2/5][0/17]	Loss: 0.534930
[INFO][15:52:50]: [Client #692] Epoch: [2/5][10/17]	Loss: 2.841006
[INFO][15:52:50]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][15:52:52]: [Client #119] Woke up.
[INFO][15:52:52]: [Client #119] Epoch: [3/5][0/17]	Loss: 0.574211
[INFO][15:52:52]: [Client #119] Epoch: [3/5][10/17]	Loss: 0.394217
[INFO][15:52:52]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][15:52:54]: [Client #692] Woke up.
[INFO][15:52:54]: [Client #692] Epoch: [3/5][0/17]	Loss: 0.363797
[INFO][15:52:54]: [Client #692] Epoch: [3/5][10/17]	Loss: 0.362968
[INFO][15:52:54]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][15:52:54]: [Client #119] Woke up.
[INFO][15:52:54]: [Client #119] Epoch: [4/5][0/17]	Loss: 0.237959
[INFO][15:52:54]: [Client #119] Epoch: [4/5][10/17]	Loss: 0.999090
[INFO][15:52:54]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][15:52:57]: [Client #119] Woke up.
[INFO][15:52:57]: [Client #119] Epoch: [5/5][0/17]	Loss: 0.021293
[INFO][15:52:57]: [Client #119] Epoch: [5/5][10/17]	Loss: 1.117276
[INFO][15:52:57]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][15:52:57]: [Client #692] Woke up.
[INFO][15:52:57]: [Client #692] Epoch: [4/5][0/17]	Loss: 0.732204
[INFO][15:52:57]: [Client #692] Epoch: [4/5][10/17]	Loss: 0.706291
[INFO][15:52:57]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][15:52:59]: [Client #119] Woke up.
[INFO][15:52:59]: [Client #119] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_119_615875.pth.
[INFO][15:53:00]: [Client #119] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_119_615875.pth.
[INFO][15:53:00]: [Client #119] Model trained.
[INFO][15:53:00]: [Client #119] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:53:00]: [Server #615782] Received 0.26 MB of payload data from client #119 (simulated).
[INFO][15:53:01]: [Client #692] Woke up.
[INFO][15:53:01]: [Client #692] Epoch: [5/5][0/17]	Loss: 1.106807
[INFO][15:53:01]: [Client #692] Epoch: [5/5][10/17]	Loss: 1.369950
[INFO][15:53:01]: [Client #692] Going to sleep for 3.44 seconds.
[INFO][15:53:04]: [Client #692] Woke up.
[INFO][15:53:04]: [Client #692] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_692_615874.pth.
[INFO][15:53:05]: [Client #692] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_692_615874.pth.
[INFO][15:53:05]: [Client #692] Model trained.
[INFO][15:53:05]: [Client #692] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:53:05]: [Server #615782] Received 0.26 MB of payload data from client #692 (simulated).
[INFO][15:53:05]: [Server #615782] Selecting client #902 for training.
[INFO][15:53:05]: [Server #615782] Sending the current model to client #902 (simulated).
[INFO][15:53:05]: [Server #615782] Sending 0.26 MB of payload data to client #902 (simulated).
[INFO][15:53:05]: [Server #615782] Selecting client #480 for training.
[INFO][15:53:05]: [Server #615782] Sending the current model to client #480 (simulated).
[INFO][15:53:05]: [Server #615782] Sending 0.26 MB of payload data to client #480 (simulated).
[INFO][15:53:05]: [Client #480] Selected by the server.
[INFO][15:53:05]: [Client #902] Selected by the server.
[INFO][15:53:05]: [Client #480] Loading its data source...
[INFO][15:53:05]: Data source: FEMNIST
[INFO][15:53:05]: [Client #902] Loading its data source...
[INFO][15:53:05]: Data source: FEMNIST
[INFO][15:53:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:53:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/902.zip.
[INFO][15:53:05]: [Client #480] Dataset size: 163
[INFO][15:53:05]: [Client #480] Sampler: all_inclusive
[INFO][15:53:05]: [Client #480] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:53:05]: [93m[1m[Client #480] Started training in communication round #13.[0m
2.2%4.4%6.6%8.7%10.9%13.1%15.3%17.5%19.7%21.9%24.1%26.2%28.4%30.6%32.8%35.0%37.2%39.4%41.6%43.7%45.9%48.1%50.3%52.5%54.7%56.9%59.0%61.2%63.4%65.6%67.8%70.0%72.2%74.4%76.5%78.7%80.9%83.1%85.3%87.5%89.7%91.9%94.0%96.2%98.4%100.0%[INFO][15:53:05]: Decompressing the dataset downloaded.
[INFO][15:53:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/902.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:53:05]: [Client #902] Dataset size: 163
[INFO][15:53:05]: [Client #902] Sampler: all_inclusive
[INFO][15:53:05]: [Client #902] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:53:05]: [93m[1m[Client #902] Started training in communication round #13.[0m

[INFO][15:53:07]: [Client #480] Loading the dataset.
[INFO][15:53:07]: [Client #902] Loading the dataset.
[INFO][15:53:14]: [Client #480] Epoch: [1/5][0/17]	Loss: 1.202832
[INFO][15:53:14]: [Client #902] Epoch: [1/5][0/17]	Loss: 0.670798
[INFO][15:53:14]: [Client #480] Epoch: [1/5][10/17]	Loss: 0.517502
[INFO][15:53:14]: [Client #902] Epoch: [1/5][10/17]	Loss: 0.870308
[INFO][15:53:14]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][15:53:14]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][15:53:15]: [Client #480] Woke up.
[INFO][15:53:15]: [Client #480] Epoch: [2/5][0/17]	Loss: 1.184281
[INFO][15:53:15]: [Client #480] Epoch: [2/5][10/17]	Loss: 0.951667
[INFO][15:53:15]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][15:53:17]: [Client #480] Woke up.
[INFO][15:53:17]: [Client #480] Epoch: [3/5][0/17]	Loss: 0.297045
[INFO][15:53:17]: [Client #480] Epoch: [3/5][10/17]	Loss: 1.081199
[INFO][15:53:17]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][15:53:18]: [Client #480] Woke up.
[INFO][15:53:18]: [Client #480] Epoch: [4/5][0/17]	Loss: 0.941960
[INFO][15:53:18]: [Client #480] Epoch: [4/5][10/17]	Loss: 1.586349
[INFO][15:53:18]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][15:53:19]: [Client #480] Woke up.
[INFO][15:53:19]: [Client #480] Epoch: [5/5][0/17]	Loss: 0.904799
[INFO][15:53:19]: [Client #480] Epoch: [5/5][10/17]	Loss: 0.928956
[INFO][15:53:19]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][15:53:20]: [Client #480] Woke up.
[INFO][15:53:20]: [Client #480] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_480_615875.pth.
[INFO][15:53:21]: [Client #480] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_480_615875.pth.
[INFO][15:53:21]: [Client #480] Model trained.
[INFO][15:53:21]: [Client #480] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:53:21]: [Server #615782] Received 0.26 MB of payload data from client #480 (simulated).
[INFO][15:53:24]: [Client #902] Woke up.
[INFO][15:53:24]: [Client #902] Epoch: [2/5][0/17]	Loss: 0.837144
[INFO][15:53:25]: [Client #902] Epoch: [2/5][10/17]	Loss: 1.219879
[INFO][15:53:25]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][15:53:35]: [Client #902] Woke up.
[INFO][15:53:35]: [Client #902] Epoch: [3/5][0/17]	Loss: 1.292025
[INFO][15:53:35]: [Client #902] Epoch: [3/5][10/17]	Loss: 1.333164
[INFO][15:53:35]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][15:53:45]: [Client #902] Woke up.
[INFO][15:53:45]: [Client #902] Epoch: [4/5][0/17]	Loss: 1.286379
[INFO][15:53:45]: [Client #902] Epoch: [4/5][10/17]	Loss: 0.712857
[INFO][15:53:45]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][15:53:56]: [Client #902] Woke up.
[INFO][15:53:56]: [Client #902] Epoch: [5/5][0/17]	Loss: 0.404031
[INFO][15:53:56]: [Client #902] Epoch: [5/5][10/17]	Loss: 1.126977
[INFO][15:53:56]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][15:54:06]: [Client #902] Woke up.
[INFO][15:54:06]: [Client #902] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_902_615874.pth.
[INFO][15:54:07]: [Client #902] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_902_615874.pth.
[INFO][15:54:07]: [Client #902] Model trained.
[INFO][15:54:07]: [Client #902] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:54:07]: [Server #615782] Received 0.26 MB of payload data from client #902 (simulated).
[INFO][15:54:07]: [Server #615782] Selecting client #947 for training.
[INFO][15:54:07]: [Server #615782] Sending the current model to client #947 (simulated).
[INFO][15:54:07]: [Server #615782] Sending 0.26 MB of payload data to client #947 (simulated).
[INFO][15:54:07]: [Server #615782] Selecting client #553 for training.
[INFO][15:54:07]: [Server #615782] Sending the current model to client #553 (simulated).
[INFO][15:54:07]: [Server #615782] Sending 0.26 MB of payload data to client #553 (simulated).
[INFO][15:54:07]: [Client #947] Selected by the server.
[INFO][15:54:07]: [Client #947] Loading its data source...
[INFO][15:54:07]: Data source: FEMNIST
[INFO][15:54:07]: [Client #553] Selected by the server.
[INFO][15:54:07]: [Client #553] Loading its data source...
[INFO][15:54:07]: Data source: FEMNIST
[INFO][15:54:07]: [Client #553] Dataset size: 164
[INFO][15:54:07]: [Client #553] Sampler: all_inclusive
[INFO][15:54:07]: [Client #947] Dataset size: 153
[INFO][15:54:07]: [Client #947] Sampler: all_inclusive
[INFO][15:54:07]: [Client #553] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:07]: [Client #947] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:07]: [93m[1m[Client #553] Started training in communication round #13.[0m
[INFO][15:54:07]: [93m[1m[Client #947] Started training in communication round #13.[0m
[INFO][15:54:09]: [Client #947] Loading the dataset.
[INFO][15:54:09]: [Client #553] Loading the dataset.
[INFO][15:54:16]: [Client #947] Epoch: [1/5][0/16]	Loss: 1.587136
[INFO][15:54:16]: [Client #947] Epoch: [1/5][10/16]	Loss: 0.992049
[INFO][15:54:16]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][15:54:16]: [Client #553] Epoch: [1/5][0/17]	Loss: 1.627893
[INFO][15:54:16]: [Client #553] Epoch: [1/5][10/17]	Loss: 1.230906
[INFO][15:54:16]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][15:54:16]: [Client #947] Woke up.
[INFO][15:54:16]: [Client #947] Epoch: [2/5][0/16]	Loss: 0.296016
[INFO][15:54:16]: [Client #947] Epoch: [2/5][10/16]	Loss: 0.939613
[INFO][15:54:16]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][15:54:17]: [Client #947] Woke up.
[INFO][15:54:17]: [Client #947] Epoch: [3/5][0/16]	Loss: 2.151397
[INFO][15:54:17]: [Client #947] Epoch: [3/5][10/16]	Loss: 1.692234
[INFO][15:54:17]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][15:54:17]: [Client #947] Woke up.
[INFO][15:54:17]: [Client #947] Epoch: [4/5][0/16]	Loss: 1.205152
[INFO][15:54:17]: [Client #947] Epoch: [4/5][10/16]	Loss: 1.072397
[INFO][15:54:17]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][15:54:18]: [Client #947] Woke up.
[INFO][15:54:18]: [Client #947] Epoch: [5/5][0/16]	Loss: 0.476854
[INFO][15:54:18]: [Client #947] Epoch: [5/5][10/16]	Loss: 1.257342
[INFO][15:54:18]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][15:54:18]: [Client #947] Woke up.
[INFO][15:54:18]: [Client #947] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_947_615874.pth.
[INFO][15:54:19]: [Client #553] Woke up.
[INFO][15:54:19]: [Client #947] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_947_615874.pth.
[INFO][15:54:19]: [Client #553] Epoch: [2/5][0/17]	Loss: 2.102532
[INFO][15:54:19]: [Client #947] Model trained.
[INFO][15:54:19]: [Client #947] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:54:19]: [Server #615782] Received 0.26 MB of payload data from client #947 (simulated).
[INFO][15:54:19]: [Client #553] Epoch: [2/5][10/17]	Loss: 1.622552
[INFO][15:54:19]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][15:54:22]: [Client #553] Woke up.
[INFO][15:54:22]: [Client #553] Epoch: [3/5][0/17]	Loss: 1.696773
[INFO][15:54:22]: [Client #553] Epoch: [3/5][10/17]	Loss: 1.644747
[INFO][15:54:22]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][15:54:25]: [Client #553] Woke up.
[INFO][15:54:25]: [Client #553] Epoch: [4/5][0/17]	Loss: 1.313604
[INFO][15:54:25]: [Client #553] Epoch: [4/5][10/17]	Loss: 1.429602
[INFO][15:54:26]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][15:54:29]: [Client #553] Woke up.
[INFO][15:54:29]: [Client #553] Epoch: [5/5][0/17]	Loss: 0.980119
[INFO][15:54:29]: [Client #553] Epoch: [5/5][10/17]	Loss: 1.529067
[INFO][15:54:29]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][15:54:32]: [Client #553] Woke up.
[INFO][15:54:32]: [Client #553] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615875.pth.
[INFO][15:54:33]: [Client #553] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615875.pth.
[INFO][15:54:33]: [Client #553] Model trained.
[INFO][15:54:33]: [Client #553] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:54:33]: [Server #615782] Received 0.26 MB of payload data from client #553 (simulated).
[INFO][15:54:33]: [Server #615782] Selecting client #85 for training.
[INFO][15:54:33]: [Server #615782] Sending the current model to client #85 (simulated).
[INFO][15:54:33]: [Server #615782] Sending 0.26 MB of payload data to client #85 (simulated).
[INFO][15:54:33]: [Server #615782] Selecting client #202 for training.
[INFO][15:54:33]: [Server #615782] Sending the current model to client #202 (simulated).
[INFO][15:54:33]: [Server #615782] Sending 0.26 MB of payload data to client #202 (simulated).
[INFO][15:54:33]: [Client #202] Selected by the server.
[INFO][15:54:33]: [Client #85] Selected by the server.
[INFO][15:54:33]: [Client #202] Loading its data source...
[INFO][15:54:33]: [Client #85] Loading its data source...
[INFO][15:54:33]: Data source: FEMNIST
[INFO][15:54:33]: Data source: FEMNIST
[INFO][15:54:33]: [Client #85] Dataset size: 155
[INFO][15:54:33]: [Client #85] Sampler: all_inclusive
[INFO][15:54:33]: [Client #85] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:33]: [93m[1m[Client #85] Started training in communication round #13.[0m
[INFO][15:54:33]: [Client #202] Dataset size: 165
[INFO][15:54:33]: [Client #202] Sampler: all_inclusive
[INFO][15:54:33]: [Client #202] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:33]: [93m[1m[Client #202] Started training in communication round #13.[0m
[INFO][15:54:35]: [Client #202] Loading the dataset.
[INFO][15:54:35]: [Client #85] Loading the dataset.
[INFO][15:54:42]: [Client #85] Epoch: [1/5][0/16]	Loss: 0.769030
[INFO][15:54:42]: [Client #202] Epoch: [1/5][0/17]	Loss: 0.490793
[INFO][15:54:42]: [Client #202] Epoch: [1/5][10/17]	Loss: 1.266493
[INFO][15:54:42]: [Client #85] Epoch: [1/5][10/16]	Loss: 2.178640
[INFO][15:54:42]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][15:54:42]: [Client #202] Going to sleep for 1.26 seconds.
[INFO][15:54:42]: [Client #85] Woke up.
[INFO][15:54:42]: [Client #85] Epoch: [2/5][0/16]	Loss: 1.316034
[INFO][15:54:42]: [Client #85] Epoch: [2/5][10/16]	Loss: 1.887237
[INFO][15:54:42]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][15:54:43]: [Client #85] Woke up.
[INFO][15:54:43]: [Client #85] Epoch: [3/5][0/16]	Loss: 1.622898
[INFO][15:54:43]: [Client #85] Epoch: [3/5][10/16]	Loss: 1.834975
[INFO][15:54:43]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][15:54:43]: [Client #202] Woke up.
[INFO][15:54:43]: [Client #202] Epoch: [2/5][0/17]	Loss: 1.118268
[INFO][15:54:43]: [Client #202] Epoch: [2/5][10/17]	Loss: 1.798151
[INFO][15:54:43]: [Client #85] Woke up.
[INFO][15:54:43]: [Client #202] Going to sleep for 1.26 seconds.
[INFO][15:54:43]: [Client #85] Epoch: [4/5][0/16]	Loss: 0.756503
[INFO][15:54:43]: [Client #85] Epoch: [4/5][10/16]	Loss: 1.793422
[INFO][15:54:43]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][15:54:44]: [Client #85] Woke up.
[INFO][15:54:44]: [Client #85] Epoch: [5/5][0/16]	Loss: 1.025616
[INFO][15:54:44]: [Client #85] Epoch: [5/5][10/16]	Loss: 1.423710
[INFO][15:54:44]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][15:54:44]: [Client #85] Woke up.
[INFO][15:54:44]: [Client #85] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_615874.pth.
[INFO][15:54:45]: [Client #202] Woke up.
[INFO][15:54:45]: [Client #202] Epoch: [3/5][0/17]	Loss: 0.903246
[INFO][15:54:45]: [Client #202] Epoch: [3/5][10/17]	Loss: 0.456066
[INFO][15:54:45]: [Client #202] Going to sleep for 1.26 seconds.
[INFO][15:54:45]: [Client #85] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_615874.pth.
[INFO][15:54:45]: [Client #85] Model trained.
[INFO][15:54:45]: [Client #85] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:54:45]: [Server #615782] Received 0.26 MB of payload data from client #85 (simulated).
[INFO][15:54:46]: [Client #202] Woke up.
[INFO][15:54:46]: [Client #202] Epoch: [4/5][0/17]	Loss: 0.586553
[INFO][15:54:46]: [Client #202] Epoch: [4/5][10/17]	Loss: 0.586689
[INFO][15:54:46]: [Client #202] Going to sleep for 1.26 seconds.
[INFO][15:54:47]: [Client #202] Woke up.
[INFO][15:54:47]: [Client #202] Epoch: [5/5][0/17]	Loss: 0.708353
[INFO][15:54:48]: [Client #202] Epoch: [5/5][10/17]	Loss: 1.471202
[INFO][15:54:48]: [Client #202] Going to sleep for 1.26 seconds.
[INFO][15:54:49]: [Client #202] Woke up.
[INFO][15:54:49]: [Client #202] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_202_615875.pth.
[INFO][15:54:49]: [Client #202] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_202_615875.pth.
[INFO][15:54:49]: [Client #202] Model trained.
[INFO][15:54:49]: [Client #202] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:54:49]: [Server #615782] Received 0.26 MB of payload data from client #202 (simulated).
[INFO][15:54:49]: [Server #615782] Selecting client #853 for training.
[INFO][15:54:49]: [Server #615782] Sending the current model to client #853 (simulated).
[INFO][15:54:49]: [Server #615782] Sending 0.26 MB of payload data to client #853 (simulated).
[INFO][15:54:49]: [Server #615782] Selecting client #705 for training.
[INFO][15:54:49]: [Server #615782] Sending the current model to client #705 (simulated).
[INFO][15:54:49]: [Server #615782] Sending 0.26 MB of payload data to client #705 (simulated).
[INFO][15:54:49]: [Client #853] Selected by the server.
[INFO][15:54:49]: [Client #705] Selected by the server.
[INFO][15:54:49]: [Client #853] Loading its data source...
[INFO][15:54:49]: [Client #705] Loading its data source...
[INFO][15:54:49]: Data source: FEMNIST
[INFO][15:54:49]: Data source: FEMNIST
[INFO][15:54:50]: [Client #853] Dataset size: 157
[INFO][15:54:50]: [Client #853] Sampler: all_inclusive
[INFO][15:54:50]: [Client #705] Dataset size: 162
[INFO][15:54:50]: [Client #705] Sampler: all_inclusive
[INFO][15:54:50]: [Client #853] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:50]: [Client #705] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:54:50]: [93m[1m[Client #853] Started training in communication round #13.[0m
[INFO][15:54:50]: [93m[1m[Client #705] Started training in communication round #13.[0m
[INFO][15:54:52]: [Client #853] Loading the dataset.
[INFO][15:54:52]: [Client #705] Loading the dataset.
[INFO][15:54:59]: [Client #705] Epoch: [1/5][0/17]	Loss: 0.693210
[INFO][15:54:59]: [Client #853] Epoch: [1/5][0/16]	Loss: 2.278517
[INFO][15:54:59]: [Client #705] Epoch: [1/5][10/17]	Loss: 0.966922
[INFO][15:54:59]: [Client #705] Going to sleep for 0.84 seconds.
[INFO][15:54:59]: [Client #853] Epoch: [1/5][10/16]	Loss: 0.647128
[INFO][15:54:59]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][15:55:00]: [Client #705] Woke up.
[INFO][15:55:00]: [Client #705] Epoch: [2/5][0/17]	Loss: 0.588596
[INFO][15:55:00]: [Client #705] Epoch: [2/5][10/17]	Loss: 0.521783
[INFO][15:55:00]: [Client #705] Going to sleep for 0.84 seconds.
[INFO][15:55:01]: [Client #853] Woke up.
[INFO][15:55:01]: [Client #853] Epoch: [2/5][0/16]	Loss: 1.790184
[INFO][15:55:01]: [Client #705] Woke up.
[INFO][15:55:01]: [Client #705] Epoch: [3/5][0/17]	Loss: 0.709978
[INFO][15:55:01]: [Client #853] Epoch: [2/5][10/16]	Loss: 1.289180
[INFO][15:55:01]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][15:55:01]: [Client #705] Epoch: [3/5][10/17]	Loss: 0.422099
[INFO][15:55:01]: [Client #705] Going to sleep for 0.84 seconds.
[INFO][15:55:02]: [Client #705] Woke up.
[INFO][15:55:02]: [Client #705] Epoch: [4/5][0/17]	Loss: 1.048754
[INFO][15:55:02]: [Client #705] Epoch: [4/5][10/17]	Loss: 0.956547
[INFO][15:55:02]: [Client #705] Going to sleep for 0.84 seconds.
[INFO][15:55:03]: [Client #853] Woke up.
[INFO][15:55:03]: [Client #853] Epoch: [3/5][0/16]	Loss: 1.645463
[INFO][15:55:03]: [Client #853] Epoch: [3/5][10/16]	Loss: 0.506043
[INFO][15:55:03]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][15:55:03]: [Client #705] Woke up.
[INFO][15:55:03]: [Client #705] Epoch: [5/5][0/17]	Loss: 1.076695
[INFO][15:55:03]: [Client #705] Epoch: [5/5][10/17]	Loss: 0.694125
[INFO][15:55:03]: [Client #705] Going to sleep for 0.84 seconds.
[INFO][15:55:04]: [Client #705] Woke up.
[INFO][15:55:04]: [Client #705] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_705_615875.pth.
[INFO][15:55:05]: [Client #853] Woke up.
[INFO][15:55:05]: [Client #853] Epoch: [4/5][0/16]	Loss: 1.267492
[INFO][15:55:05]: [Client #853] Epoch: [4/5][10/16]	Loss: 1.153634
[INFO][15:55:05]: [Client #705] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_705_615875.pth.
[INFO][15:55:05]: [Client #705] Model trained.
[INFO][15:55:05]: [Client #705] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:05]: [Server #615782] Received 0.26 MB of payload data from client #705 (simulated).
[INFO][15:55:05]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][15:55:06]: [Client #853] Woke up.
[INFO][15:55:06]: [Client #853] Epoch: [5/5][0/16]	Loss: 0.522212
[INFO][15:55:06]: [Client #853] Epoch: [5/5][10/16]	Loss: 0.242850
[INFO][15:55:07]: [Client #853] Going to sleep for 1.73 seconds.
[INFO][15:55:08]: [Client #853] Woke up.
[INFO][15:55:08]: [Client #853] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_853_615874.pth.
[INFO][15:55:09]: [Client #853] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_853_615874.pth.
[INFO][15:55:09]: [Client #853] Model trained.
[INFO][15:55:09]: [Client #853] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:09]: [Server #615782] Received 0.26 MB of payload data from client #853 (simulated).
[INFO][15:55:09]: [Server #615782] Selecting client #896 for training.
[INFO][15:55:09]: [Server #615782] Sending the current model to client #896 (simulated).
[INFO][15:55:09]: [Server #615782] Sending 0.26 MB of payload data to client #896 (simulated).
[INFO][15:55:09]: [Server #615782] Selecting client #329 for training.
[INFO][15:55:09]: [Server #615782] Sending the current model to client #329 (simulated).
[INFO][15:55:09]: [Server #615782] Sending 0.26 MB of payload data to client #329 (simulated).
[INFO][15:55:09]: [Client #896] Selected by the server.
[INFO][15:55:09]: [Client #896] Loading its data source...
[INFO][15:55:09]: Data source: FEMNIST
[INFO][15:55:09]: [Client #329] Selected by the server.
[INFO][15:55:09]: [Client #329] Loading its data source...
[INFO][15:55:09]: Data source: FEMNIST
[INFO][15:55:09]: [Client #896] Dataset size: 122
[INFO][15:55:09]: [Client #896] Sampler: all_inclusive
[INFO][15:55:09]: [Client #896] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:09]: [93m[1m[Client #896] Started training in communication round #13.[0m
[INFO][15:55:09]: [Client #329] Dataset size: 154
[INFO][15:55:09]: [Client #329] Sampler: all_inclusive
[INFO][15:55:09]: [Client #329] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:09]: [93m[1m[Client #329] Started training in communication round #13.[0m
[INFO][15:55:11]: [Client #896] Loading the dataset.
[INFO][15:55:11]: [Client #329] Loading the dataset.
[INFO][15:55:18]: [Client #896] Epoch: [1/5][0/13]	Loss: 0.583669
[INFO][15:55:18]: [Client #329] Epoch: [1/5][0/16]	Loss: 1.165571
[INFO][15:55:18]: [Client #896] Epoch: [1/5][10/13]	Loss: 2.393907
[INFO][15:55:18]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][15:55:18]: [Client #329] Epoch: [1/5][10/16]	Loss: 0.851283
[INFO][15:55:18]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][15:55:19]: [Client #896] Woke up.
[INFO][15:55:19]: [Client #896] Epoch: [2/5][0/13]	Loss: 1.233636
[INFO][15:55:19]: [Client #896] Epoch: [2/5][10/13]	Loss: 0.445743
[INFO][15:55:19]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][15:55:19]: [Client #329] Woke up.
[INFO][15:55:19]: [Client #896] Woke up.
[INFO][15:55:19]: [Client #329] Epoch: [2/5][0/16]	Loss: 0.509667
[INFO][15:55:19]: [Client #896] Epoch: [3/5][0/13]	Loss: 1.916944
[INFO][15:55:20]: [Client #329] Epoch: [2/5][10/16]	Loss: 0.268545
[INFO][15:55:20]: [Client #896] Epoch: [3/5][10/13]	Loss: 1.293527
[INFO][15:55:20]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][15:55:20]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][15:55:20]: [Client #896] Woke up.
[INFO][15:55:20]: [Client #896] Epoch: [4/5][0/13]	Loss: 1.756616
[INFO][15:55:20]: [Client #896] Epoch: [4/5][10/13]	Loss: 0.840392
[INFO][15:55:20]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][15:55:21]: [Client #329] Woke up.
[INFO][15:55:21]: [Client #329] Epoch: [3/5][0/16]	Loss: 0.272994
[INFO][15:55:21]: [Client #896] Woke up.
[INFO][15:55:21]: [Client #896] Epoch: [5/5][0/13]	Loss: 0.794438
[INFO][15:55:21]: [Client #329] Epoch: [3/5][10/16]	Loss: 0.580388
[INFO][15:55:21]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][15:55:21]: [Client #896] Epoch: [5/5][10/13]	Loss: 1.808396
[INFO][15:55:21]: [Client #896] Going to sleep for 0.57 seconds.
[INFO][15:55:22]: [Client #896] Woke up.
[INFO][15:55:22]: [Client #896] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_896_615874.pth.
[INFO][15:55:22]: [Client #329] Woke up.
[INFO][15:55:22]: [Client #329] Epoch: [4/5][0/16]	Loss: 1.039451
[INFO][15:55:22]: [Client #896] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_896_615874.pth.
[INFO][15:55:22]: [Client #896] Model trained.
[INFO][15:55:22]: [Client #896] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:22]: [Server #615782] Received 0.26 MB of payload data from client #896 (simulated).
[INFO][15:55:22]: [Client #329] Epoch: [4/5][10/16]	Loss: 0.675815
[INFO][15:55:22]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][15:55:23]: [Client #329] Woke up.
[INFO][15:55:24]: [Client #329] Epoch: [5/5][0/16]	Loss: 0.966650
[INFO][15:55:24]: [Client #329] Epoch: [5/5][10/16]	Loss: 0.726904
[INFO][15:55:24]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][15:55:25]: [Client #329] Woke up.
[INFO][15:55:25]: [Client #329] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_329_615875.pth.
[INFO][15:55:25]: [Client #329] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_329_615875.pth.
[INFO][15:55:25]: [Client #329] Model trained.
[INFO][15:55:25]: [Client #329] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:25]: [Server #615782] Received 0.26 MB of payload data from client #329 (simulated).
[INFO][15:55:25]: [Server #615782] Selecting client #528 for training.
[INFO][15:55:25]: [Server #615782] Sending the current model to client #528 (simulated).
[INFO][15:55:25]: [Server #615782] Sending 0.26 MB of payload data to client #528 (simulated).
[INFO][15:55:25]: [Server #615782] Selecting client #650 for training.
[INFO][15:55:25]: [Server #615782] Sending the current model to client #650 (simulated).
[INFO][15:55:25]: [Server #615782] Sending 0.26 MB of payload data to client #650 (simulated).
[INFO][15:55:25]: [Client #528] Selected by the server.
[INFO][15:55:25]: [Client #650] Selected by the server.
[INFO][15:55:25]: [Client #528] Loading its data source...
[INFO][15:55:25]: [Client #650] Loading its data source...
[INFO][15:55:25]: Data source: FEMNIST
[INFO][15:55:26]: Data source: FEMNIST
[INFO][15:55:26]: [Client #650] Dataset size: 149
[INFO][15:55:26]: [Client #650] Sampler: all_inclusive
[INFO][15:55:26]: [Client #528] Dataset size: 165
[INFO][15:55:26]: [Client #528] Sampler: all_inclusive
[INFO][15:55:26]: [Client #650] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:26]: [Client #528] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:26]: [93m[1m[Client #650] Started training in communication round #13.[0m
[INFO][15:55:26]: [93m[1m[Client #528] Started training in communication round #13.[0m
[INFO][15:55:28]: [Client #528] Loading the dataset.
[INFO][15:55:28]: [Client #650] Loading the dataset.
[INFO][15:55:34]: [Client #528] Epoch: [1/5][0/17]	Loss: 1.512300
[INFO][15:55:34]: [Client #650] Epoch: [1/5][0/15]	Loss: 0.411144
[INFO][15:55:35]: [Client #528] Epoch: [1/5][10/17]	Loss: 1.289147
[INFO][15:55:35]: [Client #650] Epoch: [1/5][10/15]	Loss: 1.486321
[INFO][15:55:35]: [Client #650] Going to sleep for 0.35 seconds.
[INFO][15:55:35]: [Client #528] Going to sleep for 0.07 seconds.
[INFO][15:55:35]: [Client #528] Woke up.
[INFO][15:55:35]: [Client #528] Epoch: [2/5][0/17]	Loss: 1.050846
[INFO][15:55:35]: [Client #528] Epoch: [2/5][10/17]	Loss: 0.384181
[INFO][15:55:35]: [Client #528] Going to sleep for 0.07 seconds.
[INFO][15:55:35]: [Client #528] Woke up.
[INFO][15:55:35]: [Client #528] Epoch: [3/5][0/17]	Loss: 1.036452
[INFO][15:55:35]: [Client #650] Woke up.
[INFO][15:55:35]: [Client #650] Epoch: [2/5][0/15]	Loss: 1.300034
[INFO][15:55:35]: [Client #528] Epoch: [3/5][10/17]	Loss: 1.074361
[INFO][15:55:35]: [Client #528] Going to sleep for 0.07 seconds.
[INFO][15:55:35]: [Client #650] Epoch: [2/5][10/15]	Loss: 0.573443
[INFO][15:55:35]: [Client #650] Going to sleep for 0.35 seconds.
[INFO][15:55:35]: [Client #528] Woke up.
[INFO][15:55:35]: [Client #528] Epoch: [4/5][0/17]	Loss: 0.208827
[INFO][15:55:35]: [Client #528] Epoch: [4/5][10/17]	Loss: 1.857547
[INFO][15:55:35]: [Client #528] Going to sleep for 0.07 seconds.
[INFO][15:55:35]: [Client #528] Woke up.
[INFO][15:55:35]: [Client #528] Epoch: [5/5][0/17]	Loss: 0.251556
[INFO][15:55:35]: [Client #528] Epoch: [5/5][10/17]	Loss: 1.370279
[INFO][15:55:35]: [Client #650] Woke up.
[INFO][15:55:35]: [Client #650] Epoch: [3/5][0/15]	Loss: 0.153387
[INFO][15:55:35]: [Client #528] Going to sleep for 0.07 seconds.
[INFO][15:55:36]: [Client #650] Epoch: [3/5][10/15]	Loss: 1.582270
[INFO][15:55:36]: [Client #528] Woke up.
[INFO][15:55:36]: [Client #528] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_528_615874.pth.
[INFO][15:55:36]: [Client #650] Going to sleep for 0.35 seconds.
[INFO][15:55:36]: [Client #650] Woke up.
[INFO][15:55:36]: [Client #650] Epoch: [4/5][0/15]	Loss: 0.781057
[INFO][15:55:36]: [Client #650] Epoch: [4/5][10/15]	Loss: 0.511420
[INFO][15:55:36]: [Client #650] Going to sleep for 0.35 seconds.
[INFO][15:55:36]: [Client #650] Woke up.
[INFO][15:55:36]: [Client #650] Epoch: [5/5][0/15]	Loss: 0.595148
[INFO][15:55:36]: [Client #528] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_528_615874.pth.
[INFO][15:55:36]: [Client #528] Model trained.
[INFO][15:55:36]: [Client #528] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:36]: [Server #615782] Received 0.26 MB of payload data from client #528 (simulated).
[INFO][15:55:36]: [Client #650] Epoch: [5/5][10/15]	Loss: 1.540659
[INFO][15:55:37]: [Client #650] Going to sleep for 0.35 seconds.
[INFO][15:55:37]: [Client #650] Woke up.
[INFO][15:55:37]: [Client #650] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_650_615875.pth.
[INFO][15:55:38]: [Client #650] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_650_615875.pth.
[INFO][15:55:38]: [Client #650] Model trained.
[INFO][15:55:38]: [Client #650] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:38]: [Server #615782] Received 0.26 MB of payload data from client #650 (simulated).
[INFO][15:55:38]: [Server #615782] Selecting client #594 for training.
[INFO][15:55:38]: [Server #615782] Sending the current model to client #594 (simulated).
[INFO][15:55:38]: [Server #615782] Sending 0.26 MB of payload data to client #594 (simulated).
[INFO][15:55:38]: [Server #615782] Selecting client #231 for training.
[INFO][15:55:38]: [Server #615782] Sending the current model to client #231 (simulated).
[INFO][15:55:38]: [Server #615782] Sending 0.26 MB of payload data to client #231 (simulated).
[INFO][15:55:38]: [Client #594] Selected by the server.
[INFO][15:55:38]: [Client #594] Loading its data source...
[INFO][15:55:38]: [Client #231] Selected by the server.
[INFO][15:55:38]: Data source: FEMNIST
[INFO][15:55:38]: [Client #231] Loading its data source...
[INFO][15:55:38]: Data source: FEMNIST
[INFO][15:55:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:55:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/594.zip.
[INFO][15:55:38]: [Client #231] Dataset size: 153
[INFO][15:55:38]: [Client #231] Sampler: all_inclusive
[INFO][15:55:38]: [Client #231] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:38]: [93m[1m[Client #231] Started training in communication round #13.[0m
2.5%5.0%7.4%9.9%12.4%14.9%17.3%19.8%22.3%24.8%27.3%29.7%32.2%34.7%37.2%39.6%42.1%44.6%47.1%49.6%52.0%54.5%57.0%59.5%61.9%64.4%66.9%69.4%71.9%74.3%76.8%79.3%81.8%84.2%86.7%89.2%91.7%94.2%96.6%99.1%100.0%[INFO][15:55:38]: Decompressing the dataset downloaded.
[INFO][15:55:38]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/594.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:55:38]: [Client #594] Dataset size: 154
[INFO][15:55:38]: [Client #594] Sampler: all_inclusive
[INFO][15:55:38]: [Client #594] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:38]: [93m[1m[Client #594] Started training in communication round #13.[0m

[INFO][15:55:40]: [Client #231] Loading the dataset.
[INFO][15:55:40]: [Client #594] Loading the dataset.
[INFO][15:55:47]: [Client #231] Epoch: [1/5][0/16]	Loss: 0.882376
[INFO][15:55:47]: [Client #231] Epoch: [1/5][10/16]	Loss: 1.707405
[INFO][15:55:47]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][15:55:47]: [Client #594] Epoch: [1/5][0/16]	Loss: 1.549582
[INFO][15:55:47]: [Client #594] Epoch: [1/5][10/16]	Loss: 1.664110
[INFO][15:55:47]: [Client #594] Going to sleep for 0.28 seconds.
[INFO][15:55:47]: [Client #594] Woke up.
[INFO][15:55:47]: [Client #594] Epoch: [2/5][0/16]	Loss: 0.461880
[INFO][15:55:48]: [Client #594] Epoch: [2/5][10/16]	Loss: 1.085424
[INFO][15:55:48]: [Client #594] Going to sleep for 0.28 seconds.
[INFO][15:55:48]: [Client #231] Woke up.
[INFO][15:55:48]: [Client #231] Epoch: [2/5][0/16]	Loss: 0.992071
[INFO][15:55:48]: [Client #231] Epoch: [2/5][10/16]	Loss: 0.814587
[INFO][15:55:48]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][15:55:48]: [Client #594] Woke up.
[INFO][15:55:48]: [Client #594] Epoch: [3/5][0/16]	Loss: 1.150359
[INFO][15:55:48]: [Client #594] Epoch: [3/5][10/16]	Loss: 1.545062
[INFO][15:55:48]: [Client #594] Going to sleep for 0.28 seconds.
[INFO][15:55:48]: [Client #594] Woke up.
[INFO][15:55:48]: [Client #594] Epoch: [4/5][0/16]	Loss: 1.065481
[INFO][15:55:48]: [Client #594] Epoch: [4/5][10/16]	Loss: 0.508856
[INFO][15:55:48]: [Client #594] Going to sleep for 0.28 seconds.
[INFO][15:55:49]: [Client #231] Woke up.
[INFO][15:55:49]: [Client #231] Epoch: [3/5][0/16]	Loss: 0.301824
[INFO][15:55:49]: [Client #594] Woke up.
[INFO][15:55:49]: [Client #231] Epoch: [3/5][10/16]	Loss: 0.285904
[INFO][15:55:49]: [Client #594] Epoch: [5/5][0/16]	Loss: 1.343071
[INFO][15:55:49]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][15:55:49]: [Client #594] Epoch: [5/5][10/16]	Loss: 0.513946
[INFO][15:55:49]: [Client #594] Going to sleep for 0.28 seconds.
[INFO][15:55:49]: [Client #594] Woke up.
[INFO][15:55:49]: [Client #594] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_594_615874.pth.
[INFO][15:55:50]: [Client #231] Woke up.
[INFO][15:55:50]: [Client #231] Epoch: [4/5][0/16]	Loss: 0.531500
[INFO][15:55:50]: [Client #231] Epoch: [4/5][10/16]	Loss: 0.904310
[INFO][15:55:50]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][15:55:50]: [Client #594] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_594_615874.pth.
[INFO][15:55:50]: [Client #594] Model trained.
[INFO][15:55:50]: [Client #594] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:50]: [Server #615782] Received 0.26 MB of payload data from client #594 (simulated).
[INFO][15:55:51]: [Client #231] Woke up.
[INFO][15:55:51]: [Client #231] Epoch: [5/5][0/16]	Loss: 0.822435
[INFO][15:55:51]: [Client #231] Epoch: [5/5][10/16]	Loss: 0.996748
[INFO][15:55:51]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][15:55:52]: [Client #231] Woke up.
[INFO][15:55:52]: [Client #231] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_231_615875.pth.
[INFO][15:55:52]: [Client #231] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_231_615875.pth.
[INFO][15:55:52]: [Client #231] Model trained.
[INFO][15:55:52]: [Client #231] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:55:52]: [Server #615782] Received 0.26 MB of payload data from client #231 (simulated).
[INFO][15:55:52]: [Server #615782] Selecting client #426 for training.
[INFO][15:55:52]: [Server #615782] Sending the current model to client #426 (simulated).
[INFO][15:55:52]: [Server #615782] Sending 0.26 MB of payload data to client #426 (simulated).
[INFO][15:55:52]: [Server #615782] Selecting client #248 for training.
[INFO][15:55:52]: [Server #615782] Sending the current model to client #248 (simulated).
[INFO][15:55:52]: [Server #615782] Sending 0.26 MB of payload data to client #248 (simulated).
[INFO][15:55:52]: [Client #426] Selected by the server.
[INFO][15:55:52]: [Client #426] Loading its data source...
[INFO][15:55:52]: Data source: FEMNIST
[INFO][15:55:52]: [Client #248] Selected by the server.
[INFO][15:55:52]: [Client #248] Loading its data source...
[INFO][15:55:52]: Data source: FEMNIST
[INFO][15:55:53]: [Client #248] Dataset size: 164
[INFO][15:55:53]: [Client #248] Sampler: all_inclusive
[INFO][15:55:53]: [Client #248] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:53]: [Client #426] Dataset size: 160
[INFO][15:55:53]: [Client #426] Sampler: all_inclusive
[INFO][15:55:53]: [93m[1m[Client #248] Started training in communication round #13.[0m
[INFO][15:55:53]: [Client #426] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:55:53]: [93m[1m[Client #426] Started training in communication round #13.[0m
[INFO][15:55:55]: [Client #426] Loading the dataset.
[INFO][15:55:55]: [Client #248] Loading the dataset.
[INFO][15:56:02]: [Client #426] Epoch: [1/5][0/16]	Loss: 0.684451
[INFO][15:56:02]: [Client #426] Epoch: [1/5][10/16]	Loss: 1.026686
[INFO][15:56:02]: [Client #248] Epoch: [1/5][0/17]	Loss: 0.473023
[INFO][15:56:02]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][15:56:02]: [Client #248] Epoch: [1/5][10/17]	Loss: 0.629099
[INFO][15:56:02]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][15:56:02]: [Client #426] Woke up.
[INFO][15:56:02]: [Client #426] Epoch: [2/5][0/16]	Loss: 0.249836
[INFO][15:56:03]: [Client #426] Epoch: [2/5][10/16]	Loss: 1.001989
[INFO][15:56:03]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][15:56:03]: [Client #426] Woke up.
[INFO][15:56:03]: [Client #426] Epoch: [3/5][0/16]	Loss: 0.429263
[INFO][15:56:03]: [Client #426] Epoch: [3/5][10/16]	Loss: 1.521954
[INFO][15:56:03]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][15:56:03]: [Client #426] Woke up.
[INFO][15:56:03]: [Client #426] Epoch: [4/5][0/16]	Loss: 1.531244
[INFO][15:56:03]: [Client #426] Epoch: [4/5][10/16]	Loss: 1.512419
[INFO][15:56:03]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][15:56:03]: [Client #248] Woke up.
[INFO][15:56:03]: [Client #248] Epoch: [2/5][0/17]	Loss: 0.284748
[INFO][15:56:03]: [Client #248] Epoch: [2/5][10/17]	Loss: 0.927684
[INFO][15:56:03]: [Client #426] Woke up.
[INFO][15:56:03]: [Client #426] Epoch: [5/5][0/16]	Loss: 0.813112
[INFO][15:56:03]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][15:56:03]: [Client #426] Epoch: [5/5][10/16]	Loss: 1.055989
[INFO][15:56:03]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][15:56:04]: [Client #426] Woke up.
[INFO][15:56:04]: [Client #426] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_615874.pth.
[INFO][15:56:04]: [Client #248] Woke up.
[INFO][15:56:04]: [Client #248] Epoch: [3/5][0/17]	Loss: 0.541087
[INFO][15:56:04]: [Client #248] Epoch: [3/5][10/17]	Loss: 0.817045
[INFO][15:56:04]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][15:56:04]: [Client #426] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_615874.pth.
[INFO][15:56:04]: [Client #426] Model trained.
[INFO][15:56:04]: [Client #426] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:56:04]: [Server #615782] Received 0.26 MB of payload data from client #426 (simulated).
[INFO][15:56:05]: [Client #248] Woke up.
[INFO][15:56:05]: [Client #248] Epoch: [4/5][0/17]	Loss: 0.340391
[INFO][15:56:05]: [Client #248] Epoch: [4/5][10/17]	Loss: 1.190329
[INFO][15:56:05]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][15:56:06]: [Client #248] Woke up.
[INFO][15:56:06]: [Client #248] Epoch: [5/5][0/17]	Loss: 0.431044
[INFO][15:56:06]: [Client #248] Epoch: [5/5][10/17]	Loss: 1.241355
[INFO][15:56:06]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][15:56:07]: [Client #248] Woke up.
[INFO][15:56:07]: [Client #248] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_248_615875.pth.
[INFO][15:56:07]: [Client #248] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_248_615875.pth.
[INFO][15:56:07]: [Client #248] Model trained.
[INFO][15:56:07]: [Client #248] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:56:07]: [Server #615782] Received 0.26 MB of payload data from client #248 (simulated).
[INFO][15:56:07]: [Server #615782] Selecting client #845 for training.
[INFO][15:56:07]: [Server #615782] Sending the current model to client #845 (simulated).
[INFO][15:56:07]: [Server #615782] Sending 0.26 MB of payload data to client #845 (simulated).
[INFO][15:56:07]: [Server #615782] Selecting client #987 for training.
[INFO][15:56:07]: [Server #615782] Sending the current model to client #987 (simulated).
[INFO][15:56:07]: [Server #615782] Sending 0.26 MB of payload data to client #987 (simulated).
[INFO][15:56:07]: [Client #845] Selected by the server.
[INFO][15:56:07]: [Client #845] Loading its data source...
[INFO][15:56:07]: Data source: FEMNIST
[INFO][15:56:07]: [Client #987] Selected by the server.
[INFO][15:56:07]: [Client #987] Loading its data source...
[INFO][15:56:07]: Data source: FEMNIST
[INFO][15:56:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][15:56:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/987.zip.
[INFO][15:56:07]: [Client #845] Dataset size: 140
[INFO][15:56:07]: [Client #845] Sampler: all_inclusive
[INFO][15:56:07]: [Client #845] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:56:07]: [93m[1m[Client #845] Started training in communication round #13.[0m
2.5%4.9%7.4%9.9%12.4%14.8%17.3%19.8%22.3%24.7%27.2%29.7%32.2%34.6%37.1%39.6%42.1%44.5%47.0%49.5%52.0%54.4%56.9%59.4%61.9%64.3%66.8%69.3%71.8%74.2%76.7%79.2%81.7%84.1%86.6%89.1%91.6%94.0%96.5%99.0%100.0%[INFO][15:56:08]: Decompressing the dataset downloaded.
[INFO][15:56:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/987.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][15:56:08]: [Client #987] Dataset size: 157
[INFO][15:56:08]: [Client #987] Sampler: all_inclusive
[INFO][15:56:08]: [Client #987] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:56:08]: [93m[1m[Client #987] Started training in communication round #13.[0m

[INFO][15:56:10]: [Client #845] Loading the dataset.
[INFO][15:56:10]: [Client #987] Loading the dataset.
[INFO][15:56:17]: [Client #845] Epoch: [1/5][0/14]	Loss: 0.701947
[INFO][15:56:17]: [Client #987] Epoch: [1/5][0/16]	Loss: 0.391920
[INFO][15:56:17]: [Client #845] Epoch: [1/5][10/14]	Loss: 1.244941
[INFO][15:56:17]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][15:56:17]: [Client #987] Epoch: [1/5][10/16]	Loss: 0.837727
[INFO][15:56:17]: [Client #987] Going to sleep for 1.11 seconds.
[INFO][15:56:18]: [Client #987] Woke up.
[INFO][15:56:18]: [Client #987] Epoch: [2/5][0/16]	Loss: 0.682584
[INFO][15:56:18]: [Client #987] Epoch: [2/5][10/16]	Loss: 1.064206
[INFO][15:56:19]: [Client #987] Going to sleep for 1.11 seconds.
[INFO][15:56:20]: [Client #987] Woke up.
[INFO][15:56:20]: [Client #987] Epoch: [3/5][0/16]	Loss: 1.347260
[INFO][15:56:20]: [Client #987] Epoch: [3/5][10/16]	Loss: 0.838722
[INFO][15:56:20]: [Client #987] Going to sleep for 1.11 seconds.
[INFO][15:56:21]: [Client #987] Woke up.
[INFO][15:56:21]: [Client #987] Epoch: [4/5][0/16]	Loss: 1.135924
[INFO][15:56:21]: [Client #987] Epoch: [4/5][10/16]	Loss: 0.450347
[INFO][15:56:21]: [Client #987] Going to sleep for 1.11 seconds.
[INFO][15:56:21]: [Client #845] Woke up.
[INFO][15:56:21]: [Client #845] Epoch: [2/5][0/14]	Loss: 1.649123
[INFO][15:56:21]: [Client #845] Epoch: [2/5][10/14]	Loss: 0.699571
[INFO][15:56:21]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][15:56:22]: [Client #987] Woke up.
[INFO][15:56:22]: [Client #987] Epoch: [5/5][0/16]	Loss: 1.285443
[INFO][15:56:22]: [Client #987] Epoch: [5/5][10/16]	Loss: 0.035293
[INFO][15:56:22]: [Client #987] Going to sleep for 1.11 seconds.
[INFO][15:56:23]: [Client #987] Woke up.
[INFO][15:56:23]: [Client #987] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_987_615875.pth.
[INFO][15:56:24]: [Client #987] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_987_615875.pth.
[INFO][15:56:24]: [Client #987] Model trained.
[INFO][15:56:24]: [Client #987] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:56:24]: [Server #615782] Received 0.26 MB of payload data from client #987 (simulated).
[INFO][15:56:25]: [Client #845] Woke up.
[INFO][15:56:25]: [Client #845] Epoch: [3/5][0/14]	Loss: 0.815673
[INFO][15:56:25]: [Client #845] Epoch: [3/5][10/14]	Loss: 1.208386
[INFO][15:56:26]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][15:56:30]: [Client #845] Woke up.
[INFO][15:56:30]: [Client #845] Epoch: [4/5][0/14]	Loss: 0.865464
[INFO][15:56:30]: [Client #845] Epoch: [4/5][10/14]	Loss: 1.380802
[INFO][15:56:30]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][15:56:34]: [Client #845] Woke up.
[INFO][15:56:34]: [Client #845] Epoch: [5/5][0/14]	Loss: 1.082163
[INFO][15:56:34]: [Client #845] Epoch: [5/5][10/14]	Loss: 1.305380
[INFO][15:56:34]: [Client #845] Going to sleep for 4.01 seconds.
[INFO][15:56:38]: [Client #845] Woke up.
[INFO][15:56:38]: [Client #845] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_845_615874.pth.
[INFO][15:56:38]: [Client #845] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_845_615874.pth.
[INFO][15:56:38]: [Client #845] Model trained.
[INFO][15:56:38]: [Client #845] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:56:38]: [Server #615782] Received 0.26 MB of payload data from client #845 (simulated).
[INFO][15:56:38]: [Server #615782] Selecting client #67 for training.
[INFO][15:56:38]: [Server #615782] Sending the current model to client #67 (simulated).
[INFO][15:56:38]: [Server #615782] Sending 0.26 MB of payload data to client #67 (simulated).
[INFO][15:56:38]: [Server #615782] Selecting client #713 for training.
[INFO][15:56:39]: [Server #615782] Sending the current model to client #713 (simulated).
[INFO][15:56:39]: [Server #615782] Sending 0.26 MB of payload data to client #713 (simulated).
[INFO][15:56:39]: [Client #67] Selected by the server.
[INFO][15:56:39]: [Client #713] Selected by the server.
[INFO][15:56:39]: [Client #67] Loading its data source...
[INFO][15:56:39]: [Client #713] Loading its data source...
[INFO][15:56:39]: Data source: FEMNIST
[INFO][15:56:39]: Data source: FEMNIST
[INFO][15:56:39]: [Client #713] Dataset size: 162
[INFO][15:56:39]: [Client #713] Sampler: all_inclusive
[INFO][15:56:39]: [Client #713] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:56:39]: [93m[1m[Client #713] Started training in communication round #13.[0m
[INFO][15:56:39]: [Client #67] Dataset size: 226
[INFO][15:56:39]: [Client #67] Sampler: all_inclusive
[INFO][15:56:39]: [Client #67] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:56:39]: [93m[1m[Client #67] Started training in communication round #13.[0m
[INFO][15:56:41]: [Client #713] Loading the dataset.
[INFO][15:56:41]: [Client #67] Loading the dataset.
[INFO][15:56:48]: [Client #713] Epoch: [1/5][0/17]	Loss: 0.937016
[INFO][15:56:48]: [Client #67] Epoch: [1/5][0/23]	Loss: 0.875404
[INFO][15:56:48]: [Client #713] Epoch: [1/5][10/17]	Loss: 0.887182
[INFO][15:56:48]: [Client #67] Epoch: [1/5][10/23]	Loss: 1.232308
[INFO][15:56:48]: [Client #713] Going to sleep for 0.46 seconds.
[INFO][15:56:48]: [Client #67] Epoch: [1/5][20/23]	Loss: 1.064356
[INFO][15:56:48]: [Client #67] Going to sleep for 1.97 seconds.
[INFO][15:56:49]: [Client #713] Woke up.
[INFO][15:56:49]: [Client #713] Epoch: [2/5][0/17]	Loss: 0.351870
[INFO][15:56:49]: [Client #713] Epoch: [2/5][10/17]	Loss: 0.839855
[INFO][15:56:49]: [Client #713] Going to sleep for 0.46 seconds.
[INFO][15:56:49]: [Client #713] Woke up.
[INFO][15:56:49]: [Client #713] Epoch: [3/5][0/17]	Loss: 0.974934
[INFO][15:56:50]: [Client #713] Epoch: [3/5][10/17]	Loss: 0.422682
[INFO][15:56:50]: [Client #713] Going to sleep for 0.46 seconds.
[INFO][15:56:50]: [Client #713] Woke up.
[INFO][15:56:50]: [Client #713] Epoch: [4/5][0/17]	Loss: 0.651829
[INFO][15:56:50]: [Client #713] Epoch: [4/5][10/17]	Loss: 1.232367
[INFO][15:56:50]: [Client #713] Going to sleep for 0.46 seconds.
[INFO][15:56:50]: [Client #67] Woke up.
[INFO][15:56:50]: [Client #67] Epoch: [2/5][0/23]	Loss: 1.158673
[INFO][15:56:51]: [Client #67] Epoch: [2/5][10/23]	Loss: 1.579403
[INFO][15:56:51]: [Client #67] Epoch: [2/5][20/23]	Loss: 1.449098
[INFO][15:56:51]: [Client #67] Going to sleep for 1.97 seconds.
[INFO][15:56:51]: [Client #713] Woke up.
[INFO][15:56:51]: [Client #713] Epoch: [5/5][0/17]	Loss: 1.027229
[INFO][15:56:51]: [Client #713] Epoch: [5/5][10/17]	Loss: 0.629095
[INFO][15:56:51]: [Client #713] Going to sleep for 0.46 seconds.
[INFO][15:56:51]: [Client #713] Woke up.
[INFO][15:56:51]: [Client #713] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_713_615875.pth.
[INFO][15:56:52]: [Client #713] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_713_615875.pth.
[INFO][15:56:52]: [Client #713] Model trained.
[INFO][15:56:52]: [Client #713] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:56:52]: [Server #615782] Received 0.26 MB of payload data from client #713 (simulated).
[INFO][15:56:53]: [Client #67] Woke up.
[INFO][15:56:53]: [Client #67] Epoch: [3/5][0/23]	Loss: 1.227795
[INFO][15:56:53]: [Client #67] Epoch: [3/5][10/23]	Loss: 0.848549
[INFO][15:56:53]: [Client #67] Epoch: [3/5][20/23]	Loss: 1.220025
[INFO][15:56:53]: [Client #67] Going to sleep for 1.97 seconds.
[INFO][15:56:55]: [Client #67] Woke up.
[INFO][15:56:55]: [Client #67] Epoch: [4/5][0/23]	Loss: 1.459731
[INFO][15:56:55]: [Client #67] Epoch: [4/5][10/23]	Loss: 1.166188
[INFO][15:56:55]: [Client #67] Epoch: [4/5][20/23]	Loss: 1.047691
[INFO][15:56:55]: [Client #67] Going to sleep for 1.97 seconds.
[INFO][15:56:57]: [Client #67] Woke up.
[INFO][15:56:57]: [Client #67] Epoch: [5/5][0/23]	Loss: 2.475188
[INFO][15:56:57]: [Client #67] Epoch: [5/5][10/23]	Loss: 2.679723
[INFO][15:56:57]: [Client #67] Epoch: [5/5][20/23]	Loss: 1.713849
[INFO][15:56:57]: [Client #67] Going to sleep for 1.97 seconds.
[INFO][15:56:59]: [Client #67] Woke up.
[INFO][15:56:59]: [Client #67] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_67_615874.pth.
[INFO][15:57:00]: [Client #67] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_67_615874.pth.
[INFO][15:57:00]: [Client #67] Model trained.
[INFO][15:57:00]: [Client #67] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:57:00]: [Server #615782] Received 0.26 MB of payload data from client #67 (simulated).
[INFO][15:57:00]: [Server #615782] Selecting client #330 for training.
[INFO][15:57:00]: [Server #615782] Sending the current model to client #330 (simulated).
[INFO][15:57:00]: [Server #615782] Sending 0.26 MB of payload data to client #330 (simulated).
[INFO][15:57:00]: [Client #330] Selected by the server.
[INFO][15:57:00]: [Client #330] Loading its data source...
[INFO][15:57:00]: Data source: FEMNIST
[INFO][15:57:00]: [Client #330] Dataset size: 153
[INFO][15:57:00]: [Client #330] Sampler: all_inclusive
[INFO][15:57:00]: [Client #330] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:57:00]: [93m[1m[Client #330] Started training in communication round #13.[0m
[INFO][15:57:02]: [Client #330] Loading the dataset.
[INFO][15:57:08]: [Client #330] Epoch: [1/5][0/16]	Loss: 1.914871
[INFO][15:57:08]: [Client #330] Epoch: [1/5][10/16]	Loss: 2.037370
[INFO][15:57:09]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][15:57:10]: [Client #330] Woke up.
[INFO][15:57:10]: [Client #330] Epoch: [2/5][0/16]	Loss: 1.837918
[INFO][15:57:11]: [Client #330] Epoch: [2/5][10/16]	Loss: 2.437439
[INFO][15:57:11]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][15:57:12]: [Client #330] Woke up.
[INFO][15:57:12]: [Client #330] Epoch: [3/5][0/16]	Loss: 2.224421
[INFO][15:57:13]: [Client #330] Epoch: [3/5][10/16]	Loss: 1.835773
[INFO][15:57:13]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][15:57:15]: [Client #330] Woke up.
[INFO][15:57:15]: [Client #330] Epoch: [4/5][0/16]	Loss: 1.225327
[INFO][15:57:15]: [Client #330] Epoch: [4/5][10/16]	Loss: 1.211378
[INFO][15:57:15]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][15:57:17]: [Client #330] Woke up.
[INFO][15:57:17]: [Client #330] Epoch: [5/5][0/16]	Loss: 1.472939
[INFO][15:57:17]: [Client #330] Epoch: [5/5][10/16]	Loss: 1.634941
[INFO][15:57:17]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][15:57:19]: [Client #330] Woke up.
[INFO][15:57:19]: [Client #330] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_615874.pth.
[INFO][15:57:19]: [Client #330] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_615874.pth.
[INFO][15:57:19]: [Client #330] Model trained.
[INFO][15:57:19]: [Client #330] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:57:19]: [Server #615782] Received 0.26 MB of payload data from client #330 (simulated).
[INFO][15:57:19]: [Server #615782] Adding client #856 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #528 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #426 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #594 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #947 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #650 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #85 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #896 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #713 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #231 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #248 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #705 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #480 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #433 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #987 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #329 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #202 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #330 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #853 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #67 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #119 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #553 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #692 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #845 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Adding client #902 to the list of clients for aggregation.
[INFO][15:57:19]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13535077 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19504888 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18318943 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13994017 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10323595 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08637969 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12350123 0.17496956
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11704889
 0.         0.         0.         0.         0.         0.
 0.1764033  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08149343
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08509465
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16613249 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0617624
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09124709 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0695348  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10241443 0.         0.         0.
 0.         0.         0.         0.         0.29566826 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1065349  0.
 0.         0.         0.         0.         0.         0.
 0.10234873 0.         0.         0.09296406 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19037159 0.         0.         0.         0.
 0.         0.0920659  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14423081 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05626272 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13535077 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19504888 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18318943 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13994017 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10323595 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08637969 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12350123 0.17496956
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11704889
 0.         0.         0.         0.         0.         0.
 0.1764033  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08149343
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08509465
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16613249 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0617624
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09124709 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0695348  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10241443 0.         0.         0.
 0.         0.         0.         0.         0.29566826 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1065349  0.
 0.         0.         0.         0.         0.         0.
 0.10234873 0.         0.         0.09296406 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19037159 0.         0.         0.         0.
 0.         0.0920659  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14423081 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05626272 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.001      0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03799951 0.001      0.02227617
 0.001      0.02370413 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.03767545 0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.01849272 0.001      0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.03647485 0.03861004 0.001      0.001      0.04316547 0.001
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.001      0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03463896 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.001      0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.04063039
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.04038414 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.02184778 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.0383432
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.001      0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.001      0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0383693  0.03241574 0.001
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.03792169 0.03188406 0.001
 0.001      0.001      0.001      0.04116285 0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03809524
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.04015444 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.0401379  0.001      0.001      0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.0321735  0.001      0.001      0.02051932 0.001      0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03767545 0.04076739
 0.001      0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03650413 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.02001267 0.001      0.001      0.001      0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.001      0.03866043 0.001      0.001      0.02611244
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][15:58:02]: [Server #615782] Global model accuracy: 55.09%

[INFO][15:58:02]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_13.pth.
[INFO][15:58:02]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_13.pth.
[INFO][15:58:02]: [93m[1m
[Server #615782] Starting round 14/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  8e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  5e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  5e-05  1e-10  1e-10
 7:  7.5999e+00  7.5998e+00  5e-05  2e-09  2e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  2e-10
 9:  7.5999e+00  7.5999e+00  2e-05  4e-09  4e-10
10:  7.5999e+00  7.5999e+00  3e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69099426e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69113702e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69135617e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69364394e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69551217e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69583366e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69477282e-05 7.69243590e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69484526e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.68536112e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69599332e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69585701e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69226687e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69655983e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69593800e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69629906e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69534234e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.68206503e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69569024e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69545473e-05 7.69715599e-05 7.69715599e-05 9.23183228e-01
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69360270e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69567213e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69394807e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69664181e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05 7.69715599e-05
 7.69715599e-05 7.69715599e-05 7.69715599e-05][INFO][15:58:05]: [Server #615782] Selected clients: [856 173 127 777  40 242 880 974 605 977  44 949 311 798 810 860 458 931
 258 935 618 986  33 724 565]
[INFO][15:58:05]: [Server #615782] Selecting client #856 for training.
[INFO][15:58:05]: [Server #615782] Sending the current model to client #856 (simulated).
[INFO][15:58:05]: [Server #615782] Sending 0.26 MB of payload data to client #856 (simulated).
[INFO][15:58:05]: [Server #615782] Selecting client #173 for training.
[INFO][15:58:05]: [Server #615782] Sending the current model to client #173 (simulated).
[INFO][15:58:05]: [Server #615782] Sending 0.26 MB of payload data to client #173 (simulated).
[INFO][15:58:05]: [Client #856] Selected by the server.
[INFO][15:58:05]: [Client #856] Loading its data source...
[INFO][15:58:05]: Data source: FEMNIST
[INFO][15:58:05]: [Client #173] Selected by the server.
[INFO][15:58:05]: [Client #173] Loading its data source...
[INFO][15:58:05]: Data source: FEMNIST
[INFO][15:58:05]: [Client #856] Dataset size: 154
[INFO][15:58:05]: [Client #856] Sampler: all_inclusive
[INFO][15:58:05]: [Client #856] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:58:05]: [93m[1m[Client #856] Started training in communication round #14.[0m
[INFO][15:58:05]: [Client #173] Dataset size: 163
[INFO][15:58:05]: [Client #173] Sampler: all_inclusive
[INFO][15:58:05]: [Client #173] Received 0.26 MB of payload data from the server (simulated).
[INFO][15:58:05]: [93m[1m[Client #173] Started training in communication round #14.[0m
[INFO][15:58:07]: [Client #856] Loading the dataset.
[INFO][15:58:07]: [Client #173] Loading the dataset.
[INFO][15:58:13]: [Client #173] Epoch: [1/5][0/17]	Loss: 0.587873
[INFO][15:58:14]: [Client #173] Epoch: [1/5][10/17]	Loss: 1.576785
[INFO][15:58:14]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][15:58:14]: [Client #856] Epoch: [1/5][0/16]	Loss: 1.215241
[INFO][15:58:14]: [Client #856] Epoch: [1/5][10/16]	Loss: 0.896041
[INFO][15:58:14]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][15:58:15]: [Client #173] Woke up.
[INFO][15:58:15]: [Client #173] Epoch: [2/5][0/17]	Loss: 0.533264
[INFO][15:58:15]: [Client #173] Epoch: [2/5][10/17]	Loss: 1.233604
[INFO][15:58:15]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][15:58:17]: [Client #173] Woke up.
[INFO][15:58:17]: [Client #173] Epoch: [3/5][0/17]	Loss: 0.253882
[INFO][15:58:17]: [Client #173] Epoch: [3/5][10/17]	Loss: 0.521163
[INFO][15:58:17]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][15:58:18]: [Client #173] Woke up.
[INFO][15:58:18]: [Client #173] Epoch: [4/5][0/17]	Loss: 0.195025
[INFO][15:58:18]: [Client #173] Epoch: [4/5][10/17]	Loss: 0.090748
[INFO][15:58:18]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][15:58:20]: [Client #173] Woke up.
[INFO][15:58:20]: [Client #173] Epoch: [5/5][0/17]	Loss: 0.937134
[INFO][15:58:20]: [Client #173] Epoch: [5/5][10/17]	Loss: 0.708742
[INFO][15:58:20]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][15:58:21]: [Client #173] Woke up.
[INFO][15:58:21]: [Client #173] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_615875.pth.
[INFO][15:58:22]: [Client #173] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_615875.pth.
[INFO][15:58:22]: [Client #173] Model trained.
[INFO][15:58:22]: [Client #173] Sent 0.26 MB of payload data to the server (simulated).
[INFO][15:58:22]: [Server #615782] Received 0.26 MB of payload data from client #173 (simulated).
[INFO][15:59:14]: [Client #856] Woke up.
[INFO][15:59:14]: [Client #856] Epoch: [2/5][0/16]	Loss: 1.107473
[INFO][15:59:14]: [Client #856] Epoch: [2/5][10/16]	Loss: 1.206234
[INFO][15:59:14]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:00:14]: [Client #856] Woke up.
[INFO][16:00:14]: [Client #856] Epoch: [3/5][0/16]	Loss: 0.619785
[INFO][16:00:14]: [Client #856] Epoch: [3/5][10/16]	Loss: 0.894114
[INFO][16:00:14]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:01:15]: [Client #856] Woke up.
[INFO][16:01:15]: [Client #856] Epoch: [4/5][0/16]	Loss: 1.698143
[INFO][16:01:15]: [Client #856] Epoch: [4/5][10/16]	Loss: 0.830069
[INFO][16:01:15]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:02:15]: [Client #856] Woke up.
[INFO][16:02:15]: [Client #856] Epoch: [5/5][0/16]	Loss: 0.613196
[INFO][16:02:15]: [Client #856] Epoch: [5/5][10/16]	Loss: 1.034556
[INFO][16:02:15]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:03:15]: [Client #856] Woke up.
[INFO][16:03:15]: [Client #856] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:03:16]: [Client #856] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:03:16]: [Client #856] Model trained.
[INFO][16:03:16]: [Client #856] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:03:16]: [Server #615782] Received 0.26 MB of payload data from client #856 (simulated).
[INFO][16:03:16]: [Server #615782] Selecting client #127 for training.
[INFO][16:03:16]: [Server #615782] Sending the current model to client #127 (simulated).
[INFO][16:03:16]: [Server #615782] Sending 0.26 MB of payload data to client #127 (simulated).
[INFO][16:03:16]: [Server #615782] Selecting client #777 for training.
[INFO][16:03:16]: [Server #615782] Sending the current model to client #777 (simulated).
[INFO][16:03:16]: [Server #615782] Sending 0.26 MB of payload data to client #777 (simulated).
[INFO][16:03:16]: [Client #127] Selected by the server.
[INFO][16:03:16]: [Client #127] Loading its data source...
[INFO][16:03:16]: Data source: FEMNIST
[INFO][16:03:16]: [Client #777] Selected by the server.
[INFO][16:03:16]: [Client #777] Loading its data source...
[INFO][16:03:16]: Data source: FEMNIST
[INFO][16:03:16]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:03:16]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/777.zip.
1.2%2.4%3.6%4.8%6.0%7.2%8.4%9.5%10.7%11.9%13.1%14.3%15.5%16.7%17.9%19.1%20.3%21.5%22.7%23.9%25.1%26.3%27.5%28.6%29.8%31.0%32.2%33.4%34.6%35.8%37.0%38.2%39.4%40.6%41.8%43.0%44.2%45.4%46.6%47.7%48.9%50.1%51.3%52.5%53.7%54.9%56.1%57.3%58.5%[INFO][16:03:16]: [Client #127] Dataset size: 161
[INFO][16:03:16]: [Client #127] Sampler: all_inclusive
[INFO][16:03:16]: [Client #127] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:03:16]: [93m[1m[Client #127] Started training in communication round #14.[0m
59.7%60.9%62.1%63.3%64.5%65.6%66.8%68.0%69.2%70.4%71.6%72.8%74.0%75.2%76.4%77.6%78.8%80.0%81.2%82.4%83.6%84.7%85.9%87.1%88.3%89.5%90.7%91.9%93.1%94.3%95.5%96.7%97.9%99.1%100.0%[INFO][16:03:16]: Decompressing the dataset downloaded.
[INFO][16:03:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/777.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:03:16]: [Client #777] Dataset size: 346
[INFO][16:03:16]: [Client #777] Sampler: all_inclusive
[INFO][16:03:16]: [Client #777] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:03:16]: [93m[1m[Client #777] Started training in communication round #14.[0m

[INFO][16:03:18]: [Client #127] Loading the dataset.
[INFO][16:03:18]: [Client #777] Loading the dataset.
[INFO][16:03:25]: [Client #127] Epoch: [1/5][0/17]	Loss: 0.343686
[INFO][16:03:25]: [Client #777] Epoch: [1/5][0/35]	Loss: 1.848062
[INFO][16:03:25]: [Client #127] Epoch: [1/5][10/17]	Loss: 1.165260
[INFO][16:03:25]: [Client #777] Epoch: [1/5][10/35]	Loss: 1.853278
[INFO][16:03:25]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][16:03:25]: [Client #777] Epoch: [1/5][20/35]	Loss: 0.917174
[INFO][16:03:25]: [Client #777] Epoch: [1/5][30/35]	Loss: 1.384946
[INFO][16:03:25]: [Client #777] Going to sleep for 0.47 seconds.
[INFO][16:03:26]: [Client #777] Woke up.
[INFO][16:03:26]: [Client #777] Epoch: [2/5][0/35]	Loss: 1.669928
[INFO][16:03:26]: [Client #777] Epoch: [2/5][10/35]	Loss: 1.635292
[INFO][16:03:26]: [Client #777] Epoch: [2/5][20/35]	Loss: 1.370618
[INFO][16:03:26]: [Client #777] Epoch: [2/5][30/35]	Loss: 0.975684
[INFO][16:03:26]: [Client #777] Going to sleep for 0.47 seconds.
[INFO][16:03:27]: [Client #127] Woke up.
[INFO][16:03:27]: [Client #127] Epoch: [2/5][0/17]	Loss: 0.639205
[INFO][16:03:27]: [Client #127] Epoch: [2/5][10/17]	Loss: 1.511298
[INFO][16:03:27]: [Client #777] Woke up.
[INFO][16:03:27]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][16:03:27]: [Client #777] Epoch: [3/5][0/35]	Loss: 0.752397
[INFO][16:03:27]: [Client #777] Epoch: [3/5][10/35]	Loss: 0.507548
[INFO][16:03:27]: [Client #777] Epoch: [3/5][20/35]	Loss: 0.299889
[INFO][16:03:27]: [Client #777] Epoch: [3/5][30/35]	Loss: 4.161073
[INFO][16:03:27]: [Client #777] Going to sleep for 0.47 seconds.
[INFO][16:03:27]: [Client #777] Woke up.
[INFO][16:03:27]: [Client #777] Epoch: [4/5][0/35]	Loss: 1.115916
[INFO][16:03:28]: [Client #777] Epoch: [4/5][10/35]	Loss: 0.627404
[INFO][16:03:28]: [Client #777] Epoch: [4/5][20/35]	Loss: 2.064934
[INFO][16:03:28]: [Client #777] Epoch: [4/5][30/35]	Loss: 0.279051
[INFO][16:03:28]: [Client #777] Going to sleep for 0.47 seconds.
[INFO][16:03:28]: [Client #127] Woke up.
[INFO][16:03:28]: [Client #127] Epoch: [3/5][0/17]	Loss: 1.286747
[INFO][16:03:28]: [Client #127] Epoch: [3/5][10/17]	Loss: 1.530232
[INFO][16:03:28]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][16:03:28]: [Client #777] Woke up.
[INFO][16:03:28]: [Client #777] Epoch: [5/5][0/35]	Loss: 1.091979
[INFO][16:03:28]: [Client #777] Epoch: [5/5][10/35]	Loss: 0.755754
[INFO][16:03:28]: [Client #777] Epoch: [5/5][20/35]	Loss: 0.678674
[INFO][16:03:28]: [Client #777] Epoch: [5/5][30/35]	Loss: 0.541068
[INFO][16:03:29]: [Client #777] Going to sleep for 0.47 seconds.
[INFO][16:03:29]: [Client #777] Woke up.
[INFO][16:03:29]: [Client #777] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_777_615875.pth.
[INFO][16:03:29]: [Client #127] Woke up.
[INFO][16:03:29]: [Client #127] Epoch: [4/5][0/17]	Loss: 1.538725
[INFO][16:03:29]: [Client #127] Epoch: [4/5][10/17]	Loss: 1.756500
[INFO][16:03:29]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][16:03:30]: [Client #777] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_777_615875.pth.
[INFO][16:03:30]: [Client #777] Model trained.
[INFO][16:03:30]: [Client #777] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:03:30]: [Server #615782] Received 0.26 MB of payload data from client #777 (simulated).
[INFO][16:03:31]: [Client #127] Woke up.
[INFO][16:03:31]: [Client #127] Epoch: [5/5][0/17]	Loss: 0.475194
[INFO][16:03:31]: [Client #127] Epoch: [5/5][10/17]	Loss: 1.194732
[INFO][16:03:31]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][16:03:32]: [Client #127] Woke up.
[INFO][16:03:32]: [Client #127] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_127_615874.pth.
[INFO][16:03:33]: [Client #127] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_127_615874.pth.
[INFO][16:03:33]: [Client #127] Model trained.
[INFO][16:03:33]: [Client #127] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:03:33]: [Server #615782] Received 0.26 MB of payload data from client #127 (simulated).
[INFO][16:03:33]: [Server #615782] Selecting client #40 for training.
[INFO][16:03:33]: [Server #615782] Sending the current model to client #40 (simulated).
[INFO][16:03:33]: [Server #615782] Sending 0.26 MB of payload data to client #40 (simulated).
[INFO][16:03:33]: [Server #615782] Selecting client #242 for training.
[INFO][16:03:33]: [Server #615782] Sending the current model to client #242 (simulated).
[INFO][16:03:33]: [Server #615782] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][16:03:33]: [Client #40] Selected by the server.
[INFO][16:03:33]: [Client #40] Loading its data source...
[INFO][16:03:33]: Data source: FEMNIST
[INFO][16:03:33]: [Client #242] Selected by the server.
[INFO][16:03:33]: [Client #242] Loading its data source...
[INFO][16:03:33]: Data source: FEMNIST
[INFO][16:03:33]: [Client #242] Dataset size: 146
[INFO][16:03:33]: [Client #242] Sampler: all_inclusive
[INFO][16:03:33]: [Client #40] Dataset size: 155
[INFO][16:03:33]: [Client #40] Sampler: all_inclusive
[INFO][16:03:33]: [Client #40] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:03:33]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:03:33]: [93m[1m[Client #40] Started training in communication round #14.[0m
[INFO][16:03:33]: [93m[1m[Client #242] Started training in communication round #14.[0m
[INFO][16:03:35]: [Client #242] Loading the dataset.
[INFO][16:03:35]: [Client #40] Loading the dataset.
[INFO][16:03:42]: [Client #242] Epoch: [1/5][0/15]	Loss: 1.545590
[INFO][16:03:42]: [Client #242] Epoch: [1/5][10/15]	Loss: 0.698457
[INFO][16:03:42]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][16:03:42]: [Client #40] Epoch: [1/5][0/16]	Loss: 1.175463
[INFO][16:03:42]: [Client #40] Epoch: [1/5][10/16]	Loss: 0.466507
[INFO][16:03:43]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][16:03:46]: [Client #40] Woke up.
[INFO][16:03:46]: [Client #40] Epoch: [2/5][0/16]	Loss: 0.415516
[INFO][16:03:46]: [Client #40] Epoch: [2/5][10/16]	Loss: 0.808222
[INFO][16:03:46]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][16:03:49]: [Client #40] Woke up.
[INFO][16:03:49]: [Client #40] Epoch: [3/5][0/16]	Loss: 0.265759
[INFO][16:03:49]: [Client #40] Epoch: [3/5][10/16]	Loss: 1.105470
[INFO][16:03:49]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][16:03:51]: [Client #242] Woke up.
[INFO][16:03:51]: [Client #242] Epoch: [2/5][0/15]	Loss: 2.076989
[INFO][16:03:51]: [Client #242] Epoch: [2/5][10/15]	Loss: 0.957397
[INFO][16:03:51]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][16:03:52]: [Client #40] Woke up.
[INFO][16:03:52]: [Client #40] Epoch: [4/5][0/16]	Loss: 0.310571
[INFO][16:03:52]: [Client #40] Epoch: [4/5][10/16]	Loss: 0.645641
[INFO][16:03:52]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][16:03:55]: [Client #40] Woke up.
[INFO][16:03:55]: [Client #40] Epoch: [5/5][0/16]	Loss: 0.743941
[INFO][16:03:55]: [Client #40] Epoch: [5/5][10/16]	Loss: 0.584326
[INFO][16:03:55]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][16:03:58]: [Client #40] Woke up.
[INFO][16:03:58]: [Client #40] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615874.pth.
[INFO][16:03:59]: [Client #40] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_615874.pth.
[INFO][16:03:59]: [Client #40] Model trained.
[INFO][16:03:59]: [Client #40] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:03:59]: [Server #615782] Received 0.26 MB of payload data from client #40 (simulated).
[INFO][16:03:59]: [Client #242] Woke up.
[INFO][16:03:59]: [Client #242] Epoch: [3/5][0/15]	Loss: 0.594469
[INFO][16:03:59]: [Client #242] Epoch: [3/5][10/15]	Loss: 0.590444
[INFO][16:03:59]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][16:04:08]: [Client #242] Woke up.
[INFO][16:04:08]: [Client #242] Epoch: [4/5][0/15]	Loss: 0.891702
[INFO][16:04:08]: [Client #242] Epoch: [4/5][10/15]	Loss: 0.890299
[INFO][16:04:08]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][16:04:16]: [Client #242] Woke up.
[INFO][16:04:16]: [Client #242] Epoch: [5/5][0/15]	Loss: 1.488730
[INFO][16:04:16]: [Client #242] Epoch: [5/5][10/15]	Loss: 1.894905
[INFO][16:04:16]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][16:04:24]: [Client #242] Woke up.
[INFO][16:04:24]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][16:04:25]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][16:04:25]: [Client #242] Model trained.
[INFO][16:04:25]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:04:25]: [Server #615782] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][16:04:25]: [Server #615782] Selecting client #880 for training.
[INFO][16:04:25]: [Server #615782] Sending the current model to client #880 (simulated).
[INFO][16:04:25]: [Server #615782] Sending 0.26 MB of payload data to client #880 (simulated).
[INFO][16:04:25]: [Server #615782] Selecting client #974 for training.
[INFO][16:04:25]: [Server #615782] Sending the current model to client #974 (simulated).
[INFO][16:04:25]: [Server #615782] Sending 0.26 MB of payload data to client #974 (simulated).
[INFO][16:04:25]: [Client #880] Selected by the server.
[INFO][16:04:25]: [Client #880] Loading its data source...
[INFO][16:04:25]: [Client #974] Selected by the server.
[INFO][16:04:25]: Data source: FEMNIST
[INFO][16:04:25]: [Client #974] Loading its data source...
[INFO][16:04:25]: Data source: FEMNIST
[INFO][16:04:25]: [Client #974] Dataset size: 158
[INFO][16:04:25]: [Client #974] Sampler: all_inclusive
[INFO][16:04:25]: [Client #880] Dataset size: 156
[INFO][16:04:25]: [Client #880] Sampler: all_inclusive
[INFO][16:04:25]: [Client #974] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:04:25]: [Client #880] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:04:25]: [93m[1m[Client #974] Started training in communication round #14.[0m
[INFO][16:04:25]: [93m[1m[Client #880] Started training in communication round #14.[0m
[INFO][16:04:27]: [Client #880] Loading the dataset.
[INFO][16:04:27]: [Client #974] Loading the dataset.
[INFO][16:04:35]: [Client #974] Epoch: [1/5][0/16]	Loss: 0.206116
[INFO][16:04:35]: [Client #880] Epoch: [1/5][0/16]	Loss: 0.563380
[INFO][16:04:35]: [Client #974] Epoch: [1/5][10/16]	Loss: 1.034546
[INFO][16:04:35]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][16:04:35]: [Client #880] Epoch: [1/5][10/16]	Loss: 1.216425
[INFO][16:04:35]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][16:04:37]: [Client #880] Woke up.
[INFO][16:04:37]: [Client #880] Epoch: [2/5][0/16]	Loss: 0.387971
[INFO][16:04:37]: [Client #880] Epoch: [2/5][10/16]	Loss: 0.259325
[INFO][16:04:37]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][16:04:39]: [Client #880] Woke up.
[INFO][16:04:39]: [Client #880] Epoch: [3/5][0/16]	Loss: 0.591371
[INFO][16:04:39]: [Client #880] Epoch: [3/5][10/16]	Loss: 0.758516
[INFO][16:04:39]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][16:04:41]: [Client #880] Woke up.
[INFO][16:04:41]: [Client #880] Epoch: [4/5][0/16]	Loss: 0.886763
[INFO][16:04:41]: [Client #880] Epoch: [4/5][10/16]	Loss: 1.064932
[INFO][16:04:42]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][16:04:42]: [Client #974] Woke up.
[INFO][16:04:42]: [Client #974] Epoch: [2/5][0/16]	Loss: 0.890280
[INFO][16:04:42]: [Client #974] Epoch: [2/5][10/16]	Loss: 0.498360
[INFO][16:04:42]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][16:04:44]: [Client #880] Woke up.
[INFO][16:04:44]: [Client #880] Epoch: [5/5][0/16]	Loss: 0.416096
[INFO][16:04:44]: [Client #880] Epoch: [5/5][10/16]	Loss: 0.068304
[INFO][16:04:44]: [Client #880] Going to sleep for 2.02 seconds.
[INFO][16:04:46]: [Client #880] Woke up.
[INFO][16:04:46]: [Client #880] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_880_615874.pth.
[INFO][16:04:46]: [Client #880] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_880_615874.pth.
[INFO][16:04:46]: [Client #880] Model trained.
[INFO][16:04:46]: [Client #880] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:04:46]: [Server #615782] Received 0.26 MB of payload data from client #880 (simulated).
[INFO][16:04:49]: [Client #974] Woke up.
[INFO][16:04:49]: [Client #974] Epoch: [3/5][0/16]	Loss: 0.154950
[INFO][16:04:49]: [Client #974] Epoch: [3/5][10/16]	Loss: 1.377581
[INFO][16:04:50]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][16:04:57]: [Client #974] Woke up.
[INFO][16:04:57]: [Client #974] Epoch: [4/5][0/16]	Loss: 1.267482
[INFO][16:04:57]: [Client #974] Epoch: [4/5][10/16]	Loss: 0.414507
[INFO][16:04:57]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][16:05:04]: [Client #974] Woke up.
[INFO][16:05:04]: [Client #974] Epoch: [5/5][0/16]	Loss: 1.012085
[INFO][16:05:04]: [Client #974] Epoch: [5/5][10/16]	Loss: 0.580429
[INFO][16:05:04]: [Client #974] Going to sleep for 7.13 seconds.
[INFO][16:05:11]: [Client #974] Woke up.
[INFO][16:05:11]: [Client #974] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][16:05:12]: [Client #974] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_974_615875.pth.
[INFO][16:05:12]: [Client #974] Model trained.
[INFO][16:05:12]: [Client #974] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:05:12]: [Server #615782] Received 0.26 MB of payload data from client #974 (simulated).
[INFO][16:05:12]: [Server #615782] Selecting client #605 for training.
[INFO][16:05:12]: [Server #615782] Sending the current model to client #605 (simulated).
[INFO][16:05:12]: [Server #615782] Sending 0.26 MB of payload data to client #605 (simulated).
[INFO][16:05:12]: [Server #615782] Selecting client #977 for training.
[INFO][16:05:12]: [Server #615782] Sending the current model to client #977 (simulated).
[INFO][16:05:12]: [Server #615782] Sending 0.26 MB of payload data to client #977 (simulated).
[INFO][16:05:12]: [Client #977] Selected by the server.
[INFO][16:05:12]: [Client #605] Selected by the server.
[INFO][16:05:12]: [Client #977] Loading its data source...
[INFO][16:05:12]: [Client #605] Loading its data source...
[INFO][16:05:12]: Data source: FEMNIST
[INFO][16:05:12]: Data source: FEMNIST
[INFO][16:05:12]: [Client #605] Dataset size: 153
[INFO][16:05:12]: [Client #605] Sampler: all_inclusive
[INFO][16:05:12]: [Client #977] Dataset size: 175
[INFO][16:05:12]: [Client #977] Sampler: all_inclusive
[INFO][16:05:12]: [Client #605] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:12]: [Client #977] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:12]: [93m[1m[Client #605] Started training in communication round #14.[0m
[INFO][16:05:12]: [93m[1m[Client #977] Started training in communication round #14.[0m
[INFO][16:05:14]: [Client #977] Loading the dataset.
[INFO][16:05:14]: [Client #605] Loading the dataset.
[INFO][16:05:21]: [Client #977] Epoch: [1/5][0/18]	Loss: 0.765586
[INFO][16:05:21]: [Client #605] Epoch: [1/5][0/16]	Loss: 1.579659
[INFO][16:05:21]: [Client #977] Epoch: [1/5][10/18]	Loss: 2.094033
[INFO][16:05:21]: [Client #605] Epoch: [1/5][10/16]	Loss: 0.752001
[INFO][16:05:21]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][16:05:21]: [Client #977] Going to sleep for 0.49 seconds.
[INFO][16:05:21]: [Client #605] Woke up.
[INFO][16:05:21]: [Client #605] Epoch: [2/5][0/16]	Loss: 1.629297
[INFO][16:05:21]: [Client #605] Epoch: [2/5][10/16]	Loss: 2.376846
[INFO][16:05:21]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][16:05:22]: [Client #977] Woke up.
[INFO][16:05:22]: [Client #977] Epoch: [2/5][0/18]	Loss: 0.275164
[INFO][16:05:22]: [Client #977] Epoch: [2/5][10/18]	Loss: 1.350207
[INFO][16:05:22]: [Client #977] Going to sleep for 0.49 seconds.
[INFO][16:05:22]: [Client #605] Woke up.
[INFO][16:05:22]: [Client #605] Epoch: [3/5][0/16]	Loss: 1.963287
[INFO][16:05:22]: [Client #605] Epoch: [3/5][10/16]	Loss: 1.420056
[INFO][16:05:22]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][16:05:22]: [Client #605] Woke up.
[INFO][16:05:22]: [Client #605] Epoch: [4/5][0/16]	Loss: 0.583282
[INFO][16:05:22]: [Client #977] Woke up.
[INFO][16:05:22]: [Client #977] Epoch: [3/5][0/18]	Loss: 1.280199
[INFO][16:05:22]: [Client #605] Epoch: [4/5][10/16]	Loss: 0.966216
[INFO][16:05:22]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][16:05:22]: [Client #977] Epoch: [3/5][10/18]	Loss: 1.079144
[INFO][16:05:22]: [Client #977] Going to sleep for 0.49 seconds.
[INFO][16:05:23]: [Client #605] Woke up.
[INFO][16:05:23]: [Client #605] Epoch: [5/5][0/16]	Loss: 0.598846
[INFO][16:05:23]: [Client #605] Epoch: [5/5][10/16]	Loss: 1.101946
[INFO][16:05:23]: [Client #605] Going to sleep for 0.26 seconds.
[INFO][16:05:23]: [Client #977] Woke up.
[INFO][16:05:23]: [Client #977] Epoch: [4/5][0/18]	Loss: 0.406338
[INFO][16:05:23]: [Client #605] Woke up.
[INFO][16:05:23]: [Client #605] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_605_615874.pth.
[INFO][16:05:23]: [Client #977] Epoch: [4/5][10/18]	Loss: 0.888751
[INFO][16:05:23]: [Client #977] Going to sleep for 0.49 seconds.
[INFO][16:05:23]: [Client #977] Woke up.
[INFO][16:05:24]: [Client #977] Epoch: [5/5][0/18]	Loss: 1.314574
[INFO][16:05:24]: [Client #605] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_605_615874.pth.
[INFO][16:05:24]: [Client #605] Model trained.
[INFO][16:05:24]: [Client #605] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:05:24]: [Server #615782] Received 0.26 MB of payload data from client #605 (simulated).
[INFO][16:05:24]: [Client #977] Epoch: [5/5][10/18]	Loss: 1.302666
[INFO][16:05:24]: [Client #977] Going to sleep for 0.49 seconds.
[INFO][16:05:24]: [Client #977] Woke up.
[INFO][16:05:24]: [Client #977] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_977_615875.pth.
[INFO][16:05:25]: [Client #977] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_977_615875.pth.
[INFO][16:05:25]: [Client #977] Model trained.
[INFO][16:05:25]: [Client #977] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:05:25]: [Server #615782] Received 0.26 MB of payload data from client #977 (simulated).
[INFO][16:05:25]: [Server #615782] Selecting client #44 for training.
[INFO][16:05:25]: [Server #615782] Sending the current model to client #44 (simulated).
[INFO][16:05:25]: [Server #615782] Sending 0.26 MB of payload data to client #44 (simulated).
[INFO][16:05:25]: [Server #615782] Selecting client #949 for training.
[INFO][16:05:25]: [Server #615782] Sending the current model to client #949 (simulated).
[INFO][16:05:25]: [Server #615782] Sending 0.26 MB of payload data to client #949 (simulated).
[INFO][16:05:25]: [Client #44] Selected by the server.
[INFO][16:05:25]: [Client #949] Selected by the server.
[INFO][16:05:25]: [Client #44] Loading its data source...
[INFO][16:05:25]: [Client #949] Loading its data source...
[INFO][16:05:25]: Data source: FEMNIST
[INFO][16:05:25]: Data source: FEMNIST
[INFO][16:05:25]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:05:25]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/949.zip.
[INFO][16:05:25]: [Client #44] Dataset size: 166
[INFO][16:05:25]: [Client #44] Sampler: all_inclusive
[INFO][16:05:25]: [Client #44] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:25]: [93m[1m[Client #44] Started training in communication round #14.[0m
3.0%6.0%9.0%12.1%15.1%18.1%21.1%24.1%27.1%30.1%33.2%36.2%39.2%42.2%45.2%48.2%51.2%54.2%57.3%60.3%63.3%66.3%69.3%72.3%75.3%78.4%81.4%84.4%87.4%90.4%93.4%96.4%99.5%100.0%[INFO][16:05:25]: Decompressing the dataset downloaded.
[INFO][16:05:25]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/949.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:05:25]: [Client #949] Dataset size: 153
[INFO][16:05:25]: [Client #949] Sampler: all_inclusive
[INFO][16:05:25]: [Client #949] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:25]: [93m[1m[Client #949] Started training in communication round #14.[0m

[INFO][16:05:27]: [Client #44] Loading the dataset.
[INFO][16:05:27]: [Client #949] Loading the dataset.
[INFO][16:05:35]: [Client #44] Epoch: [1/5][0/17]	Loss: 1.247269
[INFO][16:05:35]: [Client #949] Epoch: [1/5][0/16]	Loss: 1.065711
[INFO][16:05:35]: [Client #44] Epoch: [1/5][10/17]	Loss: 1.124345
[INFO][16:05:35]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][16:05:35]: [Client #949] Epoch: [1/5][10/16]	Loss: 0.715011
[INFO][16:05:35]: [Client #949] Going to sleep for 0.02 seconds.
[INFO][16:05:35]: [Client #949] Woke up.
[INFO][16:05:35]: [Client #949] Epoch: [2/5][0/16]	Loss: 1.647852
[INFO][16:05:35]: [Client #949] Epoch: [2/5][10/16]	Loss: 0.526357
[INFO][16:05:35]: [Client #949] Going to sleep for 0.02 seconds.
[INFO][16:05:35]: [Client #949] Woke up.
[INFO][16:05:35]: [Client #949] Epoch: [3/5][0/16]	Loss: 0.813053
[INFO][16:05:35]: [Client #949] Epoch: [3/5][10/16]	Loss: 0.596410
[INFO][16:05:35]: [Client #949] Going to sleep for 0.02 seconds.
[INFO][16:05:35]: [Client #949] Woke up.
[INFO][16:05:35]: [Client #949] Epoch: [4/5][0/16]	Loss: 1.052289
[INFO][16:05:35]: [Client #949] Epoch: [4/5][10/16]	Loss: 0.457902
[INFO][16:05:35]: [Client #949] Going to sleep for 0.02 seconds.
[INFO][16:05:35]: [Client #949] Woke up.
[INFO][16:05:35]: [Client #949] Epoch: [5/5][0/16]	Loss: 0.676660
[INFO][16:05:35]: [Client #949] Epoch: [5/5][10/16]	Loss: 1.037519
[INFO][16:05:35]: [Client #949] Going to sleep for 0.02 seconds.
[INFO][16:05:35]: [Client #949] Woke up.
[INFO][16:05:35]: [Client #949] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_949_615875.pth.
[INFO][16:05:36]: [Client #949] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_949_615875.pth.
[INFO][16:05:36]: [Client #949] Model trained.
[INFO][16:05:36]: [Client #949] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:05:36]: [Server #615782] Received 0.26 MB of payload data from client #949 (simulated).
[INFO][16:05:38]: [Client #44] Woke up.
[INFO][16:05:38]: [Client #44] Epoch: [2/5][0/17]	Loss: 0.390333
[INFO][16:05:39]: [Client #44] Epoch: [2/5][10/17]	Loss: 1.500650
[INFO][16:05:39]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][16:05:42]: [Client #44] Woke up.
[INFO][16:05:42]: [Client #44] Epoch: [3/5][0/17]	Loss: 0.918733
[INFO][16:05:42]: [Client #44] Epoch: [3/5][10/17]	Loss: 0.350177
[INFO][16:05:42]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][16:05:46]: [Client #44] Woke up.
[INFO][16:05:46]: [Client #44] Epoch: [4/5][0/17]	Loss: 1.454387
[INFO][16:05:46]: [Client #44] Epoch: [4/5][10/17]	Loss: 1.594060
[INFO][16:05:46]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][16:05:50]: [Client #44] Woke up.
[INFO][16:05:50]: [Client #44] Epoch: [5/5][0/17]	Loss: 0.444774
[INFO][16:05:50]: [Client #44] Epoch: [5/5][10/17]	Loss: 1.122812
[INFO][16:05:50]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][16:05:54]: [Client #44] Woke up.
[INFO][16:05:54]: [Client #44] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_615874.pth.
[INFO][16:05:55]: [Client #44] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_615874.pth.
[INFO][16:05:55]: [Client #44] Model trained.
[INFO][16:05:55]: [Client #44] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:05:55]: [Server #615782] Received 0.26 MB of payload data from client #44 (simulated).
[INFO][16:05:55]: [Server #615782] Selecting client #311 for training.
[INFO][16:05:55]: [Server #615782] Sending the current model to client #311 (simulated).
[INFO][16:05:55]: [Server #615782] Sending 0.26 MB of payload data to client #311 (simulated).
[INFO][16:05:55]: [Server #615782] Selecting client #798 for training.
[INFO][16:05:55]: [Server #615782] Sending the current model to client #798 (simulated).
[INFO][16:05:55]: [Server #615782] Sending 0.26 MB of payload data to client #798 (simulated).
[INFO][16:05:55]: [Client #311] Selected by the server.
[INFO][16:05:55]: [Client #311] Loading its data source...
[INFO][16:05:55]: Data source: FEMNIST
[INFO][16:05:55]: [Client #798] Selected by the server.
[INFO][16:05:55]: [Client #798] Loading its data source...
[INFO][16:05:55]: Data source: FEMNIST
[INFO][16:05:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:05:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/798.zip.
[INFO][16:05:55]: [Client #311] Dataset size: 288
[INFO][16:05:55]: [Client #311] Sampler: all_inclusive
[INFO][16:05:55]: [Client #311] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:55]: [93m[1m[Client #311] Started training in communication round #14.[0m
2.4%4.8%7.2%9.6%12.0%14.4%16.7%19.1%21.5%23.9%26.3%28.7%31.1%33.5%35.9%38.3%40.7%43.1%45.5%47.9%50.2%52.6%55.0%57.4%59.8%62.2%64.6%67.0%69.4%71.8%74.2%76.6%79.0%81.3%83.7%86.1%88.5%90.9%93.3%95.7%98.1%100.0%[INFO][16:05:55]: Decompressing the dataset downloaded.
[INFO][16:05:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/798.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:05:55]: [Client #798] Dataset size: 153
[INFO][16:05:55]: [Client #798] Sampler: all_inclusive
[INFO][16:05:55]: [Client #798] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:05:55]: [93m[1m[Client #798] Started training in communication round #14.[0m

[INFO][16:05:57]: [Client #798] Loading the dataset.
[INFO][16:05:57]: [Client #311] Loading the dataset.
[INFO][16:06:04]: [Client #798] Epoch: [1/5][0/16]	Loss: 0.299694
[INFO][16:06:04]: [Client #311] Epoch: [1/5][0/29]	Loss: 1.547397
[INFO][16:06:04]: [Client #311] Epoch: [1/5][10/29]	Loss: 1.538646
[INFO][16:06:04]: [Client #798] Epoch: [1/5][10/16]	Loss: 1.198005
[INFO][16:06:04]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][16:06:04]: [Client #311] Epoch: [1/5][20/29]	Loss: 1.668985
[INFO][16:06:04]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][16:06:06]: [Client #798] Woke up.
[INFO][16:06:06]: [Client #798] Epoch: [2/5][0/16]	Loss: 0.631635
[INFO][16:06:06]: [Client #798] Epoch: [2/5][10/16]	Loss: 1.524051
[INFO][16:06:06]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][16:06:07]: [Client #798] Woke up.
[INFO][16:06:07]: [Client #798] Epoch: [3/5][0/16]	Loss: 0.688945
[INFO][16:06:07]: [Client #798] Epoch: [3/5][10/16]	Loss: 0.539669
[INFO][16:06:07]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][16:06:08]: [Client #798] Woke up.
[INFO][16:06:08]: [Client #798] Epoch: [4/5][0/16]	Loss: 3.329015
[INFO][16:06:08]: [Client #798] Epoch: [4/5][10/16]	Loss: 1.442544
[INFO][16:06:08]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][16:06:10]: [Client #798] Woke up.
[INFO][16:06:10]: [Client #798] Epoch: [5/5][0/16]	Loss: 1.071025
[INFO][16:06:10]: [Client #798] Epoch: [5/5][10/16]	Loss: 2.517915
[INFO][16:06:10]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][16:06:11]: [Client #798] Woke up.
[INFO][16:06:11]: [Client #798] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_798_615875.pth.
[INFO][16:06:12]: [Client #798] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_798_615875.pth.
[INFO][16:06:12]: [Client #798] Model trained.
[INFO][16:06:12]: [Client #798] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:06:12]: [Server #615782] Received 0.26 MB of payload data from client #798 (simulated).
[INFO][16:06:15]: [Client #311] Woke up.
[INFO][16:06:15]: [Client #311] Epoch: [2/5][0/29]	Loss: 1.246103
[INFO][16:06:16]: [Client #311] Epoch: [2/5][10/29]	Loss: 0.671779
[INFO][16:06:16]: [Client #311] Epoch: [2/5][20/29]	Loss: 1.212519
[INFO][16:06:16]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][16:06:27]: [Client #311] Woke up.
[INFO][16:06:27]: [Client #311] Epoch: [3/5][0/29]	Loss: 0.929969
[INFO][16:06:27]: [Client #311] Epoch: [3/5][10/29]	Loss: 0.702250
[INFO][16:06:27]: [Client #311] Epoch: [3/5][20/29]	Loss: 0.877278
[INFO][16:06:27]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][16:06:38]: [Client #311] Woke up.
[INFO][16:06:38]: [Client #311] Epoch: [4/5][0/29]	Loss: 1.503648
[INFO][16:06:38]: [Client #311] Epoch: [4/5][10/29]	Loss: 1.117026
[INFO][16:06:38]: [Client #311] Epoch: [4/5][20/29]	Loss: 3.283393
[INFO][16:06:38]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][16:06:49]: [Client #311] Woke up.
[INFO][16:06:49]: [Client #311] Epoch: [5/5][0/29]	Loss: 0.400031
[INFO][16:06:49]: [Client #311] Epoch: [5/5][10/29]	Loss: 0.422448
[INFO][16:06:49]: [Client #311] Epoch: [5/5][20/29]	Loss: 1.401751
[INFO][16:06:49]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][16:07:00]: [Client #311] Woke up.
[INFO][16:07:00]: [Client #311] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_615874.pth.
[INFO][16:07:01]: [Client #311] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_615874.pth.
[INFO][16:07:01]: [Client #311] Model trained.
[INFO][16:07:01]: [Client #311] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:01]: [Server #615782] Received 0.26 MB of payload data from client #311 (simulated).
[INFO][16:07:01]: [Server #615782] Selecting client #810 for training.
[INFO][16:07:01]: [Server #615782] Sending the current model to client #810 (simulated).
[INFO][16:07:01]: [Server #615782] Sending 0.26 MB of payload data to client #810 (simulated).
[INFO][16:07:01]: [Server #615782] Selecting client #860 for training.
[INFO][16:07:01]: [Server #615782] Sending the current model to client #860 (simulated).
[INFO][16:07:01]: [Server #615782] Sending 0.26 MB of payload data to client #860 (simulated).
[INFO][16:07:01]: [Client #810] Selected by the server.
[INFO][16:07:01]: [Client #810] Loading its data source...
[INFO][16:07:01]: Data source: FEMNIST
[INFO][16:07:01]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:07:01]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/810.zip.
[INFO][16:07:01]: [Client #860] Selected by the server.
[INFO][16:07:01]: [Client #860] Loading its data source...
[INFO][16:07:01]: Data source: FEMNIST
[INFO][16:07:01]: [Client #860] Dataset size: 162
[INFO][16:07:01]: [Client #860] Sampler: all_inclusive
[INFO][16:07:01]: [Client #860] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:01]: [93m[1m[Client #860] Started training in communication round #14.[0m
2.5%5.0%7.5%9.9%12.4%14.9%17.4%19.9%22.4%24.8%27.3%29.8%32.3%34.8%37.3%39.8%42.2%44.7%47.2%49.7%52.2%54.7%57.1%59.6%62.1%64.6%67.1%69.6%72.1%74.5%77.0%79.5%82.0%84.5%87.0%89.4%91.9%94.4%96.9%99.4%100.0%[INFO][16:07:01]: Decompressing the dataset downloaded.
[INFO][16:07:01]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/810.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:07:01]: [Client #810] Dataset size: 160
[INFO][16:07:01]: [Client #810] Sampler: all_inclusive
[INFO][16:07:01]: [Client #810] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:01]: [93m[1m[Client #810] Started training in communication round #14.[0m

[INFO][16:07:03]: [Client #810] Loading the dataset.
[INFO][16:07:03]: [Client #860] Loading the dataset.
[INFO][16:07:10]: [Client #810] Epoch: [1/5][0/16]	Loss: 0.674192
[INFO][16:07:10]: [Client #860] Epoch: [1/5][0/17]	Loss: 1.803975
[INFO][16:07:10]: [Client #810] Epoch: [1/5][10/16]	Loss: 0.618541
[INFO][16:07:10]: [Client #860] Epoch: [1/5][10/17]	Loss: 1.089602
[INFO][16:07:10]: [Client #810] Going to sleep for 0.30 seconds.
[INFO][16:07:10]: [Client #860] Going to sleep for 1.77 seconds.
[INFO][16:07:10]: [Client #810] Woke up.
[INFO][16:07:10]: [Client #810] Epoch: [2/5][0/16]	Loss: 1.015125
[INFO][16:07:11]: [Client #810] Epoch: [2/5][10/16]	Loss: 0.305599
[INFO][16:07:11]: [Client #810] Going to sleep for 0.30 seconds.
[INFO][16:07:11]: [Client #810] Woke up.
[INFO][16:07:11]: [Client #810] Epoch: [3/5][0/16]	Loss: 0.175677
[INFO][16:07:11]: [Client #810] Epoch: [3/5][10/16]	Loss: 0.928591
[INFO][16:07:11]: [Client #810] Going to sleep for 0.30 seconds.
[INFO][16:07:11]: [Client #810] Woke up.
[INFO][16:07:11]: [Client #810] Epoch: [4/5][0/16]	Loss: 0.602426
[INFO][16:07:11]: [Client #810] Epoch: [4/5][10/16]	Loss: 0.428789
[INFO][16:07:11]: [Client #810] Going to sleep for 0.30 seconds.
[INFO][16:07:12]: [Client #810] Woke up.
[INFO][16:07:12]: [Client #810] Epoch: [5/5][0/16]	Loss: 0.831264
[INFO][16:07:12]: [Client #810] Epoch: [5/5][10/16]	Loss: 0.924584
[INFO][16:07:12]: [Client #810] Going to sleep for 0.30 seconds.
[INFO][16:07:12]: [Client #860] Woke up.
[INFO][16:07:12]: [Client #860] Epoch: [2/5][0/17]	Loss: 0.482941
[INFO][16:07:12]: [Client #860] Epoch: [2/5][10/17]	Loss: 1.434951
[INFO][16:07:12]: [Client #860] Going to sleep for 1.77 seconds.
[INFO][16:07:12]: [Client #810] Woke up.
[INFO][16:07:12]: [Client #810] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_810_615874.pth.
[INFO][16:07:13]: [Client #810] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_810_615874.pth.
[INFO][16:07:13]: [Client #810] Model trained.
[INFO][16:07:13]: [Client #810] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:13]: [Server #615782] Received 0.26 MB of payload data from client #810 (simulated).
[INFO][16:07:14]: [Client #860] Woke up.
[INFO][16:07:14]: [Client #860] Epoch: [3/5][0/17]	Loss: 0.773375
[INFO][16:07:14]: [Client #860] Epoch: [3/5][10/17]	Loss: 1.671559
[INFO][16:07:14]: [Client #860] Going to sleep for 1.77 seconds.
[INFO][16:07:16]: [Client #860] Woke up.
[INFO][16:07:16]: [Client #860] Epoch: [4/5][0/17]	Loss: 0.451840
[INFO][16:07:16]: [Client #860] Epoch: [4/5][10/17]	Loss: 0.740655
[INFO][16:07:16]: [Client #860] Going to sleep for 1.77 seconds.
[INFO][16:07:18]: [Client #860] Woke up.
[INFO][16:07:18]: [Client #860] Epoch: [5/5][0/17]	Loss: 0.739360
[INFO][16:07:18]: [Client #860] Epoch: [5/5][10/17]	Loss: 1.073673
[INFO][16:07:18]: [Client #860] Going to sleep for 1.77 seconds.
[INFO][16:07:20]: [Client #860] Woke up.
[INFO][16:07:20]: [Client #860] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_860_615875.pth.
[INFO][16:07:20]: [Client #860] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_860_615875.pth.
[INFO][16:07:20]: [Client #860] Model trained.
[INFO][16:07:20]: [Client #860] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:20]: [Server #615782] Received 0.26 MB of payload data from client #860 (simulated).
[INFO][16:07:20]: [Server #615782] Selecting client #458 for training.
[INFO][16:07:20]: [Server #615782] Sending the current model to client #458 (simulated).
[INFO][16:07:20]: [Server #615782] Sending 0.26 MB of payload data to client #458 (simulated).
[INFO][16:07:20]: [Server #615782] Selecting client #931 for training.
[INFO][16:07:20]: [Server #615782] Sending the current model to client #931 (simulated).
[INFO][16:07:20]: [Server #615782] Sending 0.26 MB of payload data to client #931 (simulated).
[INFO][16:07:20]: [Client #931] Selected by the server.
[INFO][16:07:20]: [Client #458] Selected by the server.
[INFO][16:07:20]: [Client #931] Loading its data source...
[INFO][16:07:20]: [Client #458] Loading its data source...
[INFO][16:07:20]: Data source: FEMNIST
[INFO][16:07:20]: Data source: FEMNIST
[INFO][16:07:20]: [Client #931] Dataset size: 135
[INFO][16:07:20]: [Client #931] Sampler: all_inclusive
[INFO][16:07:20]: [Client #931] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:20]: [93m[1m[Client #931] Started training in communication round #14.[0m
[INFO][16:07:20]: [Client #458] Dataset size: 163
[INFO][16:07:20]: [Client #458] Sampler: all_inclusive
[INFO][16:07:20]: [Client #458] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:20]: [93m[1m[Client #458] Started training in communication round #14.[0m
[INFO][16:07:22]: [Client #931] Loading the dataset.
[INFO][16:07:22]: [Client #458] Loading the dataset.
[INFO][16:07:29]: [Client #931] Epoch: [1/5][0/14]	Loss: 0.957001
[INFO][16:07:29]: [Client #458] Epoch: [1/5][0/17]	Loss: 0.584088
[INFO][16:07:30]: [Client #931] Epoch: [1/5][10/14]	Loss: 0.714880
[INFO][16:07:30]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][16:07:30]: [Client #458] Epoch: [1/5][10/17]	Loss: 1.057486
[INFO][16:07:30]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][16:07:30]: [Client #931] Woke up.
[INFO][16:07:30]: [Client #931] Epoch: [2/5][0/14]	Loss: 2.383991
[INFO][16:07:30]: [Client #931] Epoch: [2/5][10/14]	Loss: 1.127723
[INFO][16:07:30]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][16:07:30]: [Client #931] Woke up.
[INFO][16:07:30]: [Client #931] Epoch: [3/5][0/14]	Loss: 0.402154
[INFO][16:07:30]: [Client #931] Epoch: [3/5][10/14]	Loss: 0.913664
[INFO][16:07:30]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][16:07:30]: [Client #931] Woke up.
[INFO][16:07:30]: [Client #931] Epoch: [4/5][0/14]	Loss: 1.003963
[INFO][16:07:30]: [Client #931] Epoch: [4/5][10/14]	Loss: 0.604501
[INFO][16:07:30]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][16:07:30]: [Client #931] Woke up.
[INFO][16:07:30]: [Client #931] Epoch: [5/5][0/14]	Loss: 0.816157
[INFO][16:07:30]: [Client #458] Woke up.
[INFO][16:07:30]: [Client #458] Epoch: [2/5][0/17]	Loss: 1.007724
[INFO][16:07:30]: [Client #931] Epoch: [5/5][10/14]	Loss: 0.609779
[INFO][16:07:30]: [Client #931] Going to sleep for 0.08 seconds.
[INFO][16:07:30]: [Client #458] Epoch: [2/5][10/17]	Loss: 1.079909
[INFO][16:07:30]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][16:07:30]: [Client #931] Woke up.
[INFO][16:07:30]: [Client #931] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_931_615875.pth.
[INFO][16:07:31]: [Client #931] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_931_615875.pth.
[INFO][16:07:31]: [Client #931] Model trained.
[INFO][16:07:31]: [Client #931] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:31]: [Server #615782] Received 0.26 MB of payload data from client #931 (simulated).
[INFO][16:07:31]: [Client #458] Woke up.
[INFO][16:07:31]: [Client #458] Epoch: [3/5][0/17]	Loss: 0.686767
[INFO][16:07:31]: [Client #458] Epoch: [3/5][10/17]	Loss: 1.161821
[INFO][16:07:31]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][16:07:32]: [Client #458] Woke up.
[INFO][16:07:32]: [Client #458] Epoch: [4/5][0/17]	Loss: 1.235434
[INFO][16:07:32]: [Client #458] Epoch: [4/5][10/17]	Loss: 2.221442
[INFO][16:07:32]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][16:07:33]: [Client #458] Woke up.
[INFO][16:07:33]: [Client #458] Epoch: [5/5][0/17]	Loss: 2.155947
[INFO][16:07:33]: [Client #458] Epoch: [5/5][10/17]	Loss: 0.474482
[INFO][16:07:33]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][16:07:34]: [Client #458] Woke up.
[INFO][16:07:34]: [Client #458] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_458_615874.pth.
[INFO][16:07:34]: [Client #458] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_458_615874.pth.
[INFO][16:07:34]: [Client #458] Model trained.
[INFO][16:07:34]: [Client #458] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:35]: [Server #615782] Received 0.26 MB of payload data from client #458 (simulated).
[INFO][16:07:35]: [Server #615782] Selecting client #258 for training.
[INFO][16:07:35]: [Server #615782] Sending the current model to client #258 (simulated).
[INFO][16:07:35]: [Server #615782] Sending 0.26 MB of payload data to client #258 (simulated).
[INFO][16:07:35]: [Server #615782] Selecting client #935 for training.
[INFO][16:07:35]: [Server #615782] Sending the current model to client #935 (simulated).
[INFO][16:07:35]: [Server #615782] Sending 0.26 MB of payload data to client #935 (simulated).
[INFO][16:07:35]: [Client #258] Selected by the server.
[INFO][16:07:35]: [Client #258] Loading its data source...
[INFO][16:07:35]: Data source: FEMNIST
[INFO][16:07:35]: [Client #935] Selected by the server.
[INFO][16:07:35]: [Client #935] Loading its data source...
[INFO][16:07:35]: Data source: FEMNIST
[INFO][16:07:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:07:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/935.zip.
[INFO][16:07:35]: [Client #258] Dataset size: 165
[INFO][16:07:35]: [Client #258] Sampler: all_inclusive
[INFO][16:07:35]: [Client #258] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:35]: [93m[1m[Client #258] Started training in communication round #14.[0m
2.4%4.8%7.1%9.5%11.9%14.3%16.6%19.0%21.4%23.8%26.1%28.5%30.9%33.3%35.7%38.0%40.4%42.8%45.2%47.5%49.9%52.3%54.7%57.0%59.4%61.8%64.2%66.6%68.9%71.3%73.7%76.1%78.4%80.8%83.2%85.6%87.9%90.3%92.7%95.1%97.4%99.8%100.0%[INFO][16:07:35]: Decompressing the dataset downloaded.
[INFO][16:07:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/935.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:07:35]: [Client #935] Dataset size: 135
[INFO][16:07:35]: [Client #935] Sampler: all_inclusive
[INFO][16:07:35]: [Client #935] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:35]: [93m[1m[Client #935] Started training in communication round #14.[0m

[INFO][16:07:37]: [Client #258] Loading the dataset.
[INFO][16:07:37]: [Client #935] Loading the dataset.
[INFO][16:07:44]: [Client #258] Epoch: [1/5][0/17]	Loss: 0.912649
[INFO][16:07:44]: [Client #935] Epoch: [1/5][0/14]	Loss: 1.751263
[INFO][16:07:44]: [Client #258] Epoch: [1/5][10/17]	Loss: 0.489966
[INFO][16:07:44]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][16:07:44]: [Client #935] Epoch: [1/5][10/14]	Loss: 1.441096
[INFO][16:07:45]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][16:07:46]: [Client #935] Woke up.
[INFO][16:07:46]: [Client #935] Epoch: [2/5][0/14]	Loss: 0.572753
[INFO][16:07:46]: [Client #935] Epoch: [2/5][10/14]	Loss: 0.261561
[INFO][16:07:46]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][16:07:46]: [Client #258] Woke up.
[INFO][16:07:46]: [Client #258] Epoch: [2/5][0/17]	Loss: 1.212982
[INFO][16:07:46]: [Client #258] Epoch: [2/5][10/17]	Loss: 0.517441
[INFO][16:07:46]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][16:07:47]: [Client #935] Woke up.
[INFO][16:07:47]: [Client #935] Epoch: [3/5][0/14]	Loss: 0.739879
[INFO][16:07:47]: [Client #935] Epoch: [3/5][10/14]	Loss: 0.553642
[INFO][16:07:47]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][16:07:48]: [Client #935] Woke up.
[INFO][16:07:48]: [Client #935] Epoch: [4/5][0/14]	Loss: 0.827298
[INFO][16:07:48]: [Client #935] Epoch: [4/5][10/14]	Loss: 2.337119
[INFO][16:07:48]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][16:07:48]: [Client #258] Woke up.
[INFO][16:07:48]: [Client #258] Epoch: [3/5][0/17]	Loss: 1.574773
[INFO][16:07:48]: [Client #258] Epoch: [3/5][10/17]	Loss: 0.679235
[INFO][16:07:48]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][16:07:49]: [Client #935] Woke up.
[INFO][16:07:49]: [Client #935] Epoch: [5/5][0/14]	Loss: 2.283622
[INFO][16:07:49]: [Client #935] Epoch: [5/5][10/14]	Loss: 1.424152
[INFO][16:07:49]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][16:07:50]: [Client #258] Woke up.
[INFO][16:07:50]: [Client #258] Epoch: [4/5][0/17]	Loss: 0.584688
[INFO][16:07:50]: [Client #258] Epoch: [4/5][10/17]	Loss: 0.698000
[INFO][16:07:50]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][16:07:50]: [Client #935] Woke up.
[INFO][16:07:50]: [Client #935] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_935_615875.pth.
[INFO][16:07:51]: [Client #935] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_935_615875.pth.
[INFO][16:07:51]: [Client #935] Model trained.
[INFO][16:07:51]: [Client #935] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:51]: [Server #615782] Received 0.26 MB of payload data from client #935 (simulated).
[INFO][16:07:52]: [Client #258] Woke up.
[INFO][16:07:52]: [Client #258] Epoch: [5/5][0/17]	Loss: 0.492086
[INFO][16:07:52]: [Client #258] Epoch: [5/5][10/17]	Loss: 1.372694
[INFO][16:07:52]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][16:07:54]: [Client #258] Woke up.
[INFO][16:07:54]: [Client #258] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_615874.pth.
[INFO][16:07:54]: [Client #258] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_615874.pth.
[INFO][16:07:54]: [Client #258] Model trained.
[INFO][16:07:54]: [Client #258] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:07:54]: [Server #615782] Received 0.26 MB of payload data from client #258 (simulated).
[INFO][16:07:54]: [Server #615782] Selecting client #618 for training.
[INFO][16:07:54]: [Server #615782] Sending the current model to client #618 (simulated).
[INFO][16:07:54]: [Server #615782] Sending 0.26 MB of payload data to client #618 (simulated).
[INFO][16:07:54]: [Server #615782] Selecting client #986 for training.
[INFO][16:07:54]: [Server #615782] Sending the current model to client #986 (simulated).
[INFO][16:07:54]: [Server #615782] Sending 0.26 MB of payload data to client #986 (simulated).
[INFO][16:07:54]: [Client #618] Selected by the server.
[INFO][16:07:54]: [Client #618] Loading its data source...
[INFO][16:07:54]: Data source: FEMNIST
[INFO][16:07:54]: [Client #986] Selected by the server.
[INFO][16:07:54]: [Client #986] Loading its data source...
[INFO][16:07:54]: Data source: FEMNIST
[INFO][16:07:54]: [Client #986] Dataset size: 155
[INFO][16:07:54]: [Client #986] Sampler: all_inclusive
[INFO][16:07:54]: [Client #618] Dataset size: 162
[INFO][16:07:54]: [Client #618] Sampler: all_inclusive
[INFO][16:07:54]: [Client #986] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:54]: [Client #618] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:07:54]: [93m[1m[Client #986] Started training in communication round #14.[0m
[INFO][16:07:54]: [93m[1m[Client #618] Started training in communication round #14.[0m
[INFO][16:07:56]: [Client #618] Loading the dataset.
[INFO][16:07:56]: [Client #986] Loading the dataset.
[INFO][16:08:03]: [Client #986] Epoch: [1/5][0/16]	Loss: 0.718089
[INFO][16:08:03]: [Client #618] Epoch: [1/5][0/17]	Loss: 0.777830
[INFO][16:08:03]: [Client #986] Epoch: [1/5][10/16]	Loss: 1.355545
[INFO][16:08:03]: [Client #618] Epoch: [1/5][10/17]	Loss: 0.979222
[INFO][16:08:03]: [Client #986] Going to sleep for 1.33 seconds.
[INFO][16:08:03]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][16:08:03]: [Client #618] Woke up.
[INFO][16:08:03]: [Client #618] Epoch: [2/5][0/17]	Loss: 1.024711
[INFO][16:08:04]: [Client #618] Epoch: [2/5][10/17]	Loss: 0.365073
[INFO][16:08:04]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][16:08:04]: [Client #618] Woke up.
[INFO][16:08:04]: [Client #618] Epoch: [3/5][0/17]	Loss: 1.158520
[INFO][16:08:04]: [Client #618] Epoch: [3/5][10/17]	Loss: 1.766839
[INFO][16:08:04]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][16:08:04]: [Client #618] Woke up.
[INFO][16:08:04]: [Client #618] Epoch: [4/5][0/17]	Loss: 1.285794
[INFO][16:08:04]: [Client #618] Epoch: [4/5][10/17]	Loss: 1.683705
[INFO][16:08:04]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][16:08:04]: [Client #986] Woke up.
[INFO][16:08:05]: [Client #986] Epoch: [2/5][0/16]	Loss: 0.391098
[INFO][16:08:05]: [Client #986] Epoch: [2/5][10/16]	Loss: 0.973100
[INFO][16:08:05]: [Client #618] Woke up.
[INFO][16:08:05]: [Client #986] Going to sleep for 1.33 seconds.
[INFO][16:08:05]: [Client #618] Epoch: [5/5][0/17]	Loss: 1.035412
[INFO][16:08:05]: [Client #618] Epoch: [5/5][10/17]	Loss: 1.022997
[INFO][16:08:05]: [Client #618] Going to sleep for 0.25 seconds.
[INFO][16:08:05]: [Client #618] Woke up.
[INFO][16:08:05]: [Client #618] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_618_615874.pth.
[INFO][16:08:06]: [Client #618] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_618_615874.pth.
[INFO][16:08:06]: [Client #618] Model trained.
[INFO][16:08:06]: [Client #618] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:08:06]: [Server #615782] Received 0.26 MB of payload data from client #618 (simulated).
[INFO][16:08:06]: [Client #986] Woke up.
[INFO][16:08:06]: [Client #986] Epoch: [3/5][0/16]	Loss: 0.331474
[INFO][16:08:06]: [Client #986] Epoch: [3/5][10/16]	Loss: 0.954017
[INFO][16:08:06]: [Client #986] Going to sleep for 1.33 seconds.
[INFO][16:08:07]: [Client #986] Woke up.
[INFO][16:08:07]: [Client #986] Epoch: [4/5][0/16]	Loss: 0.784669
[INFO][16:08:08]: [Client #986] Epoch: [4/5][10/16]	Loss: 0.823552
[INFO][16:08:08]: [Client #986] Going to sleep for 1.33 seconds.
[INFO][16:08:09]: [Client #986] Woke up.
[INFO][16:08:09]: [Client #986] Epoch: [5/5][0/16]	Loss: 0.482625
[INFO][16:08:09]: [Client #986] Epoch: [5/5][10/16]	Loss: 1.049916
[INFO][16:08:09]: [Client #986] Going to sleep for 1.33 seconds.
[INFO][16:08:10]: [Client #986] Woke up.
[INFO][16:08:10]: [Client #986] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_986_615875.pth.
[INFO][16:08:11]: [Client #986] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_986_615875.pth.
[INFO][16:08:11]: [Client #986] Model trained.
[INFO][16:08:11]: [Client #986] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:08:11]: [Server #615782] Received 0.26 MB of payload data from client #986 (simulated).
[INFO][16:08:11]: [Server #615782] Selecting client #33 for training.
[INFO][16:08:11]: [Server #615782] Sending the current model to client #33 (simulated).
[INFO][16:08:11]: [Server #615782] Sending 0.26 MB of payload data to client #33 (simulated).
[INFO][16:08:11]: [Server #615782] Selecting client #724 for training.
[INFO][16:08:11]: [Server #615782] Sending the current model to client #724 (simulated).
[INFO][16:08:11]: [Server #615782] Sending 0.26 MB of payload data to client #724 (simulated).
[INFO][16:08:11]: [Client #724] Selected by the server.
[INFO][16:08:11]: [Client #33] Selected by the server.
[INFO][16:08:11]: [Client #724] Loading its data source...
[INFO][16:08:11]: [Client #33] Loading its data source...
[INFO][16:08:11]: Data source: FEMNIST
[INFO][16:08:11]: Data source: FEMNIST
[INFO][16:08:11]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:08:11]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/724.zip.
[INFO][16:08:11]: [Client #33] Dataset size: 160
[INFO][16:08:11]: [Client #33] Sampler: all_inclusive
[INFO][16:08:11]: [Client #33] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:08:11]: [93m[1m[Client #33] Started training in communication round #14.[0m
3.0%6.1%9.1%12.1%15.2%18.2%21.2%24.3%27.3%30.3%33.4%36.4%39.4%42.5%45.5%48.5%51.6%54.6%57.6%60.7%63.7%66.7%69.7%72.8%75.8%78.8%81.9%84.9%87.9%91.0%94.0%97.0%100.0%[INFO][16:08:11]: Decompressing the dataset downloaded.
[INFO][16:08:11]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/724.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:08:11]: [Client #724] Dataset size: 158
[INFO][16:08:11]: [Client #724] Sampler: all_inclusive
[INFO][16:08:11]: [Client #724] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:08:11]: [93m[1m[Client #724] Started training in communication round #14.[0m

[INFO][16:08:13]: [Client #33] Loading the dataset.
[INFO][16:08:13]: [Client #724] Loading the dataset.
[INFO][16:08:20]: [Client #33] Epoch: [1/5][0/16]	Loss: 0.620615
[INFO][16:08:20]: [Client #724] Epoch: [1/5][0/16]	Loss: 1.411499
[INFO][16:08:20]: [Client #33] Epoch: [1/5][10/16]	Loss: 2.057242
[INFO][16:08:20]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][16:08:20]: [Client #724] Epoch: [1/5][10/16]	Loss: 1.293246
[INFO][16:08:20]: [Client #724] Going to sleep for 3.29 seconds.
[INFO][16:08:23]: [Client #724] Woke up.
[INFO][16:08:23]: [Client #724] Epoch: [2/5][0/16]	Loss: 1.262739
[INFO][16:08:24]: [Client #724] Epoch: [2/5][10/16]	Loss: 0.610991
[INFO][16:08:24]: [Client #724] Going to sleep for 3.29 seconds.
[INFO][16:08:27]: [Client #724] Woke up.
[INFO][16:08:27]: [Client #724] Epoch: [3/5][0/16]	Loss: 0.959338
[INFO][16:08:27]: [Client #724] Epoch: [3/5][10/16]	Loss: 1.249979
[INFO][16:08:27]: [Client #724] Going to sleep for 3.29 seconds.
[INFO][16:08:30]: [Client #724] Woke up.
[INFO][16:08:30]: [Client #724] Epoch: [4/5][0/16]	Loss: 0.206245
[INFO][16:08:30]: [Client #724] Epoch: [4/5][10/16]	Loss: 1.152385
[INFO][16:08:30]: [Client #724] Going to sleep for 3.29 seconds.
[INFO][16:08:34]: [Client #724] Woke up.
[INFO][16:08:34]: [Client #724] Epoch: [5/5][0/16]	Loss: 1.489303
[INFO][16:08:34]: [Client #724] Epoch: [5/5][10/16]	Loss: 1.634598
[INFO][16:08:34]: [Client #724] Going to sleep for 3.29 seconds.
[INFO][16:08:37]: [Client #724] Woke up.
[INFO][16:08:37]: [Client #724] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_724_615875.pth.
[INFO][16:08:38]: [Client #724] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_724_615875.pth.
[INFO][16:08:38]: [Client #724] Model trained.
[INFO][16:08:38]: [Client #724] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:08:38]: [Server #615782] Received 0.26 MB of payload data from client #724 (simulated).
[INFO][16:08:43]: [Client #33] Woke up.
[INFO][16:08:43]: [Client #33] Epoch: [2/5][0/16]	Loss: 0.888245
[INFO][16:08:43]: [Client #33] Epoch: [2/5][10/16]	Loss: 0.651046
[INFO][16:08:43]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][16:09:06]: [Client #33] Woke up.
[INFO][16:09:06]: [Client #33] Epoch: [3/5][0/16]	Loss: 0.355865
[INFO][16:09:06]: [Client #33] Epoch: [3/5][10/16]	Loss: 1.160606
[INFO][16:09:06]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][16:09:29]: [Client #33] Woke up.
[INFO][16:09:29]: [Client #33] Epoch: [4/5][0/16]	Loss: 0.449694
[INFO][16:09:29]: [Client #33] Epoch: [4/5][10/16]	Loss: 0.321090
[INFO][16:09:29]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][16:09:52]: [Client #33] Woke up.
[INFO][16:09:52]: [Client #33] Epoch: [5/5][0/16]	Loss: 0.582996
[INFO][16:09:52]: [Client #33] Epoch: [5/5][10/16]	Loss: 0.209332
[INFO][16:09:52]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][16:10:15]: [Client #33] Woke up.
[INFO][16:10:15]: [Client #33] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_33_615874.pth.
[INFO][16:10:16]: [Client #33] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_33_615874.pth.
[INFO][16:10:16]: [Client #33] Model trained.
[INFO][16:10:16]: [Client #33] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:10:16]: [Server #615782] Received 0.26 MB of payload data from client #33 (simulated).
[INFO][16:10:16]: [Server #615782] Selecting client #565 for training.
[INFO][16:10:16]: [Server #615782] Sending the current model to client #565 (simulated).
[INFO][16:10:16]: [Server #615782] Sending 0.26 MB of payload data to client #565 (simulated).
[INFO][16:10:16]: [Client #565] Selected by the server.
[INFO][16:10:16]: [Client #565] Loading its data source...
[INFO][16:10:16]: Data source: FEMNIST
[INFO][16:10:16]: [Client #565] Dataset size: 158
[INFO][16:10:16]: [Client #565] Sampler: all_inclusive
[INFO][16:10:16]: [Client #565] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:10:16]: [93m[1m[Client #565] Started training in communication round #14.[0m
[INFO][16:10:18]: [Client #565] Loading the dataset.
[INFO][16:10:25]: [Client #565] Epoch: [1/5][0/16]	Loss: 0.880600
[INFO][16:10:25]: [Client #565] Epoch: [1/5][10/16]	Loss: 0.620122
[INFO][16:10:25]: [Client #565] Going to sleep for 2.05 seconds.
[INFO][16:10:27]: [Client #565] Woke up.
[INFO][16:10:27]: [Client #565] Epoch: [2/5][0/16]	Loss: 0.792291
[INFO][16:10:27]: [Client #565] Epoch: [2/5][10/16]	Loss: 0.858274
[INFO][16:10:27]: [Client #565] Going to sleep for 2.05 seconds.
[INFO][16:10:30]: [Client #565] Woke up.
[INFO][16:10:30]: [Client #565] Epoch: [3/5][0/16]	Loss: 0.713801
[INFO][16:10:30]: [Client #565] Epoch: [3/5][10/16]	Loss: 0.372375
[INFO][16:10:30]: [Client #565] Going to sleep for 2.05 seconds.
[INFO][16:10:32]: [Client #565] Woke up.
[INFO][16:10:32]: [Client #565] Epoch: [4/5][0/16]	Loss: 0.871951
[INFO][16:10:32]: [Client #565] Epoch: [4/5][10/16]	Loss: 1.114149
[INFO][16:10:32]: [Client #565] Going to sleep for 2.05 seconds.
[INFO][16:10:34]: [Client #565] Woke up.
[INFO][16:10:34]: [Client #565] Epoch: [5/5][0/16]	Loss: 1.282469
[INFO][16:10:34]: [Client #565] Epoch: [5/5][10/16]	Loss: 1.380477
[INFO][16:10:34]: [Client #565] Going to sleep for 2.05 seconds.
[INFO][16:10:36]: [Client #565] Woke up.
[INFO][16:10:36]: [Client #565] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_565_615874.pth.
[INFO][16:10:37]: [Client #565] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_565_615874.pth.
[INFO][16:10:37]: [Client #565] Model trained.
[INFO][16:10:37]: [Client #565] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:10:37]: [Server #615782] Received 0.26 MB of payload data from client #565 (simulated).
[INFO][16:10:37]: [Server #615782] Adding client #931 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #949 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #618 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #810 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #605 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #977 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #777 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #458 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #935 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #798 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #986 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #127 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #173 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #860 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #258 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #565 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #880 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #40 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #724 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #44 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #974 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #242 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #311 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #33 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][16:10:37]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.06060627 0.         0.         0.
 0.         0.         0.         0.07713739 0.         0.
 0.         0.13776791 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.26853566 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07877186 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21515083 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09945196
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17253667 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21330533 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0843245  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16418995 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11395929
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08508252 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.24388026 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14311324
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07785114
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14465009 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09427398
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12630628 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10388584 0.         0.         0.         0.12962302 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19751925 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06989871 0.         0.         0.11085406 0.
 0.         0.         0.         0.         0.         0.
 0.         0.09794551 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.06060627 0.         0.         0.
 0.         0.         0.         0.07713739 0.         0.
 0.         0.13776791 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.26853566 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07877186 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21515083 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09945196
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17253667 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21330533 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0843245  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16418995 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11395929
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08508252 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.24388026 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14311324
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07785114
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14465009 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09427398
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12630628 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10388584 0.         0.         0.         0.12962302 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19751925 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06989871 0.         0.         0.11085406 0.
 0.         0.         0.         0.         0.         0.
 0.         0.09794551 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.02227617
 0.001      0.03920642 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.03195266 0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.03767545 0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.001      0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.03647485 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03250518 0.001
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.001      0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.001      0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04145602 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03463896 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.001      0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.04063039
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.001      0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.01899937
 0.04038414 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.001      0.01937935 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.03826169
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.001      0.001      0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03333333 0.03731696 0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.03613604
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0383693  0.03241574 0.03778932
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.03792169 0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03614762 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03495513
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.0401379  0.001      0.001      0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.001      0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.001      0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03188474 0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03767545 0.04076739
 0.03613604 0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03650413 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02611244
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.03126294 0.01329956 0.001     ][INFO][16:11:21]: [Server #615782] Global model accuracy: 56.72%

[INFO][16:11:21]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_14.pth.
[INFO][16:11:21]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_14.pth.
[INFO][16:11:21]: [93m[1m
[Server #615782] Starting round 15/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  8e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  5e-05  1e-10  1e-10
 7:  7.5999e+00  7.5998e+00  5e-05  2e-09  2e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  2e-10
 9:  7.5999e+00  7.5999e+00  2e-05  4e-09  4e-10
10:  7.5999e+00  7.5999e+00  3e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75139199e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75109683e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.74880458e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.74069583e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75096467e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.74600963e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75033481e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.73708729e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.74467130e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75088836e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.74815311e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.74990326e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75086902e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.70922084e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.74906726e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75102321e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.74864717e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 9.22636643e-01 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.74961729e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75077266e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75011197e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.74645215e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75122343e-05 7.75195936e-05 7.75195936e-05 7.74968906e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75056882e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05 7.75195936e-05
 7.75195936e-05 7.75195936e-05 7.75195936e-05][INFO][16:11:23]: [Server #615782] Selected clients: [870 365 904 535 863 352 998 434 294  42 990 465 734 640 722  51 921 928
 552 965 281 602 397 628 300]
[INFO][16:11:23]: [Server #615782] Selecting client #870 for training.
[INFO][16:11:23]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][16:11:23]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][16:11:23]: [Server #615782] Selecting client #365 for training.
[INFO][16:11:23]: [Server #615782] Sending the current model to client #365 (simulated).
[INFO][16:11:23]: [Server #615782] Sending 0.26 MB of payload data to client #365 (simulated).
[INFO][16:11:23]: [Client #870] Selected by the server.
[INFO][16:11:23]: [Client #870] Loading its data source...
[INFO][16:11:23]: Data source: FEMNIST
[INFO][16:11:23]: [Client #365] Selected by the server.
[INFO][16:11:23]: [Client #365] Loading its data source...
[INFO][16:11:23]: Data source: FEMNIST
[INFO][16:11:23]: [Client #365] Dataset size: 164
[INFO][16:11:23]: [Client #365] Sampler: all_inclusive
[INFO][16:11:23]: [Client #365] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:11:23]: [Client #870] Dataset size: 148
[INFO][16:11:23]: [Client #870] Sampler: all_inclusive
[INFO][16:11:23]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:11:23]: [93m[1m[Client #365] Started training in communication round #15.[0m
[INFO][16:11:23]: [93m[1m[Client #870] Started training in communication round #15.[0m
[INFO][16:11:25]: [Client #870] Loading the dataset.
[INFO][16:11:25]: [Client #365] Loading the dataset.
[INFO][16:11:33]: [Client #365] Epoch: [1/5][0/17]	Loss: 0.494642
[INFO][16:11:33]: [Client #365] Epoch: [1/5][10/17]	Loss: 0.097069
[INFO][16:11:33]: [Client #870] Epoch: [1/5][0/15]	Loss: 0.706811
[INFO][16:11:33]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][16:11:33]: [Client #870] Epoch: [1/5][10/15]	Loss: 0.553255
[INFO][16:11:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:12:11]: [Client #365] Woke up.
[INFO][16:12:11]: [Client #365] Epoch: [2/5][0/17]	Loss: 0.548694
[INFO][16:12:11]: [Client #365] Epoch: [2/5][10/17]	Loss: 0.101758
[INFO][16:12:12]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][16:12:33]: [Client #870] Woke up.
[INFO][16:12:33]: [Client #870] Epoch: [2/5][0/15]	Loss: 0.374231
[INFO][16:12:33]: [Client #870] Epoch: [2/5][10/15]	Loss: 0.796977
[INFO][16:12:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:12:50]: [Client #365] Woke up.
[INFO][16:12:50]: [Client #365] Epoch: [3/5][0/17]	Loss: 0.934504
[INFO][16:12:50]: [Client #365] Epoch: [3/5][10/17]	Loss: 0.611712
[INFO][16:12:50]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][16:13:29]: [Client #365] Woke up.
[INFO][16:13:29]: [Client #365] Epoch: [4/5][0/17]	Loss: 0.360514
[INFO][16:13:29]: [Client #365] Epoch: [4/5][10/17]	Loss: 0.950746
[INFO][16:13:29]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][16:13:33]: [Client #870] Woke up.
[INFO][16:13:33]: [Client #870] Epoch: [3/5][0/15]	Loss: 0.774674
[INFO][16:13:33]: [Client #870] Epoch: [3/5][10/15]	Loss: 0.811667
[INFO][16:13:33]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:14:08]: [Client #365] Woke up.
[INFO][16:14:08]: [Client #365] Epoch: [5/5][0/17]	Loss: 0.422924
[INFO][16:14:08]: [Client #365] Epoch: [5/5][10/17]	Loss: 1.011341
[INFO][16:14:08]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][16:14:33]: [Client #870] Woke up.
[INFO][16:14:34]: [Client #870] Epoch: [4/5][0/15]	Loss: 0.679398
[INFO][16:14:34]: [Client #870] Epoch: [4/5][10/15]	Loss: 0.481303
[INFO][16:14:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:14:47]: [Client #365] Woke up.
[INFO][16:14:47]: [Client #365] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_365_615875.pth.
[INFO][16:14:47]: [Client #365] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_365_615875.pth.
[INFO][16:14:47]: [Client #365] Model trained.
[INFO][16:14:47]: [Client #365] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:14:47]: [Server #615782] Received 0.26 MB of payload data from client #365 (simulated).
[INFO][16:15:34]: [Client #870] Woke up.
[INFO][16:15:34]: [Client #870] Epoch: [5/5][0/15]	Loss: 1.097241
[INFO][16:15:34]: [Client #870] Epoch: [5/5][10/15]	Loss: 0.733082
[INFO][16:15:34]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:16:34]: [Client #870] Woke up.
[INFO][16:16:34]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][16:16:35]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][16:16:35]: [Client #870] Model trained.
[INFO][16:16:35]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:16:35]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][16:16:35]: [Server #615782] Selecting client #904 for training.
[INFO][16:16:35]: [Server #615782] Sending the current model to client #904 (simulated).
[INFO][16:16:35]: [Server #615782] Sending 0.26 MB of payload data to client #904 (simulated).
[INFO][16:16:35]: [Server #615782] Selecting client #535 for training.
[INFO][16:16:35]: [Server #615782] Sending the current model to client #535 (simulated).
[INFO][16:16:35]: [Server #615782] Sending 0.26 MB of payload data to client #535 (simulated).
[INFO][16:16:35]: [Client #904] Selected by the server.
[INFO][16:16:35]: [Client #904] Loading its data source...
[INFO][16:16:35]: Data source: FEMNIST
[INFO][16:16:35]: [Client #535] Selected by the server.
[INFO][16:16:35]: [Client #535] Loading its data source...
[INFO][16:16:35]: Data source: FEMNIST
[INFO][16:16:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:16:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/535.zip.
[INFO][16:16:35]: [Client #904] Dataset size: 158
[INFO][16:16:35]: [Client #904] Sampler: all_inclusive
[INFO][16:16:35]: [Client #904] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:16:35]: [93m[1m[Client #904] Started training in communication round #15.[0m
2.4%4.7%7.1%9.5%11.8%14.2%16.6%18.9%21.3%23.7%26.1%28.4%30.8%33.2%35.5%37.9%40.3%42.6%45.0%47.4%49.7%52.1%54.5%56.8%59.2%61.6%63.9%66.3%68.7%71.1%73.4%75.8%78.2%80.5%82.9%85.3%87.6%90.0%92.4%94.7%97.1%99.5%100.0%[INFO][16:16:35]: Decompressing the dataset downloaded.
[INFO][16:16:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/535.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:16:35]: [Client #535] Dataset size: 157
[INFO][16:16:35]: [Client #535] Sampler: all_inclusive
[INFO][16:16:35]: [Client #535] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:16:35]: [93m[1m[Client #535] Started training in communication round #15.[0m

[INFO][16:16:37]: [Client #904] Loading the dataset.
[INFO][16:16:38]: [Client #535] Loading the dataset.
[INFO][16:16:44]: [Client #904] Epoch: [1/5][0/16]	Loss: 1.538394
[INFO][16:16:44]: [Client #904] Epoch: [1/5][10/16]	Loss: 0.659606
[INFO][16:16:44]: [Client #904] Going to sleep for 19.31 seconds.
[INFO][16:16:45]: [Client #535] Epoch: [1/5][0/16]	Loss: 0.833153
[INFO][16:16:45]: [Client #535] Epoch: [1/5][10/16]	Loss: 0.903758
[INFO][16:16:45]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:16:49]: [Client #535] Woke up.
[INFO][16:16:49]: [Client #535] Epoch: [2/5][0/16]	Loss: 0.876079
[INFO][16:16:49]: [Client #535] Epoch: [2/5][10/16]	Loss: 0.817662
[INFO][16:16:50]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:16:54]: [Client #535] Woke up.
[INFO][16:16:54]: [Client #535] Epoch: [3/5][0/16]	Loss: 1.115890
[INFO][16:16:54]: [Client #535] Epoch: [3/5][10/16]	Loss: 1.521775
[INFO][16:16:54]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:16:59]: [Client #535] Woke up.
[INFO][16:16:59]: [Client #535] Epoch: [4/5][0/16]	Loss: 0.385107
[INFO][16:16:59]: [Client #535] Epoch: [4/5][10/16]	Loss: 0.538144
[INFO][16:16:59]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:17:04]: [Client #904] Woke up.
[INFO][16:17:04]: [Client #904] Epoch: [2/5][0/16]	Loss: 1.006640
[INFO][16:17:04]: [Client #904] Epoch: [2/5][10/16]	Loss: 0.787405
[INFO][16:17:04]: [Client #535] Woke up.
[INFO][16:17:04]: [Client #904] Going to sleep for 19.31 seconds.
[INFO][16:17:04]: [Client #535] Epoch: [5/5][0/16]	Loss: 0.811165
[INFO][16:17:04]: [Client #535] Epoch: [5/5][10/16]	Loss: 0.712261
[INFO][16:17:04]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:17:09]: [Client #535] Woke up.
[INFO][16:17:09]: [Client #535] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_535_615875.pth.
[INFO][16:17:09]: [Client #535] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_535_615875.pth.
[INFO][16:17:09]: [Client #535] Model trained.
[INFO][16:17:09]: [Client #535] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:17:09]: [Server #615782] Received 0.26 MB of payload data from client #535 (simulated).
[INFO][16:17:23]: [Client #904] Woke up.
[INFO][16:17:23]: [Client #904] Epoch: [3/5][0/16]	Loss: 1.074098
[INFO][16:17:23]: [Client #904] Epoch: [3/5][10/16]	Loss: 0.883890
[INFO][16:17:23]: [Client #904] Going to sleep for 19.31 seconds.
[INFO][16:17:43]: [Client #904] Woke up.
[INFO][16:17:43]: [Client #904] Epoch: [4/5][0/16]	Loss: 0.472324
[INFO][16:17:43]: [Client #904] Epoch: [4/5][10/16]	Loss: 1.504988
[INFO][16:17:43]: [Client #904] Going to sleep for 19.31 seconds.
[INFO][16:18:02]: [Client #904] Woke up.
[INFO][16:18:03]: [Client #904] Epoch: [5/5][0/16]	Loss: 0.624212
[INFO][16:18:03]: [Client #904] Epoch: [5/5][10/16]	Loss: 0.962989
[INFO][16:18:03]: [Client #904] Going to sleep for 19.31 seconds.
[INFO][16:18:22]: [Client #904] Woke up.
[INFO][16:18:22]: [Client #904] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_904_615874.pth.
[INFO][16:18:23]: [Client #904] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_904_615874.pth.
[INFO][16:18:23]: [Client #904] Model trained.
[INFO][16:18:23]: [Client #904] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:18:23]: [Server #615782] Received 0.26 MB of payload data from client #904 (simulated).
[INFO][16:18:23]: [Server #615782] Selecting client #863 for training.
[INFO][16:18:23]: [Server #615782] Sending the current model to client #863 (simulated).
[INFO][16:18:23]: [Server #615782] Sending 0.26 MB of payload data to client #863 (simulated).
[INFO][16:18:23]: [Server #615782] Selecting client #352 for training.
[INFO][16:18:23]: [Server #615782] Sending the current model to client #352 (simulated).
[INFO][16:18:23]: [Server #615782] Sending 0.26 MB of payload data to client #352 (simulated).
[INFO][16:18:23]: [Client #863] Selected by the server.
[INFO][16:18:23]: [Client #863] Loading its data source...
[INFO][16:18:23]: Data source: FEMNIST
[INFO][16:18:23]: [Client #352] Selected by the server.
[INFO][16:18:23]: [Client #352] Loading its data source...
[INFO][16:18:23]: Data source: FEMNIST
[INFO][16:18:23]: [Client #863] Dataset size: 143
[INFO][16:18:23]: [Client #863] Sampler: all_inclusive
[INFO][16:18:23]: [Client #863] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:18:23]: [93m[1m[Client #863] Started training in communication round #15.[0m
[INFO][16:18:23]: [Client #352] Dataset size: 163
[INFO][16:18:23]: [Client #352] Sampler: all_inclusive
[INFO][16:18:23]: [Client #352] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:18:23]: [93m[1m[Client #352] Started training in communication round #15.[0m
[INFO][16:18:25]: [Client #352] Loading the dataset.
[INFO][16:18:25]: [Client #863] Loading the dataset.
[INFO][16:18:32]: [Client #352] Epoch: [1/5][0/17]	Loss: 2.755065
[INFO][16:18:32]: [Client #352] Epoch: [1/5][10/17]	Loss: 1.007976
[INFO][16:18:32]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][16:18:33]: [Client #863] Epoch: [1/5][0/15]	Loss: 0.228426
[INFO][16:18:33]: [Client #863] Epoch: [1/5][10/15]	Loss: 0.541080
[INFO][16:18:33]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][16:18:34]: [Client #863] Woke up.
[INFO][16:18:34]: [Client #863] Epoch: [2/5][0/15]	Loss: 0.406281
[INFO][16:18:34]: [Client #863] Epoch: [2/5][10/15]	Loss: 0.861168
[INFO][16:18:34]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][16:18:34]: [Client #863] Woke up.
[INFO][16:18:34]: [Client #863] Epoch: [3/5][0/15]	Loss: 0.647184
[INFO][16:18:35]: [Client #863] Epoch: [3/5][10/15]	Loss: 0.771469
[INFO][16:18:35]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][16:18:35]: [Client #352] Woke up.
[INFO][16:18:35]: [Client #352] Epoch: [2/5][0/17]	Loss: 0.839877
[INFO][16:18:35]: [Client #352] Epoch: [2/5][10/17]	Loss: 0.874604
[INFO][16:18:35]: [Client #863] Woke up.
[INFO][16:18:35]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][16:18:35]: [Client #863] Epoch: [4/5][0/15]	Loss: 0.741776
[INFO][16:18:35]: [Client #863] Epoch: [4/5][10/15]	Loss: 1.276145
[INFO][16:18:35]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][16:18:36]: [Client #863] Woke up.
[INFO][16:18:36]: [Client #863] Epoch: [5/5][0/15]	Loss: 0.386137
[INFO][16:18:36]: [Client #863] Epoch: [5/5][10/15]	Loss: 0.823141
[INFO][16:18:36]: [Client #863] Going to sleep for 0.75 seconds.
[INFO][16:18:37]: [Client #863] Woke up.
[INFO][16:18:37]: [Client #863] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_863_615874.pth.
[INFO][16:18:38]: [Client #863] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_863_615874.pth.
[INFO][16:18:38]: [Client #863] Model trained.
[INFO][16:18:38]: [Client #863] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:18:38]: [Server #615782] Received 0.26 MB of payload data from client #863 (simulated).
[INFO][16:18:38]: [Client #352] Woke up.
[INFO][16:18:38]: [Client #352] Epoch: [3/5][0/17]	Loss: 1.029205
[INFO][16:18:38]: [Client #352] Epoch: [3/5][10/17]	Loss: 1.520768
[INFO][16:18:38]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][16:18:41]: [Client #352] Woke up.
[INFO][16:18:41]: [Client #352] Epoch: [4/5][0/17]	Loss: 0.822405
[INFO][16:18:41]: [Client #352] Epoch: [4/5][10/17]	Loss: 0.797530
[INFO][16:18:41]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][16:18:44]: [Client #352] Woke up.
[INFO][16:18:44]: [Client #352] Epoch: [5/5][0/17]	Loss: 0.333388
[INFO][16:18:44]: [Client #352] Epoch: [5/5][10/17]	Loss: 0.703949
[INFO][16:18:44]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][16:18:47]: [Client #352] Woke up.
[INFO][16:18:47]: [Client #352] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_615875.pth.
[INFO][16:18:48]: [Client #352] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_615875.pth.
[INFO][16:18:48]: [Client #352] Model trained.
[INFO][16:18:48]: [Client #352] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:18:48]: [Server #615782] Received 0.26 MB of payload data from client #352 (simulated).
[INFO][16:18:48]: [Server #615782] Selecting client #998 for training.
[INFO][16:18:48]: [Server #615782] Sending the current model to client #998 (simulated).
[INFO][16:18:48]: [Server #615782] Sending 0.26 MB of payload data to client #998 (simulated).
[INFO][16:18:48]: [Server #615782] Selecting client #434 for training.
[INFO][16:18:48]: [Server #615782] Sending the current model to client #434 (simulated).
[INFO][16:18:48]: [Server #615782] Sending 0.26 MB of payload data to client #434 (simulated).
[INFO][16:18:48]: [Client #434] Selected by the server.
[INFO][16:18:48]: [Client #434] Loading its data source...
[INFO][16:18:48]: [Client #998] Selected by the server.
[INFO][16:18:48]: Data source: FEMNIST
[INFO][16:18:48]: [Client #998] Loading its data source...
[INFO][16:18:48]: Data source: FEMNIST
[INFO][16:18:48]: [Client #434] Dataset size: 130
[INFO][16:18:48]: [Client #434] Sampler: all_inclusive
[INFO][16:18:48]: [Client #998] Dataset size: 151
[INFO][16:18:48]: [Client #998] Sampler: all_inclusive
[INFO][16:18:48]: [Client #434] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:18:48]: [Client #998] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:18:48]: [93m[1m[Client #434] Started training in communication round #15.[0m
[INFO][16:18:48]: [93m[1m[Client #998] Started training in communication round #15.[0m
[INFO][16:18:50]: [Client #434] Loading the dataset.
[INFO][16:18:50]: [Client #998] Loading the dataset.
[INFO][16:18:57]: [Client #998] Epoch: [1/5][0/16]	Loss: 1.157695
[INFO][16:18:58]: [Client #434] Epoch: [1/5][0/13]	Loss: 0.681442
[INFO][16:18:58]: [Client #998] Epoch: [1/5][10/16]	Loss: 0.719147
[INFO][16:18:58]: [Client #434] Epoch: [1/5][10/13]	Loss: 0.614871
[INFO][16:18:58]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][16:18:58]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][16:18:59]: [Client #434] Woke up.
[INFO][16:18:59]: [Client #434] Epoch: [2/5][0/13]	Loss: 0.506570
[INFO][16:18:59]: [Client #434] Epoch: [2/5][10/13]	Loss: 0.560082
[INFO][16:18:59]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][16:19:00]: [Client #434] Woke up.
[INFO][16:19:00]: [Client #434] Epoch: [3/5][0/13]	Loss: 0.618231
[INFO][16:19:00]: [Client #434] Epoch: [3/5][10/13]	Loss: 0.539979
[INFO][16:19:00]: [Client #998] Woke up.
[INFO][16:19:00]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][16:19:00]: [Client #998] Epoch: [2/5][0/16]	Loss: 0.704253
[INFO][16:19:00]: [Client #998] Epoch: [2/5][10/16]	Loss: 0.313541
[INFO][16:19:00]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][16:19:01]: [Client #434] Woke up.
[INFO][16:19:01]: [Client #434] Epoch: [4/5][0/13]	Loss: 0.490779
[INFO][16:19:01]: [Client #434] Epoch: [4/5][10/13]	Loss: 0.556154
[INFO][16:19:01]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][16:19:02]: [Client #434] Woke up.
[INFO][16:19:02]: [Client #434] Epoch: [5/5][0/13]	Loss: 0.434949
[INFO][16:19:02]: [Client #434] Epoch: [5/5][10/13]	Loss: 0.575652
[INFO][16:19:02]: [Client #434] Going to sleep for 0.90 seconds.
[INFO][16:19:02]: [Client #998] Woke up.
[INFO][16:19:02]: [Client #998] Epoch: [3/5][0/16]	Loss: 0.798645
[INFO][16:19:02]: [Client #998] Epoch: [3/5][10/16]	Loss: 1.017744
[INFO][16:19:02]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][16:19:03]: [Client #434] Woke up.
[INFO][16:19:03]: [Client #434] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_434_615875.pth.
[INFO][16:19:03]: [Client #434] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_434_615875.pth.
[INFO][16:19:03]: [Client #434] Model trained.
[INFO][16:19:03]: [Client #434] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:19:03]: [Server #615782] Received 0.26 MB of payload data from client #434 (simulated).
[INFO][16:19:04]: [Client #998] Woke up.
[INFO][16:19:04]: [Client #998] Epoch: [4/5][0/16]	Loss: 0.082171
[INFO][16:19:04]: [Client #998] Epoch: [4/5][10/16]	Loss: 0.827936
[INFO][16:19:04]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][16:19:06]: [Client #998] Woke up.
[INFO][16:19:06]: [Client #998] Epoch: [5/5][0/16]	Loss: 1.068712
[INFO][16:19:06]: [Client #998] Epoch: [5/5][10/16]	Loss: 0.306534
[INFO][16:19:06]: [Client #998] Going to sleep for 2.02 seconds.
[INFO][16:19:08]: [Client #998] Woke up.
[INFO][16:19:08]: [Client #998] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_998_615874.pth.
[INFO][16:19:09]: [Client #998] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_998_615874.pth.
[INFO][16:19:09]: [Client #998] Model trained.
[INFO][16:19:09]: [Client #998] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:19:09]: [Server #615782] Received 0.26 MB of payload data from client #998 (simulated).
[INFO][16:19:09]: [Server #615782] Selecting client #294 for training.
[INFO][16:19:09]: [Server #615782] Sending the current model to client #294 (simulated).
[INFO][16:19:09]: [Server #615782] Sending 0.26 MB of payload data to client #294 (simulated).
[INFO][16:19:09]: [Server #615782] Selecting client #42 for training.
[INFO][16:19:09]: [Server #615782] Sending the current model to client #42 (simulated).
[INFO][16:19:09]: [Server #615782] Sending 0.26 MB of payload data to client #42 (simulated).
[INFO][16:19:09]: [Client #294] Selected by the server.
[INFO][16:19:09]: [Client #294] Loading its data source...
[INFO][16:19:09]: Data source: FEMNIST
[INFO][16:19:09]: [Client #42] Selected by the server.
[INFO][16:19:09]: [Client #42] Loading its data source...
[INFO][16:19:09]: Data source: FEMNIST
[INFO][16:19:09]: [Client #42] Dataset size: 156
[INFO][16:19:09]: [Client #42] Sampler: all_inclusive
[INFO][16:19:09]: [Client #42] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:19:09]: [93m[1m[Client #42] Started training in communication round #15.[0m
[INFO][16:19:09]: [Client #294] Dataset size: 148
[INFO][16:19:09]: [Client #294] Sampler: all_inclusive
[INFO][16:19:09]: [Client #294] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:19:09]: [93m[1m[Client #294] Started training in communication round #15.[0m
[INFO][16:19:11]: [Client #42] Loading the dataset.
[INFO][16:19:11]: [Client #294] Loading the dataset.
[INFO][16:19:19]: [Client #42] Epoch: [1/5][0/16]	Loss: 1.630199
[INFO][16:19:19]: [Client #294] Epoch: [1/5][0/15]	Loss: 0.608400
[INFO][16:19:19]: [Client #42] Epoch: [1/5][10/16]	Loss: 1.864572
[INFO][16:19:19]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][16:19:19]: [Client #294] Epoch: [1/5][10/15]	Loss: 1.371133
[INFO][16:19:19]: [Client #294] Going to sleep for 0.87 seconds.
[INFO][16:19:20]: [Client #294] Woke up.
[INFO][16:19:20]: [Client #294] Epoch: [2/5][0/15]	Loss: 1.662439
[INFO][16:19:20]: [Client #294] Epoch: [2/5][10/15]	Loss: 1.762448
[INFO][16:19:20]: [Client #294] Going to sleep for 0.87 seconds.
[INFO][16:19:21]: [Client #294] Woke up.
[INFO][16:19:21]: [Client #294] Epoch: [3/5][0/15]	Loss: 0.979253
[INFO][16:19:21]: [Client #294] Epoch: [3/5][10/15]	Loss: 1.071308
[INFO][16:19:21]: [Client #294] Going to sleep for 0.87 seconds.
[INFO][16:19:22]: [Client #294] Woke up.
[INFO][16:19:22]: [Client #294] Epoch: [4/5][0/15]	Loss: 1.629833
[INFO][16:19:22]: [Client #42] Woke up.
[INFO][16:19:22]: [Client #42] Epoch: [2/5][0/16]	Loss: 0.116973
[INFO][16:19:22]: [Client #294] Epoch: [4/5][10/15]	Loss: 1.096204
[INFO][16:19:22]: [Client #294] Going to sleep for 0.87 seconds.
[INFO][16:19:22]: [Client #42] Epoch: [2/5][10/16]	Loss: 0.925961
[INFO][16:19:22]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][16:19:23]: [Client #294] Woke up.
[INFO][16:19:23]: [Client #294] Epoch: [5/5][0/15]	Loss: 1.857361
[INFO][16:19:23]: [Client #294] Epoch: [5/5][10/15]	Loss: 1.453839
[INFO][16:19:23]: [Client #294] Going to sleep for 0.87 seconds.
[INFO][16:19:24]: [Client #294] Woke up.
[INFO][16:19:24]: [Client #294] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_294_615874.pth.
[INFO][16:19:24]: [Client #294] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_294_615874.pth.
[INFO][16:19:24]: [Client #294] Model trained.
[INFO][16:19:24]: [Client #294] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:19:24]: [Server #615782] Received 0.26 MB of payload data from client #294 (simulated).
[INFO][16:19:25]: [Client #42] Woke up.
[INFO][16:19:25]: [Client #42] Epoch: [3/5][0/16]	Loss: 0.460036
[INFO][16:19:25]: [Client #42] Epoch: [3/5][10/16]	Loss: 0.992986
[INFO][16:19:25]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][16:19:28]: [Client #42] Woke up.
[INFO][16:19:28]: [Client #42] Epoch: [4/5][0/16]	Loss: 0.613923
[INFO][16:19:28]: [Client #42] Epoch: [4/5][10/16]	Loss: 0.495049
[INFO][16:19:28]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][16:19:31]: [Client #42] Woke up.
[INFO][16:19:31]: [Client #42] Epoch: [5/5][0/16]	Loss: 1.471337
[INFO][16:19:31]: [Client #42] Epoch: [5/5][10/16]	Loss: 1.375117
[INFO][16:19:31]: [Client #42] Going to sleep for 2.97 seconds.
[INFO][16:19:34]: [Client #42] Woke up.
[INFO][16:19:34]: [Client #42] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_42_615875.pth.
[INFO][16:19:35]: [Client #42] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_42_615875.pth.
[INFO][16:19:35]: [Client #42] Model trained.
[INFO][16:19:35]: [Client #42] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:19:35]: [Server #615782] Received 0.26 MB of payload data from client #42 (simulated).
[INFO][16:19:35]: [Server #615782] Selecting client #990 for training.
[INFO][16:19:35]: [Server #615782] Sending the current model to client #990 (simulated).
[INFO][16:19:35]: [Server #615782] Sending 0.26 MB of payload data to client #990 (simulated).
[INFO][16:19:35]: [Server #615782] Selecting client #465 for training.
[INFO][16:19:35]: [Server #615782] Sending the current model to client #465 (simulated).
[INFO][16:19:35]: [Server #615782] Sending 0.26 MB of payload data to client #465 (simulated).
[INFO][16:19:35]: [Client #465] Selected by the server.
[INFO][16:19:35]: [Client #990] Selected by the server.
[INFO][16:19:35]: [Client #465] Loading its data source...
[INFO][16:19:35]: [Client #990] Loading its data source...
[INFO][16:19:35]: Data source: FEMNIST
[INFO][16:19:35]: Data source: FEMNIST
[INFO][16:19:35]: [Client #990] Dataset size: 98
[INFO][16:19:35]: [Client #990] Sampler: all_inclusive
[INFO][16:19:35]: [Client #990] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:19:35]: [93m[1m[Client #990] Started training in communication round #15.[0m
[INFO][16:19:35]: [Client #465] Dataset size: 103
[INFO][16:19:35]: [Client #465] Sampler: all_inclusive
[INFO][16:19:35]: [Client #465] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:19:35]: [93m[1m[Client #465] Started training in communication round #15.[0m
[INFO][16:19:37]: [Client #465] Loading the dataset.
[INFO][16:19:37]: [Client #990] Loading the dataset.
[INFO][16:19:44]: [Client #465] Epoch: [1/5][0/11]	Loss: 2.183255
[INFO][16:19:44]: [Client #990] Epoch: [1/5][0/10]	Loss: 0.594232
[INFO][16:19:44]: [Client #465] Epoch: [1/5][10/11]	Loss: 0.293575
[INFO][16:19:44]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:19:44]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][16:19:49]: [Client #465] Woke up.
[INFO][16:19:49]: [Client #465] Epoch: [2/5][0/11]	Loss: 0.224379
[INFO][16:19:49]: [Client #465] Epoch: [2/5][10/11]	Loss: 1.349206
[INFO][16:19:49]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:19:53]: [Client #465] Woke up.
[INFO][16:19:53]: [Client #465] Epoch: [3/5][0/11]	Loss: 1.571864
[INFO][16:19:54]: [Client #465] Epoch: [3/5][10/11]	Loss: 1.444436
[INFO][16:19:54]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:19:58]: [Client #465] Woke up.
[INFO][16:19:58]: [Client #465] Epoch: [4/5][0/11]	Loss: 0.996208
[INFO][16:19:58]: [Client #465] Epoch: [4/5][10/11]	Loss: 0.023759
[INFO][16:19:58]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:20:03]: [Client #465] Woke up.
[INFO][16:20:03]: [Client #465] Epoch: [5/5][0/11]	Loss: 0.837289
[INFO][16:20:03]: [Client #465] Epoch: [5/5][10/11]	Loss: 0.022733
[INFO][16:20:03]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:20:04]: [Client #990] Woke up.
[INFO][16:20:04]: [Client #990] Epoch: [2/5][0/10]	Loss: 0.776069
[INFO][16:20:04]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][16:20:07]: [Client #465] Woke up.
[INFO][16:20:07]: [Client #465] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_615875.pth.
[INFO][16:20:08]: [Client #465] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_615875.pth.
[INFO][16:20:08]: [Client #465] Model trained.
[INFO][16:20:08]: [Client #465] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:20:08]: [Server #615782] Received 0.26 MB of payload data from client #465 (simulated).
[INFO][16:20:23]: [Client #990] Woke up.
[INFO][16:20:23]: [Client #990] Epoch: [3/5][0/10]	Loss: 1.244486
[INFO][16:20:24]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][16:20:43]: [Client #990] Woke up.
[INFO][16:20:43]: [Client #990] Epoch: [4/5][0/10]	Loss: 1.255362
[INFO][16:20:43]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][16:21:03]: [Client #990] Woke up.
[INFO][16:21:03]: [Client #990] Epoch: [5/5][0/10]	Loss: 0.663723
[INFO][16:21:03]: [Client #990] Going to sleep for 19.46 seconds.
[INFO][16:21:22]: [Client #990] Woke up.
[INFO][16:21:22]: [Client #990] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615874.pth.
[INFO][16:21:23]: [Client #990] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_990_615874.pth.
[INFO][16:21:23]: [Client #990] Model trained.
[INFO][16:21:23]: [Client #990] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:21:23]: [Server #615782] Received 0.26 MB of payload data from client #990 (simulated).
[INFO][16:21:23]: [Server #615782] Selecting client #734 for training.
[INFO][16:21:23]: [Server #615782] Sending the current model to client #734 (simulated).
[INFO][16:21:23]: [Server #615782] Sending 0.26 MB of payload data to client #734 (simulated).
[INFO][16:21:23]: [Server #615782] Selecting client #640 for training.
[INFO][16:21:23]: [Server #615782] Sending the current model to client #640 (simulated).
[INFO][16:21:23]: [Server #615782] Sending 0.26 MB of payload data to client #640 (simulated).
[INFO][16:21:23]: [Client #734] Selected by the server.
[INFO][16:21:23]: [Client #734] Loading its data source...
[INFO][16:21:23]: Data source: FEMNIST
[INFO][16:21:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:21:23]: [Client #640] Selected by the server.
[INFO][16:21:23]: [Client #640] Loading its data source...
[INFO][16:21:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/734.zip.
[INFO][16:21:23]: Data source: FEMNIST
[INFO][16:21:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:21:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/640.zip.
2.7%5.5%8.2%10.9%13.7%16.4%19.1%21.9%24.6%27.3%30.1%32.8%35.5%38.3%41.0%43.7%3.6%7.3%10.9%14.5%18.2%21.8%25.4%29.1%32.7%36.3%40.0%43.6%47.2%50.8%54.5%58.1%61.7%46.5%49.2%51.9%54.7%57.4%60.1%62.8%65.6%68.3%65.4%69.0%72.6%76.3%79.9%83.5%87.2%90.8%94.4%98.1%100.0%[INFO][16:21:23]: Decompressing the dataset downloaded.
[INFO][16:21:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/640.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
71.0%73.8%76.5%79.2%82.0%84.7%87.4%90.2%92.9%95.6%98.4%100.0%[INFO][16:21:23]: Decompressing the dataset downloaded.
[INFO][16:21:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/734.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:21:23]: [Client #640] Dataset size: 143
[INFO][16:21:23]: [Client #640] Sampler: all_inclusive
[INFO][16:21:23]: [Client #640] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:21:23]: [93m[1m[Client #640] Started training in communication round #15.[0m

[INFO][16:21:23]: [Client #734] Dataset size: 160
[INFO][16:21:23]: [Client #734] Sampler: all_inclusive
[INFO][16:21:23]: [Client #734] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:21:23]: [93m[1m[Client #734] Started training in communication round #15.[0m

[INFO][16:21:25]: [Client #734] Loading the dataset.
[INFO][16:21:25]: [Client #640] Loading the dataset.
[INFO][16:21:32]: [Client #640] Epoch: [1/5][0/15]	Loss: 0.813053
[INFO][16:21:33]: [Client #734] Epoch: [1/5][0/16]	Loss: 1.062733
[INFO][16:21:33]: [Client #640] Epoch: [1/5][10/15]	Loss: 1.561424
[INFO][16:21:33]: [Client #640] Going to sleep for 0.43 seconds.
[INFO][16:21:33]: [Client #734] Epoch: [1/5][10/16]	Loss: 0.993609
[INFO][16:21:33]: [Client #734] Going to sleep for 0.34 seconds.
[INFO][16:21:33]: [Client #734] Woke up.
[INFO][16:21:33]: [Client #734] Epoch: [2/5][0/16]	Loss: 0.517657
[INFO][16:21:33]: [Client #640] Woke up.
[INFO][16:21:33]: [Client #640] Epoch: [2/5][0/15]	Loss: 0.546224
[INFO][16:21:33]: [Client #734] Epoch: [2/5][10/16]	Loss: 1.081681
[INFO][16:21:33]: [Client #734] Going to sleep for 0.34 seconds.
[INFO][16:21:33]: [Client #640] Epoch: [2/5][10/15]	Loss: 1.106252
[INFO][16:21:33]: [Client #640] Going to sleep for 0.43 seconds.
[INFO][16:21:33]: [Client #734] Woke up.
[INFO][16:21:33]: [Client #734] Epoch: [3/5][0/16]	Loss: 0.815841
[INFO][16:21:34]: [Client #734] Epoch: [3/5][10/16]	Loss: 0.507653
[INFO][16:21:34]: [Client #640] Woke up.
[INFO][16:21:34]: [Client #640] Epoch: [3/5][0/15]	Loss: 1.000262
[INFO][16:21:34]: [Client #734] Going to sleep for 0.34 seconds.
[INFO][16:21:34]: [Client #640] Epoch: [3/5][10/15]	Loss: 1.203449
[INFO][16:21:34]: [Client #640] Going to sleep for 0.43 seconds.
[INFO][16:21:34]: [Client #734] Woke up.
[INFO][16:21:34]: [Client #734] Epoch: [4/5][0/16]	Loss: 0.815834
[INFO][16:21:34]: [Client #734] Epoch: [4/5][10/16]	Loss: 0.596058
[INFO][16:21:34]: [Client #734] Going to sleep for 0.34 seconds.
[INFO][16:21:34]: [Client #640] Woke up.
[INFO][16:21:34]: [Client #640] Epoch: [4/5][0/15]	Loss: 1.142581
[INFO][16:21:34]: [Client #640] Epoch: [4/5][10/15]	Loss: 1.676940
[INFO][16:21:34]: [Client #640] Going to sleep for 0.43 seconds.
[INFO][16:21:34]: [Client #734] Woke up.
[INFO][16:21:34]: [Client #734] Epoch: [5/5][0/16]	Loss: 0.647668
[INFO][16:21:35]: [Client #734] Epoch: [5/5][10/16]	Loss: 1.298906
[INFO][16:21:35]: [Client #734] Going to sleep for 0.34 seconds.
[INFO][16:21:35]: [Client #640] Woke up.
[INFO][16:21:35]: [Client #640] Epoch: [5/5][0/15]	Loss: 1.439143
[INFO][16:21:35]: [Client #640] Epoch: [5/5][10/15]	Loss: 1.038559
[INFO][16:21:35]: [Client #640] Going to sleep for 0.43 seconds.
[INFO][16:21:35]: [Client #734] Woke up.
[INFO][16:21:35]: [Client #734] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_734_615874.pth.
[INFO][16:21:35]: [Client #640] Woke up.
[INFO][16:21:35]: [Client #640] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_640_615875.pth.
[INFO][16:21:36]: [Client #734] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_734_615874.pth.
[INFO][16:21:36]: [Client #734] Model trained.
[INFO][16:21:36]: [Client #734] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:21:36]: [Server #615782] Received 0.26 MB of payload data from client #734 (simulated).
[INFO][16:21:36]: [Client #640] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_640_615875.pth.
[INFO][16:21:36]: [Client #640] Model trained.
[INFO][16:21:36]: [Client #640] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:21:36]: [Server #615782] Received 0.26 MB of payload data from client #640 (simulated).
[INFO][16:21:36]: [Server #615782] Selecting client #722 for training.
[INFO][16:21:36]: [Server #615782] Sending the current model to client #722 (simulated).
[INFO][16:21:36]: [Server #615782] Sending 0.26 MB of payload data to client #722 (simulated).
[INFO][16:21:36]: [Server #615782] Selecting client #51 for training.
[INFO][16:21:36]: [Server #615782] Sending the current model to client #51 (simulated).
[INFO][16:21:36]: [Server #615782] Sending 0.26 MB of payload data to client #51 (simulated).
[INFO][16:21:36]: [Client #722] Selected by the server.
[INFO][16:21:36]: [Client #51] Selected by the server.
[INFO][16:21:36]: [Client #722] Loading its data source...
[INFO][16:21:36]: [Client #51] Loading its data source...
[INFO][16:21:36]: Data source: FEMNIST
[INFO][16:21:36]: Data source: FEMNIST
[INFO][16:21:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:21:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/722.zip.
[INFO][16:21:36]: [Client #51] Dataset size: 135
[INFO][16:21:36]: [Client #51] Sampler: all_inclusive
[INFO][16:21:36]: [Client #51] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:21:36]: [93m[1m[Client #51] Started training in communication round #15.[0m
1.9%3.8%5.7%7.7%9.6%11.5%13.4%15.3%17.2%19.2%21.1%23.0%24.9%26.8%28.7%30.6%32.6%34.5%36.4%38.3%40.2%42.1%44.1%46.0%47.9%49.8%51.7%53.6%55.5%57.5%59.4%61.3%63.2%65.1%67.0%69.0%70.9%72.8%74.7%76.6%78.5%80.5%82.4%84.3%86.2%88.1%90.0%91.9%93.9%95.8%97.7%99.6%100.0%[INFO][16:21:36]: Decompressing the dataset downloaded.
[INFO][16:21:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/722.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:21:36]: [Client #722] Dataset size: 240
[INFO][16:21:36]: [Client #722] Sampler: all_inclusive
[INFO][16:21:36]: [Client #722] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:21:36]: [93m[1m[Client #722] Started training in communication round #15.[0m

[INFO][16:21:38]: [Client #51] Loading the dataset.
[INFO][16:21:38]: [Client #722] Loading the dataset.
[INFO][16:21:45]: [Client #51] Epoch: [1/5][0/14]	Loss: 1.842875
[INFO][16:21:45]: [Client #722] Epoch: [1/5][0/24]	Loss: 2.375445
[INFO][16:21:45]: [Client #51] Epoch: [1/5][10/14]	Loss: 1.166434
[INFO][16:21:45]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][16:21:45]: [Client #51] Woke up.
[INFO][16:21:45]: [Client #51] Epoch: [2/5][0/14]	Loss: 1.048248
[INFO][16:21:45]: [Client #722] Epoch: [1/5][10/24]	Loss: 2.307368
[INFO][16:21:45]: [Client #51] Epoch: [2/5][10/14]	Loss: 0.528178
[INFO][16:21:45]: [Client #722] Epoch: [1/5][20/24]	Loss: 0.623702
[INFO][16:21:45]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][16:21:45]: [Client #51] Woke up.
[INFO][16:21:45]: [Client #722] Going to sleep for 10.03 seconds.
[INFO][16:21:45]: [Client #51] Epoch: [3/5][0/14]	Loss: 1.056083
[INFO][16:21:45]: [Client #51] Epoch: [3/5][10/14]	Loss: 0.753732
[INFO][16:21:45]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][16:21:45]: [Client #51] Woke up.
[INFO][16:21:45]: [Client #51] Epoch: [4/5][0/14]	Loss: 0.780683
[INFO][16:21:46]: [Client #51] Epoch: [4/5][10/14]	Loss: 0.500027
[INFO][16:21:46]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][16:21:46]: [Client #51] Woke up.
[INFO][16:21:46]: [Client #51] Epoch: [5/5][0/14]	Loss: 0.798606
[INFO][16:21:46]: [Client #51] Epoch: [5/5][10/14]	Loss: 1.193486
[INFO][16:21:46]: [Client #51] Going to sleep for 0.02 seconds.
[INFO][16:21:46]: [Client #51] Woke up.
[INFO][16:21:46]: [Client #51] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_51_615875.pth.
[INFO][16:21:46]: [Client #51] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_51_615875.pth.
[INFO][16:21:46]: [Client #51] Model trained.
[INFO][16:21:46]: [Client #51] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:21:46]: [Server #615782] Received 0.26 MB of payload data from client #51 (simulated).
[INFO][16:21:55]: [Client #722] Woke up.
[INFO][16:21:55]: [Client #722] Epoch: [2/5][0/24]	Loss: 1.762368
[INFO][16:21:55]: [Client #722] Epoch: [2/5][10/24]	Loss: 1.241058
[INFO][16:21:55]: [Client #722] Epoch: [2/5][20/24]	Loss: 1.410575
[INFO][16:21:56]: [Client #722] Going to sleep for 10.03 seconds.
[INFO][16:22:06]: [Client #722] Woke up.
[INFO][16:22:06]: [Client #722] Epoch: [3/5][0/24]	Loss: 2.452326
[INFO][16:22:06]: [Client #722] Epoch: [3/5][10/24]	Loss: 1.887717
[INFO][16:22:06]: [Client #722] Epoch: [3/5][20/24]	Loss: 1.374991
[INFO][16:22:06]: [Client #722] Going to sleep for 10.03 seconds.
[INFO][16:22:16]: [Client #722] Woke up.
[INFO][16:22:16]: [Client #722] Epoch: [4/5][0/24]	Loss: 1.065943
[INFO][16:22:16]: [Client #722] Epoch: [4/5][10/24]	Loss: 0.692461
[INFO][16:22:16]: [Client #722] Epoch: [4/5][20/24]	Loss: 1.651292
[INFO][16:22:16]: [Client #722] Going to sleep for 10.03 seconds.
[INFO][16:22:26]: [Client #722] Woke up.
[INFO][16:22:26]: [Client #722] Epoch: [5/5][0/24]	Loss: 0.649210
[INFO][16:22:26]: [Client #722] Epoch: [5/5][10/24]	Loss: 1.417348
[INFO][16:22:26]: [Client #722] Epoch: [5/5][20/24]	Loss: 1.915184
[INFO][16:22:26]: [Client #722] Going to sleep for 10.03 seconds.
[INFO][16:22:36]: [Client #722] Woke up.
[INFO][16:22:36]: [Client #722] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_722_615874.pth.
[INFO][16:22:37]: [Client #722] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_722_615874.pth.
[INFO][16:22:37]: [Client #722] Model trained.
[INFO][16:22:37]: [Client #722] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:22:37]: [Server #615782] Received 0.26 MB of payload data from client #722 (simulated).
[INFO][16:22:37]: [Server #615782] Selecting client #921 for training.
[INFO][16:22:37]: [Server #615782] Sending the current model to client #921 (simulated).
[INFO][16:22:37]: [Server #615782] Sending 0.26 MB of payload data to client #921 (simulated).
[INFO][16:22:37]: [Server #615782] Selecting client #928 for training.
[INFO][16:22:37]: [Server #615782] Sending the current model to client #928 (simulated).
[INFO][16:22:37]: [Server #615782] Sending 0.26 MB of payload data to client #928 (simulated).
[INFO][16:22:37]: [Client #921] Selected by the server.
[INFO][16:22:37]: [Client #921] Loading its data source...
[INFO][16:22:37]: Data source: FEMNIST
[INFO][16:22:37]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:22:37]: [Client #928] Selected by the server.
[INFO][16:22:37]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/921.zip.
[INFO][16:22:37]: [Client #928] Loading its data source...
[INFO][16:22:37]: Data source: FEMNIST
[INFO][16:22:37]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:22:37]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/928.zip.
2.6%2.6%5.2%7.8%10.4%13.0%15.6%18.3%20.9%23.5%26.1%28.7%31.3%33.9%36.5%39.1%41.7%44.3%46.9%49.5%52.1%54.8%57.4%60.0%62.6%65.2%67.8%70.4%73.0%75.6%78.2%80.8%83.4%86.0%88.6%91.3%93.9%96.5%99.1%100.0%[INFO][16:22:37]: Decompressing the dataset downloaded.
[INFO][16:22:37]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/921.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
5.2%7.8%10.4%13.0%15.6%18.2%20.8%23.4%26.0%28.6%31.2%33.8%36.4%39.0%41.6%44.2%46.8%49.4%52.0%54.6%57.3%59.9%62.5%65.1%67.7%70.3%72.9%75.5%78.1%80.7%83.3%85.9%88.5%91.1%93.7%96.3%98.9%100.0%[INFO][16:22:37]: Decompressing the dataset downloaded.
[INFO][16:22:37]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/928.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:22:37]: [Client #921] Dataset size: 143
[INFO][16:22:37]: [Client #921] Sampler: all_inclusive
[INFO][16:22:37]: [Client #921] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:22:37]: [93m[1m[Client #921] Started training in communication round #15.[0m

[INFO][16:22:37]: [Client #928] Dataset size: 158
[INFO][16:22:37]: [Client #928] Sampler: all_inclusive
[INFO][16:22:37]: [Client #928] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:22:37]: [93m[1m[Client #928] Started training in communication round #15.[0m

[INFO][16:22:39]: [Client #921] Loading the dataset.
[INFO][16:22:39]: [Client #928] Loading the dataset.
[INFO][16:22:47]: [Client #921] Epoch: [1/5][0/15]	Loss: 2.807297
[INFO][16:22:47]: [Client #928] Epoch: [1/5][0/16]	Loss: 1.310765
[INFO][16:22:47]: [Client #921] Epoch: [1/5][10/15]	Loss: 1.002345
[INFO][16:22:47]: [Client #928] Epoch: [1/5][10/16]	Loss: 0.660101
[INFO][16:22:47]: [Client #921] Going to sleep for 0.18 seconds.
[INFO][16:22:47]: [Client #928] Going to sleep for 1.12 seconds.
[INFO][16:22:47]: [Client #921] Woke up.
[INFO][16:22:47]: [Client #921] Epoch: [2/5][0/15]	Loss: 0.169703
[INFO][16:22:47]: [Client #921] Epoch: [2/5][10/15]	Loss: 0.974562
[INFO][16:22:47]: [Client #921] Going to sleep for 0.18 seconds.
[INFO][16:22:47]: [Client #921] Woke up.
[INFO][16:22:47]: [Client #921] Epoch: [3/5][0/15]	Loss: 0.937533
[INFO][16:22:47]: [Client #921] Epoch: [3/5][10/15]	Loss: 2.407873
[INFO][16:22:48]: [Client #921] Going to sleep for 0.18 seconds.
[INFO][16:22:48]: [Client #921] Woke up.
[INFO][16:22:48]: [Client #921] Epoch: [4/5][0/15]	Loss: 0.670576
[INFO][16:22:48]: [Client #921] Epoch: [4/5][10/15]	Loss: 0.699930
[INFO][16:22:48]: [Client #921] Going to sleep for 0.18 seconds.
[INFO][16:22:48]: [Client #921] Woke up.
[INFO][16:22:48]: [Client #928] Woke up.
[INFO][16:22:48]: [Client #921] Epoch: [5/5][0/15]	Loss: 1.787524
[INFO][16:22:48]: [Client #928] Epoch: [2/5][0/16]	Loss: 0.928546
[INFO][16:22:48]: [Client #921] Epoch: [5/5][10/15]	Loss: 1.101020
[INFO][16:22:48]: [Client #928] Epoch: [2/5][10/16]	Loss: 1.691957
[INFO][16:22:48]: [Client #921] Going to sleep for 0.18 seconds.
[INFO][16:22:48]: [Client #928] Going to sleep for 1.12 seconds.
[INFO][16:22:48]: [Client #921] Woke up.
[INFO][16:22:48]: [Client #921] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_921_615874.pth.
[INFO][16:22:49]: [Client #928] Woke up.
[INFO][16:22:49]: [Client #928] Epoch: [3/5][0/16]	Loss: 1.486321
[INFO][16:22:49]: [Client #921] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_921_615874.pth.
[INFO][16:22:49]: [Client #921] Model trained.
[INFO][16:22:49]: [Client #921] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:22:49]: [Server #615782] Received 0.26 MB of payload data from client #921 (simulated).
[INFO][16:22:49]: [Client #928] Epoch: [3/5][10/16]	Loss: 1.093074
[INFO][16:22:49]: [Client #928] Going to sleep for 1.12 seconds.
[INFO][16:22:51]: [Client #928] Woke up.
[INFO][16:22:51]: [Client #928] Epoch: [4/5][0/16]	Loss: 1.184308
[INFO][16:22:51]: [Client #928] Epoch: [4/5][10/16]	Loss: 1.347184
[INFO][16:22:51]: [Client #928] Going to sleep for 1.12 seconds.
[INFO][16:22:52]: [Client #928] Woke up.
[INFO][16:22:52]: [Client #928] Epoch: [5/5][0/16]	Loss: 1.805413
[INFO][16:22:52]: [Client #928] Epoch: [5/5][10/16]	Loss: 0.755501
[INFO][16:22:52]: [Client #928] Going to sleep for 1.12 seconds.
[INFO][16:22:53]: [Client #928] Woke up.
[INFO][16:22:53]: [Client #928] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_928_615875.pth.
[INFO][16:22:54]: [Client #928] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_928_615875.pth.
[INFO][16:22:54]: [Client #928] Model trained.
[INFO][16:22:54]: [Client #928] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:22:54]: [Server #615782] Received 0.26 MB of payload data from client #928 (simulated).
[INFO][16:22:54]: [Server #615782] Selecting client #552 for training.
[INFO][16:22:54]: [Server #615782] Sending the current model to client #552 (simulated).
[INFO][16:22:54]: [Server #615782] Sending 0.26 MB of payload data to client #552 (simulated).
[INFO][16:22:54]: [Server #615782] Selecting client #965 for training.
[INFO][16:22:54]: [Server #615782] Sending the current model to client #965 (simulated).
[INFO][16:22:54]: [Server #615782] Sending 0.26 MB of payload data to client #965 (simulated).
[INFO][16:22:54]: [Client #552] Selected by the server.
[INFO][16:22:54]: [Client #552] Loading its data source...
[INFO][16:22:54]: [Client #965] Selected by the server.
[INFO][16:22:54]: Data source: FEMNIST
[INFO][16:22:54]: [Client #965] Loading its data source...
[INFO][16:22:54]: Data source: FEMNIST
[INFO][16:22:54]: [Client #965] Dataset size: 137
[INFO][16:22:54]: [Client #965] Sampler: all_inclusive
[INFO][16:22:54]: [Client #552] Dataset size: 150
[INFO][16:22:54]: [Client #552] Sampler: all_inclusive
[INFO][16:22:54]: [Client #965] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:22:54]: [Client #552] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:22:54]: [93m[1m[Client #965] Started training in communication round #15.[0m
[INFO][16:22:54]: [93m[1m[Client #552] Started training in communication round #15.[0m
[INFO][16:22:56]: [Client #965] Loading the dataset.
[INFO][16:22:56]: [Client #552] Loading the dataset.
[INFO][16:23:03]: [Client #965] Epoch: [1/5][0/14]	Loss: 1.594219
[INFO][16:23:03]: [Client #552] Epoch: [1/5][0/15]	Loss: 1.031211
[INFO][16:23:03]: [Client #965] Epoch: [1/5][10/14]	Loss: 1.414245
[INFO][16:23:03]: [Client #552] Epoch: [1/5][10/15]	Loss: 0.654895
[INFO][16:23:03]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][16:23:03]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][16:23:03]: [Client #965] Woke up.
[INFO][16:23:03]: [Client #965] Epoch: [2/5][0/14]	Loss: 2.306858
[INFO][16:23:03]: [Client #965] Epoch: [2/5][10/14]	Loss: 1.092084
[INFO][16:23:03]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][16:23:03]: [Client #965] Woke up.
[INFO][16:23:03]: [Client #965] Epoch: [3/5][0/14]	Loss: 1.813704
[INFO][16:23:03]: [Client #965] Epoch: [3/5][10/14]	Loss: 1.429292
[INFO][16:23:03]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][16:23:03]: [Client #965] Woke up.
[INFO][16:23:03]: [Client #965] Epoch: [4/5][0/14]	Loss: 0.729112
[INFO][16:23:04]: [Client #965] Epoch: [4/5][10/14]	Loss: 0.986511
[INFO][16:23:04]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][16:23:04]: [Client #965] Woke up.
[INFO][16:23:04]: [Client #965] Epoch: [5/5][0/14]	Loss: 0.671030
[INFO][16:23:04]: [Client #965] Epoch: [5/5][10/14]	Loss: 1.534637
[INFO][16:23:04]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][16:23:04]: [Client #965] Woke up.
[INFO][16:23:04]: [Client #965] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615875.pth.
[INFO][16:23:04]: [Client #552] Woke up.
[INFO][16:23:04]: [Client #552] Epoch: [2/5][0/15]	Loss: 1.009454
[INFO][16:23:04]: [Client #552] Epoch: [2/5][10/15]	Loss: 0.772361
[INFO][16:23:04]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][16:23:04]: [Client #965] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615875.pth.
[INFO][16:23:04]: [Client #965] Model trained.
[INFO][16:23:04]: [Client #965] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:23:04]: [Server #615782] Received 0.26 MB of payload data from client #965 (simulated).
[INFO][16:23:05]: [Client #552] Woke up.
[INFO][16:23:05]: [Client #552] Epoch: [3/5][0/15]	Loss: 1.520473
[INFO][16:23:06]: [Client #552] Epoch: [3/5][10/15]	Loss: 1.290060
[INFO][16:23:06]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][16:23:07]: [Client #552] Woke up.
[INFO][16:23:07]: [Client #552] Epoch: [4/5][0/15]	Loss: 0.799598
[INFO][16:23:07]: [Client #552] Epoch: [4/5][10/15]	Loss: 0.806499
[INFO][16:23:07]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][16:23:08]: [Client #552] Woke up.
[INFO][16:23:08]: [Client #552] Epoch: [5/5][0/15]	Loss: 0.455824
[INFO][16:23:08]: [Client #552] Epoch: [5/5][10/15]	Loss: 0.081045
[INFO][16:23:08]: [Client #552] Going to sleep for 1.10 seconds.
[INFO][16:23:09]: [Client #552] Woke up.
[INFO][16:23:09]: [Client #552] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_552_615874.pth.
[INFO][16:23:10]: [Client #552] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_552_615874.pth.
[INFO][16:23:10]: [Client #552] Model trained.
[INFO][16:23:10]: [Client #552] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:23:10]: [Server #615782] Received 0.26 MB of payload data from client #552 (simulated).
[INFO][16:23:10]: [Server #615782] Selecting client #281 for training.
[INFO][16:23:10]: [Server #615782] Sending the current model to client #281 (simulated).
[INFO][16:23:10]: [Server #615782] Sending 0.26 MB of payload data to client #281 (simulated).
[INFO][16:23:10]: [Server #615782] Selecting client #602 for training.
[INFO][16:23:10]: [Server #615782] Sending the current model to client #602 (simulated).
[INFO][16:23:10]: [Server #615782] Sending 0.26 MB of payload data to client #602 (simulated).
[INFO][16:23:10]: [Client #281] Selected by the server.
[INFO][16:23:10]: [Client #281] Loading its data source...
[INFO][16:23:10]: Data source: FEMNIST
[INFO][16:23:10]: [Client #602] Selected by the server.
[INFO][16:23:10]: [Client #602] Loading its data source...
[INFO][16:23:10]: Data source: FEMNIST
[INFO][16:23:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:23:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/602.zip.
[INFO][16:23:10]: [Client #281] Dataset size: 164
[INFO][16:23:10]: [Client #281] Sampler: all_inclusive
[INFO][16:23:10]: [Client #281] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:23:10]: [93m[1m[Client #281] Started training in communication round #15.[0m
3.3%6.5%9.8%13.1%16.4%19.6%22.9%26.2%29.5%32.7%36.0%39.3%42.6%45.8%49.1%52.4%55.7%58.9%62.2%65.5%68.8%72.0%75.3%78.6%81.9%85.1%88.4%91.7%95.0%98.2%100.0%[INFO][16:23:10]: Decompressing the dataset downloaded.
[INFO][16:23:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/602.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:23:10]: [Client #602] Dataset size: 121
[INFO][16:23:10]: [Client #602] Sampler: all_inclusive
[INFO][16:23:10]: [Client #602] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:23:10]: [93m[1m[Client #602] Started training in communication round #15.[0m

[INFO][16:23:12]: [Client #281] Loading the dataset.
[INFO][16:23:12]: [Client #602] Loading the dataset.
[INFO][16:23:19]: [Client #602] Epoch: [1/5][0/13]	Loss: 0.713855
[INFO][16:23:19]: [Client #281] Epoch: [1/5][0/17]	Loss: 1.145276
[INFO][16:23:19]: [Client #602] Epoch: [1/5][10/13]	Loss: 1.439333
[INFO][16:23:19]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:23:19]: [Client #281] Epoch: [1/5][10/17]	Loss: 0.872470
[INFO][16:23:19]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][16:23:23]: [Client #602] Woke up.
[INFO][16:23:23]: [Client #602] Epoch: [2/5][0/13]	Loss: 0.737820
[INFO][16:23:23]: [Client #602] Epoch: [2/5][10/13]	Loss: 1.634009
[INFO][16:23:23]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:23:26]: [Client #281] Woke up.
[INFO][16:23:26]: [Client #281] Epoch: [2/5][0/17]	Loss: 0.584287
[INFO][16:23:27]: [Client #281] Epoch: [2/5][10/17]	Loss: 0.771474
[INFO][16:23:27]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][16:23:27]: [Client #602] Woke up.
[INFO][16:23:27]: [Client #602] Epoch: [3/5][0/13]	Loss: 0.937561
[INFO][16:23:27]: [Client #602] Epoch: [3/5][10/13]	Loss: 1.623676
[INFO][16:23:27]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:23:31]: [Client #602] Woke up.
[INFO][16:23:31]: [Client #602] Epoch: [4/5][0/13]	Loss: 0.790413
[INFO][16:23:31]: [Client #602] Epoch: [4/5][10/13]	Loss: 1.727750
[INFO][16:23:31]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:23:34]: [Client #281] Woke up.
[INFO][16:23:34]: [Client #281] Epoch: [3/5][0/17]	Loss: 1.138597
[INFO][16:23:34]: [Client #281] Epoch: [3/5][10/17]	Loss: 0.888409
[INFO][16:23:34]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][16:23:35]: [Client #602] Woke up.
[INFO][16:23:35]: [Client #602] Epoch: [5/5][0/13]	Loss: 0.984205
[INFO][16:23:35]: [Client #602] Epoch: [5/5][10/13]	Loss: 1.413315
[INFO][16:23:36]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:23:40]: [Client #602] Woke up.
[INFO][16:23:40]: [Client #602] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_602_615875.pth.
[INFO][16:23:40]: [Client #602] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_602_615875.pth.
[INFO][16:23:40]: [Client #602] Model trained.
[INFO][16:23:40]: [Client #602] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:23:40]: [Server #615782] Received 0.26 MB of payload data from client #602 (simulated).
[INFO][16:23:41]: [Client #281] Woke up.
[INFO][16:23:41]: [Client #281] Epoch: [4/5][0/17]	Loss: 0.763919
[INFO][16:23:42]: [Client #281] Epoch: [4/5][10/17]	Loss: 0.814139
[INFO][16:23:42]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][16:23:49]: [Client #281] Woke up.
[INFO][16:23:49]: [Client #281] Epoch: [5/5][0/17]	Loss: 0.155074
[INFO][16:23:49]: [Client #281] Epoch: [5/5][10/17]	Loss: 1.002007
[INFO][16:23:49]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][16:23:56]: [Client #281] Woke up.
[INFO][16:23:56]: [Client #281] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_281_615874.pth.
[INFO][16:23:57]: [Client #281] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_281_615874.pth.
[INFO][16:23:57]: [Client #281] Model trained.
[INFO][16:23:57]: [Client #281] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:23:57]: [Server #615782] Received 0.26 MB of payload data from client #281 (simulated).
[INFO][16:23:57]: [Server #615782] Selecting client #397 for training.
[INFO][16:23:57]: [Server #615782] Sending the current model to client #397 (simulated).
[INFO][16:23:57]: [Server #615782] Sending 0.26 MB of payload data to client #397 (simulated).
[INFO][16:23:57]: [Server #615782] Selecting client #628 for training.
[INFO][16:23:57]: [Server #615782] Sending the current model to client #628 (simulated).
[INFO][16:23:57]: [Server #615782] Sending 0.26 MB of payload data to client #628 (simulated).
[INFO][16:23:57]: [Client #397] Selected by the server.
[INFO][16:23:57]: [Client #397] Loading its data source...
[INFO][16:23:57]: Data source: FEMNIST
[INFO][16:23:57]: [Client #628] Selected by the server.
[INFO][16:23:57]: [Client #628] Loading its data source...
[INFO][16:23:57]: Data source: FEMNIST
[INFO][16:23:57]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:23:57]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/628.zip.
[INFO][16:23:57]: [Client #397] Dataset size: 164
[INFO][16:23:57]: [Client #397] Sampler: all_inclusive
[INFO][16:23:57]: [Client #397] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:23:57]: [93m[1m[Client #397] Started training in communication round #15.[0m
2.8%5.5%8.3%11.0%13.8%16.5%19.3%22.0%24.8%27.6%30.3%33.1%35.8%38.6%41.3%44.1%46.9%49.6%52.4%55.1%57.9%60.6%63.4%66.1%68.9%71.7%74.4%77.2%79.9%82.7%85.4%88.2%90.9%93.7%96.5%99.2%100.0%[INFO][16:23:57]: Decompressing the dataset downloaded.
[INFO][16:23:57]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/628.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:23:57]: [Client #628] Dataset size: 162
[INFO][16:23:57]: [Client #628] Sampler: all_inclusive
[INFO][16:23:57]: [Client #628] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:23:57]: [93m[1m[Client #628] Started training in communication round #15.[0m

[INFO][16:23:59]: [Client #397] Loading the dataset.
[INFO][16:23:59]: [Client #628] Loading the dataset.
[INFO][16:24:07]: [Client #628] Epoch: [1/5][0/17]	Loss: 1.250033
[INFO][16:24:07]: [Client #397] Epoch: [1/5][0/17]	Loss: 0.530079
[INFO][16:24:07]: [Client #397] Epoch: [1/5][10/17]	Loss: 0.681509
[INFO][16:24:07]: [Client #628] Epoch: [1/5][10/17]	Loss: 1.388833
[INFO][16:24:07]: [Client #628] Going to sleep for 2.98 seconds.
[INFO][16:24:07]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][16:24:07]: [Client #397] Woke up.
[INFO][16:24:07]: [Client #397] Epoch: [2/5][0/17]	Loss: 0.317567
[INFO][16:24:07]: [Client #397] Epoch: [2/5][10/17]	Loss: 1.814317
[INFO][16:24:07]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][16:24:08]: [Client #397] Woke up.
[INFO][16:24:08]: [Client #397] Epoch: [3/5][0/17]	Loss: 0.497543
[INFO][16:24:08]: [Client #397] Epoch: [3/5][10/17]	Loss: 1.199396
[INFO][16:24:08]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][16:24:09]: [Client #397] Woke up.
[INFO][16:24:09]: [Client #397] Epoch: [4/5][0/17]	Loss: 1.208868
[INFO][16:24:09]: [Client #397] Epoch: [4/5][10/17]	Loss: 0.985478
[INFO][16:24:09]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][16:24:10]: [Client #397] Woke up.
[INFO][16:24:10]: [Client #397] Epoch: [5/5][0/17]	Loss: 0.727992
[INFO][16:24:10]: [Client #628] Woke up.
[INFO][16:24:10]: [Client #628] Epoch: [2/5][0/17]	Loss: 0.331224
[INFO][16:24:10]: [Client #397] Epoch: [5/5][10/17]	Loss: 1.309749
[INFO][16:24:10]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][16:24:10]: [Client #628] Epoch: [2/5][10/17]	Loss: 2.939053
[INFO][16:24:10]: [Client #628] Going to sleep for 2.98 seconds.
[INFO][16:24:10]: [Client #397] Woke up.
[INFO][16:24:10]: [Client #397] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_615874.pth.
[INFO][16:24:11]: [Client #397] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_615874.pth.
[INFO][16:24:11]: [Client #397] Model trained.
[INFO][16:24:11]: [Client #397] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:24:11]: [Server #615782] Received 0.26 MB of payload data from client #397 (simulated).
[INFO][16:24:13]: [Client #628] Woke up.
[INFO][16:24:13]: [Client #628] Epoch: [3/5][0/17]	Loss: 2.194476
[INFO][16:24:13]: [Client #628] Epoch: [3/5][10/17]	Loss: 2.161382
[INFO][16:24:13]: [Client #628] Going to sleep for 2.98 seconds.
[INFO][16:24:16]: [Client #628] Woke up.
[INFO][16:24:16]: [Client #628] Epoch: [4/5][0/17]	Loss: 1.175655
[INFO][16:24:16]: [Client #628] Epoch: [4/5][10/17]	Loss: 1.038122
[INFO][16:24:16]: [Client #628] Going to sleep for 2.98 seconds.
[INFO][16:24:19]: [Client #628] Woke up.
[INFO][16:24:19]: [Client #628] Epoch: [5/5][0/17]	Loss: 0.703846
[INFO][16:24:19]: [Client #628] Epoch: [5/5][10/17]	Loss: 1.233032
[INFO][16:24:19]: [Client #628] Going to sleep for 2.98 seconds.
[INFO][16:24:22]: [Client #628] Woke up.
[INFO][16:24:22]: [Client #628] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_628_615875.pth.
[INFO][16:24:23]: [Client #628] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_628_615875.pth.
[INFO][16:24:23]: [Client #628] Model trained.
[INFO][16:24:23]: [Client #628] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:24:23]: [Server #615782] Received 0.26 MB of payload data from client #628 (simulated).
[INFO][16:24:23]: [Server #615782] Selecting client #300 for training.
[INFO][16:24:23]: [Server #615782] Sending the current model to client #300 (simulated).
[INFO][16:24:23]: [Server #615782] Sending 0.26 MB of payload data to client #300 (simulated).
[INFO][16:24:23]: [Client #300] Selected by the server.
[INFO][16:24:23]: [Client #300] Loading its data source...
[INFO][16:24:23]: Data source: FEMNIST
[INFO][16:24:23]: [Client #300] Dataset size: 255
[INFO][16:24:23]: [Client #300] Sampler: all_inclusive
[INFO][16:24:23]: [Client #300] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:24:23]: [93m[1m[Client #300] Started training in communication round #15.[0m
[INFO][16:24:25]: [Client #300] Loading the dataset.
[INFO][16:24:31]: [Client #300] Epoch: [1/5][0/26]	Loss: 2.890702
[INFO][16:24:31]: [Client #300] Epoch: [1/5][10/26]	Loss: 0.991416
[INFO][16:24:31]: [Client #300] Epoch: [1/5][20/26]	Loss: 2.446526
[INFO][16:24:31]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][16:24:32]: [Client #300] Woke up.
[INFO][16:24:32]: [Client #300] Epoch: [2/5][0/26]	Loss: 1.359957
[INFO][16:24:32]: [Client #300] Epoch: [2/5][10/26]	Loss: 0.811479
[INFO][16:24:32]: [Client #300] Epoch: [2/5][20/26]	Loss: 1.007813
[INFO][16:24:32]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][16:24:32]: [Client #300] Woke up.
[INFO][16:24:32]: [Client #300] Epoch: [3/5][0/26]	Loss: 0.961484
[INFO][16:24:32]: [Client #300] Epoch: [3/5][10/26]	Loss: 1.499228
[INFO][16:24:32]: [Client #300] Epoch: [3/5][20/26]	Loss: 1.405473
[INFO][16:24:32]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][16:24:33]: [Client #300] Woke up.
[INFO][16:24:33]: [Client #300] Epoch: [4/5][0/26]	Loss: 3.008737
[INFO][16:24:33]: [Client #300] Epoch: [4/5][10/26]	Loss: 3.030077
[INFO][16:24:33]: [Client #300] Epoch: [4/5][20/26]	Loss: 1.878529
[INFO][16:24:33]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][16:24:33]: [Client #300] Woke up.
[INFO][16:24:33]: [Client #300] Epoch: [5/5][0/26]	Loss: 0.902460
[INFO][16:24:33]: [Client #300] Epoch: [5/5][10/26]	Loss: 2.333192
[INFO][16:24:33]: [Client #300] Epoch: [5/5][20/26]	Loss: 1.596627
[INFO][16:24:33]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][16:24:33]: [Client #300] Woke up.
[INFO][16:24:33]: [Client #300] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_300_615874.pth.
[INFO][16:24:34]: [Client #300] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_300_615874.pth.
[INFO][16:24:34]: [Client #300] Model trained.
[INFO][16:24:34]: [Client #300] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:24:34]: [Server #615782] Received 0.26 MB of payload data from client #300 (simulated).
[INFO][16:24:34]: [Server #615782] Adding client #51 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #965 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #300 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #921 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #734 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #640 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #397 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #863 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #294 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #434 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #552 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #928 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #998 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #352 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #628 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #42 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #602 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #465 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #535 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #281 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #856 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #722 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #904 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #990 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Adding client #365 to the list of clients for aggregation.
[INFO][16:24:34]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13993575
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10134979 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18111336 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0954083
 0.         0.         0.         0.         0.         0.23560141
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1361266  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07270947 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08943222 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09967886 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12118889 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08333388 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07109946
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.40336295 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10616267 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18593016 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16479762 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10657708 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09739392 0.         0.
 0.         0.         0.         0.         0.14435905 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12677756 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.21356522 0.         0.         0.
 0.         0.         0.         0.08693596 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10227239 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08920708
 0.         0.         0.         0.         0.         0.
 0.         0.09694684 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13993575
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10134979 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18111336 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0954083
 0.         0.         0.         0.         0.         0.23560141
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1361266  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07270947 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08943222 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09967886 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12118889 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08333388 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07109946
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.40336295 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10616267 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18593016 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16479762 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10657708 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09739392 0.         0.
 0.         0.         0.         0.         0.14435905 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12677756 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.21356522 0.         0.         0.
 0.         0.         0.         0.08693596 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10227239 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08920708
 0.         0.         0.         0.         0.         0.
 0.         0.09694684 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.0350013  0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.03767545 0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.001      0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.03647485 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.001      0.001      0.04226082 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.01781108 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02670469 0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.001      0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.04063039
 0.0386082  0.001      0.04316547 0.001      0.06692817 0.01709943
 0.04070521 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03889033
 0.04038414 0.001      0.001      0.001      0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.03137153 0.01937935 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.03826169
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.001      0.03707545 0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.001      0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.03613604
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0383693  0.03241574 0.03778932
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.0386082  0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.0399274  0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03466244
 0.001      0.02800639 0.001      0.001      0.001      0.03495513
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.001      0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.0401379  0.001      0.04096448 0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03188474 0.001
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03767545 0.04076739
 0.03613604 0.03358666 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03551983 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.001
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][16:25:18]: [Server #615782] Global model accuracy: 56.53%

[INFO][16:25:18]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_15.pth.
[INFO][16:25:18]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_15.pth.
[INFO][16:25:18]: [93m[1m
[Server #615782] Starting round 16/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  8e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  5e-05  1e-10  1e-10
 7:  7.5999e+00  7.5998e+00  5e-05  3e-09  3e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  2e-10
 9:  7.5999e+00  7.5999e+00  2e-05  4e-09  4e-10
10:  7.5999e+00  7.5999e+00  4e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88615601e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88823828e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88323819e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88815058e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.86367788e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88604242e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88856231e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88803735e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88837712e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88846425e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88835365e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88876712e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.87246895e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88745676e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88449887e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.87833733e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88749275e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 9.21262973e-01
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88651864e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88669789e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88287559e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88822769e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88817268e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88903576e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88958605e-05 7.88958605e-05 7.88958605e-05 7.88958605e-05
 7.88804324e-05 7.88958605e-05 7.88958605e-05][INFO][16:25:21]: [Server #615782] Selected clients: [856 531 627 556 936 864 476 553 877 950 639 748 350 919 836 551 868 849
 808 131 535 902 770 419 978]
[INFO][16:25:21]: [Server #615782] Selecting client #856 for training.
[INFO][16:25:21]: [Server #615782] Sending the current model to client #856 (simulated).
[INFO][16:25:21]: [Server #615782] Sending 0.26 MB of payload data to client #856 (simulated).
[INFO][16:25:21]: [Server #615782] Selecting client #531 for training.
[INFO][16:25:21]: [Server #615782] Sending the current model to client #531 (simulated).
[INFO][16:25:21]: [Server #615782] Sending 0.26 MB of payload data to client #531 (simulated).
[INFO][16:25:21]: [Client #856] Selected by the server.
[INFO][16:25:21]: [Client #856] Loading its data source...
[INFO][16:25:21]: Data source: FEMNIST
[INFO][16:25:21]: [Client #531] Selected by the server.
[INFO][16:25:21]: [Client #531] Loading its data source...
[INFO][16:25:21]: Data source: FEMNIST
[INFO][16:25:21]: [Client #856] Dataset size: 154
[INFO][16:25:21]: [Client #856] Sampler: all_inclusive
[INFO][16:25:21]: [Client #856] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:25:21]: [Client #531] Dataset size: 162
[INFO][16:25:21]: [Client #531] Sampler: all_inclusive
[INFO][16:25:21]: [Client #531] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:25:21]: [93m[1m[Client #856] Started training in communication round #16.[0m
[INFO][16:25:21]: [93m[1m[Client #531] Started training in communication round #16.[0m
[INFO][16:25:23]: [Client #531] Loading the dataset.
[INFO][16:25:23]: [Client #856] Loading the dataset.
[INFO][16:25:30]: [Client #531] Epoch: [1/5][0/17]	Loss: 0.932299
[INFO][16:25:30]: [Client #856] Epoch: [1/5][0/16]	Loss: 1.387950
[INFO][16:25:30]: [Client #531] Epoch: [1/5][10/17]	Loss: 0.527282
[INFO][16:25:30]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][16:25:30]: [Client #856] Epoch: [1/5][10/16]	Loss: 1.557514
[INFO][16:25:30]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:26:10]: [Client #531] Woke up.
[INFO][16:26:10]: [Client #531] Epoch: [2/5][0/17]	Loss: 0.421490
[INFO][16:26:10]: [Client #531] Epoch: [2/5][10/17]	Loss: 0.767455
[INFO][16:26:10]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][16:26:30]: [Client #856] Woke up.
[INFO][16:26:31]: [Client #856] Epoch: [2/5][0/16]	Loss: 0.409413
[INFO][16:26:31]: [Client #856] Epoch: [2/5][10/16]	Loss: 1.643593
[INFO][16:26:31]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:26:50]: [Client #531] Woke up.
[INFO][16:26:50]: [Client #531] Epoch: [3/5][0/17]	Loss: 1.257162
[INFO][16:26:50]: [Client #531] Epoch: [3/5][10/17]	Loss: 1.332630
[INFO][16:26:50]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][16:27:30]: [Client #531] Woke up.
[INFO][16:27:30]: [Client #531] Epoch: [4/5][0/17]	Loss: 0.802728
[INFO][16:27:30]: [Client #531] Epoch: [4/5][10/17]	Loss: 0.627158
[INFO][16:27:30]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][16:27:31]: [Client #856] Woke up.
[INFO][16:27:31]: [Client #856] Epoch: [3/5][0/16]	Loss: 0.658679
[INFO][16:27:31]: [Client #856] Epoch: [3/5][10/16]	Loss: 1.051588
[INFO][16:27:31]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:28:09]: [Client #531] Woke up.
[INFO][16:28:10]: [Client #531] Epoch: [5/5][0/17]	Loss: 0.450829
[INFO][16:28:10]: [Client #531] Epoch: [5/5][10/17]	Loss: 0.945188
[INFO][16:28:10]: [Client #531] Going to sleep for 39.57 seconds.
[INFO][16:28:31]: [Client #856] Woke up.
[INFO][16:28:31]: [Client #856] Epoch: [4/5][0/16]	Loss: 0.665755
[INFO][16:28:31]: [Client #856] Epoch: [4/5][10/16]	Loss: 0.941523
[INFO][16:28:31]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:28:49]: [Client #531] Woke up.
[INFO][16:28:50]: [Client #531] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][16:28:50]: [Client #531] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_531_615875.pth.
[INFO][16:28:50]: [Client #531] Model trained.
[INFO][16:28:50]: [Client #531] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:28:50]: [Server #615782] Received 0.26 MB of payload data from client #531 (simulated).
[INFO][16:29:31]: [Client #856] Woke up.
[INFO][16:29:31]: [Client #856] Epoch: [5/5][0/16]	Loss: 1.091475
[INFO][16:29:31]: [Client #856] Epoch: [5/5][10/16]	Loss: 0.820723
[INFO][16:29:31]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:30:31]: [Client #856] Woke up.
[INFO][16:30:32]: [Client #856] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:30:32]: [Client #856] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:30:32]: [Client #856] Model trained.
[INFO][16:30:32]: [Client #856] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:30:32]: [Server #615782] Received 0.26 MB of payload data from client #856 (simulated).
[INFO][16:30:32]: [Server #615782] Selecting client #627 for training.
[INFO][16:30:32]: [Server #615782] Sending the current model to client #627 (simulated).
[INFO][16:30:32]: [Server #615782] Sending 0.26 MB of payload data to client #627 (simulated).
[INFO][16:30:32]: [Server #615782] Selecting client #556 for training.
[INFO][16:30:32]: [Server #615782] Sending the current model to client #556 (simulated).
[INFO][16:30:32]: [Server #615782] Sending 0.26 MB of payload data to client #556 (simulated).
[INFO][16:30:32]: [Client #627] Selected by the server.
[INFO][16:30:32]: [Client #627] Loading its data source...
[INFO][16:30:32]: Data source: FEMNIST
[INFO][16:30:32]: [Client #556] Selected by the server.
[INFO][16:30:32]: [Client #556] Loading its data source...
[INFO][16:30:32]: Data source: FEMNIST
[INFO][16:30:32]: [Client #627] Dataset size: 154
[INFO][16:30:32]: [Client #627] Sampler: all_inclusive
[INFO][16:30:32]: [Client #627] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:30:32]: [Client #556] Dataset size: 197
[INFO][16:30:32]: [Client #556] Sampler: all_inclusive
[INFO][16:30:32]: [93m[1m[Client #627] Started training in communication round #16.[0m
[INFO][16:30:32]: [Client #556] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:30:32]: [93m[1m[Client #556] Started training in communication round #16.[0m
[INFO][16:30:34]: [Client #627] Loading the dataset.
[INFO][16:30:35]: [Client #556] Loading the dataset.
[INFO][16:30:42]: [Client #627] Epoch: [1/5][0/16]	Loss: 0.951605
[INFO][16:30:42]: [Client #556] Epoch: [1/5][0/20]	Loss: 0.865540
[INFO][16:30:42]: [Client #627] Epoch: [1/5][10/16]	Loss: 0.696188
[INFO][16:30:42]: [Client #627] Going to sleep for 1.51 seconds.
[INFO][16:30:42]: [Client #556] Epoch: [1/5][10/20]	Loss: 1.087313
[INFO][16:30:42]: [Client #556] Going to sleep for 0.45 seconds.
[INFO][16:30:42]: [Client #556] Woke up.
[INFO][16:30:42]: [Client #556] Epoch: [2/5][0/20]	Loss: 1.459524
[INFO][16:30:42]: [Client #556] Epoch: [2/5][10/20]	Loss: 1.705464
[INFO][16:30:42]: [Client #556] Going to sleep for 0.45 seconds.
[INFO][16:30:43]: [Client #556] Woke up.
[INFO][16:30:43]: [Client #556] Epoch: [3/5][0/20]	Loss: 0.841560
[INFO][16:30:43]: [Client #556] Epoch: [3/5][10/20]	Loss: 1.787143
[INFO][16:30:43]: [Client #556] Going to sleep for 0.45 seconds.
[INFO][16:30:43]: [Client #627] Woke up.
[INFO][16:30:43]: [Client #627] Epoch: [2/5][0/16]	Loss: 0.405487
[INFO][16:30:43]: [Client #627] Epoch: [2/5][10/16]	Loss: 1.425752
[INFO][16:30:43]: [Client #627] Going to sleep for 1.51 seconds.
[INFO][16:30:43]: [Client #556] Woke up.
[INFO][16:30:44]: [Client #556] Epoch: [4/5][0/20]	Loss: 0.919993
[INFO][16:30:44]: [Client #556] Epoch: [4/5][10/20]	Loss: 1.140624
[INFO][16:30:44]: [Client #556] Going to sleep for 0.45 seconds.
[INFO][16:30:44]: [Client #556] Woke up.
[INFO][16:30:44]: [Client #556] Epoch: [5/5][0/20]	Loss: 1.772989
[INFO][16:30:44]: [Client #556] Epoch: [5/5][10/20]	Loss: 1.188947
[INFO][16:30:44]: [Client #556] Going to sleep for 0.45 seconds.
[INFO][16:30:45]: [Client #556] Woke up.
[INFO][16:30:45]: [Client #556] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_556_615875.pth.
[INFO][16:30:45]: [Client #627] Woke up.
[INFO][16:30:45]: [Client #627] Epoch: [3/5][0/16]	Loss: 0.593768
[INFO][16:30:45]: [Client #627] Epoch: [3/5][10/16]	Loss: 0.670014
[INFO][16:30:45]: [Client #627] Going to sleep for 1.51 seconds.
[INFO][16:30:45]: [Client #556] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_556_615875.pth.
[INFO][16:30:45]: [Client #556] Model trained.
[INFO][16:30:45]: [Client #556] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:30:45]: [Server #615782] Received 0.26 MB of payload data from client #556 (simulated).
[INFO][16:30:46]: [Client #627] Woke up.
[INFO][16:30:47]: [Client #627] Epoch: [4/5][0/16]	Loss: 0.643831
[INFO][16:30:47]: [Client #627] Epoch: [4/5][10/16]	Loss: 0.706404
[INFO][16:30:47]: [Client #627] Going to sleep for 1.51 seconds.
[INFO][16:30:48]: [Client #627] Woke up.
[INFO][16:30:48]: [Client #627] Epoch: [5/5][0/16]	Loss: 0.613779
[INFO][16:30:48]: [Client #627] Epoch: [5/5][10/16]	Loss: 2.121372
[INFO][16:30:48]: [Client #627] Going to sleep for 1.51 seconds.
[INFO][16:30:50]: [Client #627] Woke up.
[INFO][16:30:50]: [Client #627] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_627_615874.pth.
[INFO][16:30:50]: [Client #627] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_627_615874.pth.
[INFO][16:30:50]: [Client #627] Model trained.
[INFO][16:30:50]: [Client #627] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:30:51]: [Server #615782] Received 0.26 MB of payload data from client #627 (simulated).
[INFO][16:30:51]: [Server #615782] Selecting client #936 for training.
[INFO][16:30:51]: [Server #615782] Sending the current model to client #936 (simulated).
[INFO][16:30:51]: [Server #615782] Sending 0.26 MB of payload data to client #936 (simulated).
[INFO][16:30:51]: [Server #615782] Selecting client #864 for training.
[INFO][16:30:51]: [Server #615782] Sending the current model to client #864 (simulated).
[INFO][16:30:51]: [Server #615782] Sending 0.26 MB of payload data to client #864 (simulated).
[INFO][16:30:51]: [Client #936] Selected by the server.
[INFO][16:30:51]: [Client #936] Loading its data source...
[INFO][16:30:51]: Data source: FEMNIST
[INFO][16:30:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:30:51]: [Client #864] Selected by the server.
[INFO][16:30:51]: [Client #864] Loading its data source...
[INFO][16:30:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/936.zip.
[INFO][16:30:51]: Data source: FEMNIST
[INFO][16:30:51]: [Client #864] Dataset size: 153
[INFO][16:30:51]: [Client #864] Sampler: all_inclusive
[INFO][16:30:51]: [Client #864] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:30:51]: [93m[1m[Client #864] Started training in communication round #16.[0m
2.6%5.2%7.7%10.3%12.9%15.5%18.0%20.6%23.2%25.8%28.4%30.9%33.5%36.1%38.7%41.3%43.8%46.4%49.0%51.6%54.1%56.7%59.3%61.9%64.5%67.0%69.6%72.2%74.8%77.4%79.9%82.5%85.1%87.7%90.2%92.8%95.4%98.0%100.0%[INFO][16:30:51]: Decompressing the dataset downloaded.
[INFO][16:30:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/936.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:30:51]: [Client #936] Dataset size: 164
[INFO][16:30:51]: [Client #936] Sampler: all_inclusive
[INFO][16:30:51]: [Client #936] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:30:51]: [93m[1m[Client #936] Started training in communication round #16.[0m

[INFO][16:30:53]: [Client #864] Loading the dataset.
[INFO][16:30:53]: [Client #936] Loading the dataset.
[INFO][16:31:00]: [Client #864] Epoch: [1/5][0/16]	Loss: 0.781916
[INFO][16:31:00]: [Client #936] Epoch: [1/5][0/17]	Loss: 0.720335
[INFO][16:31:00]: [Client #864] Epoch: [1/5][10/16]	Loss: 0.713725
[INFO][16:31:00]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][16:31:00]: [Client #936] Epoch: [1/5][10/17]	Loss: 1.169100
[INFO][16:31:00]: [Client #936] Going to sleep for 28.35 seconds.
[INFO][16:31:02]: [Client #864] Woke up.
[INFO][16:31:02]: [Client #864] Epoch: [2/5][0/16]	Loss: 0.601030
[INFO][16:31:02]: [Client #864] Epoch: [2/5][10/16]	Loss: 1.434247
[INFO][16:31:02]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][16:31:03]: [Client #864] Woke up.
[INFO][16:31:03]: [Client #864] Epoch: [3/5][0/16]	Loss: 0.730165
[INFO][16:31:04]: [Client #864] Epoch: [3/5][10/16]	Loss: 0.948669
[INFO][16:31:04]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][16:31:05]: [Client #864] Woke up.
[INFO][16:31:05]: [Client #864] Epoch: [4/5][0/16]	Loss: 0.069794
[INFO][16:31:05]: [Client #864] Epoch: [4/5][10/16]	Loss: 0.315477
[INFO][16:31:05]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][16:31:07]: [Client #864] Woke up.
[INFO][16:31:07]: [Client #864] Epoch: [5/5][0/16]	Loss: 1.077605
[INFO][16:31:07]: [Client #864] Epoch: [5/5][10/16]	Loss: 0.472210
[INFO][16:31:07]: [Client #864] Going to sleep for 1.50 seconds.
[INFO][16:31:08]: [Client #864] Woke up.
[INFO][16:31:08]: [Client #864] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615875.pth.
[INFO][16:31:09]: [Client #864] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_864_615875.pth.
[INFO][16:31:09]: [Client #864] Model trained.
[INFO][16:31:09]: [Client #864] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:31:09]: [Server #615782] Received 0.26 MB of payload data from client #864 (simulated).
[INFO][16:31:29]: [Client #936] Woke up.
[INFO][16:31:29]: [Client #936] Epoch: [2/5][0/17]	Loss: 0.325028
[INFO][16:31:29]: [Client #936] Epoch: [2/5][10/17]	Loss: 0.847150
[INFO][16:31:29]: [Client #936] Going to sleep for 28.35 seconds.
[INFO][16:31:57]: [Client #936] Woke up.
[INFO][16:31:58]: [Client #936] Epoch: [3/5][0/17]	Loss: 0.142325
[INFO][16:31:58]: [Client #936] Epoch: [3/5][10/17]	Loss: 1.391206
[INFO][16:31:58]: [Client #936] Going to sleep for 28.35 seconds.
[INFO][16:32:26]: [Client #936] Woke up.
[INFO][16:32:26]: [Client #936] Epoch: [4/5][0/17]	Loss: 1.090501
[INFO][16:32:26]: [Client #936] Epoch: [4/5][10/17]	Loss: 0.157043
[INFO][16:32:26]: [Client #936] Going to sleep for 28.35 seconds.
[INFO][16:32:55]: [Client #936] Woke up.
[INFO][16:32:55]: [Client #936] Epoch: [5/5][0/17]	Loss: 0.285616
[INFO][16:32:55]: [Client #936] Epoch: [5/5][10/17]	Loss: 0.992389
[INFO][16:32:55]: [Client #936] Going to sleep for 28.35 seconds.
[INFO][16:33:23]: [Client #936] Woke up.
[INFO][16:33:23]: [Client #936] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_936_615874.pth.
[INFO][16:33:24]: [Client #936] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_936_615874.pth.
[INFO][16:33:24]: [Client #936] Model trained.
[INFO][16:33:24]: [Client #936] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:33:24]: [Server #615782] Received 0.26 MB of payload data from client #936 (simulated).
[INFO][16:33:24]: [Server #615782] Selecting client #476 for training.
[INFO][16:33:24]: [Server #615782] Sending the current model to client #476 (simulated).
[INFO][16:33:24]: [Server #615782] Sending 0.26 MB of payload data to client #476 (simulated).
[INFO][16:33:24]: [Server #615782] Selecting client #553 for training.
[INFO][16:33:24]: [Server #615782] Sending the current model to client #553 (simulated).
[INFO][16:33:24]: [Server #615782] Sending 0.26 MB of payload data to client #553 (simulated).
[INFO][16:33:24]: [Client #476] Selected by the server.
[INFO][16:33:24]: [Client #553] Selected by the server.
[INFO][16:33:24]: [Client #476] Loading its data source...
[INFO][16:33:24]: [Client #553] Loading its data source...
[INFO][16:33:24]: Data source: FEMNIST
[INFO][16:33:24]: Data source: FEMNIST
[INFO][16:33:24]: [Client #553] Dataset size: 164
[INFO][16:33:24]: [Client #553] Sampler: all_inclusive
[INFO][16:33:24]: [Client #553] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:33:24]: [Client #476] Dataset size: 138
[INFO][16:33:24]: [Client #476] Sampler: all_inclusive
[INFO][16:33:24]: [93m[1m[Client #553] Started training in communication round #16.[0m
[INFO][16:33:24]: [Client #476] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:33:24]: [93m[1m[Client #476] Started training in communication round #16.[0m
[INFO][16:33:26]: [Client #553] Loading the dataset.
[INFO][16:33:26]: [Client #476] Loading the dataset.
[INFO][16:33:34]: [Client #476] Epoch: [1/5][0/14]	Loss: 1.006259
[INFO][16:33:34]: [Client #553] Epoch: [1/5][0/17]	Loss: 0.417848
[INFO][16:33:34]: [Client #476] Epoch: [1/5][10/14]	Loss: 1.340643
[INFO][16:33:34]: [Client #553] Epoch: [1/5][10/17]	Loss: 1.038414
[INFO][16:33:34]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][16:33:34]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][16:33:34]: [Client #476] Woke up.
[INFO][16:33:34]: [Client #476] Epoch: [2/5][0/14]	Loss: 1.394857
[INFO][16:33:34]: [Client #476] Epoch: [2/5][10/14]	Loss: 0.496544
[INFO][16:33:34]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][16:33:34]: [Client #476] Woke up.
[INFO][16:33:34]: [Client #476] Epoch: [3/5][0/14]	Loss: 1.244972
[INFO][16:33:34]: [Client #476] Epoch: [3/5][10/14]	Loss: 0.934929
[INFO][16:33:34]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][16:33:34]: [Client #476] Woke up.
[INFO][16:33:35]: [Client #476] Epoch: [4/5][0/14]	Loss: 1.546343
[INFO][16:33:35]: [Client #476] Epoch: [4/5][10/14]	Loss: 1.511723
[INFO][16:33:35]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][16:33:35]: [Client #476] Woke up.
[INFO][16:33:35]: [Client #476] Epoch: [5/5][0/14]	Loss: 1.233520
[INFO][16:33:35]: [Client #476] Epoch: [5/5][10/14]	Loss: 1.248445
[INFO][16:33:35]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][16:33:35]: [Client #476] Woke up.
[INFO][16:33:35]: [Client #476] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_615874.pth.
[INFO][16:33:35]: [Client #476] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_615874.pth.
[INFO][16:33:35]: [Client #476] Model trained.
[INFO][16:33:35]: [Client #476] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:33:35]: [Server #615782] Received 0.26 MB of payload data from client #476 (simulated).
[INFO][16:33:37]: [Client #553] Woke up.
[INFO][16:33:37]: [Client #553] Epoch: [2/5][0/17]	Loss: 1.211154
[INFO][16:33:37]: [Client #553] Epoch: [2/5][10/17]	Loss: 1.791321
[INFO][16:33:37]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][16:33:40]: [Client #553] Woke up.
[INFO][16:33:41]: [Client #553] Epoch: [3/5][0/17]	Loss: 0.702688
[INFO][16:33:41]: [Client #553] Epoch: [3/5][10/17]	Loss: 1.288121
[INFO][16:33:41]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][16:33:44]: [Client #553] Woke up.
[INFO][16:33:44]: [Client #553] Epoch: [4/5][0/17]	Loss: 0.633938
[INFO][16:33:44]: [Client #553] Epoch: [4/5][10/17]	Loss: 0.317262
[INFO][16:33:44]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][16:33:47]: [Client #553] Woke up.
[INFO][16:33:47]: [Client #553] Epoch: [5/5][0/17]	Loss: 0.067965
[INFO][16:33:47]: [Client #553] Epoch: [5/5][10/17]	Loss: 1.008748
[INFO][16:33:47]: [Client #553] Going to sleep for 3.08 seconds.
[INFO][16:33:50]: [Client #553] Woke up.
[INFO][16:33:50]: [Client #553] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615875.pth.
[INFO][16:33:51]: [Client #553] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_553_615875.pth.
[INFO][16:33:51]: [Client #553] Model trained.
[INFO][16:33:51]: [Client #553] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:33:51]: [Server #615782] Received 0.26 MB of payload data from client #553 (simulated).
[INFO][16:33:51]: [Server #615782] Selecting client #877 for training.
[INFO][16:33:51]: [Server #615782] Sending the current model to client #877 (simulated).
[INFO][16:33:51]: [Server #615782] Sending 0.26 MB of payload data to client #877 (simulated).
[INFO][16:33:51]: [Server #615782] Selecting client #950 for training.
[INFO][16:33:51]: [Server #615782] Sending the current model to client #950 (simulated).
[INFO][16:33:51]: [Server #615782] Sending 0.26 MB of payload data to client #950 (simulated).
[INFO][16:33:51]: [Client #877] Selected by the server.
[INFO][16:33:51]: [Client #877] Loading its data source...
[INFO][16:33:51]: Data source: FEMNIST
[INFO][16:33:51]: [Client #950] Selected by the server.
[INFO][16:33:51]: [Client #950] Loading its data source...
[INFO][16:33:51]: Data source: FEMNIST
[INFO][16:33:51]: [Client #950] Dataset size: 137
[INFO][16:33:51]: [Client #950] Sampler: all_inclusive
[INFO][16:33:51]: [Client #877] Dataset size: 152
[INFO][16:33:51]: [Client #877] Sampler: all_inclusive
[INFO][16:33:51]: [Client #950] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:33:51]: [Client #877] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:33:51]: [93m[1m[Client #950] Started training in communication round #16.[0m
[INFO][16:33:51]: [93m[1m[Client #877] Started training in communication round #16.[0m
[INFO][16:33:53]: [Client #950] Loading the dataset.
[INFO][16:33:53]: [Client #877] Loading the dataset.
[INFO][16:34:00]: [Client #950] Epoch: [1/5][0/14]	Loss: 1.138593
[INFO][16:34:00]: [Client #950] Epoch: [1/5][10/14]	Loss: 1.259395
[INFO][16:34:00]: [Client #877] Epoch: [1/5][0/16]	Loss: 0.729575
[INFO][16:34:00]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][16:34:01]: [Client #877] Epoch: [1/5][10/16]	Loss: 2.026487
[INFO][16:34:01]: [Client #877] Going to sleep for 0.40 seconds.
[INFO][16:34:01]: [Client #877] Woke up.
[INFO][16:34:01]: [Client #877] Epoch: [2/5][0/16]	Loss: 1.004438
[INFO][16:34:01]: [Client #877] Epoch: [2/5][10/16]	Loss: 1.396182
[INFO][16:34:01]: [Client #877] Going to sleep for 0.40 seconds.
[INFO][16:34:01]: [Client #950] Woke up.
[INFO][16:34:01]: [Client #950] Epoch: [2/5][0/14]	Loss: 0.400185
[INFO][16:34:01]: [Client #950] Epoch: [2/5][10/14]	Loss: 0.944061
[INFO][16:34:01]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][16:34:02]: [Client #877] Woke up.
[INFO][16:34:02]: [Client #877] Epoch: [3/5][0/16]	Loss: 0.295676
[INFO][16:34:02]: [Client #877] Epoch: [3/5][10/16]	Loss: 1.104761
[INFO][16:34:02]: [Client #877] Going to sleep for 0.40 seconds.
[INFO][16:34:02]: [Client #950] Woke up.
[INFO][16:34:02]: [Client #950] Epoch: [3/5][0/14]	Loss: 0.846078
[INFO][16:34:02]: [Client #950] Epoch: [3/5][10/14]	Loss: 1.386250
[INFO][16:34:02]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][16:34:02]: [Client #877] Woke up.
[INFO][16:34:02]: [Client #877] Epoch: [4/5][0/16]	Loss: 1.705366
[INFO][16:34:02]: [Client #877] Epoch: [4/5][10/16]	Loss: 1.179200
[INFO][16:34:02]: [Client #877] Going to sleep for 0.40 seconds.
[INFO][16:34:03]: [Client #877] Woke up.
[INFO][16:34:03]: [Client #877] Epoch: [5/5][0/16]	Loss: 0.763859
[INFO][16:34:03]: [Client #877] Epoch: [5/5][10/16]	Loss: 1.412602
[INFO][16:34:03]: [Client #950] Woke up.
[INFO][16:34:03]: [Client #950] Epoch: [4/5][0/14]	Loss: 0.657943
[INFO][16:34:03]: [Client #877] Going to sleep for 0.40 seconds.
[INFO][16:34:03]: [Client #950] Epoch: [4/5][10/14]	Loss: 0.810988
[INFO][16:34:03]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][16:34:03]: [Client #877] Woke up.
[INFO][16:34:03]: [Client #877] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_877_615874.pth.
[INFO][16:34:04]: [Client #950] Woke up.
[INFO][16:34:04]: [Client #950] Epoch: [5/5][0/14]	Loss: 0.418561
[INFO][16:34:04]: [Client #950] Epoch: [5/5][10/14]	Loss: 1.601385
[INFO][16:34:04]: [Client #950] Going to sleep for 0.66 seconds.
[INFO][16:34:04]: [Client #877] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_877_615874.pth.
[INFO][16:34:04]: [Client #877] Model trained.
[INFO][16:34:04]: [Client #877] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:04]: [Server #615782] Received 0.26 MB of payload data from client #877 (simulated).
[INFO][16:34:04]: [Client #950] Woke up.
[INFO][16:34:04]: [Client #950] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_950_615875.pth.
[INFO][16:34:05]: [Client #950] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_950_615875.pth.
[INFO][16:34:05]: [Client #950] Model trained.
[INFO][16:34:05]: [Client #950] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:05]: [Server #615782] Received 0.26 MB of payload data from client #950 (simulated).
[INFO][16:34:05]: [Server #615782] Selecting client #639 for training.
[INFO][16:34:05]: [Server #615782] Sending the current model to client #639 (simulated).
[INFO][16:34:05]: [Server #615782] Sending 0.26 MB of payload data to client #639 (simulated).
[INFO][16:34:05]: [Server #615782] Selecting client #748 for training.
[INFO][16:34:05]: [Server #615782] Sending the current model to client #748 (simulated).
[INFO][16:34:05]: [Server #615782] Sending 0.26 MB of payload data to client #748 (simulated).
[INFO][16:34:05]: [Client #639] Selected by the server.
[INFO][16:34:05]: [Client #639] Loading its data source...
[INFO][16:34:05]: [Client #748] Selected by the server.
[INFO][16:34:05]: Data source: FEMNIST
[INFO][16:34:05]: [Client #748] Loading its data source...
[INFO][16:34:05]: Data source: FEMNIST
[INFO][16:34:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:34:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/748.zip.
[INFO][16:34:05]: [Client #639] Dataset size: 155
[INFO][16:34:05]: [Client #639] Sampler: all_inclusive
[INFO][16:34:05]: [Client #639] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:05]: [93m[1m[Client #639] Started training in communication round #16.[0m
2.2%4.5%6.7%8.9%11.1%13.4%15.6%17.8%20.1%22.3%24.5%26.7%29.0%31.2%33.4%35.7%37.9%40.1%42.3%44.6%46.8%49.0%51.3%53.5%55.7%57.9%60.2%62.4%64.6%66.8%69.1%71.3%73.5%75.8%78.0%80.2%82.4%84.7%86.9%89.1%91.4%93.6%95.8%98.0%100.0%[INFO][16:34:05]: Decompressing the dataset downloaded.
[INFO][16:34:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/748.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:34:05]: [Client #748] Dataset size: 154
[INFO][16:34:05]: [Client #748] Sampler: all_inclusive
[INFO][16:34:05]: [Client #748] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:05]: [93m[1m[Client #748] Started training in communication round #16.[0m

[INFO][16:34:07]: [Client #639] Loading the dataset.
[INFO][16:34:07]: [Client #748] Loading the dataset.
[INFO][16:34:15]: [Client #639] Epoch: [1/5][0/16]	Loss: 1.326798
[INFO][16:34:15]: [Client #748] Epoch: [1/5][0/16]	Loss: 0.624964
[INFO][16:34:15]: [Client #639] Epoch: [1/5][10/16]	Loss: 0.865071
[INFO][16:34:15]: [Client #748] Epoch: [1/5][10/16]	Loss: 1.519870
[INFO][16:34:15]: [Client #639] Going to sleep for 0.65 seconds.
[INFO][16:34:15]: [Client #748] Going to sleep for 0.79 seconds.
[INFO][16:34:15]: [Client #639] Woke up.
[INFO][16:34:15]: [Client #639] Epoch: [2/5][0/16]	Loss: 0.953736
[INFO][16:34:15]: [Client #639] Epoch: [2/5][10/16]	Loss: 0.962843
[INFO][16:34:15]: [Client #748] Woke up.
[INFO][16:34:15]: [Client #639] Going to sleep for 0.65 seconds.
[INFO][16:34:15]: [Client #748] Epoch: [2/5][0/16]	Loss: 1.280480
[INFO][16:34:16]: [Client #748] Epoch: [2/5][10/16]	Loss: 1.586436
[INFO][16:34:16]: [Client #748] Going to sleep for 0.79 seconds.
[INFO][16:34:16]: [Client #639] Woke up.
[INFO][16:34:16]: [Client #639] Epoch: [3/5][0/16]	Loss: 0.640328
[INFO][16:34:16]: [Client #639] Epoch: [3/5][10/16]	Loss: 1.122221
[INFO][16:34:16]: [Client #639] Going to sleep for 0.65 seconds.
[INFO][16:34:16]: [Client #748] Woke up.
[INFO][16:34:16]: [Client #748] Epoch: [3/5][0/16]	Loss: 0.278093
[INFO][16:34:17]: [Client #748] Epoch: [3/5][10/16]	Loss: 0.875730
[INFO][16:34:17]: [Client #748] Going to sleep for 0.79 seconds.
[INFO][16:34:17]: [Client #639] Woke up.
[INFO][16:34:17]: [Client #639] Epoch: [4/5][0/16]	Loss: 0.556890
[INFO][16:34:17]: [Client #639] Epoch: [4/5][10/16]	Loss: 1.126921
[INFO][16:34:17]: [Client #639] Going to sleep for 0.65 seconds.
[INFO][16:34:17]: [Client #748] Woke up.
[INFO][16:34:17]: [Client #748] Epoch: [4/5][0/16]	Loss: 1.153646
[INFO][16:34:17]: [Client #748] Epoch: [4/5][10/16]	Loss: 0.722281
[INFO][16:34:17]: [Client #748] Going to sleep for 0.79 seconds.
[INFO][16:34:18]: [Client #639] Woke up.
[INFO][16:34:18]: [Client #639] Epoch: [5/5][0/16]	Loss: 1.381547
[INFO][16:34:18]: [Client #639] Epoch: [5/5][10/16]	Loss: 1.350839
[INFO][16:34:18]: [Client #639] Going to sleep for 0.65 seconds.
[INFO][16:34:18]: [Client #748] Woke up.
[INFO][16:34:18]: [Client #748] Epoch: [5/5][0/16]	Loss: 0.176285
[INFO][16:34:18]: [Client #748] Epoch: [5/5][10/16]	Loss: 0.719239
[INFO][16:34:18]: [Client #748] Going to sleep for 0.79 seconds.
[INFO][16:34:19]: [Client #639] Woke up.
[INFO][16:34:19]: [Client #639] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_639_615874.pth.
[INFO][16:34:19]: [Client #639] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_639_615874.pth.
[INFO][16:34:19]: [Client #748] Woke up.
[INFO][16:34:19]: [Client #748] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_748_615875.pth.
[INFO][16:34:19]: [Client #639] Model trained.
[INFO][16:34:19]: [Client #639] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:19]: [Server #615782] Received 0.26 MB of payload data from client #639 (simulated).
[INFO][16:34:20]: [Client #748] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_748_615875.pth.
[INFO][16:34:20]: [Client #748] Model trained.
[INFO][16:34:20]: [Client #748] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:20]: [Server #615782] Received 0.26 MB of payload data from client #748 (simulated).
[INFO][16:34:20]: [Server #615782] Selecting client #350 for training.
[INFO][16:34:20]: [Server #615782] Sending the current model to client #350 (simulated).
[INFO][16:34:20]: [Server #615782] Sending 0.26 MB of payload data to client #350 (simulated).
[INFO][16:34:20]: [Server #615782] Selecting client #919 for training.
[INFO][16:34:20]: [Server #615782] Sending the current model to client #919 (simulated).
[INFO][16:34:20]: [Server #615782] Sending 0.26 MB of payload data to client #919 (simulated).
[INFO][16:34:20]: [Client #350] Selected by the server.
[INFO][16:34:20]: [Client #350] Loading its data source...
[INFO][16:34:20]: Data source: FEMNIST
[INFO][16:34:20]: [Client #919] Selected by the server.
[INFO][16:34:20]: [Client #919] Loading its data source...
[INFO][16:34:20]: Data source: FEMNIST
[INFO][16:34:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:34:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/919.zip.
[INFO][16:34:20]: [Client #350] Dataset size: 138
[INFO][16:34:20]: [Client #350] Sampler: all_inclusive
[INFO][16:34:20]: [Client #350] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:20]: [93m[1m[Client #350] Started training in communication round #16.[0m
2.5%5.0%7.5%10.0%12.5%15.1%17.6%20.1%22.6%25.1%27.6%30.1%32.6%35.1%37.6%40.1%42.7%45.2%47.7%50.2%52.7%55.2%57.7%60.2%62.7%65.2%67.7%70.3%72.8%75.3%77.8%80.3%82.8%85.3%87.8%90.3%92.8%95.3%97.9%100.0%[INFO][16:34:20]: Decompressing the dataset downloaded.
[INFO][16:34:20]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/919.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:34:20]: [Client #919] Dataset size: 151
[INFO][16:34:20]: [Client #919] Sampler: all_inclusive
[INFO][16:34:20]: [Client #919] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:20]: [93m[1m[Client #919] Started training in communication round #16.[0m

[INFO][16:34:22]: [Client #350] Loading the dataset.
[INFO][16:34:22]: [Client #919] Loading the dataset.
[INFO][16:34:29]: [Client #919] Epoch: [1/5][0/16]	Loss: 1.008889
[INFO][16:34:29]: [Client #919] Epoch: [1/5][10/16]	Loss: 0.753854
[INFO][16:34:29]: [Client #350] Epoch: [1/5][0/14]	Loss: 1.098893
[INFO][16:34:29]: [Client #919] Going to sleep for 0.98 seconds.
[INFO][16:34:30]: [Client #350] Epoch: [1/5][10/14]	Loss: 2.190228
[INFO][16:34:30]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][16:34:30]: [Client #350] Woke up.
[INFO][16:34:30]: [Client #350] Epoch: [2/5][0/14]	Loss: 1.216190
[INFO][16:34:30]: [Client #350] Epoch: [2/5][10/14]	Loss: 1.634762
[INFO][16:34:30]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][16:34:30]: [Client #350] Woke up.
[INFO][16:34:30]: [Client #350] Epoch: [3/5][0/14]	Loss: 0.455305
[INFO][16:34:30]: [Client #350] Epoch: [3/5][10/14]	Loss: 1.331560
[INFO][16:34:30]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][16:34:30]: [Client #350] Woke up.
[INFO][16:34:30]: [Client #350] Epoch: [4/5][0/14]	Loss: 0.543730
[INFO][16:34:30]: [Client #350] Epoch: [4/5][10/14]	Loss: 1.380721
[INFO][16:34:30]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][16:34:30]: [Client #350] Woke up.
[INFO][16:34:30]: [Client #350] Epoch: [5/5][0/14]	Loss: 0.431114
[INFO][16:34:30]: [Client #350] Epoch: [5/5][10/14]	Loss: 1.290101
[INFO][16:34:30]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][16:34:30]: [Client #350] Woke up.
[INFO][16:34:30]: [Client #350] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_350_615874.pth.
[INFO][16:34:30]: [Client #919] Woke up.
[INFO][16:34:30]: [Client #919] Epoch: [2/5][0/16]	Loss: 0.472827
[INFO][16:34:31]: [Client #919] Epoch: [2/5][10/16]	Loss: 0.583584
[INFO][16:34:31]: [Client #919] Going to sleep for 0.98 seconds.
[INFO][16:34:31]: [Client #350] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_350_615874.pth.
[INFO][16:34:31]: [Client #350] Model trained.
[INFO][16:34:31]: [Client #350] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:31]: [Server #615782] Received 0.26 MB of payload data from client #350 (simulated).
[INFO][16:34:32]: [Client #919] Woke up.
[INFO][16:34:32]: [Client #919] Epoch: [3/5][0/16]	Loss: 1.009720
[INFO][16:34:32]: [Client #919] Epoch: [3/5][10/16]	Loss: 0.457953
[INFO][16:34:32]: [Client #919] Going to sleep for 0.98 seconds.
[INFO][16:34:33]: [Client #919] Woke up.
[INFO][16:34:33]: [Client #919] Epoch: [4/5][0/16]	Loss: 0.858270
[INFO][16:34:33]: [Client #919] Epoch: [4/5][10/16]	Loss: 0.559632
[INFO][16:34:33]: [Client #919] Going to sleep for 0.98 seconds.
[INFO][16:34:34]: [Client #919] Woke up.
[INFO][16:34:34]: [Client #919] Epoch: [5/5][0/16]	Loss: 1.428843
[INFO][16:34:34]: [Client #919] Epoch: [5/5][10/16]	Loss: 2.245592
[INFO][16:34:34]: [Client #919] Going to sleep for 0.98 seconds.
[INFO][16:34:35]: [Client #919] Woke up.
[INFO][16:34:35]: [Client #919] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_919_615875.pth.
[INFO][16:34:36]: [Client #919] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_919_615875.pth.
[INFO][16:34:36]: [Client #919] Model trained.
[INFO][16:34:36]: [Client #919] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:36]: [Server #615782] Received 0.26 MB of payload data from client #919 (simulated).
[INFO][16:34:36]: [Server #615782] Selecting client #836 for training.
[INFO][16:34:36]: [Server #615782] Sending the current model to client #836 (simulated).
[INFO][16:34:36]: [Server #615782] Sending 0.26 MB of payload data to client #836 (simulated).
[INFO][16:34:36]: [Server #615782] Selecting client #551 for training.
[INFO][16:34:36]: [Server #615782] Sending the current model to client #551 (simulated).
[INFO][16:34:36]: [Server #615782] Sending 0.26 MB of payload data to client #551 (simulated).
[INFO][16:34:36]: [Client #836] Selected by the server.
[INFO][16:34:36]: [Client #551] Selected by the server.
[INFO][16:34:36]: [Client #836] Loading its data source...
[INFO][16:34:36]: [Client #551] Loading its data source...
[INFO][16:34:36]: Data source: FEMNIST
[INFO][16:34:36]: Data source: FEMNIST
[INFO][16:34:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:34:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/551.zip.
[INFO][16:34:36]: [Client #836] Dataset size: 144
[INFO][16:34:36]: [Client #836] Sampler: all_inclusive
[INFO][16:34:36]: [Client #836] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:36]: [93m[1m[Client #836] Started training in communication round #16.[0m
2.5%4.9%7.4%9.9%12.4%14.8%17.3%19.8%22.2%24.7%27.2%29.7%32.1%34.6%37.1%39.5%42.0%44.5%47.0%49.4%51.9%54.4%56.8%59.3%61.8%64.3%66.7%69.2%71.7%74.1%76.6%79.1%81.6%84.0%86.5%89.0%91.4%93.9%96.4%98.9%100.0%[INFO][16:34:36]: Decompressing the dataset downloaded.
[INFO][16:34:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/551.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:34:36]: [Client #551] Dataset size: 140
[INFO][16:34:36]: [Client #551] Sampler: all_inclusive
[INFO][16:34:36]: [Client #551] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:34:36]: [93m[1m[Client #551] Started training in communication round #16.[0m

[INFO][16:34:38]: [Client #836] Loading the dataset.
[INFO][16:34:38]: [Client #551] Loading the dataset.
[INFO][16:34:45]: [Client #551] Epoch: [1/5][0/14]	Loss: 1.095667
[INFO][16:34:45]: [Client #551] Epoch: [1/5][10/14]	Loss: 0.813543
[INFO][16:34:45]: [Client #551] Going to sleep for 0.51 seconds.
[INFO][16:34:45]: [Client #836] Epoch: [1/5][0/15]	Loss: 2.030891
[INFO][16:34:45]: [Client #836] Epoch: [1/5][10/15]	Loss: 1.377963
[INFO][16:34:45]: [Client #836] Going to sleep for 7.02 seconds.
[INFO][16:34:45]: [Client #551] Woke up.
[INFO][16:34:45]: [Client #551] Epoch: [2/5][0/14]	Loss: 1.044075
[INFO][16:34:45]: [Client #551] Epoch: [2/5][10/14]	Loss: 1.100272
[INFO][16:34:45]: [Client #551] Going to sleep for 0.51 seconds.
[INFO][16:34:46]: [Client #551] Woke up.
[INFO][16:34:46]: [Client #551] Epoch: [3/5][0/14]	Loss: 0.475981
[INFO][16:34:46]: [Client #551] Epoch: [3/5][10/14]	Loss: 1.428846
[INFO][16:34:46]: [Client #551] Going to sleep for 0.51 seconds.
[INFO][16:34:47]: [Client #551] Woke up.
[INFO][16:34:47]: [Client #551] Epoch: [4/5][0/14]	Loss: 0.133859
[INFO][16:34:47]: [Client #551] Epoch: [4/5][10/14]	Loss: 1.867311
[INFO][16:34:47]: [Client #551] Going to sleep for 0.51 seconds.
[INFO][16:34:47]: [Client #551] Woke up.
[INFO][16:34:47]: [Client #551] Epoch: [5/5][0/14]	Loss: 0.630119
[INFO][16:34:47]: [Client #551] Epoch: [5/5][10/14]	Loss: 0.766090
[INFO][16:34:47]: [Client #551] Going to sleep for 0.51 seconds.
[INFO][16:34:48]: [Client #551] Woke up.
[INFO][16:34:48]: [Client #551] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_551_615875.pth.
[INFO][16:34:48]: [Client #551] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_551_615875.pth.
[INFO][16:34:48]: [Client #551] Model trained.
[INFO][16:34:48]: [Client #551] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:34:48]: [Server #615782] Received 0.26 MB of payload data from client #551 (simulated).
[INFO][16:34:52]: [Client #836] Woke up.
[INFO][16:34:52]: [Client #836] Epoch: [2/5][0/15]	Loss: 1.011784
[INFO][16:34:52]: [Client #836] Epoch: [2/5][10/15]	Loss: 1.370314
[INFO][16:34:52]: [Client #836] Going to sleep for 7.02 seconds.
[INFO][16:34:59]: [Client #836] Woke up.
[INFO][16:34:59]: [Client #836] Epoch: [3/5][0/15]	Loss: 0.964548
[INFO][16:34:59]: [Client #836] Epoch: [3/5][10/15]	Loss: 0.819478
[INFO][16:34:59]: [Client #836] Going to sleep for 7.02 seconds.
[INFO][16:35:06]: [Client #836] Woke up.
[INFO][16:35:06]: [Client #836] Epoch: [4/5][0/15]	Loss: 1.061869
[INFO][16:35:06]: [Client #836] Epoch: [4/5][10/15]	Loss: 0.914403
[INFO][16:35:07]: [Client #836] Going to sleep for 7.02 seconds.
[INFO][16:35:14]: [Client #836] Woke up.
[INFO][16:35:14]: [Client #836] Epoch: [5/5][0/15]	Loss: 0.938387
[INFO][16:35:14]: [Client #836] Epoch: [5/5][10/15]	Loss: 0.481870
[INFO][16:35:14]: [Client #836] Going to sleep for 7.02 seconds.
[INFO][16:35:21]: [Client #836] Woke up.
[INFO][16:35:21]: [Client #836] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_836_615874.pth.
[INFO][16:35:21]: [Client #836] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_836_615874.pth.
[INFO][16:35:21]: [Client #836] Model trained.
[INFO][16:35:21]: [Client #836] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:35:21]: [Server #615782] Received 0.26 MB of payload data from client #836 (simulated).
[INFO][16:35:21]: [Server #615782] Selecting client #868 for training.
[INFO][16:35:21]: [Server #615782] Sending the current model to client #868 (simulated).
[INFO][16:35:21]: [Server #615782] Sending 0.26 MB of payload data to client #868 (simulated).
[INFO][16:35:21]: [Server #615782] Selecting client #849 for training.
[INFO][16:35:21]: [Server #615782] Sending the current model to client #849 (simulated).
[INFO][16:35:21]: [Server #615782] Sending 0.26 MB of payload data to client #849 (simulated).
[INFO][16:35:21]: [Client #868] Selected by the server.
[INFO][16:35:21]: [Client #868] Loading its data source...
[INFO][16:35:21]: [Client #849] Selected by the server.
[INFO][16:35:21]: Data source: FEMNIST
[INFO][16:35:21]: [Client #849] Loading its data source...
[INFO][16:35:21]: Data source: FEMNIST
[INFO][16:35:21]: [Client #868] Dataset size: 161
[INFO][16:35:21]: [Client #868] Sampler: all_inclusive
[INFO][16:35:21]: [Client #849] Dataset size: 162
[INFO][16:35:21]: [Client #849] Sampler: all_inclusive
[INFO][16:35:22]: [Client #868] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:35:22]: [Client #849] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:35:22]: [93m[1m[Client #849] Started training in communication round #16.[0m
[INFO][16:35:22]: [93m[1m[Client #868] Started training in communication round #16.[0m
[INFO][16:35:24]: [Client #849] Loading the dataset.
[INFO][16:35:24]: [Client #868] Loading the dataset.
[INFO][16:35:31]: [Client #849] Epoch: [1/5][0/17]	Loss: 0.395338
[INFO][16:35:31]: [Client #868] Epoch: [1/5][0/17]	Loss: 0.386775
[INFO][16:35:31]: [Client #849] Epoch: [1/5][10/17]	Loss: 0.574545
[INFO][16:35:31]: [Client #868] Epoch: [1/5][10/17]	Loss: 0.659761
[INFO][16:35:31]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][16:35:31]: [Client #868] Going to sleep for 12.28 seconds.
[INFO][16:35:32]: [Client #849] Woke up.
[INFO][16:35:32]: [Client #849] Epoch: [2/5][0/17]	Loss: 0.478973
[INFO][16:35:32]: [Client #849] Epoch: [2/5][10/17]	Loss: 0.912347
[INFO][16:35:32]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][16:35:33]: [Client #849] Woke up.
[INFO][16:35:33]: [Client #849] Epoch: [3/5][0/17]	Loss: 2.074136
[INFO][16:35:33]: [Client #849] Epoch: [3/5][10/17]	Loss: 0.301835
[INFO][16:35:33]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][16:35:34]: [Client #849] Woke up.
[INFO][16:35:34]: [Client #849] Epoch: [4/5][0/17]	Loss: 1.399191
[INFO][16:35:34]: [Client #849] Epoch: [4/5][10/17]	Loss: 1.127061
[INFO][16:35:35]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][16:35:36]: [Client #849] Woke up.
[INFO][16:35:36]: [Client #849] Epoch: [5/5][0/17]	Loss: 1.632468
[INFO][16:35:36]: [Client #849] Epoch: [5/5][10/17]	Loss: 0.235901
[INFO][16:35:36]: [Client #849] Going to sleep for 1.04 seconds.
[INFO][16:35:37]: [Client #849] Woke up.
[INFO][16:35:37]: [Client #849] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_849_615875.pth.
[INFO][16:35:37]: [Client #849] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_849_615875.pth.
[INFO][16:35:37]: [Client #849] Model trained.
[INFO][16:35:37]: [Client #849] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:35:37]: [Server #615782] Received 0.26 MB of payload data from client #849 (simulated).
[INFO][16:35:43]: [Client #868] Woke up.
[INFO][16:35:43]: [Client #868] Epoch: [2/5][0/17]	Loss: 1.174904
[INFO][16:35:43]: [Client #868] Epoch: [2/5][10/17]	Loss: 0.487212
[INFO][16:35:43]: [Client #868] Going to sleep for 12.28 seconds.
[INFO][16:35:56]: [Client #868] Woke up.
[INFO][16:35:56]: [Client #868] Epoch: [3/5][0/17]	Loss: 0.365291
[INFO][16:35:56]: [Client #868] Epoch: [3/5][10/17]	Loss: 0.315782
[INFO][16:35:56]: [Client #868] Going to sleep for 12.28 seconds.
[INFO][16:36:08]: [Client #868] Woke up.
[INFO][16:36:08]: [Client #868] Epoch: [4/5][0/17]	Loss: 1.247530
[INFO][16:36:08]: [Client #868] Epoch: [4/5][10/17]	Loss: 2.085140
[INFO][16:36:08]: [Client #868] Going to sleep for 12.28 seconds.
[INFO][16:36:21]: [Client #868] Woke up.
[INFO][16:36:21]: [Client #868] Epoch: [5/5][0/17]	Loss: 1.634726
[INFO][16:36:21]: [Client #868] Epoch: [5/5][10/17]	Loss: 1.253999
[INFO][16:36:21]: [Client #868] Going to sleep for 12.28 seconds.
[INFO][16:36:33]: [Client #868] Woke up.
[INFO][16:36:33]: [Client #868] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_868_615874.pth.
[INFO][16:36:34]: [Client #868] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_868_615874.pth.
[INFO][16:36:34]: [Client #868] Model trained.
[INFO][16:36:34]: [Client #868] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:36:34]: [Server #615782] Received 0.26 MB of payload data from client #868 (simulated).
[INFO][16:36:34]: [Server #615782] Selecting client #808 for training.
[INFO][16:36:34]: [Server #615782] Sending the current model to client #808 (simulated).
[INFO][16:36:34]: [Server #615782] Sending 0.26 MB of payload data to client #808 (simulated).
[INFO][16:36:34]: [Server #615782] Selecting client #131 for training.
[INFO][16:36:34]: [Server #615782] Sending the current model to client #131 (simulated).
[INFO][16:36:34]: [Server #615782] Sending 0.26 MB of payload data to client #131 (simulated).
[INFO][16:36:34]: [Client #808] Selected by the server.
[INFO][16:36:34]: [Client #808] Loading its data source...
[INFO][16:36:34]: Data source: FEMNIST
[INFO][16:36:34]: [Client #131] Selected by the server.
[INFO][16:36:34]: [Client #131] Loading its data source...
[INFO][16:36:34]: Data source: FEMNIST
[INFO][16:36:34]: [Client #808] Dataset size: 144
[INFO][16:36:34]: [Client #808] Sampler: all_inclusive
[INFO][16:36:34]: [Client #808] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:36:34]: [93m[1m[Client #808] Started training in communication round #16.[0m
[INFO][16:36:34]: [Client #131] Dataset size: 157
[INFO][16:36:34]: [Client #131] Sampler: all_inclusive
[INFO][16:36:34]: [Client #131] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:36:34]: [93m[1m[Client #131] Started training in communication round #16.[0m
[INFO][16:36:36]: [Client #808] Loading the dataset.
[INFO][16:36:36]: [Client #131] Loading the dataset.
[INFO][16:36:43]: [Client #131] Epoch: [1/5][0/16]	Loss: 0.558058
[INFO][16:36:43]: [Client #808] Epoch: [1/5][0/15]	Loss: 1.031023
[INFO][16:36:43]: [Client #131] Epoch: [1/5][10/16]	Loss: 1.010232
[INFO][16:36:43]: [Client #808] Epoch: [1/5][10/15]	Loss: 1.154473
[INFO][16:36:43]: [Client #131] Going to sleep for 1.41 seconds.
[INFO][16:36:43]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][16:36:44]: [Client #131] Woke up.
[INFO][16:36:44]: [Client #131] Epoch: [2/5][0/16]	Loss: 1.182933
[INFO][16:36:44]: [Client #131] Epoch: [2/5][10/16]	Loss: 1.041203
[INFO][16:36:44]: [Client #131] Going to sleep for 1.41 seconds.
[INFO][16:36:44]: [Client #808] Woke up.
[INFO][16:36:45]: [Client #808] Epoch: [2/5][0/15]	Loss: 1.099995
[INFO][16:36:45]: [Client #808] Epoch: [2/5][10/15]	Loss: 0.422407
[INFO][16:36:45]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][16:36:46]: [Client #131] Woke up.
[INFO][16:36:46]: [Client #131] Epoch: [3/5][0/16]	Loss: 0.927315
[INFO][16:36:46]: [Client #131] Epoch: [3/5][10/16]	Loss: 1.130290
[INFO][16:36:46]: [Client #131] Going to sleep for 1.41 seconds.
[INFO][16:36:46]: [Client #808] Woke up.
[INFO][16:36:46]: [Client #808] Epoch: [3/5][0/15]	Loss: 0.382420
[INFO][16:36:46]: [Client #808] Epoch: [3/5][10/15]	Loss: 0.386217
[INFO][16:36:46]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][16:36:47]: [Client #131] Woke up.
[INFO][16:36:47]: [Client #131] Epoch: [4/5][0/16]	Loss: 1.223032
[INFO][16:36:48]: [Client #131] Epoch: [4/5][10/16]	Loss: 0.763827
[INFO][16:36:48]: [Client #131] Going to sleep for 1.41 seconds.
[INFO][16:36:48]: [Client #808] Woke up.
[INFO][16:36:48]: [Client #808] Epoch: [4/5][0/15]	Loss: 0.076686
[INFO][16:36:48]: [Client #808] Epoch: [4/5][10/15]	Loss: 0.435618
[INFO][16:36:48]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][16:36:49]: [Client #131] Woke up.
[INFO][16:36:49]: [Client #131] Epoch: [5/5][0/16]	Loss: 0.352512
[INFO][16:36:49]: [Client #131] Epoch: [5/5][10/16]	Loss: 1.534523
[INFO][16:36:49]: [Client #131] Going to sleep for 1.41 seconds.
[INFO][16:36:50]: [Client #808] Woke up.
[INFO][16:36:50]: [Client #808] Epoch: [5/5][0/15]	Loss: 1.585288
[INFO][16:36:50]: [Client #808] Epoch: [5/5][10/15]	Loss: 0.003259
[INFO][16:36:50]: [Client #808] Going to sleep for 1.56 seconds.
[INFO][16:36:51]: [Client #131] Woke up.
[INFO][16:36:51]: [Client #131] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_131_615875.pth.
[INFO][16:36:51]: [Client #131] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_131_615875.pth.
[INFO][16:36:51]: [Client #131] Model trained.
[INFO][16:36:51]: [Client #808] Woke up.
[INFO][16:36:51]: [Client #808] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_808_615874.pth.
[INFO][16:36:51]: [Client #131] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:36:51]: [Server #615782] Received 0.26 MB of payload data from client #131 (simulated).
[INFO][16:36:52]: [Client #808] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_808_615874.pth.
[INFO][16:36:52]: [Client #808] Model trained.
[INFO][16:36:52]: [Client #808] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:36:52]: [Server #615782] Received 0.26 MB of payload data from client #808 (simulated).
[INFO][16:36:52]: [Server #615782] Selecting client #535 for training.
[INFO][16:36:52]: [Server #615782] Sending the current model to client #535 (simulated).
[INFO][16:36:52]: [Server #615782] Sending 0.26 MB of payload data to client #535 (simulated).
[INFO][16:36:52]: [Server #615782] Selecting client #902 for training.
[INFO][16:36:52]: [Server #615782] Sending the current model to client #902 (simulated).
[INFO][16:36:52]: [Server #615782] Sending 0.26 MB of payload data to client #902 (simulated).
[INFO][16:36:52]: [Client #535] Selected by the server.
[INFO][16:36:52]: [Client #535] Loading its data source...
[INFO][16:36:52]: Data source: FEMNIST
[INFO][16:36:52]: [Client #902] Selected by the server.
[INFO][16:36:52]: [Client #902] Loading its data source...
[INFO][16:36:52]: Data source: FEMNIST
[INFO][16:36:52]: [Client #535] Dataset size: 157
[INFO][16:36:52]: [Client #535] Sampler: all_inclusive
[INFO][16:36:52]: [Client #902] Dataset size: 163
[INFO][16:36:52]: [Client #902] Sampler: all_inclusive
[INFO][16:36:52]: [Client #535] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:36:52]: [Client #902] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:36:52]: [93m[1m[Client #902] Started training in communication round #16.[0m
[INFO][16:36:52]: [93m[1m[Client #535] Started training in communication round #16.[0m
[INFO][16:36:54]: [Client #535] Loading the dataset.
[INFO][16:36:54]: [Client #902] Loading the dataset.
[INFO][16:37:01]: [Client #902] Epoch: [1/5][0/17]	Loss: 0.964840
[INFO][16:37:01]: [Client #535] Epoch: [1/5][0/16]	Loss: 0.746316
[INFO][16:37:01]: [Client #902] Epoch: [1/5][10/17]	Loss: 0.899030
[INFO][16:37:02]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][16:37:02]: [Client #535] Epoch: [1/5][10/16]	Loss: 1.835566
[INFO][16:37:02]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:37:06]: [Client #535] Woke up.
[INFO][16:37:06]: [Client #535] Epoch: [2/5][0/16]	Loss: 0.327851
[INFO][16:37:06]: [Client #535] Epoch: [2/5][10/16]	Loss: 0.936015
[INFO][16:37:06]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:37:11]: [Client #535] Woke up.
[INFO][16:37:11]: [Client #535] Epoch: [3/5][0/16]	Loss: 0.433980
[INFO][16:37:11]: [Client #535] Epoch: [3/5][10/16]	Loss: 0.814478
[INFO][16:37:11]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:37:12]: [Client #902] Woke up.
[INFO][16:37:12]: [Client #902] Epoch: [2/5][0/17]	Loss: 0.300466
[INFO][16:37:12]: [Client #902] Epoch: [2/5][10/17]	Loss: 0.582405
[INFO][16:37:12]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][16:37:16]: [Client #535] Woke up.
[INFO][16:37:16]: [Client #535] Epoch: [4/5][0/16]	Loss: 1.026320
[INFO][16:37:16]: [Client #535] Epoch: [4/5][10/16]	Loss: 1.250602
[INFO][16:37:16]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:37:21]: [Client #535] Woke up.
[INFO][16:37:21]: [Client #535] Epoch: [5/5][0/16]	Loss: 0.689973
[INFO][16:37:21]: [Client #535] Epoch: [5/5][10/16]	Loss: 0.918877
[INFO][16:37:21]: [Client #535] Going to sleep for 4.69 seconds.
[INFO][16:37:22]: [Client #902] Woke up.
[INFO][16:37:22]: [Client #902] Epoch: [3/5][0/17]	Loss: 1.312881
[INFO][16:37:22]: [Client #902] Epoch: [3/5][10/17]	Loss: 0.234138
[INFO][16:37:22]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][16:37:26]: [Client #535] Woke up.
[INFO][16:37:26]: [Client #535] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_535_615874.pth.
[INFO][16:37:26]: [Client #535] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_535_615874.pth.
[INFO][16:37:26]: [Client #535] Model trained.
[INFO][16:37:26]: [Client #535] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:37:26]: [Server #615782] Received 0.26 MB of payload data from client #535 (simulated).
[INFO][16:37:33]: [Client #902] Woke up.
[INFO][16:37:33]: [Client #902] Epoch: [4/5][0/17]	Loss: 0.404168
[INFO][16:37:33]: [Client #902] Epoch: [4/5][10/17]	Loss: 0.574099
[INFO][16:37:33]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][16:37:43]: [Client #902] Woke up.
[INFO][16:37:43]: [Client #902] Epoch: [5/5][0/17]	Loss: 1.253692
[INFO][16:37:43]: [Client #902] Epoch: [5/5][10/17]	Loss: 0.364358
[INFO][16:37:43]: [Client #902] Going to sleep for 10.24 seconds.
[INFO][16:37:53]: [Client #902] Woke up.
[INFO][16:37:53]: [Client #902] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_902_615875.pth.
[INFO][16:37:54]: [Client #902] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_902_615875.pth.
[INFO][16:37:54]: [Client #902] Model trained.
[INFO][16:37:54]: [Client #902] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:37:54]: [Server #615782] Received 0.26 MB of payload data from client #902 (simulated).
[INFO][16:37:54]: [Server #615782] Selecting client #770 for training.
[INFO][16:37:54]: [Server #615782] Sending the current model to client #770 (simulated).
[INFO][16:37:54]: [Server #615782] Sending 0.26 MB of payload data to client #770 (simulated).
[INFO][16:37:54]: [Server #615782] Selecting client #419 for training.
[INFO][16:37:54]: [Server #615782] Sending the current model to client #419 (simulated).
[INFO][16:37:54]: [Server #615782] Sending 0.26 MB of payload data to client #419 (simulated).
[INFO][16:37:54]: [Client #419] Selected by the server.
[INFO][16:37:54]: [Client #770] Selected by the server.
[INFO][16:37:54]: [Client #419] Loading its data source...
[INFO][16:37:54]: [Client #770] Loading its data source...
[INFO][16:37:54]: Data source: FEMNIST
[INFO][16:37:54]: Data source: FEMNIST
[INFO][16:37:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:37:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/770.zip.
[INFO][16:37:54]: [Client #419] Dataset size: 145
[INFO][16:37:54]: [Client #419] Sampler: all_inclusive
[INFO][16:37:54]: [Client #419] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:37:54]: [93m[1m[Client #419] Started training in communication round #16.[0m
2.4%4.8%7.1%9.5%11.9%14.3%16.7%19.0%21.4%23.8%26.2%28.6%31.0%33.3%35.7%38.1%40.5%42.9%45.2%47.6%50.0%52.4%54.8%57.1%59.5%61.9%64.3%66.7%69.1%71.4%73.8%76.2%78.6%81.0%83.3%85.7%88.1%90.5%92.9%95.2%97.6%100.0%[INFO][16:37:54]: Decompressing the dataset downloaded.
[INFO][16:37:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/770.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:37:54]: [Client #770] Dataset size: 159
[INFO][16:37:54]: [Client #770] Sampler: all_inclusive
[INFO][16:37:54]: [Client #770] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:37:54]: [93m[1m[Client #770] Started training in communication round #16.[0m

[INFO][16:37:56]: [Client #419] Loading the dataset.
[INFO][16:37:56]: [Client #770] Loading the dataset.
[INFO][16:38:04]: [Client #770] Epoch: [1/5][0/16]	Loss: 0.367995
[INFO][16:38:04]: [Client #770] Epoch: [1/5][10/16]	Loss: 1.017784
[INFO][16:38:04]: [Client #419] Epoch: [1/5][0/15]	Loss: 0.792661
[INFO][16:38:04]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:38:04]: [Client #419] Epoch: [1/5][10/15]	Loss: 0.853769
[INFO][16:38:04]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][16:38:05]: [Client #770] Woke up.
[INFO][16:38:05]: [Client #770] Epoch: [2/5][0/16]	Loss: 0.346352
[INFO][16:38:05]: [Client #770] Epoch: [2/5][10/16]	Loss: 0.136373
[INFO][16:38:05]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:38:06]: [Client #770] Woke up.
[INFO][16:38:06]: [Client #770] Epoch: [3/5][0/16]	Loss: 1.066997
[INFO][16:38:06]: [Client #770] Epoch: [3/5][10/16]	Loss: 0.712076
[INFO][16:38:06]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:38:07]: [Client #770] Woke up.
[INFO][16:38:07]: [Client #770] Epoch: [4/5][0/16]	Loss: 0.547632
[INFO][16:38:07]: [Client #770] Epoch: [4/5][10/16]	Loss: 0.671203
[INFO][16:38:07]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:38:08]: [Client #770] Woke up.
[INFO][16:38:08]: [Client #770] Epoch: [5/5][0/16]	Loss: 0.854531
[INFO][16:38:08]: [Client #770] Epoch: [5/5][10/16]	Loss: 0.714485
[INFO][16:38:08]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:38:08]: [Client #419] Woke up.
[INFO][16:38:08]: [Client #419] Epoch: [2/5][0/15]	Loss: 1.797655
[INFO][16:38:09]: [Client #419] Epoch: [2/5][10/15]	Loss: 0.608581
[INFO][16:38:09]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][16:38:09]: [Client #770] Woke up.
[INFO][16:38:09]: [Client #770] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_770_615874.pth.
[INFO][16:38:10]: [Client #770] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_770_615874.pth.
[INFO][16:38:10]: [Client #770] Model trained.
[INFO][16:38:10]: [Client #770] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:38:10]: [Server #615782] Received 0.26 MB of payload data from client #770 (simulated).
[INFO][16:38:13]: [Client #419] Woke up.
[INFO][16:38:13]: [Client #419] Epoch: [3/5][0/15]	Loss: 0.715479
[INFO][16:38:13]: [Client #419] Epoch: [3/5][10/15]	Loss: 0.708682
[INFO][16:38:13]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][16:38:18]: [Client #419] Woke up.
[INFO][16:38:18]: [Client #419] Epoch: [4/5][0/15]	Loss: 1.361329
[INFO][16:38:18]: [Client #419] Epoch: [4/5][10/15]	Loss: 1.582792
[INFO][16:38:18]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][16:38:23]: [Client #419] Woke up.
[INFO][16:38:23]: [Client #419] Epoch: [5/5][0/15]	Loss: 0.922751
[INFO][16:38:23]: [Client #419] Epoch: [5/5][10/15]	Loss: 1.158156
[INFO][16:38:23]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][16:38:28]: [Client #419] Woke up.
[INFO][16:38:28]: [Client #419] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_615875.pth.
[INFO][16:38:28]: [Client #419] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_615875.pth.
[INFO][16:38:28]: [Client #419] Model trained.
[INFO][16:38:28]: [Client #419] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:38:28]: [Server #615782] Received 0.26 MB of payload data from client #419 (simulated).
[INFO][16:38:28]: [Server #615782] Selecting client #978 for training.
[INFO][16:38:28]: [Server #615782] Sending the current model to client #978 (simulated).
[INFO][16:38:28]: [Server #615782] Sending 0.26 MB of payload data to client #978 (simulated).
[INFO][16:38:28]: [Client #978] Selected by the server.
[INFO][16:38:28]: [Client #978] Loading its data source...
[INFO][16:38:28]: Data source: FEMNIST
[INFO][16:38:28]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:38:28]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/978.zip.
2.3%4.7%7.0%9.3%11.6%14.0%16.3%18.6%20.9%23.3%25.6%27.9%30.2%32.6%34.9%37.2%39.5%41.9%44.2%46.5%48.8%51.2%53.5%55.8%58.1%60.5%62.8%65.1%67.4%69.8%72.1%74.4%76.7%79.1%81.4%83.7%86.0%88.4%90.7%93.0%95.3%97.7%100.0%100.0%[INFO][16:38:29]: Decompressing the dataset downloaded.
[INFO][16:38:29]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/978.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:38:29]: [Client #978] Dataset size: 161
[INFO][16:38:29]: [Client #978] Sampler: all_inclusive
[INFO][16:38:29]: [Client #978] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:38:29]: [93m[1m[Client #978] Started training in communication round #16.[0m

[INFO][16:38:30]: [Client #978] Loading the dataset.
[INFO][16:38:37]: [Client #978] Epoch: [1/5][0/17]	Loss: 0.632650
[INFO][16:38:38]: [Client #978] Epoch: [1/5][10/17]	Loss: 1.310248
[INFO][16:38:38]: [Client #978] Going to sleep for 1.21 seconds.
[INFO][16:38:39]: [Client #978] Woke up.
[INFO][16:38:39]: [Client #978] Epoch: [2/5][0/17]	Loss: 0.311438
[INFO][16:38:39]: [Client #978] Epoch: [2/5][10/17]	Loss: 0.670811
[INFO][16:38:39]: [Client #978] Going to sleep for 1.21 seconds.
[INFO][16:38:40]: [Client #978] Woke up.
[INFO][16:38:40]: [Client #978] Epoch: [3/5][0/17]	Loss: 0.973319
[INFO][16:38:40]: [Client #978] Epoch: [3/5][10/17]	Loss: 0.907666
[INFO][16:38:40]: [Client #978] Going to sleep for 1.21 seconds.
[INFO][16:38:42]: [Client #978] Woke up.
[INFO][16:38:42]: [Client #978] Epoch: [4/5][0/17]	Loss: 0.726834
[INFO][16:38:42]: [Client #978] Epoch: [4/5][10/17]	Loss: 0.241652
[INFO][16:38:42]: [Client #978] Going to sleep for 1.21 seconds.
[INFO][16:38:43]: [Client #978] Woke up.
[INFO][16:38:43]: [Client #978] Epoch: [5/5][0/17]	Loss: 1.355675
[INFO][16:38:43]: [Client #978] Epoch: [5/5][10/17]	Loss: 1.794151
[INFO][16:38:43]: [Client #978] Going to sleep for 1.21 seconds.
[INFO][16:38:44]: [Client #978] Woke up.
[INFO][16:38:44]: [Client #978] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_978_615874.pth.
[INFO][16:38:45]: [Client #978] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_978_615874.pth.
[INFO][16:38:45]: [Client #978] Model trained.
[INFO][16:38:45]: [Client #978] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:38:45]: [Server #615782] Received 0.26 MB of payload data from client #978 (simulated).
[INFO][16:38:45]: [Server #615782] Adding client #350 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #476 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #877 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #551 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #556 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #950 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #639 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #748 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #919 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #770 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #849 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #978 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #131 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #808 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #627 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #864 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #553 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #419 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #535 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #836 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #902 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #868 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #936 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Adding client #531 to the list of clients for aggregation.
[INFO][16:38:45]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11149666 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07375527 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1099478  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07785999 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13654771 0.         0.         0.
 0.07875968 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06740117 0.
 0.13131374 0.         0.         0.13838528 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11957285 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10025282 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10780046 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06847078 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09650647 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10818909 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09007592 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.23232437
 0.         0.         0.         0.58315871 0.         0.15716629
 0.         0.         0.         0.         0.         0.
 0.18054365 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11662971 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.71601303 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05096254
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12043812 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.41124851
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11149666 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07375527 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1099478  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07785999 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13654771 0.         0.         0.
 0.07875968 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06740117 0.
 0.13131374 0.         0.         0.13838528 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11957285 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10025282 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10780046 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06847078 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09650647 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10818909 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09007592 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.23232437
 0.         0.         0.         0.58315871 0.         0.15716629
 0.         0.         0.         0.         0.         0.
 0.18054365 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11662971 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.71601303 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05096254
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12043812 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.41124851
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.0350013  0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.001      0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.04067358 0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.03767545 0.001      0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.001      0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.03647485 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.0357513  0.001      0.04226082 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.03756477 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02670469 0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.0357513  0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.001      0.001      0.001      0.001      0.04063039
 0.0386082  0.001      0.04196891 0.001      0.06692817 0.01709943
 0.04067358 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03626943 0.03889033
 0.04248705 0.001      0.001      0.05103627 0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.01093232 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.03137153 0.01937935 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.03826169
 0.0364004  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03989637 0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.04015544 0.03707545 0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.001
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.001      0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.03989637 0.001      0.001
 0.001      0.03810651 0.001      0.001      0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.04119171 0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.03613604
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04039105 0.0373057  0.03241574 0.03778932
 0.001      0.001      0.001      0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0373057  0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.04196891 0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.0399274  0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03963731
 0.001      0.02800639 0.001      0.04170984 0.001      0.03834197
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.001
 0.03937824 0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.04222798 0.001      0.04096448 0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03911917 0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03188474 0.04248705
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03767545 0.04076739
 0.03613604 0.03549223 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03551983 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.04170984
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][16:39:30]: [Server #615782] Global model accuracy: 57.26%

[INFO][16:39:30]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_16.pth.
[INFO][16:39:30]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_16.pth.
[INFO][16:39:30]: [93m[1m
[Server #615782] Starting round 17/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  9e-05  4e-10  4e-10
 6:  7.5999e+00  7.5998e+00  8e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  8e-05  5e-09  8e-10
 8:  7.5999e+00  7.5998e+00  6e-05  4e-09  7e-10
 9:  7.5999e+00  7.5998e+00  4e-05  1e-08  2e-09
10:  7.5998e+00  7.5998e+00  8e-06  3e-08  5e-09
11:  7.5998e+00  7.5998e+00  1e-06  5e-09  8e-10
Optimal solution found.
The calculated probability is:  [1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53836384e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53856732e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53841626e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53855543e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53818039e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53851785e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53858192e-05 1.53867127e-05
 1.53820601e-05 1.53867127e-05 1.53867127e-05 1.53792581e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53833108e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53842900e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53839476e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53855234e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53847750e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53842775e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53845762e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53740436e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.52987298e-05 1.53867127e-05
 9.84644380e-01 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53791590e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53830869e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.52702438e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53860118e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53839812e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53428389e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05 1.53867127e-05
 1.53867127e-05 1.53867127e-05 1.53867127e-05][INFO][16:39:33]: [Server #615782] Selected clients: [870 754 232 543 626 243 915 621 231 770 106 554  95 580 253 648 714 524
 656 813 807 619 451 408 876]
[INFO][16:39:33]: [Server #615782] Selecting client #870 for training.
[INFO][16:39:33]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][16:39:33]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][16:39:33]: [Server #615782] Selecting client #754 for training.
[INFO][16:39:33]: [Server #615782] Sending the current model to client #754 (simulated).
[INFO][16:39:33]: [Server #615782] Sending 0.26 MB of payload data to client #754 (simulated).
[INFO][16:39:33]: [Client #870] Selected by the server.
[INFO][16:39:33]: [Client #870] Loading its data source...
[INFO][16:39:33]: Data source: FEMNIST
[INFO][16:39:33]: [Client #754] Selected by the server.
[INFO][16:39:33]: [Client #754] Loading its data source...
[INFO][16:39:33]: Data source: FEMNIST
[INFO][16:39:33]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:39:33]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/754.zip.
[INFO][16:39:33]: [Client #870] Dataset size: 148
[INFO][16:39:33]: [Client #870] Sampler: all_inclusive
[INFO][16:39:33]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:39:33]: [93m[1m[Client #870] Started training in communication round #17.[0m
2.9%5.8%8.7%11.6%14.5%17.4%20.3%23.2%26.1%29.0%31.9%34.8%37.7%40.6%43.5%46.4%49.3%52.2%55.1%58.0%60.9%63.8%66.7%69.6%72.5%75.4%78.3%81.2%84.1%87.0%89.9%92.8%95.7%98.6%100.0%[INFO][16:39:33]: Decompressing the dataset downloaded.
[INFO][16:39:33]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/754.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:39:33]: [Client #754] Dataset size: 112
[INFO][16:39:33]: [Client #754] Sampler: all_inclusive
[INFO][16:39:33]: [Client #754] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:39:33]: [93m[1m[Client #754] Started training in communication round #17.[0m

[INFO][16:39:35]: [Client #870] Loading the dataset.
[INFO][16:39:35]: [Client #754] Loading the dataset.
[INFO][16:39:43]: [Client #870] Epoch: [1/5][0/15]	Loss: 0.930553
[INFO][16:39:43]: [Client #754] Epoch: [1/5][0/12]	Loss: 1.012834
[INFO][16:39:43]: [Client #870] Epoch: [1/5][10/15]	Loss: 0.383254
[INFO][16:39:43]: [Client #754] Epoch: [1/5][10/12]	Loss: 0.758946
[INFO][16:39:43]: [Client #754] Going to sleep for 8.61 seconds.
[INFO][16:39:43]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:39:51]: [Client #754] Woke up.
[INFO][16:39:51]: [Client #754] Epoch: [2/5][0/12]	Loss: 0.572141
[INFO][16:39:51]: [Client #754] Epoch: [2/5][10/12]	Loss: 0.580469
[INFO][16:39:51]: [Client #754] Going to sleep for 8.61 seconds.
[INFO][16:40:00]: [Client #754] Woke up.
[INFO][16:40:00]: [Client #754] Epoch: [3/5][0/12]	Loss: 0.979540
[INFO][16:40:00]: [Client #754] Epoch: [3/5][10/12]	Loss: 1.028712
[INFO][16:40:00]: [Client #754] Going to sleep for 8.61 seconds.
[INFO][16:40:09]: [Client #754] Woke up.
[INFO][16:40:09]: [Client #754] Epoch: [4/5][0/12]	Loss: 0.490886
[INFO][16:40:09]: [Client #754] Epoch: [4/5][10/12]	Loss: 0.748729
[INFO][16:40:09]: [Client #754] Going to sleep for 8.61 seconds.
[INFO][16:40:17]: [Client #754] Woke up.
[INFO][16:40:17]: [Client #754] Epoch: [5/5][0/12]	Loss: 1.080681
[INFO][16:40:18]: [Client #754] Epoch: [5/5][10/12]	Loss: 0.218010
[INFO][16:40:18]: [Client #754] Going to sleep for 8.61 seconds.
[INFO][16:40:26]: [Client #754] Woke up.
[INFO][16:40:26]: [Client #754] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_754_615875.pth.
[INFO][16:40:27]: [Client #754] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_754_615875.pth.
[INFO][16:40:27]: [Client #754] Model trained.
[INFO][16:40:27]: [Client #754] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:40:27]: [Server #615782] Received 0.26 MB of payload data from client #754 (simulated).
[INFO][16:40:43]: [Client #870] Woke up.
[INFO][16:40:43]: [Client #870] Epoch: [2/5][0/15]	Loss: 0.632640
[INFO][16:40:43]: [Client #870] Epoch: [2/5][10/15]	Loss: 0.859974
[INFO][16:40:43]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:41:43]: [Client #870] Woke up.
[INFO][16:41:43]: [Client #870] Epoch: [3/5][0/15]	Loss: 0.201177
[INFO][16:41:43]: [Client #870] Epoch: [3/5][10/15]	Loss: 0.649827
[INFO][16:41:43]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:42:43]: [Client #870] Woke up.
[INFO][16:42:43]: [Client #870] Epoch: [4/5][0/15]	Loss: 1.022534
[INFO][16:42:43]: [Client #870] Epoch: [4/5][10/15]	Loss: 0.479765
[INFO][16:42:44]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:43:44]: [Client #870] Woke up.
[INFO][16:43:44]: [Client #870] Epoch: [5/5][0/15]	Loss: 0.168611
[INFO][16:43:44]: [Client #870] Epoch: [5/5][10/15]	Loss: 1.141034
[INFO][16:43:44]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][16:44:44]: [Client #870] Woke up.
[INFO][16:44:44]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][16:44:45]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][16:44:45]: [Client #870] Model trained.
[INFO][16:44:45]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:44:45]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][16:44:45]: [Server #615782] Selecting client #232 for training.
[INFO][16:44:45]: [Server #615782] Sending the current model to client #232 (simulated).
[INFO][16:44:45]: [Server #615782] Sending 0.26 MB of payload data to client #232 (simulated).
[INFO][16:44:45]: [Server #615782] Selecting client #543 for training.
[INFO][16:44:45]: [Server #615782] Sending the current model to client #543 (simulated).
[INFO][16:44:45]: [Server #615782] Sending 0.26 MB of payload data to client #543 (simulated).
[INFO][16:44:45]: [Client #232] Selected by the server.
[INFO][16:44:45]: [Client #232] Loading its data source...
[INFO][16:44:45]: Data source: FEMNIST
[INFO][16:44:45]: [Client #543] Selected by the server.
[INFO][16:44:45]: [Client #543] Loading its data source...
[INFO][16:44:45]: Data source: FEMNIST
[INFO][16:44:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:44:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/543.zip.
[INFO][16:44:45]: [Client #232] Dataset size: 162
[INFO][16:44:45]: [Client #232] Sampler: all_inclusive
[INFO][16:44:45]: [Client #232] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:44:45]: [93m[1m[Client #232] Started training in communication round #17.[0m
2.4%4.9%7.3%9.7%12.1%14.6%17.0%19.4%21.8%24.3%26.7%29.1%31.5%34.0%36.4%38.8%41.2%43.7%46.1%48.5%51.0%53.4%55.8%58.2%60.7%63.1%65.5%67.9%70.4%72.8%75.2%77.6%80.1%82.5%84.9%87.3%89.8%92.2%94.6%97.1%99.5%100.0%[INFO][16:44:45]: Decompressing the dataset downloaded.
[INFO][16:44:45]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/543.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:44:45]: [Client #543] Dataset size: 146
[INFO][16:44:45]: [Client #543] Sampler: all_inclusive
[INFO][16:44:45]: [Client #543] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:44:45]: [93m[1m[Client #543] Started training in communication round #17.[0m

[INFO][16:44:47]: [Client #232] Loading the dataset.
[INFO][16:44:47]: [Client #543] Loading the dataset.
[INFO][16:44:54]: [Client #232] Epoch: [1/5][0/17]	Loss: 1.436561
[INFO][16:44:54]: [Client #543] Epoch: [1/5][0/15]	Loss: 0.678301
[INFO][16:44:54]: [Client #232] Epoch: [1/5][10/17]	Loss: 0.723775
[INFO][16:44:54]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][16:44:54]: [Client #543] Epoch: [1/5][10/15]	Loss: 1.421459
[INFO][16:44:54]: [Client #543] Going to sleep for 0.88 seconds.
[INFO][16:44:55]: [Client #543] Woke up.
[INFO][16:44:55]: [Client #543] Epoch: [2/5][0/15]	Loss: 0.450685
[INFO][16:44:55]: [Client #543] Epoch: [2/5][10/15]	Loss: 1.391989
[INFO][16:44:55]: [Client #543] Going to sleep for 0.88 seconds.
[INFO][16:44:55]: [Client #232] Woke up.
[INFO][16:44:55]: [Client #232] Epoch: [2/5][0/17]	Loss: 1.770099
[INFO][16:44:56]: [Client #232] Epoch: [2/5][10/17]	Loss: 0.885358
[INFO][16:44:56]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][16:44:56]: [Client #543] Woke up.
[INFO][16:44:56]: [Client #543] Epoch: [3/5][0/15]	Loss: 1.026247
[INFO][16:44:56]: [Client #543] Epoch: [3/5][10/15]	Loss: 1.548266
[INFO][16:44:56]: [Client #543] Going to sleep for 0.88 seconds.
[INFO][16:44:57]: [Client #232] Woke up.
[INFO][16:44:57]: [Client #232] Epoch: [3/5][0/17]	Loss: 1.344787
[INFO][16:44:57]: [Client #232] Epoch: [3/5][10/17]	Loss: 1.094105
[INFO][16:44:57]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][16:44:57]: [Client #543] Woke up.
[INFO][16:44:57]: [Client #543] Epoch: [4/5][0/15]	Loss: 0.407092
[INFO][16:44:57]: [Client #543] Epoch: [4/5][10/15]	Loss: 0.735942
[INFO][16:44:57]: [Client #543] Going to sleep for 0.88 seconds.
[INFO][16:44:58]: [Client #232] Woke up.
[INFO][16:44:58]: [Client #232] Epoch: [4/5][0/17]	Loss: 1.094462
[INFO][16:44:58]: [Client #543] Woke up.
[INFO][16:44:58]: [Client #543] Epoch: [5/5][0/15]	Loss: 1.938929
[INFO][16:44:58]: [Client #232] Epoch: [4/5][10/17]	Loss: 0.849293
[INFO][16:44:58]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][16:44:58]: [Client #543] Epoch: [5/5][10/15]	Loss: 1.392918
[INFO][16:44:58]: [Client #543] Going to sleep for 0.88 seconds.
[INFO][16:44:59]: [Client #543] Woke up.
[INFO][16:44:59]: [Client #543] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_543_615875.pth.
[INFO][16:44:59]: [Client #232] Woke up.
[INFO][16:44:59]: [Client #232] Epoch: [5/5][0/17]	Loss: 1.032798
[INFO][16:45:00]: [Client #232] Epoch: [5/5][10/17]	Loss: 1.113823
[INFO][16:45:00]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][16:45:00]: [Client #543] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_543_615875.pth.
[INFO][16:45:00]: [Client #543] Model trained.
[INFO][16:45:00]: [Client #543] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:45:00]: [Server #615782] Received 0.26 MB of payload data from client #543 (simulated).
[INFO][16:45:01]: [Client #232] Woke up.
[INFO][16:45:01]: [Client #232] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_615874.pth.
[INFO][16:45:01]: [Client #232] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_615874.pth.
[INFO][16:45:01]: [Client #232] Model trained.
[INFO][16:45:01]: [Client #232] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:45:02]: [Server #615782] Received 0.26 MB of payload data from client #232 (simulated).
[INFO][16:45:02]: [Server #615782] Selecting client #626 for training.
[INFO][16:45:02]: [Server #615782] Sending the current model to client #626 (simulated).
[INFO][16:45:02]: [Server #615782] Sending 0.26 MB of payload data to client #626 (simulated).
[INFO][16:45:02]: [Server #615782] Selecting client #243 for training.
[INFO][16:45:02]: [Server #615782] Sending the current model to client #243 (simulated).
[INFO][16:45:02]: [Server #615782] Sending 0.26 MB of payload data to client #243 (simulated).
[INFO][16:45:02]: [Client #626] Selected by the server.
[INFO][16:45:02]: [Client #626] Loading its data source...
[INFO][16:45:02]: Data source: FEMNIST
[INFO][16:45:02]: [Client #243] Selected by the server.
[INFO][16:45:02]: [Client #243] Loading its data source...
[INFO][16:45:02]: Data source: FEMNIST
[INFO][16:45:02]: [Client #626] Dataset size: 162
[INFO][16:45:02]: [Client #626] Sampler: all_inclusive
[INFO][16:45:02]: [Client #626] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:45:02]: [93m[1m[Client #626] Started training in communication round #17.[0m
[INFO][16:45:02]: [Client #243] Dataset size: 159
[INFO][16:45:02]: [Client #243] Sampler: all_inclusive
[INFO][16:45:02]: [Client #243] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:45:02]: [93m[1m[Client #243] Started training in communication round #17.[0m
[INFO][16:45:04]: [Client #626] Loading the dataset.
[INFO][16:45:04]: [Client #243] Loading the dataset.
[INFO][16:45:11]: [Client #626] Epoch: [1/5][0/17]	Loss: 0.946369
[INFO][16:45:11]: [Client #626] Epoch: [1/5][10/17]	Loss: 0.952942
[INFO][16:45:11]: [Client #243] Epoch: [1/5][0/16]	Loss: 1.012417
[INFO][16:45:11]: [Client #626] Going to sleep for 0.27 seconds.
[INFO][16:45:11]: [Client #243] Epoch: [1/5][10/16]	Loss: 1.198421
[INFO][16:45:11]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][16:45:11]: [Client #626] Woke up.
[INFO][16:45:11]: [Client #626] Epoch: [2/5][0/17]	Loss: 0.616868
[INFO][16:45:11]: [Client #626] Epoch: [2/5][10/17]	Loss: 0.323667
[INFO][16:45:11]: [Client #626] Going to sleep for 0.27 seconds.
[INFO][16:45:12]: [Client #626] Woke up.
[INFO][16:45:12]: [Client #626] Epoch: [3/5][0/17]	Loss: 0.266655
[INFO][16:45:12]: [Client #626] Epoch: [3/5][10/17]	Loss: 2.129215
[INFO][16:45:12]: [Client #626] Going to sleep for 0.27 seconds.
[INFO][16:45:12]: [Client #626] Woke up.
[INFO][16:45:12]: [Client #626] Epoch: [4/5][0/17]	Loss: 0.089146
[INFO][16:45:12]: [Client #626] Epoch: [4/5][10/17]	Loss: 0.849699
[INFO][16:45:12]: [Client #626] Going to sleep for 0.27 seconds.
[INFO][16:45:12]: [Client #243] Woke up.
[INFO][16:45:12]: [Client #243] Epoch: [2/5][0/16]	Loss: 0.069329
[INFO][16:45:12]: [Client #626] Woke up.
[INFO][16:45:13]: [Client #626] Epoch: [5/5][0/17]	Loss: 0.264909
[INFO][16:45:13]: [Client #243] Epoch: [2/5][10/16]	Loss: 0.632346
[INFO][16:45:13]: [Client #626] Epoch: [5/5][10/17]	Loss: 1.175961
[INFO][16:45:13]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][16:45:13]: [Client #626] Going to sleep for 0.27 seconds.
[INFO][16:45:13]: [Client #626] Woke up.
[INFO][16:45:13]: [Client #626] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_626_615874.pth.
[INFO][16:45:14]: [Client #626] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_626_615874.pth.
[INFO][16:45:14]: [Client #626] Model trained.
[INFO][16:45:14]: [Client #626] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:45:14]: [Server #615782] Received 0.26 MB of payload data from client #626 (simulated).
[INFO][16:45:14]: [Client #243] Woke up.
[INFO][16:45:14]: [Client #243] Epoch: [3/5][0/16]	Loss: 1.325791
[INFO][16:45:14]: [Client #243] Epoch: [3/5][10/16]	Loss: 0.785014
[INFO][16:45:14]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][16:45:15]: [Client #243] Woke up.
[INFO][16:45:15]: [Client #243] Epoch: [4/5][0/16]	Loss: 1.016022
[INFO][16:45:16]: [Client #243] Epoch: [4/5][10/16]	Loss: 1.002990
[INFO][16:45:16]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][16:45:17]: [Client #243] Woke up.
[INFO][16:45:17]: [Client #243] Epoch: [5/5][0/16]	Loss: 0.333679
[INFO][16:45:17]: [Client #243] Epoch: [5/5][10/16]	Loss: 1.028340
[INFO][16:45:17]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][16:45:18]: [Client #243] Woke up.
[INFO][16:45:19]: [Client #243] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_243_615875.pth.
[INFO][16:45:19]: [Client #243] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_243_615875.pth.
[INFO][16:45:19]: [Client #243] Model trained.
[INFO][16:45:19]: [Client #243] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:45:19]: [Server #615782] Received 0.26 MB of payload data from client #243 (simulated).
[INFO][16:45:19]: [Server #615782] Selecting client #915 for training.
[INFO][16:45:19]: [Server #615782] Sending the current model to client #915 (simulated).
[INFO][16:45:19]: [Server #615782] Sending 0.26 MB of payload data to client #915 (simulated).
[INFO][16:45:19]: [Server #615782] Selecting client #621 for training.
[INFO][16:45:19]: [Server #615782] Sending the current model to client #621 (simulated).
[INFO][16:45:19]: [Server #615782] Sending 0.26 MB of payload data to client #621 (simulated).
[INFO][16:45:19]: [Client #915] Selected by the server.
[INFO][16:45:19]: [Client #621] Selected by the server.
[INFO][16:45:19]: [Client #915] Loading its data source...
[INFO][16:45:19]: [Client #621] Loading its data source...
[INFO][16:45:19]: Data source: FEMNIST
[INFO][16:45:19]: Data source: FEMNIST
[INFO][16:45:19]: [Client #915] Dataset size: 155
[INFO][16:45:19]: [Client #915] Sampler: all_inclusive
[INFO][16:45:19]: [Client #621] Dataset size: 154
[INFO][16:45:19]: [Client #621] Sampler: all_inclusive
[INFO][16:45:19]: [Client #915] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:45:19]: [Client #621] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:45:19]: [93m[1m[Client #621] Started training in communication round #17.[0m
[INFO][16:45:19]: [93m[1m[Client #915] Started training in communication round #17.[0m
[INFO][16:45:21]: [Client #621] Loading the dataset.
[INFO][16:45:21]: [Client #915] Loading the dataset.
[INFO][16:45:28]: [Client #621] Epoch: [1/5][0/16]	Loss: 1.910610
[INFO][16:45:28]: [Client #621] Epoch: [1/5][10/16]	Loss: 0.586414
[INFO][16:45:28]: [Client #621] Going to sleep for 0.17 seconds.
[INFO][16:45:29]: [Client #621] Woke up.
[INFO][16:45:29]: [Client #621] Epoch: [2/5][0/16]	Loss: 1.216628
[INFO][16:45:29]: [Client #915] Epoch: [1/5][0/16]	Loss: 1.122149
[INFO][16:45:29]: [Client #621] Epoch: [2/5][10/16]	Loss: 1.688479
[INFO][16:45:29]: [Client #621] Going to sleep for 0.17 seconds.
[INFO][16:45:29]: [Client #915] Epoch: [1/5][10/16]	Loss: 0.647901
[INFO][16:45:29]: [Client #915] Going to sleep for 6.99 seconds.
[INFO][16:45:29]: [Client #621] Woke up.
[INFO][16:45:29]: [Client #621] Epoch: [3/5][0/16]	Loss: 1.036974
[INFO][16:45:29]: [Client #621] Epoch: [3/5][10/16]	Loss: 1.095941
[INFO][16:45:29]: [Client #621] Going to sleep for 0.17 seconds.
[INFO][16:45:29]: [Client #621] Woke up.
[INFO][16:45:29]: [Client #621] Epoch: [4/5][0/16]	Loss: 0.938628
[INFO][16:45:29]: [Client #621] Epoch: [4/5][10/16]	Loss: 0.482863
[INFO][16:45:29]: [Client #621] Going to sleep for 0.17 seconds.
[INFO][16:45:30]: [Client #621] Woke up.
[INFO][16:45:30]: [Client #621] Epoch: [5/5][0/16]	Loss: 0.553015
[INFO][16:45:30]: [Client #621] Epoch: [5/5][10/16]	Loss: 1.330459
[INFO][16:45:30]: [Client #621] Going to sleep for 0.17 seconds.
[INFO][16:45:30]: [Client #621] Woke up.
[INFO][16:45:30]: [Client #621] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_621_615875.pth.
[INFO][16:45:30]: [Client #621] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_621_615875.pth.
[INFO][16:45:30]: [Client #621] Model trained.
[INFO][16:45:30]: [Client #621] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:45:30]: [Server #615782] Received 0.26 MB of payload data from client #621 (simulated).
[INFO][16:45:36]: [Client #915] Woke up.
[INFO][16:45:36]: [Client #915] Epoch: [2/5][0/16]	Loss: 0.569650
[INFO][16:45:36]: [Client #915] Epoch: [2/5][10/16]	Loss: 0.588718
[INFO][16:45:36]: [Client #915] Going to sleep for 6.99 seconds.
[INFO][16:45:43]: [Client #915] Woke up.
[INFO][16:45:43]: [Client #915] Epoch: [3/5][0/16]	Loss: 0.467030
[INFO][16:45:43]: [Client #915] Epoch: [3/5][10/16]	Loss: 0.219481
[INFO][16:45:43]: [Client #915] Going to sleep for 6.99 seconds.
[INFO][16:45:50]: [Client #915] Woke up.
[INFO][16:45:50]: [Client #915] Epoch: [4/5][0/16]	Loss: 0.944880
[INFO][16:45:50]: [Client #915] Epoch: [4/5][10/16]	Loss: 0.463127
[INFO][16:45:50]: [Client #915] Going to sleep for 6.99 seconds.
[INFO][16:45:57]: [Client #915] Woke up.
[INFO][16:45:57]: [Client #915] Epoch: [5/5][0/16]	Loss: 0.708291
[INFO][16:45:57]: [Client #915] Epoch: [5/5][10/16]	Loss: 0.183206
[INFO][16:45:57]: [Client #915] Going to sleep for 6.99 seconds.
[INFO][16:46:04]: [Client #915] Woke up.
[INFO][16:46:04]: [Client #915] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_915_615874.pth.
[INFO][16:46:05]: [Client #915] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_915_615874.pth.
[INFO][16:46:05]: [Client #915] Model trained.
[INFO][16:46:05]: [Client #915] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:05]: [Server #615782] Received 0.26 MB of payload data from client #915 (simulated).
[INFO][16:46:05]: [Server #615782] Selecting client #231 for training.
[INFO][16:46:05]: [Server #615782] Sending the current model to client #231 (simulated).
[INFO][16:46:05]: [Server #615782] Sending 0.26 MB of payload data to client #231 (simulated).
[INFO][16:46:05]: [Server #615782] Selecting client #770 for training.
[INFO][16:46:05]: [Server #615782] Sending the current model to client #770 (simulated).
[INFO][16:46:05]: [Server #615782] Sending 0.26 MB of payload data to client #770 (simulated).
[INFO][16:46:05]: [Client #231] Selected by the server.
[INFO][16:46:05]: [Client #231] Loading its data source...
[INFO][16:46:05]: Data source: FEMNIST
[INFO][16:46:05]: [Client #770] Selected by the server.
[INFO][16:46:05]: [Client #770] Loading its data source...
[INFO][16:46:05]: Data source: FEMNIST
[INFO][16:46:05]: [Client #770] Dataset size: 159
[INFO][16:46:05]: [Client #770] Sampler: all_inclusive
[INFO][16:46:05]: [Client #231] Dataset size: 153
[INFO][16:46:05]: [Client #231] Sampler: all_inclusive
[INFO][16:46:05]: [Client #770] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:05]: [Client #231] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:05]: [93m[1m[Client #770] Started training in communication round #17.[0m
[INFO][16:46:05]: [93m[1m[Client #231] Started training in communication round #17.[0m
[INFO][16:46:07]: [Client #770] Loading the dataset.
[INFO][16:46:07]: [Client #231] Loading the dataset.
[INFO][16:46:14]: [Client #770] Epoch: [1/5][0/16]	Loss: 0.961268
[INFO][16:46:14]: [Client #231] Epoch: [1/5][0/16]	Loss: 0.765408
[INFO][16:46:14]: [Client #770] Epoch: [1/5][10/16]	Loss: 0.706098
[INFO][16:46:14]: [Client #231] Epoch: [1/5][10/16]	Loss: 0.767577
[INFO][16:46:14]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:46:14]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][16:46:15]: [Client #231] Woke up.
[INFO][16:46:15]: [Client #231] Epoch: [2/5][0/16]	Loss: 0.720076
[INFO][16:46:15]: [Client #231] Epoch: [2/5][10/16]	Loss: 0.688383
[INFO][16:46:15]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][16:46:15]: [Client #770] Woke up.
[INFO][16:46:16]: [Client #770] Epoch: [2/5][0/16]	Loss: 0.590277
[INFO][16:46:16]: [Client #770] Epoch: [2/5][10/16]	Loss: 0.486869
[INFO][16:46:16]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:46:16]: [Client #231] Woke up.
[INFO][16:46:16]: [Client #231] Epoch: [3/5][0/16]	Loss: 1.718949
[INFO][16:46:16]: [Client #231] Epoch: [3/5][10/16]	Loss: 1.077952
[INFO][16:46:16]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][16:46:17]: [Client #770] Woke up.
[INFO][16:46:17]: [Client #770] Epoch: [3/5][0/16]	Loss: 0.698665
[INFO][16:46:17]: [Client #770] Epoch: [3/5][10/16]	Loss: 1.002928
[INFO][16:46:17]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:46:17]: [Client #231] Woke up.
[INFO][16:46:17]: [Client #231] Epoch: [4/5][0/16]	Loss: 0.996427
[INFO][16:46:17]: [Client #231] Epoch: [4/5][10/16]	Loss: 2.108732
[INFO][16:46:17]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][16:46:18]: [Client #770] Woke up.
[INFO][16:46:18]: [Client #770] Epoch: [4/5][0/16]	Loss: 0.220446
[INFO][16:46:18]: [Client #770] Epoch: [4/5][10/16]	Loss: 1.055120
[INFO][16:46:18]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:46:18]: [Client #231] Woke up.
[INFO][16:46:18]: [Client #231] Epoch: [5/5][0/16]	Loss: 0.479836
[INFO][16:46:18]: [Client #231] Epoch: [5/5][10/16]	Loss: 0.775726
[INFO][16:46:18]: [Client #231] Going to sleep for 0.85 seconds.
[INFO][16:46:19]: [Client #770] Woke up.
[INFO][16:46:19]: [Client #770] Epoch: [5/5][0/16]	Loss: 0.903777
[INFO][16:46:19]: [Client #770] Epoch: [5/5][10/16]	Loss: 1.279544
[INFO][16:46:19]: [Client #770] Going to sleep for 1.03 seconds.
[INFO][16:46:19]: [Client #231] Woke up.
[INFO][16:46:19]: [Client #231] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_231_615874.pth.
[INFO][16:46:20]: [Client #231] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_231_615874.pth.
[INFO][16:46:20]: [Client #231] Model trained.
[INFO][16:46:20]: [Client #231] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:20]: [Server #615782] Received 0.26 MB of payload data from client #231 (simulated).
[INFO][16:46:20]: [Client #770] Woke up.
[INFO][16:46:20]: [Client #770] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_770_615875.pth.
[INFO][16:46:21]: [Client #770] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_770_615875.pth.
[INFO][16:46:21]: [Client #770] Model trained.
[INFO][16:46:21]: [Client #770] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:21]: [Server #615782] Received 0.26 MB of payload data from client #770 (simulated).
[INFO][16:46:21]: [Server #615782] Selecting client #106 for training.
[INFO][16:46:21]: [Server #615782] Sending the current model to client #106 (simulated).
[INFO][16:46:21]: [Server #615782] Sending 0.26 MB of payload data to client #106 (simulated).
[INFO][16:46:21]: [Server #615782] Selecting client #554 for training.
[INFO][16:46:21]: [Server #615782] Sending the current model to client #554 (simulated).
[INFO][16:46:21]: [Server #615782] Sending 0.26 MB of payload data to client #554 (simulated).
[INFO][16:46:21]: [Client #106] Selected by the server.
[INFO][16:46:21]: [Client #554] Selected by the server.
[INFO][16:46:21]: [Client #106] Loading its data source...
[INFO][16:46:21]: [Client #554] Loading its data source...
[INFO][16:46:21]: Data source: FEMNIST
[INFO][16:46:21]: Data source: FEMNIST
[INFO][16:46:21]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:46:21]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/554.zip.
[INFO][16:46:21]: [Client #106] Dataset size: 133
[INFO][16:46:21]: [Client #106] Sampler: all_inclusive
[INFO][16:46:21]: [Client #106] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:21]: [93m[1m[Client #106] Started training in communication round #17.[0m
2.6%5.2%7.9%10.5%13.1%15.7%18.4%21.0%23.6%26.2%28.8%31.5%34.1%36.7%39.3%42.0%44.6%47.2%49.8%52.4%55.1%57.7%60.3%62.9%65.6%68.2%70.8%73.4%76.0%78.7%81.3%83.9%86.5%89.2%91.8%94.4%97.0%99.6%100.0%[INFO][16:46:21]: Decompressing the dataset downloaded.
[INFO][16:46:21]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/554.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:46:21]: [Client #554] Dataset size: 162
[INFO][16:46:21]: [Client #554] Sampler: all_inclusive
[INFO][16:46:21]: [Client #554] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:21]: [93m[1m[Client #554] Started training in communication round #17.[0m

[INFO][16:46:23]: [Client #106] Loading the dataset.
[INFO][16:46:23]: [Client #554] Loading the dataset.
[INFO][16:46:30]: [Client #554] Epoch: [1/5][0/17]	Loss: 0.713409
[INFO][16:46:30]: [Client #106] Epoch: [1/5][0/14]	Loss: 0.824232
[INFO][16:46:30]: [Client #106] Epoch: [1/5][10/14]	Loss: 1.378690
[INFO][16:46:30]: [Client #554] Epoch: [1/5][10/17]	Loss: 0.393902
[INFO][16:46:30]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][16:46:30]: [Client #554] Going to sleep for 0.87 seconds.
[INFO][16:46:31]: [Client #554] Woke up.
[INFO][16:46:31]: [Client #554] Epoch: [2/5][0/17]	Loss: 0.612423
[INFO][16:46:31]: [Client #554] Epoch: [2/5][10/17]	Loss: 0.650246
[INFO][16:46:31]: [Client #554] Going to sleep for 0.87 seconds.
[INFO][16:46:32]: [Client #106] Woke up.
[INFO][16:46:32]: [Client #106] Epoch: [2/5][0/14]	Loss: 0.517324
[INFO][16:46:32]: [Client #106] Epoch: [2/5][10/14]	Loss: 0.655042
[INFO][16:46:32]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][16:46:32]: [Client #554] Woke up.
[INFO][16:46:32]: [Client #554] Epoch: [3/5][0/17]	Loss: 0.117330
[INFO][16:46:32]: [Client #554] Epoch: [3/5][10/17]	Loss: 2.410195
[INFO][16:46:32]: [Client #554] Going to sleep for 0.87 seconds.
[INFO][16:46:33]: [Client #554] Woke up.
[INFO][16:46:33]: [Client #554] Epoch: [4/5][0/17]	Loss: 2.302507
[INFO][16:46:33]: [Client #554] Epoch: [4/5][10/17]	Loss: 1.263050
[INFO][16:46:33]: [Client #554] Going to sleep for 0.87 seconds.
[INFO][16:46:34]: [Client #106] Woke up.
[INFO][16:46:34]: [Client #106] Epoch: [3/5][0/14]	Loss: 0.349794
[INFO][16:46:34]: [Client #106] Epoch: [3/5][10/14]	Loss: 0.099865
[INFO][16:46:34]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][16:46:34]: [Client #554] Woke up.
[INFO][16:46:34]: [Client #554] Epoch: [5/5][0/17]	Loss: 0.671853
[INFO][16:46:34]: [Client #554] Epoch: [5/5][10/17]	Loss: 0.986116
[INFO][16:46:34]: [Client #554] Going to sleep for 0.87 seconds.
[INFO][16:46:35]: [Client #554] Woke up.
[INFO][16:46:35]: [Client #554] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_554_615875.pth.
[INFO][16:46:36]: [Client #106] Woke up.
[INFO][16:46:36]: [Client #106] Epoch: [4/5][0/14]	Loss: 0.376796
[INFO][16:46:36]: [Client #106] Epoch: [4/5][10/14]	Loss: 0.272351
[INFO][16:46:36]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][16:46:36]: [Client #554] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_554_615875.pth.
[INFO][16:46:36]: [Client #554] Model trained.
[INFO][16:46:36]: [Client #554] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:36]: [Server #615782] Received 0.26 MB of payload data from client #554 (simulated).
[INFO][16:46:37]: [Client #106] Woke up.
[INFO][16:46:37]: [Client #106] Epoch: [5/5][0/14]	Loss: 1.424408
[INFO][16:46:37]: [Client #106] Epoch: [5/5][10/14]	Loss: 2.688655
[INFO][16:46:37]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][16:46:39]: [Client #106] Woke up.
[INFO][16:46:39]: [Client #106] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_106_615874.pth.
[INFO][16:46:40]: [Client #106] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_106_615874.pth.
[INFO][16:46:40]: [Client #106] Model trained.
[INFO][16:46:40]: [Client #106] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:40]: [Server #615782] Received 0.26 MB of payload data from client #106 (simulated).
[INFO][16:46:40]: [Server #615782] Selecting client #95 for training.
[INFO][16:46:40]: [Server #615782] Sending the current model to client #95 (simulated).
[INFO][16:46:40]: [Server #615782] Sending 0.26 MB of payload data to client #95 (simulated).
[INFO][16:46:40]: [Server #615782] Selecting client #580 for training.
[INFO][16:46:40]: [Server #615782] Sending the current model to client #580 (simulated).
[INFO][16:46:40]: [Server #615782] Sending 0.26 MB of payload data to client #580 (simulated).
[INFO][16:46:40]: [Client #95] Selected by the server.
[INFO][16:46:40]: [Client #95] Loading its data source...
[INFO][16:46:40]: Data source: FEMNIST
[INFO][16:46:40]: [Client #580] Selected by the server.
[INFO][16:46:40]: [Client #580] Loading its data source...
[INFO][16:46:40]: Data source: FEMNIST
[INFO][16:46:40]: [Client #580] Dataset size: 89
[INFO][16:46:40]: [Client #580] Sampler: all_inclusive
[INFO][16:46:40]: [Client #580] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:40]: [93m[1m[Client #580] Started training in communication round #17.[0m
[INFO][16:46:40]: [Client #95] Dataset size: 158
[INFO][16:46:40]: [Client #95] Sampler: all_inclusive
[INFO][16:46:40]: [Client #95] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:40]: [93m[1m[Client #95] Started training in communication round #17.[0m
[INFO][16:46:42]: [Client #95] Loading the dataset.
[INFO][16:46:42]: [Client #580] Loading the dataset.
[INFO][16:46:49]: [Client #580] Epoch: [1/5][0/9]	Loss: 2.561008
[INFO][16:46:49]: [Client #95] Epoch: [1/5][0/16]	Loss: 2.038766
[INFO][16:46:49]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][16:46:49]: [Client #95] Epoch: [1/5][10/16]	Loss: 0.103364
[INFO][16:46:49]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][16:46:50]: [Client #580] Woke up.
[INFO][16:46:50]: [Client #580] Epoch: [2/5][0/9]	Loss: 0.988762
[INFO][16:46:50]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][16:46:50]: [Client #95] Woke up.
[INFO][16:46:50]: [Client #95] Epoch: [2/5][0/16]	Loss: 0.458109
[INFO][16:46:50]: [Client #95] Epoch: [2/5][10/16]	Loss: 0.762682
[INFO][16:46:50]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][16:46:50]: [Client #580] Woke up.
[INFO][16:46:50]: [Client #580] Epoch: [3/5][0/9]	Loss: 0.875844
[INFO][16:46:51]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][16:46:51]: [Client #95] Woke up.
[INFO][16:46:51]: [Client #95] Epoch: [3/5][0/16]	Loss: 1.263349
[INFO][16:46:51]: [Client #95] Epoch: [3/5][10/16]	Loss: 0.497571
[INFO][16:46:51]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][16:46:51]: [Client #580] Woke up.
[INFO][16:46:51]: [Client #580] Epoch: [4/5][0/9]	Loss: 1.847684
[INFO][16:46:51]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][16:46:52]: [Client #95] Woke up.
[INFO][16:46:52]: [Client #580] Woke up.
[INFO][16:46:52]: [Client #95] Epoch: [4/5][0/16]	Loss: 1.148816
[INFO][16:46:52]: [Client #580] Epoch: [5/5][0/9]	Loss: 1.417570
[INFO][16:46:52]: [Client #580] Going to sleep for 0.54 seconds.
[INFO][16:46:52]: [Client #95] Epoch: [4/5][10/16]	Loss: 1.452664
[INFO][16:46:52]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][16:46:52]: [Client #580] Woke up.
[INFO][16:46:52]: [Client #580] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_580_615875.pth.
[INFO][16:46:53]: [Client #95] Woke up.
[INFO][16:46:53]: [Client #95] Epoch: [5/5][0/16]	Loss: 0.435173
[INFO][16:46:53]: [Client #95] Epoch: [5/5][10/16]	Loss: 0.689082
[INFO][16:46:53]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][16:46:53]: [Client #580] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_580_615875.pth.
[INFO][16:46:53]: [Client #580] Model trained.
[INFO][16:46:53]: [Client #580] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:53]: [Server #615782] Received 0.26 MB of payload data from client #580 (simulated).
[INFO][16:46:53]: [Client #95] Woke up.
[INFO][16:46:53]: [Client #95] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_95_615874.pth.
[INFO][16:46:54]: [Client #95] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_95_615874.pth.
[INFO][16:46:54]: [Client #95] Model trained.
[INFO][16:46:54]: [Client #95] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:46:54]: [Server #615782] Received 0.26 MB of payload data from client #95 (simulated).
[INFO][16:46:54]: [Server #615782] Selecting client #253 for training.
[INFO][16:46:54]: [Server #615782] Sending the current model to client #253 (simulated).
[INFO][16:46:54]: [Server #615782] Sending 0.26 MB of payload data to client #253 (simulated).
[INFO][16:46:54]: [Server #615782] Selecting client #648 for training.
[INFO][16:46:54]: [Server #615782] Sending the current model to client #648 (simulated).
[INFO][16:46:54]: [Server #615782] Sending 0.26 MB of payload data to client #648 (simulated).
[INFO][16:46:54]: [Client #253] Selected by the server.
[INFO][16:46:54]: [Client #253] Loading its data source...
[INFO][16:46:54]: Data source: FEMNIST
[INFO][16:46:54]: [Client #648] Selected by the server.
[INFO][16:46:54]: [Client #648] Loading its data source...
[INFO][16:46:54]: Data source: FEMNIST
[INFO][16:46:54]: [Client #648] Dataset size: 151
[INFO][16:46:54]: [Client #648] Sampler: all_inclusive
[INFO][16:46:54]: [Client #253] Dataset size: 161
[INFO][16:46:54]: [Client #253] Sampler: all_inclusive
[INFO][16:46:54]: [Client #648] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:54]: [93m[1m[Client #648] Started training in communication round #17.[0m
[INFO][16:46:54]: [Client #253] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:46:54]: [93m[1m[Client #253] Started training in communication round #17.[0m
[INFO][16:46:56]: [Client #648] Loading the dataset.
[INFO][16:46:56]: [Client #253] Loading the dataset.
[INFO][16:47:04]: [Client #253] Epoch: [1/5][0/17]	Loss: 0.647191
[INFO][16:47:04]: [Client #648] Epoch: [1/5][0/16]	Loss: 0.494014
[INFO][16:47:04]: [Client #253] Epoch: [1/5][10/17]	Loss: 0.636250
[INFO][16:47:04]: [Client #648] Epoch: [1/5][10/16]	Loss: 0.904613
[INFO][16:47:04]: [Client #648] Going to sleep for 0.08 seconds.
[INFO][16:47:04]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][16:47:04]: [Client #648] Woke up.
[INFO][16:47:04]: [Client #648] Epoch: [2/5][0/16]	Loss: 0.949234
[INFO][16:47:04]: [Client #648] Epoch: [2/5][10/16]	Loss: 0.808574
[INFO][16:47:04]: [Client #648] Going to sleep for 0.08 seconds.
[INFO][16:47:04]: [Client #648] Woke up.
[INFO][16:47:04]: [Client #648] Epoch: [3/5][0/16]	Loss: 1.841491
[INFO][16:47:04]: [Client #648] Epoch: [3/5][10/16]	Loss: 1.199311
[INFO][16:47:04]: [Client #648] Going to sleep for 0.08 seconds.
[INFO][16:47:04]: [Client #648] Woke up.
[INFO][16:47:05]: [Client #648] Epoch: [4/5][0/16]	Loss: 0.496674
[INFO][16:47:05]: [Client #253] Woke up.
[INFO][16:47:05]: [Client #253] Epoch: [2/5][0/17]	Loss: 0.395161
[INFO][16:47:05]: [Client #648] Epoch: [4/5][10/16]	Loss: 1.097709
[INFO][16:47:05]: [Client #648] Going to sleep for 0.08 seconds.
[INFO][16:47:05]: [Client #253] Epoch: [2/5][10/17]	Loss: 1.350338
[INFO][16:47:05]: [Client #648] Woke up.
[INFO][16:47:05]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][16:47:05]: [Client #648] Epoch: [5/5][0/16]	Loss: 0.186340
[INFO][16:47:05]: [Client #648] Epoch: [5/5][10/16]	Loss: 1.367648
[INFO][16:47:05]: [Client #648] Going to sleep for 0.08 seconds.
[INFO][16:47:05]: [Client #648] Woke up.
[INFO][16:47:05]: [Client #648] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_648_615875.pth.
[INFO][16:47:05]: [Client #253] Woke up.
[INFO][16:47:05]: [Client #253] Epoch: [3/5][0/17]	Loss: 1.201288
[INFO][16:47:05]: [Client #253] Epoch: [3/5][10/17]	Loss: 0.695479
[INFO][16:47:05]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][16:47:06]: [Client #648] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_648_615875.pth.
[INFO][16:47:06]: [Client #648] Model trained.
[INFO][16:47:06]: [Client #648] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:47:06]: [Server #615782] Received 0.26 MB of payload data from client #648 (simulated).
[INFO][16:47:06]: [Client #253] Woke up.
[INFO][16:47:06]: [Client #253] Epoch: [4/5][0/17]	Loss: 0.405578
[INFO][16:47:06]: [Client #253] Epoch: [4/5][10/17]	Loss: 0.580574
[INFO][16:47:06]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][16:47:07]: [Client #253] Woke up.
[INFO][16:47:07]: [Client #253] Epoch: [5/5][0/17]	Loss: 0.402309
[INFO][16:47:07]: [Client #253] Epoch: [5/5][10/17]	Loss: 0.474408
[INFO][16:47:07]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][16:47:08]: [Client #253] Woke up.
[INFO][16:47:08]: [Client #253] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_615874.pth.
[INFO][16:47:08]: [Client #253] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_615874.pth.
[INFO][16:47:08]: [Client #253] Model trained.
[INFO][16:47:08]: [Client #253] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:47:08]: [Server #615782] Received 0.26 MB of payload data from client #253 (simulated).
[INFO][16:47:08]: [Server #615782] Selecting client #714 for training.
[INFO][16:47:08]: [Server #615782] Sending the current model to client #714 (simulated).
[INFO][16:47:08]: [Server #615782] Sending 0.26 MB of payload data to client #714 (simulated).
[INFO][16:47:08]: [Server #615782] Selecting client #524 for training.
[INFO][16:47:08]: [Server #615782] Sending the current model to client #524 (simulated).
[INFO][16:47:08]: [Server #615782] Sending 0.26 MB of payload data to client #524 (simulated).
[INFO][16:47:08]: [Client #714] Selected by the server.
[INFO][16:47:08]: [Client #714] Loading its data source...
[INFO][16:47:08]: Data source: FEMNIST
[INFO][16:47:08]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:47:08]: [Client #524] Selected by the server.
[INFO][16:47:08]: [Client #524] Loading its data source...
[INFO][16:47:08]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/714.zip.
[INFO][16:47:08]: Data source: FEMNIST
[INFO][16:47:08]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:47:08]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/524.zip.
2.2%4.4%6.6%8.8%11.0%13.2%15.4%17.7%19.9%22.1%24.3%26.5%28.7%30.9%33.1%2.9%35.3%37.5%39.7%41.9%44.1%46.3%48.6%50.8%53.0%55.2%57.4%59.6%61.8%64.0%66.2%68.4%70.6%72.8%75.0%77.2%79.4%81.7%83.9%86.1%88.3%90.5%92.7%94.9%97.1%99.3%100.0%5.8%8.7%11.5%14.4%[INFO][16:47:08]: Decompressing the dataset downloaded.
17.3%20.2%23.1%[INFO][16:47:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/524.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
26.0%28.8%31.7%34.6%37.5%40.4%43.3%46.2%49.0%51.9%54.8%57.7%60.6%63.5%66.3%69.2%72.1%75.0%77.9%80.8%83.7%86.5%89.4%92.3%95.2%98.1%100.0%[INFO][16:47:08]: Decompressing the dataset downloaded.
[INFO][16:47:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/714.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:47:09]: [Client #524] Dataset size: 162
[INFO][16:47:09]: [Client #524] Sampler: all_inclusive
[INFO][16:47:09]: [Client #714] Dataset size: 162
[INFO][16:47:09]: [Client #714] Sampler: all_inclusive
[INFO][16:47:09]: [Client #524] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:47:09]: [Client #714] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:47:09]: [93m[1m[Client #524] Started training in communication round #17.[0m

[INFO][16:47:09]: [93m[1m[Client #714] Started training in communication round #17.[0m

[INFO][16:47:11]: [Client #714] Loading the dataset.
[INFO][16:47:11]: [Client #524] Loading the dataset.
[INFO][16:47:17]: [Client #524] Epoch: [1/5][0/17]	Loss: 1.042177
[INFO][16:47:18]: [Client #714] Epoch: [1/5][0/17]	Loss: 0.330675
[INFO][16:47:18]: [Client #524] Epoch: [1/5][10/17]	Loss: 0.820301
[INFO][16:47:18]: [Client #524] Going to sleep for 9.16 seconds.
[INFO][16:47:18]: [Client #714] Epoch: [1/5][10/17]	Loss: 1.311855
[INFO][16:47:18]: [Client #714] Going to sleep for 1.68 seconds.
[INFO][16:47:19]: [Client #714] Woke up.
[INFO][16:47:19]: [Client #714] Epoch: [2/5][0/17]	Loss: 0.507153
[INFO][16:47:19]: [Client #714] Epoch: [2/5][10/17]	Loss: 0.933081
[INFO][16:47:20]: [Client #714] Going to sleep for 1.68 seconds.
[INFO][16:47:21]: [Client #714] Woke up.
[INFO][16:47:21]: [Client #714] Epoch: [3/5][0/17]	Loss: 0.895517
[INFO][16:47:21]: [Client #714] Epoch: [3/5][10/17]	Loss: 1.654717
[INFO][16:47:21]: [Client #714] Going to sleep for 1.68 seconds.
[INFO][16:47:23]: [Client #714] Woke up.
[INFO][16:47:23]: [Client #714] Epoch: [4/5][0/17]	Loss: 1.000688
[INFO][16:47:23]: [Client #714] Epoch: [4/5][10/17]	Loss: 1.305553
[INFO][16:47:23]: [Client #714] Going to sleep for 1.68 seconds.
[INFO][16:47:25]: [Client #714] Woke up.
[INFO][16:47:25]: [Client #714] Epoch: [5/5][0/17]	Loss: 1.503849
[INFO][16:47:25]: [Client #714] Epoch: [5/5][10/17]	Loss: 0.901075
[INFO][16:47:25]: [Client #714] Going to sleep for 1.68 seconds.
[INFO][16:47:27]: [Client #714] Woke up.
[INFO][16:47:27]: [Client #714] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_714_615874.pth.
[INFO][16:47:27]: [Client #524] Woke up.
[INFO][16:47:27]: [Client #524] Epoch: [2/5][0/17]	Loss: 1.279325
[INFO][16:47:27]: [Client #524] Epoch: [2/5][10/17]	Loss: 0.857142
[INFO][16:47:27]: [Client #524] Going to sleep for 9.16 seconds.
[INFO][16:47:27]: [Client #714] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_714_615874.pth.
[INFO][16:47:27]: [Client #714] Model trained.
[INFO][16:47:27]: [Client #714] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:47:27]: [Server #615782] Received 0.26 MB of payload data from client #714 (simulated).
[INFO][16:47:36]: [Client #524] Woke up.
[INFO][16:47:36]: [Client #524] Epoch: [3/5][0/17]	Loss: 0.198085
[INFO][16:47:36]: [Client #524] Epoch: [3/5][10/17]	Loss: 1.605316
[INFO][16:47:36]: [Client #524] Going to sleep for 9.16 seconds.
[INFO][16:47:45]: [Client #524] Woke up.
[INFO][16:47:45]: [Client #524] Epoch: [4/5][0/17]	Loss: 0.588299
[INFO][16:47:46]: [Client #524] Epoch: [4/5][10/17]	Loss: 0.707976
[INFO][16:47:46]: [Client #524] Going to sleep for 9.16 seconds.
[INFO][16:47:55]: [Client #524] Woke up.
[INFO][16:47:55]: [Client #524] Epoch: [5/5][0/17]	Loss: 1.086089
[INFO][16:47:55]: [Client #524] Epoch: [5/5][10/17]	Loss: 1.091485
[INFO][16:47:55]: [Client #524] Going to sleep for 9.16 seconds.
[INFO][16:48:04]: [Client #524] Woke up.
[INFO][16:48:04]: [Client #524] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_524_615875.pth.
[INFO][16:48:05]: [Client #524] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_524_615875.pth.
[INFO][16:48:05]: [Client #524] Model trained.
[INFO][16:48:05]: [Client #524] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:48:05]: [Server #615782] Received 0.26 MB of payload data from client #524 (simulated).
[INFO][16:48:05]: [Server #615782] Selecting client #656 for training.
[INFO][16:48:05]: [Server #615782] Sending the current model to client #656 (simulated).
[INFO][16:48:05]: [Server #615782] Sending 0.26 MB of payload data to client #656 (simulated).
[INFO][16:48:05]: [Server #615782] Selecting client #813 for training.
[INFO][16:48:05]: [Server #615782] Sending the current model to client #813 (simulated).
[INFO][16:48:05]: [Server #615782] Sending 0.26 MB of payload data to client #813 (simulated).
[INFO][16:48:05]: [Client #656] Selected by the server.
[INFO][16:48:05]: [Client #656] Loading its data source...
[INFO][16:48:05]: [Client #813] Selected by the server.
[INFO][16:48:05]: Data source: FEMNIST
[INFO][16:48:05]: [Client #813] Loading its data source...
[INFO][16:48:05]: Data source: FEMNIST
[INFO][16:48:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:48:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][16:48:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/656.zip.
[INFO][16:48:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/813.zip.
2.3%4.6%6.9%9.2%11.5%13.8%16.1%18.4%20.7%23.0%25.3%27.6%29.9%32.2%34.5%36.8%2.7%5.5%8.2%10.9%13.7%16.4%19.1%21.8%24.6%27.3%30.0%32.8%35.5%38.2%41.0%43.7%39.1%41.4%43.7%46.0%48.2%50.5%52.8%55.1%57.4%59.7%62.0%46.4%64.3%66.6%68.9%49.2%71.2%51.9%73.5%54.6%75.8%57.4%60.1%78.1%62.8%65.5%80.4%82.7%68.3%85.0%87.3%71.0%89.6%73.7%91.9%76.5%94.2%79.2%96.5%81.9%98.8%84.7%87.4%90.1%92.9%95.6%98.3%100.0%100.0%[INFO][16:48:05]: Decompressing the dataset downloaded.
[INFO][16:48:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/813.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:48:05]: Decompressing the dataset downloaded.
[INFO][16:48:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/656.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][16:48:05]: [Client #813] Dataset size: 151
[INFO][16:48:05]: [Client #813] Sampler: all_inclusive
[INFO][16:48:05]: [Client #656] Dataset size: 158
[INFO][16:48:05]: [Client #656] Sampler: all_inclusive
[INFO][16:48:05]: [Client #813] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:48:05]: [Client #656] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:48:05]: [93m[1m[Client #656] Started training in communication round #17.[0m
[INFO][16:48:05]: [93m[1m[Client #813] Started training in communication round #17.[0m


[INFO][16:48:07]: [Client #656] Loading the dataset.
[INFO][16:48:07]: [Client #813] Loading the dataset.
[INFO][16:48:14]: [Client #656] Epoch: [1/5][0/16]	Loss: 0.803580
[INFO][16:48:15]: [Client #813] Epoch: [1/5][0/16]	Loss: 0.164768
[INFO][16:48:15]: [Client #656] Epoch: [1/5][10/16]	Loss: 1.562624
[INFO][16:48:15]: [Client #813] Epoch: [1/5][10/16]	Loss: 0.224589
[INFO][16:48:15]: [Client #656] Going to sleep for 0.22 seconds.
[INFO][16:48:15]: [Client #813] Going to sleep for 15.26 seconds.
[INFO][16:48:15]: [Client #656] Woke up.
[INFO][16:48:15]: [Client #656] Epoch: [2/5][0/16]	Loss: 0.425737
[INFO][16:48:15]: [Client #656] Epoch: [2/5][10/16]	Loss: 0.564737
[INFO][16:48:15]: [Client #656] Going to sleep for 0.22 seconds.
[INFO][16:48:15]: [Client #656] Woke up.
[INFO][16:48:15]: [Client #656] Epoch: [3/5][0/16]	Loss: 0.691038
[INFO][16:48:15]: [Client #656] Epoch: [3/5][10/16]	Loss: 0.351390
[INFO][16:48:15]: [Client #656] Going to sleep for 0.22 seconds.
[INFO][16:48:16]: [Client #656] Woke up.
[INFO][16:48:16]: [Client #656] Epoch: [4/5][0/16]	Loss: 0.613260
[INFO][16:48:16]: [Client #656] Epoch: [4/5][10/16]	Loss: 1.132310
[INFO][16:48:16]: [Client #656] Going to sleep for 0.22 seconds.
[INFO][16:48:16]: [Client #656] Woke up.
[INFO][16:48:16]: [Client #656] Epoch: [5/5][0/16]	Loss: 0.879685
[INFO][16:48:16]: [Client #656] Epoch: [5/5][10/16]	Loss: 1.000016
[INFO][16:48:16]: [Client #656] Going to sleep for 0.22 seconds.
[INFO][16:48:16]: [Client #656] Woke up.
[INFO][16:48:16]: [Client #656] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_656_615874.pth.
[INFO][16:48:17]: [Client #656] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_656_615874.pth.
[INFO][16:48:17]: [Client #656] Model trained.
[INFO][16:48:17]: [Client #656] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:48:17]: [Server #615782] Received 0.26 MB of payload data from client #656 (simulated).
[INFO][16:48:30]: [Client #813] Woke up.
[INFO][16:48:30]: [Client #813] Epoch: [2/5][0/16]	Loss: 0.675595
[INFO][16:48:30]: [Client #813] Epoch: [2/5][10/16]	Loss: 0.614509
[INFO][16:48:30]: [Client #813] Going to sleep for 15.26 seconds.
[INFO][16:48:45]: [Client #813] Woke up.
[INFO][16:48:45]: [Client #813] Epoch: [3/5][0/16]	Loss: 1.013087
[INFO][16:48:45]: [Client #813] Epoch: [3/5][10/16]	Loss: 2.424456
[INFO][16:48:45]: [Client #813] Going to sleep for 15.26 seconds.
[INFO][16:49:01]: [Client #813] Woke up.
[INFO][16:49:01]: [Client #813] Epoch: [4/5][0/16]	Loss: 1.053768
[INFO][16:49:01]: [Client #813] Epoch: [4/5][10/16]	Loss: 2.018747
[INFO][16:49:01]: [Client #813] Going to sleep for 15.26 seconds.
[INFO][16:49:16]: [Client #813] Woke up.
[INFO][16:49:16]: [Client #813] Epoch: [5/5][0/16]	Loss: 2.957454
[INFO][16:49:16]: [Client #813] Epoch: [5/5][10/16]	Loss: 1.140781
[INFO][16:49:16]: [Client #813] Going to sleep for 15.26 seconds.
[INFO][16:49:32]: [Client #813] Woke up.
[INFO][16:49:32]: [Client #813] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_813_615875.pth.
[INFO][16:49:32]: [Client #813] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_813_615875.pth.
[INFO][16:49:32]: [Client #813] Model trained.
[INFO][16:49:32]: [Client #813] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:49:32]: [Server #615782] Received 0.26 MB of payload data from client #813 (simulated).
[INFO][16:49:32]: [Server #615782] Selecting client #807 for training.
[INFO][16:49:32]: [Server #615782] Sending the current model to client #807 (simulated).
[INFO][16:49:32]: [Server #615782] Sending 0.26 MB of payload data to client #807 (simulated).
[INFO][16:49:32]: [Server #615782] Selecting client #619 for training.
[INFO][16:49:32]: [Server #615782] Sending the current model to client #619 (simulated).
[INFO][16:49:32]: [Server #615782] Sending 0.26 MB of payload data to client #619 (simulated).
[INFO][16:49:32]: [Client #807] Selected by the server.
[INFO][16:49:32]: [Client #807] Loading its data source...
[INFO][16:49:32]: Data source: FEMNIST
[INFO][16:49:32]: [Client #619] Selected by the server.
[INFO][16:49:32]: [Client #619] Loading its data source...
[INFO][16:49:32]: Data source: FEMNIST
[INFO][16:49:32]: [Client #619] Dataset size: 144
[INFO][16:49:32]: [Client #619] Sampler: all_inclusive
[INFO][16:49:32]: [Client #807] Dataset size: 157
[INFO][16:49:32]: [Client #807] Sampler: all_inclusive
[INFO][16:49:32]: [Client #619] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:49:32]: [Client #807] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:49:32]: [93m[1m[Client #619] Started training in communication round #17.[0m
[INFO][16:49:32]: [93m[1m[Client #807] Started training in communication round #17.[0m
[INFO][16:49:34]: [Client #619] Loading the dataset.
[INFO][16:49:34]: [Client #807] Loading the dataset.
[INFO][16:49:42]: [Client #619] Epoch: [1/5][0/15]	Loss: 1.049388
[INFO][16:49:42]: [Client #807] Epoch: [1/5][0/16]	Loss: 1.882586
[INFO][16:49:42]: [Client #619] Epoch: [1/5][10/15]	Loss: 0.959273
[INFO][16:49:42]: [Client #807] Epoch: [1/5][10/16]	Loss: 0.478113
[INFO][16:49:42]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][16:49:42]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][16:49:42]: [Client #807] Woke up.
[INFO][16:49:42]: [Client #807] Epoch: [2/5][0/16]	Loss: 0.801036
[INFO][16:49:43]: [Client #807] Epoch: [2/5][10/16]	Loss: 0.642179
[INFO][16:49:43]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][16:49:43]: [Client #619] Woke up.
[INFO][16:49:43]: [Client #619] Epoch: [2/5][0/15]	Loss: 1.068678
[INFO][16:49:43]: [Client #619] Epoch: [2/5][10/15]	Loss: 0.772742
[INFO][16:49:43]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][16:49:43]: [Client #807] Woke up.
[INFO][16:49:43]: [Client #807] Epoch: [3/5][0/16]	Loss: 0.128801
[INFO][16:49:43]: [Client #807] Epoch: [3/5][10/16]	Loss: 0.539606
[INFO][16:49:43]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][16:49:43]: [Client #807] Woke up.
[INFO][16:49:43]: [Client #807] Epoch: [4/5][0/16]	Loss: 0.556521
[INFO][16:49:44]: [Client #807] Epoch: [4/5][10/16]	Loss: 0.803572
[INFO][16:49:44]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][16:49:44]: [Client #619] Woke up.
[INFO][16:49:44]: [Client #619] Epoch: [3/5][0/15]	Loss: 0.706750
[INFO][16:49:44]: [Client #619] Epoch: [3/5][10/15]	Loss: 0.825375
[INFO][16:49:44]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][16:49:44]: [Client #807] Woke up.
[INFO][16:49:44]: [Client #807] Epoch: [5/5][0/16]	Loss: 0.424947
[INFO][16:49:44]: [Client #807] Epoch: [5/5][10/16]	Loss: 0.481722
[INFO][16:49:44]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][16:49:45]: [Client #807] Woke up.
[INFO][16:49:45]: [Client #807] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][16:49:45]: [Client #619] Woke up.
[INFO][16:49:45]: [Client #619] Epoch: [4/5][0/15]	Loss: 1.391049
[INFO][16:49:45]: [Client #619] Epoch: [4/5][10/15]	Loss: 2.077375
[INFO][16:49:45]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][16:49:45]: [Client #807] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][16:49:45]: [Client #807] Model trained.
[INFO][16:49:45]: [Client #807] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:49:45]: [Server #615782] Received 0.26 MB of payload data from client #807 (simulated).
[INFO][16:49:45]: [Client #619] Woke up.
[INFO][16:49:45]: [Client #619] Epoch: [5/5][0/15]	Loss: 1.243623
[INFO][16:49:46]: [Client #619] Epoch: [5/5][10/15]	Loss: 0.873479
[INFO][16:49:46]: [Client #619] Going to sleep for 0.76 seconds.
[INFO][16:49:46]: [Client #619] Woke up.
[INFO][16:49:46]: [Client #619] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615875.pth.
[INFO][16:49:47]: [Client #619] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_619_615875.pth.
[INFO][16:49:47]: [Client #619] Model trained.
[INFO][16:49:47]: [Client #619] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:49:47]: [Server #615782] Received 0.26 MB of payload data from client #619 (simulated).
[INFO][16:49:47]: [Server #615782] Selecting client #451 for training.
[INFO][16:49:47]: [Server #615782] Sending the current model to client #451 (simulated).
[INFO][16:49:47]: [Server #615782] Sending 0.26 MB of payload data to client #451 (simulated).
[INFO][16:49:47]: [Server #615782] Selecting client #408 for training.
[INFO][16:49:47]: [Server #615782] Sending the current model to client #408 (simulated).
[INFO][16:49:47]: [Server #615782] Sending 0.26 MB of payload data to client #408 (simulated).
[INFO][16:49:47]: [Client #451] Selected by the server.
[INFO][16:49:47]: [Client #408] Selected by the server.
[INFO][16:49:47]: [Client #451] Loading its data source...
[INFO][16:49:47]: [Client #408] Loading its data source...
[INFO][16:49:47]: Data source: FEMNIST
[INFO][16:49:47]: Data source: FEMNIST
[INFO][16:49:47]: [Client #451] Dataset size: 146
[INFO][16:49:47]: [Client #451] Sampler: all_inclusive
[INFO][16:49:47]: [Client #451] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:49:47]: [Client #408] Dataset size: 156
[INFO][16:49:47]: [Client #408] Sampler: all_inclusive
[INFO][16:49:47]: [93m[1m[Client #451] Started training in communication round #17.[0m
[INFO][16:49:47]: [Client #408] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:49:47]: [93m[1m[Client #408] Started training in communication round #17.[0m
[INFO][16:49:49]: [Client #451] Loading the dataset.
[INFO][16:49:49]: [Client #408] Loading the dataset.
[INFO][16:49:57]: [Client #451] Epoch: [1/5][0/15]	Loss: 1.360064
[INFO][16:49:57]: [Client #408] Epoch: [1/5][0/16]	Loss: 2.043178
[INFO][16:49:57]: [Client #451] Epoch: [1/5][10/15]	Loss: 0.697350
[INFO][16:49:57]: [Client #408] Epoch: [1/5][10/16]	Loss: 2.229727
[INFO][16:49:57]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][16:49:57]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][16:49:57]: [Client #451] Woke up.
[INFO][16:49:57]: [Client #451] Epoch: [2/5][0/15]	Loss: 1.578098
[INFO][16:49:57]: [Client #451] Epoch: [2/5][10/15]	Loss: 0.859774
[INFO][16:49:57]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][16:49:57]: [Client #408] Woke up.
[INFO][16:49:57]: [Client #408] Epoch: [2/5][0/16]	Loss: 1.302890
[INFO][16:49:57]: [Client #408] Epoch: [2/5][10/16]	Loss: 0.339070
[INFO][16:49:57]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][16:49:57]: [Client #451] Woke up.
[INFO][16:49:57]: [Client #451] Epoch: [3/5][0/15]	Loss: 0.743600
[INFO][16:49:57]: [Client #451] Epoch: [3/5][10/15]	Loss: 1.011229
[INFO][16:49:57]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][16:49:58]: [Client #408] Woke up.
[INFO][16:49:58]: [Client #408] Epoch: [3/5][0/16]	Loss: 0.141844
[INFO][16:49:58]: [Client #451] Woke up.
[INFO][16:49:58]: [Client #451] Epoch: [4/5][0/15]	Loss: 0.760848
[INFO][16:49:58]: [Client #408] Epoch: [3/5][10/16]	Loss: 0.999111
[INFO][16:49:58]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][16:49:58]: [Client #451] Epoch: [4/5][10/15]	Loss: 1.487039
[INFO][16:49:58]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][16:49:58]: [Client #451] Woke up.
[INFO][16:49:58]: [Client #451] Epoch: [5/5][0/15]	Loss: 0.822444
[INFO][16:49:58]: [Client #408] Woke up.
[INFO][16:49:58]: [Client #408] Epoch: [4/5][0/16]	Loss: 0.825331
[INFO][16:49:58]: [Client #451] Epoch: [5/5][10/15]	Loss: 1.239834
[INFO][16:49:58]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][16:49:58]: [Client #408] Epoch: [4/5][10/16]	Loss: 0.817573
[INFO][16:49:58]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][16:49:58]: [Client #451] Woke up.
[INFO][16:49:58]: [Client #451] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_615874.pth.
[INFO][16:49:59]: [Client #408] Woke up.
[INFO][16:49:59]: [Client #408] Epoch: [5/5][0/16]	Loss: 1.171847
[INFO][16:49:59]: [Client #408] Epoch: [5/5][10/16]	Loss: 0.693410
[INFO][16:49:59]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][16:49:59]: [Client #408] Woke up.
[INFO][16:49:59]: [Client #408] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_408_615875.pth.
[INFO][16:49:59]: [Client #451] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_615874.pth.
[INFO][16:49:59]: [Client #451] Model trained.
[INFO][16:49:59]: [Client #451] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:49:59]: [Server #615782] Received 0.26 MB of payload data from client #451 (simulated).
[INFO][16:50:00]: [Client #408] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_408_615875.pth.
[INFO][16:50:00]: [Client #408] Model trained.
[INFO][16:50:00]: [Client #408] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:50:00]: [Server #615782] Received 0.26 MB of payload data from client #408 (simulated).
[INFO][16:50:00]: [Server #615782] Selecting client #876 for training.
[INFO][16:50:00]: [Server #615782] Sending the current model to client #876 (simulated).
[INFO][16:50:00]: [Server #615782] Sending 0.26 MB of payload data to client #876 (simulated).
[INFO][16:50:00]: [Client #876] Selected by the server.
[INFO][16:50:00]: [Client #876] Loading its data source...
[INFO][16:50:00]: Data source: FEMNIST
[INFO][16:50:00]: [Client #876] Dataset size: 155
[INFO][16:50:00]: [Client #876] Sampler: all_inclusive
[INFO][16:50:00]: [Client #876] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:50:00]: [93m[1m[Client #876] Started training in communication round #17.[0m
[INFO][16:50:02]: [Client #876] Loading the dataset.
[INFO][16:50:09]: [Client #876] Epoch: [1/5][0/16]	Loss: 1.453691
[INFO][16:50:09]: [Client #876] Epoch: [1/5][10/16]	Loss: 1.531801
[INFO][16:50:09]: [Client #876] Going to sleep for 0.05 seconds.
[INFO][16:50:09]: [Client #876] Woke up.
[INFO][16:50:09]: [Client #876] Epoch: [2/5][0/16]	Loss: 0.387560
[INFO][16:50:09]: [Client #876] Epoch: [2/5][10/16]	Loss: 1.045050
[INFO][16:50:09]: [Client #876] Going to sleep for 0.05 seconds.
[INFO][16:50:09]: [Client #876] Woke up.
[INFO][16:50:09]: [Client #876] Epoch: [3/5][0/16]	Loss: 0.277181
[INFO][16:50:09]: [Client #876] Epoch: [3/5][10/16]	Loss: 0.460939
[INFO][16:50:09]: [Client #876] Going to sleep for 0.05 seconds.
[INFO][16:50:09]: [Client #876] Woke up.
[INFO][16:50:09]: [Client #876] Epoch: [4/5][0/16]	Loss: 0.379241
[INFO][16:50:09]: [Client #876] Epoch: [4/5][10/16]	Loss: 0.502430
[INFO][16:50:09]: [Client #876] Going to sleep for 0.05 seconds.
[INFO][16:50:09]: [Client #876] Woke up.
[INFO][16:50:09]: [Client #876] Epoch: [5/5][0/16]	Loss: 0.136840
[INFO][16:50:10]: [Client #876] Epoch: [5/5][10/16]	Loss: 0.955460
[INFO][16:50:10]: [Client #876] Going to sleep for 0.05 seconds.
[INFO][16:50:10]: [Client #876] Woke up.
[INFO][16:50:10]: [Client #876] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_876_615874.pth.
[INFO][16:50:10]: [Client #876] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_876_615874.pth.
[INFO][16:50:10]: [Client #876] Model trained.
[INFO][16:50:10]: [Client #876] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:50:10]: [Server #615782] Received 0.26 MB of payload data from client #876 (simulated).
[INFO][16:50:10]: [Server #615782] Adding client #876 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #621 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #648 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #656 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #626 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #451 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #408 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #807 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #580 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #253 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #95 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #619 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #554 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #543 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #231 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #770 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #232 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #243 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #106 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #714 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #915 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #754 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #524 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #813 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Adding client #856 to the list of clients for aggregation.
[INFO][16:50:10]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12896313 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16716411 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1302436  0.24706062 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12678533 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.32744854 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14385592
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12067867 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1762849  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16178224 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11858716 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20683387 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14403748 0.         0.14928123 0.         0.         0.
 0.         0.11308515 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.33364913
 0.         0.         0.         0.         0.         0.
 0.         0.09753228 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10971024
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16385453 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08061525 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07494987 0.         0.         0.
 0.         0.         0.74520782 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08759169 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14678965
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1005381  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12896313 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16716411 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1302436  0.24706062 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12678533 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.32744854 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14385592
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12067867 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1762849  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16178224 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11858716 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20683387 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14403748 0.         0.14928123 0.         0.         0.
 0.         0.11308515 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.33364913
 0.         0.         0.         0.         0.         0.
 0.         0.09753228 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10971024
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16385453 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08061525 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07494987 0.         0.         0.
 0.         0.         0.74520782 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08759169 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14678965
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1005381  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.001      0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.0350013  0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.0420101  0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.03536294 0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.04067358 0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.001      0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07796028 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.001      0.04095046
 0.001      0.001      0.001      0.001      0.001      0.001
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.04068067 0.04307365 0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.04227599 0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.04280776 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.0357513  0.001      0.04226082 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.04147833
 0.001      0.001      0.001      0.001      0.02013933 0.01879376
 0.001      0.001      0.001      0.001      0.03756477 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03881946 0.001      0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02670469 0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.0357513  0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.04307365 0.001      0.001      0.001      0.04063039
 0.0386082  0.001      0.04196891 0.001      0.06692817 0.01709943
 0.04067358 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.03881946 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03626943 0.03889033
 0.04248705 0.04307365 0.001      0.05103627 0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.02366392 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.01879376 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.03137153 0.01937935 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.03826169
 0.03828769 0.001      0.04094656 0.001      0.001      0.001
 0.001      0.04307365 0.03989637 0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.04015544 0.03707545 0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.0401489
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.0420101  0.03892821 0.04066924 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.001      0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.01709943
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.04307365
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.001
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.03989637 0.001      0.001
 0.001      0.03810651 0.001      0.02977931 0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.04227599 0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.02064598 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.03613604
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.04174422 0.0373057  0.03241574 0.03778932
 0.001      0.001      0.0401489  0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0373057  0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.04196891 0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.04094656 0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03963731
 0.001      0.02800639 0.001      0.04170984 0.001      0.03834197
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.04121244
 0.03937824 0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.0192851  0.03987651 0.01937935 0.07340324
 0.001      0.04222798 0.001      0.04096448 0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.04121244 0.001      0.001      0.001
 0.03911917 0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03188474 0.04248705
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03767545 0.04076739
 0.03613604 0.03549223 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03551983 0.001
 0.001      0.03304023 0.001      0.001      0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.04170984
 0.04095046 0.001      0.02051932 0.001      0.001      0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][16:50:54]: [Server #615782] Global model accuracy: 57.69%

[INFO][16:50:54]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_17.pth.
[INFO][16:50:54]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_17.pth.
[INFO][16:50:54]: [93m[1m
[Server #615782] Starting round 18/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  8e-04  4e-09  4e-09
 5:  7.5999e+00  7.5999e+00  5e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  4e-05  1e-10  1e-10
 7:  7.5999e+00  7.5999e+00  4e-05  2e-09  2e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  2e-10
 9:  7.5999e+00  7.5999e+00  2e-05  3e-09  3e-10
10:  7.5999e+00  7.5999e+00  3e-06  9e-09  8e-10
Optimal solution found.
The calculated probability is:  [7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48937780e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.48875645e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48951992e-05 7.48006750e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48944699e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.47085231e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.48868323e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49020073e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.48623415e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48825687e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.48974009e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.48997738e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48925985e-05 7.49264042e-05
 7.48848779e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49000289e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.47273728e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49077400e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49015792e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.48999370e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49134902e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49155203e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.39435905e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 9.25225591e-01
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.48857289e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49073179e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05 7.49264042e-05
 7.49264042e-05 7.49264042e-05 7.49264042e-05][INFO][16:50:56]: [Server #615782] Selected clients: [856 502 590 667 452 525 658 181 787 603 981 222 465 897 602 726 413 684
 947 200 807 970  15 215 117]
[INFO][16:50:56]: [Server #615782] Selecting client #856 for training.
[INFO][16:50:56]: [Server #615782] Sending the current model to client #856 (simulated).
[INFO][16:50:56]: [Server #615782] Sending 0.26 MB of payload data to client #856 (simulated).
[INFO][16:50:56]: [Server #615782] Selecting client #502 for training.
[INFO][16:50:56]: [Server #615782] Sending the current model to client #502 (simulated).
[INFO][16:50:56]: [Server #615782] Sending 0.26 MB of payload data to client #502 (simulated).
[INFO][16:50:56]: [Client #856] Selected by the server.
[INFO][16:50:56]: [Client #856] Loading its data source...
[INFO][16:50:56]: Data source: FEMNIST
[INFO][16:50:56]: [Client #502] Selected by the server.
[INFO][16:50:56]: [Client #502] Loading its data source...
[INFO][16:50:56]: Data source: FEMNIST
[INFO][16:50:56]: [Client #502] Dataset size: 163
[INFO][16:50:56]: [Client #502] Sampler: all_inclusive
[INFO][16:50:56]: [Client #502] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:50:56]: [Client #856] Dataset size: 154
[INFO][16:50:56]: [Client #856] Sampler: all_inclusive
[INFO][16:50:56]: [Client #856] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:50:56]: [93m[1m[Client #856] Started training in communication round #18.[0m
[INFO][16:50:56]: [93m[1m[Client #502] Started training in communication round #18.[0m
[INFO][16:50:59]: [Client #856] Loading the dataset.
[INFO][16:50:59]: [Client #502] Loading the dataset.
[INFO][16:51:06]: [Client #856] Epoch: [1/5][0/16]	Loss: 0.605846
[INFO][16:51:06]: [Client #502] Epoch: [1/5][0/17]	Loss: 0.119966
[INFO][16:51:06]: [Client #856] Epoch: [1/5][10/16]	Loss: 0.764532
[INFO][16:51:06]: [Client #502] Epoch: [1/5][10/17]	Loss: 0.144315
[INFO][16:51:06]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:51:06]: [Client #502] Going to sleep for 0.29 seconds.
[INFO][16:51:06]: [Client #502] Woke up.
[INFO][16:51:06]: [Client #502] Epoch: [2/5][0/17]	Loss: 0.604296
[INFO][16:51:06]: [Client #502] Epoch: [2/5][10/17]	Loss: 0.580924
[INFO][16:51:06]: [Client #502] Going to sleep for 0.29 seconds.
[INFO][16:51:06]: [Client #502] Woke up.
[INFO][16:51:06]: [Client #502] Epoch: [3/5][0/17]	Loss: 1.337925
[INFO][16:51:07]: [Client #502] Epoch: [3/5][10/17]	Loss: 0.853949
[INFO][16:51:07]: [Client #502] Going to sleep for 0.29 seconds.
[INFO][16:51:07]: [Client #502] Woke up.
[INFO][16:51:07]: [Client #502] Epoch: [4/5][0/17]	Loss: 0.142229
[INFO][16:51:07]: [Client #502] Epoch: [4/5][10/17]	Loss: 0.419105
[INFO][16:51:07]: [Client #502] Going to sleep for 0.29 seconds.
[INFO][16:51:07]: [Client #502] Woke up.
[INFO][16:51:07]: [Client #502] Epoch: [5/5][0/17]	Loss: 0.870787
[INFO][16:51:07]: [Client #502] Epoch: [5/5][10/17]	Loss: 0.626783
[INFO][16:51:07]: [Client #502] Going to sleep for 0.29 seconds.
[INFO][16:51:08]: [Client #502] Woke up.
[INFO][16:51:08]: [Client #502] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_502_615875.pth.
[INFO][16:51:08]: [Client #502] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_502_615875.pth.
[INFO][16:51:08]: [Client #502] Model trained.
[INFO][16:51:08]: [Client #502] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:51:08]: [Server #615782] Received 0.26 MB of payload data from client #502 (simulated).
[INFO][16:52:06]: [Client #856] Woke up.
[INFO][16:52:06]: [Client #856] Epoch: [2/5][0/16]	Loss: 0.744991
[INFO][16:52:06]: [Client #856] Epoch: [2/5][10/16]	Loss: 0.924232
[INFO][16:52:06]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:53:06]: [Client #856] Woke up.
[INFO][16:53:06]: [Client #856] Epoch: [3/5][0/16]	Loss: 0.493473
[INFO][16:53:06]: [Client #856] Epoch: [3/5][10/16]	Loss: 1.009677
[INFO][16:53:06]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:54:06]: [Client #856] Woke up.
[INFO][16:54:06]: [Client #856] Epoch: [4/5][0/16]	Loss: 0.488151
[INFO][16:54:07]: [Client #856] Epoch: [4/5][10/16]	Loss: 0.772347
[INFO][16:54:07]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:55:07]: [Client #856] Woke up.
[INFO][16:55:07]: [Client #856] Epoch: [5/5][0/16]	Loss: 0.838378
[INFO][16:55:07]: [Client #856] Epoch: [5/5][10/16]	Loss: 0.183344
[INFO][16:55:07]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][16:56:07]: [Client #856] Woke up.
[INFO][16:56:07]: [Client #856] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:56:08]: [Client #856] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][16:56:08]: [Client #856] Model trained.
[INFO][16:56:08]: [Client #856] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:56:08]: [Server #615782] Received 0.26 MB of payload data from client #856 (simulated).
[INFO][16:56:08]: [Server #615782] Selecting client #590 for training.
[INFO][16:56:08]: [Server #615782] Sending the current model to client #590 (simulated).
[INFO][16:56:08]: [Server #615782] Sending 0.26 MB of payload data to client #590 (simulated).
[INFO][16:56:08]: [Server #615782] Selecting client #667 for training.
[INFO][16:56:08]: [Server #615782] Sending the current model to client #667 (simulated).
[INFO][16:56:08]: [Server #615782] Sending 0.26 MB of payload data to client #667 (simulated).
[INFO][16:56:08]: [Client #590] Selected by the server.
[INFO][16:56:08]: [Client #590] Loading its data source...
[INFO][16:56:08]: Data source: FEMNIST
[INFO][16:56:08]: [Client #667] Selected by the server.
[INFO][16:56:08]: [Client #667] Loading its data source...
[INFO][16:56:08]: Data source: FEMNIST
[INFO][16:56:08]: [Client #590] Dataset size: 153
[INFO][16:56:08]: [Client #590] Sampler: all_inclusive
[INFO][16:56:08]: [Client #590] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:08]: [93m[1m[Client #590] Started training in communication round #18.[0m
[INFO][16:56:08]: [Client #667] Dataset size: 243
[INFO][16:56:08]: [Client #667] Sampler: all_inclusive
[INFO][16:56:08]: [Client #667] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:08]: [93m[1m[Client #667] Started training in communication round #18.[0m
[INFO][16:56:10]: [Client #590] Loading the dataset.
[INFO][16:56:10]: [Client #667] Loading the dataset.
[INFO][16:56:15]: [Client #590] Epoch: [1/5][0/16]	Loss: 0.390358
[INFO][16:56:15]: [Client #590] Epoch: [1/5][10/16]	Loss: 0.248222
[INFO][16:56:15]: [Client #667] Epoch: [1/5][0/25]	Loss: 3.474081
[INFO][16:56:15]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][16:56:15]: [Client #667] Epoch: [1/5][10/25]	Loss: 2.695988
[INFO][16:56:15]: [Client #667] Epoch: [1/5][20/25]	Loss: 1.219166
[INFO][16:56:15]: [Client #667] Going to sleep for 2.61 seconds.
[INFO][16:56:18]: [Client #667] Woke up.
[INFO][16:56:18]: [Client #667] Epoch: [2/5][0/25]	Loss: 1.332246
[INFO][16:56:18]: [Client #667] Epoch: [2/5][10/25]	Loss: 0.736185
[INFO][16:56:18]: [Client #667] Epoch: [2/5][20/25]	Loss: 1.718379
[INFO][16:56:18]: [Client #667] Going to sleep for 2.61 seconds.
[INFO][16:56:19]: [Client #590] Woke up.
[INFO][16:56:19]: [Client #590] Epoch: [2/5][0/16]	Loss: 0.301984
[INFO][16:56:19]: [Client #590] Epoch: [2/5][10/16]	Loss: 0.389122
[INFO][16:56:19]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][16:56:21]: [Client #667] Woke up.
[INFO][16:56:21]: [Client #667] Epoch: [3/5][0/25]	Loss: 1.937292
[INFO][16:56:21]: [Client #667] Epoch: [3/5][10/25]	Loss: 1.893228
[INFO][16:56:21]: [Client #667] Epoch: [3/5][20/25]	Loss: 1.573259
[INFO][16:56:21]: [Client #667] Going to sleep for 2.61 seconds.
[INFO][16:56:22]: [Client #590] Woke up.
[INFO][16:56:22]: [Client #590] Epoch: [3/5][0/16]	Loss: 1.195266
[INFO][16:56:22]: [Client #590] Epoch: [3/5][10/16]	Loss: 0.785256
[INFO][16:56:22]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][16:56:24]: [Client #667] Woke up.
[INFO][16:56:24]: [Client #667] Epoch: [4/5][0/25]	Loss: 0.789878
[INFO][16:56:24]: [Client #667] Epoch: [4/5][10/25]	Loss: 2.094184
[INFO][16:56:24]: [Client #667] Epoch: [4/5][20/25]	Loss: 2.444033
[INFO][16:56:24]: [Client #667] Going to sleep for 2.61 seconds.
[INFO][16:56:25]: [Client #590] Woke up.
[INFO][16:56:25]: [Client #590] Epoch: [4/5][0/16]	Loss: 0.240682
[INFO][16:56:26]: [Client #590] Epoch: [4/5][10/16]	Loss: 0.627792
[INFO][16:56:26]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][16:56:26]: [Client #667] Woke up.
[INFO][16:56:26]: [Client #667] Epoch: [5/5][0/25]	Loss: 0.872057
[INFO][16:56:27]: [Client #667] Epoch: [5/5][10/25]	Loss: 3.032979
[INFO][16:56:27]: [Client #667] Epoch: [5/5][20/25]	Loss: 1.376445
[INFO][16:56:27]: [Client #667] Going to sleep for 2.61 seconds.
[INFO][16:56:29]: [Client #590] Woke up.
[INFO][16:56:29]: [Client #590] Epoch: [5/5][0/16]	Loss: 0.235179
[INFO][16:56:29]: [Client #590] Epoch: [5/5][10/16]	Loss: 2.529653
[INFO][16:56:29]: [Client #590] Going to sleep for 3.30 seconds.
[INFO][16:56:29]: [Client #667] Woke up.
[INFO][16:56:29]: [Client #667] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_667_615875.pth.
[INFO][16:56:30]: [Client #667] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_667_615875.pth.
[INFO][16:56:30]: [Client #667] Model trained.
[INFO][16:56:30]: [Client #667] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:56:30]: [Server #615782] Received 0.26 MB of payload data from client #667 (simulated).
[INFO][16:56:32]: [Client #590] Woke up.
[INFO][16:56:32]: [Client #590] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615874.pth.
[INFO][16:56:33]: [Client #590] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_590_615874.pth.
[INFO][16:56:33]: [Client #590] Model trained.
[INFO][16:56:33]: [Client #590] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:56:33]: [Server #615782] Received 0.26 MB of payload data from client #590 (simulated).
[INFO][16:56:33]: [Server #615782] Selecting client #452 for training.
[INFO][16:56:33]: [Server #615782] Sending the current model to client #452 (simulated).
[INFO][16:56:33]: [Server #615782] Sending 0.26 MB of payload data to client #452 (simulated).
[INFO][16:56:33]: [Server #615782] Selecting client #525 for training.
[INFO][16:56:33]: [Server #615782] Sending the current model to client #525 (simulated).
[INFO][16:56:33]: [Server #615782] Sending 0.26 MB of payload data to client #525 (simulated).
[INFO][16:56:33]: [Client #452] Selected by the server.
[INFO][16:56:33]: [Client #452] Loading its data source...
[INFO][16:56:33]: Data source: FEMNIST
[INFO][16:56:33]: [Client #525] Selected by the server.
[INFO][16:56:33]: [Client #525] Loading its data source...
[INFO][16:56:33]: Data source: FEMNIST
[INFO][16:56:33]: [Client #525] Dataset size: 146
[INFO][16:56:33]: [Client #525] Sampler: all_inclusive
[INFO][16:56:33]: [Client #525] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:33]: [93m[1m[Client #525] Started training in communication round #18.[0m
[INFO][16:56:33]: [Client #452] Dataset size: 162
[INFO][16:56:33]: [Client #452] Sampler: all_inclusive
[INFO][16:56:33]: [Client #452] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:33]: [93m[1m[Client #452] Started training in communication round #18.[0m
[INFO][16:56:35]: [Client #525] Loading the dataset.
[INFO][16:56:35]: [Client #452] Loading the dataset.
[INFO][16:56:41]: [Client #525] Epoch: [1/5][0/15]	Loss: 0.886730
[INFO][16:56:41]: [Client #452] Epoch: [1/5][0/17]	Loss: 0.719529
[INFO][16:56:41]: [Client #525] Epoch: [1/5][10/15]	Loss: 2.605060
[INFO][16:56:41]: [Client #525] Going to sleep for 1.47 seconds.
[INFO][16:56:41]: [Client #452] Epoch: [1/5][10/17]	Loss: 0.629307
[INFO][16:56:41]: [Client #452] Going to sleep for 1.65 seconds.
[INFO][16:56:42]: [Client #525] Woke up.
[INFO][16:56:42]: [Client #525] Epoch: [2/5][0/15]	Loss: 1.213506
[INFO][16:56:42]: [Client #525] Epoch: [2/5][10/15]	Loss: 1.792804
[INFO][16:56:42]: [Client #525] Going to sleep for 1.47 seconds.
[INFO][16:56:42]: [Client #452] Woke up.
[INFO][16:56:42]: [Client #452] Epoch: [2/5][0/17]	Loss: 0.687837
[INFO][16:56:43]: [Client #452] Epoch: [2/5][10/17]	Loss: 2.125068
[INFO][16:56:43]: [Client #452] Going to sleep for 1.65 seconds.
[INFO][16:56:44]: [Client #525] Woke up.
[INFO][16:56:44]: [Client #525] Epoch: [3/5][0/15]	Loss: 1.211768
[INFO][16:56:44]: [Client #525] Epoch: [3/5][10/15]	Loss: 2.247311
[INFO][16:56:44]: [Client #525] Going to sleep for 1.47 seconds.
[INFO][16:56:44]: [Client #452] Woke up.
[INFO][16:56:44]: [Client #452] Epoch: [3/5][0/17]	Loss: 0.828238
[INFO][16:56:44]: [Client #452] Epoch: [3/5][10/17]	Loss: 1.095672
[INFO][16:56:44]: [Client #452] Going to sleep for 1.65 seconds.
[INFO][16:56:45]: [Client #525] Woke up.
[INFO][16:56:45]: [Client #525] Epoch: [4/5][0/15]	Loss: 1.609875
[INFO][16:56:46]: [Client #525] Epoch: [4/5][10/15]	Loss: 1.558199
[INFO][16:56:46]: [Client #525] Going to sleep for 1.47 seconds.
[INFO][16:56:46]: [Client #452] Woke up.
[INFO][16:56:46]: [Client #452] Epoch: [4/5][0/17]	Loss: 0.329828
[INFO][16:56:46]: [Client #452] Epoch: [4/5][10/17]	Loss: 0.515052
[INFO][16:56:46]: [Client #452] Going to sleep for 1.65 seconds.
[INFO][16:56:47]: [Client #525] Woke up.
[INFO][16:56:47]: [Client #525] Epoch: [5/5][0/15]	Loss: 2.507908
[INFO][16:56:47]: [Client #525] Epoch: [5/5][10/15]	Loss: 1.091572
[INFO][16:56:47]: [Client #525] Going to sleep for 1.47 seconds.
[INFO][16:56:48]: [Client #452] Woke up.
[INFO][16:56:48]: [Client #452] Epoch: [5/5][0/17]	Loss: 0.593757
[INFO][16:56:48]: [Client #452] Epoch: [5/5][10/17]	Loss: 1.085234
[INFO][16:56:48]: [Client #452] Going to sleep for 1.65 seconds.
[INFO][16:56:49]: [Client #525] Woke up.
[INFO][16:56:49]: [Client #525] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_525_615875.pth.
[INFO][16:56:49]: [Client #525] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_525_615875.pth.
[INFO][16:56:49]: [Client #525] Model trained.
[INFO][16:56:49]: [Client #525] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:56:49]: [Server #615782] Received 0.26 MB of payload data from client #525 (simulated).
[INFO][16:56:50]: [Client #452] Woke up.
[INFO][16:56:50]: [Client #452] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_452_615874.pth.
[INFO][16:56:50]: [Client #452] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_452_615874.pth.
[INFO][16:56:50]: [Client #452] Model trained.
[INFO][16:56:50]: [Client #452] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:56:50]: [Server #615782] Received 0.26 MB of payload data from client #452 (simulated).
[INFO][16:56:50]: [Server #615782] Selecting client #658 for training.
[INFO][16:56:50]: [Server #615782] Sending the current model to client #658 (simulated).
[INFO][16:56:50]: [Server #615782] Sending 0.26 MB of payload data to client #658 (simulated).
[INFO][16:56:50]: [Server #615782] Selecting client #181 for training.
[INFO][16:56:50]: [Server #615782] Sending the current model to client #181 (simulated).
[INFO][16:56:50]: [Server #615782] Sending 0.26 MB of payload data to client #181 (simulated).
[INFO][16:56:50]: [Client #658] Selected by the server.
[INFO][16:56:50]: [Client #658] Loading its data source...
[INFO][16:56:50]: Data source: FEMNIST
[INFO][16:56:50]: [Client #181] Selected by the server.
[INFO][16:56:50]: [Client #181] Loading its data source...
[INFO][16:56:50]: Data source: FEMNIST
[INFO][16:56:50]: [Client #181] Dataset size: 161
[INFO][16:56:50]: [Client #181] Sampler: all_inclusive
[INFO][16:56:50]: [Client #658] Dataset size: 158
[INFO][16:56:50]: [Client #658] Sampler: all_inclusive
[INFO][16:56:50]: [Client #181] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:50]: [93m[1m[Client #181] Started training in communication round #18.[0m
[INFO][16:56:50]: [Client #658] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:56:50]: [93m[1m[Client #658] Started training in communication round #18.[0m
[INFO][16:56:52]: [Client #181] Loading the dataset.
[INFO][16:56:52]: [Client #658] Loading the dataset.
[INFO][16:56:58]: [Client #658] Epoch: [1/5][0/16]	Loss: 1.152770
[INFO][16:56:58]: [Client #181] Epoch: [1/5][0/17]	Loss: 0.230076
[INFO][16:56:58]: [Client #658] Epoch: [1/5][10/16]	Loss: 2.262982
[INFO][16:56:58]: [Client #181] Epoch: [1/5][10/17]	Loss: 0.548786
[INFO][16:56:58]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][16:56:58]: [Client #181] Going to sleep for 1.70 seconds.
[INFO][16:56:58]: [Client #658] Woke up.
[INFO][16:56:58]: [Client #658] Epoch: [2/5][0/16]	Loss: 0.693710
[INFO][16:56:58]: [Client #658] Epoch: [2/5][10/16]	Loss: 1.312819
[INFO][16:56:58]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][16:56:58]: [Client #658] Woke up.
[INFO][16:56:58]: [Client #658] Epoch: [3/5][0/16]	Loss: 1.153866
[INFO][16:56:58]: [Client #658] Epoch: [3/5][10/16]	Loss: 0.915434
[INFO][16:56:58]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][16:56:59]: [Client #658] Woke up.
[INFO][16:56:59]: [Client #658] Epoch: [4/5][0/16]	Loss: 0.723262
[INFO][16:56:59]: [Client #658] Epoch: [4/5][10/16]	Loss: 1.105414
[INFO][16:56:59]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][16:56:59]: [Client #658] Woke up.
[INFO][16:56:59]: [Client #658] Epoch: [5/5][0/16]	Loss: 1.308408
[INFO][16:56:59]: [Client #658] Epoch: [5/5][10/16]	Loss: 1.213777
[INFO][16:56:59]: [Client #658] Going to sleep for 0.05 seconds.
[INFO][16:56:59]: [Client #658] Woke up.
[INFO][16:56:59]: [Client #658] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615874.pth.
[INFO][16:57:00]: [Client #658] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_658_615874.pth.
[INFO][16:57:00]: [Client #658] Model trained.
[INFO][16:57:00]: [Client #658] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:57:00]: [Server #615782] Received 0.26 MB of payload data from client #658 (simulated).
[INFO][16:57:00]: [Client #181] Woke up.
[INFO][16:57:00]: [Client #181] Epoch: [2/5][0/17]	Loss: 0.665419
[INFO][16:57:00]: [Client #181] Epoch: [2/5][10/17]	Loss: 2.909939
[INFO][16:57:00]: [Client #181] Going to sleep for 1.70 seconds.
[INFO][16:57:02]: [Client #181] Woke up.
[INFO][16:57:02]: [Client #181] Epoch: [3/5][0/17]	Loss: 0.937144
[INFO][16:57:02]: [Client #181] Epoch: [3/5][10/17]	Loss: 0.643313
[INFO][16:57:02]: [Client #181] Going to sleep for 1.70 seconds.
[INFO][16:57:04]: [Client #181] Woke up.
[INFO][16:57:04]: [Client #181] Epoch: [4/5][0/17]	Loss: 0.602458
[INFO][16:57:04]: [Client #181] Epoch: [4/5][10/17]	Loss: 0.340696
[INFO][16:57:04]: [Client #181] Going to sleep for 1.70 seconds.
[INFO][16:57:05]: [Client #181] Woke up.
[INFO][16:57:05]: [Client #181] Epoch: [5/5][0/17]	Loss: 0.965118
[INFO][16:57:05]: [Client #181] Epoch: [5/5][10/17]	Loss: 0.335533
[INFO][16:57:06]: [Client #181] Going to sleep for 1.70 seconds.
[INFO][16:57:07]: [Client #181] Woke up.
[INFO][16:57:07]: [Client #181] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_181_615875.pth.
[INFO][16:57:08]: [Client #181] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_181_615875.pth.
[INFO][16:57:08]: [Client #181] Model trained.
[INFO][16:57:08]: [Client #181] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:57:08]: [Server #615782] Received 0.26 MB of payload data from client #181 (simulated).
[INFO][16:57:08]: [Server #615782] Selecting client #787 for training.
[INFO][16:57:08]: [Server #615782] Sending the current model to client #787 (simulated).
[INFO][16:57:08]: [Server #615782] Sending 0.26 MB of payload data to client #787 (simulated).
[INFO][16:57:08]: [Server #615782] Selecting client #603 for training.
[INFO][16:57:08]: [Server #615782] Sending the current model to client #603 (simulated).
[INFO][16:57:08]: [Server #615782] Sending 0.26 MB of payload data to client #603 (simulated).
[INFO][16:57:08]: [Client #787] Selected by the server.
[INFO][16:57:08]: [Client #787] Loading its data source...
[INFO][16:57:08]: Data source: FEMNIST
[INFO][16:57:08]: [Client #603] Selected by the server.
[INFO][16:57:08]: [Client #603] Loading its data source...
[INFO][16:57:08]: Data source: FEMNIST
[INFO][16:57:08]: [Client #603] Dataset size: 153
[INFO][16:57:08]: [Client #603] Sampler: all_inclusive
[INFO][16:57:08]: [Client #787] Dataset size: 163
[INFO][16:57:08]: [Client #787] Sampler: all_inclusive
[INFO][16:57:08]: [Client #603] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:57:08]: [Client #787] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:57:08]: [93m[1m[Client #603] Started training in communication round #18.[0m
[INFO][16:57:08]: [93m[1m[Client #787] Started training in communication round #18.[0m
[INFO][16:57:10]: [Client #603] Loading the dataset.
[INFO][16:57:10]: [Client #787] Loading the dataset.
[INFO][16:57:16]: [Client #787] Epoch: [1/5][0/17]	Loss: 0.395920
[INFO][16:57:16]: [Client #603] Epoch: [1/5][0/16]	Loss: 0.444758
[INFO][16:57:16]: [Client #787] Epoch: [1/5][10/17]	Loss: 1.544887
[INFO][16:57:16]: [Client #603] Epoch: [1/5][10/16]	Loss: 1.031654
[INFO][16:57:16]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][16:57:16]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][16:57:16]: [Client #603] Woke up.
[INFO][16:57:16]: [Client #603] Epoch: [2/5][0/16]	Loss: 0.987248
[INFO][16:57:16]: [Client #603] Epoch: [2/5][10/16]	Loss: 0.687732
[INFO][16:57:16]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][16:57:16]: [Client #603] Woke up.
[INFO][16:57:17]: [Client #603] Epoch: [3/5][0/16]	Loss: 0.847781
[INFO][16:57:17]: [Client #603] Epoch: [3/5][10/16]	Loss: 0.372278
[INFO][16:57:17]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][16:57:17]: [Client #603] Woke up.
[INFO][16:57:17]: [Client #603] Epoch: [4/5][0/16]	Loss: 0.275572
[INFO][16:57:17]: [Client #603] Epoch: [4/5][10/16]	Loss: 0.789028
[INFO][16:57:17]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][16:57:17]: [Client #603] Woke up.
[INFO][16:57:17]: [Client #603] Epoch: [5/5][0/16]	Loss: 0.411496
[INFO][16:57:17]: [Client #603] Epoch: [5/5][10/16]	Loss: 0.969232
[INFO][16:57:17]: [Client #603] Going to sleep for 0.09 seconds.
[INFO][16:57:17]: [Client #603] Woke up.
[INFO][16:57:17]: [Client #603] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615875.pth.
[INFO][16:57:18]: [Client #603] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_603_615875.pth.
[INFO][16:57:18]: [Client #603] Model trained.
[INFO][16:57:18]: [Client #603] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:57:18]: [Server #615782] Received 0.26 MB of payload data from client #603 (simulated).
[INFO][16:57:22]: [Client #787] Woke up.
[INFO][16:57:22]: [Client #787] Epoch: [2/5][0/17]	Loss: 1.093657
[INFO][16:57:22]: [Client #787] Epoch: [2/5][10/17]	Loss: 1.182414
[INFO][16:57:22]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][16:57:28]: [Client #787] Woke up.
[INFO][16:57:28]: [Client #787] Epoch: [3/5][0/17]	Loss: 0.754580
[INFO][16:57:28]: [Client #787] Epoch: [3/5][10/17]	Loss: 1.387758
[INFO][16:57:28]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][16:57:35]: [Client #787] Woke up.
[INFO][16:57:35]: [Client #787] Epoch: [4/5][0/17]	Loss: 1.224245
[INFO][16:57:35]: [Client #787] Epoch: [4/5][10/17]	Loss: 0.483333
[INFO][16:57:35]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][16:57:41]: [Client #787] Woke up.
[INFO][16:57:41]: [Client #787] Epoch: [5/5][0/17]	Loss: 0.803751
[INFO][16:57:41]: [Client #787] Epoch: [5/5][10/17]	Loss: 1.810717
[INFO][16:57:41]: [Client #787] Going to sleep for 6.02 seconds.
[INFO][16:57:47]: [Client #787] Woke up.
[INFO][16:57:47]: [Client #787] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_787_615874.pth.
[INFO][16:57:48]: [Client #787] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_787_615874.pth.
[INFO][16:57:48]: [Client #787] Model trained.
[INFO][16:57:48]: [Client #787] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:57:48]: [Server #615782] Received 0.26 MB of payload data from client #787 (simulated).
[INFO][16:57:48]: [Server #615782] Selecting client #981 for training.
[INFO][16:57:48]: [Server #615782] Sending the current model to client #981 (simulated).
[INFO][16:57:48]: [Server #615782] Sending 0.26 MB of payload data to client #981 (simulated).
[INFO][16:57:48]: [Server #615782] Selecting client #222 for training.
[INFO][16:57:48]: [Server #615782] Sending the current model to client #222 (simulated).
[INFO][16:57:48]: [Server #615782] Sending 0.26 MB of payload data to client #222 (simulated).
[INFO][16:57:48]: [Client #981] Selected by the server.
[INFO][16:57:48]: [Client #981] Loading its data source...
[INFO][16:57:48]: Data source: FEMNIST
[INFO][16:57:48]: [Client #222] Selected by the server.
[INFO][16:57:48]: [Client #222] Loading its data source...
[INFO][16:57:48]: Data source: FEMNIST
[INFO][16:57:48]: [Client #981] Dataset size: 162
[INFO][16:57:48]: [Client #981] Sampler: all_inclusive
[INFO][16:57:48]: [Client #981] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:57:48]: [93m[1m[Client #981] Started training in communication round #18.[0m
[INFO][16:57:48]: [Client #222] Dataset size: 328
[INFO][16:57:48]: [Client #222] Sampler: all_inclusive
[INFO][16:57:48]: [Client #222] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:57:48]: [93m[1m[Client #222] Started training in communication round #18.[0m
[INFO][16:57:50]: [Client #222] Loading the dataset.
[INFO][16:57:50]: [Client #981] Loading the dataset.
[INFO][16:57:56]: [Client #222] Epoch: [1/5][0/33]	Loss: 2.121459
[INFO][16:57:56]: [Client #981] Epoch: [1/5][0/17]	Loss: 0.426994
[INFO][16:57:56]: [Client #222] Epoch: [1/5][10/33]	Loss: 1.708809
[INFO][16:57:56]: [Client #981] Epoch: [1/5][10/17]	Loss: 0.828144
[INFO][16:57:56]: [Client #222] Epoch: [1/5][20/33]	Loss: 1.216389
[INFO][16:57:56]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][16:57:56]: [Client #222] Epoch: [1/5][30/33]	Loss: 2.163472
[INFO][16:57:56]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][16:57:56]: [Client #981] Woke up.
[INFO][16:57:56]: [Client #981] Epoch: [2/5][0/17]	Loss: 1.087493
[INFO][16:57:56]: [Client #981] Epoch: [2/5][10/17]	Loss: 0.604422
[INFO][16:57:56]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][16:57:57]: [Client #981] Woke up.
[INFO][16:57:57]: [Client #981] Epoch: [3/5][0/17]	Loss: 1.391982
[INFO][16:57:57]: [Client #222] Woke up.
[INFO][16:57:57]: [Client #222] Epoch: [2/5][0/33]	Loss: 1.254174
[INFO][16:57:57]: [Client #981] Epoch: [3/5][10/17]	Loss: 0.170523
[INFO][16:57:57]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][16:57:57]: [Client #222] Epoch: [2/5][10/33]	Loss: 0.738047
[INFO][16:57:57]: [Client #222] Epoch: [2/5][20/33]	Loss: 1.458627
[INFO][16:57:57]: [Client #981] Woke up.
[INFO][16:57:57]: [Client #981] Epoch: [4/5][0/17]	Loss: 1.501513
[INFO][16:57:57]: [Client #222] Epoch: [2/5][30/33]	Loss: 1.184361
[INFO][16:57:57]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][16:57:57]: [Client #981] Epoch: [4/5][10/17]	Loss: 0.662416
[INFO][16:57:57]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][16:57:57]: [Client #981] Woke up.
[INFO][16:57:57]: [Client #981] Epoch: [5/5][0/17]	Loss: 0.369031
[INFO][16:57:57]: [Client #981] Epoch: [5/5][10/17]	Loss: 0.953213
[INFO][16:57:57]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][16:57:57]: [Client #222] Woke up.
[INFO][16:57:57]: [Client #222] Epoch: [3/5][0/33]	Loss: 0.476000
[INFO][16:57:58]: [Client #981] Woke up.
[INFO][16:57:58]: [Client #981] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][16:57:58]: [Client #222] Epoch: [3/5][10/33]	Loss: 1.081616
[INFO][16:57:58]: [Client #222] Epoch: [3/5][20/33]	Loss: 0.988895
[INFO][16:57:58]: [Client #222] Epoch: [3/5][30/33]	Loss: 1.644613
[INFO][16:57:58]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][16:57:58]: [Client #222] Woke up.
[INFO][16:57:58]: [Client #222] Epoch: [4/5][0/33]	Loss: 2.168087
[INFO][16:57:58]: [Client #981] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][16:57:58]: [Client #981] Model trained.
[INFO][16:57:58]: [Client #981] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:57:58]: [Server #615782] Received 0.26 MB of payload data from client #981 (simulated).
[INFO][16:57:58]: [Client #222] Epoch: [4/5][10/33]	Loss: 1.701304
[INFO][16:57:58]: [Client #222] Epoch: [4/5][20/33]	Loss: 2.770139
[INFO][16:57:58]: [Client #222] Epoch: [4/5][30/33]	Loss: 1.417663
[INFO][16:57:58]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][16:57:59]: [Client #222] Woke up.
[INFO][16:57:59]: [Client #222] Epoch: [5/5][0/33]	Loss: 1.301795
[INFO][16:57:59]: [Client #222] Epoch: [5/5][10/33]	Loss: 1.036640
[INFO][16:57:59]: [Client #222] Epoch: [5/5][20/33]	Loss: 1.213120
[INFO][16:57:59]: [Client #222] Epoch: [5/5][30/33]	Loss: 1.419299
[INFO][16:57:59]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][16:58:00]: [Client #222] Woke up.
[INFO][16:58:00]: [Client #222] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_222_615875.pth.
[INFO][16:58:00]: [Client #222] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_222_615875.pth.
[INFO][16:58:00]: [Client #222] Model trained.
[INFO][16:58:00]: [Client #222] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:58:00]: [Server #615782] Received 0.26 MB of payload data from client #222 (simulated).
[INFO][16:58:00]: [Server #615782] Selecting client #465 for training.
[INFO][16:58:00]: [Server #615782] Sending the current model to client #465 (simulated).
[INFO][16:58:00]: [Server #615782] Sending 0.26 MB of payload data to client #465 (simulated).
[INFO][16:58:00]: [Server #615782] Selecting client #897 for training.
[INFO][16:58:00]: [Server #615782] Sending the current model to client #897 (simulated).
[INFO][16:58:00]: [Server #615782] Sending 0.26 MB of payload data to client #897 (simulated).
[INFO][16:58:00]: [Client #465] Selected by the server.
[INFO][16:58:00]: [Client #465] Loading its data source...
[INFO][16:58:00]: Data source: FEMNIST
[INFO][16:58:00]: [Client #897] Selected by the server.
[INFO][16:58:00]: [Client #897] Loading its data source...
[INFO][16:58:00]: Data source: FEMNIST
[INFO][16:58:01]: [Client #465] Dataset size: 103
[INFO][16:58:01]: [Client #465] Sampler: all_inclusive
[INFO][16:58:01]: [Client #465] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:58:01]: [Client #897] Dataset size: 157
[INFO][16:58:01]: [Client #897] Sampler: all_inclusive
[INFO][16:58:01]: [Client #897] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:58:01]: [93m[1m[Client #465] Started training in communication round #18.[0m
[INFO][16:58:01]: [93m[1m[Client #897] Started training in communication round #18.[0m
[INFO][16:58:03]: [Client #465] Loading the dataset.
[INFO][16:58:03]: [Client #897] Loading the dataset.
[INFO][16:58:09]: [Client #465] Epoch: [1/5][0/11]	Loss: 1.125818
[INFO][16:58:09]: [Client #897] Epoch: [1/5][0/16]	Loss: 1.273175
[INFO][16:58:09]: [Client #465] Epoch: [1/5][10/11]	Loss: 1.774960
[INFO][16:58:09]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:58:09]: [Client #897] Epoch: [1/5][10/16]	Loss: 1.925497
[INFO][16:58:09]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][16:58:12]: [Client #897] Woke up.
[INFO][16:58:12]: [Client #897] Epoch: [2/5][0/16]	Loss: 0.770202
[INFO][16:58:12]: [Client #897] Epoch: [2/5][10/16]	Loss: 0.731331
[INFO][16:58:12]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][16:58:13]: [Client #465] Woke up.
[INFO][16:58:13]: [Client #465] Epoch: [2/5][0/11]	Loss: 0.992662
[INFO][16:58:13]: [Client #465] Epoch: [2/5][10/11]	Loss: 0.930265
[INFO][16:58:13]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:58:16]: [Client #897] Woke up.
[INFO][16:58:16]: [Client #897] Epoch: [3/5][0/16]	Loss: 1.012345
[INFO][16:58:16]: [Client #897] Epoch: [3/5][10/16]	Loss: 1.322683
[INFO][16:58:16]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][16:58:18]: [Client #465] Woke up.
[INFO][16:58:18]: [Client #465] Epoch: [3/5][0/11]	Loss: 0.666718
[INFO][16:58:18]: [Client #465] Epoch: [3/5][10/11]	Loss: 0.350417
[INFO][16:58:18]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:58:19]: [Client #897] Woke up.
[INFO][16:58:19]: [Client #897] Epoch: [4/5][0/16]	Loss: 0.512545
[INFO][16:58:19]: [Client #897] Epoch: [4/5][10/16]	Loss: 0.556296
[INFO][16:58:19]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][16:58:22]: [Client #465] Woke up.
[INFO][16:58:22]: [Client #465] Epoch: [4/5][0/11]	Loss: 0.952474
[INFO][16:58:23]: [Client #465] Epoch: [4/5][10/11]	Loss: 0.350722
[INFO][16:58:23]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:58:23]: [Client #897] Woke up.
[INFO][16:58:23]: [Client #897] Epoch: [5/5][0/16]	Loss: 1.487471
[INFO][16:58:23]: [Client #897] Epoch: [5/5][10/16]	Loss: 1.050977
[INFO][16:58:23]: [Client #897] Going to sleep for 3.43 seconds.
[INFO][16:58:26]: [Client #897] Woke up.
[INFO][16:58:26]: [Client #897] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_897_615875.pth.
[INFO][16:58:27]: [Client #465] Woke up.
[INFO][16:58:27]: [Client #465] Epoch: [5/5][0/11]	Loss: 0.066165
[INFO][16:58:27]: [Client #897] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_897_615875.pth.
[INFO][16:58:27]: [Client #897] Model trained.
[INFO][16:58:27]: [Client #897] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:58:27]: [Server #615782] Received 0.26 MB of payload data from client #897 (simulated).
[INFO][16:58:27]: [Client #465] Epoch: [5/5][10/11]	Loss: 0.892365
[INFO][16:58:27]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][16:58:32]: [Client #465] Woke up.
[INFO][16:58:32]: [Client #465] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_615874.pth.
[INFO][16:58:32]: [Client #465] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_615874.pth.
[INFO][16:58:32]: [Client #465] Model trained.
[INFO][16:58:32]: [Client #465] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:58:32]: [Server #615782] Received 0.26 MB of payload data from client #465 (simulated).
[INFO][16:58:32]: [Server #615782] Selecting client #602 for training.
[INFO][16:58:32]: [Server #615782] Sending the current model to client #602 (simulated).
[INFO][16:58:32]: [Server #615782] Sending 0.26 MB of payload data to client #602 (simulated).
[INFO][16:58:32]: [Server #615782] Selecting client #726 for training.
[INFO][16:58:32]: [Server #615782] Sending the current model to client #726 (simulated).
[INFO][16:58:32]: [Server #615782] Sending 0.26 MB of payload data to client #726 (simulated).
[INFO][16:58:32]: [Client #602] Selected by the server.
[INFO][16:58:32]: [Client #602] Loading its data source...
[INFO][16:58:32]: Data source: FEMNIST
[INFO][16:58:32]: [Client #726] Selected by the server.
[INFO][16:58:32]: [Client #726] Loading its data source...
[INFO][16:58:32]: Data source: FEMNIST
[INFO][16:58:32]: [Client #726] Dataset size: 152
[INFO][16:58:32]: [Client #726] Sampler: all_inclusive
[INFO][16:58:32]: [Client #726] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:58:32]: [Client #602] Dataset size: 121
[INFO][16:58:32]: [Client #602] Sampler: all_inclusive
[INFO][16:58:32]: [93m[1m[Client #726] Started training in communication round #18.[0m
[INFO][16:58:32]: [Client #602] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:58:32]: [93m[1m[Client #602] Started training in communication round #18.[0m
[INFO][16:58:34]: [Client #726] Loading the dataset.
[INFO][16:58:34]: [Client #602] Loading the dataset.
[INFO][16:58:40]: [Client #726] Epoch: [1/5][0/16]	Loss: 1.729723
[INFO][16:58:40]: [Client #602] Epoch: [1/5][0/13]	Loss: 0.857964
[INFO][16:58:40]: [Client #726] Epoch: [1/5][10/16]	Loss: 1.223236
[INFO][16:58:40]: [Client #726] Going to sleep for 0.99 seconds.
[INFO][16:58:40]: [Client #602] Epoch: [1/5][10/13]	Loss: 1.971374
[INFO][16:58:40]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:58:41]: [Client #726] Woke up.
[INFO][16:58:41]: [Client #726] Epoch: [2/5][0/16]	Loss: 1.228078
[INFO][16:58:41]: [Client #726] Epoch: [2/5][10/16]	Loss: 0.924287
[INFO][16:58:41]: [Client #726] Going to sleep for 0.99 seconds.
[INFO][16:58:42]: [Client #726] Woke up.
[INFO][16:58:42]: [Client #726] Epoch: [3/5][0/16]	Loss: 1.014259
[INFO][16:58:42]: [Client #726] Epoch: [3/5][10/16]	Loss: 0.497081
[INFO][16:58:42]: [Client #726] Going to sleep for 0.99 seconds.
[INFO][16:58:43]: [Client #726] Woke up.
[INFO][16:58:43]: [Client #726] Epoch: [4/5][0/16]	Loss: 0.549687
[INFO][16:58:43]: [Client #726] Epoch: [4/5][10/16]	Loss: 0.539785
[INFO][16:58:43]: [Client #726] Going to sleep for 0.99 seconds.
[INFO][16:58:44]: [Client #602] Woke up.
[INFO][16:58:44]: [Client #602] Epoch: [2/5][0/13]	Loss: 0.663979
[INFO][16:58:44]: [Client #602] Epoch: [2/5][10/13]	Loss: 0.841970
[INFO][16:58:44]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:58:44]: [Client #726] Woke up.
[INFO][16:58:44]: [Client #726] Epoch: [5/5][0/16]	Loss: 0.392644
[INFO][16:58:45]: [Client #726] Epoch: [5/5][10/16]	Loss: 0.876933
[INFO][16:58:45]: [Client #726] Going to sleep for 0.99 seconds.
[INFO][16:58:46]: [Client #726] Woke up.
[INFO][16:58:46]: [Client #726] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_726_615875.pth.
[INFO][16:58:46]: [Client #726] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_726_615875.pth.
[INFO][16:58:46]: [Client #726] Model trained.
[INFO][16:58:46]: [Client #726] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:58:46]: [Server #615782] Received 0.26 MB of payload data from client #726 (simulated).
[INFO][16:58:48]: [Client #602] Woke up.
[INFO][16:58:48]: [Client #602] Epoch: [3/5][0/13]	Loss: 0.556392
[INFO][16:58:48]: [Client #602] Epoch: [3/5][10/13]	Loss: 0.196288
[INFO][16:58:48]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:58:52]: [Client #602] Woke up.
[INFO][16:58:52]: [Client #602] Epoch: [4/5][0/13]	Loss: 0.342598
[INFO][16:58:52]: [Client #602] Epoch: [4/5][10/13]	Loss: 0.886090
[INFO][16:58:52]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:58:56]: [Client #602] Woke up.
[INFO][16:58:56]: [Client #602] Epoch: [5/5][0/13]	Loss: 0.450062
[INFO][16:58:57]: [Client #602] Epoch: [5/5][10/13]	Loss: 0.754180
[INFO][16:58:57]: [Client #602] Going to sleep for 3.99 seconds.
[INFO][16:59:01]: [Client #602] Woke up.
[INFO][16:59:01]: [Client #602] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_602_615874.pth.
[INFO][16:59:01]: [Client #602] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_602_615874.pth.
[INFO][16:59:01]: [Client #602] Model trained.
[INFO][16:59:01]: [Client #602] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:59:01]: [Server #615782] Received 0.26 MB of payload data from client #602 (simulated).
[INFO][16:59:01]: [Server #615782] Selecting client #413 for training.
[INFO][16:59:01]: [Server #615782] Sending the current model to client #413 (simulated).
[INFO][16:59:01]: [Server #615782] Sending 0.26 MB of payload data to client #413 (simulated).
[INFO][16:59:01]: [Server #615782] Selecting client #684 for training.
[INFO][16:59:01]: [Server #615782] Sending the current model to client #684 (simulated).
[INFO][16:59:01]: [Server #615782] Sending 0.26 MB of payload data to client #684 (simulated).
[INFO][16:59:01]: [Client #413] Selected by the server.
[INFO][16:59:01]: [Client #413] Loading its data source...
[INFO][16:59:01]: Data source: FEMNIST
[INFO][16:59:01]: [Client #684] Selected by the server.
[INFO][16:59:01]: [Client #684] Loading its data source...
[INFO][16:59:01]: Data source: FEMNIST
[INFO][16:59:01]: [Client #684] Dataset size: 135
[INFO][16:59:01]: [Client #684] Sampler: all_inclusive
[INFO][16:59:01]: [Client #413] Dataset size: 159
[INFO][16:59:01]: [Client #413] Sampler: all_inclusive
[INFO][16:59:01]: [Client #684] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:59:01]: [Client #413] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:59:01]: [93m[1m[Client #684] Started training in communication round #18.[0m
[INFO][16:59:01]: [93m[1m[Client #413] Started training in communication round #18.[0m
[INFO][16:59:03]: [Client #684] Loading the dataset.
[INFO][16:59:03]: [Client #413] Loading the dataset.
[INFO][16:59:09]: [Client #684] Epoch: [1/5][0/14]	Loss: 0.614528
[INFO][16:59:09]: [Client #413] Epoch: [1/5][0/16]	Loss: 1.208169
[INFO][16:59:09]: [Client #684] Epoch: [1/5][10/14]	Loss: 0.836999
[INFO][16:59:09]: [Client #413] Epoch: [1/5][10/16]	Loss: 0.670462
[INFO][16:59:09]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][16:59:09]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][16:59:13]: [Client #684] Woke up.
[INFO][16:59:13]: [Client #684] Epoch: [2/5][0/14]	Loss: 1.713677
[INFO][16:59:13]: [Client #684] Epoch: [2/5][10/14]	Loss: 0.920620
[INFO][16:59:13]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][16:59:13]: [Client #413] Woke up.
[INFO][16:59:13]: [Client #413] Epoch: [2/5][0/16]	Loss: 0.862244
[INFO][16:59:14]: [Client #413] Epoch: [2/5][10/16]	Loss: 0.455747
[INFO][16:59:14]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][16:59:17]: [Client #684] Woke up.
[INFO][16:59:17]: [Client #684] Epoch: [3/5][0/14]	Loss: 0.678785
[INFO][16:59:17]: [Client #684] Epoch: [3/5][10/14]	Loss: 0.274936
[INFO][16:59:17]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][16:59:18]: [Client #413] Woke up.
[INFO][16:59:18]: [Client #413] Epoch: [3/5][0/16]	Loss: 1.005078
[INFO][16:59:18]: [Client #413] Epoch: [3/5][10/16]	Loss: 0.690076
[INFO][16:59:18]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][16:59:20]: [Client #684] Woke up.
[INFO][16:59:20]: [Client #684] Epoch: [4/5][0/14]	Loss: 0.669750
[INFO][16:59:20]: [Client #684] Epoch: [4/5][10/14]	Loss: 1.172370
[INFO][16:59:20]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][16:59:22]: [Client #413] Woke up.
[INFO][16:59:22]: [Client #413] Epoch: [4/5][0/16]	Loss: 0.349704
[INFO][16:59:22]: [Client #413] Epoch: [4/5][10/16]	Loss: 0.286903
[INFO][16:59:22]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][16:59:24]: [Client #684] Woke up.
[INFO][16:59:24]: [Client #684] Epoch: [5/5][0/14]	Loss: 0.156554
[INFO][16:59:24]: [Client #684] Epoch: [5/5][10/14]	Loss: 1.312276
[INFO][16:59:24]: [Client #684] Going to sleep for 3.56 seconds.
[INFO][16:59:26]: [Client #413] Woke up.
[INFO][16:59:26]: [Client #413] Epoch: [5/5][0/16]	Loss: 0.792980
[INFO][16:59:26]: [Client #413] Epoch: [5/5][10/16]	Loss: 0.485850
[INFO][16:59:26]: [Client #413] Going to sleep for 4.08 seconds.
[INFO][16:59:28]: [Client #684] Woke up.
[INFO][16:59:28]: [Client #684] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615875.pth.
[INFO][16:59:28]: [Client #684] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_684_615875.pth.
[INFO][16:59:28]: [Client #684] Model trained.
[INFO][16:59:28]: [Client #684] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:59:28]: [Server #615782] Received 0.26 MB of payload data from client #684 (simulated).
[INFO][16:59:30]: [Client #413] Woke up.
[INFO][16:59:30]: [Client #413] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_413_615874.pth.
[INFO][16:59:31]: [Client #413] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_413_615874.pth.
[INFO][16:59:31]: [Client #413] Model trained.
[INFO][16:59:31]: [Client #413] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:59:31]: [Server #615782] Received 0.26 MB of payload data from client #413 (simulated).
[INFO][16:59:31]: [Server #615782] Selecting client #947 for training.
[INFO][16:59:31]: [Server #615782] Sending the current model to client #947 (simulated).
[INFO][16:59:31]: [Server #615782] Sending 0.26 MB of payload data to client #947 (simulated).
[INFO][16:59:31]: [Server #615782] Selecting client #200 for training.
[INFO][16:59:31]: [Server #615782] Sending the current model to client #200 (simulated).
[INFO][16:59:31]: [Server #615782] Sending 0.26 MB of payload data to client #200 (simulated).
[INFO][16:59:31]: [Client #947] Selected by the server.
[INFO][16:59:31]: [Client #947] Loading its data source...
[INFO][16:59:31]: Data source: FEMNIST
[INFO][16:59:31]: [Client #200] Selected by the server.
[INFO][16:59:31]: [Client #200] Loading its data source...
[INFO][16:59:31]: Data source: FEMNIST
[INFO][16:59:31]: [Client #947] Dataset size: 153
[INFO][16:59:31]: [Client #947] Sampler: all_inclusive
[INFO][16:59:31]: [Client #947] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:59:31]: [93m[1m[Client #947] Started training in communication round #18.[0m
[INFO][16:59:31]: [Client #200] Dataset size: 318
[INFO][16:59:31]: [Client #200] Sampler: all_inclusive
[INFO][16:59:31]: [Client #200] Received 0.26 MB of payload data from the server (simulated).
[INFO][16:59:31]: [93m[1m[Client #200] Started training in communication round #18.[0m
[INFO][16:59:33]: [Client #200] Loading the dataset.
[INFO][16:59:33]: [Client #947] Loading the dataset.
[INFO][16:59:39]: [Client #200] Epoch: [1/5][0/32]	Loss: 1.987952
[INFO][16:59:39]: [Client #947] Epoch: [1/5][0/16]	Loss: 1.188891
[INFO][16:59:39]: [Client #200] Epoch: [1/5][10/32]	Loss: 1.671907
[INFO][16:59:39]: [Client #947] Epoch: [1/5][10/16]	Loss: 0.852348
[INFO][16:59:39]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][16:59:39]: [Client #200] Epoch: [1/5][20/32]	Loss: 1.238197
[INFO][16:59:39]: [Client #200] Epoch: [1/5][30/32]	Loss: 1.095921
[INFO][16:59:39]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][16:59:39]: [Client #947] Woke up.
[INFO][16:59:39]: [Client #947] Epoch: [2/5][0/16]	Loss: 0.852048
[INFO][16:59:40]: [Client #947] Epoch: [2/5][10/16]	Loss: 1.076982
[INFO][16:59:40]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][16:59:40]: [Client #947] Woke up.
[INFO][16:59:40]: [Client #947] Epoch: [3/5][0/16]	Loss: 0.567797
[INFO][16:59:40]: [Client #947] Epoch: [3/5][10/16]	Loss: 0.858380
[INFO][16:59:40]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][16:59:41]: [Client #947] Woke up.
[INFO][16:59:41]: [Client #947] Epoch: [4/5][0/16]	Loss: 0.671017
[INFO][16:59:41]: [Client #947] Epoch: [4/5][10/16]	Loss: 0.938522
[INFO][16:59:41]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][16:59:41]: [Client #947] Woke up.
[INFO][16:59:41]: [Client #947] Epoch: [5/5][0/16]	Loss: 0.677436
[INFO][16:59:41]: [Client #947] Epoch: [5/5][10/16]	Loss: 1.590039
[INFO][16:59:41]: [Client #947] Going to sleep for 0.41 seconds.
[INFO][16:59:42]: [Client #947] Woke up.
[INFO][16:59:42]: [Client #947] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_947_615874.pth.
[INFO][16:59:42]: [Client #947] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_947_615874.pth.
[INFO][16:59:42]: [Client #947] Model trained.
[INFO][16:59:42]: [Client #947] Sent 0.26 MB of payload data to the server (simulated).
[INFO][16:59:42]: [Server #615782] Received 0.26 MB of payload data from client #947 (simulated).
[INFO][16:59:58]: [Client #200] Woke up.
[INFO][16:59:58]: [Client #200] Epoch: [2/5][0/32]	Loss: 0.677064
[INFO][16:59:58]: [Client #200] Epoch: [2/5][10/32]	Loss: 1.720067
[INFO][16:59:58]: [Client #200] Epoch: [2/5][20/32]	Loss: 0.870663
[INFO][16:59:58]: [Client #200] Epoch: [2/5][30/32]	Loss: 1.542435
[INFO][16:59:58]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][17:00:17]: [Client #200] Woke up.
[INFO][17:00:17]: [Client #200] Epoch: [3/5][0/32]	Loss: 0.691270
[INFO][17:00:17]: [Client #200] Epoch: [3/5][10/32]	Loss: 0.419118
[INFO][17:00:17]: [Client #200] Epoch: [3/5][20/32]	Loss: 0.275470
[INFO][17:00:17]: [Client #200] Epoch: [3/5][30/32]	Loss: 0.479565
[INFO][17:00:17]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][17:00:36]: [Client #200] Woke up.
[INFO][17:00:36]: [Client #200] Epoch: [4/5][0/32]	Loss: 0.549784
[INFO][17:00:36]: [Client #200] Epoch: [4/5][10/32]	Loss: 1.365972
[INFO][17:00:36]: [Client #200] Epoch: [4/5][20/32]	Loss: 1.139709
[INFO][17:00:36]: [Client #200] Epoch: [4/5][30/32]	Loss: 0.672363
[INFO][17:00:36]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][17:00:55]: [Client #200] Woke up.
[INFO][17:00:55]: [Client #200] Epoch: [5/5][0/32]	Loss: 0.323824
[INFO][17:00:55]: [Client #200] Epoch: [5/5][10/32]	Loss: 0.461833
[INFO][17:00:55]: [Client #200] Epoch: [5/5][20/32]	Loss: 1.123293
[INFO][17:00:55]: [Client #200] Epoch: [5/5][30/32]	Loss: 1.569196
[INFO][17:00:55]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][17:01:14]: [Client #200] Woke up.
[INFO][17:01:14]: [Client #200] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][17:01:15]: [Client #200] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_615875.pth.
[INFO][17:01:15]: [Client #200] Model trained.
[INFO][17:01:15]: [Client #200] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:01:15]: [Server #615782] Received 0.26 MB of payload data from client #200 (simulated).
[INFO][17:01:15]: [Server #615782] Selecting client #807 for training.
[INFO][17:01:15]: [Server #615782] Sending the current model to client #807 (simulated).
[INFO][17:01:15]: [Server #615782] Sending 0.26 MB of payload data to client #807 (simulated).
[INFO][17:01:15]: [Server #615782] Selecting client #970 for training.
[INFO][17:01:15]: [Server #615782] Sending the current model to client #970 (simulated).
[INFO][17:01:15]: [Server #615782] Sending 0.26 MB of payload data to client #970 (simulated).
[INFO][17:01:15]: [Client #807] Selected by the server.
[INFO][17:01:15]: [Client #807] Loading its data source...
[INFO][17:01:15]: Data source: FEMNIST
[INFO][17:01:15]: [Client #970] Selected by the server.
[INFO][17:01:15]: [Client #970] Loading its data source...
[INFO][17:01:15]: Data source: FEMNIST
[INFO][17:01:15]: [Client #807] Dataset size: 157
[INFO][17:01:15]: [Client #807] Sampler: all_inclusive
[INFO][17:01:15]: [Client #970] Dataset size: 164
[INFO][17:01:15]: [Client #970] Sampler: all_inclusive
[INFO][17:01:15]: [Client #807] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:01:15]: [Client #970] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:01:15]: [93m[1m[Client #807] Started training in communication round #18.[0m
[INFO][17:01:15]: [93m[1m[Client #970] Started training in communication round #18.[0m
[INFO][17:01:17]: [Client #970] Loading the dataset.
[INFO][17:01:17]: [Client #807] Loading the dataset.
[INFO][17:01:22]: [Client #970] Epoch: [1/5][0/17]	Loss: 0.959012
[INFO][17:01:22]: [Client #807] Epoch: [1/5][0/16]	Loss: 0.639020
[INFO][17:01:22]: [Client #807] Epoch: [1/5][10/16]	Loss: 0.346187
[INFO][17:01:22]: [Client #970] Epoch: [1/5][10/17]	Loss: 0.766841
[INFO][17:01:22]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][17:01:22]: [Client #970] Going to sleep for 0.96 seconds.
[INFO][17:01:23]: [Client #807] Woke up.
[INFO][17:01:23]: [Client #807] Epoch: [2/5][0/16]	Loss: 0.197260
[INFO][17:01:23]: [Client #807] Epoch: [2/5][10/16]	Loss: 0.662879
[INFO][17:01:23]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][17:01:23]: [Client #807] Woke up.
[INFO][17:01:23]: [Client #807] Epoch: [3/5][0/16]	Loss: 0.594109
[INFO][17:01:23]: [Client #970] Woke up.
[INFO][17:01:23]: [Client #970] Epoch: [2/5][0/17]	Loss: 0.384120
[INFO][17:01:23]: [Client #807] Epoch: [3/5][10/16]	Loss: 1.181114
[INFO][17:01:23]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][17:01:23]: [Client #970] Epoch: [2/5][10/17]	Loss: 0.231448
[INFO][17:01:23]: [Client #970] Going to sleep for 0.96 seconds.
[INFO][17:01:24]: [Client #807] Woke up.
[INFO][17:01:24]: [Client #807] Epoch: [4/5][0/16]	Loss: 1.450930
[INFO][17:01:24]: [Client #807] Epoch: [4/5][10/16]	Loss: 0.869521
[INFO][17:01:24]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][17:01:24]: [Client #807] Woke up.
[INFO][17:01:24]: [Client #807] Epoch: [5/5][0/16]	Loss: 0.834258
[INFO][17:01:24]: [Client #807] Epoch: [5/5][10/16]	Loss: 0.452181
[INFO][17:01:24]: [Client #970] Woke up.
[INFO][17:01:24]: [Client #970] Epoch: [3/5][0/17]	Loss: 0.880205
[INFO][17:01:24]: [Client #807] Going to sleep for 0.39 seconds.
[INFO][17:01:24]: [Client #970] Epoch: [3/5][10/17]	Loss: 0.542621
[INFO][17:01:24]: [Client #970] Going to sleep for 0.96 seconds.
[INFO][17:01:25]: [Client #807] Woke up.
[INFO][17:01:25]: [Client #807] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][17:01:25]: [Client #807] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_807_615874.pth.
[INFO][17:01:25]: [Client #807] Model trained.
[INFO][17:01:25]: [Client #807] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:01:25]: [Server #615782] Received 0.26 MB of payload data from client #807 (simulated).
[INFO][17:01:25]: [Client #970] Woke up.
[INFO][17:01:25]: [Client #970] Epoch: [4/5][0/17]	Loss: 0.814506
[INFO][17:01:26]: [Client #970] Epoch: [4/5][10/17]	Loss: 1.859796
[INFO][17:01:26]: [Client #970] Going to sleep for 0.96 seconds.
[INFO][17:01:27]: [Client #970] Woke up.
[INFO][17:01:27]: [Client #970] Epoch: [5/5][0/17]	Loss: 0.589679
[INFO][17:01:27]: [Client #970] Epoch: [5/5][10/17]	Loss: 0.782069
[INFO][17:01:27]: [Client #970] Going to sleep for 0.96 seconds.
[INFO][17:01:28]: [Client #970] Woke up.
[INFO][17:01:28]: [Client #970] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_970_615875.pth.
[INFO][17:01:28]: [Client #970] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_970_615875.pth.
[INFO][17:01:28]: [Client #970] Model trained.
[INFO][17:01:28]: [Client #970] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:01:28]: [Server #615782] Received 0.26 MB of payload data from client #970 (simulated).
[INFO][17:01:28]: [Server #615782] Selecting client #15 for training.
[INFO][17:01:28]: [Server #615782] Sending the current model to client #15 (simulated).
[INFO][17:01:28]: [Server #615782] Sending 0.26 MB of payload data to client #15 (simulated).
[INFO][17:01:28]: [Server #615782] Selecting client #215 for training.
[INFO][17:01:28]: [Server #615782] Sending the current model to client #215 (simulated).
[INFO][17:01:28]: [Server #615782] Sending 0.26 MB of payload data to client #215 (simulated).
[INFO][17:01:28]: [Client #15] Selected by the server.
[INFO][17:01:28]: [Client #15] Loading its data source...
[INFO][17:01:28]: Data source: FEMNIST
[INFO][17:01:28]: [Client #215] Selected by the server.
[INFO][17:01:28]: [Client #215] Loading its data source...
[INFO][17:01:28]: Data source: FEMNIST
[INFO][17:01:28]: [Client #15] Dataset size: 144
[INFO][17:01:28]: [Client #15] Sampler: all_inclusive
[INFO][17:01:28]: [Client #15] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:01:28]: [93m[1m[Client #15] Started training in communication round #18.[0m
[INFO][17:01:28]: [Client #215] Dataset size: 161
[INFO][17:01:28]: [Client #215] Sampler: all_inclusive
[INFO][17:01:28]: [Client #215] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:01:28]: [93m[1m[Client #215] Started training in communication round #18.[0m
[INFO][17:01:31]: [Client #215] Loading the dataset.
[INFO][17:01:31]: [Client #15] Loading the dataset.
[INFO][17:01:36]: [Client #215] Epoch: [1/5][0/17]	Loss: 2.040124
[INFO][17:01:37]: [Client #15] Epoch: [1/5][0/15]	Loss: 1.362268
[INFO][17:01:37]: [Client #215] Epoch: [1/5][10/17]	Loss: 1.403566
[INFO][17:01:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][17:01:37]: [Client #15] Epoch: [1/5][10/15]	Loss: 1.075512
[INFO][17:01:37]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][17:01:37]: [Client #15] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [2/5][0/15]	Loss: 0.951447
[INFO][17:01:37]: [Client #215] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [2/5][10/15]	Loss: 0.717787
[INFO][17:01:37]: [Client #215] Epoch: [2/5][0/17]	Loss: 1.028573
[INFO][17:01:37]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][17:01:37]: [Client #15] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [3/5][0/15]	Loss: 0.837722
[INFO][17:01:37]: [Client #215] Epoch: [2/5][10/17]	Loss: 0.802554
[INFO][17:01:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][17:01:37]: [Client #15] Epoch: [3/5][10/15]	Loss: 0.823844
[INFO][17:01:37]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][17:01:37]: [Client #15] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [4/5][0/15]	Loss: 0.883173
[INFO][17:01:37]: [Client #215] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [4/5][10/15]	Loss: 0.889395
[INFO][17:01:37]: [Client #215] Epoch: [3/5][0/17]	Loss: 1.758962
[INFO][17:01:37]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][17:01:37]: [Client #15] Woke up.
[INFO][17:01:37]: [Client #15] Epoch: [5/5][0/15]	Loss: 0.279094
[INFO][17:01:37]: [Client #215] Epoch: [3/5][10/17]	Loss: 0.833073
[INFO][17:01:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][17:01:37]: [Client #15] Epoch: [5/5][10/15]	Loss: 0.873283
[INFO][17:01:37]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][17:01:37]: [Client #15] Woke up.
[INFO][17:01:37]: [Client #15] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_15_615874.pth.
[INFO][17:01:37]: [Client #215] Woke up.
[INFO][17:01:37]: [Client #215] Epoch: [4/5][0/17]	Loss: 1.449777
[INFO][17:01:38]: [Client #215] Epoch: [4/5][10/17]	Loss: 1.052034
[INFO][17:01:38]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][17:01:38]: [Client #215] Woke up.
[INFO][17:01:38]: [Client #215] Epoch: [5/5][0/17]	Loss: 2.067637
[INFO][17:01:38]: [Client #215] Epoch: [5/5][10/17]	Loss: 1.564433
[INFO][17:01:38]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][17:01:38]: [Client #15] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_15_615874.pth.
[INFO][17:01:38]: [Client #15] Model trained.
[INFO][17:01:38]: [Client #15] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:01:38]: [Server #615782] Received 0.26 MB of payload data from client #15 (simulated).
[INFO][17:01:38]: [Client #215] Woke up.
[INFO][17:01:38]: [Client #215] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_615875.pth.
[INFO][17:01:39]: [Client #215] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_615875.pth.
[INFO][17:01:39]: [Client #215] Model trained.
[INFO][17:01:39]: [Client #215] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:01:39]: [Server #615782] Received 0.26 MB of payload data from client #215 (simulated).
[INFO][17:01:39]: [Server #615782] Selecting client #117 for training.
[INFO][17:01:39]: [Server #615782] Sending the current model to client #117 (simulated).
[INFO][17:01:39]: [Server #615782] Sending 0.26 MB of payload data to client #117 (simulated).
[INFO][17:01:39]: [Client #117] Selected by the server.
[INFO][17:01:39]: [Client #117] Loading its data source...
[INFO][17:01:39]: Data source: FEMNIST
[INFO][17:01:39]: [Client #117] Dataset size: 152
[INFO][17:01:39]: [Client #117] Sampler: all_inclusive
[INFO][17:01:39]: [Client #117] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:01:39]: [93m[1m[Client #117] Started training in communication round #18.[0m
[INFO][17:01:41]: [Client #117] Loading the dataset.
[INFO][17:01:47]: [Client #117] Epoch: [1/5][0/16]	Loss: 0.064724
[INFO][17:01:47]: [Client #117] Epoch: [1/5][10/16]	Loss: 1.331518
[INFO][17:01:47]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][17:01:50]: [Client #117] Woke up.
[INFO][17:01:50]: [Client #117] Epoch: [2/5][0/16]	Loss: 0.924109
[INFO][17:01:50]: [Client #117] Epoch: [2/5][10/16]	Loss: 1.287856
[INFO][17:01:50]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][17:01:53]: [Client #117] Woke up.
[INFO][17:01:53]: [Client #117] Epoch: [3/5][0/16]	Loss: 1.744306
[INFO][17:01:53]: [Client #117] Epoch: [3/5][10/16]	Loss: 0.846199
[INFO][17:01:53]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][17:01:56]: [Client #117] Woke up.
[INFO][17:01:56]: [Client #117] Epoch: [4/5][0/16]	Loss: 0.360586
[INFO][17:01:56]: [Client #117] Epoch: [4/5][10/16]	Loss: 0.247405
[INFO][17:01:56]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][17:01:59]: [Client #117] Woke up.
[INFO][17:01:59]: [Client #117] Epoch: [5/5][0/16]	Loss: 0.476117
[INFO][17:02:00]: [Client #117] Epoch: [5/5][10/16]	Loss: 1.033471
[INFO][17:02:00]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][17:02:03]: [Client #117] Woke up.
[INFO][17:02:03]: [Client #117] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_615874.pth.
[INFO][17:02:03]: [Client #117] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_615874.pth.
[INFO][17:02:03]: [Client #117] Model trained.
[INFO][17:02:03]: [Client #117] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:02:03]: [Server #615782] Received 0.26 MB of payload data from client #117 (simulated).
[INFO][17:02:03]: [Server #615782] Adding client #658 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #15 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #603 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #215 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #981 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #807 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #947 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #502 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #222 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #726 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #970 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #525 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #452 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #181 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #667 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #117 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #590 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #897 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #684 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #602 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #413 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #465 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #787 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #200 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][17:02:03]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11061841 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11665962 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30720043 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.18753154 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14739196 0.
 0.         0.         0.         0.         0.         0.24572004
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08700908 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25176123 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1054717  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11470305 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.28358515 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14912121 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06940135 0.10978468 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10592373 0.         0.
 0.         0.         0.         0.         0.         0.
 0.19155647 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0711088
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14377357
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1760058  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09533487 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08728959
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1705141  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13477653 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09843169 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15066518 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11061841 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11665962 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30720043 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.18753154 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14739196 0.
 0.         0.         0.         0.         0.         0.24572004
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08700908 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25176123 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1054717  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11470305 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.28358515 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14912121 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06940135 0.10978468 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10592373 0.         0.
 0.         0.         0.         0.         0.         0.
 0.19155647 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0711088
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14377357
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1760058  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09533487 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08728959
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1705141  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13477653 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09843169 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15066518 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.001      0.0341556  0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.001      0.001      0.001      0.03602175
 0.001      0.001      0.0350013  0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.0420101  0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.03536294 0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03605313 0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.04067358 0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.03818786 0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07542694 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.03818786 0.04095046
 0.001      0.001      0.001      0.001      0.001      0.07779886
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.04068067 0.04307365 0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.04227599 0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.04280776 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.0357513  0.001      0.04226082 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.04147833
 0.001      0.001      0.001      0.001      0.03771347 0.01879376
 0.001      0.001      0.001      0.001      0.03756477 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.01953077 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03881946 0.03842505 0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02443074 0.04316547 0.001      0.001
 0.02002211 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.0357513  0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03866224 0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.04307365 0.03462998 0.001      0.001      0.04063039
 0.0386082  0.001      0.04196891 0.001      0.06692817 0.01709943
 0.04067358 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.03881946 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03626943 0.03889033
 0.04248705 0.04307365 0.001      0.05103627 0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.02366392 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.03629032 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.02870019 0.03629032 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.001      0.03826169
 0.03828769 0.001      0.04094656 0.001      0.001      0.001
 0.001      0.04307365 0.03989637 0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.04015544 0.03707545 0.04095046 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.0401489
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.0420101  0.03892821 0.03747628 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.05763757 0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.01940794 0.03202087
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.02141939
 0.001      0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.04307365
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.03605313
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.03989637 0.001      0.001
 0.001      0.03810651 0.001      0.02977931 0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.04227599 0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03866224 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.03613604
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.001      0.01937935 0.03723909 0.0373057  0.03241574 0.03778932
 0.001      0.001      0.0401489  0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0373057  0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.001      0.03431953 0.04196891 0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.04094656 0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03963731
 0.001      0.02800639 0.001      0.04170984 0.001      0.03510436
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.04121244
 0.03937824 0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.03723909 0.03987651 0.01937935 0.07340324
 0.001      0.04222798 0.001      0.04096448 0.001      0.001
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.04121244 0.001      0.001      0.001
 0.03911917 0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03188474 0.04248705
 0.03665319 0.001      0.001      0.02227617 0.001      0.02522523
 0.001      0.03012994 0.001      0.001      0.03629032 0.04076739
 0.03613604 0.03549223 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03551983 0.001
 0.001      0.03304023 0.001      0.03889943 0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.04170984
 0.04095046 0.001      0.03842505 0.001      0.001      0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][17:02:48]: [Server #615782] Global model accuracy: 59.44%

[INFO][17:02:48]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_18.pth.
[INFO][17:02:48]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_18.pth.
[INFO][17:02:48]: [93m[1m
[Server #615782] Starting round 19/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5991e+00  8e-04  4e-09  4e-09
 5:  7.5999e+00  7.5999e+00  5e-05  2e-10  2e-10
 6:  7.5999e+00  7.5999e+00  4e-05  1e-10  1e-10
 7:  7.5999e+00  7.5999e+00  4e-05  2e-09  2e-10
 8:  7.5999e+00  7.5999e+00  3e-05  2e-09  2e-10
 9:  7.5999e+00  7.5999e+00  2e-05  3e-09  3e-10
10:  7.5999e+00  7.5999e+00  3e-06  9e-09  8e-10
Optimal solution found.
The calculated probability is:  [7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48042402e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48004392e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.46671798e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.45979671e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.47848701e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.44153011e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48081446e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.47160584e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48127404e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.47982395e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.47128843e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.47875347e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48157157e-05 7.48024613e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48025896e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.46846243e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48143605e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.47902246e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.47686031e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48061006e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 9.25331044e-01 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.47752598e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.47935026e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48038109e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.47828283e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05 7.48201335e-05
 7.48201335e-05 7.48201335e-05 7.48201335e-05][INFO][17:02:51]: [Server #615782] Selected clients: [870 979 702 942 869 703 469 680  14 983 172 906 805 798 268 219 428 847
 449 935 352 617 981 641  46]
[INFO][17:02:51]: [Server #615782] Selecting client #870 for training.
[INFO][17:02:51]: [Server #615782] Sending the current model to client #870 (simulated).
[INFO][17:02:51]: [Server #615782] Sending 0.26 MB of payload data to client #870 (simulated).
[INFO][17:02:51]: [Server #615782] Selecting client #979 for training.
[INFO][17:02:51]: [Server #615782] Sending the current model to client #979 (simulated).
[INFO][17:02:51]: [Server #615782] Sending 0.26 MB of payload data to client #979 (simulated).
[INFO][17:02:51]: [Client #870] Selected by the server.
[INFO][17:02:51]: [Client #870] Loading its data source...
[INFO][17:02:51]: Data source: FEMNIST
[INFO][17:02:51]: [Client #979] Selected by the server.
[INFO][17:02:51]: [Client #979] Loading its data source...
[INFO][17:02:51]: Data source: FEMNIST
[INFO][17:02:51]: [Client #870] Dataset size: 148
[INFO][17:02:51]: [Client #870] Sampler: all_inclusive
[INFO][17:02:51]: [Client #870] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:02:51]: [Client #979] Dataset size: 162
[INFO][17:02:51]: [Client #979] Sampler: all_inclusive
[INFO][17:02:51]: [Client #979] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:02:51]: [93m[1m[Client #979] Started training in communication round #19.[0m
[INFO][17:02:51]: [93m[1m[Client #870] Started training in communication round #19.[0m
[INFO][17:02:53]: [Client #979] Loading the dataset.
[INFO][17:02:53]: [Client #870] Loading the dataset.
[INFO][17:02:58]: [Client #870] Epoch: [1/5][0/15]	Loss: 0.579148
[INFO][17:02:58]: [Client #979] Epoch: [1/5][0/17]	Loss: 0.731578
[INFO][17:02:58]: [Client #870] Epoch: [1/5][10/15]	Loss: 0.193773
[INFO][17:02:58]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][17:02:58]: [Client #979] Epoch: [1/5][10/17]	Loss: 1.304570
[INFO][17:02:59]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][17:02:59]: [Client #979] Woke up.
[INFO][17:02:59]: [Client #979] Epoch: [2/5][0/17]	Loss: 0.386256
[INFO][17:02:59]: [Client #979] Epoch: [2/5][10/17]	Loss: 1.982442
[INFO][17:02:59]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][17:02:59]: [Client #979] Woke up.
[INFO][17:02:59]: [Client #979] Epoch: [3/5][0/17]	Loss: 0.808545
[INFO][17:02:59]: [Client #979] Epoch: [3/5][10/17]	Loss: 0.766607
[INFO][17:02:59]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][17:03:00]: [Client #979] Woke up.
[INFO][17:03:00]: [Client #979] Epoch: [4/5][0/17]	Loss: 1.524354
[INFO][17:03:00]: [Client #979] Epoch: [4/5][10/17]	Loss: 0.659246
[INFO][17:03:00]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][17:03:00]: [Client #979] Woke up.
[INFO][17:03:00]: [Client #979] Epoch: [5/5][0/17]	Loss: 0.356799
[INFO][17:03:00]: [Client #979] Epoch: [5/5][10/17]	Loss: 0.531055
[INFO][17:03:00]: [Client #979] Going to sleep for 0.28 seconds.
[INFO][17:03:01]: [Client #979] Woke up.
[INFO][17:03:01]: [Client #979] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_979_615875.pth.
[INFO][17:03:01]: [Client #979] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_979_615875.pth.
[INFO][17:03:01]: [Client #979] Model trained.
[INFO][17:03:01]: [Client #979] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:03:01]: [Server #615782] Received 0.26 MB of payload data from client #979 (simulated).
[INFO][17:03:59]: [Client #870] Woke up.
[INFO][17:03:59]: [Client #870] Epoch: [2/5][0/15]	Loss: 0.250577
[INFO][17:03:59]: [Client #870] Epoch: [2/5][10/15]	Loss: 0.601509
[INFO][17:03:59]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][17:04:59]: [Client #870] Woke up.
[INFO][17:04:59]: [Client #870] Epoch: [3/5][0/15]	Loss: 0.334907
[INFO][17:04:59]: [Client #870] Epoch: [3/5][10/15]	Loss: 0.850406
[INFO][17:04:59]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][17:05:59]: [Client #870] Woke up.
[INFO][17:05:59]: [Client #870] Epoch: [4/5][0/15]	Loss: 0.243960
[INFO][17:05:59]: [Client #870] Epoch: [4/5][10/15]	Loss: 0.433630
[INFO][17:05:59]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][17:06:59]: [Client #870] Woke up.
[INFO][17:07:00]: [Client #870] Epoch: [5/5][0/15]	Loss: 0.662307
[INFO][17:07:00]: [Client #870] Epoch: [5/5][10/15]	Loss: 0.131397
[INFO][17:07:00]: [Client #870] Going to sleep for 60.00 seconds.
[INFO][17:08:00]: [Client #870] Woke up.
[INFO][17:08:00]: [Client #870] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][17:08:01]: [Client #870] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_870_615874.pth.
[INFO][17:08:01]: [Client #870] Model trained.
[INFO][17:08:01]: [Client #870] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:01]: [Server #615782] Received 0.26 MB of payload data from client #870 (simulated).
[INFO][17:08:01]: [Server #615782] Selecting client #702 for training.
[INFO][17:08:01]: [Server #615782] Sending the current model to client #702 (simulated).
[INFO][17:08:01]: [Server #615782] Sending 0.26 MB of payload data to client #702 (simulated).
[INFO][17:08:01]: [Server #615782] Selecting client #942 for training.
[INFO][17:08:01]: [Server #615782] Sending the current model to client #942 (simulated).
[INFO][17:08:01]: [Server #615782] Sending 0.26 MB of payload data to client #942 (simulated).
[INFO][17:08:01]: [Client #702] Selected by the server.
[INFO][17:08:01]: [Client #702] Loading its data source...
[INFO][17:08:01]: Data source: FEMNIST
[INFO][17:08:01]: [Client #942] Selected by the server.
[INFO][17:08:01]: [Client #942] Loading its data source...
[INFO][17:08:01]: Data source: FEMNIST
[INFO][17:08:01]: [Client #942] Dataset size: 98
[INFO][17:08:01]: [Client #942] Sampler: all_inclusive
[INFO][17:08:01]: [Client #942] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:01]: [Client #702] Dataset size: 150
[INFO][17:08:01]: [Client #702] Sampler: all_inclusive
[INFO][17:08:01]: [93m[1m[Client #942] Started training in communication round #19.[0m
[INFO][17:08:01]: [Client #702] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:01]: [93m[1m[Client #702] Started training in communication round #19.[0m
[INFO][17:08:02]: [Client #942] Loading the dataset.
[INFO][17:08:02]: [Client #702] Loading the dataset.
[INFO][17:08:08]: [Client #942] Epoch: [1/5][0/10]	Loss: 1.076433
[INFO][17:08:08]: [Client #702] Epoch: [1/5][0/15]	Loss: 1.568196
[INFO][17:08:08]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][17:08:08]: [Client #702] Epoch: [1/5][10/15]	Loss: 1.374242
[INFO][17:08:08]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][17:08:08]: [Client #942] Woke up.
[INFO][17:08:08]: [Client #942] Epoch: [2/5][0/10]	Loss: 1.151504
[INFO][17:08:09]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][17:08:09]: [Client #942] Woke up.
[INFO][17:08:09]: [Client #942] Epoch: [3/5][0/10]	Loss: 0.352157
[INFO][17:08:09]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][17:08:09]: [Client #942] Woke up.
[INFO][17:08:09]: [Client #702] Woke up.
[INFO][17:08:09]: [Client #942] Epoch: [4/5][0/10]	Loss: 0.703331
[INFO][17:08:09]: [Client #702] Epoch: [2/5][0/15]	Loss: 0.310181
[INFO][17:08:09]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][17:08:09]: [Client #702] Epoch: [2/5][10/15]	Loss: 0.590136
[INFO][17:08:09]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][17:08:09]: [Client #942] Woke up.
[INFO][17:08:09]: [Client #942] Epoch: [5/5][0/10]	Loss: 0.603995
[INFO][17:08:09]: [Client #942] Going to sleep for 0.09 seconds.
[INFO][17:08:09]: [Client #942] Woke up.
[INFO][17:08:09]: [Client #942] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_942_615875.pth.
[INFO][17:08:09]: [Client #702] Woke up.
[INFO][17:08:09]: [Client #702] Epoch: [3/5][0/15]	Loss: 0.821362
[INFO][17:08:09]: [Client #702] Epoch: [3/5][10/15]	Loss: 0.659820
[INFO][17:08:09]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][17:08:10]: [Client #942] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_942_615875.pth.
[INFO][17:08:10]: [Client #942] Model trained.
[INFO][17:08:10]: [Client #942] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:10]: [Server #615782] Received 0.26 MB of payload data from client #942 (simulated).
[INFO][17:08:10]: [Client #702] Woke up.
[INFO][17:08:10]: [Client #702] Epoch: [4/5][0/15]	Loss: 0.482168
[INFO][17:08:10]: [Client #702] Epoch: [4/5][10/15]	Loss: 0.821719
[INFO][17:08:10]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][17:08:10]: [Client #702] Woke up.
[INFO][17:08:10]: [Client #702] Epoch: [5/5][0/15]	Loss: 0.433607
[INFO][17:08:11]: [Client #702] Epoch: [5/5][10/15]	Loss: 0.977489
[INFO][17:08:11]: [Client #702] Going to sleep for 0.41 seconds.
[INFO][17:08:11]: [Client #702] Woke up.
[INFO][17:08:11]: [Client #702] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_702_615874.pth.
[INFO][17:08:12]: [Client #702] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_702_615874.pth.
[INFO][17:08:12]: [Client #702] Model trained.
[INFO][17:08:12]: [Client #702] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:12]: [Server #615782] Received 0.26 MB of payload data from client #702 (simulated).
[INFO][17:08:12]: [Server #615782] Selecting client #869 for training.
[INFO][17:08:12]: [Server #615782] Sending the current model to client #869 (simulated).
[INFO][17:08:12]: [Server #615782] Sending 0.26 MB of payload data to client #869 (simulated).
[INFO][17:08:12]: [Server #615782] Selecting client #703 for training.
[INFO][17:08:12]: [Server #615782] Sending the current model to client #703 (simulated).
[INFO][17:08:12]: [Server #615782] Sending 0.26 MB of payload data to client #703 (simulated).
[INFO][17:08:12]: [Client #869] Selected by the server.
[INFO][17:08:12]: [Client #869] Loading its data source...
[INFO][17:08:12]: Data source: FEMNIST
[INFO][17:08:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:08:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/869.zip.
[INFO][17:08:12]: [Client #703] Selected by the server.
[INFO][17:08:12]: [Client #703] Loading its data source...
[INFO][17:08:12]: Data source: FEMNIST
[INFO][17:08:12]: [Client #703] Dataset size: 164
[INFO][17:08:12]: [Client #703] Sampler: all_inclusive
[INFO][17:08:12]: [Client #703] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:12]: [93m[1m[Client #703] Started training in communication round #19.[0m
2.8%5.7%8.5%11.4%14.2%17.0%19.9%22.7%25.5%28.4%31.2%34.1%36.9%39.7%42.6%45.4%48.2%51.1%53.9%56.8%59.6%62.4%65.3%68.1%70.9%73.8%76.6%79.5%82.3%85.1%88.0%90.8%93.7%96.5%99.3%100.0%[INFO][17:08:12]: Decompressing the dataset downloaded.
[INFO][17:08:12]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/869.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:08:12]: [Client #869] Dataset size: 162
[INFO][17:08:12]: [Client #869] Sampler: all_inclusive
[INFO][17:08:12]: [Client #869] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:12]: [93m[1m[Client #869] Started training in communication round #19.[0m

[INFO][17:08:14]: [Client #703] Loading the dataset.
[INFO][17:08:14]: [Client #869] Loading the dataset.
[INFO][17:08:19]: [Client #703] Epoch: [1/5][0/17]	Loss: 0.923241
[INFO][17:08:19]: [Client #869] Epoch: [1/5][0/17]	Loss: 0.606332
[INFO][17:08:19]: [Client #703] Epoch: [1/5][10/17]	Loss: 0.497113
[INFO][17:08:19]: [Client #869] Epoch: [1/5][10/17]	Loss: 1.177954
[INFO][17:08:20]: [Client #869] Going to sleep for 0.07 seconds.
[INFO][17:08:20]: [Client #703] Going to sleep for 1.59 seconds.
[INFO][17:08:20]: [Client #869] Woke up.
[INFO][17:08:20]: [Client #869] Epoch: [2/5][0/17]	Loss: 0.367231
[INFO][17:08:20]: [Client #869] Epoch: [2/5][10/17]	Loss: 1.333873
[INFO][17:08:20]: [Client #869] Going to sleep for 0.07 seconds.
[INFO][17:08:20]: [Client #869] Woke up.
[INFO][17:08:20]: [Client #869] Epoch: [3/5][0/17]	Loss: 1.459104
[INFO][17:08:20]: [Client #869] Epoch: [3/5][10/17]	Loss: 0.795914
[INFO][17:08:20]: [Client #869] Going to sleep for 0.07 seconds.
[INFO][17:08:20]: [Client #869] Woke up.
[INFO][17:08:20]: [Client #869] Epoch: [4/5][0/17]	Loss: 0.266632
[INFO][17:08:20]: [Client #869] Epoch: [4/5][10/17]	Loss: 0.624220
[INFO][17:08:20]: [Client #869] Going to sleep for 0.07 seconds.
[INFO][17:08:20]: [Client #869] Woke up.
[INFO][17:08:20]: [Client #869] Epoch: [5/5][0/17]	Loss: 1.287710
[INFO][17:08:20]: [Client #869] Epoch: [5/5][10/17]	Loss: 1.626087
[INFO][17:08:20]: [Client #869] Going to sleep for 0.07 seconds.
[INFO][17:08:20]: [Client #869] Woke up.
[INFO][17:08:20]: [Client #869] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_869_615874.pth.
[INFO][17:08:21]: [Client #869] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_869_615874.pth.
[INFO][17:08:21]: [Client #703] Woke up.
[INFO][17:08:21]: [Client #869] Model trained.
[INFO][17:08:21]: [Client #703] Epoch: [2/5][0/17]	Loss: 0.356435
[INFO][17:08:21]: [Client #869] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:21]: [Server #615782] Received 0.26 MB of payload data from client #869 (simulated).
[INFO][17:08:21]: [Client #703] Epoch: [2/5][10/17]	Loss: 0.438392
[INFO][17:08:21]: [Client #703] Going to sleep for 1.59 seconds.
[INFO][17:08:23]: [Client #703] Woke up.
[INFO][17:08:23]: [Client #703] Epoch: [3/5][0/17]	Loss: 0.416516
[INFO][17:08:23]: [Client #703] Epoch: [3/5][10/17]	Loss: 0.268543
[INFO][17:08:23]: [Client #703] Going to sleep for 1.59 seconds.
[INFO][17:08:25]: [Client #703] Woke up.
[INFO][17:08:25]: [Client #703] Epoch: [4/5][0/17]	Loss: 0.162367
[INFO][17:08:25]: [Client #703] Epoch: [4/5][10/17]	Loss: 1.522247
[INFO][17:08:25]: [Client #703] Going to sleep for 1.59 seconds.
[INFO][17:08:26]: [Client #703] Woke up.
[INFO][17:08:26]: [Client #703] Epoch: [5/5][0/17]	Loss: 0.487840
[INFO][17:08:26]: [Client #703] Epoch: [5/5][10/17]	Loss: 0.695600
[INFO][17:08:26]: [Client #703] Going to sleep for 1.59 seconds.
[INFO][17:08:28]: [Client #703] Woke up.
[INFO][17:08:28]: [Client #703] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_703_615875.pth.
[INFO][17:08:29]: [Client #703] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_703_615875.pth.
[INFO][17:08:29]: [Client #703] Model trained.
[INFO][17:08:29]: [Client #703] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:29]: [Server #615782] Received 0.26 MB of payload data from client #703 (simulated).
[INFO][17:08:29]: [Server #615782] Selecting client #469 for training.
[INFO][17:08:29]: [Server #615782] Sending the current model to client #469 (simulated).
[INFO][17:08:29]: [Server #615782] Sending 0.26 MB of payload data to client #469 (simulated).
[INFO][17:08:29]: [Server #615782] Selecting client #680 for training.
[INFO][17:08:29]: [Server #615782] Sending the current model to client #680 (simulated).
[INFO][17:08:29]: [Server #615782] Sending 0.26 MB of payload data to client #680 (simulated).
[INFO][17:08:29]: [Client #469] Selected by the server.
[INFO][17:08:29]: [Client #469] Loading its data source...
[INFO][17:08:29]: [Client #680] Selected by the server.
[INFO][17:08:29]: Data source: FEMNIST
[INFO][17:08:29]: [Client #680] Loading its data source...
[INFO][17:08:29]: Data source: FEMNIST
[INFO][17:08:29]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:08:29]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/680.zip.
[INFO][17:08:29]: [Client #469] Dataset size: 163
[INFO][17:08:29]: [Client #469] Sampler: all_inclusive
[INFO][17:08:29]: [Client #469] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:29]: [93m[1m[Client #469] Started training in communication round #19.[0m
2.8%5.6%8.4%11.2%13.9%16.7%19.5%22.3%25.1%27.9%30.7%33.5%36.2%39.0%41.8%44.6%47.4%50.2%53.0%55.8%58.5%61.3%64.1%66.9%69.7%72.5%75.3%78.1%80.8%83.6%86.4%89.2%92.0%94.8%97.6%100.0%[INFO][17:08:29]: Decompressing the dataset downloaded.
[INFO][17:08:29]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/680.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:08:29]: [Client #680] Dataset size: 123
[INFO][17:08:29]: [Client #680] Sampler: all_inclusive
[INFO][17:08:29]: [Client #680] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:08:29]: [93m[1m[Client #680] Started training in communication round #19.[0m

[INFO][17:08:31]: [Client #469] Loading the dataset.
[INFO][17:08:31]: [Client #680] Loading the dataset.
[INFO][17:08:37]: [Client #680] Epoch: [1/5][0/13]	Loss: 1.161922
[INFO][17:08:37]: [Client #469] Epoch: [1/5][0/17]	Loss: 0.525580
[INFO][17:08:37]: [Client #680] Epoch: [1/5][10/13]	Loss: 1.283990
[INFO][17:08:37]: [Client #680] Going to sleep for 6.04 seconds.
[INFO][17:08:37]: [Client #469] Epoch: [1/5][10/17]	Loss: 1.359932
[INFO][17:08:37]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][17:08:38]: [Client #469] Woke up.
[INFO][17:08:38]: [Client #469] Epoch: [2/5][0/17]	Loss: 0.629250
[INFO][17:08:38]: [Client #469] Epoch: [2/5][10/17]	Loss: 1.091003
[INFO][17:08:38]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][17:08:39]: [Client #469] Woke up.
[INFO][17:08:39]: [Client #469] Epoch: [3/5][0/17]	Loss: 0.183465
[INFO][17:08:39]: [Client #469] Epoch: [3/5][10/17]	Loss: 0.839626
[INFO][17:08:39]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][17:08:41]: [Client #469] Woke up.
[INFO][17:08:41]: [Client #469] Epoch: [4/5][0/17]	Loss: 0.433643
[INFO][17:08:41]: [Client #469] Epoch: [4/5][10/17]	Loss: 2.811640
[INFO][17:08:41]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][17:08:42]: [Client #469] Woke up.
[INFO][17:08:42]: [Client #469] Epoch: [5/5][0/17]	Loss: 0.819477
[INFO][17:08:42]: [Client #469] Epoch: [5/5][10/17]	Loss: 1.403263
[INFO][17:08:42]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][17:08:43]: [Client #680] Woke up.
[INFO][17:08:43]: [Client #680] Epoch: [2/5][0/13]	Loss: 0.591046
[INFO][17:08:43]: [Client #680] Epoch: [2/5][10/13]	Loss: 0.598129
[INFO][17:08:43]: [Client #680] Going to sleep for 6.04 seconds.
[INFO][17:08:43]: [Client #469] Woke up.
[INFO][17:08:43]: [Client #469] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_615874.pth.
[INFO][17:08:44]: [Client #469] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_615874.pth.
[INFO][17:08:44]: [Client #469] Model trained.
[INFO][17:08:44]: [Client #469] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:08:44]: [Server #615782] Received 0.26 MB of payload data from client #469 (simulated).
[INFO][17:08:49]: [Client #680] Woke up.
[INFO][17:08:49]: [Client #680] Epoch: [3/5][0/13]	Loss: 1.010710
[INFO][17:08:49]: [Client #680] Epoch: [3/5][10/13]	Loss: 0.197868
[INFO][17:08:49]: [Client #680] Going to sleep for 6.04 seconds.
[INFO][17:08:55]: [Client #680] Woke up.
[INFO][17:08:55]: [Client #680] Epoch: [4/5][0/13]	Loss: 0.372063
[INFO][17:08:55]: [Client #680] Epoch: [4/5][10/13]	Loss: 1.364259
[INFO][17:08:55]: [Client #680] Going to sleep for 6.04 seconds.
[INFO][17:09:01]: [Client #680] Woke up.
[INFO][17:09:01]: [Client #680] Epoch: [5/5][0/13]	Loss: 0.489137
[INFO][17:09:01]: [Client #680] Epoch: [5/5][10/13]	Loss: 0.134054
[INFO][17:09:01]: [Client #680] Going to sleep for 6.04 seconds.
[INFO][17:09:07]: [Client #680] Woke up.
[INFO][17:09:07]: [Client #680] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_680_615875.pth.
[INFO][17:09:08]: [Client #680] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_680_615875.pth.
[INFO][17:09:08]: [Client #680] Model trained.
[INFO][17:09:08]: [Client #680] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:09:08]: [Server #615782] Received 0.26 MB of payload data from client #680 (simulated).
[INFO][17:09:08]: [Server #615782] Selecting client #14 for training.
[INFO][17:09:08]: [Server #615782] Sending the current model to client #14 (simulated).
[INFO][17:09:08]: [Server #615782] Sending 0.26 MB of payload data to client #14 (simulated).
[INFO][17:09:08]: [Server #615782] Selecting client #983 for training.
[INFO][17:09:08]: [Server #615782] Sending the current model to client #983 (simulated).
[INFO][17:09:08]: [Server #615782] Sending 0.26 MB of payload data to client #983 (simulated).
[INFO][17:09:08]: [Client #14] Selected by the server.
[INFO][17:09:08]: [Client #14] Loading its data source...
[INFO][17:09:08]: [Client #983] Selected by the server.
[INFO][17:09:08]: Data source: FEMNIST
[INFO][17:09:08]: [Client #983] Loading its data source...
[INFO][17:09:08]: Data source: FEMNIST
[INFO][17:09:08]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:09:08]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/983.zip.
[INFO][17:09:08]: [Client #14] Dataset size: 154
[INFO][17:09:08]: [Client #14] Sampler: all_inclusive
[INFO][17:09:08]: [Client #14] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:09:08]: [93m[1m[Client #14] Started training in communication round #19.[0m
2.4%4.8%7.2%9.6%12.0%14.4%16.9%19.3%21.7%24.1%26.5%28.9%31.3%33.7%36.1%38.5%40.9%43.3%45.8%48.2%50.6%53.0%55.4%57.8%60.2%62.6%65.0%67.4%69.8%72.2%74.6%77.1%79.5%81.9%84.3%86.7%89.1%91.5%93.9%96.3%98.7%100.0%[INFO][17:09:08]: Decompressing the dataset downloaded.
[INFO][17:09:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/983.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:09:08]: [Client #983] Dataset size: 155
[INFO][17:09:08]: [Client #983] Sampler: all_inclusive
[INFO][17:09:08]: [Client #983] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:09:08]: [93m[1m[Client #983] Started training in communication round #19.[0m

[INFO][17:09:10]: [Client #14] Loading the dataset.
[INFO][17:09:10]: [Client #983] Loading the dataset.
[INFO][17:09:16]: [Client #14] Epoch: [1/5][0/16]	Loss: 0.863580
[INFO][17:09:16]: [Client #983] Epoch: [1/5][0/16]	Loss: 0.906886
[INFO][17:09:16]: [Client #14] Epoch: [1/5][10/16]	Loss: 0.287781
[INFO][17:09:16]: [Client #983] Epoch: [1/5][10/16]	Loss: 0.888158
[INFO][17:09:16]: [Client #14] Going to sleep for 7.20 seconds.
[INFO][17:09:16]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:09:23]: [Client #983] Woke up.
[INFO][17:09:23]: [Client #983] Epoch: [2/5][0/16]	Loss: 0.497463
[INFO][17:09:23]: [Client #983] Epoch: [2/5][10/16]	Loss: 0.444329
[INFO][17:09:23]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:09:23]: [Client #14] Woke up.
[INFO][17:09:23]: [Client #14] Epoch: [2/5][0/16]	Loss: 0.515417
[INFO][17:09:24]: [Client #14] Epoch: [2/5][10/16]	Loss: 0.429817
[INFO][17:09:24]: [Client #14] Going to sleep for 7.20 seconds.
[INFO][17:09:30]: [Client #983] Woke up.
[INFO][17:09:30]: [Client #983] Epoch: [3/5][0/16]	Loss: 0.090142
[INFO][17:09:30]: [Client #983] Epoch: [3/5][10/16]	Loss: 0.226791
[INFO][17:09:30]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:09:31]: [Client #14] Woke up.
[INFO][17:09:31]: [Client #14] Epoch: [3/5][0/16]	Loss: 0.632483
[INFO][17:09:31]: [Client #14] Epoch: [3/5][10/16]	Loss: 0.256583
[INFO][17:09:31]: [Client #14] Going to sleep for 7.20 seconds.
[INFO][17:09:37]: [Client #983] Woke up.
[INFO][17:09:37]: [Client #983] Epoch: [4/5][0/16]	Loss: 0.612781
[INFO][17:09:37]: [Client #983] Epoch: [4/5][10/16]	Loss: 0.199687
[INFO][17:09:37]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:09:38]: [Client #14] Woke up.
[INFO][17:09:38]: [Client #14] Epoch: [4/5][0/16]	Loss: 2.873105
[INFO][17:09:38]: [Client #14] Epoch: [4/5][10/16]	Loss: 1.672440
[INFO][17:09:38]: [Client #14] Going to sleep for 7.20 seconds.
[INFO][17:09:44]: [Client #983] Woke up.
[INFO][17:09:44]: [Client #983] Epoch: [5/5][0/16]	Loss: 0.629181
[INFO][17:09:44]: [Client #983] Epoch: [5/5][10/16]	Loss: 0.062149
[INFO][17:09:44]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:09:46]: [Client #14] Woke up.
[INFO][17:09:46]: [Client #14] Epoch: [5/5][0/16]	Loss: 0.858688
[INFO][17:09:46]: [Client #14] Epoch: [5/5][10/16]	Loss: 1.924508
[INFO][17:09:46]: [Client #14] Going to sleep for 7.20 seconds.
[INFO][17:09:50]: [Client #983] Woke up.
[INFO][17:09:50]: [Client #983] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_983_615875.pth.
[INFO][17:09:51]: [Client #983] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_983_615875.pth.
[INFO][17:09:51]: [Client #983] Model trained.
[INFO][17:09:51]: [Client #983] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:09:51]: [Server #615782] Received 0.26 MB of payload data from client #983 (simulated).
[INFO][17:09:53]: [Client #14] Woke up.
[INFO][17:09:53]: [Client #14] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_14_615874.pth.
[INFO][17:09:54]: [Client #14] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_14_615874.pth.
[INFO][17:09:54]: [Client #14] Model trained.
[INFO][17:09:54]: [Client #14] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:09:54]: [Server #615782] Received 0.26 MB of payload data from client #14 (simulated).
[INFO][17:09:54]: [Server #615782] Selecting client #172 for training.
[INFO][17:09:54]: [Server #615782] Sending the current model to client #172 (simulated).
[INFO][17:09:54]: [Server #615782] Sending 0.26 MB of payload data to client #172 (simulated).
[INFO][17:09:54]: [Server #615782] Selecting client #906 for training.
[INFO][17:09:54]: [Server #615782] Sending the current model to client #906 (simulated).
[INFO][17:09:54]: [Server #615782] Sending 0.26 MB of payload data to client #906 (simulated).
[INFO][17:09:54]: [Client #172] Selected by the server.
[INFO][17:09:54]: [Client #172] Loading its data source...
[INFO][17:09:54]: Data source: FEMNIST
[INFO][17:09:54]: [Client #906] Selected by the server.
[INFO][17:09:54]: [Client #906] Loading its data source...
[INFO][17:09:54]: Data source: FEMNIST
[INFO][17:09:54]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:09:54]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/906.zip.
[INFO][17:09:54]: [Client #172] Dataset size: 164
[INFO][17:09:54]: [Client #172] Sampler: all_inclusive
[INFO][17:09:54]: [Client #172] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:09:54]: [93m[1m[Client #172] Started training in communication round #19.[0m
2.5%4.9%7.4%9.9%12.4%14.8%17.3%19.8%22.2%24.7%27.2%29.6%32.1%34.6%37.1%39.5%42.0%44.5%46.9%49.4%51.9%54.3%56.8%59.3%61.8%64.2%66.7%69.2%71.6%74.1%76.6%79.0%81.5%84.0%86.5%88.9%91.4%93.9%96.3%98.8%100.0%[INFO][17:09:54]: Decompressing the dataset downloaded.
[INFO][17:09:54]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/906.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:09:54]: [Client #906] Dataset size: 164
[INFO][17:09:54]: [Client #906] Sampler: all_inclusive
[INFO][17:09:54]: [Client #906] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:09:54]: [93m[1m[Client #906] Started training in communication round #19.[0m

[INFO][17:09:56]: [Client #172] Loading the dataset.
[INFO][17:09:56]: [Client #906] Loading the dataset.
[INFO][17:10:02]: [Client #172] Epoch: [1/5][0/17]	Loss: 1.020410
[INFO][17:10:02]: [Client #172] Epoch: [1/5][10/17]	Loss: 0.855374
[INFO][17:10:02]: [Client #906] Epoch: [1/5][0/17]	Loss: 0.772550
[INFO][17:10:02]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:10:02]: [Client #906] Epoch: [1/5][10/17]	Loss: 0.433013
[INFO][17:10:02]: [Client #906] Going to sleep for 0.60 seconds.
[INFO][17:10:02]: [Client #906] Woke up.
[INFO][17:10:02]: [Client #906] Epoch: [2/5][0/17]	Loss: 0.260797
[INFO][17:10:03]: [Client #906] Epoch: [2/5][10/17]	Loss: 0.521582
[INFO][17:10:03]: [Client #906] Going to sleep for 0.60 seconds.
[INFO][17:10:03]: [Client #906] Woke up.
[INFO][17:10:03]: [Client #906] Epoch: [3/5][0/17]	Loss: 0.170521
[INFO][17:10:03]: [Client #906] Epoch: [3/5][10/17]	Loss: 1.050806
[INFO][17:10:03]: [Client #906] Going to sleep for 0.60 seconds.
[INFO][17:10:04]: [Client #906] Woke up.
[INFO][17:10:04]: [Client #906] Epoch: [4/5][0/17]	Loss: 0.457334
[INFO][17:10:04]: [Client #906] Epoch: [4/5][10/17]	Loss: 1.366431
[INFO][17:10:04]: [Client #906] Going to sleep for 0.60 seconds.
[INFO][17:10:05]: [Client #906] Woke up.
[INFO][17:10:05]: [Client #906] Epoch: [5/5][0/17]	Loss: 0.613096
[INFO][17:10:05]: [Client #906] Epoch: [5/5][10/17]	Loss: 0.458030
[INFO][17:10:05]: [Client #906] Going to sleep for 0.60 seconds.
[INFO][17:10:05]: [Client #906] Woke up.
[INFO][17:10:05]: [Client #906] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_906_615875.pth.
[INFO][17:10:06]: [Client #906] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_906_615875.pth.
[INFO][17:10:06]: [Client #906] Model trained.
[INFO][17:10:06]: [Client #906] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:10:06]: [Server #615782] Received 0.26 MB of payload data from client #906 (simulated).
[INFO][17:11:02]: [Client #172] Woke up.
[INFO][17:11:02]: [Client #172] Epoch: [2/5][0/17]	Loss: 0.689333
[INFO][17:11:02]: [Client #172] Epoch: [2/5][10/17]	Loss: 0.936113
[INFO][17:11:02]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:12:02]: [Client #172] Woke up.
[INFO][17:12:02]: [Client #172] Epoch: [3/5][0/17]	Loss: 0.305081
[INFO][17:12:02]: [Client #172] Epoch: [3/5][10/17]	Loss: 0.392804
[INFO][17:12:02]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:13:02]: [Client #172] Woke up.
[INFO][17:13:03]: [Client #172] Epoch: [4/5][0/17]	Loss: 1.056932
[INFO][17:13:03]: [Client #172] Epoch: [4/5][10/17]	Loss: 0.222044
[INFO][17:13:03]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:14:03]: [Client #172] Woke up.
[INFO][17:14:03]: [Client #172] Epoch: [5/5][0/17]	Loss: 0.569472
[INFO][17:14:03]: [Client #172] Epoch: [5/5][10/17]	Loss: 0.374540
[INFO][17:14:03]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:15:03]: [Client #172] Woke up.
[INFO][17:15:03]: [Client #172] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615874.pth.
[INFO][17:15:04]: [Client #172] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615874.pth.
[INFO][17:15:04]: [Client #172] Model trained.
[INFO][17:15:04]: [Client #172] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:15:04]: [Server #615782] Received 0.26 MB of payload data from client #172 (simulated).
[INFO][17:15:04]: [Server #615782] Selecting client #805 for training.
[INFO][17:15:04]: [Server #615782] Sending the current model to client #805 (simulated).
[INFO][17:15:04]: [Server #615782] Sending 0.26 MB of payload data to client #805 (simulated).
[INFO][17:15:04]: [Server #615782] Selecting client #798 for training.
[INFO][17:15:04]: [Server #615782] Sending the current model to client #798 (simulated).
[INFO][17:15:04]: [Server #615782] Sending 0.26 MB of payload data to client #798 (simulated).
[INFO][17:15:04]: [Client #805] Selected by the server.
[INFO][17:15:04]: [Client #805] Loading its data source...
[INFO][17:15:04]: Data source: FEMNIST
[INFO][17:15:04]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:15:04]: [Client #798] Selected by the server.
[INFO][17:15:04]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/805.zip.
[INFO][17:15:04]: [Client #798] Loading its data source...
[INFO][17:15:04]: Data source: FEMNIST
[INFO][17:15:04]: [Client #798] Dataset size: 153
[INFO][17:15:04]: [Client #798] Sampler: all_inclusive
[INFO][17:15:04]: [Client #798] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:04]: [93m[1m[Client #798] Started training in communication round #19.[0m
3.0%6.0%9.0%12.0%15.0%18.0%21.0%24.0%27.0%30.0%33.0%36.0%39.0%42.0%45.0%48.0%51.0%54.0%57.0%60.0%63.0%66.0%69.0%72.0%75.0%78.0%81.0%84.0%87.0%90.0%93.0%96.0%99.0%100.0%[INFO][17:15:04]: Decompressing the dataset downloaded.
[INFO][17:15:04]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/805.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:15:04]: [Client #805] Dataset size: 161
[INFO][17:15:04]: [Client #805] Sampler: all_inclusive
[INFO][17:15:04]: [Client #805] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:04]: [93m[1m[Client #805] Started training in communication round #19.[0m

[INFO][17:15:06]: [Client #798] Loading the dataset.
[INFO][17:15:06]: [Client #805] Loading the dataset.
[INFO][17:15:11]: [Client #798] Epoch: [1/5][0/16]	Loss: 0.182962
[INFO][17:15:11]: [Client #805] Epoch: [1/5][0/17]	Loss: 0.777862
[INFO][17:15:11]: [Client #798] Epoch: [1/5][10/16]	Loss: 0.772554
[INFO][17:15:11]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][17:15:12]: [Client #805] Epoch: [1/5][10/17]	Loss: 1.636349
[INFO][17:15:12]: [Client #805] Going to sleep for 0.81 seconds.
[INFO][17:15:12]: [Client #805] Woke up.
[INFO][17:15:12]: [Client #805] Epoch: [2/5][0/17]	Loss: 1.025807
[INFO][17:15:12]: [Client #805] Epoch: [2/5][10/17]	Loss: 0.533727
[INFO][17:15:12]: [Client #805] Going to sleep for 0.81 seconds.
[INFO][17:15:13]: [Client #798] Woke up.
[INFO][17:15:13]: [Client #798] Epoch: [2/5][0/16]	Loss: 0.905815
[INFO][17:15:13]: [Client #798] Epoch: [2/5][10/16]	Loss: 0.308152
[INFO][17:15:13]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][17:15:13]: [Client #805] Woke up.
[INFO][17:15:13]: [Client #805] Epoch: [3/5][0/17]	Loss: 2.523094
[INFO][17:15:13]: [Client #805] Epoch: [3/5][10/17]	Loss: 1.692222
[INFO][17:15:13]: [Client #805] Going to sleep for 0.81 seconds.
[INFO][17:15:14]: [Client #798] Woke up.
[INFO][17:15:14]: [Client #798] Epoch: [3/5][0/16]	Loss: 0.852259
[INFO][17:15:14]: [Client #798] Epoch: [3/5][10/16]	Loss: 0.976247
[INFO][17:15:14]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][17:15:14]: [Client #805] Woke up.
[INFO][17:15:14]: [Client #805] Epoch: [4/5][0/17]	Loss: 1.469038
[INFO][17:15:14]: [Client #805] Epoch: [4/5][10/17]	Loss: 1.339738
[INFO][17:15:14]: [Client #805] Going to sleep for 0.81 seconds.
[INFO][17:15:15]: [Client #805] Woke up.
[INFO][17:15:15]: [Client #805] Epoch: [5/5][0/17]	Loss: 1.451613
[INFO][17:15:15]: [Client #805] Epoch: [5/5][10/17]	Loss: 2.379546
[INFO][17:15:15]: [Client #805] Going to sleep for 0.81 seconds.
[INFO][17:15:15]: [Client #798] Woke up.
[INFO][17:15:15]: [Client #798] Epoch: [4/5][0/16]	Loss: 0.359920
[INFO][17:15:15]: [Client #798] Epoch: [4/5][10/16]	Loss: 0.823068
[INFO][17:15:15]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][17:15:16]: [Client #805] Woke up.
[INFO][17:15:16]: [Client #805] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_805_615874.pth.
[INFO][17:15:17]: [Client #798] Woke up.
[INFO][17:15:17]: [Client #798] Epoch: [5/5][0/16]	Loss: 0.012093
[INFO][17:15:17]: [Client #798] Epoch: [5/5][10/16]	Loss: 0.353520
[INFO][17:15:17]: [Client #805] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_805_615874.pth.
[INFO][17:15:17]: [Client #805] Model trained.
[INFO][17:15:17]: [Client #805] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:15:17]: [Server #615782] Received 0.26 MB of payload data from client #805 (simulated).
[INFO][17:15:17]: [Client #798] Going to sleep for 1.19 seconds.
[INFO][17:15:18]: [Client #798] Woke up.
[INFO][17:15:18]: [Client #798] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_798_615875.pth.
[INFO][17:15:19]: [Client #798] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_798_615875.pth.
[INFO][17:15:19]: [Client #798] Model trained.
[INFO][17:15:19]: [Client #798] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:15:19]: [Server #615782] Received 0.26 MB of payload data from client #798 (simulated).
[INFO][17:15:19]: [Server #615782] Selecting client #268 for training.
[INFO][17:15:19]: [Server #615782] Sending the current model to client #268 (simulated).
[INFO][17:15:19]: [Server #615782] Sending 0.26 MB of payload data to client #268 (simulated).
[INFO][17:15:19]: [Server #615782] Selecting client #219 for training.
[INFO][17:15:19]: [Server #615782] Sending the current model to client #219 (simulated).
[INFO][17:15:19]: [Server #615782] Sending 0.26 MB of payload data to client #219 (simulated).
[INFO][17:15:19]: [Client #268] Selected by the server.
[INFO][17:15:19]: [Client #268] Loading its data source...
[INFO][17:15:19]: Data source: FEMNIST
[INFO][17:15:19]: [Client #219] Selected by the server.
[INFO][17:15:19]: [Client #219] Loading its data source...
[INFO][17:15:19]: Data source: FEMNIST
[INFO][17:15:19]: [Client #219] Dataset size: 154
[INFO][17:15:19]: [Client #219] Sampler: all_inclusive
[INFO][17:15:19]: [Client #268] Dataset size: 161
[INFO][17:15:19]: [Client #268] Sampler: all_inclusive
[INFO][17:15:19]: [Client #219] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:19]: [Client #268] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:19]: [93m[1m[Client #268] Started training in communication round #19.[0m
[INFO][17:15:19]: [93m[1m[Client #219] Started training in communication round #19.[0m
[INFO][17:15:21]: [Client #268] Loading the dataset.
[INFO][17:15:21]: [Client #219] Loading the dataset.
[INFO][17:15:27]: [Client #268] Epoch: [1/5][0/17]	Loss: 0.427811
[INFO][17:15:27]: [Client #219] Epoch: [1/5][0/16]	Loss: 1.109752
[INFO][17:15:27]: [Client #219] Epoch: [1/5][10/16]	Loss: 1.326553
[INFO][17:15:27]: [Client #268] Epoch: [1/5][10/17]	Loss: 0.478115
[INFO][17:15:27]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][17:15:27]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][17:15:28]: [Client #268] Woke up.
[INFO][17:15:28]: [Client #268] Epoch: [2/5][0/17]	Loss: 0.908897
[INFO][17:15:28]: [Client #268] Epoch: [2/5][10/17]	Loss: 1.104097
[INFO][17:15:28]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][17:15:29]: [Client #268] Woke up.
[INFO][17:15:29]: [Client #268] Epoch: [3/5][0/17]	Loss: 0.384303
[INFO][17:15:29]: [Client #268] Epoch: [3/5][10/17]	Loss: 2.246134
[INFO][17:15:29]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][17:15:30]: [Client #268] Woke up.
[INFO][17:15:30]: [Client #268] Epoch: [4/5][0/17]	Loss: 0.797178
[INFO][17:15:30]: [Client #268] Epoch: [4/5][10/17]	Loss: 0.822683
[INFO][17:15:30]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][17:15:31]: [Client #268] Woke up.
[INFO][17:15:31]: [Client #268] Epoch: [5/5][0/17]	Loss: 0.145243
[INFO][17:15:31]: [Client #268] Epoch: [5/5][10/17]	Loss: 1.052816
[INFO][17:15:31]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][17:15:32]: [Client #219] Woke up.
[INFO][17:15:32]: [Client #268] Woke up.
[INFO][17:15:32]: [Client #219] Epoch: [2/5][0/16]	Loss: 0.935925
[INFO][17:15:32]: [Client #268] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_268_615874.pth.
[INFO][17:15:32]: [Client #219] Epoch: [2/5][10/16]	Loss: 1.796277
[INFO][17:15:32]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][17:15:33]: [Client #268] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_268_615874.pth.
[INFO][17:15:33]: [Client #268] Model trained.
[INFO][17:15:33]: [Client #268] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:15:33]: [Server #615782] Received 0.26 MB of payload data from client #268 (simulated).
[INFO][17:15:37]: [Client #219] Woke up.
[INFO][17:15:37]: [Client #219] Epoch: [3/5][0/16]	Loss: 2.064605
[INFO][17:15:37]: [Client #219] Epoch: [3/5][10/16]	Loss: 0.969521
[INFO][17:15:37]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][17:15:42]: [Client #219] Woke up.
[INFO][17:15:42]: [Client #219] Epoch: [4/5][0/16]	Loss: 0.713909
[INFO][17:15:42]: [Client #219] Epoch: [4/5][10/16]	Loss: 1.737614
[INFO][17:15:42]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][17:15:47]: [Client #219] Woke up.
[INFO][17:15:47]: [Client #219] Epoch: [5/5][0/16]	Loss: 0.837933
[INFO][17:15:47]: [Client #219] Epoch: [5/5][10/16]	Loss: 0.956307
[INFO][17:15:47]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][17:15:52]: [Client #219] Woke up.
[INFO][17:15:52]: [Client #219] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_219_615875.pth.
[INFO][17:15:52]: [Client #219] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_219_615875.pth.
[INFO][17:15:52]: [Client #219] Model trained.
[INFO][17:15:52]: [Client #219] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:15:52]: [Server #615782] Received 0.26 MB of payload data from client #219 (simulated).
[INFO][17:15:52]: [Server #615782] Selecting client #428 for training.
[INFO][17:15:52]: [Server #615782] Sending the current model to client #428 (simulated).
[INFO][17:15:52]: [Server #615782] Sending 0.26 MB of payload data to client #428 (simulated).
[INFO][17:15:52]: [Server #615782] Selecting client #847 for training.
[INFO][17:15:52]: [Server #615782] Sending the current model to client #847 (simulated).
[INFO][17:15:52]: [Server #615782] Sending 0.26 MB of payload data to client #847 (simulated).
[INFO][17:15:52]: [Client #428] Selected by the server.
[INFO][17:15:52]: [Client #428] Loading its data source...
[INFO][17:15:52]: Data source: FEMNIST
[INFO][17:15:52]: [Client #847] Selected by the server.
[INFO][17:15:52]: [Client #847] Loading its data source...
[INFO][17:15:52]: Data source: FEMNIST
[INFO][17:15:52]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:15:52]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/847.zip.
[INFO][17:15:52]: [Client #428] Dataset size: 159
[INFO][17:15:52]: [Client #428] Sampler: all_inclusive
[INFO][17:15:52]: [Client #428] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:52]: [93m[1m[Client #428] Started training in communication round #19.[0m
2.6%5.2%7.8%10.4%13.0%15.6%18.2%20.8%23.4%26.0%28.6%31.2%33.8%36.4%39.0%41.6%44.2%46.8%49.4%52.0%54.6%57.2%59.8%62.4%64.9%67.5%70.1%72.7%75.3%77.9%80.5%83.1%85.7%88.3%90.9%93.5%96.1%98.7%100.0%[INFO][17:15:52]: Decompressing the dataset downloaded.
[INFO][17:15:52]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/847.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:15:53]: [Client #847] Dataset size: 164
[INFO][17:15:53]: [Client #847] Sampler: all_inclusive
[INFO][17:15:53]: [Client #847] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:15:53]: [93m[1m[Client #847] Started training in communication round #19.[0m

[INFO][17:15:54]: [Client #428] Loading the dataset.
[INFO][17:15:54]: [Client #847] Loading the dataset.
[INFO][17:16:00]: [Client #428] Epoch: [1/5][0/16]	Loss: 0.981684
[INFO][17:16:00]: [Client #847] Epoch: [1/5][0/17]	Loss: 0.072617
[INFO][17:16:00]: [Client #428] Epoch: [1/5][10/16]	Loss: 0.578420
[INFO][17:16:00]: [Client #847] Epoch: [1/5][10/17]	Loss: 0.989837
[INFO][17:16:00]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][17:16:00]: [Client #847] Going to sleep for 1.54 seconds.
[INFO][17:16:02]: [Client #847] Woke up.
[INFO][17:16:02]: [Client #847] Epoch: [2/5][0/17]	Loss: 0.858485
[INFO][17:16:02]: [Client #847] Epoch: [2/5][10/17]	Loss: 1.030818
[INFO][17:16:02]: [Client #847] Going to sleep for 1.54 seconds.
[INFO][17:16:03]: [Client #428] Woke up.
[INFO][17:16:03]: [Client #428] Epoch: [2/5][0/16]	Loss: 1.104934
[INFO][17:16:03]: [Client #428] Epoch: [2/5][10/16]	Loss: 1.230929
[INFO][17:16:03]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][17:16:03]: [Client #847] Woke up.
[INFO][17:16:03]: [Client #847] Epoch: [3/5][0/17]	Loss: 0.459369
[INFO][17:16:03]: [Client #847] Epoch: [3/5][10/17]	Loss: 1.108447
[INFO][17:16:03]: [Client #847] Going to sleep for 1.54 seconds.
[INFO][17:16:05]: [Client #847] Woke up.
[INFO][17:16:05]: [Client #847] Epoch: [4/5][0/17]	Loss: 0.986714
[INFO][17:16:05]: [Client #847] Epoch: [4/5][10/17]	Loss: 0.324136
[INFO][17:16:05]: [Client #847] Going to sleep for 1.54 seconds.
[INFO][17:16:06]: [Client #428] Woke up.
[INFO][17:16:06]: [Client #428] Epoch: [3/5][0/16]	Loss: 1.603027
[INFO][17:16:06]: [Client #428] Epoch: [3/5][10/16]	Loss: 1.776910
[INFO][17:16:06]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][17:16:07]: [Client #847] Woke up.
[INFO][17:16:07]: [Client #847] Epoch: [5/5][0/17]	Loss: 1.268150
[INFO][17:16:07]: [Client #847] Epoch: [5/5][10/17]	Loss: 0.352442
[INFO][17:16:07]: [Client #847] Going to sleep for 1.54 seconds.
[INFO][17:16:08]: [Client #847] Woke up.
[INFO][17:16:08]: [Client #847] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_847_615875.pth.
[INFO][17:16:09]: [Client #847] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_847_615875.pth.
[INFO][17:16:09]: [Client #847] Model trained.
[INFO][17:16:09]: [Client #847] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:09]: [Server #615782] Received 0.26 MB of payload data from client #847 (simulated).
[INFO][17:16:09]: [Client #428] Woke up.
[INFO][17:16:10]: [Client #428] Epoch: [4/5][0/16]	Loss: 0.499664
[INFO][17:16:10]: [Client #428] Epoch: [4/5][10/16]	Loss: 0.329803
[INFO][17:16:10]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][17:16:13]: [Client #428] Woke up.
[INFO][17:16:13]: [Client #428] Epoch: [5/5][0/16]	Loss: 0.521861
[INFO][17:16:13]: [Client #428] Epoch: [5/5][10/16]	Loss: 0.843324
[INFO][17:16:13]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][17:16:16]: [Client #428] Woke up.
[INFO][17:16:16]: [Client #428] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_615874.pth.
[INFO][17:16:17]: [Client #428] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_615874.pth.
[INFO][17:16:17]: [Client #428] Model trained.
[INFO][17:16:17]: [Client #428] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:17]: [Server #615782] Received 0.26 MB of payload data from client #428 (simulated).
[INFO][17:16:17]: [Server #615782] Selecting client #449 for training.
[INFO][17:16:17]: [Server #615782] Sending the current model to client #449 (simulated).
[INFO][17:16:17]: [Server #615782] Sending 0.26 MB of payload data to client #449 (simulated).
[INFO][17:16:17]: [Server #615782] Selecting client #935 for training.
[INFO][17:16:17]: [Server #615782] Sending the current model to client #935 (simulated).
[INFO][17:16:17]: [Server #615782] Sending 0.26 MB of payload data to client #935 (simulated).
[INFO][17:16:17]: [Client #449] Selected by the server.
[INFO][17:16:17]: [Client #449] Loading its data source...
[INFO][17:16:17]: Data source: FEMNIST
[INFO][17:16:17]: [Client #935] Selected by the server.
[INFO][17:16:17]: [Client #935] Loading its data source...
[INFO][17:16:17]: Data source: FEMNIST
[INFO][17:16:17]: [Client #935] Dataset size: 135
[INFO][17:16:17]: [Client #935] Sampler: all_inclusive
[INFO][17:16:17]: [Client #449] Dataset size: 162
[INFO][17:16:17]: [Client #449] Sampler: all_inclusive
[INFO][17:16:17]: [Client #935] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:17]: [Client #449] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:17]: [93m[1m[Client #935] Started training in communication round #19.[0m
[INFO][17:16:17]: [93m[1m[Client #449] Started training in communication round #19.[0m
[INFO][17:16:19]: [Client #449] Loading the dataset.
[INFO][17:16:19]: [Client #935] Loading the dataset.
[INFO][17:16:24]: [Client #935] Epoch: [1/5][0/14]	Loss: 1.363058
[INFO][17:16:24]: [Client #449] Epoch: [1/5][0/17]	Loss: 1.326243
[INFO][17:16:24]: [Client #935] Epoch: [1/5][10/14]	Loss: 0.445666
[INFO][17:16:24]: [Client #449] Epoch: [1/5][10/17]	Loss: 0.508204
[INFO][17:16:24]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][17:16:24]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][17:16:24]: [Client #449] Woke up.
[INFO][17:16:24]: [Client #449] Epoch: [2/5][0/17]	Loss: 0.465634
[INFO][17:16:25]: [Client #449] Epoch: [2/5][10/17]	Loss: 0.763740
[INFO][17:16:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][17:16:25]: [Client #449] Woke up.
[INFO][17:16:25]: [Client #449] Epoch: [3/5][0/17]	Loss: 0.978781
[INFO][17:16:25]: [Client #449] Epoch: [3/5][10/17]	Loss: 0.999408
[INFO][17:16:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][17:16:25]: [Client #449] Woke up.
[INFO][17:16:25]: [Client #449] Epoch: [4/5][0/17]	Loss: 0.120842
[INFO][17:16:25]: [Client #449] Epoch: [4/5][10/17]	Loss: 0.628609
[INFO][17:16:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][17:16:25]: [Client #935] Woke up.
[INFO][17:16:25]: [Client #935] Epoch: [2/5][0/14]	Loss: 0.639479
[INFO][17:16:25]: [Client #935] Epoch: [2/5][10/14]	Loss: 0.885015
[INFO][17:16:25]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][17:16:25]: [Client #449] Woke up.
[INFO][17:16:25]: [Client #449] Epoch: [5/5][0/17]	Loss: 0.772901
[INFO][17:16:26]: [Client #449] Epoch: [5/5][10/17]	Loss: 1.033127
[INFO][17:16:26]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][17:16:26]: [Client #449] Woke up.
[INFO][17:16:26]: [Client #449] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_449_615874.pth.
[INFO][17:16:26]: [Client #449] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_449_615874.pth.
[INFO][17:16:26]: [Client #449] Model trained.
[INFO][17:16:26]: [Client #449] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:26]: [Server #615782] Received 0.26 MB of payload data from client #449 (simulated).
[INFO][17:16:26]: [Client #935] Woke up.
[INFO][17:16:26]: [Client #935] Epoch: [3/5][0/14]	Loss: 0.156992
[INFO][17:16:27]: [Client #935] Epoch: [3/5][10/14]	Loss: 1.593985
[INFO][17:16:27]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][17:16:28]: [Client #935] Woke up.
[INFO][17:16:28]: [Client #935] Epoch: [4/5][0/14]	Loss: 1.965787
[INFO][17:16:28]: [Client #935] Epoch: [4/5][10/14]	Loss: 0.688079
[INFO][17:16:28]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][17:16:29]: [Client #935] Woke up.
[INFO][17:16:29]: [Client #935] Epoch: [5/5][0/14]	Loss: 0.969741
[INFO][17:16:29]: [Client #935] Epoch: [5/5][10/14]	Loss: 0.482944
[INFO][17:16:29]: [Client #935] Going to sleep for 1.01 seconds.
[INFO][17:16:30]: [Client #935] Woke up.
[INFO][17:16:30]: [Client #935] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_935_615875.pth.
[INFO][17:16:30]: [Client #935] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_935_615875.pth.
[INFO][17:16:30]: [Client #935] Model trained.
[INFO][17:16:31]: [Client #935] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:31]: [Server #615782] Received 0.26 MB of payload data from client #935 (simulated).
[INFO][17:16:31]: [Server #615782] Selecting client #352 for training.
[INFO][17:16:31]: [Server #615782] Sending the current model to client #352 (simulated).
[INFO][17:16:31]: [Server #615782] Sending 0.26 MB of payload data to client #352 (simulated).
[INFO][17:16:31]: [Server #615782] Selecting client #617 for training.
[INFO][17:16:31]: [Server #615782] Sending the current model to client #617 (simulated).
[INFO][17:16:31]: [Server #615782] Sending 0.26 MB of payload data to client #617 (simulated).
[INFO][17:16:31]: [Client #617] Selected by the server.
[INFO][17:16:31]: [Client #352] Selected by the server.
[INFO][17:16:31]: [Client #617] Loading its data source...
[INFO][17:16:31]: [Client #352] Loading its data source...
[INFO][17:16:31]: Data source: FEMNIST
[INFO][17:16:31]: Data source: FEMNIST
[INFO][17:16:31]: [Client #617] Dataset size: 140
[INFO][17:16:31]: [Client #617] Sampler: all_inclusive
[INFO][17:16:31]: [Client #352] Dataset size: 163
[INFO][17:16:31]: [Client #352] Sampler: all_inclusive
[INFO][17:16:31]: [Client #617] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:31]: [Client #352] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:31]: [93m[1m[Client #352] Started training in communication round #19.[0m
[INFO][17:16:31]: [93m[1m[Client #617] Started training in communication round #19.[0m
[INFO][17:16:33]: [Client #617] Loading the dataset.
[INFO][17:16:33]: [Client #352] Loading the dataset.
[INFO][17:16:38]: [Client #352] Epoch: [1/5][0/17]	Loss: 0.590394
[INFO][17:16:38]: [Client #617] Epoch: [1/5][0/14]	Loss: 0.608723
[INFO][17:16:38]: [Client #352] Epoch: [1/5][10/17]	Loss: 2.579490
[INFO][17:16:39]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][17:16:39]: [Client #617] Epoch: [1/5][10/14]	Loss: 0.875010
[INFO][17:16:39]: [Client #617] Going to sleep for 0.19 seconds.
[INFO][17:16:39]: [Client #617] Woke up.
[INFO][17:16:39]: [Client #617] Epoch: [2/5][0/14]	Loss: 0.892746
[INFO][17:16:39]: [Client #617] Epoch: [2/5][10/14]	Loss: 1.148549
[INFO][17:16:39]: [Client #617] Going to sleep for 0.19 seconds.
[INFO][17:16:39]: [Client #617] Woke up.
[INFO][17:16:39]: [Client #617] Epoch: [3/5][0/14]	Loss: 0.485659
[INFO][17:16:39]: [Client #617] Epoch: [3/5][10/14]	Loss: 0.924091
[INFO][17:16:39]: [Client #617] Going to sleep for 0.19 seconds.
[INFO][17:16:39]: [Client #617] Woke up.
[INFO][17:16:39]: [Client #617] Epoch: [4/5][0/14]	Loss: 0.482281
[INFO][17:16:39]: [Client #617] Epoch: [4/5][10/14]	Loss: 0.600784
[INFO][17:16:39]: [Client #617] Going to sleep for 0.19 seconds.
[INFO][17:16:40]: [Client #617] Woke up.
[INFO][17:16:40]: [Client #617] Epoch: [5/5][0/14]	Loss: 0.424974
[INFO][17:16:40]: [Client #617] Epoch: [5/5][10/14]	Loss: 0.351373
[INFO][17:16:40]: [Client #617] Going to sleep for 0.19 seconds.
[INFO][17:16:40]: [Client #617] Woke up.
[INFO][17:16:40]: [Client #617] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_617_615875.pth.
[INFO][17:16:41]: [Client #617] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_617_615875.pth.
[INFO][17:16:41]: [Client #617] Model trained.
[INFO][17:16:41]: [Client #617] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:41]: [Server #615782] Received 0.26 MB of payload data from client #617 (simulated).
[INFO][17:16:41]: [Client #352] Woke up.
[INFO][17:16:41]: [Client #352] Epoch: [2/5][0/17]	Loss: 0.495145
[INFO][17:16:41]: [Client #352] Epoch: [2/5][10/17]	Loss: 1.100907
[INFO][17:16:41]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][17:16:44]: [Client #352] Woke up.
[INFO][17:16:44]: [Client #352] Epoch: [3/5][0/17]	Loss: 0.895767
[INFO][17:16:44]: [Client #352] Epoch: [3/5][10/17]	Loss: 1.937728
[INFO][17:16:44]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][17:16:47]: [Client #352] Woke up.
[INFO][17:16:47]: [Client #352] Epoch: [4/5][0/17]	Loss: 1.914025
[INFO][17:16:47]: [Client #352] Epoch: [4/5][10/17]	Loss: 2.498123
[INFO][17:16:47]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][17:16:50]: [Client #352] Woke up.
[INFO][17:16:50]: [Client #352] Epoch: [5/5][0/17]	Loss: 1.709499
[INFO][17:16:50]: [Client #352] Epoch: [5/5][10/17]	Loss: 1.341014
[INFO][17:16:50]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][17:16:53]: [Client #352] Woke up.
[INFO][17:16:53]: [Client #352] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_615874.pth.
[INFO][17:16:54]: [Client #352] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_615874.pth.
[INFO][17:16:54]: [Client #352] Model trained.
[INFO][17:16:54]: [Client #352] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:16:54]: [Server #615782] Received 0.26 MB of payload data from client #352 (simulated).
[INFO][17:16:54]: [Server #615782] Selecting client #981 for training.
[INFO][17:16:54]: [Server #615782] Sending the current model to client #981 (simulated).
[INFO][17:16:54]: [Server #615782] Sending 0.26 MB of payload data to client #981 (simulated).
[INFO][17:16:54]: [Server #615782] Selecting client #641 for training.
[INFO][17:16:54]: [Server #615782] Sending the current model to client #641 (simulated).
[INFO][17:16:54]: [Server #615782] Sending 0.26 MB of payload data to client #641 (simulated).
[INFO][17:16:54]: [Client #981] Selected by the server.
[INFO][17:16:54]: [Client #981] Loading its data source...
[INFO][17:16:54]: Data source: FEMNIST
[INFO][17:16:54]: [Client #641] Selected by the server.
[INFO][17:16:54]: [Client #641] Loading its data source...
[INFO][17:16:54]: Data source: FEMNIST
[INFO][17:16:54]: [Client #641] Dataset size: 162
[INFO][17:16:54]: [Client #641] Sampler: all_inclusive
[INFO][17:16:54]: [Client #641] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:54]: [Client #981] Dataset size: 162
[INFO][17:16:54]: [Client #981] Sampler: all_inclusive
[INFO][17:16:54]: [Client #981] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:16:54]: [93m[1m[Client #641] Started training in communication round #19.[0m
[INFO][17:16:54]: [93m[1m[Client #981] Started training in communication round #19.[0m
[INFO][17:16:56]: [Client #981] Loading the dataset.
[INFO][17:16:56]: [Client #641] Loading the dataset.
[INFO][17:17:02]: [Client #641] Epoch: [1/5][0/17]	Loss: 0.389958
[INFO][17:17:02]: [Client #981] Epoch: [1/5][0/17]	Loss: 0.641819
[INFO][17:17:02]: [Client #641] Epoch: [1/5][10/17]	Loss: 0.094146
[INFO][17:17:02]: [Client #981] Epoch: [1/5][10/17]	Loss: 1.190203
[INFO][17:17:02]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][17:17:02]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][17:17:02]: [Client #641] Woke up.
[INFO][17:17:02]: [Client #641] Epoch: [2/5][0/17]	Loss: 0.055549
[INFO][17:17:02]: [Client #981] Woke up.
[INFO][17:17:02]: [Client #981] Epoch: [2/5][0/17]	Loss: 1.780992
[INFO][17:17:02]: [Client #641] Epoch: [2/5][10/17]	Loss: 0.921042
[INFO][17:17:02]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][17:17:02]: [Client #981] Epoch: [2/5][10/17]	Loss: 1.736267
[INFO][17:17:02]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][17:17:02]: [Client #641] Woke up.
[INFO][17:17:02]: [Client #641] Epoch: [3/5][0/17]	Loss: 0.225219
[INFO][17:17:02]: [Client #641] Epoch: [3/5][10/17]	Loss: 0.522498
[INFO][17:17:02]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][17:17:02]: [Client #981] Woke up.
[INFO][17:17:02]: [Client #981] Epoch: [3/5][0/17]	Loss: 0.569078
[INFO][17:17:02]: [Client #641] Woke up.
[INFO][17:17:02]: [Client #641] Epoch: [4/5][0/17]	Loss: 0.503884
[INFO][17:17:02]: [Client #981] Epoch: [3/5][10/17]	Loss: 0.817720
[INFO][17:17:02]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][17:17:02]: [Client #641] Epoch: [4/5][10/17]	Loss: 1.919272
[INFO][17:17:02]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][17:17:03]: [Client #641] Woke up.
[INFO][17:17:03]: [Client #981] Woke up.
[INFO][17:17:03]: [Client #641] Epoch: [5/5][0/17]	Loss: 0.174661
[INFO][17:17:03]: [Client #981] Epoch: [4/5][0/17]	Loss: 0.165857
[INFO][17:17:03]: [Client #641] Epoch: [5/5][10/17]	Loss: 0.311631
[INFO][17:17:03]: [Client #981] Epoch: [4/5][10/17]	Loss: 1.153676
[INFO][17:17:03]: [Client #641] Going to sleep for 0.09 seconds.
[INFO][17:17:03]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][17:17:03]: [Client #641] Woke up.
[INFO][17:17:03]: [Client #641] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_641_615875.pth.
[INFO][17:17:03]: [Client #981] Woke up.
[INFO][17:17:03]: [Client #981] Epoch: [5/5][0/17]	Loss: 0.288804
[INFO][17:17:03]: [Client #981] Epoch: [5/5][10/17]	Loss: 1.028306
[INFO][17:17:03]: [Client #981] Going to sleep for 0.17 seconds.
[INFO][17:17:03]: [Client #981] Woke up.
[INFO][17:17:03]: [Client #981] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][17:17:03]: [Client #641] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_641_615875.pth.
[INFO][17:17:03]: [Client #641] Model trained.
[INFO][17:17:04]: [Client #641] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:17:04]: [Server #615782] Received 0.26 MB of payload data from client #641 (simulated).
[INFO][17:17:04]: [Client #981] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_981_615874.pth.
[INFO][17:17:04]: [Client #981] Model trained.
[INFO][17:17:04]: [Client #981] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:17:04]: [Server #615782] Received 0.26 MB of payload data from client #981 (simulated).
[INFO][17:17:04]: [Server #615782] Selecting client #46 for training.
[INFO][17:17:04]: [Server #615782] Sending the current model to client #46 (simulated).
[INFO][17:17:04]: [Server #615782] Sending 0.26 MB of payload data to client #46 (simulated).
[INFO][17:17:04]: [Client #46] Selected by the server.
[INFO][17:17:04]: [Client #46] Loading its data source...
[INFO][17:17:04]: Data source: FEMNIST
[INFO][17:17:04]: [Client #46] Dataset size: 134
[INFO][17:17:04]: [Client #46] Sampler: all_inclusive
[INFO][17:17:04]: [Client #46] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:17:04]: [93m[1m[Client #46] Started training in communication round #19.[0m
[INFO][17:17:06]: [Client #46] Loading the dataset.
[INFO][17:17:11]: [Client #46] Epoch: [1/5][0/14]	Loss: 1.553241
[INFO][17:17:11]: [Client #46] Epoch: [1/5][10/14]	Loss: 1.198735
[INFO][17:17:11]: [Client #46] Going to sleep for 0.81 seconds.
[INFO][17:17:12]: [Client #46] Woke up.
[INFO][17:17:12]: [Client #46] Epoch: [2/5][0/14]	Loss: 0.899404
[INFO][17:17:12]: [Client #46] Epoch: [2/5][10/14]	Loss: 1.744766
[INFO][17:17:12]: [Client #46] Going to sleep for 0.81 seconds.
[INFO][17:17:13]: [Client #46] Woke up.
[INFO][17:17:13]: [Client #46] Epoch: [3/5][0/14]	Loss: 0.625315
[INFO][17:17:13]: [Client #46] Epoch: [3/5][10/14]	Loss: 1.485947
[INFO][17:17:13]: [Client #46] Going to sleep for 0.81 seconds.
[INFO][17:17:14]: [Client #46] Woke up.
[INFO][17:17:14]: [Client #46] Epoch: [4/5][0/14]	Loss: 1.124172
[INFO][17:17:14]: [Client #46] Epoch: [4/5][10/14]	Loss: 1.087134
[INFO][17:17:14]: [Client #46] Going to sleep for 0.81 seconds.
[INFO][17:17:15]: [Client #46] Woke up.
[INFO][17:17:15]: [Client #46] Epoch: [5/5][0/14]	Loss: 0.306145
[INFO][17:17:15]: [Client #46] Epoch: [5/5][10/14]	Loss: 2.118056
[INFO][17:17:15]: [Client #46] Going to sleep for 0.81 seconds.
[INFO][17:17:16]: [Client #46] Woke up.
[INFO][17:17:16]: [Client #46] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_46_615874.pth.
[INFO][17:17:16]: [Client #46] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_46_615874.pth.
[INFO][17:17:16]: [Client #46] Model trained.
[INFO][17:17:16]: [Client #46] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:17:16]: [Server #615782] Received 0.26 MB of payload data from client #46 (simulated).
[INFO][17:17:16]: [Server #615782] Adding client #942 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #869 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #449 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #641 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #617 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #981 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #979 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #702 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #906 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #46 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #805 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #268 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #935 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #469 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #798 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #847 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #703 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #352 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #428 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #219 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #680 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #983 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #14 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #856 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Adding client #870 to the list of clients for aggregation.
[INFO][17:17:16]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10697674 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19639752 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.18102723 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.24681072 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.23088129 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10575124 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10837084 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10229692 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08338891 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11046536 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.18720836 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12766636
 0.06797308 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11122878
 0.         0.         0.         0.         0.         0.
 0.5442182  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0859063  0.         0.         0.         0.         0.
 0.         0.         0.         0.13904185 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.2387525  0.08546078
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15021154
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13442611 0.
 0.         0.         0.         0.         0.         0.11764788
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09350053 0.         0.15273774 0.         0.08600413 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10697674 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19639752 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.18102723 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.24681072 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.23088129 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10575124 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10837084 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10229692 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08338891 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11046536 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.18720836 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12766636
 0.06797308 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11122878
 0.         0.         0.         0.         0.         0.
 0.5442182  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0859063  0.         0.         0.         0.         0.
 0.         0.         0.         0.13904185 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.2387525  0.08546078
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15021154
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13442611 0.
 0.         0.         0.         0.         0.         0.11764788
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09350053 0.         0.15273774 0.         0.08600413 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.0404518  0.0341556  0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.001      0.03519832 0.001      0.03602175
 0.001      0.001      0.0350013  0.02051932 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.001
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.0420101  0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.03536294 0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03605313 0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.001      0.04067358 0.001
 0.001      0.001      0.02156219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.0386082  0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.02077264 0.03849787 0.001
 0.001      0.001      0.001      0.05542233 0.03898014 0.001
 0.03818786 0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07542694 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.03818786 0.04095046
 0.001      0.001      0.0404518  0.001      0.001      0.07779886
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.04068067 0.04307365 0.001      0.001
 0.03336511 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03448276 0.04227599 0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.04280776 0.03861004 0.001      0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.04229052 0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.001      0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.03167702 0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.03996077
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.0357513  0.001      0.04281587 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.001      0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.04147833
 0.001      0.001      0.001      0.001      0.03771347 0.01879376
 0.001      0.001      0.001      0.001      0.03756477 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.04176517 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.04255319 0.001
 0.03881946 0.03842505 0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02443074 0.04316547 0.001      0.001
 0.04281587 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.0357513  0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03866224 0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.001
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04244919 0.04307365 0.03462998 0.001      0.001      0.04063039
 0.0386082  0.001      0.04196891 0.001      0.06692817 0.01709943
 0.04067358 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.03881946 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03626943 0.03889033
 0.04248705 0.04307365 0.001      0.05103627 0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.02366392 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.03629032 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.02870019 0.03629032 0.001      0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.03677436 0.03826169
 0.03828769 0.001      0.04094656 0.001      0.001      0.001
 0.001      0.04307365 0.03989637 0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.04015544 0.03707545 0.04255319 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.0401489
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.0420101  0.03892821 0.03747628 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.05763757 0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.0323089  0.001      0.001      0.01940794 0.03202087
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.0394011
 0.04307854 0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.04307365
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.03605313
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.03989637 0.001      0.001
 0.001      0.03810651 0.001      0.02977931 0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.04227599 0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03866224 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.04018913
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.04229052 0.01937935 0.03723909 0.0373057  0.03241574 0.03778932
 0.001      0.001      0.0401489  0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0373057  0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.04307854 0.03431953 0.04196891 0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.0404518  0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03963731
 0.001      0.02800639 0.001      0.04170984 0.04255319 0.03887576
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.04121244
 0.03937824 0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.03723909 0.03987651 0.01937935 0.07340324
 0.001      0.04222798 0.001      0.04096448 0.001      0.04307854
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.04121244 0.001      0.001      0.001
 0.03911917 0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03546099 0.04248705
 0.03665319 0.001      0.001      0.02227617 0.001      0.02574205
 0.001      0.03012994 0.001      0.001      0.03629032 0.04076739
 0.03613604 0.03549223 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.03551983 0.001
 0.001      0.03304023 0.001      0.03889943 0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.04170984
 0.04255319 0.001      0.04255319 0.001      0.04071447 0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][17:17:59]: [Server #615782] Global model accuracy: 59.88%

[INFO][17:17:59]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_19.pth.
[INFO][17:17:59]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_19.pth.
[INFO][17:17:59]: [93m[1m
[Server #615782] Starting round 20/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  8e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  7e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  7e-05  4e-09  6e-10
 8:  7.5999e+00  7.5998e+00  5e-05  4e-09  6e-10
 9:  7.5999e+00  7.5998e+00  3e-05  8e-09  1e-09
10:  7.5998e+00  7.5998e+00  6e-06  2e-08  3e-09
Optimal solution found.
The calculated probability is:  [1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02740300e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02710446e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02704452e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02647672e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02659189e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02739497e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02737690e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02739830e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02749880e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02736837e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02721953e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02733543e-04 1.02750733e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02739009e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02217778e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02745470e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 8.97447317e-01 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02653548e-04
 1.02748201e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02716521e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02736193e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02750119e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02743276e-04 1.02759546e-04 1.02716140e-04
 1.02759546e-04 1.02746944e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04 1.02759546e-04
 1.02759546e-04 1.02759546e-04 1.02759546e-04][INFO][17:18:02]: [Server #615782] Selected clients: [856 604 320 681  52 135 130 655 176 342  45 235 965 510 151 523 944 866
 393 285 762 242 255  84 865]
[INFO][17:18:02]: [Server #615782] Selecting client #856 for training.
[INFO][17:18:02]: [Server #615782] Sending the current model to client #856 (simulated).
[INFO][17:18:02]: [Server #615782] Sending 0.26 MB of payload data to client #856 (simulated).
[INFO][17:18:02]: [Server #615782] Selecting client #604 for training.
[INFO][17:18:02]: [Server #615782] Sending the current model to client #604 (simulated).
[INFO][17:18:02]: [Server #615782] Sending 0.26 MB of payload data to client #604 (simulated).
[INFO][17:18:02]: [Client #856] Selected by the server.
[INFO][17:18:02]: [Client #856] Loading its data source...
[INFO][17:18:02]: Data source: FEMNIST
[INFO][17:18:02]: [Client #604] Selected by the server.
[INFO][17:18:02]: [Client #604] Loading its data source...
[INFO][17:18:02]: Data source: FEMNIST
[INFO][17:18:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:18:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/604.zip.
[INFO][17:18:02]: [Client #856] Dataset size: 154
[INFO][17:18:02]: [Client #856] Sampler: all_inclusive
[INFO][17:18:02]: [Client #856] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:18:02]: [93m[1m[Client #856] Started training in communication round #20.[0m
3.5%6.9%10.4%13.8%17.3%20.8%24.2%27.7%31.2%34.6%38.1%41.5%45.0%48.5%51.9%55.4%58.8%62.3%65.8%69.2%72.7%76.2%79.6%83.1%86.5%90.0%93.5%96.9%100.0%[INFO][17:18:02]: Decompressing the dataset downloaded.
[INFO][17:18:02]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/604.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:18:02]: [Client #604] Dataset size: 137
[INFO][17:18:02]: [Client #604] Sampler: all_inclusive
[INFO][17:18:02]: [Client #604] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:18:02]: [93m[1m[Client #604] Started training in communication round #20.[0m

[INFO][17:18:04]: [Client #856] Loading the dataset.
[INFO][17:18:04]: [Client #604] Loading the dataset.
[INFO][17:18:09]: [Client #856] Epoch: [1/5][0/16]	Loss: 1.655090
[INFO][17:18:09]: [Client #856] Epoch: [1/5][10/16]	Loss: 1.989142
[INFO][17:18:09]: [Client #604] Epoch: [1/5][0/14]	Loss: 0.645366
[INFO][17:18:09]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][17:18:10]: [Client #604] Epoch: [1/5][10/14]	Loss: 0.650116
[INFO][17:18:10]: [Client #604] Going to sleep for 0.30 seconds.
[INFO][17:18:10]: [Client #604] Woke up.
[INFO][17:18:10]: [Client #604] Epoch: [2/5][0/14]	Loss: 0.541084
[INFO][17:18:10]: [Client #604] Epoch: [2/5][10/14]	Loss: 0.626796
[INFO][17:18:10]: [Client #604] Going to sleep for 0.30 seconds.
[INFO][17:18:10]: [Client #604] Woke up.
[INFO][17:18:10]: [Client #604] Epoch: [3/5][0/14]	Loss: 0.801350
[INFO][17:18:10]: [Client #604] Epoch: [3/5][10/14]	Loss: 1.368813
[INFO][17:18:10]: [Client #604] Going to sleep for 0.30 seconds.
[INFO][17:18:11]: [Client #604] Woke up.
[INFO][17:18:11]: [Client #604] Epoch: [4/5][0/14]	Loss: 0.384548
[INFO][17:18:11]: [Client #604] Epoch: [4/5][10/14]	Loss: 0.703377
[INFO][17:18:11]: [Client #604] Going to sleep for 0.30 seconds.
[INFO][17:18:11]: [Client #604] Woke up.
[INFO][17:18:11]: [Client #604] Epoch: [5/5][0/14]	Loss: 0.651885
[INFO][17:18:11]: [Client #604] Epoch: [5/5][10/14]	Loss: 0.222452
[INFO][17:18:11]: [Client #604] Going to sleep for 0.30 seconds.
[INFO][17:18:12]: [Client #604] Woke up.
[INFO][17:18:12]: [Client #604] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_604_615875.pth.
[INFO][17:18:12]: [Client #604] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_604_615875.pth.
[INFO][17:18:12]: [Client #604] Model trained.
[INFO][17:18:12]: [Client #604] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:18:12]: [Server #615782] Received 0.26 MB of payload data from client #604 (simulated).
[INFO][17:19:10]: [Client #856] Woke up.
[INFO][17:19:10]: [Client #856] Epoch: [2/5][0/16]	Loss: 0.862924
[INFO][17:19:10]: [Client #856] Epoch: [2/5][10/16]	Loss: 0.782888
[INFO][17:19:10]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][17:20:10]: [Client #856] Woke up.
[INFO][17:20:10]: [Client #856] Epoch: [3/5][0/16]	Loss: 0.893802
[INFO][17:20:10]: [Client #856] Epoch: [3/5][10/16]	Loss: 0.522414
[INFO][17:20:10]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][17:21:10]: [Client #856] Woke up.
[INFO][17:21:10]: [Client #856] Epoch: [4/5][0/16]	Loss: 0.294836
[INFO][17:21:10]: [Client #856] Epoch: [4/5][10/16]	Loss: 0.697880
[INFO][17:21:10]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][17:22:11]: [Client #856] Woke up.
[INFO][17:22:11]: [Client #856] Epoch: [5/5][0/16]	Loss: 0.628856
[INFO][17:22:11]: [Client #856] Epoch: [5/5][10/16]	Loss: 0.592537
[INFO][17:22:11]: [Client #856] Going to sleep for 60.00 seconds.
[INFO][17:23:11]: [Client #856] Woke up.
[INFO][17:23:11]: [Client #856] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][17:23:12]: [Client #856] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_856_615874.pth.
[INFO][17:23:12]: [Client #856] Model trained.
[INFO][17:23:12]: [Client #856] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:23:12]: [Server #615782] Received 0.26 MB of payload data from client #856 (simulated).
[INFO][17:23:12]: [Server #615782] Selecting client #320 for training.
[INFO][17:23:12]: [Server #615782] Sending the current model to client #320 (simulated).
[INFO][17:23:12]: [Server #615782] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][17:23:12]: [Server #615782] Selecting client #681 for training.
[INFO][17:23:12]: [Server #615782] Sending the current model to client #681 (simulated).
[INFO][17:23:12]: [Server #615782] Sending 0.26 MB of payload data to client #681 (simulated).
[INFO][17:23:12]: [Client #320] Selected by the server.
[INFO][17:23:12]: [Client #320] Loading its data source...
[INFO][17:23:12]: Data source: FEMNIST
[INFO][17:23:12]: [Client #681] Selected by the server.
[INFO][17:23:12]: [Client #681] Loading its data source...
[INFO][17:23:12]: Data source: FEMNIST
[INFO][17:23:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:23:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/681.zip.
[INFO][17:23:12]: [Client #320] Dataset size: 153
[INFO][17:23:12]: [Client #320] Sampler: all_inclusive
[INFO][17:23:12]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:23:12]: [93m[1m[Client #320] Started training in communication round #20.[0m
2.3%4.6%6.9%9.3%11.6%13.9%16.2%18.5%20.8%23.2%25.5%27.8%30.1%32.4%34.7%37.1%39.4%41.7%44.0%46.3%48.6%51.0%53.3%55.6%57.9%60.2%62.5%64.9%67.2%69.5%71.8%74.1%76.4%78.8%81.1%83.4%85.7%88.0%90.3%92.7%95.0%97.3%99.6%100.0%[INFO][17:23:12]: Decompressing the dataset downloaded.
[INFO][17:23:12]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/681.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:23:12]: [Client #681] Dataset size: 147
[INFO][17:23:12]: [Client #681] Sampler: all_inclusive
[INFO][17:23:12]: [Client #681] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:23:12]: [93m[1m[Client #681] Started training in communication round #20.[0m

[INFO][17:23:14]: [Client #320] Loading the dataset.
[INFO][17:23:14]: [Client #681] Loading the dataset.
[INFO][17:23:19]: [Client #320] Epoch: [1/5][0/16]	Loss: 0.616620
[INFO][17:23:19]: [Client #681] Epoch: [1/5][0/15]	Loss: 1.166191
[INFO][17:23:19]: [Client #320] Epoch: [1/5][10/16]	Loss: 0.543331
[INFO][17:23:19]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][17:23:19]: [Client #681] Epoch: [1/5][10/15]	Loss: 1.093098
[INFO][17:23:20]: [Client #681] Going to sleep for 2.69 seconds.
[INFO][17:23:22]: [Client #681] Woke up.
[INFO][17:23:22]: [Client #681] Epoch: [2/5][0/15]	Loss: 0.351829
[INFO][17:23:22]: [Client #681] Epoch: [2/5][10/15]	Loss: 1.238999
[INFO][17:23:22]: [Client #681] Going to sleep for 2.69 seconds.
[INFO][17:23:25]: [Client #681] Woke up.
[INFO][17:23:25]: [Client #681] Epoch: [3/5][0/15]	Loss: 0.458721
[INFO][17:23:25]: [Client #681] Epoch: [3/5][10/15]	Loss: 0.904016
[INFO][17:23:25]: [Client #681] Going to sleep for 2.69 seconds.
[INFO][17:23:25]: [Client #320] Woke up.
[INFO][17:23:25]: [Client #320] Epoch: [2/5][0/16]	Loss: 0.555455
[INFO][17:23:25]: [Client #320] Epoch: [2/5][10/16]	Loss: 1.386388
[INFO][17:23:25]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][17:23:28]: [Client #681] Woke up.
[INFO][17:23:28]: [Client #681] Epoch: [4/5][0/15]	Loss: 0.349933
[INFO][17:23:28]: [Client #681] Epoch: [4/5][10/15]	Loss: 0.510447
[INFO][17:23:28]: [Client #681] Going to sleep for 2.69 seconds.
[INFO][17:23:31]: [Client #681] Woke up.
[INFO][17:23:31]: [Client #681] Epoch: [5/5][0/15]	Loss: 0.585011
[INFO][17:23:31]: [Client #681] Epoch: [5/5][10/15]	Loss: 0.660584
[INFO][17:23:31]: [Client #681] Going to sleep for 2.69 seconds.
[INFO][17:23:31]: [Client #320] Woke up.
[INFO][17:23:31]: [Client #320] Epoch: [3/5][0/16]	Loss: 0.706124
[INFO][17:23:31]: [Client #320] Epoch: [3/5][10/16]	Loss: 1.942844
[INFO][17:23:31]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][17:23:34]: [Client #681] Woke up.
[INFO][17:23:34]: [Client #681] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_681_615875.pth.
[INFO][17:23:34]: [Client #681] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_681_615875.pth.
[INFO][17:23:34]: [Client #681] Model trained.
[INFO][17:23:34]: [Client #681] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:23:34]: [Server #615782] Received 0.26 MB of payload data from client #681 (simulated).
[INFO][17:23:37]: [Client #320] Woke up.
[INFO][17:23:37]: [Client #320] Epoch: [4/5][0/16]	Loss: 0.948715
[INFO][17:23:37]: [Client #320] Epoch: [4/5][10/16]	Loss: 0.439703
[INFO][17:23:37]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][17:23:43]: [Client #320] Woke up.
[INFO][17:23:43]: [Client #320] Epoch: [5/5][0/16]	Loss: 1.347330
[INFO][17:23:43]: [Client #320] Epoch: [5/5][10/16]	Loss: 1.391322
[INFO][17:23:43]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][17:23:49]: [Client #320] Woke up.
[INFO][17:23:49]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_615874.pth.
[INFO][17:23:49]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_615874.pth.
[INFO][17:23:49]: [Client #320] Model trained.
[INFO][17:23:49]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:23:49]: [Server #615782] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][17:23:49]: [Server #615782] Selecting client #52 for training.
[INFO][17:23:49]: [Server #615782] Sending the current model to client #52 (simulated).
[INFO][17:23:49]: [Server #615782] Sending 0.26 MB of payload data to client #52 (simulated).
[INFO][17:23:49]: [Server #615782] Selecting client #135 for training.
[INFO][17:23:49]: [Server #615782] Sending the current model to client #135 (simulated).
[INFO][17:23:49]: [Server #615782] Sending 0.26 MB of payload data to client #135 (simulated).
[INFO][17:23:49]: [Client #52] Selected by the server.
[INFO][17:23:49]: [Client #52] Loading its data source...
[INFO][17:23:49]: Data source: FEMNIST
[INFO][17:23:49]: [Client #135] Selected by the server.
[INFO][17:23:49]: [Client #135] Loading its data source...
[INFO][17:23:49]: Data source: FEMNIST
[INFO][17:23:49]: [Client #135] Dataset size: 151
[INFO][17:23:49]: [Client #135] Sampler: all_inclusive
[INFO][17:23:49]: [Client #52] Dataset size: 162
[INFO][17:23:49]: [Client #52] Sampler: all_inclusive
[INFO][17:23:49]: [Client #135] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:23:49]: [Client #52] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:23:49]: [93m[1m[Client #135] Started training in communication round #20.[0m
[INFO][17:23:50]: [93m[1m[Client #52] Started training in communication round #20.[0m
[INFO][17:23:51]: [Client #52] Loading the dataset.
[INFO][17:23:51]: [Client #135] Loading the dataset.
[INFO][17:23:57]: [Client #52] Epoch: [1/5][0/17]	Loss: 0.673557
[INFO][17:23:57]: [Client #135] Epoch: [1/5][0/16]	Loss: 1.593071
[INFO][17:23:57]: [Client #52] Epoch: [1/5][10/17]	Loss: 2.082695
[INFO][17:23:57]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][17:23:57]: [Client #135] Epoch: [1/5][10/16]	Loss: 2.174426
[INFO][17:23:57]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][17:23:59]: [Client #52] Woke up.
[INFO][17:23:59]: [Client #52] Epoch: [2/5][0/17]	Loss: 1.388474
[INFO][17:23:59]: [Client #52] Epoch: [2/5][10/17]	Loss: 1.048591
[INFO][17:23:59]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][17:24:01]: [Client #135] Woke up.
[INFO][17:24:01]: [Client #135] Epoch: [2/5][0/16]	Loss: 0.874666
[INFO][17:24:01]: [Client #135] Epoch: [2/5][10/16]	Loss: 1.481133
[INFO][17:24:01]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][17:24:02]: [Client #52] Woke up.
[INFO][17:24:02]: [Client #52] Epoch: [3/5][0/17]	Loss: 0.806317
[INFO][17:24:02]: [Client #52] Epoch: [3/5][10/17]	Loss: 1.704943
[INFO][17:24:02]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][17:24:04]: [Client #52] Woke up.
[INFO][17:24:04]: [Client #52] Epoch: [4/5][0/17]	Loss: 0.762569
[INFO][17:24:04]: [Client #52] Epoch: [4/5][10/17]	Loss: 1.174229
[INFO][17:24:04]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][17:24:05]: [Client #135] Woke up.
[INFO][17:24:05]: [Client #135] Epoch: [3/5][0/16]	Loss: 1.917151
[INFO][17:24:05]: [Client #135] Epoch: [3/5][10/16]	Loss: 1.820840
[INFO][17:24:06]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][17:24:06]: [Client #52] Woke up.
[INFO][17:24:06]: [Client #52] Epoch: [5/5][0/17]	Loss: 1.562981
[INFO][17:24:06]: [Client #52] Epoch: [5/5][10/17]	Loss: 0.626575
[INFO][17:24:06]: [Client #52] Going to sleep for 2.11 seconds.
[INFO][17:24:08]: [Client #52] Woke up.
[INFO][17:24:08]: [Client #52] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_52_615874.pth.
[INFO][17:24:09]: [Client #52] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_52_615874.pth.
[INFO][17:24:09]: [Client #52] Model trained.
[INFO][17:24:09]: [Client #52] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:24:09]: [Server #615782] Received 0.26 MB of payload data from client #52 (simulated).
[INFO][17:24:10]: [Client #135] Woke up.
[INFO][17:24:10]: [Client #135] Epoch: [4/5][0/16]	Loss: 0.892762
[INFO][17:24:10]: [Client #135] Epoch: [4/5][10/16]	Loss: 1.100348
[INFO][17:24:10]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][17:24:14]: [Client #135] Woke up.
[INFO][17:24:14]: [Client #135] Epoch: [5/5][0/16]	Loss: 1.158097
[INFO][17:24:14]: [Client #135] Epoch: [5/5][10/16]	Loss: 0.935098
[INFO][17:24:14]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][17:24:18]: [Client #135] Woke up.
[INFO][17:24:18]: [Client #135] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_615875.pth.
[INFO][17:24:19]: [Client #135] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_615875.pth.
[INFO][17:24:19]: [Client #135] Model trained.
[INFO][17:24:19]: [Client #135] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:24:19]: [Server #615782] Received 0.26 MB of payload data from client #135 (simulated).
[INFO][17:24:19]: [Server #615782] Selecting client #130 for training.
[INFO][17:24:19]: [Server #615782] Sending the current model to client #130 (simulated).
[INFO][17:24:19]: [Server #615782] Sending 0.26 MB of payload data to client #130 (simulated).
[INFO][17:24:19]: [Server #615782] Selecting client #655 for training.
[INFO][17:24:19]: [Server #615782] Sending the current model to client #655 (simulated).
[INFO][17:24:19]: [Server #615782] Sending 0.26 MB of payload data to client #655 (simulated).
[INFO][17:24:19]: [Client #655] Selected by the server.
[INFO][17:24:19]: [Client #655] Loading its data source...
[INFO][17:24:19]: Data source: FEMNIST
[INFO][17:24:19]: [Client #130] Selected by the server.
[INFO][17:24:19]: [Client #130] Loading its data source...
[INFO][17:24:19]: Data source: FEMNIST
[INFO][17:24:19]: [Client #130] Dataset size: 159
[INFO][17:24:19]: [Client #130] Sampler: all_inclusive
[INFO][17:24:19]: [Client #655] Dataset size: 216
[INFO][17:24:19]: [Client #655] Sampler: all_inclusive
[INFO][17:24:19]: [Client #130] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:24:19]: [Client #655] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:24:19]: [93m[1m[Client #130] Started training in communication round #20.[0m
[INFO][17:24:19]: [93m[1m[Client #655] Started training in communication round #20.[0m
[INFO][17:24:21]: [Client #655] Loading the dataset.
[INFO][17:24:21]: [Client #130] Loading the dataset.
[INFO][17:24:26]: [Client #655] Epoch: [1/5][0/22]	Loss: 1.530997
[INFO][17:24:26]: [Client #655] Epoch: [1/5][10/22]	Loss: 1.374569
[INFO][17:24:26]: [Client #130] Epoch: [1/5][0/16]	Loss: 0.942765
[INFO][17:24:27]: [Client #655] Epoch: [1/5][20/22]	Loss: 2.728149
[INFO][17:24:27]: [Client #655] Going to sleep for 60.00 seconds.
[INFO][17:24:27]: [Client #130] Epoch: [1/5][10/16]	Loss: 0.422677
[INFO][17:24:27]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][17:24:27]: [Client #130] Woke up.
[INFO][17:24:27]: [Client #130] Epoch: [2/5][0/16]	Loss: 1.341868
[INFO][17:24:27]: [Client #130] Epoch: [2/5][10/16]	Loss: 0.998152
[INFO][17:24:27]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][17:24:28]: [Client #130] Woke up.
[INFO][17:24:28]: [Client #130] Epoch: [3/5][0/16]	Loss: 0.383750
[INFO][17:24:28]: [Client #130] Epoch: [3/5][10/16]	Loss: 0.168455
[INFO][17:24:28]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][17:24:28]: [Client #130] Woke up.
[INFO][17:24:28]: [Client #130] Epoch: [4/5][0/16]	Loss: 0.864446
[INFO][17:24:28]: [Client #130] Epoch: [4/5][10/16]	Loss: 0.468902
[INFO][17:24:28]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][17:24:29]: [Client #130] Woke up.
[INFO][17:24:29]: [Client #130] Epoch: [5/5][0/16]	Loss: 0.543831
[INFO][17:24:29]: [Client #130] Epoch: [5/5][10/16]	Loss: 0.429978
[INFO][17:24:29]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][17:24:29]: [Client #130] Woke up.
[INFO][17:24:29]: [Client #130] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_130_615874.pth.
[INFO][17:24:30]: [Client #130] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_130_615874.pth.
[INFO][17:24:30]: [Client #130] Model trained.
[INFO][17:24:30]: [Client #130] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:24:30]: [Server #615782] Received 0.26 MB of payload data from client #130 (simulated).
[INFO][17:25:27]: [Client #655] Woke up.
[INFO][17:25:27]: [Client #655] Epoch: [2/5][0/22]	Loss: 1.421645
[INFO][17:25:27]: [Client #655] Epoch: [2/5][10/22]	Loss: 1.797027
[INFO][17:25:27]: [Client #655] Epoch: [2/5][20/22]	Loss: 1.001905
[INFO][17:25:27]: [Client #655] Going to sleep for 60.00 seconds.
[INFO][17:26:27]: [Client #655] Woke up.
[INFO][17:26:27]: [Client #655] Epoch: [3/5][0/22]	Loss: 1.288465
[INFO][17:26:27]: [Client #655] Epoch: [3/5][10/22]	Loss: 0.902519
[INFO][17:26:27]: [Client #655] Epoch: [3/5][20/22]	Loss: 0.986346
[INFO][17:26:27]: [Client #655] Going to sleep for 60.00 seconds.
[INFO][17:27:27]: [Client #655] Woke up.
[INFO][17:27:27]: [Client #655] Epoch: [4/5][0/22]	Loss: 1.445490
[INFO][17:27:28]: [Client #655] Epoch: [4/5][10/22]	Loss: 1.071039
[INFO][17:27:28]: [Client #655] Epoch: [4/5][20/22]	Loss: 1.285116
[INFO][17:27:28]: [Client #655] Going to sleep for 60.00 seconds.
[INFO][17:28:28]: [Client #655] Woke up.
[INFO][17:28:28]: [Client #655] Epoch: [5/5][0/22]	Loss: 1.230926
[INFO][17:28:28]: [Client #655] Epoch: [5/5][10/22]	Loss: 0.685877
[INFO][17:28:28]: [Client #655] Epoch: [5/5][20/22]	Loss: 0.910306
[INFO][17:28:28]: [Client #655] Going to sleep for 60.00 seconds.
[INFO][17:29:28]: [Client #655] Woke up.
[INFO][17:29:28]: [Client #655] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_655_615875.pth.
[INFO][17:29:29]: [Client #655] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_655_615875.pth.
[INFO][17:29:29]: [Client #655] Model trained.
[INFO][17:29:29]: [Client #655] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:29:29]: [Server #615782] Received 0.26 MB of payload data from client #655 (simulated).
[INFO][17:29:29]: [Server #615782] Selecting client #176 for training.
[INFO][17:29:29]: [Server #615782] Sending the current model to client #176 (simulated).
[INFO][17:29:29]: [Server #615782] Sending 0.26 MB of payload data to client #176 (simulated).
[INFO][17:29:29]: [Server #615782] Selecting client #342 for training.
[INFO][17:29:29]: [Server #615782] Sending the current model to client #342 (simulated).
[INFO][17:29:29]: [Server #615782] Sending 0.26 MB of payload data to client #342 (simulated).
[INFO][17:29:29]: [Client #176] Selected by the server.
[INFO][17:29:29]: [Client #176] Loading its data source...
[INFO][17:29:29]: Data source: FEMNIST
[INFO][17:29:29]: [Client #342] Selected by the server.
[INFO][17:29:29]: [Client #342] Loading its data source...
[INFO][17:29:29]: Data source: FEMNIST
[INFO][17:29:29]: [Client #176] Dataset size: 148
[INFO][17:29:29]: [Client #176] Sampler: all_inclusive
[INFO][17:29:29]: [Client #342] Dataset size: 163
[INFO][17:29:29]: [Client #342] Sampler: all_inclusive
[INFO][17:29:29]: [Client #176] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:29:29]: [Client #342] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:29:29]: [93m[1m[Client #176] Started training in communication round #20.[0m
[INFO][17:29:29]: [93m[1m[Client #342] Started training in communication round #20.[0m
[INFO][17:29:31]: [Client #176] Loading the dataset.
[INFO][17:29:31]: [Client #342] Loading the dataset.
[INFO][17:29:37]: [Client #176] Epoch: [1/5][0/15]	Loss: 0.975466
[INFO][17:29:37]: [Client #342] Epoch: [1/5][0/17]	Loss: 1.110449
[INFO][17:29:37]: [Client #176] Epoch: [1/5][10/15]	Loss: 0.422503
[INFO][17:29:37]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][17:29:37]: [Client #342] Epoch: [1/5][10/17]	Loss: 0.486815
[INFO][17:29:37]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][17:29:40]: [Client #176] Woke up.
[INFO][17:29:40]: [Client #176] Epoch: [2/5][0/15]	Loss: 0.460238
[INFO][17:29:40]: [Client #176] Epoch: [2/5][10/15]	Loss: 0.716158
[INFO][17:29:40]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][17:29:43]: [Client #176] Woke up.
[INFO][17:29:43]: [Client #176] Epoch: [3/5][0/15]	Loss: 0.521068
[INFO][17:29:43]: [Client #176] Epoch: [3/5][10/15]	Loss: 1.348396
[INFO][17:29:43]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][17:29:46]: [Client #176] Woke up.
[INFO][17:29:46]: [Client #176] Epoch: [4/5][0/15]	Loss: 1.287574
[INFO][17:29:46]: [Client #176] Epoch: [4/5][10/15]	Loss: 1.258791
[INFO][17:29:46]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][17:29:49]: [Client #176] Woke up.
[INFO][17:29:49]: [Client #176] Epoch: [5/5][0/15]	Loss: 0.357817
[INFO][17:29:49]: [Client #176] Epoch: [5/5][10/15]	Loss: 0.232085
[INFO][17:29:49]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][17:29:52]: [Client #176] Woke up.
[INFO][17:29:52]: [Client #176] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_615874.pth.
[INFO][17:29:53]: [Client #176] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_615874.pth.
[INFO][17:29:53]: [Client #176] Model trained.
[INFO][17:29:53]: [Client #176] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:29:53]: [Server #615782] Received 0.26 MB of payload data from client #176 (simulated).
[INFO][17:29:56]: [Client #342] Woke up.
[INFO][17:29:56]: [Client #342] Epoch: [2/5][0/17]	Loss: 1.298494
[INFO][17:29:56]: [Client #342] Epoch: [2/5][10/17]	Loss: 1.221576
[INFO][17:29:56]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][17:30:15]: [Client #342] Woke up.
[INFO][17:30:15]: [Client #342] Epoch: [3/5][0/17]	Loss: 1.499612
[INFO][17:30:15]: [Client #342] Epoch: [3/5][10/17]	Loss: 1.424084
[INFO][17:30:16]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][17:30:34]: [Client #342] Woke up.
[INFO][17:30:35]: [Client #342] Epoch: [4/5][0/17]	Loss: 0.992193
[INFO][17:30:35]: [Client #342] Epoch: [4/5][10/17]	Loss: 1.014474
[INFO][17:30:35]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][17:30:54]: [Client #342] Woke up.
[INFO][17:30:54]: [Client #342] Epoch: [5/5][0/17]	Loss: 1.409252
[INFO][17:30:54]: [Client #342] Epoch: [5/5][10/17]	Loss: 0.580612
[INFO][17:30:54]: [Client #342] Going to sleep for 18.92 seconds.
[INFO][17:31:13]: [Client #342] Woke up.
[INFO][17:31:13]: [Client #342] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615875.pth.
[INFO][17:31:14]: [Client #342] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_342_615875.pth.
[INFO][17:31:14]: [Client #342] Model trained.
[INFO][17:31:14]: [Client #342] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:14]: [Server #615782] Received 0.26 MB of payload data from client #342 (simulated).
[INFO][17:31:14]: [Server #615782] Selecting client #45 for training.
[INFO][17:31:14]: [Server #615782] Sending the current model to client #45 (simulated).
[INFO][17:31:14]: [Server #615782] Sending 0.26 MB of payload data to client #45 (simulated).
[INFO][17:31:14]: [Server #615782] Selecting client #235 for training.
[INFO][17:31:14]: [Server #615782] Sending the current model to client #235 (simulated).
[INFO][17:31:14]: [Server #615782] Sending 0.26 MB of payload data to client #235 (simulated).
[INFO][17:31:14]: [Client #235] Selected by the server.
[INFO][17:31:14]: [Client #45] Selected by the server.
[INFO][17:31:14]: [Client #235] Loading its data source...
[INFO][17:31:14]: [Client #45] Loading its data source...
[INFO][17:31:14]: Data source: FEMNIST
[INFO][17:31:14]: Data source: FEMNIST
[INFO][17:31:14]: [Client #235] Dataset size: 140
[INFO][17:31:14]: [Client #235] Sampler: all_inclusive
[INFO][17:31:14]: [Client #235] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:14]: [93m[1m[Client #235] Started training in communication round #20.[0m
[INFO][17:31:14]: [Client #45] Dataset size: 192
[INFO][17:31:14]: [Client #45] Sampler: all_inclusive
[INFO][17:31:14]: [Client #45] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:14]: [93m[1m[Client #45] Started training in communication round #20.[0m
[INFO][17:31:16]: [Client #235] Loading the dataset.
[INFO][17:31:16]: [Client #45] Loading the dataset.
[INFO][17:31:22]: [Client #45] Epoch: [1/5][0/20]	Loss: 1.123503
[INFO][17:31:22]: [Client #235] Epoch: [1/5][0/14]	Loss: 1.420946
[INFO][17:31:22]: [Client #45] Epoch: [1/5][10/20]	Loss: 1.150439
[INFO][17:31:22]: [Client #235] Epoch: [1/5][10/14]	Loss: 3.049978
[INFO][17:31:22]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][17:31:22]: [Client #45] Going to sleep for 0.12 seconds.
[INFO][17:31:22]: [Client #45] Woke up.
[INFO][17:31:22]: [Client #45] Epoch: [2/5][0/20]	Loss: 0.873272
[INFO][17:31:22]: [Client #45] Epoch: [2/5][10/20]	Loss: 1.632556
[INFO][17:31:22]: [Client #45] Going to sleep for 0.12 seconds.
[INFO][17:31:22]: [Client #45] Woke up.
[INFO][17:31:23]: [Client #45] Epoch: [3/5][0/20]	Loss: 1.371393
[INFO][17:31:23]: [Client #45] Epoch: [3/5][10/20]	Loss: 0.938086
[INFO][17:31:23]: [Client #45] Going to sleep for 0.12 seconds.
[INFO][17:31:23]: [Client #45] Woke up.
[INFO][17:31:23]: [Client #45] Epoch: [4/5][0/20]	Loss: 1.952333
[INFO][17:31:23]: [Client #45] Epoch: [4/5][10/20]	Loss: 0.975512
[INFO][17:31:23]: [Client #45] Going to sleep for 0.12 seconds.
[INFO][17:31:23]: [Client #235] Woke up.
[INFO][17:31:23]: [Client #235] Epoch: [2/5][0/14]	Loss: 1.167078
[INFO][17:31:23]: [Client #45] Woke up.
[INFO][17:31:23]: [Client #45] Epoch: [5/5][0/20]	Loss: 1.159627
[INFO][17:31:23]: [Client #235] Epoch: [2/5][10/14]	Loss: 1.201935
[INFO][17:31:23]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][17:31:23]: [Client #45] Epoch: [5/5][10/20]	Loss: 0.961065
[INFO][17:31:23]: [Client #45] Going to sleep for 0.12 seconds.
[INFO][17:31:23]: [Client #45] Woke up.
[INFO][17:31:23]: [Client #45] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_45_615874.pth.
[INFO][17:31:24]: [Client #45] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_45_615874.pth.
[INFO][17:31:24]: [Client #45] Model trained.
[INFO][17:31:24]: [Client #45] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:24]: [Server #615782] Received 0.26 MB of payload data from client #45 (simulated).
[INFO][17:31:24]: [Client #235] Woke up.
[INFO][17:31:24]: [Client #235] Epoch: [3/5][0/14]	Loss: 0.673752
[INFO][17:31:24]: [Client #235] Epoch: [3/5][10/14]	Loss: 2.192786
[INFO][17:31:24]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][17:31:25]: [Client #235] Woke up.
[INFO][17:31:25]: [Client #235] Epoch: [4/5][0/14]	Loss: 1.119933
[INFO][17:31:25]: [Client #235] Epoch: [4/5][10/14]	Loss: 1.105578
[INFO][17:31:25]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][17:31:26]: [Client #235] Woke up.
[INFO][17:31:26]: [Client #235] Epoch: [5/5][0/14]	Loss: 0.662677
[INFO][17:31:26]: [Client #235] Epoch: [5/5][10/14]	Loss: 1.613258
[INFO][17:31:26]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][17:31:27]: [Client #235] Woke up.
[INFO][17:31:27]: [Client #235] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_615875.pth.
[INFO][17:31:28]: [Client #235] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_615875.pth.
[INFO][17:31:28]: [Client #235] Model trained.
[INFO][17:31:28]: [Client #235] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:28]: [Server #615782] Received 0.26 MB of payload data from client #235 (simulated).
[INFO][17:31:28]: [Server #615782] Selecting client #965 for training.
[INFO][17:31:28]: [Server #615782] Sending the current model to client #965 (simulated).
[INFO][17:31:28]: [Server #615782] Sending 0.26 MB of payload data to client #965 (simulated).
[INFO][17:31:28]: [Server #615782] Selecting client #510 for training.
[INFO][17:31:28]: [Server #615782] Sending the current model to client #510 (simulated).
[INFO][17:31:28]: [Server #615782] Sending 0.26 MB of payload data to client #510 (simulated).
[INFO][17:31:28]: [Client #510] Selected by the server.
[INFO][17:31:28]: [Client #965] Selected by the server.
[INFO][17:31:28]: [Client #510] Loading its data source...
[INFO][17:31:28]: [Client #965] Loading its data source...
[INFO][17:31:28]: Data source: FEMNIST
[INFO][17:31:28]: Data source: FEMNIST
[INFO][17:31:28]: [Client #965] Dataset size: 137
[INFO][17:31:28]: [Client #965] Sampler: all_inclusive
[INFO][17:31:28]: [Client #510] Dataset size: 161
[INFO][17:31:28]: [Client #510] Sampler: all_inclusive
[INFO][17:31:28]: [Client #965] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:28]: [Client #510] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:28]: [93m[1m[Client #965] Started training in communication round #20.[0m
[INFO][17:31:28]: [93m[1m[Client #510] Started training in communication round #20.[0m
[INFO][17:31:30]: [Client #965] Loading the dataset.
[INFO][17:31:30]: [Client #510] Loading the dataset.
[INFO][17:31:36]: [Client #965] Epoch: [1/5][0/14]	Loss: 2.192512
[INFO][17:31:36]: [Client #510] Epoch: [1/5][0/17]	Loss: 1.128621
[INFO][17:31:36]: [Client #965] Epoch: [1/5][10/14]	Loss: 0.660892
[INFO][17:31:36]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][17:31:36]: [Client #510] Epoch: [1/5][10/17]	Loss: 1.642952
[INFO][17:31:36]: [Client #965] Woke up.
[INFO][17:31:36]: [Client #510] Going to sleep for 0.32 seconds.
[INFO][17:31:36]: [Client #965] Epoch: [2/5][0/14]	Loss: 0.300162
[INFO][17:31:36]: [Client #965] Epoch: [2/5][10/14]	Loss: 1.153951
[INFO][17:31:36]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][17:31:36]: [Client #965] Woke up.
[INFO][17:31:36]: [Client #965] Epoch: [3/5][0/14]	Loss: 1.740357
[INFO][17:31:36]: [Client #965] Epoch: [3/5][10/14]	Loss: 1.351230
[INFO][17:31:36]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][17:31:36]: [Client #510] Woke up.
[INFO][17:31:36]: [Client #965] Woke up.
[INFO][17:31:36]: [Client #510] Epoch: [2/5][0/17]	Loss: 0.638430
[INFO][17:31:36]: [Client #965] Epoch: [4/5][0/14]	Loss: 1.142739
[INFO][17:31:36]: [Client #510] Epoch: [2/5][10/17]	Loss: 2.221654
[INFO][17:31:36]: [Client #965] Epoch: [4/5][10/14]	Loss: 1.051435
[INFO][17:31:36]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][17:31:36]: [Client #510] Going to sleep for 0.32 seconds.
[INFO][17:31:36]: [Client #965] Woke up.
[INFO][17:31:36]: [Client #965] Epoch: [5/5][0/14]	Loss: 0.920724
[INFO][17:31:37]: [Client #965] Epoch: [5/5][10/14]	Loss: 0.375616
[INFO][17:31:37]: [Client #965] Going to sleep for 0.04 seconds.
[INFO][17:31:37]: [Client #965] Woke up.
[INFO][17:31:37]: [Client #965] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615874.pth.
[INFO][17:31:37]: [Client #510] Woke up.
[INFO][17:31:37]: [Client #510] Epoch: [3/5][0/17]	Loss: 2.399369
[INFO][17:31:37]: [Client #510] Epoch: [3/5][10/17]	Loss: 2.309040
[INFO][17:31:37]: [Client #510] Going to sleep for 0.32 seconds.
[INFO][17:31:37]: [Client #510] Woke up.
[INFO][17:31:37]: [Client #510] Epoch: [4/5][0/17]	Loss: 0.394707
[INFO][17:31:37]: [Client #510] Epoch: [4/5][10/17]	Loss: 0.758441
[INFO][17:31:37]: [Client #965] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_965_615874.pth.
[INFO][17:31:37]: [Client #965] Model trained.
[INFO][17:31:37]: [Client #965] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:37]: [Server #615782] Received 0.26 MB of payload data from client #965 (simulated).
[INFO][17:31:37]: [Client #510] Going to sleep for 0.32 seconds.
[INFO][17:31:38]: [Client #510] Woke up.
[INFO][17:31:38]: [Client #510] Epoch: [5/5][0/17]	Loss: 1.025941
[INFO][17:31:38]: [Client #510] Epoch: [5/5][10/17]	Loss: 1.706440
[INFO][17:31:38]: [Client #510] Going to sleep for 0.32 seconds.
[INFO][17:31:38]: [Client #510] Woke up.
[INFO][17:31:38]: [Client #510] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_510_615875.pth.
[INFO][17:31:39]: [Client #510] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_510_615875.pth.
[INFO][17:31:39]: [Client #510] Model trained.
[INFO][17:31:39]: [Client #510] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:39]: [Server #615782] Received 0.26 MB of payload data from client #510 (simulated).
[INFO][17:31:39]: [Server #615782] Selecting client #151 for training.
[INFO][17:31:39]: [Server #615782] Sending the current model to client #151 (simulated).
[INFO][17:31:39]: [Server #615782] Sending 0.26 MB of payload data to client #151 (simulated).
[INFO][17:31:39]: [Server #615782] Selecting client #523 for training.
[INFO][17:31:39]: [Server #615782] Sending the current model to client #523 (simulated).
[INFO][17:31:39]: [Server #615782] Sending 0.26 MB of payload data to client #523 (simulated).
[INFO][17:31:39]: [Client #151] Selected by the server.
[INFO][17:31:39]: [Client #151] Loading its data source...
[INFO][17:31:39]: Data source: FEMNIST
[INFO][17:31:39]: [Client #523] Selected by the server.
[INFO][17:31:39]: [Client #523] Loading its data source...
[INFO][17:31:39]: Data source: FEMNIST
[INFO][17:31:39]: [Client #151] Dataset size: 162
[INFO][17:31:39]: [Client #151] Sampler: all_inclusive
[INFO][17:31:39]: [Client #523] Dataset size: 165
[INFO][17:31:39]: [Client #523] Sampler: all_inclusive
[INFO][17:31:39]: [Client #151] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:39]: [Client #523] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:31:39]: [93m[1m[Client #523] Started training in communication round #20.[0m
[INFO][17:31:39]: [93m[1m[Client #151] Started training in communication round #20.[0m
[INFO][17:31:41]: [Client #523] Loading the dataset.
[INFO][17:31:41]: [Client #151] Loading the dataset.
[INFO][17:31:47]: [Client #523] Epoch: [1/5][0/17]	Loss: 0.387414
[INFO][17:31:47]: [Client #151] Epoch: [1/5][0/17]	Loss: 1.586942
[INFO][17:31:47]: [Client #523] Epoch: [1/5][10/17]	Loss: 0.677892
[INFO][17:31:47]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][17:31:47]: [Client #151] Epoch: [1/5][10/17]	Loss: 2.024463
[INFO][17:31:47]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][17:31:47]: [Client #151] Woke up.
[INFO][17:31:47]: [Client #151] Epoch: [2/5][0/17]	Loss: 0.808208
[INFO][17:31:47]: [Client #151] Epoch: [2/5][10/17]	Loss: 0.829685
[INFO][17:31:47]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][17:31:47]: [Client #151] Woke up.
[INFO][17:31:47]: [Client #151] Epoch: [3/5][0/17]	Loss: 1.067143
[INFO][17:31:47]: [Client #151] Epoch: [3/5][10/17]	Loss: 1.108371
[INFO][17:31:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][17:31:48]: [Client #151] Woke up.
[INFO][17:31:48]: [Client #151] Epoch: [4/5][0/17]	Loss: 1.216253
[INFO][17:31:48]: [Client #151] Epoch: [4/5][10/17]	Loss: 0.881154
[INFO][17:31:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][17:31:48]: [Client #151] Woke up.
[INFO][17:31:48]: [Client #151] Epoch: [5/5][0/17]	Loss: 0.814549
[INFO][17:31:48]: [Client #151] Epoch: [5/5][10/17]	Loss: 0.315446
[INFO][17:31:48]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][17:31:48]: [Client #151] Woke up.
[INFO][17:31:48]: [Client #151] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_615874.pth.
[INFO][17:31:49]: [Client #151] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_615874.pth.
[INFO][17:31:49]: [Client #151] Model trained.
[INFO][17:31:49]: [Client #151] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:31:49]: [Server #615782] Received 0.26 MB of payload data from client #151 (simulated).
[INFO][17:32:28]: [Client #523] Woke up.
[INFO][17:32:28]: [Client #523] Epoch: [2/5][0/17]	Loss: 0.599623
[INFO][17:32:28]: [Client #523] Epoch: [2/5][10/17]	Loss: 1.744821
[INFO][17:32:28]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][17:33:09]: [Client #523] Woke up.
[INFO][17:33:09]: [Client #523] Epoch: [3/5][0/17]	Loss: 0.230231
[INFO][17:33:09]: [Client #523] Epoch: [3/5][10/17]	Loss: 0.804307
[INFO][17:33:09]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][17:33:50]: [Client #523] Woke up.
[INFO][17:33:50]: [Client #523] Epoch: [4/5][0/17]	Loss: 0.548418
[INFO][17:33:50]: [Client #523] Epoch: [4/5][10/17]	Loss: 0.380036
[INFO][17:33:50]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][17:34:31]: [Client #523] Woke up.
[INFO][17:34:31]: [Client #523] Epoch: [5/5][0/17]	Loss: 0.340445
[INFO][17:34:31]: [Client #523] Epoch: [5/5][10/17]	Loss: 0.574872
[INFO][17:34:31]: [Client #523] Going to sleep for 40.65 seconds.
[INFO][17:35:11]: [Client #523] Woke up.
[INFO][17:35:12]: [Client #523] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_523_615875.pth.
[INFO][17:35:12]: [Client #523] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_523_615875.pth.
[INFO][17:35:12]: [Client #523] Model trained.
[INFO][17:35:12]: [Client #523] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:35:12]: [Server #615782] Received 0.26 MB of payload data from client #523 (simulated).
[INFO][17:35:12]: [Server #615782] Selecting client #944 for training.
[INFO][17:35:12]: [Server #615782] Sending the current model to client #944 (simulated).
[INFO][17:35:12]: [Server #615782] Sending 0.26 MB of payload data to client #944 (simulated).
[INFO][17:35:12]: [Server #615782] Selecting client #866 for training.
[INFO][17:35:12]: [Server #615782] Sending the current model to client #866 (simulated).
[INFO][17:35:12]: [Server #615782] Sending 0.26 MB of payload data to client #866 (simulated).
[INFO][17:35:12]: [Client #866] Selected by the server.
[INFO][17:35:12]: [Client #944] Selected by the server.
[INFO][17:35:12]: [Client #866] Loading its data source...
[INFO][17:35:12]: Data source: FEMNIST
[INFO][17:35:12]: [Client #944] Loading its data source...
[INFO][17:35:12]: Data source: FEMNIST
[INFO][17:35:12]: [Client #944] Dataset size: 211
[INFO][17:35:12]: [Client #944] Sampler: all_inclusive
[INFO][17:35:12]: [Client #866] Dataset size: 228
[INFO][17:35:12]: [Client #866] Sampler: all_inclusive
[INFO][17:35:12]: [Client #944] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:12]: [Client #866] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:12]: [93m[1m[Client #944] Started training in communication round #20.[0m
[INFO][17:35:12]: [93m[1m[Client #866] Started training in communication round #20.[0m
[INFO][17:35:14]: [Client #944] Loading the dataset.
[INFO][17:35:14]: [Client #866] Loading the dataset.
[INFO][17:35:20]: [Client #944] Epoch: [1/5][0/22]	Loss: 1.198140
[INFO][17:35:21]: [Client #866] Epoch: [1/5][0/23]	Loss: 1.566036
[INFO][17:35:21]: [Client #944] Epoch: [1/5][10/22]	Loss: 1.902619
[INFO][17:35:21]: [Client #944] Epoch: [1/5][20/22]	Loss: 2.164237
[INFO][17:35:21]: [Client #866] Epoch: [1/5][10/23]	Loss: 0.509605
[INFO][17:35:21]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][17:35:21]: [Client #866] Epoch: [1/5][20/23]	Loss: 1.744524
[INFO][17:35:21]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][17:35:24]: [Client #866] Woke up.
[INFO][17:35:24]: [Client #866] Epoch: [2/5][0/23]	Loss: 0.552043
[INFO][17:35:24]: [Client #866] Epoch: [2/5][10/23]	Loss: 1.282560
[INFO][17:35:24]: [Client #866] Epoch: [2/5][20/23]	Loss: 1.514525
[INFO][17:35:24]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][17:35:25]: [Client #944] Woke up.
[INFO][17:35:25]: [Client #944] Epoch: [2/5][0/22]	Loss: 0.608653
[INFO][17:35:25]: [Client #944] Epoch: [2/5][10/22]	Loss: 0.890330
[INFO][17:35:25]: [Client #944] Epoch: [2/5][20/22]	Loss: 1.705240
[INFO][17:35:25]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][17:35:27]: [Client #866] Woke up.
[INFO][17:35:27]: [Client #866] Epoch: [3/5][0/23]	Loss: 0.710626
[INFO][17:35:27]: [Client #866] Epoch: [3/5][10/23]	Loss: 0.653453
[INFO][17:35:27]: [Client #866] Epoch: [3/5][20/23]	Loss: 0.464769
[INFO][17:35:27]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][17:35:29]: [Client #944] Woke up.
[INFO][17:35:29]: [Client #944] Epoch: [3/5][0/22]	Loss: 1.031291
[INFO][17:35:29]: [Client #944] Epoch: [3/5][10/22]	Loss: 1.376595
[INFO][17:35:29]: [Client #944] Epoch: [3/5][20/22]	Loss: 0.711098
[INFO][17:35:29]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][17:35:30]: [Client #866] Woke up.
[INFO][17:35:30]: [Client #866] Epoch: [4/5][0/23]	Loss: 0.314224
[INFO][17:35:30]: [Client #866] Epoch: [4/5][10/23]	Loss: 1.449574
[INFO][17:35:30]: [Client #866] Epoch: [4/5][20/23]	Loss: 0.881800
[INFO][17:35:30]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][17:35:33]: [Client #944] Woke up.
[INFO][17:35:33]: [Client #944] Epoch: [4/5][0/22]	Loss: 2.169719
[INFO][17:35:33]: [Client #944] Epoch: [4/5][10/22]	Loss: 1.559203
[INFO][17:35:33]: [Client #944] Epoch: [4/5][20/22]	Loss: 1.123510
[INFO][17:35:33]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][17:35:34]: [Client #866] Woke up.
[INFO][17:35:34]: [Client #866] Epoch: [5/5][0/23]	Loss: 1.174924
[INFO][17:35:34]: [Client #866] Epoch: [5/5][10/23]	Loss: 1.613115
[INFO][17:35:34]: [Client #866] Epoch: [5/5][20/23]	Loss: 1.977124
[INFO][17:35:34]: [Client #866] Going to sleep for 3.02 seconds.
[INFO][17:35:37]: [Client #866] Woke up.
[INFO][17:35:37]: [Client #866] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_866_615875.pth.
[INFO][17:35:37]: [Client #944] Woke up.
[INFO][17:35:37]: [Client #944] Epoch: [5/5][0/22]	Loss: 0.863237
[INFO][17:35:37]: [Client #944] Epoch: [5/5][10/22]	Loss: 1.524926
[INFO][17:35:37]: [Client #944] Epoch: [5/5][20/22]	Loss: 1.475871
[INFO][17:35:37]: [Client #944] Going to sleep for 3.93 seconds.
[INFO][17:35:37]: [Client #866] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_866_615875.pth.
[INFO][17:35:37]: [Client #866] Model trained.
[INFO][17:35:37]: [Client #866] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:35:37]: [Server #615782] Received 0.26 MB of payload data from client #866 (simulated).
[INFO][17:35:41]: [Client #944] Woke up.
[INFO][17:35:41]: [Client #944] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_944_615874.pth.
[INFO][17:35:42]: [Client #944] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_944_615874.pth.
[INFO][17:35:42]: [Client #944] Model trained.
[INFO][17:35:42]: [Client #944] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:35:42]: [Server #615782] Received 0.26 MB of payload data from client #944 (simulated).
[INFO][17:35:42]: [Server #615782] Selecting client #393 for training.
[INFO][17:35:42]: [Server #615782] Sending the current model to client #393 (simulated).
[INFO][17:35:42]: [Server #615782] Sending 0.26 MB of payload data to client #393 (simulated).
[INFO][17:35:42]: [Server #615782] Selecting client #285 for training.
[INFO][17:35:42]: [Server #615782] Sending the current model to client #285 (simulated).
[INFO][17:35:42]: [Server #615782] Sending 0.26 MB of payload data to client #285 (simulated).
[INFO][17:35:42]: [Client #393] Selected by the server.
[INFO][17:35:42]: [Client #393] Loading its data source...
[INFO][17:35:42]: Data source: FEMNIST
[INFO][17:35:42]: [Client #285] Selected by the server.
[INFO][17:35:42]: [Client #285] Loading its data source...
[INFO][17:35:42]: Data source: FEMNIST
[INFO][17:35:42]: [Client #393] Dataset size: 161
[INFO][17:35:42]: [Client #393] Sampler: all_inclusive
[INFO][17:35:42]: [Client #285] Dataset size: 163
[INFO][17:35:42]: [Client #285] Sampler: all_inclusive
[INFO][17:35:42]: [Client #393] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:42]: [Client #285] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:42]: [93m[1m[Client #393] Started training in communication round #20.[0m
[INFO][17:35:42]: [93m[1m[Client #285] Started training in communication round #20.[0m
[INFO][17:35:44]: [Client #285] Loading the dataset.
[INFO][17:35:44]: [Client #393] Loading the dataset.
[INFO][17:35:50]: [Client #285] Epoch: [1/5][0/17]	Loss: 0.260325
[INFO][17:35:50]: [Client #393] Epoch: [1/5][0/17]	Loss: 0.708381
[INFO][17:35:50]: [Client #285] Epoch: [1/5][10/17]	Loss: 2.288424
[INFO][17:35:50]: [Client #393] Epoch: [1/5][10/17]	Loss: 0.338863
[INFO][17:35:50]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][17:35:50]: [Client #393] Going to sleep for 0.42 seconds.
[INFO][17:35:50]: [Client #285] Woke up.
[INFO][17:35:50]: [Client #285] Epoch: [2/5][0/17]	Loss: 0.808224
[INFO][17:35:50]: [Client #285] Epoch: [2/5][10/17]	Loss: 0.479688
[INFO][17:35:50]: [Client #393] Woke up.
[INFO][17:35:50]: [Client #393] Epoch: [2/5][0/17]	Loss: 0.373972
[INFO][17:35:50]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][17:35:50]: [Client #393] Epoch: [2/5][10/17]	Loss: 0.823078
[INFO][17:35:50]: [Client #393] Going to sleep for 0.42 seconds.
[INFO][17:35:51]: [Client #285] Woke up.
[INFO][17:35:51]: [Client #285] Epoch: [3/5][0/17]	Loss: 0.937449
[INFO][17:35:51]: [Client #285] Epoch: [3/5][10/17]	Loss: 1.775791
[INFO][17:35:51]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][17:35:51]: [Client #393] Woke up.
[INFO][17:35:51]: [Client #393] Epoch: [3/5][0/17]	Loss: 0.653328
[INFO][17:35:51]: [Client #393] Epoch: [3/5][10/17]	Loss: 0.553628
[INFO][17:35:51]: [Client #393] Going to sleep for 0.42 seconds.
[INFO][17:35:51]: [Client #285] Woke up.
[INFO][17:35:51]: [Client #285] Epoch: [4/5][0/17]	Loss: 0.370572
[INFO][17:35:51]: [Client #285] Epoch: [4/5][10/17]	Loss: 1.151166
[INFO][17:35:51]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][17:35:51]: [Client #393] Woke up.
[INFO][17:35:51]: [Client #393] Epoch: [4/5][0/17]	Loss: 0.448335
[INFO][17:35:52]: [Client #393] Epoch: [4/5][10/17]	Loss: 0.605761
[INFO][17:35:52]: [Client #393] Going to sleep for 0.42 seconds.
[INFO][17:35:52]: [Client #285] Woke up.
[INFO][17:35:52]: [Client #285] Epoch: [5/5][0/17]	Loss: 0.560203
[INFO][17:35:52]: [Client #285] Epoch: [5/5][10/17]	Loss: 0.769071
[INFO][17:35:52]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][17:35:52]: [Client #393] Woke up.
[INFO][17:35:52]: [Client #393] Epoch: [5/5][0/17]	Loss: 0.746719
[INFO][17:35:52]: [Client #393] Epoch: [5/5][10/17]	Loss: 1.578527
[INFO][17:35:52]: [Client #285] Woke up.
[INFO][17:35:52]: [Client #285] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_285_615875.pth.
[INFO][17:35:52]: [Client #393] Going to sleep for 0.42 seconds.
[INFO][17:35:53]: [Client #393] Woke up.
[INFO][17:35:53]: [Client #393] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_393_615874.pth.
[INFO][17:35:53]: [Client #285] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_285_615875.pth.
[INFO][17:35:53]: [Client #285] Model trained.
[INFO][17:35:53]: [Client #285] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:35:53]: [Server #615782] Received 0.26 MB of payload data from client #285 (simulated).
[INFO][17:35:53]: [Client #393] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_393_615874.pth.
[INFO][17:35:53]: [Client #393] Model trained.
[INFO][17:35:53]: [Client #393] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:35:53]: [Server #615782] Received 0.26 MB of payload data from client #393 (simulated).
[INFO][17:35:53]: [Server #615782] Selecting client #762 for training.
[INFO][17:35:53]: [Server #615782] Sending the current model to client #762 (simulated).
[INFO][17:35:53]: [Server #615782] Sending 0.26 MB of payload data to client #762 (simulated).
[INFO][17:35:53]: [Server #615782] Selecting client #242 for training.
[INFO][17:35:53]: [Server #615782] Sending the current model to client #242 (simulated).
[INFO][17:35:53]: [Server #615782] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][17:35:53]: [Client #762] Selected by the server.
[INFO][17:35:53]: [Client #762] Loading its data source...
[INFO][17:35:53]: Data source: FEMNIST
[INFO][17:35:53]: [Client #242] Selected by the server.
[INFO][17:35:53]: [Client #242] Loading its data source...
[INFO][17:35:53]: Data source: FEMNIST
[INFO][17:35:53]: [Client #242] Dataset size: 146
[INFO][17:35:53]: [Client #242] Sampler: all_inclusive
[INFO][17:35:53]: [Client #762] Dataset size: 163
[INFO][17:35:53]: [Client #762] Sampler: all_inclusive
[INFO][17:35:53]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:53]: [Client #762] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:35:53]: [93m[1m[Client #242] Started training in communication round #20.[0m
[INFO][17:35:53]: [93m[1m[Client #762] Started training in communication round #20.[0m
[INFO][17:35:55]: [Client #762] Loading the dataset.
[INFO][17:35:55]: [Client #242] Loading the dataset.
[INFO][17:36:01]: [Client #762] Epoch: [1/5][0/17]	Loss: 0.503761
[INFO][17:36:01]: [Client #242] Epoch: [1/5][0/15]	Loss: 1.791866
[INFO][17:36:01]: [Client #242] Epoch: [1/5][10/15]	Loss: 1.657964
[INFO][17:36:01]: [Client #762] Epoch: [1/5][10/17]	Loss: 1.401656
[INFO][17:36:01]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][17:36:01]: [Client #762] Going to sleep for 27.56 seconds.
[INFO][17:36:10]: [Client #242] Woke up.
[INFO][17:36:10]: [Client #242] Epoch: [2/5][0/15]	Loss: 1.758184
[INFO][17:36:10]: [Client #242] Epoch: [2/5][10/15]	Loss: 1.506970
[INFO][17:36:10]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][17:36:18]: [Client #242] Woke up.
[INFO][17:36:18]: [Client #242] Epoch: [3/5][0/15]	Loss: 0.750721
[INFO][17:36:18]: [Client #242] Epoch: [3/5][10/15]	Loss: 0.911560
[INFO][17:36:18]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][17:36:27]: [Client #242] Woke up.
[INFO][17:36:27]: [Client #242] Epoch: [4/5][0/15]	Loss: 0.838254
[INFO][17:36:27]: [Client #242] Epoch: [4/5][10/15]	Loss: 0.415907
[INFO][17:36:27]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][17:36:29]: [Client #762] Woke up.
[INFO][17:36:29]: [Client #762] Epoch: [2/5][0/17]	Loss: 1.013758
[INFO][17:36:29]: [Client #762] Epoch: [2/5][10/17]	Loss: 0.767005
[INFO][17:36:29]: [Client #762] Going to sleep for 27.56 seconds.
[INFO][17:36:35]: [Client #242] Woke up.
[INFO][17:36:35]: [Client #242] Epoch: [5/5][0/15]	Loss: 0.782029
[INFO][17:36:35]: [Client #242] Epoch: [5/5][10/15]	Loss: 1.378115
[INFO][17:36:35]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][17:36:44]: [Client #242] Woke up.
[INFO][17:36:44]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][17:36:44]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_615875.pth.
[INFO][17:36:44]: [Client #242] Model trained.
[INFO][17:36:44]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:36:44]: [Server #615782] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][17:36:57]: [Client #762] Woke up.
[INFO][17:36:57]: [Client #762] Epoch: [3/5][0/17]	Loss: 0.254955
[INFO][17:36:57]: [Client #762] Epoch: [3/5][10/17]	Loss: 1.181927
[INFO][17:36:57]: [Client #762] Going to sleep for 27.56 seconds.
[INFO][17:37:24]: [Client #762] Woke up.
[INFO][17:37:25]: [Client #762] Epoch: [4/5][0/17]	Loss: 0.715508
[INFO][17:37:25]: [Client #762] Epoch: [4/5][10/17]	Loss: 0.532792
[INFO][17:37:25]: [Client #762] Going to sleep for 27.56 seconds.
[INFO][17:37:52]: [Client #762] Woke up.
[INFO][17:37:52]: [Client #762] Epoch: [5/5][0/17]	Loss: 0.022599
[INFO][17:37:53]: [Client #762] Epoch: [5/5][10/17]	Loss: 0.968548
[INFO][17:37:53]: [Client #762] Going to sleep for 27.56 seconds.
[INFO][17:38:20]: [Client #762] Woke up.
[INFO][17:38:20]: [Client #762] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_762_615874.pth.
[INFO][17:38:21]: [Client #762] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_762_615874.pth.
[INFO][17:38:21]: [Client #762] Model trained.
[INFO][17:38:21]: [Client #762] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:38:21]: [Server #615782] Received 0.26 MB of payload data from client #762 (simulated).
[INFO][17:38:21]: [Server #615782] Selecting client #255 for training.
[INFO][17:38:21]: [Server #615782] Sending the current model to client #255 (simulated).
[INFO][17:38:21]: [Server #615782] Sending 0.26 MB of payload data to client #255 (simulated).
[INFO][17:38:21]: [Server #615782] Selecting client #84 for training.
[INFO][17:38:21]: [Server #615782] Sending the current model to client #84 (simulated).
[INFO][17:38:21]: [Server #615782] Sending 0.26 MB of payload data to client #84 (simulated).
[INFO][17:38:21]: [Client #255] Selected by the server.
[INFO][17:38:21]: [Client #255] Loading its data source...
[INFO][17:38:21]: [Client #84] Selected by the server.
[INFO][17:38:21]: Data source: FEMNIST
[INFO][17:38:21]: [Client #84] Loading its data source...
[INFO][17:38:21]: Data source: FEMNIST
[INFO][17:38:21]: [Client #84] Dataset size: 127
[INFO][17:38:21]: [Client #84] Sampler: all_inclusive
[INFO][17:38:21]: [Client #84] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:38:21]: [93m[1m[Client #84] Started training in communication round #20.[0m
[INFO][17:38:21]: [Client #255] Dataset size: 166
[INFO][17:38:21]: [Client #255] Sampler: all_inclusive
[INFO][17:38:21]: [Client #255] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:38:21]: [93m[1m[Client #255] Started training in communication round #20.[0m
[INFO][17:38:23]: [Client #84] Loading the dataset.
[INFO][17:38:23]: [Client #255] Loading the dataset.
[INFO][17:38:29]: [Client #84] Epoch: [1/5][0/13]	Loss: 1.970903
[INFO][17:38:29]: [Client #255] Epoch: [1/5][0/17]	Loss: 0.846336
[INFO][17:38:29]: [Client #84] Epoch: [1/5][10/13]	Loss: 1.139410
[INFO][17:38:29]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][17:38:29]: [Client #255] Epoch: [1/5][10/17]	Loss: 0.887281
[INFO][17:38:29]: [Client #255] Going to sleep for 1.53 seconds.
[INFO][17:38:30]: [Client #84] Woke up.
[INFO][17:38:30]: [Client #84] Epoch: [2/5][0/13]	Loss: 0.543742
[INFO][17:38:30]: [Client #84] Epoch: [2/5][10/13]	Loss: 0.894655
[INFO][17:38:30]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][17:38:30]: [Client #84] Woke up.
[INFO][17:38:31]: [Client #84] Epoch: [3/5][0/13]	Loss: 0.216437
[INFO][17:38:31]: [Client #84] Epoch: [3/5][10/13]	Loss: 0.400523
[INFO][17:38:31]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][17:38:31]: [Client #255] Woke up.
[INFO][17:38:31]: [Client #255] Epoch: [2/5][0/17]	Loss: 0.342494
[INFO][17:38:31]: [Client #255] Epoch: [2/5][10/17]	Loss: 1.020217
[INFO][17:38:31]: [Client #255] Going to sleep for 1.53 seconds.
[INFO][17:38:31]: [Client #84] Woke up.
[INFO][17:38:31]: [Client #84] Epoch: [4/5][0/13]	Loss: 0.659252
[INFO][17:38:31]: [Client #84] Epoch: [4/5][10/13]	Loss: 1.430280
[INFO][17:38:31]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][17:38:32]: [Client #84] Woke up.
[INFO][17:38:32]: [Client #84] Epoch: [5/5][0/13]	Loss: 0.627057
[INFO][17:38:32]: [Client #84] Epoch: [5/5][10/13]	Loss: 0.763130
[INFO][17:38:32]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][17:38:32]: [Client #84] Woke up.
[INFO][17:38:32]: [Client #84] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_84_615875.pth.
[INFO][17:38:33]: [Client #255] Woke up.
[INFO][17:38:33]: [Client #255] Epoch: [3/5][0/17]	Loss: 0.712359
[INFO][17:38:33]: [Client #255] Epoch: [3/5][10/17]	Loss: 0.819296
[INFO][17:38:33]: [Client #255] Going to sleep for 1.53 seconds.
[INFO][17:38:33]: [Client #84] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_84_615875.pth.
[INFO][17:38:33]: [Client #84] Model trained.
[INFO][17:38:33]: [Client #84] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:38:33]: [Server #615782] Received 0.26 MB of payload data from client #84 (simulated).
[INFO][17:38:34]: [Client #255] Woke up.
[INFO][17:38:34]: [Client #255] Epoch: [4/5][0/17]	Loss: 1.219955
[INFO][17:38:34]: [Client #255] Epoch: [4/5][10/17]	Loss: 1.809401
[INFO][17:38:34]: [Client #255] Going to sleep for 1.53 seconds.
[INFO][17:38:36]: [Client #255] Woke up.
[INFO][17:38:36]: [Client #255] Epoch: [5/5][0/17]	Loss: 1.082562
[INFO][17:38:36]: [Client #255] Epoch: [5/5][10/17]	Loss: 0.611476
[INFO][17:38:36]: [Client #255] Going to sleep for 1.53 seconds.
[INFO][17:38:38]: [Client #255] Woke up.
[INFO][17:38:38]: [Client #255] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_255_615874.pth.
[INFO][17:38:38]: [Client #255] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_255_615874.pth.
[INFO][17:38:38]: [Client #255] Model trained.
[INFO][17:38:38]: [Client #255] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:38:38]: [Server #615782] Received 0.26 MB of payload data from client #255 (simulated).
[INFO][17:38:38]: [Server #615782] Selecting client #865 for training.
[INFO][17:38:38]: [Server #615782] Sending the current model to client #865 (simulated).
[INFO][17:38:38]: [Server #615782] Sending 0.26 MB of payload data to client #865 (simulated).
[INFO][17:38:38]: [Client #865] Selected by the server.
[INFO][17:38:38]: [Client #865] Loading its data source...
[INFO][17:38:38]: Data source: FEMNIST
[INFO][17:38:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:38:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/865.zip.
2.2%4.3%6.5%8.6%10.8%13.0%15.1%17.3%19.5%21.6%23.8%25.9%28.1%30.3%32.4%34.6%36.8%38.9%41.1%43.2%45.4%47.6%49.7%51.9%54.1%56.2%58.4%60.5%62.7%64.9%67.0%69.2%71.4%73.5%75.7%77.8%80.0%82.2%84.3%86.5%88.7%90.8%93.0%95.1%97.3%99.5%100.0%[INFO][17:38:39]: Decompressing the dataset downloaded.
[INFO][17:38:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/865.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:38:39]: [Client #865] Dataset size: 160
[INFO][17:38:39]: [Client #865] Sampler: all_inclusive
[INFO][17:38:39]: [Client #865] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:38:39]: [93m[1m[Client #865] Started training in communication round #20.[0m

[INFO][17:38:41]: [Client #865] Loading the dataset.
[INFO][17:38:46]: [Client #865] Epoch: [1/5][0/16]	Loss: 1.323941
[INFO][17:38:46]: [Client #865] Epoch: [1/5][10/16]	Loss: 0.546079
[INFO][17:38:46]: [Client #865] Going to sleep for 5.67 seconds.
[INFO][17:38:52]: [Client #865] Woke up.
[INFO][17:38:52]: [Client #865] Epoch: [2/5][0/16]	Loss: 1.143172
[INFO][17:38:52]: [Client #865] Epoch: [2/5][10/16]	Loss: 0.453080
[INFO][17:38:52]: [Client #865] Going to sleep for 5.67 seconds.
[INFO][17:38:58]: [Client #865] Woke up.
[INFO][17:38:58]: [Client #865] Epoch: [3/5][0/16]	Loss: 0.766576
[INFO][17:38:58]: [Client #865] Epoch: [3/5][10/16]	Loss: 0.292764
[INFO][17:38:58]: [Client #865] Going to sleep for 5.67 seconds.
[INFO][17:39:03]: [Client #865] Woke up.
[INFO][17:39:03]: [Client #865] Epoch: [4/5][0/16]	Loss: 0.516134
[INFO][17:39:03]: [Client #865] Epoch: [4/5][10/16]	Loss: 0.153352
[INFO][17:39:04]: [Client #865] Going to sleep for 5.67 seconds.
[INFO][17:39:09]: [Client #865] Woke up.
[INFO][17:39:09]: [Client #865] Epoch: [5/5][0/16]	Loss: 0.580245
[INFO][17:39:09]: [Client #865] Epoch: [5/5][10/16]	Loss: 0.977877
[INFO][17:39:09]: [Client #865] Going to sleep for 5.67 seconds.
[INFO][17:39:15]: [Client #865] Woke up.
[INFO][17:39:15]: [Client #865] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_865_615874.pth.
[INFO][17:39:16]: [Client #865] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_865_615874.pth.
[INFO][17:39:16]: [Client #865] Model trained.
[INFO][17:39:16]: [Client #865] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:39:16]: [Server #615782] Received 0.26 MB of payload data from client #865 (simulated).
[INFO][17:39:16]: [Server #615782] Adding client #172 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #965 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #151 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #604 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #45 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #510 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #285 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #130 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #393 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #84 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #235 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #255 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #52 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #681 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #176 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #866 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #135 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #944 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #865 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #320 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #242 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #342 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #762 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #523 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Adding client #856 to the list of clients for aggregation.
[INFO][17:39:16]: [Server #615782] Aggregating 25 clients in total.

current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.18449469 0.         0.         0.
 0.         0.         0.         0.25662913 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10867253
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12960575 0.         0.
 0.         0.         0.26518891 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13759086 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12654395 0.         0.
 0.         0.10057283 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13656072 0.         0.         0.         0.         0.
 0.         0.22605692 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08828885 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14074439 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13969668 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12146771
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.68633881 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.29557374
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1564984  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09719116 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11969526 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10152864
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09454655 0.         0.
 0.         0.         0.         0.         0.         0.
 0.09232284 0.15206948 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.64514025 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10858618 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.18449469 0.         0.         0.
 0.         0.         0.         0.25662913 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10867253
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12960575 0.         0.
 0.         0.         0.26518891 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13759086 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12654395 0.         0.
 0.         0.10057283 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13656072 0.         0.         0.         0.         0.
 0.         0.22605692 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08828885 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14074439 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13969668 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12146771
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.68633881 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.29557374
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1564984  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09719116 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11969526 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10152864
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09454655 0.         0.
 0.         0.         0.         0.         0.         0.
 0.09232284 0.15206948 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.64514025 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10858618 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
!!!!!!The aggregation weights of this round are:  [0.02714654 0.03938224 0.001      0.001      0.001      0.02064598
 0.001      0.02919255 0.001      0.03375623 0.03936198 0.001
 0.02981366 0.0404518  0.0341556  0.02341853 0.001      0.001
 0.001      0.001      0.001      0.01977644 0.001      0.001
 0.001      0.001      0.001      0.03938224 0.001      0.001
 0.001      0.001      0.03778932 0.001      0.03330313 0.001
 0.02077264 0.02313294 0.001      0.03660841 0.001      0.04044594
 0.001      0.03920642 0.04776119 0.03519832 0.001      0.03602175
 0.001      0.001      0.0350013  0.04029851 0.03668639 0.001
 0.001      0.001      0.001      0.01856347 0.001      0.04316547
 0.03750919 0.03534209 0.001      0.03313609 0.001      0.001
 0.05565132 0.02313294 0.03333333 0.001      0.01823939 0.001
 0.01963268 0.02077264 0.0364633  0.001      0.001      0.001
 0.001      0.001      0.001      0.02313294 0.001      0.03159204
 0.03816794 0.04066924 0.001      0.04167739 0.001      0.001
 0.001      0.02064598 0.03824467 0.001      0.0420101  0.001
 0.001      0.001      0.001      0.001      0.001      0.03623768
 0.02013933 0.001      0.001      0.03536294 0.001      0.01937935
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.03605313 0.001      0.03989165 0.03961924
 0.01953077 0.03333333 0.08317445 0.001      0.001      0.03395445
 0.03802551 0.001      0.001      0.03955224 0.04067358 0.001
 0.001      0.001      0.03756219 0.02256176 0.001      0.001
 0.001      0.01925269 0.001      0.02013933 0.01916227 0.04050093
 0.001      0.001      0.001      0.001      0.01817958 0.001
 0.04029851 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03466244 0.001
 0.001      0.001      0.001      0.03262347 0.001      0.001
 0.001      0.001      0.001      0.04079602 0.03849787 0.001
 0.001      0.03681592 0.001      0.05542233 0.03898014 0.001
 0.03818786 0.001      0.001      0.04092664 0.001      0.03543832
 0.02014495 0.001      0.001      0.01965361 0.03395445 0.04064831
 0.001      0.02256176 0.001      0.001      0.03693994 0.03738106
 0.001      0.07542694 0.001      0.04063039 0.001      0.01903943
 0.001      0.001      0.001      0.02341853 0.001      0.001
 0.05663797 0.001      0.001      0.001      0.03818786 0.04095046
 0.001      0.001      0.0404518  0.001      0.001      0.07779886
 0.08013145 0.03692796 0.001      0.001      0.0189166  0.001
 0.001      0.001      0.04068067 0.04307365 0.001      0.001
 0.03482587 0.02299015 0.001      0.001      0.001      0.02227617
 0.03970157 0.03631841 0.04227599 0.001      0.06819212 0.001
 0.001      0.04038414 0.001      0.001      0.001      0.001
 0.04280776 0.03861004 0.04129353 0.001      0.04316547 0.03897024
 0.01784949 0.001      0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.04229052 0.001      0.04044489
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.02482584 0.01874604 0.001      0.04252009 0.001
 0.001      0.001      0.04054726 0.001      0.04169884 0.001
 0.001      0.001      0.001      0.001      0.001      0.03837179
 0.001      0.001      0.001      0.001      0.03250518 0.06611356
 0.001      0.03312629 0.001      0.001      0.03741659 0.001
 0.01989928 0.001      0.001      0.001      0.06802078 0.001
 0.001      0.03140283 0.001      0.001      0.001      0.001
 0.001      0.0380597  0.001      0.04513458 0.001      0.001
 0.001      0.03195266 0.001      0.03395445 0.03792169 0.03767545
 0.001      0.001      0.001      0.001      0.001      0.03786982
 0.03693994 0.001      0.001      0.03987651 0.001      0.04054726
 0.001      0.01879376 0.0541459  0.001      0.03892821 0.001
 0.001      0.0357513  0.001      0.04281587 0.001      0.01842525
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.04169884 0.001      0.04252009 0.04095046
 0.001      0.001      0.001      0.03836988 0.001      0.001
 0.001      0.01963268 0.001      0.001      0.001      0.001
 0.001      0.03789323 0.001      0.04045109 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.04130029 0.001      0.04004975 0.001      0.01879376 0.001
 0.04252009 0.001      0.03918099 0.001      0.01912603 0.0208993
 0.001      0.001      0.04092664 0.001      0.001      0.04147833
 0.001      0.001      0.001      0.001      0.03771347 0.01879376
 0.001      0.001      0.001      0.001      0.03756477 0.001
 0.001      0.06461538 0.001      0.02284735 0.03726404 0.03939916
 0.001      0.04176517 0.03979981 0.001      0.0383432  0.001
 0.05909874 0.03370495 0.02270456 0.001      0.001      0.001
 0.001      0.001      0.0320911  0.03970157 0.02077264 0.06207522
 0.001      0.001      0.001      0.001      0.04255319 0.001
 0.03881946 0.03842505 0.01912603 0.03783784 0.0212766  0.05325444
 0.04195624 0.03849787 0.0417088  0.001      0.001      0.001
 0.001      0.03677372 0.02443074 0.04316547 0.001      0.001
 0.04281587 0.03763314 0.001      0.001      0.001      0.0383432
 0.001      0.0357513  0.03706564 0.001      0.001      0.0401379
 0.001      0.001      0.001      0.001      0.0418332  0.01965361
 0.03668639 0.001      0.001      0.001      0.001      0.001
 0.04050093 0.04289901 0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.03866224 0.04142012 0.001
 0.001      0.001      0.001      0.03961924 0.001      0.04004975
 0.001      0.001      0.04145602 0.001      0.001      0.03443589
 0.001      0.03836988 0.001      0.03936198 0.001      0.001
 0.04104478 0.04307365 0.03462998 0.001      0.001      0.04063039
 0.0386082  0.001      0.04196891 0.001      0.06692817 0.01709943
 0.04067358 0.001      0.02284735 0.019886   0.001      0.001
 0.001      0.001      0.03881946 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03626943 0.03889033
 0.04248705 0.04307365 0.001      0.05103627 0.001      0.01830242
 0.01925269 0.04116285 0.001      0.001      0.001      0.001
 0.03731696 0.001      0.001      0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03443589 0.001
 0.03481245 0.001      0.001      0.02366392 0.001      0.0343184
 0.001      0.03229814 0.001      0.001      0.001      0.03361982
 0.001      0.03629032 0.03873498 0.0310559  0.001      0.03792169
 0.03758044 0.04095046 0.001      0.001      0.001      0.001
 0.03690597 0.02870019 0.03629032 0.0340796  0.03613604 0.04118404
 0.03188406 0.001      0.001      0.001      0.001      0.001
 0.001      0.03810651 0.001      0.001      0.03677436 0.03826169
 0.03828769 0.001      0.04094656 0.001      0.001      0.001
 0.001      0.04307365 0.03989637 0.04200156 0.01731974 0.001
 0.03285002 0.001      0.06116901 0.04092664 0.01916227 0.03288847
 0.001      0.001      0.04015544 0.03707545 0.04255319 0.001
 0.001      0.001      0.001      0.001      0.04076739 0.0401489
 0.001      0.03669047 0.001      0.02077264 0.001      0.001
 0.001      0.0420101  0.03892821 0.03747628 0.001      0.001
 0.001      0.001      0.001      0.03970157 0.001      0.001
 0.05763757 0.03384175 0.001      0.001      0.04167739 0.001
 0.001      0.001      0.03993933 0.001      0.001      0.001
 0.001      0.0323089  0.03656716 0.001      0.01940794 0.03202087
 0.03910471 0.0188727  0.001      0.04076739 0.001      0.001
 0.001      0.04038414 0.01849272 0.03601749 0.03511554 0.001
 0.001      0.03898014 0.001      0.001      0.001      0.0394011
 0.04307854 0.001      0.03989165 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.03989165 0.04307365
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.06222453 0.03333333 0.03731696 0.03622498 0.03605313
 0.001      0.001      0.001      0.0362834  0.04015444 0.001
 0.02441811 0.04148302 0.01989928 0.001      0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.06898327
 0.00886637 0.001      0.001      0.03989637 0.001      0.001
 0.001      0.03810651 0.001      0.02977931 0.04016563 0.001
 0.001      0.001      0.001      0.001      0.001      0.04054726
 0.03750919 0.001      0.001      0.001      0.03912484 0.02241896
 0.01899937 0.04227599 0.001      0.01975934 0.01670713 0.001
 0.001      0.001      0.08171941 0.03414814 0.001      0.001
 0.001      0.001      0.001      0.001      0.001      0.001
 0.03866224 0.001      0.001      0.01747942 0.04020593 0.001
 0.001      0.001      0.001      0.001      0.001      0.04018913
 0.001      0.001      0.001      0.03524569 0.001      0.001
 0.04229052 0.01937935 0.03723909 0.0373057  0.03241574 0.03778932
 0.001      0.001      0.0401489  0.001      0.02256176 0.001
 0.001      0.02026778 0.001      0.001      0.001      0.001
 0.01965361 0.03354037 0.001      0.01613594 0.001      0.03653203
 0.001      0.001      0.001      0.001      0.001      0.001
 0.001      0.0373057  0.001      0.02077264 0.001      0.001
 0.001      0.02284735 0.04169884 0.001      0.03447427 0.001
 0.04307854 0.03431953 0.04196891 0.001      0.011915   0.001
 0.03866043 0.001      0.001      0.03830846 0.03188406 0.001
 0.001      0.03826169 0.001      0.04116285 0.03707545 0.03963731
 0.039801   0.05671642 0.001      0.04170984 0.04255319 0.03887576
 0.03936198 0.03765491 0.01842525 0.0357952  0.001      0.04121244
 0.03937824 0.001      0.0192851  0.03684459 0.03398278 0.01925466
 0.03898014 0.001      0.001      0.001      0.001      0.001
 0.001      0.01977644 0.001      0.001      0.03526384 0.001
 0.01658273 0.03004186 0.03723909 0.03987651 0.01937935 0.07340324
 0.001      0.04222798 0.001      0.04096448 0.001      0.04307854
 0.001      0.04167739 0.03574833 0.001      0.001      0.01805675
 0.001      0.001      0.04121244 0.001      0.001      0.001
 0.03911917 0.03333333 0.03707545 0.03267891 0.001      0.001
 0.03892821 0.001      0.001      0.04096448 0.001      0.03701888
 0.03188474 0.001      0.001      0.02051932 0.03546099 0.04248705
 0.03665319 0.001      0.001      0.02227617 0.001      0.02574205
 0.001      0.05248756 0.001      0.001      0.03629032 0.04076739
 0.03613604 0.03549223 0.001      0.02241896 0.03147929 0.001
 0.001      0.04020593 0.01879376 0.03898014 0.001      0.001
 0.001      0.03938224 0.001      0.001      0.0340796  0.001
 0.001      0.03304023 0.001      0.03889943 0.001      0.001
 0.001      0.03731696 0.001      0.001      0.04133207 0.04170984
 0.04255319 0.001      0.04255319 0.001      0.04071447 0.001
 0.03103761 0.03660841 0.03866043 0.001      0.001      0.02540835
 0.01989928 0.03455672 0.03765491 0.001      0.001      0.001
 0.001      0.0391496  0.01329956 0.001     ][INFO][17:39:59]: [Server #615782] Global model accuracy: 60.14%

[INFO][17:39:59]: [Server #615782] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_20.pth.
[INFO][17:39:59]: [Server #615782] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_20.pth.
[INFO][17:39:59]: [93m[1m
[Server #615782] Starting round 21/100.[0m

Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  7.5999e+00  1e+03  1e+00  1e+00
 1:  7.5239e+00  6.6010e+00  1e+01  1e-02  1e-02
 2:  7.5992e+00  6.6903e+00  1e+00  9e-05  9e-05
 3:  7.5999e+00  7.5198e+00  8e-02  4e-07  4e-07
 4:  7.5999e+00  7.5990e+00  9e-04  4e-09  4e-09
 5:  7.5999e+00  7.5998e+00  7e-05  3e-10  3e-10
 6:  7.5999e+00  7.5998e+00  6e-05  2e-10  2e-10
 7:  7.5999e+00  7.5998e+00  6e-05  4e-09  5e-10
 8:  7.5999e+00  7.5998e+00  4e-05  3e-09  4e-10
 9:  7.5999e+00  7.5998e+00  3e-05  7e-09  9e-10
10:  7.5998e+00  7.5998e+00  5e-06  2e-08  3e-09
Optimal solution found.
The calculated probability is:  [9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49038039e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.48736522e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49716293e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49566976e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.48816026e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49520968e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.05209056e-01
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49696475e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49604683e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49143449e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49700785e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49502181e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49546468e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49587792e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.42109698e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.48395394e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49412640e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49724701e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49640340e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49663114e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49702570e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49698614e-05
 9.49071570e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.38156933e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49696636e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05 9.49837777e-05
 9.49837777e-05 9.49837777e-05 9.49837777e-05][INFO][17:40:02]: [Server #615782] Selected clients: [172 439 600 273 599 874 128 959 685 743 983 416 532 681 513 299 105 285
 770 642 803 518 233 629 304]
[INFO][17:40:02]: [Server #615782] Selecting client #172 for training.
[INFO][17:40:02]: [Server #615782] Sending the current model to client #172 (simulated).
[INFO][17:40:02]: [Server #615782] Sending 0.26 MB of payload data to client #172 (simulated).
[INFO][17:40:02]: [Server #615782] Selecting client #439 for training.
[INFO][17:40:02]: [Server #615782] Sending the current model to client #439 (simulated).
[INFO][17:40:02]: [Server #615782] Sending 0.26 MB of payload data to client #439 (simulated).
[INFO][17:40:02]: [Client #172] Selected by the server.
[INFO][17:40:02]: [Client #172] Loading its data source...
[INFO][17:40:02]: Data source: FEMNIST
[INFO][17:40:02]: [Client #439] Selected by the server.
[INFO][17:40:02]: [Client #439] Loading its data source...
[INFO][17:40:02]: Data source: FEMNIST
[INFO][17:40:02]: [Client #172] Dataset size: 164
[INFO][17:40:02]: [Client #172] Sampler: all_inclusive
[INFO][17:40:02]: [Client #172] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:40:02]: [Client #439] Dataset size: 144
[INFO][17:40:02]: [Client #439] Sampler: all_inclusive
[INFO][17:40:02]: [93m[1m[Client #172] Started training in communication round #21.[0m
[INFO][17:40:02]: [Client #439] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:40:02]: [93m[1m[Client #439] Started training in communication round #21.[0m
[INFO][17:40:04]: [Client #439] Loading the dataset.
[INFO][17:40:04]: [Client #172] Loading the dataset.
[INFO][17:40:10]: [Client #439] Epoch: [1/5][0/15]	Loss: 1.273183
[INFO][17:40:10]: [Client #172] Epoch: [1/5][0/17]	Loss: 0.954797
[INFO][17:40:10]: [Client #439] Epoch: [1/5][10/15]	Loss: 1.016505
[INFO][17:40:10]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][17:40:10]: [Client #172] Epoch: [1/5][10/17]	Loss: 0.682187
[INFO][17:40:10]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:40:13]: [Client #439] Woke up.
[INFO][17:40:13]: [Client #439] Epoch: [2/5][0/15]	Loss: 1.031381
[INFO][17:40:13]: [Client #439] Epoch: [2/5][10/15]	Loss: 0.364982
[INFO][17:40:14]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][17:40:17]: [Client #439] Woke up.
[INFO][17:40:17]: [Client #439] Epoch: [3/5][0/15]	Loss: 0.318733
[INFO][17:40:17]: [Client #439] Epoch: [3/5][10/15]	Loss: 1.184708
[INFO][17:40:17]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][17:40:20]: [Client #439] Woke up.
[INFO][17:40:21]: [Client #439] Epoch: [4/5][0/15]	Loss: 1.463038
[INFO][17:40:21]: [Client #439] Epoch: [4/5][10/15]	Loss: 0.844112
[INFO][17:40:21]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][17:40:24]: [Client #439] Woke up.
[INFO][17:40:24]: [Client #439] Epoch: [5/5][0/15]	Loss: 0.550540
[INFO][17:40:24]: [Client #439] Epoch: [5/5][10/15]	Loss: 1.272788
[INFO][17:40:24]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][17:40:28]: [Client #439] Woke up.
[INFO][17:40:28]: [Client #439] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_439_615875.pth.
[INFO][17:40:28]: [Client #439] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_439_615875.pth.
[INFO][17:40:28]: [Client #439] Model trained.
[INFO][17:40:28]: [Client #439] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:40:28]: [Server #615782] Received 0.26 MB of payload data from client #439 (simulated).
[INFO][17:41:10]: [Client #172] Woke up.
[INFO][17:41:10]: [Client #172] Epoch: [2/5][0/17]	Loss: 1.591830
[INFO][17:41:10]: [Client #172] Epoch: [2/5][10/17]	Loss: 0.399548
[INFO][17:41:10]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:42:10]: [Client #172] Woke up.
[INFO][17:42:11]: [Client #172] Epoch: [3/5][0/17]	Loss: 0.629041
[INFO][17:42:11]: [Client #172] Epoch: [3/5][10/17]	Loss: 0.541384
[INFO][17:42:11]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:43:11]: [Client #172] Woke up.
[INFO][17:43:11]: [Client #172] Epoch: [4/5][0/17]	Loss: 0.597959
[INFO][17:43:11]: [Client #172] Epoch: [4/5][10/17]	Loss: 0.921160
[INFO][17:43:11]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:44:11]: [Client #172] Woke up.
[INFO][17:44:11]: [Client #172] Epoch: [5/5][0/17]	Loss: 0.593121
[INFO][17:44:11]: [Client #172] Epoch: [5/5][10/17]	Loss: 0.368045
[INFO][17:44:11]: [Client #172] Going to sleep for 60.00 seconds.
[INFO][17:45:11]: [Client #172] Woke up.
[INFO][17:45:11]: [Client #172] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615874.pth.
[INFO][17:45:12]: [Client #172] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_172_615874.pth.
[INFO][17:45:12]: [Client #172] Model trained.
[INFO][17:45:12]: [Client #172] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:12]: [Server #615782] Received 0.26 MB of payload data from client #172 (simulated).
[INFO][17:45:12]: [Server #615782] Selecting client #600 for training.
[INFO][17:45:12]: [Server #615782] Sending the current model to client #600 (simulated).
[INFO][17:45:12]: [Server #615782] Sending 0.26 MB of payload data to client #600 (simulated).
[INFO][17:45:12]: [Server #615782] Selecting client #273 for training.
[INFO][17:45:12]: [Server #615782] Sending the current model to client #273 (simulated).
[INFO][17:45:12]: [Server #615782] Sending 0.26 MB of payload data to client #273 (simulated).
[INFO][17:45:12]: [Client #600] Selected by the server.
[INFO][17:45:12]: [Client #600] Loading its data source...
[INFO][17:45:12]: Data source: FEMNIST
[INFO][17:45:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:45:12]: [Client #273] Selected by the server.
[INFO][17:45:12]: [Client #273] Loading its data source...
[INFO][17:45:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/600.zip.
[INFO][17:45:12]: Data source: FEMNIST
[INFO][17:45:12]: [Client #273] Dataset size: 164
[INFO][17:45:12]: [Client #273] Sampler: all_inclusive
[INFO][17:45:12]: [Client #273] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:12]: [93m[1m[Client #273] Started training in communication round #21.[0m
1.5%3.1%4.6%6.1%7.6%9.2%10.7%12.2%13.7%15.3%16.8%18.3%19.8%21.4%22.9%24.4%25.9%27.5%29.0%30.5%32.0%33.6%35.1%36.6%38.1%39.7%41.2%42.7%44.2%45.8%47.3%48.8%50.3%51.9%53.4%54.9%56.4%58.0%59.5%61.0%62.6%64.1%65.6%67.1%68.7%70.2%71.7%73.2%74.8%76.3%77.8%79.3%80.9%82.4%83.9%85.4%87.0%88.5%90.0%91.5%93.1%94.6%96.1%97.6%99.2%100.0%[INFO][17:45:12]: Decompressing the dataset downloaded.
[INFO][17:45:12]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/600.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:45:12]: [Client #600] Dataset size: 283
[INFO][17:45:12]: [Client #600] Sampler: all_inclusive
[INFO][17:45:12]: [Client #600] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:12]: [93m[1m[Client #600] Started training in communication round #21.[0m

[INFO][17:45:14]: [Client #273] Loading the dataset.
[INFO][17:45:14]: [Client #600] Loading the dataset.
[INFO][17:45:20]: [Client #273] Epoch: [1/5][0/17]	Loss: 0.306541
[INFO][17:45:20]: [Client #600] Epoch: [1/5][0/29]	Loss: 1.694425
[INFO][17:45:20]: [Client #273] Epoch: [1/5][10/17]	Loss: 0.391008
[INFO][17:45:20]: [Client #600] Epoch: [1/5][10/29]	Loss: 1.137142
[INFO][17:45:20]: [Client #273] Going to sleep for 1.64 seconds.
[INFO][17:45:20]: [Client #600] Epoch: [1/5][20/29]	Loss: 1.838849
[INFO][17:45:20]: [Client #600] Going to sleep for 0.12 seconds.
[INFO][17:45:20]: [Client #600] Woke up.
[INFO][17:45:20]: [Client #600] Epoch: [2/5][0/29]	Loss: 1.617934
[INFO][17:45:21]: [Client #600] Epoch: [2/5][10/29]	Loss: 0.860953
[INFO][17:45:21]: [Client #600] Epoch: [2/5][20/29]	Loss: 2.355576
[INFO][17:45:21]: [Client #600] Going to sleep for 0.12 seconds.
[INFO][17:45:21]: [Client #600] Woke up.
[INFO][17:45:21]: [Client #600] Epoch: [3/5][0/29]	Loss: 1.807161
[INFO][17:45:21]: [Client #600] Epoch: [3/5][10/29]	Loss: 0.763323
[INFO][17:45:21]: [Client #600] Epoch: [3/5][20/29]	Loss: 1.033571
[INFO][17:45:21]: [Client #600] Going to sleep for 0.12 seconds.
[INFO][17:45:21]: [Client #600] Woke up.
[INFO][17:45:21]: [Client #600] Epoch: [4/5][0/29]	Loss: 0.596556
[INFO][17:45:21]: [Client #600] Epoch: [4/5][10/29]	Loss: 0.773672
[INFO][17:45:21]: [Client #600] Epoch: [4/5][20/29]	Loss: 1.267066
[INFO][17:45:21]: [Client #600] Going to sleep for 0.12 seconds.
[INFO][17:45:22]: [Client #600] Woke up.
[INFO][17:45:22]: [Client #600] Epoch: [5/5][0/29]	Loss: 1.233345
[INFO][17:45:22]: [Client #600] Epoch: [5/5][10/29]	Loss: 1.062811
[INFO][17:45:22]: [Client #600] Epoch: [5/5][20/29]	Loss: 1.731823
[INFO][17:45:22]: [Client #600] Going to sleep for 0.12 seconds.
[INFO][17:45:22]: [Client #273] Woke up.
[INFO][17:45:22]: [Client #273] Epoch: [2/5][0/17]	Loss: 0.289303
[INFO][17:45:22]: [Client #600] Woke up.
[INFO][17:45:22]: [Client #600] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_600_615874.pth.
[INFO][17:45:22]: [Client #273] Epoch: [2/5][10/17]	Loss: 0.692724
[INFO][17:45:22]: [Client #273] Going to sleep for 1.64 seconds.
[INFO][17:45:23]: [Client #600] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_600_615874.pth.
[INFO][17:45:23]: [Client #600] Model trained.
[INFO][17:45:23]: [Client #600] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:23]: [Server #615782] Received 0.26 MB of payload data from client #600 (simulated).
[INFO][17:45:24]: [Client #273] Woke up.
[INFO][17:45:24]: [Client #273] Epoch: [3/5][0/17]	Loss: 0.819512
[INFO][17:45:24]: [Client #273] Epoch: [3/5][10/17]	Loss: 0.322336
[INFO][17:45:24]: [Client #273] Going to sleep for 1.64 seconds.
[INFO][17:45:25]: [Client #273] Woke up.
[INFO][17:45:25]: [Client #273] Epoch: [4/5][0/17]	Loss: 0.416972
[INFO][17:45:26]: [Client #273] Epoch: [4/5][10/17]	Loss: 0.241858
[INFO][17:45:26]: [Client #273] Going to sleep for 1.64 seconds.
[INFO][17:45:27]: [Client #273] Woke up.
[INFO][17:45:27]: [Client #273] Epoch: [5/5][0/17]	Loss: 0.691143
[INFO][17:45:27]: [Client #273] Epoch: [5/5][10/17]	Loss: 0.899540
[INFO][17:45:27]: [Client #273] Going to sleep for 1.64 seconds.
[INFO][17:45:29]: [Client #273] Woke up.
[INFO][17:45:29]: [Client #273] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_273_615875.pth.
[INFO][17:45:30]: [Client #273] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_273_615875.pth.
[INFO][17:45:30]: [Client #273] Model trained.
[INFO][17:45:30]: [Client #273] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:30]: [Server #615782] Received 0.26 MB of payload data from client #273 (simulated).
[INFO][17:45:30]: [Server #615782] Selecting client #599 for training.
[INFO][17:45:30]: [Server #615782] Sending the current model to client #599 (simulated).
[INFO][17:45:30]: [Server #615782] Sending 0.26 MB of payload data to client #599 (simulated).
[INFO][17:45:30]: [Server #615782] Selecting client #874 for training.
[INFO][17:45:30]: [Server #615782] Sending the current model to client #874 (simulated).
[INFO][17:45:30]: [Server #615782] Sending 0.26 MB of payload data to client #874 (simulated).
[INFO][17:45:30]: [Client #599] Selected by the server.
[INFO][17:45:30]: [Client #599] Loading its data source...
[INFO][17:45:30]: Data source: FEMNIST
[INFO][17:45:30]: [Client #874] Selected by the server.
[INFO][17:45:30]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:45:30]: [Client #874] Loading its data source...
[INFO][17:45:30]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/599.zip.
[INFO][17:45:30]: Data source: FEMNIST
[INFO][17:45:30]: [Client #874] Dataset size: 158
[INFO][17:45:30]: [Client #874] Sampler: all_inclusive
[INFO][17:45:30]: [Client #874] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:30]: [93m[1m[Client #874] Started training in communication round #21.[0m
2.2%4.4%6.7%8.9%11.1%13.3%15.5%17.8%20.0%22.2%24.4%26.6%28.9%31.1%33.3%35.5%37.8%40.0%42.2%44.4%46.6%48.9%51.1%53.3%55.5%57.7%60.0%62.2%64.4%66.6%68.8%71.1%73.3%75.5%77.7%79.9%82.2%84.4%86.6%88.8%91.1%93.3%95.5%97.7%99.9%100.0%[INFO][17:45:30]: Decompressing the dataset downloaded.
[INFO][17:45:30]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/599.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:45:30]: [Client #599] Dataset size: 142
[INFO][17:45:30]: [Client #599] Sampler: all_inclusive
[INFO][17:45:30]: [Client #599] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:30]: [93m[1m[Client #599] Started training in communication round #21.[0m

[INFO][17:45:32]: [Client #874] Loading the dataset.
[INFO][17:45:32]: [Client #599] Loading the dataset.
[INFO][17:45:38]: [Client #599] Epoch: [1/5][0/15]	Loss: 1.953362
[INFO][17:45:38]: [Client #874] Epoch: [1/5][0/16]	Loss: 1.442877
[INFO][17:45:38]: [Client #874] Epoch: [1/5][10/16]	Loss: 0.489793
[INFO][17:45:38]: [Client #599] Epoch: [1/5][10/15]	Loss: 0.450282
[INFO][17:45:38]: [Client #599] Going to sleep for 0.03 seconds.
[INFO][17:45:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][17:45:38]: [Client #599] Woke up.
[INFO][17:45:38]: [Client #599] Epoch: [2/5][0/15]	Loss: 0.651466
[INFO][17:45:38]: [Client #599] Epoch: [2/5][10/15]	Loss: 0.358422
[INFO][17:45:38]: [Client #874] Woke up.
[INFO][17:45:38]: [Client #874] Epoch: [2/5][0/16]	Loss: 0.491392
[INFO][17:45:38]: [Client #599] Going to sleep for 0.03 seconds.
[INFO][17:45:38]: [Client #599] Woke up.
[INFO][17:45:38]: [Client #599] Epoch: [3/5][0/15]	Loss: 0.771720
[INFO][17:45:38]: [Client #874] Epoch: [2/5][10/16]	Loss: 0.280280
[INFO][17:45:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][17:45:38]: [Client #599] Epoch: [3/5][10/15]	Loss: 0.711264
[INFO][17:45:38]: [Client #599] Going to sleep for 0.03 seconds.
[INFO][17:45:38]: [Client #599] Woke up.
[INFO][17:45:38]: [Client #599] Epoch: [4/5][0/15]	Loss: 1.016414
[INFO][17:45:38]: [Client #874] Woke up.
[INFO][17:45:38]: [Client #874] Epoch: [3/5][0/16]	Loss: 0.780466
[INFO][17:45:38]: [Client #599] Epoch: [4/5][10/15]	Loss: 0.905093
[INFO][17:45:38]: [Client #599] Going to sleep for 0.03 seconds.
[INFO][17:45:38]: [Client #874] Epoch: [3/5][10/16]	Loss: 0.657173
[INFO][17:45:38]: [Client #599] Woke up.
[INFO][17:45:38]: [Client #599] Epoch: [5/5][0/15]	Loss: 0.391061
[INFO][17:45:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][17:45:38]: [Client #599] Epoch: [5/5][10/15]	Loss: 1.041520
[INFO][17:45:38]: [Client #599] Going to sleep for 0.03 seconds.
[INFO][17:45:38]: [Client #599] Woke up.
[INFO][17:45:38]: [Client #599] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_599_615874.pth.
[INFO][17:45:38]: [Client #874] Woke up.
[INFO][17:45:38]: [Client #874] Epoch: [4/5][0/16]	Loss: 0.095475
[INFO][17:45:38]: [Client #874] Epoch: [4/5][10/16]	Loss: 0.955802
[INFO][17:45:38]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][17:45:39]: [Client #874] Woke up.
[INFO][17:45:39]: [Client #874] Epoch: [5/5][0/16]	Loss: 0.895003
[INFO][17:45:39]: [Client #874] Epoch: [5/5][10/16]	Loss: 0.972903
[INFO][17:45:39]: [Client #874] Going to sleep for 0.12 seconds.
[INFO][17:45:39]: [Client #874] Woke up.
[INFO][17:45:39]: [Client #874] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615875.pth.
[INFO][17:45:39]: [Client #599] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_599_615874.pth.
[INFO][17:45:39]: [Client #599] Model trained.
[INFO][17:45:39]: [Client #599] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:39]: [Server #615782] Received 0.26 MB of payload data from client #599 (simulated).
[INFO][17:45:40]: [Client #874] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_874_615875.pth.
[INFO][17:45:40]: [Client #874] Model trained.
[INFO][17:45:40]: [Client #874] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:40]: [Server #615782] Received 0.26 MB of payload data from client #874 (simulated).
[INFO][17:45:40]: [Server #615782] Selecting client #128 for training.
[INFO][17:45:40]: [Server #615782] Sending the current model to client #128 (simulated).
[INFO][17:45:40]: [Server #615782] Sending 0.26 MB of payload data to client #128 (simulated).
[INFO][17:45:40]: [Server #615782] Selecting client #959 for training.
[INFO][17:45:40]: [Server #615782] Sending the current model to client #959 (simulated).
[INFO][17:45:40]: [Server #615782] Sending 0.26 MB of payload data to client #959 (simulated).
[INFO][17:45:40]: [Client #128] Selected by the server.
[INFO][17:45:40]: [Client #959] Selected by the server.
[INFO][17:45:40]: [Client #128] Loading its data source...
[INFO][17:45:40]: [Client #959] Loading its data source...
[INFO][17:45:40]: Data source: FEMNIST
[INFO][17:45:40]: Data source: FEMNIST
[INFO][17:45:40]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:45:40]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/959.zip.
[INFO][17:45:40]: [Client #128] Dataset size: 158
[INFO][17:45:40]: [Client #128] Sampler: all_inclusive
[INFO][17:45:40]: [Client #128] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:40]: [93m[1m[Client #128] Started training in communication round #21.[0m
2.6%5.1%7.7%10.3%12.8%15.4%18.0%20.5%23.1%25.7%28.2%30.8%33.4%35.9%38.5%41.1%43.7%46.2%48.8%51.4%53.9%56.5%59.1%61.6%64.2%66.8%69.3%71.9%74.5%77.0%79.6%82.2%84.7%87.3%89.9%92.4%95.0%97.6%100.0%[INFO][17:45:40]: Decompressing the dataset downloaded.
[INFO][17:45:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/959.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:45:40]: [Client #959] Dataset size: 150
[INFO][17:45:40]: [Client #959] Sampler: all_inclusive
[INFO][17:45:40]: [Client #959] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:45:40]: [93m[1m[Client #959] Started training in communication round #21.[0m

[INFO][17:45:42]: [Client #128] Loading the dataset.
[INFO][17:45:42]: [Client #959] Loading the dataset.
[INFO][17:45:47]: [Client #128] Epoch: [1/5][0/16]	Loss: 0.641802
[INFO][17:45:47]: [Client #128] Epoch: [1/5][10/16]	Loss: 1.003680
[INFO][17:45:47]: [Client #959] Epoch: [1/5][0/15]	Loss: 0.934955
[INFO][17:45:47]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][17:45:47]: [Client #959] Epoch: [1/5][10/15]	Loss: 1.265643
[INFO][17:45:47]: [Client #959] Going to sleep for 0.47 seconds.
[INFO][17:45:48]: [Client #959] Woke up.
[INFO][17:45:48]: [Client #959] Epoch: [2/5][0/15]	Loss: 0.632463
[INFO][17:45:48]: [Client #959] Epoch: [2/5][10/15]	Loss: 0.490866
[INFO][17:45:48]: [Client #959] Going to sleep for 0.47 seconds.
[INFO][17:45:48]: [Client #959] Woke up.
[INFO][17:45:48]: [Client #959] Epoch: [3/5][0/15]	Loss: 0.601300
[INFO][17:45:48]: [Client #959] Epoch: [3/5][10/15]	Loss: 1.511613
[INFO][17:45:49]: [Client #959] Going to sleep for 0.47 seconds.
[INFO][17:45:49]: [Client #959] Woke up.
[INFO][17:45:49]: [Client #959] Epoch: [4/5][0/15]	Loss: 0.326948
[INFO][17:45:49]: [Client #959] Epoch: [4/5][10/15]	Loss: 0.663878
[INFO][17:45:49]: [Client #959] Going to sleep for 0.47 seconds.
[INFO][17:45:50]: [Client #959] Woke up.
[INFO][17:45:50]: [Client #959] Epoch: [5/5][0/15]	Loss: 0.350703
[INFO][17:45:50]: [Client #959] Epoch: [5/5][10/15]	Loss: 0.112310
[INFO][17:45:50]: [Client #959] Going to sleep for 0.47 seconds.
[INFO][17:45:50]: [Client #959] Woke up.
[INFO][17:45:50]: [Client #959] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_959_615875.pth.
[INFO][17:45:51]: [Client #959] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_959_615875.pth.
[INFO][17:45:51]: [Client #959] Model trained.
[INFO][17:45:51]: [Client #959] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:45:51]: [Server #615782] Received 0.26 MB of payload data from client #959 (simulated).
[INFO][17:45:53]: [Client #128] Woke up.
[INFO][17:45:53]: [Client #128] Epoch: [2/5][0/16]	Loss: 0.320277
[INFO][17:45:53]: [Client #128] Epoch: [2/5][10/16]	Loss: 0.795020
[INFO][17:45:53]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][17:45:58]: [Client #128] Woke up.
[INFO][17:45:58]: [Client #128] Epoch: [3/5][0/16]	Loss: 0.398510
[INFO][17:45:58]: [Client #128] Epoch: [3/5][10/16]	Loss: 0.190942
[INFO][17:45:58]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][17:46:04]: [Client #128] Woke up.
[INFO][17:46:04]: [Client #128] Epoch: [4/5][0/16]	Loss: 0.035658
[INFO][17:46:04]: [Client #128] Epoch: [4/5][10/16]	Loss: 2.126649
[INFO][17:46:04]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][17:46:09]: [Client #128] Woke up.
[INFO][17:46:09]: [Client #128] Epoch: [5/5][0/16]	Loss: 0.567115
[INFO][17:46:09]: [Client #128] Epoch: [5/5][10/16]	Loss: 0.785602
[INFO][17:46:09]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][17:46:14]: [Client #128] Woke up.
[INFO][17:46:14]: [Client #128] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_615874.pth.
[INFO][17:46:15]: [Client #128] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_615874.pth.
[INFO][17:46:15]: [Client #128] Model trained.
[INFO][17:46:15]: [Client #128] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:46:15]: [Server #615782] Received 0.26 MB of payload data from client #128 (simulated).
[INFO][17:46:15]: [Server #615782] Selecting client #685 for training.
[INFO][17:46:15]: [Server #615782] Sending the current model to client #685 (simulated).
[INFO][17:46:15]: [Server #615782] Sending 0.26 MB of payload data to client #685 (simulated).
[INFO][17:46:15]: [Server #615782] Selecting client #743 for training.
[INFO][17:46:15]: [Server #615782] Sending the current model to client #743 (simulated).
[INFO][17:46:15]: [Server #615782] Sending 0.26 MB of payload data to client #743 (simulated).
[INFO][17:46:15]: [Client #685] Selected by the server.
[INFO][17:46:15]: [Client #685] Loading its data source...
[INFO][17:46:15]: Data source: FEMNIST
[INFO][17:46:15]: [Client #743] Selected by the server.
[INFO][17:46:15]: [Client #743] Loading its data source...
[INFO][17:46:15]: Data source: FEMNIST
[INFO][17:46:15]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:46:15]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/743.zip.
[INFO][17:46:15]: [Client #685] Dataset size: 152
[INFO][17:46:15]: [Client #685] Sampler: all_inclusive
[INFO][17:46:15]: [Client #685] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:46:15]: [93m[1m[Client #685] Started training in communication round #21.[0m
2.5%4.9%7.4%9.9%12.3%14.8%17.2%19.7%22.2%24.6%27.1%29.6%32.0%34.5%36.9%39.4%41.9%44.3%46.8%49.3%51.7%54.2%56.6%59.1%61.6%64.0%66.5%69.0%71.4%73.9%76.3%78.8%81.3%83.7%86.2%88.7%91.1%93.6%96.1%98.5%100.0%[INFO][17:46:15]: Decompressing the dataset downloaded.
[INFO][17:46:15]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/743.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:46:16]: [Client #743] Dataset size: 160
[INFO][17:46:16]: [Client #743] Sampler: all_inclusive
[INFO][17:46:16]: [Client #743] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:46:16]: [93m[1m[Client #743] Started training in communication round #21.[0m

[INFO][17:46:17]: [Client #685] Loading the dataset.
[INFO][17:46:18]: [Client #743] Loading the dataset.
[INFO][17:46:23]: [Client #743] Epoch: [1/5][0/16]	Loss: 0.812839
[INFO][17:46:23]: [Client #685] Epoch: [1/5][0/16]	Loss: 1.057926
[INFO][17:46:23]: [Client #743] Epoch: [1/5][10/16]	Loss: 1.709346
[INFO][17:46:23]: [Client #685] Epoch: [1/5][10/16]	Loss: 0.929154
[INFO][17:46:23]: [Client #743] Going to sleep for 0.48 seconds.
[INFO][17:46:23]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][17:46:24]: [Client #743] Woke up.
[INFO][17:46:24]: [Client #743] Epoch: [2/5][0/16]	Loss: 0.659143
[INFO][17:46:24]: [Client #743] Epoch: [2/5][10/16]	Loss: 1.726238
[INFO][17:46:24]: [Client #685] Woke up.
[INFO][17:46:24]: [Client #743] Going to sleep for 0.48 seconds.
[INFO][17:46:24]: [Client #685] Epoch: [2/5][0/16]	Loss: 0.374771
[INFO][17:46:24]: [Client #685] Epoch: [2/5][10/16]	Loss: 1.269355
[INFO][17:46:24]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][17:46:24]: [Client #743] Woke up.
[INFO][17:46:24]: [Client #743] Epoch: [3/5][0/16]	Loss: 1.458072
[INFO][17:46:24]: [Client #743] Epoch: [3/5][10/16]	Loss: 1.366870
[INFO][17:46:24]: [Client #743] Going to sleep for 0.48 seconds.
[INFO][17:46:25]: [Client #685] Woke up.
[INFO][17:46:25]: [Client #685] Epoch: [3/5][0/16]	Loss: 0.304011
[INFO][17:46:25]: [Client #685] Epoch: [3/5][10/16]	Loss: 0.995206
[INFO][17:46:25]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][17:46:25]: [Client #743] Woke up.
[INFO][17:46:25]: [Client #743] Epoch: [4/5][0/16]	Loss: 1.232918
[INFO][17:46:25]: [Client #743] Epoch: [4/5][10/16]	Loss: 0.669675
[INFO][17:46:25]: [Client #743] Going to sleep for 0.48 seconds.
[INFO][17:46:25]: [Client #685] Woke up.
[INFO][17:46:25]: [Client #685] Epoch: [4/5][0/16]	Loss: 0.737650
[INFO][17:46:25]: [Client #685] Epoch: [4/5][10/16]	Loss: 0.631806
[INFO][17:46:25]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][17:46:26]: [Client #743] Woke up.
[INFO][17:46:26]: [Client #743] Epoch: [5/5][0/16]	Loss: 0.882257
[INFO][17:46:26]: [Client #743] Epoch: [5/5][10/16]	Loss: 0.636482
[INFO][17:46:26]: [Client #743] Going to sleep for 0.48 seconds.
[INFO][17:46:26]: [Client #685] Woke up.
[INFO][17:46:26]: [Client #685] Epoch: [5/5][0/16]	Loss: 0.745355
[INFO][17:46:26]: [Client #743] Woke up.
[INFO][17:46:26]: [Client #685] Epoch: [5/5][10/16]	Loss: 0.733619
[INFO][17:46:26]: [Client #743] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_743_615875.pth.
[INFO][17:46:26]: [Client #685] Going to sleep for 0.60 seconds.
[INFO][17:46:27]: [Client #685] Woke up.
[INFO][17:46:27]: [Client #685] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_685_615874.pth.
[INFO][17:46:27]: [Client #743] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_743_615875.pth.
[INFO][17:46:27]: [Client #743] Model trained.
[INFO][17:46:27]: [Client #743] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:46:27]: [Server #615782] Received 0.26 MB of payload data from client #743 (simulated).
[INFO][17:46:27]: [Client #685] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_685_615874.pth.
[INFO][17:46:27]: [Client #685] Model trained.
[INFO][17:46:28]: [Client #685] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:46:28]: [Server #615782] Received 0.26 MB of payload data from client #685 (simulated).
[INFO][17:46:28]: [Server #615782] Selecting client #983 for training.
[INFO][17:46:28]: [Server #615782] Sending the current model to client #983 (simulated).
[INFO][17:46:28]: [Server #615782] Sending 0.26 MB of payload data to client #983 (simulated).
[INFO][17:46:28]: [Server #615782] Selecting client #416 for training.
[INFO][17:46:28]: [Server #615782] Sending the current model to client #416 (simulated).
[INFO][17:46:28]: [Server #615782] Sending 0.26 MB of payload data to client #416 (simulated).
[INFO][17:46:28]: [Client #983] Selected by the server.
[INFO][17:46:28]: [Client #983] Loading its data source...
[INFO][17:46:28]: Data source: FEMNIST
[INFO][17:46:28]: [Client #416] Selected by the server.
[INFO][17:46:28]: [Client #416] Loading its data source...
[INFO][17:46:28]: Data source: FEMNIST
[INFO][17:46:28]: [Client #416] Dataset size: 157
[INFO][17:46:28]: [Client #416] Sampler: all_inclusive
[INFO][17:46:28]: [Client #983] Dataset size: 155
[INFO][17:46:28]: [Client #983] Sampler: all_inclusive
[INFO][17:46:28]: [Client #416] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:46:28]: [Client #983] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:46:28]: [93m[1m[Client #983] Started training in communication round #21.[0m
[INFO][17:46:28]: [93m[1m[Client #416] Started training in communication round #21.[0m
[INFO][17:46:30]: [Client #416] Loading the dataset.
[INFO][17:46:30]: [Client #983] Loading the dataset.
[INFO][17:46:36]: [Client #416] Epoch: [1/5][0/16]	Loss: 1.262342
[INFO][17:46:36]: [Client #983] Epoch: [1/5][0/16]	Loss: 0.072901
[INFO][17:46:36]: [Client #416] Epoch: [1/5][10/16]	Loss: 0.529049
[INFO][17:46:36]: [Client #983] Epoch: [1/5][10/16]	Loss: 0.326004
[INFO][17:46:36]: [Client #416] Going to sleep for 0.52 seconds.
[INFO][17:46:36]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:46:36]: [Client #416] Woke up.
[INFO][17:46:36]: [Client #416] Epoch: [2/5][0/16]	Loss: 1.444087
[INFO][17:46:36]: [Client #416] Epoch: [2/5][10/16]	Loss: 0.434407
[INFO][17:46:37]: [Client #416] Going to sleep for 0.52 seconds.
[INFO][17:46:37]: [Client #416] Woke up.
[INFO][17:46:37]: [Client #416] Epoch: [3/5][0/16]	Loss: 0.126325
[INFO][17:46:37]: [Client #416] Epoch: [3/5][10/16]	Loss: 0.343148
[INFO][17:46:37]: [Client #416] Going to sleep for 0.52 seconds.
[INFO][17:46:38]: [Client #416] Woke up.
[INFO][17:46:38]: [Client #416] Epoch: [4/5][0/16]	Loss: 0.685993
[INFO][17:46:38]: [Client #416] Epoch: [4/5][10/16]	Loss: 1.441715
[INFO][17:46:38]: [Client #416] Going to sleep for 0.52 seconds.
[INFO][17:46:38]: [Client #416] Woke up.
[INFO][17:46:38]: [Client #416] Epoch: [5/5][0/16]	Loss: 0.914334
[INFO][17:46:38]: [Client #416] Epoch: [5/5][10/16]	Loss: 0.321089
[INFO][17:46:39]: [Client #416] Going to sleep for 0.52 seconds.
[INFO][17:46:39]: [Client #416] Woke up.
[INFO][17:46:39]: [Client #416] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_416_615875.pth.
[INFO][17:46:40]: [Client #416] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_416_615875.pth.
[INFO][17:46:40]: [Client #416] Model trained.
[INFO][17:46:40]: [Client #416] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:46:40]: [Server #615782] Received 0.26 MB of payload data from client #416 (simulated).
[INFO][17:46:43]: [Client #983] Woke up.
[INFO][17:46:43]: [Client #983] Epoch: [2/5][0/16]	Loss: 0.605521
[INFO][17:46:43]: [Client #983] Epoch: [2/5][10/16]	Loss: 0.156519
[INFO][17:46:43]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:46:49]: [Client #983] Woke up.
[INFO][17:46:49]: [Client #983] Epoch: [3/5][0/16]	Loss: 0.435068
[INFO][17:46:50]: [Client #983] Epoch: [3/5][10/16]	Loss: 0.047395
[INFO][17:46:50]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:46:56]: [Client #983] Woke up.
[INFO][17:46:56]: [Client #983] Epoch: [4/5][0/16]	Loss: 0.215575
[INFO][17:46:56]: [Client #983] Epoch: [4/5][10/16]	Loss: 0.466922
[INFO][17:46:56]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:47:03]: [Client #983] Woke up.
[INFO][17:47:03]: [Client #983] Epoch: [5/5][0/16]	Loss: 0.124529
[INFO][17:47:03]: [Client #983] Epoch: [5/5][10/16]	Loss: 0.064643
[INFO][17:47:03]: [Client #983] Going to sleep for 6.70 seconds.
[INFO][17:47:10]: [Client #983] Woke up.
[INFO][17:47:10]: [Client #983] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_983_615874.pth.
[INFO][17:47:11]: [Client #983] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_983_615874.pth.
[INFO][17:47:11]: [Client #983] Model trained.
[INFO][17:47:11]: [Client #983] Sent 0.26 MB of payload data to the server (simulated).
[INFO][17:47:11]: [Server #615782] Received 0.26 MB of payload data from client #983 (simulated).
[INFO][17:47:11]: [Server #615782] Selecting client #532 for training.
[INFO][17:47:11]: [Server #615782] Sending the current model to client #532 (simulated).
[INFO][17:47:11]: [Server #615782] Sending 0.26 MB of payload data to client #532 (simulated).
[INFO][17:47:11]: [Server #615782] Selecting client #681 for training.
[INFO][17:47:11]: [Server #615782] Sending the current model to client #681 (simulated).
[INFO][17:47:11]: [Server #615782] Sending 0.26 MB of payload data to client #681 (simulated).
[INFO][17:47:11]: [Client #532] Selected by the server.
[INFO][17:47:11]: [Client #532] Loading its data source...
[INFO][17:47:11]: Data source: FEMNIST
[INFO][17:47:11]: [Client #681] Selected by the server.
[INFO][17:47:11]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][17:47:11]: [Client #681] Loading its data source...
[INFO][17:47:11]: Data source: FEMNIST
[INFO][17:47:11]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/532.zip.
[INFO][17:47:11]: [Client #681] Dataset size: 147
[INFO][17:47:11]: [Client #681] Sampler: all_inclusive
[INFO][17:47:11]: [Client #681] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:47:11]: [93m[1m[Client #681] Started training in communication round #21.[0m
3.1%6.2%9.3%12.4%15.5%18.6%21.6%24.7%27.8%30.9%34.0%37.1%40.2%43.3%46.4%49.5%52.6%55.7%58.8%61.8%64.9%68.0%71.1%74.2%77.3%80.4%83.5%86.6%89.7%92.8%95.9%99.0%100.0%[INFO][17:47:11]: Decompressing the dataset downloaded.
[INFO][17:47:11]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/532.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][17:47:11]: [Client #532] Dataset size: 147
[INFO][17:47:11]: [Client #532] Sampler: all_inclusive
[INFO][17:47:11]: [Client #532] Received 0.26 MB of payload data from the server (simulated).
[INFO][17:47:11]: [93m[1m[Client #532] Started training in communication round #21.[0m

[INFO][17:47:13]: [Client #681] Loading the dataset.
[INFO][17:47:13]: [Client #532] Loading the dataset.
slurmstepd-sim: error: *** JOB 2912 ON sim CANCELLED AT 2022-07-08T17:47:14 ***
