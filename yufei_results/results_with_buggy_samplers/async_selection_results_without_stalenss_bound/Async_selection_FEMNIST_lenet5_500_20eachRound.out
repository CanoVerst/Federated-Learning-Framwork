[INFO][07:58:54]: [Server #554754] Started training on 500 clients with 20 per round.
[INFO][07:58:54]: [Server #554754] Configuring the server...
[INFO][07:58:54]: Training: 100 rounds or accuracy above 98.0%

[INFO][07:58:54]: Trainer: basic
[INFO][07:58:54]: Algorithm: fedavg
[INFO][07:58:54]: Data source: FEMNIST
[INFO][07:59:05]: Starting client #1's process.
[INFO][07:59:05]: Starting client #2's process.
[INFO][07:59:05]: Setting the random seed for selecting clients: 1
[INFO][07:59:05]: Starting a server at address 127.0.0.1 and port 6300.
[INFO][07:59:07]: Client: simple
[INFO][07:59:07]: Starting a simple client #1.
[INFO][07:59:07]: Trainer: basic
[INFO][07:59:07]: Client: simple
[INFO][07:59:07]: Starting a simple client #2.
[INFO][07:59:07]: Trainer: basic
[INFO][07:59:07]: Algorithm: fedavg
[INFO][07:59:07]: Algorithm: fedavg
[INFO][07:59:12]: [Client #1] Contacting the server.
[INFO][07:59:12]: [Client #1] Connecting to the server at http://127.0.0.1:6300.
[INFO][07:59:12]: [Client #2] Contacting the server.
[INFO][07:59:12]: [Client #2] Connecting to the server at http://127.0.0.1:6300.
[INFO][07:59:12]: 127.0.0.1 [08/Jul/2022:11:59:12 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1657281552.4333744 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.1"
[INFO][07:59:12]: 127.0.0.1 [08/Jul/2022:11:59:12 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1657281552.4343448 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.1"
[INFO][07:59:12]: [Server #554754] A new client just connected.
[INFO][07:59:12]: [Server #554754] A new client just connected.
[INFO][07:59:12]: [Client #2] Connected to the server.
[INFO][07:59:12]: [Client #1] Connected to the server.
[INFO][07:59:12]: [Client #2] Waiting to be selected.
[INFO][07:59:12]: [Client #1] Waiting to be selected.
[INFO][07:59:12]: [Server #554754] New client with id #2 arrived.
[INFO][07:59:12]: [Server #554754] New client with id #1 arrived.
[INFO][07:59:12]: [Server #554754] Starting training.
[INFO][07:59:12]: [93m[1m
[Server #554754] Starting round 1/100.[0m
[INFO][07:59:12]: [Server #554754] Selected clients: [ 44 114 158  88 304 207 409  93 351 121 288 175  29 115 333 249 260 286
 499 411]
[INFO][07:59:12]: [Server #554754] Selecting client #44 for training.
[INFO][07:59:12]: [Server #554754] Sending the current model to client #44 (simulated).
[INFO][07:59:12]: [Server #554754] Sending 0.26 MB of payload data to client #44 (simulated).
[INFO][07:59:12]: [Server #554754] Selecting client #114 for training.
[INFO][07:59:12]: [Server #554754] Sending the current model to client #114 (simulated).
[INFO][07:59:12]: [Server #554754] Sending 0.26 MB of payload data to client #114 (simulated).
[INFO][07:59:12]: [Client #44] Selected by the server.
[INFO][07:59:12]: [Client #114] Selected by the server.
[INFO][07:59:12]: [Client #44] Loading its data source...
[INFO][07:59:12]: Data source: FEMNIST
[INFO][07:59:12]: [Client #114] Loading its data source...
[INFO][07:59:12]: Data source: FEMNIST
[INFO][07:59:12]: [Client #44] Dataset size: 166
[INFO][07:59:12]: [Client #44] Sampler: all_inclusive
[INFO][07:59:12]: [Client #44] Received 0.26 MB of payload data from the server (simulated).
[INFO][07:59:12]: [Client #114] Dataset size: 153
[INFO][07:59:12]: [Client #114] Sampler: all_inclusive
[INFO][07:59:12]: [Client #114] Received 0.26 MB of payload data from the server (simulated).
[INFO][07:59:12]: [93m[1m[Client #44] Started training in communication round #1.[0m
[INFO][07:59:12]: [93m[1m[Client #114] Started training in communication round #1.[0m
[INFO][07:59:14]: [Client #44] Loading the dataset.
[INFO][07:59:14]: [Client #114] Loading the dataset.
[INFO][07:59:20]: [Client #114] Epoch: [1/5][0/16]	Loss: 4.178714
[INFO][07:59:20]: [Client #44] Epoch: [1/5][0/17]	Loss: 4.125518
[INFO][07:59:20]: [Client #114] Epoch: [1/5][10/16]	Loss: 4.125021
[INFO][07:59:20]: [Client #114] Going to sleep for 2.30 seconds.
[INFO][07:59:20]: [Client #44] Epoch: [1/5][10/17]	Loss: 4.084116
[INFO][07:59:20]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][07:59:22]: [Client #114] Woke up.
[INFO][07:59:22]: [Client #114] Epoch: [2/5][0/16]	Loss: 4.001937
[INFO][07:59:22]: [Client #114] Epoch: [2/5][10/16]	Loss: 3.008393
[INFO][07:59:22]: [Client #114] Going to sleep for 2.30 seconds.
[INFO][07:59:24]: [Client #44] Woke up.
[INFO][07:59:24]: [Client #44] Epoch: [2/5][0/17]	Loss: 3.899535
[INFO][07:59:24]: [Client #44] Epoch: [2/5][10/17]	Loss: 3.623446
[INFO][07:59:24]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][07:59:25]: [Client #114] Woke up.
[INFO][07:59:25]: [Client #114] Epoch: [3/5][0/16]	Loss: 3.631728
[INFO][07:59:25]: [Client #114] Epoch: [3/5][10/16]	Loss: 3.958916
[INFO][07:59:25]: [Client #114] Going to sleep for 2.30 seconds.
[INFO][07:59:27]: [Client #114] Woke up.
[INFO][07:59:27]: [Client #114] Epoch: [4/5][0/16]	Loss: 3.685633
[INFO][07:59:27]: [Client #114] Epoch: [4/5][10/16]	Loss: 3.621414
[INFO][07:59:27]: [Client #114] Going to sleep for 2.30 seconds.
[INFO][07:59:28]: [Client #44] Woke up.
[INFO][07:59:28]: [Client #44] Epoch: [3/5][0/17]	Loss: 3.004637
[INFO][07:59:28]: [Client #44] Epoch: [3/5][10/17]	Loss: 3.545879
[INFO][07:59:28]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][07:59:30]: [Client #114] Woke up.
[INFO][07:59:30]: [Client #114] Epoch: [5/5][0/16]	Loss: 3.667646
[INFO][07:59:30]: [Client #114] Epoch: [5/5][10/16]	Loss: 3.533390
[INFO][07:59:30]: [Client #114] Going to sleep for 2.30 seconds.
[INFO][07:59:32]: [Client #44] Woke up.
[INFO][07:59:32]: [Client #44] Epoch: [4/5][0/17]	Loss: 3.402274
[INFO][07:59:32]: [Client #44] Epoch: [4/5][10/17]	Loss: 2.891125
[INFO][07:59:32]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][07:59:32]: [Client #114] Woke up.
[INFO][07:59:32]: [Client #114] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_114_554860.pth.
[INFO][07:59:33]: [Client #114] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_114_554860.pth.
[INFO][07:59:33]: [Client #114] Model trained.
[INFO][07:59:33]: [Client #114] Sent 0.26 MB of payload data to the server (simulated).
[INFO][07:59:33]: [Server #554754] Received 0.26 MB of payload data from client #114 (simulated).
[INFO][07:59:36]: [Client #44] Woke up.
[INFO][07:59:36]: [Client #44] Epoch: [5/5][0/17]	Loss: 3.415693
[INFO][07:59:36]: [Client #44] Epoch: [5/5][10/17]	Loss: 3.517567
[INFO][07:59:36]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][07:59:40]: [Client #44] Woke up.
[INFO][07:59:40]: [Client #44] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_554853.pth.
[INFO][07:59:40]: [Client #44] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_554853.pth.
[INFO][07:59:40]: [Client #44] Model trained.
[INFO][07:59:40]: [Client #44] Sent 0.26 MB of payload data to the server (simulated).
[INFO][07:59:40]: [Server #554754] Received 0.26 MB of payload data from client #44 (simulated).
[INFO][07:59:40]: [Server #554754] Selecting client #158 for training.
[INFO][07:59:40]: [Server #554754] Sending the current model to client #158 (simulated).
[INFO][07:59:40]: [Server #554754] Sending 0.26 MB of payload data to client #158 (simulated).
[INFO][07:59:40]: [Server #554754] Selecting client #88 for training.
[INFO][07:59:40]: [Server #554754] Sending the current model to client #88 (simulated).
[INFO][07:59:40]: [Server #554754] Sending 0.26 MB of payload data to client #88 (simulated).
[INFO][07:59:40]: [Client #158] Selected by the server.
[INFO][07:59:40]: [Client #158] Loading its data source...
[INFO][07:59:40]: Data source: FEMNIST
[INFO][07:59:40]: [Client #88] Selected by the server.
[INFO][07:59:40]: [Client #88] Loading its data source...
[INFO][07:59:40]: Data source: FEMNIST
[INFO][07:59:40]: [Client #158] Dataset size: 162
[INFO][07:59:40]: [Client #158] Sampler: all_inclusive
[INFO][07:59:40]: [Client #158] Received 0.26 MB of payload data from the server (simulated).
[INFO][07:59:40]: [93m[1m[Client #158] Started training in communication round #1.[0m
[INFO][07:59:40]: [Client #88] Dataset size: 162
[INFO][07:59:40]: [Client #88] Sampler: all_inclusive
[INFO][07:59:40]: [Client #88] Received 0.26 MB of payload data from the server (simulated).
[INFO][07:59:40]: [93m[1m[Client #88] Started training in communication round #1.[0m
[INFO][07:59:42]: [Client #88] Loading the dataset.
[INFO][07:59:42]: [Client #158] Loading the dataset.
[INFO][07:59:48]: [Client #88] Epoch: [1/5][0/17]	Loss: 4.149095
[INFO][07:59:48]: [Client #158] Epoch: [1/5][0/17]	Loss: 4.134685
[INFO][07:59:48]: [Client #88] Epoch: [1/5][10/17]	Loss: 4.058154
[INFO][07:59:48]: [Client #158] Epoch: [1/5][10/17]	Loss: 4.003385
[INFO][07:59:48]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][07:59:48]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][07:59:49]: [Client #158] Woke up.
[INFO][07:59:49]: [Client #158] Epoch: [2/5][0/17]	Loss: 3.952987
[INFO][07:59:49]: [Client #158] Epoch: [2/5][10/17]	Loss: 3.689994
[INFO][07:59:49]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][07:59:51]: [Client #158] Woke up.
[INFO][07:59:51]: [Client #158] Epoch: [3/5][0/17]	Loss: 3.738657
[INFO][07:59:51]: [Client #158] Epoch: [3/5][10/17]	Loss: 3.290862
[INFO][07:59:51]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][07:59:52]: [Client #158] Woke up.
[INFO][07:59:52]: [Client #158] Epoch: [4/5][0/17]	Loss: 3.461428
[INFO][07:59:52]: [Client #158] Epoch: [4/5][10/17]	Loss: 3.261194
[INFO][07:59:52]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][07:59:54]: [Client #158] Woke up.
[INFO][07:59:54]: [Client #158] Epoch: [5/5][0/17]	Loss: 3.027766
[INFO][07:59:54]: [Client #158] Epoch: [5/5][10/17]	Loss: 3.325196
[INFO][07:59:54]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][07:59:55]: [Client #158] Woke up.
[INFO][07:59:55]: [Client #158] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_158_554853.pth.
[INFO][07:59:56]: [Client #158] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_158_554853.pth.
[INFO][07:59:56]: [Client #158] Model trained.
[INFO][07:59:56]: [Client #158] Sent 0.26 MB of payload data to the server (simulated).
[INFO][07:59:56]: [Server #554754] Received 0.26 MB of payload data from client #158 (simulated).
[INFO][08:00:15]: [Client #88] Woke up.
[INFO][08:00:15]: [Client #88] Epoch: [2/5][0/17]	Loss: 3.943983
[INFO][08:00:15]: [Client #88] Epoch: [2/5][10/17]	Loss: 3.871128
[INFO][08:00:16]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][08:00:43]: [Client #88] Woke up.
[INFO][08:00:43]: [Client #88] Epoch: [3/5][0/17]	Loss: 3.535879
[INFO][08:00:43]: [Client #88] Epoch: [3/5][10/17]	Loss: 3.241128
[INFO][08:00:43]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][08:01:11]: [Client #88] Woke up.
[INFO][08:01:11]: [Client #88] Epoch: [4/5][0/17]	Loss: 2.918903
[INFO][08:01:11]: [Client #88] Epoch: [4/5][10/17]	Loss: 3.564667
[INFO][08:01:11]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][08:01:38]: [Client #88] Woke up.
[INFO][08:01:39]: [Client #88] Epoch: [5/5][0/17]	Loss: 3.152083
[INFO][08:01:39]: [Client #88] Epoch: [5/5][10/17]	Loss: 3.368505
[INFO][08:01:39]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][08:02:06]: [Client #88] Woke up.
[INFO][08:02:06]: [Client #88] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_554860.pth.
[INFO][08:02:07]: [Client #88] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_554860.pth.
[INFO][08:02:07]: [Client #88] Model trained.
[INFO][08:02:07]: [Client #88] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:07]: [Server #554754] Received 0.26 MB of payload data from client #88 (simulated).
[INFO][08:02:07]: [Server #554754] Selecting client #304 for training.
[INFO][08:02:07]: [Server #554754] Sending the current model to client #304 (simulated).
[INFO][08:02:07]: [Server #554754] Sending 0.26 MB of payload data to client #304 (simulated).
[INFO][08:02:07]: [Server #554754] Selecting client #207 for training.
[INFO][08:02:07]: [Server #554754] Sending the current model to client #207 (simulated).
[INFO][08:02:07]: [Server #554754] Sending 0.26 MB of payload data to client #207 (simulated).
[INFO][08:02:07]: [Client #304] Selected by the server.
[INFO][08:02:07]: [Client #304] Loading its data source...
[INFO][08:02:07]: [Client #207] Selected by the server.
[INFO][08:02:07]: Data source: FEMNIST
[INFO][08:02:07]: [Client #207] Loading its data source...
[INFO][08:02:07]: Data source: FEMNIST
[INFO][08:02:07]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:02:07]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/304.zip.
[INFO][08:02:07]: [Client #207] Dataset size: 162
[INFO][08:02:07]: [Client #207] Sampler: all_inclusive
[INFO][08:02:07]: [Client #207] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:07]: [93m[1m[Client #207] Started training in communication round #1.[0m

2.6%
5.3%
7.9%
10.6%
13.2%
15.8%
18.5%
21.1%
23.8%
26.4%
29.0%
31.7%
34.3%
37.0%
39.6%
42.2%
44.9%
47.5%
50.2%
52.8%
55.4%
58.1%
60.7%
63.4%
66.0%
68.7%
71.3%
73.9%
76.6%
79.2%
81.9%
84.5%
87.1%
89.8%
92.4%
95.1%
97.7%
100.0%[INFO][08:02:07]: Decompressing the dataset downloaded.
[INFO][08:02:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/304.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:02:07]: [Client #304] Dataset size: 150
[INFO][08:02:07]: [Client #304] Sampler: all_inclusive
[INFO][08:02:07]: [Client #304] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:07]: [93m[1m[Client #304] Started training in communication round #1.[0m

[INFO][08:02:09]: [Client #207] Loading the dataset.
[INFO][08:02:09]: [Client #304] Loading the dataset.
[INFO][08:02:15]: [Client #304] Epoch: [1/5][0/15]	Loss: 4.122801
[INFO][08:02:15]: [Client #207] Epoch: [1/5][0/17]	Loss: 4.136867
[INFO][08:02:15]: [Client #304] Epoch: [1/5][10/15]	Loss: 4.025156
[INFO][08:02:15]: [Client #207] Epoch: [1/5][10/17]	Loss: 4.158442
[INFO][08:02:15]: [Client #304] Going to sleep for 1.32 seconds.
[INFO][08:02:15]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][08:02:16]: [Client #304] Woke up.
[INFO][08:02:16]: [Client #304] Epoch: [2/5][0/15]	Loss: 4.049147
[INFO][08:02:16]: [Client #304] Epoch: [2/5][10/15]	Loss: 3.547444
[INFO][08:02:16]: [Client #304] Going to sleep for 1.32 seconds.
[INFO][08:02:16]: [Client #207] Woke up.
[INFO][08:02:16]: [Client #207] Epoch: [2/5][0/17]	Loss: 3.829849
[INFO][08:02:16]: [Client #207] Epoch: [2/5][10/17]	Loss: 3.613223
[INFO][08:02:16]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][08:02:17]: [Client #304] Woke up.
[INFO][08:02:17]: [Client #304] Epoch: [3/5][0/15]	Loss: 3.232458
[INFO][08:02:18]: [Client #304] Epoch: [3/5][10/15]	Loss: 3.442863
[INFO][08:02:18]: [Client #304] Going to sleep for 1.32 seconds.
[INFO][08:02:18]: [Client #207] Woke up.
[INFO][08:02:18]: [Client #207] Epoch: [3/5][0/17]	Loss: 3.773412
[INFO][08:02:18]: [Client #207] Epoch: [3/5][10/17]	Loss: 3.606044
[INFO][08:02:18]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][08:02:19]: [Client #304] Woke up.
[INFO][08:02:19]: [Client #304] Epoch: [4/5][0/15]	Loss: 2.816712
[INFO][08:02:19]: [Client #304] Epoch: [4/5][10/15]	Loss: 3.129117
[INFO][08:02:19]: [Client #304] Going to sleep for 1.32 seconds.
[INFO][08:02:20]: [Client #207] Woke up.
[INFO][08:02:20]: [Client #207] Epoch: [4/5][0/17]	Loss: 3.445837
[INFO][08:02:20]: [Client #207] Epoch: [4/5][10/17]	Loss: 3.534724
[INFO][08:02:20]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][08:02:20]: [Client #304] Woke up.
[INFO][08:02:20]: [Client #304] Epoch: [5/5][0/15]	Loss: 3.349769
[INFO][08:02:20]: [Client #304] Epoch: [5/5][10/15]	Loss: 3.251812
[INFO][08:02:20]: [Client #304] Going to sleep for 1.32 seconds.
[INFO][08:02:21]: [Client #207] Woke up.
[INFO][08:02:21]: [Client #207] Epoch: [5/5][0/17]	Loss: 2.925943
[INFO][08:02:21]: [Client #207] Epoch: [5/5][10/17]	Loss: 2.870192
[INFO][08:02:21]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][08:02:22]: [Client #304] Woke up.
[INFO][08:02:22]: [Client #304] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_304_554853.pth.
[INFO][08:02:22]: [Client #304] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_304_554853.pth.
[INFO][08:02:22]: [Client #304] Model trained.
[INFO][08:02:23]: [Client #304] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:23]: [Server #554754] Received 0.26 MB of payload data from client #304 (simulated).
[INFO][08:02:23]: [Client #207] Woke up.
[INFO][08:02:23]: [Client #207] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554860.pth.
[INFO][08:02:24]: [Client #207] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554860.pth.
[INFO][08:02:24]: [Client #207] Model trained.
[INFO][08:02:24]: [Client #207] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:24]: [Server #554754] Received 0.26 MB of payload data from client #207 (simulated).
[INFO][08:02:24]: [Server #554754] Selecting client #409 for training.
[INFO][08:02:24]: [Server #554754] Sending the current model to client #409 (simulated).
[INFO][08:02:24]: [Server #554754] Sending 0.26 MB of payload data to client #409 (simulated).
[INFO][08:02:24]: [Server #554754] Selecting client #93 for training.
[INFO][08:02:24]: [Server #554754] Sending the current model to client #93 (simulated).
[INFO][08:02:24]: [Server #554754] Sending 0.26 MB of payload data to client #93 (simulated).
[INFO][08:02:24]: [Client #409] Selected by the server.
[INFO][08:02:24]: [Client #409] Loading its data source...
[INFO][08:02:24]: Data source: FEMNIST
[INFO][08:02:24]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:02:24]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/409.zip.
[INFO][08:02:24]: [Client #93] Selected by the server.
[INFO][08:02:24]: [Client #93] Loading its data source...
[INFO][08:02:24]: Data source: FEMNIST
[INFO][08:02:24]: [Client #93] Dataset size: 156
[INFO][08:02:24]: [Client #93] Sampler: all_inclusive
[INFO][08:02:24]: [Client #93] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:24]: [93m[1m[Client #93] Started training in communication round #1.[0m

2.4%
4.7%
7.1%
9.5%
11.8%
14.2%
16.6%
18.9%
21.3%
23.7%
26.0%
28.4%
30.8%
33.1%
35.5%
37.9%
40.3%
42.6%
45.0%
47.4%
49.7%
52.1%
54.5%
56.8%
59.2%
61.6%
63.9%
66.3%
68.7%
71.0%
73.4%
75.8%
78.1%
80.5%
82.9%
85.2%
87.6%
90.0%
92.3%
94.7%
97.1%
99.4%
100.0%[INFO][08:02:24]: Decompressing the dataset downloaded.
[INFO][08:02:24]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/409.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:02:24]: [Client #409] Dataset size: 155
[INFO][08:02:24]: [Client #409] Sampler: all_inclusive
[INFO][08:02:24]: [Client #409] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:24]: [93m[1m[Client #409] Started training in communication round #1.[0m

[INFO][08:02:26]: [Client #93] Loading the dataset.
[INFO][08:02:26]: [Client #409] Loading the dataset.
[INFO][08:02:31]: [Client #93] Epoch: [1/5][0/16]	Loss: 4.117192
[INFO][08:02:31]: [Client #409] Epoch: [1/5][0/16]	Loss: 4.113165
[INFO][08:02:31]: [Client #93] Epoch: [1/5][10/16]	Loss: 4.105248
[INFO][08:02:31]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][08:02:31]: [Client #409] Epoch: [1/5][10/16]	Loss: 4.051862
[INFO][08:02:31]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][08:02:32]: [Client #409] Woke up.
[INFO][08:02:32]: [Client #409] Epoch: [2/5][0/16]	Loss: 3.953300
[INFO][08:02:32]: [Client #409] Epoch: [2/5][10/16]	Loss: 3.866660
[INFO][08:02:32]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][08:02:32]: [Client #409] Woke up.
[INFO][08:02:32]: [Client #409] Epoch: [3/5][0/16]	Loss: 3.603877
[INFO][08:02:32]: [Client #409] Epoch: [3/5][10/16]	Loss: 3.625438
[INFO][08:02:32]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][08:02:32]: [Client #409] Woke up.
[INFO][08:02:32]: [Client #409] Epoch: [4/5][0/16]	Loss: 3.284536
[INFO][08:02:32]: [Client #409] Epoch: [4/5][10/16]	Loss: 3.079840
[INFO][08:02:32]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][08:02:32]: [Client #93] Woke up.
[INFO][08:02:32]: [Client #93] Epoch: [2/5][0/16]	Loss: 3.753998
[INFO][08:02:32]: [Client #409] Woke up.
[INFO][08:02:32]: [Client #409] Epoch: [5/5][0/16]	Loss: 3.433390
[INFO][08:02:32]: [Client #93] Epoch: [2/5][10/16]	Loss: 3.487586
[INFO][08:02:32]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][08:02:32]: [Client #409] Epoch: [5/5][10/16]	Loss: 3.272490
[INFO][08:02:32]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][08:02:32]: [Client #409] Woke up.
[INFO][08:02:32]: [Client #409] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_409_554853.pth.
[INFO][08:02:33]: [Client #409] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_409_554853.pth.
[INFO][08:02:33]: [Client #409] Model trained.
[INFO][08:02:33]: [Client #409] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:33]: [Server #554754] Received 0.26 MB of payload data from client #409 (simulated).
[INFO][08:02:33]: [Client #93] Woke up.
[INFO][08:02:33]: [Client #93] Epoch: [3/5][0/16]	Loss: 3.340518
[INFO][08:02:33]: [Client #93] Epoch: [3/5][10/16]	Loss: 3.506897
[INFO][08:02:33]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][08:02:34]: [Client #93] Woke up.
[INFO][08:02:34]: [Client #93] Epoch: [4/5][0/16]	Loss: 3.257117
[INFO][08:02:34]: [Client #93] Epoch: [4/5][10/16]	Loss: 3.597375
[INFO][08:02:34]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][08:02:35]: [Client #93] Woke up.
[INFO][08:02:35]: [Client #93] Epoch: [5/5][0/16]	Loss: 2.568257
[INFO][08:02:35]: [Client #93] Epoch: [5/5][10/16]	Loss: 3.338963
[INFO][08:02:35]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][08:02:36]: [Client #93] Woke up.
[INFO][08:02:36]: [Client #93] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_554860.pth.
[INFO][08:02:37]: [Client #93] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_554860.pth.
[INFO][08:02:37]: [Client #93] Model trained.
[INFO][08:02:37]: [Client #93] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:37]: [Server #554754] Received 0.26 MB of payload data from client #93 (simulated).
[INFO][08:02:37]: [Server #554754] Selecting client #351 for training.
[INFO][08:02:37]: [Server #554754] Sending the current model to client #351 (simulated).
[INFO][08:02:37]: [Server #554754] Sending 0.26 MB of payload data to client #351 (simulated).
[INFO][08:02:37]: [Server #554754] Selecting client #121 for training.
[INFO][08:02:37]: [Server #554754] Sending the current model to client #121 (simulated).
[INFO][08:02:37]: [Server #554754] Sending 0.26 MB of payload data to client #121 (simulated).
[INFO][08:02:37]: [Client #351] Selected by the server.
[INFO][08:02:37]: [Client #121] Selected by the server.
[INFO][08:02:37]: [Client #351] Loading its data source...
[INFO][08:02:37]: [Client #121] Loading its data source...
[INFO][08:02:37]: Data source: FEMNIST
[INFO][08:02:37]: Data source: FEMNIST
[INFO][08:02:37]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:02:37]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/351.zip.
[INFO][08:02:37]: [Client #121] Dataset size: 159
[INFO][08:02:37]: [Client #121] Sampler: all_inclusive
[INFO][08:02:37]: [Client #121] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:37]: [93m[1m[Client #121] Started training in communication round #1.[0m

2.7%
5.3%
8.0%
10.7%
13.4%
16.0%
18.7%
21.4%
24.1%
26.7%
29.4%
32.1%
34.8%
37.4%
40.1%
42.8%
45.5%
48.1%
50.8%
53.5%
56.2%
58.8%
61.5%
64.2%
66.8%
69.5%
72.2%
74.9%
77.5%
80.2%
82.9%
85.6%
88.2%
90.9%
93.6%
96.3%
98.9%
100.0%[INFO][08:02:37]: Decompressing the dataset downloaded.
[INFO][08:02:37]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/351.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:02:37]: [Client #351] Dataset size: 162
[INFO][08:02:37]: [Client #351] Sampler: all_inclusive
[INFO][08:02:37]: [Client #351] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:02:37]: [93m[1m[Client #351] Started training in communication round #1.[0m

[INFO][08:02:39]: [Client #121] Loading the dataset.
[INFO][08:02:39]: [Client #351] Loading the dataset.
[INFO][08:02:44]: [Client #121] Epoch: [1/5][0/16]	Loss: 4.151036
[INFO][08:02:44]: [Client #351] Epoch: [1/5][0/17]	Loss: 4.160186
[INFO][08:02:44]: [Client #121] Epoch: [1/5][10/16]	Loss: 4.142239
[INFO][08:02:44]: [Client #351] Epoch: [1/5][10/17]	Loss: 4.119172
[INFO][08:02:44]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][08:02:44]: [Client #121] Woke up.
[INFO][08:02:44]: [Client #121] Epoch: [2/5][0/16]	Loss: 4.019338
[INFO][08:02:44]: [Client #351] Going to sleep for 3.35 seconds.
[INFO][08:02:44]: [Client #121] Epoch: [2/5][10/16]	Loss: 3.856448
[INFO][08:02:45]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][08:02:45]: [Client #121] Woke up.
[INFO][08:02:45]: [Client #121] Epoch: [3/5][0/16]	Loss: 3.632665
[INFO][08:02:45]: [Client #121] Epoch: [3/5][10/16]	Loss: 3.462336
[INFO][08:02:45]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][08:02:45]: [Client #121] Woke up.
[INFO][08:02:45]: [Client #121] Epoch: [4/5][0/16]	Loss: 3.415565
[INFO][08:02:45]: [Client #121] Epoch: [4/5][10/16]	Loss: 3.268033
[INFO][08:02:45]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][08:02:45]: [Client #121] Woke up.
[INFO][08:02:45]: [Client #121] Epoch: [5/5][0/16]	Loss: 3.734068
[INFO][08:02:45]: [Client #121] Epoch: [5/5][10/16]	Loss: 2.761637
[INFO][08:02:45]: [Client #121] Going to sleep for 0.02 seconds.
[INFO][08:02:45]: [Client #121] Woke up.
[INFO][08:02:45]: [Client #121] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_121_554860.pth.
[INFO][08:02:46]: [Client #121] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_121_554860.pth.
[INFO][08:02:46]: [Client #121] Model trained.
[INFO][08:02:46]: [Client #121] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:02:46]: [Server #554754] Received 0.26 MB of payload data from client #121 (simulated).
[INFO][08:02:48]: [Client #351] Woke up.
[INFO][08:02:48]: [Client #351] Epoch: [2/5][0/17]	Loss: 3.857995
[INFO][08:02:48]: [Client #351] Epoch: [2/5][10/17]	Loss: 4.130952
[INFO][08:02:48]: [Client #351] Going to sleep for 3.35 seconds.
[INFO][08:02:51]: [Client #351] Woke up.
[INFO][08:02:51]: [Client #351] Epoch: [3/5][0/17]	Loss: 3.250732
[INFO][08:02:51]: [Client #351] Epoch: [3/5][10/17]	Loss: 3.602825
[INFO][08:02:51]: [Client #351] Going to sleep for 3.35 seconds.
[INFO][08:02:55]: [Client #351] Woke up.
[INFO][08:02:55]: [Client #351] Epoch: [4/5][0/17]	Loss: 3.845444
[INFO][08:02:55]: [Client #351] Epoch: [4/5][10/17]	Loss: 3.367391
[INFO][08:02:55]: [Client #351] Going to sleep for 3.35 seconds.
[INFO][08:02:58]: [Client #351] Woke up.
[INFO][08:02:58]: [Client #351] Epoch: [5/5][0/17]	Loss: 3.132508
[INFO][08:02:58]: [Client #351] Epoch: [5/5][10/17]	Loss: 3.266022
[INFO][08:02:59]: [Client #351] Going to sleep for 3.35 seconds.
[INFO][08:03:02]: [Client #351] Woke up.
[INFO][08:03:02]: [Client #351] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_351_554853.pth.
[INFO][08:03:03]: [Client #351] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_351_554853.pth.
[INFO][08:03:03]: [Client #351] Model trained.
[INFO][08:03:03]: [Client #351] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:03]: [Server #554754] Received 0.26 MB of payload data from client #351 (simulated).
[INFO][08:03:03]: [Server #554754] Selecting client #288 for training.
[INFO][08:03:03]: [Server #554754] Sending the current model to client #288 (simulated).
[INFO][08:03:03]: [Server #554754] Sending 0.26 MB of payload data to client #288 (simulated).
[INFO][08:03:03]: [Server #554754] Selecting client #175 for training.
[INFO][08:03:03]: [Server #554754] Sending the current model to client #175 (simulated).
[INFO][08:03:03]: [Server #554754] Sending 0.26 MB of payload data to client #175 (simulated).
[INFO][08:03:03]: [Client #288] Selected by the server.
[INFO][08:03:03]: [Client #288] Loading its data source...
[INFO][08:03:03]: Data source: FEMNIST
[INFO][08:03:03]: [Client #175] Selected by the server.
[INFO][08:03:03]: [Client #175] Loading its data source...
[INFO][08:03:03]: Data source: FEMNIST
[INFO][08:03:03]: [Client #175] Dataset size: 145
[INFO][08:03:03]: [Client #175] Sampler: all_inclusive
[INFO][08:03:03]: [Client #175] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:03]: [93m[1m[Client #175] Started training in communication round #1.[0m
[INFO][08:03:03]: [Client #288] Dataset size: 161
[INFO][08:03:03]: [Client #288] Sampler: all_inclusive
[INFO][08:03:03]: [Client #288] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:03]: [93m[1m[Client #288] Started training in communication round #1.[0m
[INFO][08:03:05]: [Client #288] Loading the dataset.
[INFO][08:03:05]: [Client #175] Loading the dataset.
[INFO][08:03:10]: [Client #175] Epoch: [1/5][0/15]	Loss: 4.154544
[INFO][08:03:10]: [Client #288] Epoch: [1/5][0/17]	Loss: 4.136933
[INFO][08:03:10]: [Client #175] Epoch: [1/5][10/15]	Loss: 4.116269
[INFO][08:03:10]: [Client #288] Epoch: [1/5][10/17]	Loss: 4.146233
[INFO][08:03:10]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][08:03:10]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:03:11]: [Client #175] Woke up.
[INFO][08:03:11]: [Client #175] Epoch: [2/5][0/15]	Loss: 3.905350
[INFO][08:03:12]: [Client #175] Epoch: [2/5][10/15]	Loss: 3.530829
[INFO][08:03:12]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][08:03:13]: [Client #175] Woke up.
[INFO][08:03:13]: [Client #175] Epoch: [3/5][0/15]	Loss: 3.380666
[INFO][08:03:13]: [Client #175] Epoch: [3/5][10/15]	Loss: 3.292491
[INFO][08:03:13]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][08:03:14]: [Client #175] Woke up.
[INFO][08:03:14]: [Client #175] Epoch: [4/5][0/15]	Loss: 3.335524
[INFO][08:03:14]: [Client #175] Epoch: [4/5][10/15]	Loss: 3.277368
[INFO][08:03:14]: [Client #288] Woke up.
[INFO][08:03:14]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][08:03:14]: [Client #288] Epoch: [2/5][0/17]	Loss: 3.906808
[INFO][08:03:14]: [Client #288] Epoch: [2/5][10/17]	Loss: 3.606827
[INFO][08:03:14]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:03:16]: [Client #175] Woke up.
[INFO][08:03:16]: [Client #175] Epoch: [5/5][0/15]	Loss: 2.847731
[INFO][08:03:16]: [Client #175] Epoch: [5/5][10/15]	Loss: 3.544925
[INFO][08:03:16]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][08:03:17]: [Client #175] Woke up.
[INFO][08:03:17]: [Client #175] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554860.pth.
[INFO][08:03:18]: [Client #175] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554860.pth.
[INFO][08:03:18]: [Client #175] Model trained.
[INFO][08:03:18]: [Client #175] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:18]: [Server #554754] Received 0.26 MB of payload data from client #175 (simulated).
[INFO][08:03:19]: [Client #288] Woke up.
[INFO][08:03:19]: [Client #288] Epoch: [3/5][0/17]	Loss: 3.465724
[INFO][08:03:19]: [Client #288] Epoch: [3/5][10/17]	Loss: 3.959685
[INFO][08:03:19]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:03:23]: [Client #288] Woke up.
[INFO][08:03:23]: [Client #288] Epoch: [4/5][0/17]	Loss: 3.777543
[INFO][08:03:23]: [Client #288] Epoch: [4/5][10/17]	Loss: 3.257148
[INFO][08:03:23]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:03:27]: [Client #288] Woke up.
[INFO][08:03:27]: [Client #288] Epoch: [5/5][0/17]	Loss: 3.746171
[INFO][08:03:27]: [Client #288] Epoch: [5/5][10/17]	Loss: 3.170090
[INFO][08:03:27]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:03:31]: [Client #288] Woke up.
[INFO][08:03:31]: [Client #288] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_288_554853.pth.
[INFO][08:03:32]: [Client #288] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_288_554853.pth.
[INFO][08:03:32]: [Client #288] Model trained.
[INFO][08:03:32]: [Client #288] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:32]: [Server #554754] Received 0.26 MB of payload data from client #288 (simulated).
[INFO][08:03:32]: [Server #554754] Selecting client #29 for training.
[INFO][08:03:32]: [Server #554754] Sending the current model to client #29 (simulated).
[INFO][08:03:32]: [Server #554754] Sending 0.26 MB of payload data to client #29 (simulated).
[INFO][08:03:32]: [Server #554754] Selecting client #115 for training.
[INFO][08:03:32]: [Server #554754] Sending the current model to client #115 (simulated).
[INFO][08:03:32]: [Server #554754] Sending 0.26 MB of payload data to client #115 (simulated).
[INFO][08:03:32]: [Client #29] Selected by the server.
[INFO][08:03:32]: [Client #29] Loading its data source...
[INFO][08:03:32]: Data source: FEMNIST
[INFO][08:03:32]: [Client #115] Selected by the server.
[INFO][08:03:32]: [Client #115] Loading its data source...
[INFO][08:03:32]: Data source: FEMNIST
[INFO][08:03:32]: [Client #115] Dataset size: 126
[INFO][08:03:32]: [Client #115] Sampler: all_inclusive
[INFO][08:03:32]: [Client #115] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:32]: [93m[1m[Client #115] Started training in communication round #1.[0m
[INFO][08:03:32]: [Client #29] Dataset size: 164
[INFO][08:03:32]: [Client #29] Sampler: all_inclusive
[INFO][08:03:32]: [Client #29] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:32]: [93m[1m[Client #29] Started training in communication round #1.[0m
[INFO][08:03:34]: [Client #115] Loading the dataset.
[INFO][08:03:34]: [Client #29] Loading the dataset.
[INFO][08:03:40]: [Client #115] Epoch: [1/5][0/13]	Loss: 4.082667
[INFO][08:03:40]: [Client #29] Epoch: [1/5][0/17]	Loss: 4.143537
[INFO][08:03:40]: [Client #115] Epoch: [1/5][10/13]	Loss: 3.994828
[INFO][08:03:40]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][08:03:40]: [Client #29] Epoch: [1/5][10/17]	Loss: 4.106332
[INFO][08:03:40]: [Client #115] Woke up.
[INFO][08:03:40]: [Client #115] Epoch: [2/5][0/13]	Loss: 3.754562
[INFO][08:03:40]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][08:03:40]: [Client #115] Epoch: [2/5][10/13]	Loss: 3.162046
[INFO][08:03:40]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][08:03:40]: [Client #115] Woke up.
[INFO][08:03:40]: [Client #115] Epoch: [3/5][0/13]	Loss: 3.261639
[INFO][08:03:40]: [Client #29] Woke up.
[INFO][08:03:40]: [Client #29] Epoch: [2/5][0/17]	Loss: 3.708008
[INFO][08:03:40]: [Client #115] Epoch: [3/5][10/13]	Loss: 3.328733
[INFO][08:03:40]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][08:03:40]: [Client #29] Epoch: [2/5][10/17]	Loss: 3.327874
[INFO][08:03:40]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][08:03:40]: [Client #115] Woke up.
[INFO][08:03:40]: [Client #115] Epoch: [4/5][0/13]	Loss: 3.565421
[INFO][08:03:40]: [Client #115] Epoch: [4/5][10/13]	Loss: 3.300675
[INFO][08:03:40]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][08:03:40]: [Client #115] Woke up.
[INFO][08:03:40]: [Client #29] Woke up.
[INFO][08:03:40]: [Client #115] Epoch: [5/5][0/13]	Loss: 2.714017
[INFO][08:03:40]: [Client #29] Epoch: [3/5][0/17]	Loss: 3.721812
[INFO][08:03:40]: [Client #115] Epoch: [5/5][10/13]	Loss: 3.026880
[INFO][08:03:40]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][08:03:40]: [Client #29] Epoch: [3/5][10/17]	Loss: 3.865402
[INFO][08:03:40]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][08:03:40]: [Client #115] Woke up.
[INFO][08:03:40]: [Client #115] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554860.pth.
[INFO][08:03:41]: [Client #29] Woke up.
[INFO][08:03:41]: [Client #29] Epoch: [4/5][0/17]	Loss: 3.738660
[INFO][08:03:41]: [Client #29] Epoch: [4/5][10/17]	Loss: 3.263196
[INFO][08:03:41]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][08:03:41]: [Client #29] Woke up.
[INFO][08:03:41]: [Client #29] Epoch: [5/5][0/17]	Loss: 2.634620
[INFO][08:03:41]: [Client #29] Epoch: [5/5][10/17]	Loss: 3.205262
[INFO][08:03:41]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][08:03:41]: [Client #115] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554860.pth.
[INFO][08:03:41]: [Client #115] Model trained.
[INFO][08:03:41]: [Client #115] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:41]: [Server #554754] Received 0.26 MB of payload data from client #115 (simulated).
[INFO][08:03:41]: [Client #29] Woke up.
[INFO][08:03:41]: [Client #29] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_29_554853.pth.
[INFO][08:03:42]: [Client #29] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_29_554853.pth.
[INFO][08:03:42]: [Client #29] Model trained.
[INFO][08:03:42]: [Client #29] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:42]: [Server #554754] Received 0.26 MB of payload data from client #29 (simulated).
[INFO][08:03:42]: [Server #554754] Selecting client #333 for training.
[INFO][08:03:42]: [Server #554754] Sending the current model to client #333 (simulated).
[INFO][08:03:42]: [Server #554754] Sending 0.26 MB of payload data to client #333 (simulated).
[INFO][08:03:42]: [Server #554754] Selecting client #249 for training.
[INFO][08:03:42]: [Server #554754] Sending the current model to client #249 (simulated).
[INFO][08:03:42]: [Server #554754] Sending 0.26 MB of payload data to client #249 (simulated).
[INFO][08:03:42]: [Client #333] Selected by the server.
[INFO][08:03:42]: [Client #333] Loading its data source...
[INFO][08:03:42]: Data source: FEMNIST
[INFO][08:03:42]: [Client #249] Selected by the server.
[INFO][08:03:42]: [Client #249] Loading its data source...
[INFO][08:03:42]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:03:42]: Data source: FEMNIST
[INFO][08:03:42]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/333.zip.
[INFO][08:03:42]: [Client #249] Dataset size: 144
[INFO][08:03:42]: [Client #249] Sampler: all_inclusive
[INFO][08:03:42]: [Client #249] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:42]: [93m[1m[Client #249] Started training in communication round #1.[0m

2.5%
5.1%
7.6%
10.1%
12.7%
15.2%
17.8%
20.3%
22.8%
25.4%
27.9%
30.4%
33.0%
35.5%
38.0%
40.6%
43.1%
45.7%
48.2%
50.7%
53.3%
55.8%
58.3%
60.9%
63.4%
66.0%
68.5%
71.0%
73.6%
76.1%
78.6%
81.2%
83.7%
86.2%
88.8%
91.3%
93.9%
96.4%
98.9%
100.0%[INFO][08:03:42]: Decompressing the dataset downloaded.
[INFO][08:03:42]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/333.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:03:42]: [Client #333] Dataset size: 161
[INFO][08:03:42]: [Client #333] Sampler: all_inclusive
[INFO][08:03:42]: [Client #333] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:03:42]: [93m[1m[Client #333] Started training in communication round #1.[0m

[INFO][08:03:44]: [Client #249] Loading the dataset.
[INFO][08:03:44]: [Client #333] Loading the dataset.
[INFO][08:03:50]: [Client #249] Epoch: [1/5][0/15]	Loss: 4.082801
[INFO][08:03:50]: [Client #333] Epoch: [1/5][0/17]	Loss: 4.146664
[INFO][08:03:50]: [Client #249] Epoch: [1/5][10/15]	Loss: 4.093308
[INFO][08:03:50]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][08:03:50]: [Client #333] Epoch: [1/5][10/17]	Loss: 4.149608
[INFO][08:03:50]: [Client #333] Going to sleep for 0.29 seconds.
[INFO][08:03:50]: [Client #333] Woke up.
[INFO][08:03:50]: [Client #333] Epoch: [2/5][0/17]	Loss: 4.093980
[INFO][08:03:50]: [Client #333] Epoch: [2/5][10/17]	Loss: 4.044484
[INFO][08:03:50]: [Client #333] Going to sleep for 0.29 seconds.
[INFO][08:03:50]: [Client #333] Woke up.
[INFO][08:03:50]: [Client #333] Epoch: [3/5][0/17]	Loss: 3.680141
[INFO][08:03:51]: [Client #333] Epoch: [3/5][10/17]	Loss: 3.689180
[INFO][08:03:51]: [Client #333] Going to sleep for 0.29 seconds.
[INFO][08:03:51]: [Client #333] Woke up.
[INFO][08:03:51]: [Client #333] Epoch: [4/5][0/17]	Loss: 4.037932
[INFO][08:03:51]: [Client #333] Epoch: [4/5][10/17]	Loss: 3.515770
[INFO][08:03:51]: [Client #333] Going to sleep for 0.29 seconds.
[INFO][08:03:51]: [Client #333] Woke up.
[INFO][08:03:51]: [Client #333] Epoch: [5/5][0/17]	Loss: 3.449214
[INFO][08:03:51]: [Client #333] Epoch: [5/5][10/17]	Loss: 3.520353
[INFO][08:03:51]: [Client #333] Going to sleep for 0.29 seconds.
[INFO][08:03:52]: [Client #249] Woke up.
[INFO][08:03:52]: [Client #333] Woke up.
[INFO][08:03:52]: [Client #333] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_333_554853.pth.
[INFO][08:03:52]: [Client #249] Epoch: [2/5][0/15]	Loss: 3.975549
[INFO][08:03:52]: [Client #249] Epoch: [2/5][10/15]	Loss: 3.868555
[INFO][08:03:52]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][08:03:52]: [Client #333] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_333_554853.pth.
[INFO][08:03:52]: [Client #333] Model trained.
[INFO][08:03:52]: [Client #333] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:03:52]: [Server #554754] Received 0.26 MB of payload data from client #333 (simulated).
[INFO][08:03:54]: [Client #249] Woke up.
[INFO][08:03:54]: [Client #249] Epoch: [3/5][0/15]	Loss: 3.491712
[INFO][08:03:54]: [Client #249] Epoch: [3/5][10/15]	Loss: 3.802460
[INFO][08:03:54]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][08:03:56]: [Client #249] Woke up.
[INFO][08:03:56]: [Client #249] Epoch: [4/5][0/15]	Loss: 3.706753
[INFO][08:03:56]: [Client #249] Epoch: [4/5][10/15]	Loss: 3.244817
[INFO][08:03:56]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][08:03:59]: [Client #249] Woke up.
[INFO][08:03:59]: [Client #249] Epoch: [5/5][0/15]	Loss: 2.950844
[INFO][08:03:59]: [Client #249] Epoch: [5/5][10/15]	Loss: 3.816322
[INFO][08:03:59]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][08:04:01]: [Client #249] Woke up.
[INFO][08:04:01]: [Client #249] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_249_554860.pth.
[INFO][08:04:01]: [Client #249] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_249_554860.pth.
[INFO][08:04:01]: [Client #249] Model trained.
[INFO][08:04:01]: [Client #249] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:04:01]: [Server #554754] Received 0.26 MB of payload data from client #249 (simulated).
[INFO][08:04:01]: [Server #554754] Selecting client #260 for training.
[INFO][08:04:01]: [Server #554754] Sending the current model to client #260 (simulated).
[INFO][08:04:01]: [Server #554754] Sending 0.26 MB of payload data to client #260 (simulated).
[INFO][08:04:01]: [Server #554754] Selecting client #286 for training.
[INFO][08:04:01]: [Server #554754] Sending the current model to client #286 (simulated).
[INFO][08:04:01]: [Server #554754] Sending 0.26 MB of payload data to client #286 (simulated).
[INFO][08:04:01]: [Client #260] Selected by the server.
[INFO][08:04:01]: [Client #260] Loading its data source...
[INFO][08:04:01]: [Client #286] Selected by the server.
[INFO][08:04:01]: Data source: FEMNIST
[INFO][08:04:01]: [Client #286] Loading its data source...
[INFO][08:04:01]: Data source: FEMNIST
[INFO][08:04:02]: [Client #286] Dataset size: 154
[INFO][08:04:02]: [Client #286] Sampler: all_inclusive
[INFO][08:04:02]: [Client #286] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:04:02]: [93m[1m[Client #286] Started training in communication round #1.[0m
[INFO][08:04:02]: [Client #260] Dataset size: 146
[INFO][08:04:02]: [Client #260] Sampler: all_inclusive
[INFO][08:04:02]: [Client #260] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:04:02]: [93m[1m[Client #260] Started training in communication round #1.[0m
[INFO][08:04:03]: [Client #286] Loading the dataset.
[INFO][08:04:03]: [Client #260] Loading the dataset.
[INFO][08:04:09]: [Client #286] Epoch: [1/5][0/16]	Loss: 4.104030
[INFO][08:04:09]: [Client #260] Epoch: [1/5][0/15]	Loss: 4.130326
[INFO][08:04:09]: [Client #286] Epoch: [1/5][10/16]	Loss: 3.950276
[INFO][08:04:09]: [Client #260] Epoch: [1/5][10/15]	Loss: 4.087344
[INFO][08:04:09]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][08:04:09]: [Client #260] Going to sleep for 1.42 seconds.
[INFO][08:04:11]: [Client #260] Woke up.
[INFO][08:04:11]: [Client #260] Epoch: [2/5][0/15]	Loss: 4.014728
[INFO][08:04:11]: [Client #260] Epoch: [2/5][10/15]	Loss: 3.609035
[INFO][08:04:11]: [Client #260] Going to sleep for 1.42 seconds.
[INFO][08:04:12]: [Client #260] Woke up.
[INFO][08:04:12]: [Client #260] Epoch: [3/5][0/15]	Loss: 2.662848
[INFO][08:04:12]: [Client #260] Epoch: [3/5][10/15]	Loss: 3.634220
[INFO][08:04:12]: [Client #260] Going to sleep for 1.42 seconds.
[INFO][08:04:14]: [Client #260] Woke up.
[INFO][08:04:14]: [Client #260] Epoch: [4/5][0/15]	Loss: 3.705683
[INFO][08:04:14]: [Client #260] Epoch: [4/5][10/15]	Loss: 3.670806
[INFO][08:04:14]: [Client #260] Going to sleep for 1.42 seconds.
[INFO][08:04:15]: [Client #286] Woke up.
[INFO][08:04:15]: [Client #286] Epoch: [2/5][0/16]	Loss: 3.640074
[INFO][08:04:15]: [Client #286] Epoch: [2/5][10/16]	Loss: 4.355783
[INFO][08:04:15]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][08:04:15]: [Client #260] Woke up.
[INFO][08:04:15]: [Client #260] Epoch: [5/5][0/15]	Loss: 3.261123
[INFO][08:04:15]: [Client #260] Epoch: [5/5][10/15]	Loss: 3.186346
[INFO][08:04:15]: [Client #260] Going to sleep for 1.42 seconds.
[INFO][08:04:17]: [Client #260] Woke up.
[INFO][08:04:17]: [Client #260] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_260_554853.pth.
[INFO][08:04:18]: [Client #260] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_260_554853.pth.
[INFO][08:04:18]: [Client #260] Model trained.
[INFO][08:04:18]: [Client #260] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:04:18]: [Server #554754] Received 0.26 MB of payload data from client #260 (simulated).
[INFO][08:04:21]: [Client #286] Woke up.
[INFO][08:04:21]: [Client #286] Epoch: [3/5][0/16]	Loss: 3.638526
[INFO][08:04:21]: [Client #286] Epoch: [3/5][10/16]	Loss: 3.043788
[INFO][08:04:21]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][08:04:27]: [Client #286] Woke up.
[INFO][08:04:27]: [Client #286] Epoch: [4/5][0/16]	Loss: 3.524587
[INFO][08:04:27]: [Client #286] Epoch: [4/5][10/16]	Loss: 2.651016
[INFO][08:04:27]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][08:04:33]: [Client #286] Woke up.
[INFO][08:04:33]: [Client #286] Epoch: [5/5][0/16]	Loss: 2.510888
[INFO][08:04:33]: [Client #286] Epoch: [5/5][10/16]	Loss: 3.015812
[INFO][08:04:33]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][08:04:39]: [Client #286] Woke up.
[INFO][08:04:39]: [Client #286] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554860.pth.
[INFO][08:04:40]: [Client #286] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554860.pth.
[INFO][08:04:40]: [Client #286] Model trained.
[INFO][08:04:40]: [Client #286] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:04:40]: [Server #554754] Received 0.26 MB of payload data from client #286 (simulated).
[INFO][08:04:40]: [Server #554754] Selecting client #499 for training.
[INFO][08:04:40]: [Server #554754] Sending the current model to client #499 (simulated).
[INFO][08:04:40]: [Server #554754] Sending 0.26 MB of payload data to client #499 (simulated).
[INFO][08:04:40]: [Server #554754] Selecting client #411 for training.
[INFO][08:04:40]: [Server #554754] Sending the current model to client #411 (simulated).
[INFO][08:04:40]: [Server #554754] Sending 0.26 MB of payload data to client #411 (simulated).
[INFO][08:04:40]: [Client #499] Selected by the server.
[INFO][08:04:40]: [Client #499] Loading its data source...
[INFO][08:04:40]: Data source: FEMNIST
[INFO][08:04:40]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:04:40]: [Client #411] Selected by the server.
[INFO][08:04:40]: [Client #411] Loading its data source...
[INFO][08:04:40]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/499.zip.
[INFO][08:04:40]: Data source: FEMNIST
[INFO][08:04:40]: [Client #411] Dataset size: 317
[INFO][08:04:40]: [Client #411] Sampler: all_inclusive
[INFO][08:04:40]: [Client #411] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:04:40]: [93m[1m[Client #411] Started training in communication round #1.[0m

2.5%
5.1%
7.6%
10.2%
12.7%
15.3%
17.8%
20.4%
22.9%
25.5%
28.0%
30.6%
33.1%
35.7%
38.2%
40.8%
43.3%
45.9%
48.4%
51.0%
53.5%
56.0%
58.6%
61.1%
63.7%
66.2%
68.8%
71.3%
73.9%
76.4%
79.0%
81.5%
84.1%
86.6%
89.2%
91.7%
94.3%
96.8%
99.4%
100.0%[INFO][08:04:40]: Decompressing the dataset downloaded.
[INFO][08:04:40]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/499.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:04:40]: [Client #499] Dataset size: 168
[INFO][08:04:40]: [Client #499] Sampler: all_inclusive
[INFO][08:04:40]: [Client #499] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:04:40]: [93m[1m[Client #499] Started training in communication round #1.[0m

[INFO][08:04:42]: [Client #411] Loading the dataset.
[INFO][08:04:42]: [Client #499] Loading the dataset.
[INFO][08:04:47]: [Client #411] Epoch: [1/5][0/32]	Loss: 4.134283
[INFO][08:04:47]: [Client #499] Epoch: [1/5][0/17]	Loss: 4.134215
[INFO][08:04:47]: [Client #411] Epoch: [1/5][10/32]	Loss: 4.132165
[INFO][08:04:48]: [Client #411] Epoch: [1/5][20/32]	Loss: 4.137427
[INFO][08:04:48]: [Client #499] Epoch: [1/5][10/17]	Loss: 4.077425
[INFO][08:04:48]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][08:04:48]: [Client #411] Epoch: [1/5][30/32]	Loss: 3.891252
[INFO][08:04:48]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][08:04:48]: [Client #411] Woke up.
[INFO][08:04:48]: [Client #411] Epoch: [2/5][0/32]	Loss: 3.601229
[INFO][08:04:48]: [Client #411] Epoch: [2/5][10/32]	Loss: 3.674864
[INFO][08:04:48]: [Client #411] Epoch: [2/5][20/32]	Loss: 3.822556
[INFO][08:04:48]: [Client #411] Epoch: [2/5][30/32]	Loss: 3.682774
[INFO][08:04:48]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][08:04:48]: [Client #411] Woke up.
[INFO][08:04:48]: [Client #411] Epoch: [3/5][0/32]	Loss: 3.654785
[INFO][08:04:48]: [Client #411] Epoch: [3/5][10/32]	Loss: 3.563883
[INFO][08:04:48]: [Client #411] Epoch: [3/5][20/32]	Loss: 3.701513
[INFO][08:04:48]: [Client #411] Epoch: [3/5][30/32]	Loss: 4.153956
[INFO][08:04:48]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][08:04:49]: [Client #411] Woke up.
[INFO][08:04:49]: [Client #411] Epoch: [4/5][0/32]	Loss: 3.527333
[INFO][08:04:49]: [Client #411] Epoch: [4/5][10/32]	Loss: 3.705577
[INFO][08:04:49]: [Client #411] Epoch: [4/5][20/32]	Loss: 3.699021
[INFO][08:04:49]: [Client #411] Epoch: [4/5][30/32]	Loss: 3.120899
[INFO][08:04:49]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][08:04:49]: [Client #411] Woke up.
[INFO][08:04:49]: [Client #411] Epoch: [5/5][0/32]	Loss: 3.372685
[INFO][08:04:49]: [Client #411] Epoch: [5/5][10/32]	Loss: 2.730400
[INFO][08:04:49]: [Client #411] Epoch: [5/5][20/32]	Loss: 3.358916
[INFO][08:04:49]: [Client #411] Epoch: [5/5][30/32]	Loss: 3.898022
[INFO][08:04:49]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][08:04:49]: [Client #411] Woke up.
[INFO][08:04:49]: [Client #411] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554860.pth.
[INFO][08:04:50]: [Client #411] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554860.pth.
[INFO][08:04:50]: [Client #411] Model trained.
[INFO][08:04:50]: [Client #411] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:04:50]: [Server #554754] Received 0.26 MB of payload data from client #411 (simulated).
[INFO][08:04:59]: [Client #499] Woke up.
[INFO][08:04:59]: [Client #499] Epoch: [2/5][0/17]	Loss: 3.990318
[INFO][08:04:59]: [Client #499] Epoch: [2/5][10/17]	Loss: 4.392620
[INFO][08:04:59]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][08:05:11]: [Client #499] Woke up.
[INFO][08:05:11]: [Client #499] Epoch: [3/5][0/17]	Loss: 3.664004
[INFO][08:05:11]: [Client #499] Epoch: [3/5][10/17]	Loss: 3.406445
[INFO][08:05:11]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][08:05:23]: [Client #499] Woke up.
[INFO][08:05:23]: [Client #499] Epoch: [4/5][0/17]	Loss: 3.703683
[INFO][08:05:23]: [Client #499] Epoch: [4/5][10/17]	Loss: 3.463919
[INFO][08:05:23]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][08:05:34]: [Client #499] Woke up.
[INFO][08:05:34]: [Client #499] Epoch: [5/5][0/17]	Loss: 3.365490
[INFO][08:05:34]: [Client #499] Epoch: [5/5][10/17]	Loss: 3.746841
[INFO][08:05:34]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][08:05:46]: [Client #499] Woke up.
[INFO][08:05:46]: [Client #499] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_499_554853.pth.
[INFO][08:05:47]: [Client #499] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_499_554853.pth.
[INFO][08:05:47]: [Client #499] Model trained.
[INFO][08:05:47]: [Client #499] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:05:47]: [Server #554754] Received 0.26 MB of payload data from client #499 (simulated).
[INFO][08:05:47]: [Server #554754] Adding client #121 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #409 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #115 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #29 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #333 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #411 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #93 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #175 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #304 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Adding client #158 to the list of clients for aggregation.
[INFO][08:05:47]: [Server #554754] Aggregating 10 clients in total.
======== Running on http://127.0.0.1:6300 ========
(Press CTRL+C to quit)
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9078e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9074e+00  3e-04  6e-09  6e-09
 5:  6.9078e+00  6.9078e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21900762 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12601703 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1590586  0.         0.         0.         0.         0.
 0.14853841 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15792355 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1581004  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10469184 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14147727 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14701961 0.         0.19372707 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21900762 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12601703 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1590586  0.         0.         0.         0.         0.
 0.14853841 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15792355 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1581004  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10469184 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14147727 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14701961 0.         0.19372707 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:06:36]: [Server #554754] Global model accuracy: 9.55%

[INFO][08:06:36]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_1.pth.
[INFO][08:06:36]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_1.pth.
[INFO][08:06:36]: [93m[1m
[Server #554754] Starting round 2/100.[0m
[0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.0920354  0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07433628 0.002      0.002      0.002      0.002      0.002
 0.09380531 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.09498525 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][08:06:36]: [Server #554754] Selected clients: [300 488 451  16  47  33 226 187 487  85]
[INFO][08:06:36]: [Server #554754] Selecting client #300 for training.
[INFO][08:06:36]: [Server #554754] Sending the current model to client #300 (simulated).
[INFO][08:06:36]: [Server #554754] Sending 0.26 MB of payload data to client #300 (simulated).
[INFO][08:06:36]: [Server #554754] Selecting client #488 for training.
[INFO][08:06:36]: [Server #554754] Sending the current model to client #488 (simulated).
[INFO][08:06:36]: [Server #554754] Sending 0.26 MB of payload data to client #488 (simulated).
[INFO][08:06:36]: [Client #300] Selected by the server.
[INFO][08:06:36]: [Client #300] Loading its data source...
[INFO][08:06:36]: Data source: FEMNIST
[INFO][08:06:36]: [Client #488] Selected by the server.
[INFO][08:06:36]: [Client #488] Loading its data source...
[INFO][08:06:36]: Data source: FEMNIST
[INFO][08:06:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:06:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/488.zip.
[INFO][08:06:36]: [Client #300] Dataset size: 255
[INFO][08:06:36]: [Client #300] Sampler: all_inclusive
[INFO][08:06:36]: [Client #300] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:06:36]: [93m[1m[Client #300] Started training in communication round #2.[0m

2.2%
4.4%
6.6%
8.8%
11.0%
13.1%
15.3%
17.5%
19.7%
21.9%
24.1%
26.3%
28.5%
30.7%
32.9%
35.0%
37.2%
39.4%
41.6%
43.8%
46.0%
48.2%
50.4%
52.6%
54.8%
56.9%
59.1%
61.3%
63.5%
65.7%
67.9%
70.1%
72.3%
74.5%
76.7%
78.8%
81.0%
83.2%
85.4%
87.6%
89.8%
92.0%
94.2%
96.4%
98.6%
100.0%[INFO][08:06:37]: Decompressing the dataset downloaded.
[INFO][08:06:37]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/488.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:06:37]: [Client #488] Dataset size: 151
[INFO][08:06:37]: [Client #488] Sampler: all_inclusive
[INFO][08:06:37]: [Client #488] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:06:37]: [93m[1m[Client #488] Started training in communication round #2.[0m

[INFO][08:06:38]: [Client #300] Loading the dataset.
[INFO][08:06:38]: [Client #488] Loading the dataset.
[INFO][08:06:44]: [Client #300] Epoch: [1/5][0/26]	Loss: 3.984084
[INFO][08:06:44]: [Client #300] Epoch: [1/5][10/26]	Loss: 3.016444
[INFO][08:06:44]: [Client #488] Epoch: [1/5][0/16]	Loss: 3.278712
[INFO][08:06:44]: [Client #300] Epoch: [1/5][20/26]	Loss: 3.927952
[INFO][08:06:44]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][08:06:44]: [Client #488] Epoch: [1/5][10/16]	Loss: 3.188039
[INFO][08:06:44]: [Client #488] Going to sleep for 0.01 seconds.
[INFO][08:06:44]: [Client #488] Woke up.
[INFO][08:06:44]: [Client #488] Epoch: [2/5][0/16]	Loss: 3.510893
[INFO][08:06:44]: [Client #488] Epoch: [2/5][10/16]	Loss: 2.619033
[INFO][08:06:44]: [Client #300] Woke up.
[INFO][08:06:44]: [Client #488] Going to sleep for 0.01 seconds.
[INFO][08:06:44]: [Client #300] Epoch: [2/5][0/26]	Loss: 4.047065
[INFO][08:06:44]: [Client #488] Woke up.
[INFO][08:06:44]: [Client #488] Epoch: [3/5][0/16]	Loss: 3.012987
[INFO][08:06:44]: [Client #300] Epoch: [2/5][10/26]	Loss: 3.668600
[INFO][08:06:44]: [Client #488] Epoch: [3/5][10/16]	Loss: 3.510546
[INFO][08:06:44]: [Client #488] Going to sleep for 0.01 seconds.
[INFO][08:06:44]: [Client #488] Woke up.
[INFO][08:06:44]: [Client #488] Epoch: [4/5][0/16]	Loss: 3.473640
[INFO][08:06:44]: [Client #300] Epoch: [2/5][20/26]	Loss: 3.142461
[INFO][08:06:44]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][08:06:44]: [Client #488] Epoch: [4/5][10/16]	Loss: 2.924246
[INFO][08:06:44]: [Client #488] Going to sleep for 0.01 seconds.
[INFO][08:06:44]: [Client #488] Woke up.
[INFO][08:06:44]: [Client #488] Epoch: [5/5][0/16]	Loss: 1.953638
[INFO][08:06:44]: [Client #488] Epoch: [5/5][10/16]	Loss: 2.689489
[INFO][08:06:45]: [Client #488] Going to sleep for 0.01 seconds.
[INFO][08:06:45]: [Client #488] Woke up.
[INFO][08:06:45]: [Client #488] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_488_554860.pth.
[INFO][08:06:45]: [Client #300] Woke up.
[INFO][08:06:45]: [Client #300] Epoch: [3/5][0/26]	Loss: 3.425925
[INFO][08:06:45]: [Client #300] Epoch: [3/5][10/26]	Loss: 3.366324
[INFO][08:06:45]: [Client #300] Epoch: [3/5][20/26]	Loss: 3.235226
[INFO][08:06:45]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][08:06:45]: [Client #300] Woke up.
[INFO][08:06:45]: [Client #300] Epoch: [4/5][0/26]	Loss: 3.564834
[INFO][08:06:45]: [Client #300] Epoch: [4/5][10/26]	Loss: 3.195199
[INFO][08:06:45]: [Client #300] Epoch: [4/5][20/26]	Loss: 3.307091
[INFO][08:06:45]: [Client #488] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_488_554860.pth.
[INFO][08:06:45]: [Client #488] Model trained.
[INFO][08:06:45]: [Client #488] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:06:45]: [Server #554754] Received 0.26 MB of payload data from client #488 (simulated).
[INFO][08:06:45]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][08:06:45]: [Client #300] Woke up.
[INFO][08:06:45]: [Client #300] Epoch: [5/5][0/26]	Loss: 3.541632
[INFO][08:06:46]: [Client #300] Epoch: [5/5][10/26]	Loss: 3.690081
[INFO][08:06:46]: [Client #300] Epoch: [5/5][20/26]	Loss: 3.739883
[INFO][08:06:46]: [Client #300] Going to sleep for 0.22 seconds.
[INFO][08:06:46]: [Client #300] Woke up.
[INFO][08:06:46]: [Client #300] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_300_554853.pth.
[INFO][08:06:47]: [Client #300] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_300_554853.pth.
[INFO][08:06:47]: [Client #300] Model trained.
[INFO][08:06:47]: [Client #300] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:06:47]: [Server #554754] Received 0.26 MB of payload data from client #300 (simulated).
[INFO][08:06:47]: [Server #554754] Selecting client #451 for training.
[INFO][08:06:47]: [Server #554754] Sending the current model to client #451 (simulated).
[INFO][08:06:47]: [Server #554754] Sending 0.26 MB of payload data to client #451 (simulated).
[INFO][08:06:47]: [Server #554754] Selecting client #16 for training.
[INFO][08:06:47]: [Server #554754] Sending the current model to client #16 (simulated).
[INFO][08:06:47]: [Server #554754] Sending 0.26 MB of payload data to client #16 (simulated).
[INFO][08:06:47]: [Client #451] Selected by the server.
[INFO][08:06:47]: [Client #451] Loading its data source...
[INFO][08:06:47]: [Client #16] Selected by the server.
[INFO][08:06:47]: Data source: FEMNIST
[INFO][08:06:47]: [Client #16] Loading its data source...
[INFO][08:06:47]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:06:47]: Data source: FEMNIST
[INFO][08:06:47]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/451.zip.
[INFO][08:06:47]: [Client #16] Dataset size: 164
[INFO][08:06:47]: [Client #16] Sampler: all_inclusive
[INFO][08:06:47]: [Client #16] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:06:47]: [93m[1m[Client #16] Started training in communication round #2.[0m

2.1%
4.3%
6.4%
8.6%
10.7%
12.8%
15.0%
17.1%
19.3%
21.4%
23.5%
25.7%
27.8%
29.9%
32.1%
34.2%
36.4%
38.5%
40.6%
42.8%
44.9%
47.1%
49.2%
51.3%
53.5%
55.6%
57.8%
59.9%
62.0%
64.2%
66.3%
68.5%
70.6%
72.7%
74.9%
77.0%
79.2%
81.3%
83.4%
85.6%
87.7%
89.8%
92.0%
94.1%
96.3%
98.4%
100.0%[INFO][08:06:47]: Decompressing the dataset downloaded.
[INFO][08:06:47]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/451.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:06:47]: [Client #451] Dataset size: 146
[INFO][08:06:47]: [Client #451] Sampler: all_inclusive
[INFO][08:06:47]: [Client #451] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:06:47]: [93m[1m[Client #451] Started training in communication round #2.[0m

[INFO][08:06:49]: [Client #16] Loading the dataset.
[INFO][08:06:49]: [Client #451] Loading the dataset.
[INFO][08:06:54]: [Client #16] Epoch: [1/5][0/17]	Loss: 3.626144
[INFO][08:06:54]: [Client #451] Epoch: [1/5][0/15]	Loss: 3.310147
[INFO][08:06:54]: [Client #16] Epoch: [1/5][10/17]	Loss: 4.066483
[INFO][08:06:54]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][08:06:54]: [Client #451] Epoch: [1/5][10/15]	Loss: 3.486528
[INFO][08:06:54]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:06:54]: [Client #451] Woke up.
[INFO][08:06:54]: [Client #451] Epoch: [2/5][0/15]	Loss: 3.016338
[INFO][08:06:54]: [Client #451] Epoch: [2/5][10/15]	Loss: 3.228492
[INFO][08:06:54]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:06:55]: [Client #451] Woke up.
[INFO][08:06:55]: [Client #451] Epoch: [3/5][0/15]	Loss: 2.835477
[INFO][08:06:55]: [Client #451] Epoch: [3/5][10/15]	Loss: 3.343964
[INFO][08:06:55]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:06:55]: [Client #451] Woke up.
[INFO][08:06:55]: [Client #451] Epoch: [4/5][0/15]	Loss: 3.358186
[INFO][08:06:55]: [Client #451] Epoch: [4/5][10/15]	Loss: 3.262388
[INFO][08:06:55]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:06:55]: [Client #451] Woke up.
[INFO][08:06:55]: [Client #451] Epoch: [5/5][0/15]	Loss: 2.919567
[INFO][08:06:56]: [Client #451] Epoch: [5/5][10/15]	Loss: 2.297365
[INFO][08:06:56]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:06:56]: [Client #451] Woke up.
[INFO][08:06:56]: [Client #451] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_554853.pth.
[INFO][08:06:56]: [Client #16] Woke up.
[INFO][08:06:56]: [Client #16] Epoch: [2/5][0/17]	Loss: 3.742714
[INFO][08:06:56]: [Client #16] Epoch: [2/5][10/17]	Loss: 3.020824
[INFO][08:06:56]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][08:06:56]: [Client #451] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_554853.pth.
[INFO][08:06:57]: [Client #451] Model trained.
[INFO][08:06:57]: [Client #451] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:06:57]: [Server #554754] Received 0.26 MB of payload data from client #451 (simulated).
[INFO][08:06:58]: [Client #16] Woke up.
[INFO][08:06:58]: [Client #16] Epoch: [3/5][0/17]	Loss: 2.926395
[INFO][08:06:58]: [Client #16] Epoch: [3/5][10/17]	Loss: 3.048098
[INFO][08:06:58]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][08:07:01]: [Client #16] Woke up.
[INFO][08:07:01]: [Client #16] Epoch: [4/5][0/17]	Loss: 2.471717
[INFO][08:07:01]: [Client #16] Epoch: [4/5][10/17]	Loss: 2.779864
[INFO][08:07:01]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][08:07:03]: [Client #16] Woke up.
[INFO][08:07:03]: [Client #16] Epoch: [5/5][0/17]	Loss: 1.958295
[INFO][08:07:03]: [Client #16] Epoch: [5/5][10/17]	Loss: 4.154120
[INFO][08:07:03]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][08:07:05]: [Client #16] Woke up.
[INFO][08:07:05]: [Client #16] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_554860.pth.
[INFO][08:07:06]: [Client #16] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_554860.pth.
[INFO][08:07:06]: [Client #16] Model trained.
[INFO][08:07:06]: [Client #16] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:07:06]: [Server #554754] Received 0.26 MB of payload data from client #16 (simulated).
[INFO][08:07:06]: [Server #554754] Selecting client #47 for training.
[INFO][08:07:06]: [Server #554754] Sending the current model to client #47 (simulated).
[INFO][08:07:06]: [Server #554754] Sending 0.26 MB of payload data to client #47 (simulated).
[INFO][08:07:06]: [Server #554754] Selecting client #33 for training.
[INFO][08:07:06]: [Server #554754] Sending the current model to client #33 (simulated).
[INFO][08:07:06]: [Server #554754] Sending 0.26 MB of payload data to client #33 (simulated).
[INFO][08:07:06]: [Client #33] Selected by the server.
[INFO][08:07:06]: [Client #47] Selected by the server.
[INFO][08:07:06]: [Client #33] Loading its data source...
[INFO][08:07:06]: [Client #47] Loading its data source...
[INFO][08:07:06]: Data source: FEMNIST
[INFO][08:07:06]: Data source: FEMNIST
[INFO][08:07:06]: [Client #33] Dataset size: 160
[INFO][08:07:06]: [Client #33] Sampler: all_inclusive
[INFO][08:07:06]: [Client #33] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:07:06]: [93m[1m[Client #33] Started training in communication round #2.[0m
[INFO][08:07:06]: [Client #47] Dataset size: 161
[INFO][08:07:06]: [Client #47] Sampler: all_inclusive
[INFO][08:07:06]: [Client #47] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:07:06]: [93m[1m[Client #47] Started training in communication round #2.[0m
[INFO][08:07:08]: [Client #33] Loading the dataset.
[INFO][08:07:08]: [Client #47] Loading the dataset.
[INFO][08:07:13]: [Client #33] Epoch: [1/5][0/16]	Loss: 3.505309
[INFO][08:07:13]: [Client #47] Epoch: [1/5][0/17]	Loss: 3.304324
[INFO][08:07:13]: [Client #33] Epoch: [1/5][10/16]	Loss: 3.948315
[INFO][08:07:13]: [Client #47] Epoch: [1/5][10/17]	Loss: 3.357241
[INFO][08:07:13]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][08:07:13]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:07:23]: [Client #47] Woke up.
[INFO][08:07:23]: [Client #47] Epoch: [2/5][0/17]	Loss: 3.871313
[INFO][08:07:23]: [Client #47] Epoch: [2/5][10/17]	Loss: 3.894506
[INFO][08:07:23]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:07:33]: [Client #47] Woke up.
[INFO][08:07:33]: [Client #47] Epoch: [3/5][0/17]	Loss: 3.132962
[INFO][08:07:33]: [Client #47] Epoch: [3/5][10/17]	Loss: 3.538559
[INFO][08:07:33]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:07:36]: [Client #33] Woke up.
[INFO][08:07:36]: [Client #33] Epoch: [2/5][0/16]	Loss: 3.627335
[INFO][08:07:36]: [Client #33] Epoch: [2/5][10/16]	Loss: 2.989743
[INFO][08:07:36]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][08:07:43]: [Client #47] Woke up.
[INFO][08:07:43]: [Client #47] Epoch: [4/5][0/17]	Loss: 3.392876
[INFO][08:07:43]: [Client #47] Epoch: [4/5][10/17]	Loss: 3.480795
[INFO][08:07:43]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:07:53]: [Client #47] Woke up.
[INFO][08:07:53]: [Client #47] Epoch: [5/5][0/17]	Loss: 3.109522
[INFO][08:07:53]: [Client #47] Epoch: [5/5][10/17]	Loss: 2.978502
[INFO][08:07:54]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:07:59]: [Client #33] Woke up.
[INFO][08:07:59]: [Client #33] Epoch: [3/5][0/16]	Loss: 3.142127
[INFO][08:07:59]: [Client #33] Epoch: [3/5][10/16]	Loss: 3.368092
[INFO][08:07:59]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][08:08:03]: [Client #47] Woke up.
[INFO][08:08:03]: [Client #47] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554853.pth.
[INFO][08:08:04]: [Client #47] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554853.pth.
[INFO][08:08:04]: [Client #47] Model trained.
[INFO][08:08:04]: [Client #47] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:08:04]: [Server #554754] Received 0.26 MB of payload data from client #47 (simulated).
[INFO][08:08:22]: [Client #33] Woke up.
[INFO][08:08:22]: [Client #33] Epoch: [4/5][0/16]	Loss: 3.056504
[INFO][08:08:22]: [Client #33] Epoch: [4/5][10/16]	Loss: 2.986595
[INFO][08:08:22]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][08:08:45]: [Client #33] Woke up.
[INFO][08:08:45]: [Client #33] Epoch: [5/5][0/16]	Loss: 2.951898
[INFO][08:08:45]: [Client #33] Epoch: [5/5][10/16]	Loss: 2.281687
[INFO][08:08:45]: [Client #33] Going to sleep for 22.75 seconds.
[INFO][08:09:08]: [Client #33] Woke up.
[INFO][08:09:08]: [Client #33] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_33_554860.pth.
[INFO][08:09:08]: [Client #33] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_33_554860.pth.
[INFO][08:09:08]: [Client #33] Model trained.
[INFO][08:09:08]: [Client #33] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:09:08]: [Server #554754] Received 0.26 MB of payload data from client #33 (simulated).
[INFO][08:09:08]: [Server #554754] Selecting client #226 for training.
[INFO][08:09:08]: [Server #554754] Sending the current model to client #226 (simulated).
[INFO][08:09:08]: [Server #554754] Sending 0.26 MB of payload data to client #226 (simulated).
[INFO][08:09:08]: [Server #554754] Selecting client #187 for training.
[INFO][08:09:08]: [Server #554754] Sending the current model to client #187 (simulated).
[INFO][08:09:08]: [Server #554754] Sending 0.26 MB of payload data to client #187 (simulated).
[INFO][08:09:08]: [Client #187] Selected by the server.
[INFO][08:09:08]: [Client #226] Selected by the server.
[INFO][08:09:08]: [Client #187] Loading its data source...
[INFO][08:09:08]: [Client #226] Loading its data source...
[INFO][08:09:08]: Data source: FEMNIST
[INFO][08:09:08]: Data source: FEMNIST
[INFO][08:09:09]: [Client #187] Dataset size: 164
[INFO][08:09:09]: [Client #187] Sampler: all_inclusive
[INFO][08:09:09]: [Client #187] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:09:09]: [93m[1m[Client #187] Started training in communication round #2.[0m
[INFO][08:09:09]: [Client #226] Dataset size: 146
[INFO][08:09:09]: [Client #226] Sampler: all_inclusive
[INFO][08:09:09]: [Client #226] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:09:09]: [93m[1m[Client #226] Started training in communication round #2.[0m
[INFO][08:09:10]: [Client #226] Loading the dataset.
[INFO][08:09:10]: [Client #187] Loading the dataset.
[INFO][08:09:16]: [Client #187] Epoch: [1/5][0/17]	Loss: 3.775043
[INFO][08:09:16]: [Client #226] Epoch: [1/5][0/15]	Loss: 3.565114
[INFO][08:09:16]: [Client #187] Epoch: [1/5][10/17]	Loss: 3.310040
[INFO][08:09:16]: [Client #226] Epoch: [1/5][10/15]	Loss: 4.008570
[INFO][08:09:16]: [Client #226] Going to sleep for 15.70 seconds.
[INFO][08:09:16]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][08:09:16]: [Client #187] Woke up.
[INFO][08:09:16]: [Client #187] Epoch: [2/5][0/17]	Loss: 4.365706
[INFO][08:09:16]: [Client #187] Epoch: [2/5][10/17]	Loss: 3.511573
[INFO][08:09:16]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][08:09:17]: [Client #187] Woke up.
[INFO][08:09:17]: [Client #187] Epoch: [3/5][0/17]	Loss: 3.899607
[INFO][08:09:17]: [Client #187] Epoch: [3/5][10/17]	Loss: 3.532156
[INFO][08:09:17]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][08:09:17]: [Client #187] Woke up.
[INFO][08:09:17]: [Client #187] Epoch: [4/5][0/17]	Loss: 3.275027
[INFO][08:09:17]: [Client #187] Epoch: [4/5][10/17]	Loss: 3.505044
[INFO][08:09:17]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][08:09:17]: [Client #187] Woke up.
[INFO][08:09:17]: [Client #187] Epoch: [5/5][0/17]	Loss: 3.095788
[INFO][08:09:18]: [Client #187] Epoch: [5/5][10/17]	Loss: 2.711545
[INFO][08:09:18]: [Client #187] Going to sleep for 0.24 seconds.
[INFO][08:09:18]: [Client #187] Woke up.
[INFO][08:09:18]: [Client #187] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_187_554860.pth.
[INFO][08:09:18]: [Client #187] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_187_554860.pth.
[INFO][08:09:18]: [Client #187] Model trained.
[INFO][08:09:18]: [Client #187] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:09:18]: [Server #554754] Received 0.26 MB of payload data from client #187 (simulated).
[INFO][08:09:32]: [Client #226] Woke up.
[INFO][08:09:32]: [Client #226] Epoch: [2/5][0/15]	Loss: 3.153265
[INFO][08:09:32]: [Client #226] Epoch: [2/5][10/15]	Loss: 3.429990
[INFO][08:09:32]: [Client #226] Going to sleep for 15.70 seconds.
[INFO][08:09:48]: [Client #226] Woke up.
[INFO][08:09:48]: [Client #226] Epoch: [3/5][0/15]	Loss: 3.356824
[INFO][08:09:48]: [Client #226] Epoch: [3/5][10/15]	Loss: 3.368004
[INFO][08:09:48]: [Client #226] Going to sleep for 15.70 seconds.
[INFO][08:10:03]: [Client #226] Woke up.
[INFO][08:10:03]: [Client #226] Epoch: [4/5][0/15]	Loss: 3.027516
[INFO][08:10:04]: [Client #226] Epoch: [4/5][10/15]	Loss: 3.091176
[INFO][08:10:04]: [Client #226] Going to sleep for 15.70 seconds.
[INFO][08:10:19]: [Client #226] Woke up.
[INFO][08:10:19]: [Client #226] Epoch: [5/5][0/15]	Loss: 3.740198
[INFO][08:10:19]: [Client #226] Epoch: [5/5][10/15]	Loss: 3.388564
[INFO][08:10:19]: [Client #226] Going to sleep for 15.70 seconds.
[INFO][08:10:35]: [Client #226] Woke up.
[INFO][08:10:35]: [Client #226] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_226_554853.pth.
[INFO][08:10:36]: [Client #226] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_226_554853.pth.
[INFO][08:10:36]: [Client #226] Model trained.
[INFO][08:10:36]: [Client #226] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:10:36]: [Server #554754] Received 0.26 MB of payload data from client #226 (simulated).
[INFO][08:10:36]: [Server #554754] Selecting client #487 for training.
[INFO][08:10:36]: [Server #554754] Sending the current model to client #487 (simulated).
[INFO][08:10:36]: [Server #554754] Sending 0.26 MB of payload data to client #487 (simulated).
[INFO][08:10:36]: [Server #554754] Selecting client #85 for training.
[INFO][08:10:36]: [Server #554754] Sending the current model to client #85 (simulated).
[INFO][08:10:36]: [Server #554754] Sending 0.26 MB of payload data to client #85 (simulated).
[INFO][08:10:36]: [Client #487] Selected by the server.
[INFO][08:10:36]: [Client #487] Loading its data source...
[INFO][08:10:36]: Data source: FEMNIST
[INFO][08:10:36]: [Client #85] Selected by the server.
[INFO][08:10:36]: [Client #85] Loading its data source...
[INFO][08:10:36]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:10:36]: Data source: FEMNIST
[INFO][08:10:36]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/487.zip.
[INFO][08:10:36]: [Client #85] Dataset size: 155
[INFO][08:10:36]: [Client #85] Sampler: all_inclusive
[INFO][08:10:36]: [Client #85] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:10:36]: [93m[1m[Client #85] Started training in communication round #2.[0m

2.4%
4.8%
7.2%
9.6%
12.0%
14.4%
16.8%
19.2%
21.6%
24.0%
26.4%
28.8%
31.2%
33.6%
36.0%
38.4%
40.8%
43.2%
45.6%
48.0%
50.4%
52.8%
55.2%
57.5%
59.9%
62.3%
64.7%
67.1%
69.5%
71.9%
74.3%
76.7%
79.1%
81.5%
83.9%
86.3%
88.7%
91.1%
93.5%
95.9%
98.3%
100.0%[INFO][08:10:36]: Decompressing the dataset downloaded.
[INFO][08:10:36]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/487.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:10:36]: [Client #487] Dataset size: 155
[INFO][08:10:36]: [Client #487] Sampler: all_inclusive
[INFO][08:10:36]: [Client #487] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:10:36]: [93m[1m[Client #487] Started training in communication round #2.[0m

[INFO][08:10:38]: [Client #85] Loading the dataset.
[INFO][08:10:38]: [Client #487] Loading the dataset.
[INFO][08:10:43]: [Client #487] Epoch: [1/5][0/16]	Loss: 3.197022
[INFO][08:10:43]: [Client #85] Epoch: [1/5][0/16]	Loss: 3.641851
[INFO][08:10:43]: [Client #487] Epoch: [1/5][10/16]	Loss: 3.300764
[INFO][08:10:43]: [Client #85] Epoch: [1/5][10/16]	Loss: 3.448906
[INFO][08:10:43]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][08:10:43]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][08:10:44]: [Client #487] Woke up.
[INFO][08:10:44]: [Client #85] Woke up.
[INFO][08:10:44]: [Client #487] Epoch: [2/5][0/16]	Loss: 3.698008
[INFO][08:10:44]: [Client #85] Epoch: [2/5][0/16]	Loss: 3.376416
[INFO][08:10:44]: [Client #487] Epoch: [2/5][10/16]	Loss: 3.377079
[INFO][08:10:44]: [Client #85] Epoch: [2/5][10/16]	Loss: 3.374548
[INFO][08:10:44]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][08:10:44]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][08:10:44]: [Client #85] Woke up.
[INFO][08:10:44]: [Client #85] Epoch: [3/5][0/16]	Loss: 2.660082
[INFO][08:10:44]: [Client #487] Woke up.
[INFO][08:10:44]: [Client #487] Epoch: [3/5][0/16]	Loss: 3.473841
[INFO][08:10:45]: [Client #85] Epoch: [3/5][10/16]	Loss: 3.182738
[INFO][08:10:45]: [Client #487] Epoch: [3/5][10/16]	Loss: 3.834593
[INFO][08:10:45]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][08:10:45]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][08:10:45]: [Client #85] Woke up.
[INFO][08:10:45]: [Client #85] Epoch: [4/5][0/16]	Loss: 3.364637
[INFO][08:10:45]: [Client #487] Woke up.
[INFO][08:10:45]: [Client #487] Epoch: [4/5][0/16]	Loss: 3.788022
[INFO][08:10:45]: [Client #85] Epoch: [4/5][10/16]	Loss: 2.980029
[INFO][08:10:45]: [Client #487] Epoch: [4/5][10/16]	Loss: 2.540439
[INFO][08:10:45]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][08:10:45]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][08:10:45]: [Client #85] Woke up.
[INFO][08:10:45]: [Client #85] Epoch: [5/5][0/16]	Loss: 1.875379
[INFO][08:10:46]: [Client #487] Woke up.
[INFO][08:10:46]: [Client #487] Epoch: [5/5][0/16]	Loss: 3.032880
[INFO][08:10:46]: [Client #85] Epoch: [5/5][10/16]	Loss: 3.466399
[INFO][08:10:46]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][08:10:46]: [Client #487] Epoch: [5/5][10/16]	Loss: 2.966423
[INFO][08:10:46]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][08:10:46]: [Client #85] Woke up.
[INFO][08:10:46]: [Client #85] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_554860.pth.
[INFO][08:10:46]: [Client #487] Woke up.
[INFO][08:10:46]: [Client #487] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_554853.pth.
[INFO][08:10:47]: [Client #85] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_554860.pth.
[INFO][08:10:47]: [Client #85] Model trained.
[INFO][08:10:47]: [Client #85] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:10:47]: [Server #554754] Received 0.26 MB of payload data from client #85 (simulated).
[INFO][08:10:47]: [Client #487] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_554853.pth.
[INFO][08:10:47]: [Client #487] Model trained.
[INFO][08:10:47]: [Client #487] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:10:47]: [Server #554754] Received 0.26 MB of payload data from client #487 (simulated).
[INFO][08:10:47]: [Server #554754] Adding client #260 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #207 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #249 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #114 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #488 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #451 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #351 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #187 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #300 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #487 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #85 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #44 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #288 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #16 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #286 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #499 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #47 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #226 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #33 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Adding client #88 to the list of clients for aggregation.
[INFO][08:10:47]: [Server #554754] Aggregating 20 clients in total.
[0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00203789 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00203997 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00203993 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00203957 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00203935 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00203965 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204029 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00203966 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00203966 0.00204086 0.0020322
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12221902 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13164501 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04499908 0.         0.         0.10594233 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0977343  0.         0.         0.0456915  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06748348
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05755757 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04098477 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06560568 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.02344986 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03601856 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0552106  0.         0.30459159
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13672055
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04876434 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08669849 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1115537  0.25493819 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03709034 0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12221902 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13164501 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04499908 0.         0.         0.10594233 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0977343  0.         0.         0.0456915  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06748348
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05755757 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04098477 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06560568 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.02344986 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.03601856 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0552106  0.         0.30459159
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13672055
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04876434 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08669849 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1115537  0.25493819 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03709034 0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:11:38]: [Server #554754] : accuracy: 15.43%

[INFO][08:11:38]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_2.pth.
[INFO][08:11:38]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_2.pth.
[INFO][08:11:38]: [93m[1m
[Server #554754] Starting round 3/100.[0m
[0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.04976816 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.002
 0.002      0.002      0.0920354  0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.002
 0.09380531 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04760433 0.002      0.04976816
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.09498525 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04513138 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9078e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9071e+00  6e-04  1e-08  1e-08
 5:  6.9078e+00  6.9074e+00  3e-04  4e-09  4e-09
 6:  6.9077e+00  6.9074e+00  3e-04  4e-08  1e-08
 7:  6.9077e+00  6.9075e+00  2e-04  3e-08  1e-08
 8:  6.9076e+00  6.9075e+00  1e-04  2e-07  8e-08
 9:  6.9075e+00  6.9075e+00  4e-05  2e-07  5e-08
10:  6.9075e+00  6.9075e+00  2e-06  4e-08  1e-08
Optimal solution found.
The calculated probability is:  [1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64371467e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64365924e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 2.51726945e-05
 1.64424637e-05 1.64424637e-05 1.64386132e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64394263e-05 1.64424637e-05 1.64424637e-05 2.53596781e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 3.25381206e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64412842e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 2.41297991e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64412492e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 2.02728113e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 2.29293267e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 2.81622159e-05 1.64424637e-05 9.91715295e-01
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64263860e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 2.62155495e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64403429e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64385067e-05 1.64228650e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 1.64424637e-05 1.64424637e-05
 1.64424637e-05 1.64424637e-05 2.31803028e-05 1.64424637e-05]
current clients pool:  [INFO][08:11:38]: [Server #554754] Selected clients: [288 377 232  63 156 252 337 385  66  12 259 405   7 336 344 224 458 322
   3 242]
[INFO][08:11:38]: [Server #554754] Selecting client #288 for training.
[INFO][08:11:38]: [Server #554754] Sending the current model to client #288 (simulated).
[INFO][08:11:38]: [Server #554754] Sending 0.26 MB of payload data to client #288 (simulated).
[INFO][08:11:38]: [Server #554754] Selecting client #377 for training.
[INFO][08:11:38]: [Server #554754] Sending the current model to client #377 (simulated).
[INFO][08:11:38]: [Server #554754] Sending 0.26 MB of payload data to client #377 (simulated).
[INFO][08:11:38]: [Client #288] Selected by the server.
[INFO][08:11:38]: [Client #288] Loading its data source...
[INFO][08:11:38]: Data source: FEMNIST
[INFO][08:11:38]: [Client #377] Selected by the server.
[INFO][08:11:38]: [Client #377] Loading its data source...
[INFO][08:11:38]: Data source: FEMNIST
[INFO][08:11:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:11:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/377.zip.
[INFO][08:11:38]: [Client #288] Dataset size: 161
[INFO][08:11:38]: [Client #288] Sampler: all_inclusive
[INFO][08:11:38]: [Client #288] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:11:38]: [93m[1m[Client #288] Started training in communication round #3.[0m

2.7%
5.3%
8.0%
10.7%
13.3%
16.0%
18.6%
21.3%
24.0%
26.6%
29.3%
32.0%
34.6%
37.3%
39.9%
42.6%
45.3%
47.9%
50.6%
53.3%
55.9%
58.6%
61.2%
63.9%
66.6%
69.2%
71.9%
74.6%
77.2%
79.9%
82.5%
85.2%
87.9%
90.5%
93.2%
95.9%
98.5%
100.0%[INFO][08:11:39]: Decompressing the dataset downloaded.
[INFO][08:11:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/377.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:11:39]: [Client #377] Dataset size: 142
[INFO][08:11:39]: [Client #377] Sampler: all_inclusive
[INFO][08:11:39]: [Client #377] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:11:39]: [93m[1m[Client #377] Started training in communication round #3.[0m

[INFO][08:11:40]: [Client #288] Loading the dataset.
[INFO][08:11:40]: [Client #377] Loading the dataset.
[INFO][08:11:46]: [Client #288] Epoch: [1/5][0/17]	Loss: 3.504064
[INFO][08:11:46]: [Client #288] Epoch: [1/5][10/17]	Loss: 3.937872
[INFO][08:11:46]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:11:46]: [Client #377] Epoch: [1/5][0/15]	Loss: 3.458329
[INFO][08:11:46]: [Client #377] Epoch: [1/5][10/15]	Loss: 2.398423
[INFO][08:11:46]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:11:50]: [Client #288] Woke up.
[INFO][08:11:50]: [Client #288] Epoch: [2/5][0/17]	Loss: 2.863071
[INFO][08:11:50]: [Client #288] Epoch: [2/5][10/17]	Loss: 3.991679
[INFO][08:11:50]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:11:52]: [Client #377] Woke up.
[INFO][08:11:52]: [Client #377] Epoch: [2/5][0/15]	Loss: 2.482613
[INFO][08:11:52]: [Client #377] Epoch: [2/5][10/15]	Loss: 2.376781
[INFO][08:11:52]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:11:54]: [Client #288] Woke up.
[INFO][08:11:54]: [Client #288] Epoch: [3/5][0/17]	Loss: 3.465194
[INFO][08:11:54]: [Client #288] Epoch: [3/5][10/17]	Loss: 3.632019
[INFO][08:11:54]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:11:58]: [Client #288] Woke up.
[INFO][08:11:58]: [Client #288] Epoch: [4/5][0/17]	Loss: 3.707691
[INFO][08:11:58]: [Client #288] Epoch: [4/5][10/17]	Loss: 2.925608
[INFO][08:11:58]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:11:59]: [Client #377] Woke up.
[INFO][08:11:59]: [Client #377] Epoch: [3/5][0/15]	Loss: 3.524500
[INFO][08:11:59]: [Client #377] Epoch: [3/5][10/15]	Loss: 2.021479
[INFO][08:11:59]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:12:02]: [Client #288] Woke up.
[INFO][08:12:02]: [Client #288] Epoch: [5/5][0/17]	Loss: 3.521183
[INFO][08:12:03]: [Client #288] Epoch: [5/5][10/17]	Loss: 2.741714
[INFO][08:12:03]: [Client #288] Going to sleep for 4.05 seconds.
[INFO][08:12:05]: [Client #377] Woke up.
[INFO][08:12:05]: [Client #377] Epoch: [4/5][0/15]	Loss: 2.987985
[INFO][08:12:05]: [Client #377] Epoch: [4/5][10/15]	Loss: 2.942792
[INFO][08:12:05]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:12:07]: [Client #288] Woke up.
[INFO][08:12:07]: [Client #288] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_288_554853.pth.
[INFO][08:12:07]: [Client #288] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_288_554853.pth.
[INFO][08:12:07]: [Client #288] Model trained.
[INFO][08:12:07]: [Client #288] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:12:07]: [Server #554754] Received 0.26 MB of payload data from client #288 (simulated).
[INFO][08:12:11]: [Client #377] Woke up.
[INFO][08:12:11]: [Client #377] Epoch: [5/5][0/15]	Loss: 2.445063
[INFO][08:12:11]: [Client #377] Epoch: [5/5][10/15]	Loss: 1.909997
[INFO][08:12:12]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:12:18]: [Client #377] Woke up.
[INFO][08:12:18]: [Client #377] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554860.pth.
[INFO][08:12:18]: [Client #377] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554860.pth.
[INFO][08:12:18]: [Client #377] Model trained.
[INFO][08:12:18]: [Client #377] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:12:18]: [Server #554754] Received 0.26 MB of payload data from client #377 (simulated).
[INFO][08:12:18]: [Server #554754] Selecting client #232 for training.
[INFO][08:12:18]: [Server #554754] Sending the current model to client #232 (simulated).
[INFO][08:12:18]: [Server #554754] Sending 0.26 MB of payload data to client #232 (simulated).
[INFO][08:12:18]: [Server #554754] Selecting client #63 for training.
[INFO][08:12:18]: [Server #554754] Sending the current model to client #63 (simulated).
[INFO][08:12:18]: [Server #554754] Sending 0.26 MB of payload data to client #63 (simulated).
[INFO][08:12:18]: [Client #63] Selected by the server.
[INFO][08:12:18]: [Client #232] Selected by the server.
[INFO][08:12:18]: [Client #63] Loading its data source...
[INFO][08:12:18]: Data source: FEMNIST
[INFO][08:12:18]: [Client #232] Loading its data source...
[INFO][08:12:18]: Data source: FEMNIST
[INFO][08:12:19]: [Client #232] Dataset size: 162
[INFO][08:12:19]: [Client #232] Sampler: all_inclusive
[INFO][08:12:19]: [Client #232] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:12:19]: [93m[1m[Client #232] Started training in communication round #3.[0m
[INFO][08:12:19]: [Client #63] Dataset size: 154
[INFO][08:12:19]: [Client #63] Sampler: all_inclusive
[INFO][08:12:19]: [Client #63] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:12:19]: [93m[1m[Client #63] Started training in communication round #3.[0m
[INFO][08:12:20]: [Client #63] Loading the dataset.
[INFO][08:12:20]: [Client #232] Loading the dataset.
[INFO][08:12:26]: [Client #63] Epoch: [1/5][0/16]	Loss: 3.597016
[INFO][08:12:26]: [Client #232] Epoch: [1/5][0/17]	Loss: 4.238826
[INFO][08:12:26]: [Client #63] Epoch: [1/5][10/16]	Loss: 3.030923
[INFO][08:12:26]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][08:12:26]: [Client #232] Epoch: [1/5][10/17]	Loss: 3.885009
[INFO][08:12:26]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][08:12:27]: [Client #232] Woke up.
[INFO][08:12:27]: [Client #232] Epoch: [2/5][0/17]	Loss: 3.030801
[INFO][08:12:27]: [Client #232] Epoch: [2/5][10/17]	Loss: 3.466368
[INFO][08:12:27]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][08:12:28]: [Client #63] Woke up.
[INFO][08:12:28]: [Client #63] Epoch: [2/5][0/16]	Loss: 3.396128
[INFO][08:12:28]: [Client #63] Epoch: [2/5][10/16]	Loss: 3.210696
[INFO][08:12:28]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][08:12:29]: [Client #232] Woke up.
[INFO][08:12:29]: [Client #232] Epoch: [3/5][0/17]	Loss: 2.852819
[INFO][08:12:29]: [Client #232] Epoch: [3/5][10/17]	Loss: 3.262419
[INFO][08:12:29]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][08:12:30]: [Client #232] Woke up.
[INFO][08:12:30]: [Client #232] Epoch: [4/5][0/17]	Loss: 3.266662
[INFO][08:12:30]: [Client #232] Epoch: [4/5][10/17]	Loss: 3.450666
[INFO][08:12:30]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][08:12:31]: [Client #63] Woke up.
[INFO][08:12:31]: [Client #63] Epoch: [3/5][0/16]	Loss: 2.158135
[INFO][08:12:31]: [Client #63] Epoch: [3/5][10/16]	Loss: 2.348030
[INFO][08:12:31]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][08:12:31]: [Client #232] Woke up.
[INFO][08:12:31]: [Client #232] Epoch: [5/5][0/17]	Loss: 3.096932
[INFO][08:12:31]: [Client #232] Epoch: [5/5][10/17]	Loss: 3.285063
[INFO][08:12:32]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][08:12:33]: [Client #232] Woke up.
[INFO][08:12:33]: [Client #232] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][08:12:33]: [Client #63] Woke up.
[INFO][08:12:33]: [Client #63] Epoch: [4/5][0/16]	Loss: 2.159975
[INFO][08:12:33]: [Client #63] Epoch: [4/5][10/16]	Loss: 2.741810
[INFO][08:12:33]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][08:12:33]: [Client #232] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][08:12:33]: [Client #232] Model trained.
[INFO][08:12:33]: [Client #232] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:12:33]: [Server #554754] Received 0.26 MB of payload data from client #232 (simulated).
[INFO][08:12:35]: [Client #63] Woke up.
[INFO][08:12:35]: [Client #63] Epoch: [5/5][0/16]	Loss: 2.287115
[INFO][08:12:36]: [Client #63] Epoch: [5/5][10/16]	Loss: 2.360571
[INFO][08:12:36]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][08:12:38]: [Client #63] Woke up.
[INFO][08:12:38]: [Client #63] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_63_554860.pth.
[INFO][08:12:39]: [Client #63] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_63_554860.pth.
[INFO][08:12:39]: [Client #63] Model trained.
[INFO][08:12:39]: [Client #63] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:12:39]: [Server #554754] Received 0.26 MB of payload data from client #63 (simulated).
[INFO][08:12:39]: [Server #554754] Selecting client #156 for training.
[INFO][08:12:39]: [Server #554754] Sending the current model to client #156 (simulated).
[INFO][08:12:39]: [Server #554754] Sending 0.26 MB of payload data to client #156 (simulated).
[INFO][08:12:39]: [Server #554754] Selecting client #252 for training.
[INFO][08:12:39]: [Server #554754] Sending the current model to client #252 (simulated).
[INFO][08:12:39]: [Server #554754] Sending 0.26 MB of payload data to client #252 (simulated).
[INFO][08:12:39]: [Client #252] Selected by the server.
[INFO][08:12:39]: [Client #156] Selected by the server.
[INFO][08:12:39]: [Client #252] Loading its data source...
[INFO][08:12:39]: [Client #156] Loading its data source...
[INFO][08:12:39]: Data source: FEMNIST
[INFO][08:12:39]: Data source: FEMNIST
[INFO][08:12:39]: [Client #252] Dataset size: 149
[INFO][08:12:39]: [Client #252] Sampler: all_inclusive
[INFO][08:12:39]: [Client #252] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:12:39]: [93m[1m[Client #252] Started training in communication round #3.[0m
[INFO][08:12:39]: [Client #156] Dataset size: 168
[INFO][08:12:39]: [Client #156] Sampler: all_inclusive
[INFO][08:12:39]: [Client #156] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:12:39]: [93m[1m[Client #156] Started training in communication round #3.[0m
[INFO][08:12:40]: [Client #252] Loading the dataset.
[INFO][08:12:40]: [Client #156] Loading the dataset.
[INFO][08:12:46]: [Client #252] Epoch: [1/5][0/15]	Loss: 3.609130
[INFO][08:12:46]: [Client #156] Epoch: [1/5][0/17]	Loss: 3.592036
[INFO][08:12:46]: [Client #252] Epoch: [1/5][10/15]	Loss: 3.403045
[INFO][08:12:46]: [Client #156] Epoch: [1/5][10/17]	Loss: 3.245856
[INFO][08:12:46]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][08:12:46]: [Client #156] Going to sleep for 2.90 seconds.
[INFO][08:12:49]: [Client #156] Woke up.
[INFO][08:12:49]: [Client #156] Epoch: [2/5][0/17]	Loss: 3.368315
[INFO][08:12:49]: [Client #156] Epoch: [2/5][10/17]	Loss: 3.268467
[INFO][08:12:49]: [Client #156] Going to sleep for 2.90 seconds.
[INFO][08:12:52]: [Client #156] Woke up.
[INFO][08:12:52]: [Client #156] Epoch: [3/5][0/17]	Loss: 3.061403
[INFO][08:12:52]: [Client #156] Epoch: [3/5][10/17]	Loss: 3.095758
[INFO][08:12:52]: [Client #156] Going to sleep for 2.90 seconds.
[INFO][08:12:55]: [Client #156] Woke up.
[INFO][08:12:55]: [Client #156] Epoch: [4/5][0/17]	Loss: 3.087196
[INFO][08:12:55]: [Client #156] Epoch: [4/5][10/17]	Loss: 2.575241
[INFO][08:12:55]: [Client #156] Going to sleep for 2.90 seconds.
[INFO][08:12:58]: [Client #156] Woke up.
[INFO][08:12:58]: [Client #156] Epoch: [5/5][0/17]	Loss: 2.719093
[INFO][08:12:58]: [Client #156] Epoch: [5/5][10/17]	Loss: 2.740374
[INFO][08:12:58]: [Client #156] Going to sleep for 2.90 seconds.
[INFO][08:13:01]: [Client #156] Woke up.
[INFO][08:13:01]: [Client #156] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_156_554853.pth.
[INFO][08:13:02]: [Client #156] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_156_554853.pth.
[INFO][08:13:02]: [Client #156] Model trained.
[INFO][08:13:02]: [Client #156] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:13:02]: [Server #554754] Received 0.26 MB of payload data from client #156 (simulated).
[INFO][08:13:28]: [Client #252] Woke up.
[INFO][08:13:28]: [Client #252] Epoch: [2/5][0/15]	Loss: 2.532852
[INFO][08:13:28]: [Client #252] Epoch: [2/5][10/15]	Loss: 3.750364
[INFO][08:13:28]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][08:14:10]: [Client #252] Woke up.
[INFO][08:14:11]: [Client #252] Epoch: [3/5][0/15]	Loss: 3.164185
[INFO][08:14:11]: [Client #252] Epoch: [3/5][10/15]	Loss: 3.494068
[INFO][08:14:11]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][08:14:53]: [Client #252] Woke up.
[INFO][08:14:53]: [Client #252] Epoch: [4/5][0/15]	Loss: 2.958959
[INFO][08:14:53]: [Client #252] Epoch: [4/5][10/15]	Loss: 2.284104
[INFO][08:14:53]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][08:15:35]: [Client #252] Woke up.
[INFO][08:15:35]: [Client #252] Epoch: [5/5][0/15]	Loss: 2.597537
[INFO][08:15:35]: [Client #252] Epoch: [5/5][10/15]	Loss: 1.870462
[INFO][08:15:35]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][08:16:17]: [Client #252] Woke up.
[INFO][08:16:17]: [Client #252] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554860.pth.
[INFO][08:16:18]: [Client #252] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554860.pth.
[INFO][08:16:18]: [Client #252] Model trained.
[INFO][08:16:18]: [Client #252] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:16:18]: [Server #554754] Received 0.26 MB of payload data from client #252 (simulated).
[INFO][08:16:18]: [Server #554754] Selecting client #337 for training.
[INFO][08:16:18]: [Server #554754] Sending the current model to client #337 (simulated).
[INFO][08:16:18]: [Server #554754] Sending 0.26 MB of payload data to client #337 (simulated).
[INFO][08:16:18]: [Server #554754] Selecting client #385 for training.
[INFO][08:16:18]: [Server #554754] Sending the current model to client #385 (simulated).
[INFO][08:16:18]: [Server #554754] Sending 0.26 MB of payload data to client #385 (simulated).
[INFO][08:16:18]: [Client #385] Selected by the server.
[INFO][08:16:18]: [Client #337] Selected by the server.
[INFO][08:16:18]: [Client #385] Loading its data source...
[INFO][08:16:18]: [Client #337] Loading its data source...
[INFO][08:16:18]: Data source: FEMNIST
[INFO][08:16:18]: Data source: FEMNIST
[INFO][08:16:18]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:16:18]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:16:18]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/385.zip.
[INFO][08:16:18]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/337.zip.

2.6%
5.2%
7.8%
10.3%
12.9%
15.5%
18.1%
20.7%
23.3%
25.9%
28.4%
31.0%
33.6%
36.2%
38.8%
41.4%
44.0%
46.5%
49.1%
51.7%
54.3%
56.9%
59.5%
62.1%
64.6%
67.2%
69.8%
72.4%
75.0%
77.6%
80.2%
82.7%
85.3%
87.9%
90.5%
93.1%
95.7%
98.3%
2.4%
4.8%
7.2%
9.6%
12.0%
14.4%
16.8%
19.2%
21.6%
24.0%
26.4%
28.8%
31.2%
33.6%
36.0%
38.4%
40.8%
100.0%[INFO][08:16:18]: Decompressing the dataset downloaded.
[INFO][08:16:18]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/385.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

43.2%[INFO][08:16:18]: [Client #385] Dataset size: 162
[INFO][08:16:18]: [Client #385] Sampler: all_inclusive
[INFO][08:16:18]: [Client #385] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:18]: [93m[1m[Client #385] Started training in communication round #3.[0m


45.6%
48.0%
50.4%
52.8%
55.2%
57.6%
60.0%
62.4%
64.8%
67.2%
69.6%
72.0%
74.4%
76.8%
79.2%
81.6%
84.0%
86.4%
88.8%
91.2%
93.6%
96.0%
98.4%
100.0%[INFO][08:16:19]: Decompressing the dataset downloaded.
[INFO][08:16:19]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/337.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:16:19]: [Client #337] Dataset size: 155
[INFO][08:16:19]: [Client #337] Sampler: all_inclusive
[INFO][08:16:19]: [Client #337] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:19]: [93m[1m[Client #337] Started training in communication round #3.[0m

[INFO][08:16:20]: [Client #385] Loading the dataset.
[INFO][08:16:20]: [Client #337] Loading the dataset.
[INFO][08:16:26]: [Client #385] Epoch: [1/5][0/17]	Loss: 3.139907
[INFO][08:16:26]: [Client #337] Epoch: [1/5][0/16]	Loss: 3.648521
[INFO][08:16:26]: [Client #385] Epoch: [1/5][10/17]	Loss: 2.984646
[INFO][08:16:26]: [Client #337] Epoch: [1/5][10/16]	Loss: 2.451647
[INFO][08:16:26]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][08:16:26]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][08:16:26]: [Client #385] Woke up.
[INFO][08:16:26]: [Client #385] Epoch: [2/5][0/17]	Loss: 2.929463
[INFO][08:16:26]: [Client #385] Epoch: [2/5][10/17]	Loss: 3.391054
[INFO][08:16:26]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][08:16:26]: [Client #337] Woke up.
[INFO][08:16:26]: [Client #337] Epoch: [2/5][0/16]	Loss: 3.369644
[INFO][08:16:27]: [Client #337] Epoch: [2/5][10/16]	Loss: 3.352533
[INFO][08:16:27]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][08:16:27]: [Client #385] Woke up.
[INFO][08:16:27]: [Client #385] Epoch: [3/5][0/17]	Loss: 3.102211
[INFO][08:16:27]: [Client #385] Epoch: [3/5][10/17]	Loss: 2.918326
[INFO][08:16:27]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][08:16:27]: [Client #337] Woke up.
[INFO][08:16:27]: [Client #337] Epoch: [3/5][0/16]	Loss: 2.867394
[INFO][08:16:27]: [Client #337] Epoch: [3/5][10/16]	Loss: 3.144037
[INFO][08:16:27]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][08:16:27]: [Client #385] Woke up.
[INFO][08:16:27]: [Client #385] Epoch: [4/5][0/17]	Loss: 2.791719
[INFO][08:16:27]: [Client #385] Epoch: [4/5][10/17]	Loss: 3.265753
[INFO][08:16:27]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][08:16:28]: [Client #337] Woke up.
[INFO][08:16:28]: [Client #337] Epoch: [4/5][0/16]	Loss: 3.627001
[INFO][08:16:28]: [Client #385] Woke up.
[INFO][08:16:28]: [Client #385] Epoch: [5/5][0/17]	Loss: 2.722363
[INFO][08:16:28]: [Client #337] Epoch: [4/5][10/16]	Loss: 2.216603
[INFO][08:16:28]: [Client #385] Epoch: [5/5][10/17]	Loss: 3.128632
[INFO][08:16:28]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][08:16:28]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][08:16:28]: [Client #385] Woke up.
[INFO][08:16:28]: [Client #385] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_385_554860.pth.
[INFO][08:16:28]: [Client #337] Woke up.
[INFO][08:16:28]: [Client #337] Epoch: [5/5][0/16]	Loss: 3.752542
[INFO][08:16:28]: [Client #337] Epoch: [5/5][10/16]	Loss: 3.006418
[INFO][08:16:28]: [Client #337] Going to sleep for 0.48 seconds.
[INFO][08:16:29]: [Client #385] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_385_554860.pth.
[INFO][08:16:29]: [Client #385] Model trained.
[INFO][08:16:29]: [Client #385] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:16:29]: [Server #554754] Received 0.26 MB of payload data from client #385 (simulated).
[INFO][08:16:29]: [Client #337] Woke up.
[INFO][08:16:29]: [Client #337] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_337_554853.pth.
[INFO][08:16:30]: [Client #337] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_337_554853.pth.
[INFO][08:16:30]: [Client #337] Model trained.
[INFO][08:16:30]: [Client #337] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:16:30]: [Server #554754] Received 0.26 MB of payload data from client #337 (simulated).
[INFO][08:16:30]: [Server #554754] Selecting client #66 for training.
[INFO][08:16:30]: [Server #554754] Sending the current model to client #66 (simulated).
[INFO][08:16:30]: [Server #554754] Sending 0.26 MB of payload data to client #66 (simulated).
[INFO][08:16:30]: [Server #554754] Selecting client #12 for training.
[INFO][08:16:30]: [Server #554754] Sending the current model to client #12 (simulated).
[INFO][08:16:30]: [Server #554754] Sending 0.26 MB of payload data to client #12 (simulated).
[INFO][08:16:30]: [Client #66] Selected by the server.
[INFO][08:16:30]: [Client #66] Loading its data source...
[INFO][08:16:30]: Data source: FEMNIST
[INFO][08:16:30]: [Client #12] Selected by the server.
[INFO][08:16:30]: [Client #12] Loading its data source...
[INFO][08:16:30]: Data source: FEMNIST
[INFO][08:16:30]: [Client #12] Dataset size: 118
[INFO][08:16:30]: [Client #12] Sampler: all_inclusive
[INFO][08:16:30]: [Client #12] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:30]: [93m[1m[Client #12] Started training in communication round #3.[0m
[INFO][08:16:30]: [Client #66] Dataset size: 162
[INFO][08:16:30]: [Client #66] Sampler: all_inclusive
[INFO][08:16:30]: [Client #66] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:30]: [93m[1m[Client #66] Started training in communication round #3.[0m
[INFO][08:16:32]: [Client #66] Loading the dataset.
[INFO][08:16:32]: [Client #12] Loading the dataset.
[INFO][08:16:37]: [Client #66] Epoch: [1/5][0/17]	Loss: 3.195286
[INFO][08:16:37]: [Client #12] Epoch: [1/5][0/12]	Loss: 3.069657
[INFO][08:16:37]: [Client #66] Epoch: [1/5][10/17]	Loss: 2.953313
[INFO][08:16:37]: [Client #12] Epoch: [1/5][10/12]	Loss: 3.976328
[INFO][08:16:37]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][08:16:37]: [Client #12] Going to sleep for 2.18 seconds.
[INFO][08:16:38]: [Client #66] Woke up.
[INFO][08:16:38]: [Client #66] Epoch: [2/5][0/17]	Loss: 2.929337
[INFO][08:16:38]: [Client #66] Epoch: [2/5][10/17]	Loss: 2.713669
[INFO][08:16:39]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][08:16:39]: [Client #12] Woke up.
[INFO][08:16:39]: [Client #12] Epoch: [2/5][0/12]	Loss: 3.598085
[INFO][08:16:39]: [Client #12] Epoch: [2/5][10/12]	Loss: 3.394178
[INFO][08:16:39]: [Client #12] Going to sleep for 2.18 seconds.
[INFO][08:16:40]: [Client #66] Woke up.
[INFO][08:16:40]: [Client #66] Epoch: [3/5][0/17]	Loss: 2.769095
[INFO][08:16:40]: [Client #66] Epoch: [3/5][10/17]	Loss: 2.627400
[INFO][08:16:40]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][08:16:41]: [Client #66] Woke up.
[INFO][08:16:41]: [Client #66] Epoch: [4/5][0/17]	Loss: 2.500830
[INFO][08:16:41]: [Client #66] Epoch: [4/5][10/17]	Loss: 1.878555
[INFO][08:16:41]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][08:16:42]: [Client #12] Woke up.
[INFO][08:16:42]: [Client #12] Epoch: [3/5][0/12]	Loss: 3.050355
[INFO][08:16:42]: [Client #12] Epoch: [3/5][10/12]	Loss: 4.014577
[INFO][08:16:42]: [Client #12] Going to sleep for 2.18 seconds.
[INFO][08:16:42]: [Client #66] Woke up.
[INFO][08:16:42]: [Client #66] Epoch: [5/5][0/17]	Loss: 2.029920
[INFO][08:16:42]: [Client #66] Epoch: [5/5][10/17]	Loss: 2.673221
[INFO][08:16:42]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][08:16:44]: [Client #66] Woke up.
[INFO][08:16:44]: [Client #66] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554853.pth.
[INFO][08:16:44]: [Client #12] Woke up.
[INFO][08:16:44]: [Client #12] Epoch: [4/5][0/12]	Loss: 2.931091
[INFO][08:16:44]: [Client #12] Epoch: [4/5][10/12]	Loss: 3.553948
[INFO][08:16:44]: [Client #12] Going to sleep for 2.18 seconds.
[INFO][08:16:44]: [Client #66] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554853.pth.
[INFO][08:16:44]: [Client #66] Model trained.
[INFO][08:16:44]: [Client #66] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:16:44]: [Server #554754] Received 0.26 MB of payload data from client #66 (simulated).
[INFO][08:16:46]: [Client #12] Woke up.
[INFO][08:16:46]: [Client #12] Epoch: [5/5][0/12]	Loss: 3.315368
[INFO][08:16:46]: [Client #12] Epoch: [5/5][10/12]	Loss: 2.572648
[INFO][08:16:46]: [Client #12] Going to sleep for 2.18 seconds.
[INFO][08:16:49]: [Client #12] Woke up.
[INFO][08:16:49]: [Client #12] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_12_554860.pth.
[INFO][08:16:49]: [Client #12] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_12_554860.pth.
[INFO][08:16:49]: [Client #12] Model trained.
[INFO][08:16:49]: [Client #12] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:16:49]: [Server #554754] Received 0.26 MB of payload data from client #12 (simulated).
[INFO][08:16:49]: [Server #554754] Selecting client #259 for training.
[INFO][08:16:49]: [Server #554754] Sending the current model to client #259 (simulated).
[INFO][08:16:49]: [Server #554754] Sending 0.26 MB of payload data to client #259 (simulated).
[INFO][08:16:49]: [Server #554754] Selecting client #405 for training.
[INFO][08:16:49]: [Server #554754] Sending the current model to client #405 (simulated).
[INFO][08:16:49]: [Server #554754] Sending 0.26 MB of payload data to client #405 (simulated).
[INFO][08:16:49]: [Client #405] Selected by the server.
[INFO][08:16:49]: [Client #259] Selected by the server.
[INFO][08:16:49]: [Client #405] Loading its data source...
[INFO][08:16:49]: [Client #259] Loading its data source...
[INFO][08:16:49]: Data source: FEMNIST
[INFO][08:16:49]: Data source: FEMNIST
[INFO][08:16:49]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:16:49]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/405.zip.
[INFO][08:16:49]: [Client #259] Dataset size: 125
[INFO][08:16:49]: [Client #259] Sampler: all_inclusive
[INFO][08:16:49]: [Client #259] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:49]: [93m[1m[Client #259] Started training in communication round #3.[0m

2.3%
4.6%
6.8%
9.1%
11.4%
13.7%
16.0%
18.3%
20.5%
22.8%
25.1%
27.4%
29.7%
32.0%
34.2%
36.5%
38.8%
41.1%
43.4%
45.7%
47.9%
50.2%
52.5%
54.8%
57.1%
59.4%
61.6%
63.9%
66.2%
68.5%
70.8%
73.1%
75.3%
77.6%
79.9%
82.2%
84.5%
86.8%
89.0%
91.3%
93.6%
95.9%
98.2%
100.0%[INFO][08:16:50]: Decompressing the dataset downloaded.
[INFO][08:16:50]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/405.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:16:50]: [Client #405] Dataset size: 159
[INFO][08:16:50]: [Client #405] Sampler: all_inclusive
[INFO][08:16:50]: [Client #405] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:16:50]: [93m[1m[Client #405] Started training in communication round #3.[0m

[INFO][08:16:51]: [Client #259] Loading the dataset.
[INFO][08:16:51]: [Client #405] Loading the dataset.
[INFO][08:16:57]: [Client #259] Epoch: [1/5][0/13]	Loss: 3.166787
[INFO][08:16:57]: [Client #259] Epoch: [1/5][10/13]	Loss: 3.664184
[INFO][08:16:57]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][08:16:57]: [Client #405] Epoch: [1/5][0/16]	Loss: 3.272023
[INFO][08:16:57]: [Client #405] Epoch: [1/5][10/16]	Loss: 2.864960
[INFO][08:16:57]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][08:16:57]: [Client #259] Woke up.
[INFO][08:16:57]: [Client #259] Epoch: [2/5][0/13]	Loss: 3.276519
[INFO][08:16:57]: [Client #259] Epoch: [2/5][10/13]	Loss: 3.320509
[INFO][08:16:57]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][08:16:58]: [Client #259] Woke up.
[INFO][08:16:58]: [Client #259] Epoch: [3/5][0/13]	Loss: 3.042913
[INFO][08:16:58]: [Client #405] Woke up.
[INFO][08:16:58]: [Client #259] Epoch: [3/5][10/13]	Loss: 2.979794
[INFO][08:16:58]: [Client #405] Epoch: [2/5][0/16]	Loss: 3.519028
[INFO][08:16:58]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][08:16:58]: [Client #405] Epoch: [2/5][10/16]	Loss: 2.507508
[INFO][08:16:58]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][08:16:58]: [Client #259] Woke up.
[INFO][08:16:58]: [Client #259] Epoch: [4/5][0/13]	Loss: 2.706344
[INFO][08:16:58]: [Client #259] Epoch: [4/5][10/13]	Loss: 2.957797
[INFO][08:16:58]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][08:16:59]: [Client #259] Woke up.
[INFO][08:16:59]: [Client #259] Epoch: [5/5][0/13]	Loss: 3.008877
[INFO][08:16:59]: [Client #405] Woke up.
[INFO][08:16:59]: [Client #405] Epoch: [3/5][0/16]	Loss: 3.503979
[INFO][08:16:59]: [Client #259] Epoch: [5/5][10/13]	Loss: 1.714066
[INFO][08:16:59]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][08:16:59]: [Client #405] Epoch: [3/5][10/16]	Loss: 3.710614
[INFO][08:16:59]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][08:16:59]: [Client #259] Woke up.
[INFO][08:16:59]: [Client #259] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][08:17:00]: [Client #405] Woke up.
[INFO][08:17:00]: [Client #405] Epoch: [4/5][0/16]	Loss: 1.936216
[INFO][08:17:00]: [Client #405] Epoch: [4/5][10/16]	Loss: 2.590038
[INFO][08:17:00]: [Client #259] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][08:17:00]: [Client #259] Model trained.
[INFO][08:17:00]: [Client #259] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:00]: [Server #554754] Received 0.26 MB of payload data from client #259 (simulated).
[INFO][08:17:00]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][08:17:01]: [Client #405] Woke up.
[INFO][08:17:01]: [Client #405] Epoch: [5/5][0/16]	Loss: 1.815223
[INFO][08:17:01]: [Client #405] Epoch: [5/5][10/16]	Loss: 1.387023
[INFO][08:17:01]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][08:17:02]: [Client #405] Woke up.
[INFO][08:17:02]: [Client #405] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_554860.pth.
[INFO][08:17:02]: [Client #405] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_554860.pth.
[INFO][08:17:02]: [Client #405] Model trained.
[INFO][08:17:02]: [Client #405] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:02]: [Server #554754] Received 0.26 MB of payload data from client #405 (simulated).
[INFO][08:17:02]: [Server #554754] Selecting client #7 for training.
[INFO][08:17:02]: [Server #554754] Sending the current model to client #7 (simulated).
[INFO][08:17:02]: [Server #554754] Sending 0.26 MB of payload data to client #7 (simulated).
[INFO][08:17:02]: [Server #554754] Selecting client #336 for training.
[INFO][08:17:02]: [Server #554754] Sending the current model to client #336 (simulated).
[INFO][08:17:02]: [Server #554754] Sending 0.26 MB of payload data to client #336 (simulated).
[INFO][08:17:02]: [Client #336] Selected by the server.
[INFO][08:17:02]: [Client #336] Loading its data source...
[INFO][08:17:02]: [Client #7] Selected by the server.
[INFO][08:17:02]: Data source: FEMNIST
[INFO][08:17:02]: [Client #7] Loading its data source...
[INFO][08:17:02]: Data source: FEMNIST
[INFO][08:17:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:17:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/336.zip.
[INFO][08:17:03]: [Client #7] Dataset size: 159
[INFO][08:17:03]: [Client #7] Sampler: all_inclusive
[INFO][08:17:03]: [Client #7] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:03]: [93m[1m[Client #7] Started training in communication round #3.[0m

2.2%
4.5%
6.7%
8.9%
11.1%
13.4%
15.6%
17.8%
20.0%
22.3%
24.5%
26.7%
28.9%
31.2%
33.4%
35.6%
37.8%
40.1%
42.3%
44.5%
46.7%
49.0%
51.2%
53.4%
55.6%
57.9%
60.1%
62.3%
64.5%
66.8%
69.0%
71.2%
73.4%
75.7%
77.9%
80.1%
82.4%
84.6%
86.8%
89.0%
91.3%
93.5%
95.7%
97.9%
100.0%[INFO][08:17:03]: Decompressing the dataset downloaded.
[INFO][08:17:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/336.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:17:03]: [Client #336] Dataset size: 160
[INFO][08:17:03]: [Client #336] Sampler: all_inclusive
[INFO][08:17:03]: [Client #336] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:03]: [93m[1m[Client #336] Started training in communication round #3.[0m

[INFO][08:17:04]: [Client #7] Loading the dataset.
[INFO][08:17:05]: [Client #336] Loading the dataset.
[INFO][08:17:10]: [Client #7] Epoch: [1/5][0/16]	Loss: 3.191669
[INFO][08:17:10]: [Client #336] Epoch: [1/5][0/16]	Loss: 3.663640
[INFO][08:17:10]: [Client #7] Epoch: [1/5][10/16]	Loss: 3.774512
[INFO][08:17:10]: [Client #336] Epoch: [1/5][10/16]	Loss: 3.160053
[INFO][08:17:10]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][08:17:10]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][08:17:10]: [Client #336] Woke up.
[INFO][08:17:10]: [Client #336] Epoch: [2/5][0/16]	Loss: 3.403944
[INFO][08:17:10]: [Client #336] Epoch: [2/5][10/16]	Loss: 2.875168
[INFO][08:17:10]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][08:17:10]: [Client #336] Woke up.
[INFO][08:17:10]: [Client #7] Woke up.
[INFO][08:17:10]: [Client #336] Epoch: [3/5][0/16]	Loss: 2.976361
[INFO][08:17:10]: [Client #7] Epoch: [2/5][0/16]	Loss: 3.319118
[INFO][08:17:10]: [Client #7] Epoch: [2/5][10/16]	Loss: 3.101759
[INFO][08:17:10]: [Client #336] Epoch: [3/5][10/16]	Loss: 2.639001
[INFO][08:17:10]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][08:17:10]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][08:17:10]: [Client #336] Woke up.
[INFO][08:17:10]: [Client #336] Epoch: [4/5][0/16]	Loss: 2.221762
[INFO][08:17:11]: [Client #336] Epoch: [4/5][10/16]	Loss: 2.667293
[INFO][08:17:11]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][08:17:11]: [Client #336] Woke up.
[INFO][08:17:11]: [Client #336] Epoch: [5/5][0/16]	Loss: 2.157323
[INFO][08:17:11]: [Client #7] Woke up.
[INFO][08:17:11]: [Client #7] Epoch: [3/5][0/16]	Loss: 2.993155
[INFO][08:17:11]: [Client #336] Epoch: [5/5][10/16]	Loss: 1.964634
[INFO][08:17:11]: [Client #7] Epoch: [3/5][10/16]	Loss: 2.417626
[INFO][08:17:11]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][08:17:11]: [Client #336] Woke up.
[INFO][08:17:11]: [Client #336] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_554860.pth.
[INFO][08:17:11]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][08:17:11]: [Client #7] Woke up.
[INFO][08:17:11]: [Client #7] Epoch: [4/5][0/16]	Loss: 1.940337
[INFO][08:17:11]: [Client #7] Epoch: [4/5][10/16]	Loss: 2.444629
[INFO][08:17:11]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][08:17:11]: [Client #7] Woke up.
[INFO][08:17:11]: [Client #7] Epoch: [5/5][0/16]	Loss: 1.466827
[INFO][08:17:11]: [Client #336] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_554860.pth.
[INFO][08:17:11]: [Client #336] Model trained.
[INFO][08:17:11]: [Client #336] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:11]: [Server #554754] Received 0.26 MB of payload data from client #336 (simulated).
[INFO][08:17:11]: [Client #7] Epoch: [5/5][10/16]	Loss: 1.226628
[INFO][08:17:12]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][08:17:12]: [Client #7] Woke up.
[INFO][08:17:12]: [Client #7] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554853.pth.
[INFO][08:17:12]: [Client #7] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554853.pth.
[INFO][08:17:12]: [Client #7] Model trained.
[INFO][08:17:12]: [Client #7] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:12]: [Server #554754] Received 0.26 MB of payload data from client #7 (simulated).
[INFO][08:17:12]: [Server #554754] Selecting client #344 for training.
[INFO][08:17:12]: [Server #554754] Sending the current model to client #344 (simulated).
[INFO][08:17:12]: [Server #554754] Sending 0.26 MB of payload data to client #344 (simulated).
[INFO][08:17:12]: [Server #554754] Selecting client #224 for training.
[INFO][08:17:12]: [Server #554754] Sending the current model to client #224 (simulated).
[INFO][08:17:12]: [Server #554754] Sending 0.26 MB of payload data to client #224 (simulated).
[INFO][08:17:12]: [Client #344] Selected by the server.
[INFO][08:17:12]: [Client #344] Loading its data source...
[INFO][08:17:12]: Data source: FEMNIST
[INFO][08:17:12]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:17:12]: [Client #224] Selected by the server.
[INFO][08:17:12]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/344.zip.
[INFO][08:17:12]: [Client #224] Loading its data source...
[INFO][08:17:12]: Data source: FEMNIST
[INFO][08:17:12]: [Client #224] Dataset size: 163
[INFO][08:17:12]: [Client #224] Sampler: all_inclusive
[INFO][08:17:12]: [Client #224] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:12]: [93m[1m[Client #224] Started training in communication round #3.[0m

2.2%
4.3%
6.5%
8.6%
10.8%
12.9%
15.1%
17.2%
19.4%
21.5%
23.7%
25.8%
28.0%
30.1%
32.3%
34.4%
36.6%
38.7%
40.9%
43.0%
45.2%
47.3%
49.5%
51.7%
53.8%
56.0%
58.1%
60.3%
62.4%
64.6%
66.7%
68.9%
71.0%
73.2%
75.3%
77.5%
79.6%
81.8%
83.9%
86.1%
88.2%
90.4%
92.5%
94.7%
96.9%
99.0%
100.0%[INFO][08:17:13]: Decompressing the dataset downloaded.
[INFO][08:17:13]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/344.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:17:13]: [Client #344] Dataset size: 153
[INFO][08:17:13]: [Client #344] Sampler: all_inclusive
[INFO][08:17:13]: [Client #344] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:13]: [93m[1m[Client #344] Started training in communication round #3.[0m

[INFO][08:17:14]: [Client #224] Loading the dataset.
[INFO][08:17:15]: [Client #344] Loading the dataset.
[INFO][08:17:20]: [Client #224] Epoch: [1/5][0/17]	Loss: 3.310115
[INFO][08:17:20]: [Client #344] Epoch: [1/5][0/16]	Loss: 3.723511
[INFO][08:17:20]: [Client #344] Epoch: [1/5][10/16]	Loss: 3.513021
[INFO][08:17:20]: [Client #224] Epoch: [1/5][10/17]	Loss: 2.906316
[INFO][08:17:20]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][08:17:20]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][08:17:24]: [Client #224] Woke up.
[INFO][08:17:24]: [Client #224] Epoch: [2/5][0/17]	Loss: 2.599535
[INFO][08:17:24]: [Client #224] Epoch: [2/5][10/17]	Loss: 3.177282
[INFO][08:17:24]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][08:17:26]: [Client #344] Woke up.
[INFO][08:17:26]: [Client #344] Epoch: [2/5][0/16]	Loss: 3.668416
[INFO][08:17:26]: [Client #344] Epoch: [2/5][10/16]	Loss: 2.875942
[INFO][08:17:26]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][08:17:29]: [Client #224] Woke up.
[INFO][08:17:29]: [Client #224] Epoch: [3/5][0/17]	Loss: 3.577801
[INFO][08:17:29]: [Client #224] Epoch: [3/5][10/17]	Loss: 2.898115
[INFO][08:17:29]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][08:17:32]: [Client #344] Woke up.
[INFO][08:17:32]: [Client #344] Epoch: [3/5][0/16]	Loss: 2.999463
[INFO][08:17:32]: [Client #344] Epoch: [3/5][10/16]	Loss: 2.707010
[INFO][08:17:32]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][08:17:33]: [Client #224] Woke up.
[INFO][08:17:33]: [Client #224] Epoch: [4/5][0/17]	Loss: 2.404828
[INFO][08:17:33]: [Client #224] Epoch: [4/5][10/17]	Loss: 2.373360
[INFO][08:17:33]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][08:17:38]: [Client #224] Woke up.
[INFO][08:17:38]: [Client #224] Epoch: [5/5][0/17]	Loss: 2.625279
[INFO][08:17:38]: [Client #224] Epoch: [5/5][10/17]	Loss: 2.374660
[INFO][08:17:38]: [Client #224] Going to sleep for 4.25 seconds.
[INFO][08:17:38]: [Client #344] Woke up.
[INFO][08:17:38]: [Client #344] Epoch: [4/5][0/16]	Loss: 2.267249
[INFO][08:17:38]: [Client #344] Epoch: [4/5][10/16]	Loss: 1.072946
[INFO][08:17:38]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][08:17:42]: [Client #224] Woke up.
[INFO][08:17:42]: [Client #224] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_224_554860.pth.
[INFO][08:17:43]: [Client #224] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_224_554860.pth.
[INFO][08:17:43]: [Client #224] Model trained.
[INFO][08:17:43]: [Client #224] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:43]: [Server #554754] Received 0.26 MB of payload data from client #224 (simulated).
[INFO][08:17:44]: [Client #344] Woke up.
[INFO][08:17:44]: [Client #344] Epoch: [5/5][0/16]	Loss: 2.335490
[INFO][08:17:44]: [Client #344] Epoch: [5/5][10/16]	Loss: 3.090087
[INFO][08:17:44]: [Client #344] Going to sleep for 5.85 seconds.
[INFO][08:17:50]: [Client #344] Woke up.
[INFO][08:17:50]: [Client #344] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_344_554853.pth.
[INFO][08:17:51]: [Client #344] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_344_554853.pth.
[INFO][08:17:51]: [Client #344] Model trained.
[INFO][08:17:51]: [Client #344] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:17:51]: [Server #554754] Received 0.26 MB of payload data from client #344 (simulated).
[INFO][08:17:51]: [Server #554754] Selecting client #458 for training.
[INFO][08:17:51]: [Server #554754] Sending the current model to client #458 (simulated).
[INFO][08:17:51]: [Server #554754] Sending 0.26 MB of payload data to client #458 (simulated).
[INFO][08:17:51]: [Server #554754] Selecting client #322 for training.
[INFO][08:17:51]: [Server #554754] Sending the current model to client #322 (simulated).
[INFO][08:17:51]: [Server #554754] Sending 0.26 MB of payload data to client #322 (simulated).
[INFO][08:17:51]: [Client #458] Selected by the server.
[INFO][08:17:51]: [Client #458] Loading its data source...
[INFO][08:17:51]: Data source: FEMNIST
[INFO][08:17:51]: [Client #322] Selected by the server.
[INFO][08:17:51]: [Client #322] Loading its data source...
[INFO][08:17:51]: Data source: FEMNIST
[INFO][08:17:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:17:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/322.zip.
[INFO][08:17:51]: [Client #458] Dataset size: 163
[INFO][08:17:51]: [Client #458] Sampler: all_inclusive
[INFO][08:17:51]: [Client #458] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:51]: [93m[1m[Client #458] Started training in communication round #3.[0m

2.3%
4.6%
6.9%
9.2%
11.5%
13.8%
16.0%
18.3%
20.6%
22.9%
25.2%
27.5%
29.8%
32.1%
34.4%
36.7%
39.0%
41.3%
43.5%
45.8%
48.1%
50.4%
52.7%
55.0%
57.3%
59.6%
61.9%
64.2%
66.5%
68.8%
71.0%
73.3%
75.6%
77.9%
80.2%
82.5%
84.8%
87.1%
89.4%
91.7%
94.0%
96.3%
98.5%
100.0%[INFO][08:17:51]: Decompressing the dataset downloaded.
[INFO][08:17:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/322.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:17:51]: [Client #322] Dataset size: 218
[INFO][08:17:51]: [Client #322] Sampler: all_inclusive
[INFO][08:17:51]: [Client #322] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:17:51]: [93m[1m[Client #322] Started training in communication round #3.[0m

[INFO][08:17:52]: [Client #458] Loading the dataset.
[INFO][08:17:53]: [Client #322] Loading the dataset.
[INFO][08:17:58]: [Client #458] Epoch: [1/5][0/17]	Loss: 3.549460
[INFO][08:17:58]: [Client #458] Epoch: [1/5][10/17]	Loss: 2.732493
[INFO][08:17:58]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][08:17:58]: [Client #322] Epoch: [1/5][0/22]	Loss: 4.367070
[INFO][08:17:58]: [Client #322] Epoch: [1/5][10/22]	Loss: 4.179027
[INFO][08:17:59]: [Client #322] Epoch: [1/5][20/22]	Loss: 4.039334
[INFO][08:17:59]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:17:59]: [Client #458] Woke up.
[INFO][08:17:59]: [Client #458] Epoch: [2/5][0/17]	Loss: 3.458780
[INFO][08:17:59]: [Client #458] Epoch: [2/5][10/17]	Loss: 3.387059
[INFO][08:17:59]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][08:18:00]: [Client #458] Woke up.
[INFO][08:18:00]: [Client #458] Epoch: [3/5][0/17]	Loss: 3.305575
[INFO][08:18:00]: [Client #458] Epoch: [3/5][10/17]	Loss: 3.200091
[INFO][08:18:00]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][08:18:00]: [Client #322] Woke up.
[INFO][08:18:00]: [Client #322] Epoch: [2/5][0/22]	Loss: 3.854446
[INFO][08:18:00]: [Client #322] Epoch: [2/5][10/22]	Loss: 3.893913
[INFO][08:18:00]: [Client #322] Epoch: [2/5][20/22]	Loss: 3.618079
[INFO][08:18:00]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:18:00]: [Client #458] Woke up.
[INFO][08:18:00]: [Client #458] Epoch: [4/5][0/17]	Loss: 1.949220
[INFO][08:18:00]: [Client #458] Epoch: [4/5][10/17]	Loss: 2.892942
[INFO][08:18:01]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][08:18:01]: [Client #458] Woke up.
[INFO][08:18:01]: [Client #458] Epoch: [5/5][0/17]	Loss: 2.670258
[INFO][08:18:01]: [Client #458] Epoch: [5/5][10/17]	Loss: 3.402281
[INFO][08:18:01]: [Client #458] Going to sleep for 0.67 seconds.
[INFO][08:18:02]: [Client #322] Woke up.
[INFO][08:18:02]: [Client #322] Epoch: [3/5][0/22]	Loss: 3.383122
[INFO][08:18:02]: [Client #458] Woke up.
[INFO][08:18:02]: [Client #458] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_458_554853.pth.
[INFO][08:18:02]: [Client #322] Epoch: [3/5][10/22]	Loss: 3.345379
[INFO][08:18:02]: [Client #322] Epoch: [3/5][20/22]	Loss: 3.056455
[INFO][08:18:02]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:18:03]: [Client #458] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_458_554853.pth.
[INFO][08:18:03]: [Client #458] Model trained.
[INFO][08:18:03]: [Client #458] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:18:03]: [Server #554754] Received 0.26 MB of payload data from client #458 (simulated).
[INFO][08:18:04]: [Client #322] Woke up.
[INFO][08:18:04]: [Client #322] Epoch: [4/5][0/22]	Loss: 2.947763
[INFO][08:18:04]: [Client #322] Epoch: [4/5][10/22]	Loss: 3.920818
[INFO][08:18:04]: [Client #322] Epoch: [4/5][20/22]	Loss: 3.268859
[INFO][08:18:04]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:18:06]: [Client #322] Woke up.
[INFO][08:18:06]: [Client #322] Epoch: [5/5][0/22]	Loss: 3.353562
[INFO][08:18:06]: [Client #322] Epoch: [5/5][10/22]	Loss: 3.658674
[INFO][08:18:06]: [Client #322] Epoch: [5/5][20/22]	Loss: 2.608947
[INFO][08:18:06]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:18:07]: [Client #322] Woke up.
[INFO][08:18:07]: [Client #322] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554860.pth.
[INFO][08:18:08]: [Client #322] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554860.pth.
[INFO][08:18:08]: [Client #322] Model trained.
[INFO][08:18:08]: [Client #322] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:18:08]: [Server #554754] Received 0.26 MB of payload data from client #322 (simulated).
[INFO][08:18:08]: [Server #554754] Selecting client #3 for training.
[INFO][08:18:08]: [Server #554754] Sending the current model to client #3 (simulated).
[INFO][08:18:08]: [Server #554754] Sending 0.26 MB of payload data to client #3 (simulated).
[INFO][08:18:08]: [Server #554754] Selecting client #242 for training.
[INFO][08:18:08]: [Server #554754] Sending the current model to client #242 (simulated).
[INFO][08:18:08]: [Server #554754] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][08:18:08]: [Client #3] Selected by the server.
[INFO][08:18:08]: [Client #3] Loading its data source...
[INFO][08:18:08]: [Client #242] Selected by the server.
[INFO][08:18:08]: Data source: FEMNIST
[INFO][08:18:08]: [Client #242] Loading its data source...
[INFO][08:18:08]: Data source: FEMNIST
[INFO][08:18:08]: [Client #242] Dataset size: 146
[INFO][08:18:08]: [Client #242] Sampler: all_inclusive
[INFO][08:18:08]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:18:08]: [93m[1m[Client #242] Started training in communication round #3.[0m
[INFO][08:18:08]: [Client #3] Dataset size: 165
[INFO][08:18:08]: [Client #3] Sampler: all_inclusive
[INFO][08:18:08]: [Client #3] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:18:08]: [93m[1m[Client #3] Started training in communication round #3.[0m
[INFO][08:18:10]: [Client #242] Loading the dataset.
[INFO][08:18:10]: [Client #3] Loading the dataset.
[INFO][08:18:15]: [Client #242] Epoch: [1/5][0/15]	Loss: 3.539310
[INFO][08:18:16]: [Client #3] Epoch: [1/5][0/17]	Loss: 3.645605
[INFO][08:18:16]: [Client #242] Epoch: [1/5][10/15]	Loss: 3.290285
[INFO][08:18:16]: [Client #3] Epoch: [1/5][10/17]	Loss: 3.514344
[INFO][08:18:16]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:18:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][08:18:16]: [Client #3] Woke up.
[INFO][08:18:16]: [Client #3] Epoch: [2/5][0/17]	Loss: 3.431588
[INFO][08:18:16]: [Client #3] Epoch: [2/5][10/17]	Loss: 2.757329
[INFO][08:18:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][08:18:16]: [Client #3] Woke up.
[INFO][08:18:16]: [Client #3] Epoch: [3/5][0/17]	Loss: 2.882309
[INFO][08:18:16]: [Client #3] Epoch: [3/5][10/17]	Loss: 2.654411
[INFO][08:18:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][08:18:16]: [Client #3] Woke up.
[INFO][08:18:16]: [Client #3] Epoch: [4/5][0/17]	Loss: 1.768203
[INFO][08:18:16]: [Client #3] Epoch: [4/5][10/17]	Loss: 2.889019
[INFO][08:18:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][08:18:16]: [Client #3] Woke up.
[INFO][08:18:16]: [Client #3] Epoch: [5/5][0/17]	Loss: 2.443228
[INFO][08:18:16]: [Client #3] Epoch: [5/5][10/17]	Loss: 2.873842
[INFO][08:18:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][08:18:16]: [Client #3] Woke up.
[INFO][08:18:16]: [Client #3] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_3_554853.pth.
[INFO][08:18:17]: [Client #3] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_3_554853.pth.
[INFO][08:18:17]: [Client #3] Model trained.
[INFO][08:18:17]: [Client #3] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:18:17]: [Server #554754] Received 0.26 MB of payload data from client #3 (simulated).
[INFO][08:18:24]: [Client #242] Woke up.
[INFO][08:18:24]: [Client #242] Epoch: [2/5][0/15]	Loss: 3.875550
[INFO][08:18:24]: [Client #242] Epoch: [2/5][10/15]	Loss: 2.671943
[INFO][08:18:24]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:18:32]: [Client #242] Woke up.
[INFO][08:18:32]: [Client #242] Epoch: [3/5][0/15]	Loss: 3.290579
[INFO][08:18:33]: [Client #242] Epoch: [3/5][10/15]	Loss: 3.649765
[INFO][08:18:33]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:18:41]: [Client #242] Woke up.
[INFO][08:18:41]: [Client #242] Epoch: [4/5][0/15]	Loss: 2.655108
[INFO][08:18:41]: [Client #242] Epoch: [4/5][10/15]	Loss: 2.492472
[INFO][08:18:41]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:18:49]: [Client #242] Woke up.
[INFO][08:18:49]: [Client #242] Epoch: [5/5][0/15]	Loss: 1.892213
[INFO][08:18:50]: [Client #242] Epoch: [5/5][10/15]	Loss: 2.703984
[INFO][08:18:50]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:18:58]: [Client #242] Woke up.
[INFO][08:18:58]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554860.pth.
[INFO][08:18:59]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554860.pth.
[INFO][08:18:59]: [Client #242] Model trained.
[INFO][08:18:59]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:18:59]: [Server #554754] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][08:18:59]: [Server #554754] Adding client #336 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #3 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #7 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #385 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #259 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #337 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #458 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #405 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #66 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Adding client #232 to the list of clients for aggregation.
[INFO][08:18:59]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.10981164 0.         0.         0.
 0.15429069 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13719844
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08912197 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0979637  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11773936
 0.08744037 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08432156 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08910153 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12052661 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.10981164 0.         0.         0.
 0.15429069 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13719844
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08912197 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0979637  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11773936
 0.08744037 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08432156 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08910153 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12052661 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:19:42]: [Server #554754] Global model accuracy: 24.44%

[INFO][08:19:42]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_3.pth.
[INFO][08:19:42]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_3.pth.
[INFO][08:19:42]: [93m[1m
[Server #554754] Starting round 4/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.04976816 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.002
 0.002      0.002      0.0920354  0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.002
 0.09380531 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04760433 0.002      0.04976816
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.10305344 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04513138 0.002      0.002      0.002      0.002      0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][08:19:43]: [Server #554754] Selected clients: [432 417 327 339 291 137 281 338 176 430]
[INFO][08:19:43]: [Server #554754] Selecting client #432 for training.
[INFO][08:19:43]: [Server #554754] Sending the current model to client #432 (simulated).
[INFO][08:19:43]: [Server #554754] Sending 0.26 MB of payload data to client #432 (simulated).
[INFO][08:19:43]: [Server #554754] Selecting client #417 for training.
[INFO][08:19:43]: [Server #554754] Sending the current model to client #417 (simulated).
[INFO][08:19:43]: [Server #554754] Sending 0.26 MB of payload data to client #417 (simulated).
[INFO][08:19:43]: [Client #432] Selected by the server.
[INFO][08:19:43]: [Client #432] Loading its data source...
[INFO][08:19:43]: Data source: FEMNIST
[INFO][08:19:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:19:43]: [Client #417] Selected by the server.
[INFO][08:19:43]: [Client #417] Loading its data source...
[INFO][08:19:43]: Data source: FEMNIST
[INFO][08:19:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/432.zip.
[INFO][08:19:43]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:19:43]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/417.zip.

2.8%
5.5%
8.3%
11.0%
13.8%
16.5%
19.3%
22.0%
24.8%
27.5%
30.3%
33.1%
35.8%
38.6%
41.3%
44.1%
2.3%
46.8%
49.6%
52.3%
55.1%
57.8%
60.6%
63.4%
66.1%
68.9%
4.5%
6.8%
9.1%
11.4%
13.6%
15.9%
18.2%
20.4%
22.7%
25.0%
27.3%
29.5%
31.8%
34.1%
36.3%
38.6%
40.9%
43.2%
45.4%
47.7%
50.0%
52.2%
54.5%
56.8%
59.1%
61.3%
63.6%
65.9%
68.2%
70.4%
72.7%
75.0%
77.2%
79.5%
81.8%
84.1%
86.3%
88.6%
90.9%
93.1%
95.4%
97.7%
100.0%
100.0%[INFO][08:19:43]: Decompressing the dataset downloaded.
[INFO][08:19:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/432.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

71.6%
74.4%
77.1%
79.9%
82.6%
85.4%
88.2%
90.9%
93.7%
96.4%
99.2%
100.0%[INFO][08:19:43]: Decompressing the dataset downloaded.
[INFO][08:19:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/417.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:19:43]: [Client #432] Dataset size: 160
[INFO][08:19:43]: [Client #432] Sampler: all_inclusive
[INFO][08:19:43]: [Client #432] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:19:43]: [93m[1m[Client #432] Started training in communication round #4.[0m

[INFO][08:19:43]: [Client #417] Dataset size: 157
[INFO][08:19:43]: [Client #417] Sampler: all_inclusive
[INFO][08:19:43]: [Client #417] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:19:43]: [93m[1m[Client #417] Started training in communication round #4.[0m

[INFO][08:19:45]: [Client #432] Loading the dataset.
[INFO][08:19:45]: [Client #417] Loading the dataset.
[INFO][08:19:50]: [Client #417] Epoch: [1/5][0/16]	Loss: 2.515552
[INFO][08:19:50]: [Client #432] Epoch: [1/5][0/16]	Loss: 2.304400
[INFO][08:19:50]: [Client #417] Epoch: [1/5][10/16]	Loss: 2.529076
[INFO][08:19:50]: [Client #417] Going to sleep for 5.49 seconds.
[INFO][08:19:50]: [Client #432] Epoch: [1/5][10/16]	Loss: 2.255294
[INFO][08:19:50]: [Client #432] Going to sleep for 0.82 seconds.
[INFO][08:19:51]: [Client #432] Woke up.
[INFO][08:19:51]: [Client #432] Epoch: [2/5][0/16]	Loss: 3.362532
[INFO][08:19:51]: [Client #432] Epoch: [2/5][10/16]	Loss: 1.609898
[INFO][08:19:51]: [Client #432] Going to sleep for 0.82 seconds.
[INFO][08:19:52]: [Client #432] Woke up.
[INFO][08:19:52]: [Client #432] Epoch: [3/5][0/16]	Loss: 2.044808
[INFO][08:19:52]: [Client #432] Epoch: [3/5][10/16]	Loss: 1.665093
[INFO][08:19:52]: [Client #432] Going to sleep for 0.82 seconds.
[INFO][08:19:53]: [Client #432] Woke up.
[INFO][08:19:53]: [Client #432] Epoch: [4/5][0/16]	Loss: 1.094691
[INFO][08:19:53]: [Client #432] Epoch: [4/5][10/16]	Loss: 2.769300
[INFO][08:19:53]: [Client #432] Going to sleep for 0.82 seconds.
[INFO][08:19:54]: [Client #432] Woke up.
[INFO][08:19:54]: [Client #432] Epoch: [5/5][0/16]	Loss: 2.756777
[INFO][08:19:54]: [Client #432] Epoch: [5/5][10/16]	Loss: 0.952227
[INFO][08:19:54]: [Client #432] Going to sleep for 0.82 seconds.
[INFO][08:19:55]: [Client #432] Woke up.
[INFO][08:19:55]: [Client #432] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_432_554853.pth.
[INFO][08:19:56]: [Client #432] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_432_554853.pth.
[INFO][08:19:56]: [Client #417] Woke up.
[INFO][08:19:56]: [Client #432] Model trained.
[INFO][08:19:56]: [Client #432] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:19:56]: [Server #554754] Received 0.26 MB of payload data from client #432 (simulated).
[INFO][08:19:56]: [Client #417] Epoch: [2/5][0/16]	Loss: 2.837939
[INFO][08:19:56]: [Client #417] Epoch: [2/5][10/16]	Loss: 3.870418
[INFO][08:19:56]: [Client #417] Going to sleep for 5.49 seconds.
[INFO][08:20:01]: [Client #417] Woke up.
[INFO][08:20:01]: [Client #417] Epoch: [3/5][0/16]	Loss: 2.509353
[INFO][08:20:02]: [Client #417] Epoch: [3/5][10/16]	Loss: 1.762790
[INFO][08:20:02]: [Client #417] Going to sleep for 5.49 seconds.
[INFO][08:20:07]: [Client #417] Woke up.
[INFO][08:20:07]: [Client #417] Epoch: [4/5][0/16]	Loss: 2.379240
[INFO][08:20:07]: [Client #417] Epoch: [4/5][10/16]	Loss: 1.772000
[INFO][08:20:07]: [Client #417] Going to sleep for 5.49 seconds.
[INFO][08:20:13]: [Client #417] Woke up.
[INFO][08:20:13]: [Client #417] Epoch: [5/5][0/16]	Loss: 2.422913
[INFO][08:20:13]: [Client #417] Epoch: [5/5][10/16]	Loss: 2.136118
[INFO][08:20:13]: [Client #417] Going to sleep for 5.49 seconds.
[INFO][08:20:18]: [Client #417] Woke up.
[INFO][08:20:18]: [Client #417] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_417_554860.pth.
[INFO][08:20:19]: [Client #417] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_417_554860.pth.
[INFO][08:20:19]: [Client #417] Model trained.
[INFO][08:20:19]: [Client #417] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:20:19]: [Server #554754] Received 0.26 MB of payload data from client #417 (simulated).
[INFO][08:20:19]: [Server #554754] Selecting client #327 for training.
[INFO][08:20:19]: [Server #554754] Sending the current model to client #327 (simulated).
[INFO][08:20:19]: [Server #554754] Sending 0.26 MB of payload data to client #327 (simulated).
[INFO][08:20:19]: [Server #554754] Selecting client #339 for training.
[INFO][08:20:19]: [Server #554754] Sending the current model to client #339 (simulated).
[INFO][08:20:19]: [Server #554754] Sending 0.26 MB of payload data to client #339 (simulated).
[INFO][08:20:19]: [Client #339] Selected by the server.
[INFO][08:20:19]: [Client #339] Loading its data source...
[INFO][08:20:19]: [Client #327] Selected by the server.
[INFO][08:20:19]: Data source: FEMNIST
[INFO][08:20:19]: [Client #327] Loading its data source...
[INFO][08:20:19]: Data source: FEMNIST
[INFO][08:20:19]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:20:19]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:20:19]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/339.zip.
[INFO][08:20:19]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/327.zip.

2.4%
4.7%
7.1%
9.4%
11.8%
14.2%
16.5%
18.9%
21.2%
23.6%
26.0%
28.3%
30.7%
33.0%
35.4%
37.8%
40.1%
42.5%
44.8%
47.2%
49.6%
51.9%
54.3%
56.7%
59.0%
61.4%
63.7%
66.1%
68.5%
70.8%
73.2%
75.5%
77.9%
80.3%
82.6%
85.0%
87.3%
89.7%
92.1%
94.4%
96.8%
99.1%
100.0%[INFO][08:20:19]: Decompressing the dataset downloaded.
[INFO][08:20:19]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/327.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:20:19]: [Client #327] Dataset size: 155
[INFO][08:20:19]: [Client #327] Sampler: all_inclusive
[INFO][08:20:19]: [Client #327] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:20:19]: [93m[1m[Client #327] Started training in communication round #4.[0m


2.5%
5.0%
7.5%
10.0%
12.5%
15.0%
17.5%
20.0%
22.5%
25.0%
27.5%
30.1%
32.6%
35.1%
37.6%
40.1%
42.6%
45.1%
47.6%
50.1%
52.6%
55.1%
57.6%
60.1%
62.6%
65.1%
67.6%
70.1%
72.6%
75.1%
77.6%
80.1%
82.6%
85.1%
87.6%
90.2%
92.7%
95.2%
97.7%
100.0%[INFO][08:20:19]: Decompressing the dataset downloaded.
[INFO][08:20:19]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/339.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:20:19]: [Client #339] Dataset size: 145
[INFO][08:20:19]: [Client #339] Sampler: all_inclusive
[INFO][08:20:19]: [Client #339] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:20:19]: [93m[1m[Client #339] Started training in communication round #4.[0m

[INFO][08:20:21]: [Client #327] Loading the dataset.
[INFO][08:20:21]: [Client #339] Loading the dataset.
[INFO][08:20:27]: [Client #327] Epoch: [1/5][0/16]	Loss: 2.418943
[INFO][08:20:27]: [Client #339] Epoch: [1/5][0/15]	Loss: 2.173684
[INFO][08:20:27]: [Client #327] Epoch: [1/5][10/16]	Loss: 2.984794
[INFO][08:20:27]: [Client #339] Epoch: [1/5][10/15]	Loss: 2.650079
[INFO][08:20:27]: [Client #339] Going to sleep for 5.44 seconds.
[INFO][08:20:27]: [Client #327] Going to sleep for 0.18 seconds.
[INFO][08:20:27]: [Client #327] Woke up.
[INFO][08:20:27]: [Client #327] Epoch: [2/5][0/16]	Loss: 2.635767
[INFO][08:20:27]: [Client #327] Epoch: [2/5][10/16]	Loss: 2.195551
[INFO][08:20:27]: [Client #327] Going to sleep for 0.18 seconds.
[INFO][08:20:27]: [Client #327] Woke up.
[INFO][08:20:27]: [Client #327] Epoch: [3/5][0/16]	Loss: 1.360602
[INFO][08:20:27]: [Client #327] Epoch: [3/5][10/16]	Loss: 1.981815
[INFO][08:20:28]: [Client #327] Going to sleep for 0.18 seconds.
[INFO][08:20:28]: [Client #327] Woke up.
[INFO][08:20:28]: [Client #327] Epoch: [4/5][0/16]	Loss: 3.173423
[INFO][08:20:28]: [Client #327] Epoch: [4/5][10/16]	Loss: 2.576917
[INFO][08:20:28]: [Client #327] Going to sleep for 0.18 seconds.
[INFO][08:20:28]: [Client #327] Woke up.
[INFO][08:20:28]: [Client #327] Epoch: [5/5][0/16]	Loss: 1.707155
[INFO][08:20:28]: [Client #327] Epoch: [5/5][10/16]	Loss: 2.479075
[INFO][08:20:28]: [Client #327] Going to sleep for 0.18 seconds.
[INFO][08:20:28]: [Client #327] Woke up.
[INFO][08:20:28]: [Client #327] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_327_554853.pth.
[INFO][08:20:29]: [Client #327] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_327_554853.pth.
[INFO][08:20:29]: [Client #327] Model trained.
[INFO][08:20:29]: [Client #327] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:20:29]: [Server #554754] Received 0.26 MB of payload data from client #327 (simulated).
[INFO][08:20:32]: [Client #339] Woke up.
[INFO][08:20:32]: [Client #339] Epoch: [2/5][0/15]	Loss: 2.385399
[INFO][08:20:32]: [Client #339] Epoch: [2/5][10/15]	Loss: 3.147544
[INFO][08:20:32]: [Client #339] Going to sleep for 5.44 seconds.
[INFO][08:20:38]: [Client #339] Woke up.
[INFO][08:20:38]: [Client #339] Epoch: [3/5][0/15]	Loss: 2.441312
[INFO][08:20:38]: [Client #339] Epoch: [3/5][10/15]	Loss: 2.349571
[INFO][08:20:38]: [Client #339] Going to sleep for 5.44 seconds.
[INFO][08:20:43]: [Client #339] Woke up.
[INFO][08:20:43]: [Client #339] Epoch: [4/5][0/15]	Loss: 1.887991
[INFO][08:20:44]: [Client #339] Epoch: [4/5][10/15]	Loss: 2.528931
[INFO][08:20:44]: [Client #339] Going to sleep for 5.44 seconds.
[INFO][08:20:49]: [Client #339] Woke up.
[INFO][08:20:49]: [Client #339] Epoch: [5/5][0/15]	Loss: 1.933128
[INFO][08:20:49]: [Client #339] Epoch: [5/5][10/15]	Loss: 2.049802
[INFO][08:20:49]: [Client #339] Going to sleep for 5.44 seconds.
[INFO][08:20:55]: [Client #339] Woke up.
[INFO][08:20:55]: [Client #339] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_339_554860.pth.
[INFO][08:20:55]: [Client #339] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_339_554860.pth.
[INFO][08:20:55]: [Client #339] Model trained.
[INFO][08:20:55]: [Client #339] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:20:55]: [Server #554754] Received 0.26 MB of payload data from client #339 (simulated).
[INFO][08:20:55]: [Server #554754] Selecting client #291 for training.
[INFO][08:20:55]: [Server #554754] Sending the current model to client #291 (simulated).
[INFO][08:20:55]: [Server #554754] Sending 0.26 MB of payload data to client #291 (simulated).
[INFO][08:20:55]: [Server #554754] Selecting client #137 for training.
[INFO][08:20:55]: [Server #554754] Sending the current model to client #137 (simulated).
[INFO][08:20:55]: [Server #554754] Sending 0.26 MB of payload data to client #137 (simulated).
[INFO][08:20:55]: [Client #137] Selected by the server.
[INFO][08:20:55]: [Client #291] Selected by the server.
[INFO][08:20:55]: [Client #137] Loading its data source...
[INFO][08:20:55]: [Client #291] Loading its data source...
[INFO][08:20:55]: Data source: FEMNIST
[INFO][08:20:55]: Data source: FEMNIST
[INFO][08:20:55]: [Client #137] Dataset size: 148
[INFO][08:20:55]: [Client #137] Sampler: all_inclusive
[INFO][08:20:55]: [Client #137] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:20:55]: [93m[1m[Client #137] Started training in communication round #4.[0m
[INFO][08:20:55]: [Client #291] Dataset size: 163
[INFO][08:20:55]: [Client #291] Sampler: all_inclusive
[INFO][08:20:55]: [Client #291] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:20:55]: [93m[1m[Client #291] Started training in communication round #4.[0m
[INFO][08:20:57]: [Client #137] Loading the dataset.
[INFO][08:20:57]: [Client #291] Loading the dataset.
[INFO][08:21:03]: [Client #137] Epoch: [1/5][0/15]	Loss: 3.302194
[INFO][08:21:03]: [Client #291] Epoch: [1/5][0/17]	Loss: 2.543520
[INFO][08:21:03]: [Client #137] Epoch: [1/5][10/15]	Loss: 3.104846
[INFO][08:21:03]: [Client #291] Epoch: [1/5][10/17]	Loss: 2.982090
[INFO][08:21:03]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:21:03]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][08:21:04]: [Client #291] Woke up.
[INFO][08:21:04]: [Client #291] Epoch: [2/5][0/17]	Loss: 2.739874
[INFO][08:21:04]: [Client #291] Epoch: [2/5][10/17]	Loss: 2.205060
[INFO][08:21:04]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][08:21:05]: [Client #291] Woke up.
[INFO][08:21:05]: [Client #291] Epoch: [3/5][0/17]	Loss: 2.818931
[INFO][08:21:05]: [Client #291] Epoch: [3/5][10/17]	Loss: 2.253297
[INFO][08:21:05]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][08:21:06]: [Client #291] Woke up.
[INFO][08:21:06]: [Client #291] Epoch: [4/5][0/17]	Loss: 1.186957
[INFO][08:21:07]: [Client #291] Epoch: [4/5][10/17]	Loss: 2.073104
[INFO][08:21:07]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][08:21:07]: [Client #137] Woke up.
[INFO][08:21:07]: [Client #137] Epoch: [2/5][0/15]	Loss: 2.628379
[INFO][08:21:07]: [Client #137] Epoch: [2/5][10/15]	Loss: 3.458853
[INFO][08:21:07]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:21:08]: [Client #291] Woke up.
[INFO][08:21:08]: [Client #291] Epoch: [5/5][0/17]	Loss: 1.576164
[INFO][08:21:08]: [Client #291] Epoch: [5/5][10/17]	Loss: 1.641526
[INFO][08:21:08]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][08:21:09]: [Client #291] Woke up.
[INFO][08:21:09]: [Client #291] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554853.pth.
[INFO][08:21:10]: [Client #291] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554853.pth.
[INFO][08:21:10]: [Client #291] Model trained.
[INFO][08:21:10]: [Client #291] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:21:10]: [Server #554754] Received 0.26 MB of payload data from client #291 (simulated).
[INFO][08:21:11]: [Client #137] Woke up.
[INFO][08:21:11]: [Client #137] Epoch: [3/5][0/15]	Loss: 2.620172
[INFO][08:21:11]: [Client #137] Epoch: [3/5][10/15]	Loss: 2.191032
[INFO][08:21:11]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:21:16]: [Client #137] Woke up.
[INFO][08:21:16]: [Client #137] Epoch: [4/5][0/15]	Loss: 1.498730
[INFO][08:21:16]: [Client #137] Epoch: [4/5][10/15]	Loss: 2.265841
[INFO][08:21:16]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:21:20]: [Client #137] Woke up.
[INFO][08:21:20]: [Client #137] Epoch: [5/5][0/15]	Loss: 2.339195
[INFO][08:21:20]: [Client #137] Epoch: [5/5][10/15]	Loss: 1.755802
[INFO][08:21:20]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:21:24]: [Client #137] Woke up.
[INFO][08:21:24]: [Client #137] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_137_554860.pth.
[INFO][08:21:25]: [Client #137] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_137_554860.pth.
[INFO][08:21:25]: [Client #137] Model trained.
[INFO][08:21:25]: [Client #137] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:21:25]: [Server #554754] Received 0.26 MB of payload data from client #137 (simulated).
[INFO][08:21:25]: [Server #554754] Selecting client #281 for training.
[INFO][08:21:25]: [Server #554754] Sending the current model to client #281 (simulated).
[INFO][08:21:25]: [Server #554754] Sending 0.26 MB of payload data to client #281 (simulated).
[INFO][08:21:25]: [Server #554754] Selecting client #338 for training.
[INFO][08:21:25]: [Server #554754] Sending the current model to client #338 (simulated).
[INFO][08:21:25]: [Server #554754] Sending 0.26 MB of payload data to client #338 (simulated).
[INFO][08:21:25]: [Client #338] Selected by the server.
[INFO][08:21:25]: [Client #281] Selected by the server.
[INFO][08:21:25]: [Client #338] Loading its data source...
[INFO][08:21:25]: [Client #281] Loading its data source...
[INFO][08:21:25]: Data source: FEMNIST
[INFO][08:21:25]: Data source: FEMNIST
[INFO][08:21:25]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:21:25]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/338.zip.
[INFO][08:21:25]: [Client #281] Dataset size: 164
[INFO][08:21:25]: [Client #281] Sampler: all_inclusive
[INFO][08:21:25]: [Client #281] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:21:25]: [93m[1m[Client #281] Started training in communication round #4.[0m

2.4%
4.8%
7.2%
9.6%
12.0%
14.4%
16.8%
19.2%
21.6%
24.0%
26.4%
28.8%
31.2%
33.6%
36.0%
38.4%
40.8%
43.2%
45.6%
48.0%
50.4%
52.8%
55.2%
57.6%
60.0%
62.4%
64.8%
67.2%
69.6%
72.0%
74.4%
76.8%
79.2%
81.6%
84.0%
86.4%
88.8%
91.2%
93.5%
95.9%
98.3%
100.0%[INFO][08:21:25]: Decompressing the dataset downloaded.
[INFO][08:21:25]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/338.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:21:25]: [Client #338] Dataset size: 158
[INFO][08:21:25]: [Client #338] Sampler: all_inclusive
[INFO][08:21:25]: [Client #338] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:21:25]: [93m[1m[Client #338] Started training in communication round #4.[0m

[INFO][08:21:27]: [Client #281] Loading the dataset.
[INFO][08:21:27]: [Client #338] Loading the dataset.
[INFO][08:21:32]: [Client #281] Epoch: [1/5][0/17]	Loss: 2.341974
[INFO][08:21:32]: [Client #338] Epoch: [1/5][0/16]	Loss: 2.398579
[INFO][08:21:33]: [Client #281] Epoch: [1/5][10/17]	Loss: 2.243557
[INFO][08:21:33]: [Client #338] Epoch: [1/5][10/16]	Loss: 2.039524
[INFO][08:21:33]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][08:21:33]: [Client #338] Going to sleep for 6.87 seconds.
[INFO][08:21:39]: [Client #338] Woke up.
[INFO][08:21:39]: [Client #338] Epoch: [2/5][0/16]	Loss: 2.562568
[INFO][08:21:40]: [Client #338] Epoch: [2/5][10/16]	Loss: 2.783562
[INFO][08:21:40]: [Client #338] Going to sleep for 6.87 seconds.
[INFO][08:21:40]: [Client #281] Woke up.
[INFO][08:21:40]: [Client #281] Epoch: [2/5][0/17]	Loss: 2.411281
[INFO][08:21:40]: [Client #281] Epoch: [2/5][10/17]	Loss: 2.166794
[INFO][08:21:40]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][08:21:46]: [Client #338] Woke up.
[INFO][08:21:46]: [Client #338] Epoch: [3/5][0/16]	Loss: 2.245240
[INFO][08:21:47]: [Client #338] Epoch: [3/5][10/16]	Loss: 2.497413
[INFO][08:21:47]: [Client #338] Going to sleep for 6.87 seconds.
[INFO][08:21:47]: [Client #281] Woke up.
[INFO][08:21:47]: [Client #281] Epoch: [3/5][0/17]	Loss: 1.607927
[INFO][08:21:48]: [Client #281] Epoch: [3/5][10/17]	Loss: 1.202656
[INFO][08:21:48]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][08:21:53]: [Client #338] Woke up.
[INFO][08:21:54]: [Client #338] Epoch: [4/5][0/16]	Loss: 2.099860
[INFO][08:21:54]: [Client #338] Epoch: [4/5][10/16]	Loss: 2.740313
[INFO][08:21:54]: [Client #338] Going to sleep for 6.87 seconds.
[INFO][08:21:55]: [Client #281] Woke up.
[INFO][08:21:55]: [Client #281] Epoch: [4/5][0/17]	Loss: 2.002314
[INFO][08:21:55]: [Client #281] Epoch: [4/5][10/17]	Loss: 2.463794
[INFO][08:21:55]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][08:22:01]: [Client #338] Woke up.
[INFO][08:22:01]: [Client #338] Epoch: [5/5][0/16]	Loss: 1.573348
[INFO][08:22:01]: [Client #338] Epoch: [5/5][10/16]	Loss: 2.173581
[INFO][08:22:01]: [Client #338] Going to sleep for 6.87 seconds.
[INFO][08:22:02]: [Client #281] Woke up.
[INFO][08:22:02]: [Client #281] Epoch: [5/5][0/17]	Loss: 2.086982
[INFO][08:22:03]: [Client #281] Epoch: [5/5][10/17]	Loss: 1.861945
[INFO][08:22:03]: [Client #281] Going to sleep for 7.33 seconds.
[INFO][08:22:08]: [Client #338] Woke up.
[INFO][08:22:08]: [Client #338] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_338_554860.pth.
[INFO][08:22:08]: [Client #338] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_338_554860.pth.
[INFO][08:22:08]: [Client #338] Model trained.
[INFO][08:22:08]: [Client #338] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:22:08]: [Server #554754] Received 0.26 MB of payload data from client #338 (simulated).
[INFO][08:22:10]: [Client #281] Woke up.
[INFO][08:22:10]: [Client #281] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_281_554853.pth.
[INFO][08:22:11]: [Client #281] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_281_554853.pth.
[INFO][08:22:11]: [Client #281] Model trained.
[INFO][08:22:11]: [Client #281] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:22:11]: [Server #554754] Received 0.26 MB of payload data from client #281 (simulated).
[INFO][08:22:11]: [Server #554754] Selecting client #176 for training.
[INFO][08:22:11]: [Server #554754] Sending the current model to client #176 (simulated).
[INFO][08:22:11]: [Server #554754] Sending 0.26 MB of payload data to client #176 (simulated).
[INFO][08:22:11]: [Server #554754] Selecting client #430 for training.
[INFO][08:22:11]: [Server #554754] Sending the current model to client #430 (simulated).
[INFO][08:22:11]: [Server #554754] Sending 0.26 MB of payload data to client #430 (simulated).
[INFO][08:22:11]: [Client #176] Selected by the server.
[INFO][08:22:11]: [Client #176] Loading its data source...
[INFO][08:22:11]: Data source: FEMNIST
[INFO][08:22:11]: [Client #430] Selected by the server.
[INFO][08:22:11]: [Client #430] Loading its data source...
[INFO][08:22:11]: Data source: FEMNIST
[INFO][08:22:11]: [Client #430] Dataset size: 160
[INFO][08:22:11]: [Client #430] Sampler: all_inclusive
[INFO][08:22:11]: [Client #430] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:22:11]: [93m[1m[Client #430] Started training in communication round #4.[0m
[INFO][08:22:11]: [Client #176] Dataset size: 148
[INFO][08:22:11]: [Client #176] Sampler: all_inclusive
[INFO][08:22:11]: [Client #176] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:22:11]: [93m[1m[Client #176] Started training in communication round #4.[0m
[INFO][08:22:13]: [Client #176] Loading the dataset.
[INFO][08:22:13]: [Client #430] Loading the dataset.
[INFO][08:22:18]: [Client #430] Epoch: [1/5][0/16]	Loss: 3.124779
[INFO][08:22:18]: [Client #176] Epoch: [1/5][0/15]	Loss: 3.007964
[INFO][08:22:18]: [Client #430] Epoch: [1/5][10/16]	Loss: 2.252615
[INFO][08:22:18]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:22:18]: [Client #176] Epoch: [1/5][10/15]	Loss: 1.824432
[INFO][08:22:18]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:22:21]: [Client #430] Woke up.
[INFO][08:22:21]: [Client #176] Woke up.
[INFO][08:22:21]: [Client #430] Epoch: [2/5][0/16]	Loss: 2.246092
[INFO][08:22:21]: [Client #176] Epoch: [2/5][0/15]	Loss: 1.861845
[INFO][08:22:21]: [Client #430] Epoch: [2/5][10/16]	Loss: 3.521450
[INFO][08:22:21]: [Client #176] Epoch: [2/5][10/15]	Loss: 2.816970
[INFO][08:22:21]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:22:21]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:22:24]: [Client #176] Woke up.
[INFO][08:22:24]: [Client #430] Woke up.
[INFO][08:22:24]: [Client #176] Epoch: [3/5][0/15]	Loss: 1.955152
[INFO][08:22:24]: [Client #430] Epoch: [3/5][0/16]	Loss: 3.681138
[INFO][08:22:24]: [Client #176] Epoch: [3/5][10/15]	Loss: 0.878525
[INFO][08:22:24]: [Client #430] Epoch: [3/5][10/16]	Loss: 2.504644
[INFO][08:22:24]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:22:24]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:22:27]: [Client #176] Woke up.
[INFO][08:22:27]: [Client #176] Epoch: [4/5][0/15]	Loss: 0.878486
[INFO][08:22:27]: [Client #430] Woke up.
[INFO][08:22:27]: [Client #430] Epoch: [4/5][0/16]	Loss: 1.856326
[INFO][08:22:27]: [Client #176] Epoch: [4/5][10/15]	Loss: 2.477059
[INFO][08:22:27]: [Client #430] Epoch: [4/5][10/16]	Loss: 2.189237
[INFO][08:22:27]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:22:27]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:22:30]: [Client #176] Woke up.
[INFO][08:22:30]: [Client #176] Epoch: [5/5][0/15]	Loss: 1.638947
[INFO][08:22:30]: [Client #430] Woke up.
[INFO][08:22:30]: [Client #430] Epoch: [5/5][0/16]	Loss: 3.793054
[INFO][08:22:30]: [Client #176] Epoch: [5/5][10/15]	Loss: 2.236810
[INFO][08:22:31]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:22:31]: [Client #430] Epoch: [5/5][10/16]	Loss: 1.681929
[INFO][08:22:31]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:22:33]: [Client #176] Woke up.
[INFO][08:22:33]: [Client #176] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554853.pth.
[INFO][08:22:34]: [Client #430] Woke up.
[INFO][08:22:34]: [Client #430] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554860.pth.
[INFO][08:22:34]: [Client #176] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554853.pth.
[INFO][08:22:34]: [Client #176] Model trained.
[INFO][08:22:34]: [Client #176] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:22:34]: [Server #554754] Received 0.26 MB of payload data from client #176 (simulated).
[INFO][08:22:34]: [Client #430] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554860.pth.
[INFO][08:22:34]: [Client #430] Model trained.
[INFO][08:22:34]: [Client #430] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:22:34]: [Server #554754] Received 0.26 MB of payload data from client #430 (simulated).
[INFO][08:22:34]: [Server #554754] Adding client #322 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #12 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #63 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #156 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #327 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #432 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #288 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #291 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #224 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #344 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #176 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #430 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #377 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #137 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #242 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #339 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #417 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #338 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #281 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Adding client #252 to the list of clients for aggregation.
[INFO][08:22:34]: [Server #554754] Aggregating 20 clients in total.
[0.00204083 0.00204083 0.00203995 0.00204083 0.00204083 0.00204083
 0.00203922 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00203951 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204027
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204043 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00203988 0.00204034 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204033 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.0020403  0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.0020398  0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083 0.00204083
 0.00204083 0.00204083 0.00204083 0.00204083]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06964017
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04640069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11050432 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.090377
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1016061  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06399889 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15668647 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07113967
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07720831 0.
 0.         0.         0.         0.         0.         0.09075501
 0.         0.         0.08748283 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20099768 0.         0.
 0.         0.         0.06462195 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10395401 0.05449536 0.         0.         0.
 0.         0.06260442 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08888358 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12529466 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09847315 0.         0.09099904
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06964017
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04640069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11050432 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.090377
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1016061  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06399889 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15668647 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07113967
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07720831 0.
 0.         0.         0.         0.         0.         0.09075501
 0.         0.         0.08748283 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20099768 0.         0.
 0.         0.         0.06462195 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10395401 0.05449536 0.         0.         0.
 0.         0.06260442 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08888358 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12529466 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09847315 0.         0.09099904
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:23:18]: [Server #554754] Global model accuracy: 28.07%

[INFO][08:23:18]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_4.pth.
[INFO][08:23:18]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_4.pth.
[INFO][08:23:18]: [93m[1m
[Server #554754] Starting round 5/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.04976816 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.002
 0.002      0.002      0.0920354  0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.002
 0.09380531 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04728435 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.04728435 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.04664537 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.06964856 0.002      0.002
 0.002      0.002      0.04952077 0.002      0.002      0.002
 0.002      0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04536741 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.10305344 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05111821 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04513138 0.002      0.002      0.002      0.002      0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9072e+00  5e-04  9e-09  9e-09
 5:  6.9078e+00  6.9076e+00  2e-04  3e-09  3e-09
 6:  6.9077e+00  6.9075e+00  2e-04  9e-09  2e-09
 7:  6.9077e+00  6.9076e+00  2e-04  9e-09  2e-09
 8:  6.9077e+00  6.9076e+00  9e-05  9e-08  2e-08
 9:  6.9076e+00  6.9076e+00  4e-05  8e-08  2e-08
10:  6.9076e+00  6.9076e+00  3e-06  4e-08  9e-09
Optimal solution found.
The calculated probability is:  [3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 9.06750093e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 6.25997895e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61280897e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 1.37961042e-04
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61296018e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 8.21995983e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.15591828e-03 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 9.31564204e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61320089e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 1.39173173e-04
 3.61378750e-05 3.61378750e-05 3.61304356e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 9.78317158e-01 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61342040e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61280056e-05 3.61355903e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 8.03042569e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 1.33374035e-04 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61237198e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61287931e-05 3.61378750e-05 3.61301192e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05
 3.61378750e-05 3.61378750e-05 3.61378750e-05 3.61378750e-05]
current clients pool:  [INFO][08:23:18]: [Server #554754] Selected clients: [322 380  47 137 123 451 331 242 178 401 455 328  74 486  94 120 237  72
 363  95]
[INFO][08:23:18]: [Server #554754] Selecting client #322 for training.
[INFO][08:23:18]: [Server #554754] Sending the current model to client #322 (simulated).
[INFO][08:23:18]: [Server #554754] Sending 0.26 MB of payload data to client #322 (simulated).
[INFO][08:23:18]: [Server #554754] Selecting client #380 for training.
[INFO][08:23:18]: [Server #554754] Sending the current model to client #380 (simulated).
[INFO][08:23:18]: [Server #554754] Sending 0.26 MB of payload data to client #380 (simulated).
[INFO][08:23:18]: [Client #322] Selected by the server.
[INFO][08:23:18]: [Client #322] Loading its data source...
[INFO][08:23:18]: Data source: FEMNIST
[INFO][08:23:18]: [Client #380] Selected by the server.
[INFO][08:23:18]: [Client #380] Loading its data source...
[INFO][08:23:18]: Data source: FEMNIST
[INFO][08:23:18]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:23:18]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/380.zip.
[INFO][08:23:19]: [Client #322] Dataset size: 218
[INFO][08:23:19]: [Client #322] Sampler: all_inclusive
[INFO][08:23:19]: [Client #322] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:23:19]: [93m[1m[Client #322] Started training in communication round #5.[0m

2.5%
5.0%
7.6%
10.1%
12.6%
15.1%
17.7%
20.2%
22.7%
25.2%
27.8%
30.3%
32.8%
35.3%
37.9%
40.4%
42.9%
45.4%
47.9%
50.5%
53.0%
55.5%
58.0%
60.6%
63.1%
65.6%
68.1%
70.7%
73.2%
75.7%
78.2%
80.8%
83.3%
85.8%
88.3%
90.8%
93.4%
95.9%
98.4%
100.0%[INFO][08:23:19]: Decompressing the dataset downloaded.
[INFO][08:23:19]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/380.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:23:19]: [Client #380] Dataset size: 159
[INFO][08:23:19]: [Client #380] Sampler: all_inclusive
[INFO][08:23:19]: [Client #380] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:23:19]: [93m[1m[Client #380] Started training in communication round #5.[0m

[INFO][08:23:20]: [Client #322] Loading the dataset.
[INFO][08:23:21]: [Client #380] Loading the dataset.
[INFO][08:23:26]: [Client #322] Epoch: [1/5][0/22]	Loss: 3.422960
[INFO][08:23:26]: [Client #322] Epoch: [1/5][10/22]	Loss: 3.447486
[INFO][08:23:26]: [Client #380] Epoch: [1/5][0/16]	Loss: 1.630379
[INFO][08:23:26]: [Client #322] Epoch: [1/5][20/22]	Loss: 3.867114
[INFO][08:23:26]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:23:26]: [Client #380] Epoch: [1/5][10/16]	Loss: 2.638780
[INFO][08:23:26]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:23:26]: [Client #380] Woke up.
[INFO][08:23:26]: [Client #380] Epoch: [2/5][0/16]	Loss: 2.844910
[INFO][08:23:26]: [Client #380] Epoch: [2/5][10/16]	Loss: 2.838199
[INFO][08:23:27]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:23:27]: [Client #380] Woke up.
[INFO][08:23:27]: [Client #380] Epoch: [3/5][0/16]	Loss: 1.085826
[INFO][08:23:27]: [Client #380] Epoch: [3/5][10/16]	Loss: 3.547307
[INFO][08:23:27]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:23:27]: [Client #380] Woke up.
[INFO][08:23:27]: [Client #380] Epoch: [4/5][0/16]	Loss: 2.908263
[INFO][08:23:27]: [Client #380] Epoch: [4/5][10/16]	Loss: 1.101943
[INFO][08:23:27]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:23:28]: [Client #380] Woke up.
[INFO][08:23:28]: [Client #380] Epoch: [5/5][0/16]	Loss: 1.856696
[INFO][08:23:28]: [Client #380] Epoch: [5/5][10/16]	Loss: 2.700544
[INFO][08:23:28]: [Client #322] Woke up.
[INFO][08:23:28]: [Client #322] Epoch: [2/5][0/22]	Loss: 3.283415
[INFO][08:23:28]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:23:28]: [Client #322] Epoch: [2/5][10/22]	Loss: 3.162141
[INFO][08:23:28]: [Client #322] Epoch: [2/5][20/22]	Loss: 3.120027
[INFO][08:23:28]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:23:28]: [Client #380] Woke up.
[INFO][08:23:28]: [Client #380] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_554860.pth.
[INFO][08:23:29]: [Client #380] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_554860.pth.
[INFO][08:23:29]: [Client #380] Model trained.
[INFO][08:23:29]: [Client #380] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:23:29]: [Server #554754] Received 0.26 MB of payload data from client #380 (simulated).
[INFO][08:23:29]: [Client #322] Woke up.
[INFO][08:23:29]: [Client #322] Epoch: [3/5][0/22]	Loss: 2.271873
[INFO][08:23:30]: [Client #322] Epoch: [3/5][10/22]	Loss: 2.858970
[INFO][08:23:30]: [Client #322] Epoch: [3/5][20/22]	Loss: 3.157403
[INFO][08:23:30]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:23:31]: [Client #322] Woke up.
[INFO][08:23:31]: [Client #322] Epoch: [4/5][0/22]	Loss: 2.054339
[INFO][08:23:31]: [Client #322] Epoch: [4/5][10/22]	Loss: 3.503355
[INFO][08:23:32]: [Client #322] Epoch: [4/5][20/22]	Loss: 3.047180
[INFO][08:23:32]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:23:33]: [Client #322] Woke up.
[INFO][08:23:33]: [Client #322] Epoch: [5/5][0/22]	Loss: 2.936523
[INFO][08:23:33]: [Client #322] Epoch: [5/5][10/22]	Loss: 1.996529
[INFO][08:23:33]: [Client #322] Epoch: [5/5][20/22]	Loss: 2.461920
[INFO][08:23:33]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:23:35]: [Client #322] Woke up.
[INFO][08:23:35]: [Client #322] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554853.pth.
[INFO][08:23:36]: [Client #322] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554853.pth.
[INFO][08:23:36]: [Client #322] Model trained.
[INFO][08:23:36]: [Client #322] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:23:36]: [Server #554754] Received 0.26 MB of payload data from client #322 (simulated).
[INFO][08:23:36]: [Server #554754] Selecting client #47 for training.
[INFO][08:23:36]: [Server #554754] Sending the current model to client #47 (simulated).
[INFO][08:23:36]: [Server #554754] Sending 0.26 MB of payload data to client #47 (simulated).
[INFO][08:23:36]: [Server #554754] Selecting client #137 for training.
[INFO][08:23:36]: [Server #554754] Sending the current model to client #137 (simulated).
[INFO][08:23:36]: [Server #554754] Sending 0.26 MB of payload data to client #137 (simulated).
[INFO][08:23:36]: [Client #47] Selected by the server.
[INFO][08:23:36]: [Client #47] Loading its data source...
[INFO][08:23:36]: Data source: FEMNIST
[INFO][08:23:36]: [Client #137] Selected by the server.
[INFO][08:23:36]: [Client #137] Loading its data source...
[INFO][08:23:36]: Data source: FEMNIST
[INFO][08:23:36]: [Client #137] Dataset size: 148
[INFO][08:23:36]: [Client #137] Sampler: all_inclusive
[INFO][08:23:36]: [Client #137] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:23:36]: [93m[1m[Client #137] Started training in communication round #5.[0m
[INFO][08:23:36]: [Client #47] Dataset size: 161
[INFO][08:23:36]: [Client #47] Sampler: all_inclusive
[INFO][08:23:36]: [Client #47] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:23:36]: [93m[1m[Client #47] Started training in communication round #5.[0m
[INFO][08:23:38]: [Client #137] Loading the dataset.
[INFO][08:23:38]: [Client #47] Loading the dataset.
[INFO][08:23:43]: [Client #137] Epoch: [1/5][0/15]	Loss: 3.497250
[INFO][08:23:43]: [Client #137] Epoch: [1/5][10/15]	Loss: 3.832036
[INFO][08:23:43]: [Client #47] Epoch: [1/5][0/17]	Loss: 1.848057
[INFO][08:23:43]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:23:43]: [Client #47] Epoch: [1/5][10/17]	Loss: 3.604697
[INFO][08:23:43]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:23:47]: [Client #137] Woke up.
[INFO][08:23:47]: [Client #137] Epoch: [2/5][0/15]	Loss: 2.307441
[INFO][08:23:47]: [Client #137] Epoch: [2/5][10/15]	Loss: 1.757969
[INFO][08:23:47]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:23:52]: [Client #137] Woke up.
[INFO][08:23:52]: [Client #137] Epoch: [3/5][0/15]	Loss: 2.230975
[INFO][08:23:52]: [Client #137] Epoch: [3/5][10/15]	Loss: 2.712360
[INFO][08:23:52]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:23:53]: [Client #47] Woke up.
[INFO][08:23:53]: [Client #47] Epoch: [2/5][0/17]	Loss: 1.600646
[INFO][08:23:53]: [Client #47] Epoch: [2/5][10/17]	Loss: 1.811201
[INFO][08:23:53]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:23:56]: [Client #137] Woke up.
[INFO][08:23:56]: [Client #137] Epoch: [4/5][0/15]	Loss: 1.599334
[INFO][08:23:56]: [Client #137] Epoch: [4/5][10/15]	Loss: 1.324478
[INFO][08:23:56]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:24:00]: [Client #137] Woke up.
[INFO][08:24:00]: [Client #137] Epoch: [5/5][0/15]	Loss: 2.168325
[INFO][08:24:00]: [Client #137] Epoch: [5/5][10/15]	Loss: 1.977874
[INFO][08:24:00]: [Client #137] Going to sleep for 4.18 seconds.
[INFO][08:24:03]: [Client #47] Woke up.
[INFO][08:24:03]: [Client #47] Epoch: [3/5][0/17]	Loss: 2.323611
[INFO][08:24:03]: [Client #47] Epoch: [3/5][10/17]	Loss: 2.000960
[INFO][08:24:03]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:24:05]: [Client #137] Woke up.
[INFO][08:24:05]: [Client #137] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_137_554860.pth.
[INFO][08:24:05]: [Client #137] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_137_554860.pth.
[INFO][08:24:05]: [Client #137] Model trained.
[INFO][08:24:05]: [Client #137] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:24:05]: [Server #554754] Received 0.26 MB of payload data from client #137 (simulated).
[INFO][08:24:13]: [Client #47] Woke up.
[INFO][08:24:13]: [Client #47] Epoch: [4/5][0/17]	Loss: 2.190650
[INFO][08:24:14]: [Client #47] Epoch: [4/5][10/17]	Loss: 2.625729
[INFO][08:24:14]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:24:24]: [Client #47] Woke up.
[INFO][08:24:24]: [Client #47] Epoch: [5/5][0/17]	Loss: 2.670443
[INFO][08:24:24]: [Client #47] Epoch: [5/5][10/17]	Loss: 2.194583
[INFO][08:24:24]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:24:34]: [Client #47] Woke up.
[INFO][08:24:34]: [Client #47] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554853.pth.
[INFO][08:24:34]: [Client #47] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554853.pth.
[INFO][08:24:34]: [Client #47] Model trained.
[INFO][08:24:34]: [Client #47] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:24:34]: [Server #554754] Received 0.26 MB of payload data from client #47 (simulated).
[INFO][08:24:34]: [Server #554754] Selecting client #123 for training.
[INFO][08:24:34]: [Server #554754] Sending the current model to client #123 (simulated).
[INFO][08:24:34]: [Server #554754] Sending 0.26 MB of payload data to client #123 (simulated).
[INFO][08:24:34]: [Server #554754] Selecting client #451 for training.
[INFO][08:24:34]: [Server #554754] Sending the current model to client #451 (simulated).
[INFO][08:24:34]: [Server #554754] Sending 0.26 MB of payload data to client #451 (simulated).
[INFO][08:24:34]: [Client #123] Selected by the server.
[INFO][08:24:34]: [Client #123] Loading its data source...
[INFO][08:24:34]: Data source: FEMNIST
[INFO][08:24:34]: [Client #451] Selected by the server.
[INFO][08:24:34]: [Client #451] Loading its data source...
[INFO][08:24:34]: Data source: FEMNIST
[INFO][08:24:34]: [Client #451] Dataset size: 146
[INFO][08:24:34]: [Client #451] Sampler: all_inclusive
[INFO][08:24:34]: [Client #451] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:24:34]: [93m[1m[Client #451] Started training in communication round #5.[0m
[INFO][08:24:34]: [Client #123] Dataset size: 349
[INFO][08:24:34]: [Client #123] Sampler: all_inclusive
[INFO][08:24:34]: [Client #123] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:24:34]: [93m[1m[Client #123] Started training in communication round #5.[0m
[INFO][08:24:36]: [Client #451] Loading the dataset.
[INFO][08:24:36]: [Client #123] Loading the dataset.
[INFO][08:24:42]: [Client #123] Epoch: [1/5][0/35]	Loss: 3.096799
[INFO][08:24:42]: [Client #451] Epoch: [1/5][0/15]	Loss: 3.416502
[INFO][08:24:42]: [Client #123] Epoch: [1/5][10/35]	Loss: 3.475065
[INFO][08:24:42]: [Client #451] Epoch: [1/5][10/15]	Loss: 2.536588
[INFO][08:24:42]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:24:42]: [Client #123] Epoch: [1/5][20/35]	Loss: 3.682127
[INFO][08:24:42]: [Client #123] Epoch: [1/5][30/35]	Loss: 2.495935
[INFO][08:24:42]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][08:24:42]: [Client #123] Woke up.
[INFO][08:24:42]: [Client #123] Epoch: [2/5][0/35]	Loss: 2.492438
[INFO][08:24:42]: [Client #451] Woke up.
[INFO][08:24:42]: [Client #451] Epoch: [2/5][0/15]	Loss: 2.080921
[INFO][08:24:42]: [Client #123] Epoch: [2/5][10/35]	Loss: 2.251334
[INFO][08:24:42]: [Client #451] Epoch: [2/5][10/15]	Loss: 2.552436
[INFO][08:24:42]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:24:42]: [Client #123] Epoch: [2/5][20/35]	Loss: 2.027591
[INFO][08:24:42]: [Client #123] Epoch: [2/5][30/35]	Loss: 2.268853
[INFO][08:24:42]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][08:24:42]: [Client #123] Woke up.
[INFO][08:24:42]: [Client #123] Epoch: [3/5][0/35]	Loss: 1.929042
[INFO][08:24:42]: [Client #451] Woke up.
[INFO][08:24:42]: [Client #123] Epoch: [3/5][10/35]	Loss: 2.334947
[INFO][08:24:42]: [Client #451] Epoch: [3/5][0/15]	Loss: 2.262997
[INFO][08:24:43]: [Client #123] Epoch: [3/5][20/35]	Loss: 2.402131
[INFO][08:24:43]: [Client #451] Epoch: [3/5][10/15]	Loss: 1.989834
[INFO][08:24:43]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:24:43]: [Client #123] Epoch: [3/5][30/35]	Loss: 1.692238
[INFO][08:24:43]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][08:24:43]: [Client #123] Woke up.
[INFO][08:24:43]: [Client #123] Epoch: [4/5][0/35]	Loss: 1.856533
[INFO][08:24:43]: [Client #123] Epoch: [4/5][10/35]	Loss: 2.662038
[INFO][08:24:43]: [Client #451] Woke up.
[INFO][08:24:43]: [Client #451] Epoch: [4/5][0/15]	Loss: 1.851542
[INFO][08:24:43]: [Client #123] Epoch: [4/5][20/35]	Loss: 1.794225
[INFO][08:24:43]: [Client #451] Epoch: [4/5][10/15]	Loss: 2.392292
[INFO][08:24:43]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:24:43]: [Client #123] Epoch: [4/5][30/35]	Loss: 1.820082
[INFO][08:24:43]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][08:24:43]: [Client #123] Woke up.
[INFO][08:24:43]: [Client #123] Epoch: [5/5][0/35]	Loss: 2.619724
[INFO][08:24:43]: [Client #123] Epoch: [5/5][10/35]	Loss: 2.512770
[INFO][08:24:43]: [Client #451] Woke up.
[INFO][08:24:43]: [Client #451] Epoch: [5/5][0/15]	Loss: 2.426445
[INFO][08:24:43]: [Client #123] Epoch: [5/5][20/35]	Loss: 1.255796
[INFO][08:24:43]: [Client #451] Epoch: [5/5][10/15]	Loss: 2.537313
[INFO][08:24:43]: [Client #123] Epoch: [5/5][30/35]	Loss: 1.180365
[INFO][08:24:43]: [Client #451] Going to sleep for 0.23 seconds.
[INFO][08:24:43]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][08:24:43]: [Client #123] Woke up.
[INFO][08:24:43]: [Client #123] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_554853.pth.
[INFO][08:24:44]: [Client #451] Woke up.
[INFO][08:24:44]: [Client #451] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_554860.pth.
[INFO][08:24:44]: [Client #123] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_554853.pth.
[INFO][08:24:44]: [Client #123] Model trained.
[INFO][08:24:44]: [Client #123] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:24:44]: [Server #554754] Received 0.26 MB of payload data from client #123 (simulated).
[INFO][08:24:44]: [Client #451] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_451_554860.pth.
[INFO][08:24:44]: [Client #451] Model trained.
[INFO][08:24:44]: [Client #451] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:24:44]: [Server #554754] Received 0.26 MB of payload data from client #451 (simulated).
[INFO][08:24:44]: [Server #554754] Selecting client #331 for training.
[INFO][08:24:44]: [Server #554754] Sending the current model to client #331 (simulated).
[INFO][08:24:44]: [Server #554754] Sending 0.26 MB of payload data to client #331 (simulated).
[INFO][08:24:44]: [Server #554754] Selecting client #242 for training.
[INFO][08:24:44]: [Server #554754] Sending the current model to client #242 (simulated).
[INFO][08:24:44]: [Server #554754] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][08:24:44]: [Client #331] Selected by the server.
[INFO][08:24:44]: [Client #331] Loading its data source...
[INFO][08:24:44]: Data source: FEMNIST
[INFO][08:24:44]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:24:44]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/331.zip.
[INFO][08:24:44]: [Client #242] Selected by the server.
[INFO][08:24:44]: [Client #242] Loading its data source...
[INFO][08:24:44]: Data source: FEMNIST
[INFO][08:24:44]: [Client #242] Dataset size: 146
[INFO][08:24:44]: [Client #242] Sampler: all_inclusive
[INFO][08:24:44]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:24:44]: [93m[1m[Client #242] Started training in communication round #5.[0m

2.6%
5.2%
7.8%
10.4%
13.0%
15.6%
18.2%
20.8%
23.4%
25.9%
28.5%
31.1%
33.7%
36.3%
38.9%
41.5%
44.1%
46.7%
49.3%
51.9%
54.5%
57.1%
59.7%
62.3%
64.9%
67.5%
70.1%
72.7%
75.2%
77.8%
80.4%
83.0%
85.6%
88.2%
90.8%
93.4%
96.0%
98.6%
100.0%[INFO][08:24:45]: Decompressing the dataset downloaded.
[INFO][08:24:45]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/331.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:24:45]: [Client #331] Dataset size: 163
[INFO][08:24:45]: [Client #331] Sampler: all_inclusive
[INFO][08:24:45]: [Client #331] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:24:45]: [93m[1m[Client #331] Started training in communication round #5.[0m

[INFO][08:24:46]: [Client #242] Loading the dataset.
[INFO][08:24:46]: [Client #331] Loading the dataset.
[INFO][08:24:52]: [Client #242] Epoch: [1/5][0/15]	Loss: 2.520962
[INFO][08:24:52]: [Client #242] Epoch: [1/5][10/15]	Loss: 2.234956
[INFO][08:24:52]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:24:52]: [Client #331] Epoch: [1/5][0/17]	Loss: 3.032143
[INFO][08:24:52]: [Client #331] Epoch: [1/5][10/17]	Loss: 2.116060
[INFO][08:24:52]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][08:24:52]: [Client #331] Woke up.
[INFO][08:24:52]: [Client #331] Epoch: [2/5][0/17]	Loss: 2.205836
[INFO][08:24:52]: [Client #331] Epoch: [2/5][10/17]	Loss: 2.697386
[INFO][08:24:52]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][08:24:52]: [Client #331] Woke up.
[INFO][08:24:52]: [Client #331] Epoch: [3/5][0/17]	Loss: 0.865680
[INFO][08:24:53]: [Client #331] Epoch: [3/5][10/17]	Loss: 1.434950
[INFO][08:24:53]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][08:24:53]: [Client #331] Woke up.
[INFO][08:24:53]: [Client #331] Epoch: [4/5][0/17]	Loss: 1.840685
[INFO][08:24:53]: [Client #331] Epoch: [4/5][10/17]	Loss: 0.805030
[INFO][08:24:53]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][08:24:53]: [Client #331] Woke up.
[INFO][08:24:53]: [Client #331] Epoch: [5/5][0/17]	Loss: 1.708056
[INFO][08:24:53]: [Client #331] Epoch: [5/5][10/17]	Loss: 3.250736
[INFO][08:24:53]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][08:24:53]: [Client #331] Woke up.
[INFO][08:24:53]: [Client #331] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554853.pth.
[INFO][08:24:54]: [Client #331] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554853.pth.
[INFO][08:24:54]: [Client #331] Model trained.
[INFO][08:24:54]: [Client #331] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:24:54]: [Server #554754] Received 0.26 MB of payload data from client #331 (simulated).
[INFO][08:25:00]: [Client #242] Woke up.
[INFO][08:25:00]: [Client #242] Epoch: [2/5][0/15]	Loss: 2.786217
[INFO][08:25:00]: [Client #242] Epoch: [2/5][10/15]	Loss: 2.325158
[INFO][08:25:00]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:25:09]: [Client #242] Woke up.
[INFO][08:25:09]: [Client #242] Epoch: [3/5][0/15]	Loss: 3.074087
[INFO][08:25:09]: [Client #242] Epoch: [3/5][10/15]	Loss: 2.660601
[INFO][08:25:09]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:25:17]: [Client #242] Woke up.
[INFO][08:25:17]: [Client #242] Epoch: [4/5][0/15]	Loss: 2.673063
[INFO][08:25:17]: [Client #242] Epoch: [4/5][10/15]	Loss: 2.386810
[INFO][08:25:17]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:25:25]: [Client #242] Woke up.
[INFO][08:25:26]: [Client #242] Epoch: [5/5][0/15]	Loss: 1.399922
[INFO][08:25:26]: [Client #242] Epoch: [5/5][10/15]	Loss: 2.308609
[INFO][08:25:26]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:25:34]: [Client #242] Woke up.
[INFO][08:25:34]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554860.pth.
[INFO][08:25:35]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554860.pth.
[INFO][08:25:35]: [Client #242] Model trained.
[INFO][08:25:35]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:25:35]: [Server #554754] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][08:25:35]: [Server #554754] Selecting client #178 for training.
[INFO][08:25:35]: [Server #554754] Sending the current model to client #178 (simulated).
[INFO][08:25:35]: [Server #554754] Sending 0.26 MB of payload data to client #178 (simulated).
[INFO][08:25:35]: [Server #554754] Selecting client #401 for training.
[INFO][08:25:35]: [Server #554754] Sending the current model to client #401 (simulated).
[INFO][08:25:35]: [Server #554754] Sending 0.26 MB of payload data to client #401 (simulated).
[INFO][08:25:35]: [Client #401] Selected by the server.
[INFO][08:25:35]: [Client #178] Selected by the server.
[INFO][08:25:35]: [Client #401] Loading its data source...
[INFO][08:25:35]: Data source: FEMNIST
[INFO][08:25:35]: [Client #178] Loading its data source...
[INFO][08:25:35]: Data source: FEMNIST
[INFO][08:25:35]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:25:35]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/401.zip.
[INFO][08:25:35]: [Client #178] Dataset size: 208
[INFO][08:25:35]: [Client #178] Sampler: all_inclusive
[INFO][08:25:35]: [Client #178] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:25:35]: [93m[1m[Client #178] Started training in communication round #5.[0m

3.1%
6.2%
9.3%
12.4%
15.5%
18.6%
21.7%
24.8%
27.9%
31.0%
34.1%
37.2%
40.2%
43.3%
46.4%
49.5%
52.6%
55.7%
58.8%
61.9%
65.0%
68.1%
71.2%
74.3%
77.4%
80.5%
83.6%
86.7%
89.8%
92.9%
96.0%
99.1%
100.0%[INFO][08:25:35]: Decompressing the dataset downloaded.
[INFO][08:25:35]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/401.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:25:35]: [Client #401] Dataset size: 151
[INFO][08:25:35]: [Client #401] Sampler: all_inclusive
[INFO][08:25:35]: [Client #401] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:25:35]: [93m[1m[Client #401] Started training in communication round #5.[0m

[INFO][08:25:37]: [Client #178] Loading the dataset.
[INFO][08:25:37]: [Client #401] Loading the dataset.
[INFO][08:25:42]: [Client #178] Epoch: [1/5][0/21]	Loss: 3.435579
[INFO][08:25:42]: [Client #401] Epoch: [1/5][0/16]	Loss: 2.278169
[INFO][08:25:42]: [Client #178] Epoch: [1/5][10/21]	Loss: 2.289283
[INFO][08:25:42]: [Client #401] Epoch: [1/5][10/16]	Loss: 2.236947
[INFO][08:25:42]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][08:25:42]: [Client #178] Epoch: [1/5][20/21]	Loss: 2.763259
[INFO][08:25:42]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][08:25:43]: [Client #178] Woke up.
[INFO][08:25:43]: [Client #178] Epoch: [2/5][0/21]	Loss: 2.421499
[INFO][08:25:43]: [Client #178] Epoch: [2/5][10/21]	Loss: 3.309186
[INFO][08:25:43]: [Client #178] Epoch: [2/5][20/21]	Loss: 3.080430
[INFO][08:25:43]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][08:25:43]: [Client #178] Woke up.
[INFO][08:25:43]: [Client #178] Epoch: [3/5][0/21]	Loss: 2.731932
[INFO][08:25:43]: [Client #178] Epoch: [3/5][10/21]	Loss: 2.161183
[INFO][08:25:43]: [Client #178] Epoch: [3/5][20/21]	Loss: 2.919540
[INFO][08:25:43]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][08:25:44]: [Client #178] Woke up.
[INFO][08:25:44]: [Client #178] Epoch: [4/5][0/21]	Loss: 1.826659
[INFO][08:25:44]: [Client #178] Epoch: [4/5][10/21]	Loss: 2.904948
[INFO][08:25:44]: [Client #178] Epoch: [4/5][20/21]	Loss: 1.783913
[INFO][08:25:44]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][08:25:44]: [Client #178] Woke up.
[INFO][08:25:44]: [Client #178] Epoch: [5/5][0/21]	Loss: 2.606878
[INFO][08:25:44]: [Client #178] Epoch: [5/5][10/21]	Loss: 2.515699
[INFO][08:25:44]: [Client #178] Epoch: [5/5][20/21]	Loss: 3.261227
[INFO][08:25:44]: [Client #178] Going to sleep for 0.36 seconds.
[INFO][08:25:45]: [Client #178] Woke up.
[INFO][08:25:45]: [Client #178] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_178_554853.pth.
[INFO][08:25:45]: [Client #178] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_178_554853.pth.
[INFO][08:25:45]: [Client #178] Model trained.
[INFO][08:25:45]: [Client #178] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:25:45]: [Server #554754] Received 0.26 MB of payload data from client #178 (simulated).
[INFO][08:26:06]: [Client #401] Woke up.
[INFO][08:26:06]: [Client #401] Epoch: [2/5][0/16]	Loss: 3.479277
[INFO][08:26:06]: [Client #401] Epoch: [2/5][10/16]	Loss: 2.933154
[INFO][08:26:06]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][08:26:30]: [Client #401] Woke up.
[INFO][08:26:30]: [Client #401] Epoch: [3/5][0/16]	Loss: 3.193346
[INFO][08:26:30]: [Client #401] Epoch: [3/5][10/16]	Loss: 2.461601
[INFO][08:26:30]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][08:26:54]: [Client #401] Woke up.
[INFO][08:26:54]: [Client #401] Epoch: [4/5][0/16]	Loss: 1.428997
[INFO][08:26:54]: [Client #401] Epoch: [4/5][10/16]	Loss: 1.653767
[INFO][08:26:54]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][08:27:18]: [Client #401] Woke up.
[INFO][08:27:18]: [Client #401] Epoch: [5/5][0/16]	Loss: 3.050884
[INFO][08:27:18]: [Client #401] Epoch: [5/5][10/16]	Loss: 2.736901
[INFO][08:27:18]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][08:27:42]: [Client #401] Woke up.
[INFO][08:27:42]: [Client #401] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554860.pth.
[INFO][08:27:42]: [Client #401] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554860.pth.
[INFO][08:27:42]: [Client #401] Model trained.
[INFO][08:27:42]: [Client #401] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:27:42]: [Server #554754] Received 0.26 MB of payload data from client #401 (simulated).
[INFO][08:27:42]: [Server #554754] Selecting client #455 for training.
[INFO][08:27:42]: [Server #554754] Sending the current model to client #455 (simulated).
[INFO][08:27:42]: [Server #554754] Sending 0.26 MB of payload data to client #455 (simulated).
[INFO][08:27:42]: [Server #554754] Selecting client #328 for training.
[INFO][08:27:42]: [Server #554754] Sending the current model to client #328 (simulated).
[INFO][08:27:42]: [Server #554754] Sending 0.26 MB of payload data to client #328 (simulated).
[INFO][08:27:42]: [Client #455] Selected by the server.
[INFO][08:27:42]: [Client #455] Loading its data source...
[INFO][08:27:42]: Data source: FEMNIST
[INFO][08:27:42]: [Client #328] Selected by the server.
[INFO][08:27:42]: [Client #328] Loading its data source...
[INFO][08:27:42]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:27:42]: Data source: FEMNIST
[INFO][08:27:42]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/455.zip.
[INFO][08:27:42]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:27:42]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/328.zip.

2.8%
5.5%
8.3%
11.1%
13.9%
16.6%
19.4%
22.2%
2.7%
5.3%
8.0%
10.7%
13.3%
16.0%
18.7%
21.3%
24.0%
26.7%
29.3%
32.0%
34.7%
37.3%
40.0%
42.7%
24.9%
27.7%
30.5%
33.3%
36.0%
38.8%
41.6%
44.3%
47.1%
49.9%
52.7%
55.4%
58.2%
61.0%
63.7%
66.5%
69.3%
72.1%
74.8%
77.6%
80.4%
83.1%
85.9%
88.7%
91.5%
94.2%
97.0%
99.8%
100.0%[INFO][08:27:43]: Decompressing the dataset downloaded.
[INFO][08:27:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/328.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

45.3%
48.0%
50.6%
53.3%
56.0%
58.6%
61.3%
64.0%
66.6%
69.3%
72.0%
74.6%
77.3%
80.0%
82.6%
85.3%
88.0%
90.6%
93.3%
96.0%
98.6%
100.0%[INFO][08:27:43]: Decompressing the dataset downloaded.
[INFO][08:27:43]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/455.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:27:43]: [Client #328] Dataset size: 164
[INFO][08:27:43]: [Client #328] Sampler: all_inclusive
[INFO][08:27:43]: [Client #455] Dataset size: 149
[INFO][08:27:43]: [Client #455] Sampler: all_inclusive
[INFO][08:27:43]: [Client #328] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:27:43]: [Client #455] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:27:43]: [93m[1m[Client #328] Started training in communication round #5.[0m

[INFO][08:27:43]: [93m[1m[Client #455] Started training in communication round #5.[0m

[INFO][08:27:44]: [Client #455] Loading the dataset.
[INFO][08:27:45]: [Client #328] Loading the dataset.
[INFO][08:27:50]: [Client #455] Epoch: [1/5][0/15]	Loss: 2.247434
[INFO][08:27:50]: [Client #328] Epoch: [1/5][0/17]	Loss: 2.407249
[INFO][08:27:50]: [Client #455] Epoch: [1/5][10/15]	Loss: 1.834143
[INFO][08:27:50]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][08:27:50]: [Client #328] Epoch: [1/5][10/17]	Loss: 2.255191
[INFO][08:27:50]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][08:27:52]: [Client #328] Woke up.
[INFO][08:27:52]: [Client #328] Epoch: [2/5][0/17]	Loss: 2.514779
[INFO][08:27:52]: [Client #328] Epoch: [2/5][10/17]	Loss: 2.465221
[INFO][08:27:52]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][08:27:53]: [Client #455] Woke up.
[INFO][08:27:53]: [Client #455] Epoch: [2/5][0/15]	Loss: 2.834278
[INFO][08:27:53]: [Client #455] Epoch: [2/5][10/15]	Loss: 2.462595
[INFO][08:27:53]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][08:27:54]: [Client #328] Woke up.
[INFO][08:27:54]: [Client #328] Epoch: [3/5][0/17]	Loss: 2.136956
[INFO][08:27:54]: [Client #328] Epoch: [3/5][10/17]	Loss: 2.286663
[INFO][08:27:54]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][08:27:55]: [Client #455] Woke up.
[INFO][08:27:55]: [Client #455] Epoch: [3/5][0/15]	Loss: 2.360322
[INFO][08:27:55]: [Client #455] Epoch: [3/5][10/15]	Loss: 2.282345
[INFO][08:27:55]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][08:27:55]: [Client #328] Woke up.
[INFO][08:27:55]: [Client #328] Epoch: [4/5][0/17]	Loss: 2.783667
[INFO][08:27:56]: [Client #328] Epoch: [4/5][10/17]	Loss: 0.967151
[INFO][08:27:56]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][08:27:57]: [Client #328] Woke up.
[INFO][08:27:57]: [Client #328] Epoch: [5/5][0/17]	Loss: 1.916204
[INFO][08:27:57]: [Client #328] Epoch: [5/5][10/17]	Loss: 2.195432
[INFO][08:27:57]: [Client #328] Going to sleep for 1.64 seconds.
[INFO][08:27:58]: [Client #455] Woke up.
[INFO][08:27:58]: [Client #455] Epoch: [4/5][0/15]	Loss: 2.896199
[INFO][08:27:58]: [Client #455] Epoch: [4/5][10/15]	Loss: 2.787489
[INFO][08:27:58]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][08:27:59]: [Client #328] Woke up.
[INFO][08:27:59]: [Client #328] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_328_554860.pth.
[INFO][08:28:00]: [Client #328] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_328_554860.pth.
[INFO][08:28:00]: [Client #328] Model trained.
[INFO][08:28:00]: [Client #328] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:00]: [Server #554754] Received 0.26 MB of payload data from client #328 (simulated).
[INFO][08:28:00]: [Client #455] Woke up.
[INFO][08:28:00]: [Client #455] Epoch: [5/5][0/15]	Loss: 1.384576
[INFO][08:28:00]: [Client #455] Epoch: [5/5][10/15]	Loss: 2.575361
[INFO][08:28:01]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][08:28:03]: [Client #455] Woke up.
[INFO][08:28:03]: [Client #455] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_554853.pth.
[INFO][08:28:04]: [Client #455] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_554853.pth.
[INFO][08:28:04]: [Client #455] Model trained.
[INFO][08:28:04]: [Client #455] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:04]: [Server #554754] Received 0.26 MB of payload data from client #455 (simulated).
[INFO][08:28:04]: [Server #554754] Selecting client #74 for training.
[INFO][08:28:04]: [Server #554754] Sending the current model to client #74 (simulated).
[INFO][08:28:04]: [Server #554754] Sending 0.26 MB of payload data to client #74 (simulated).
[INFO][08:28:04]: [Server #554754] Selecting client #486 for training.
[INFO][08:28:04]: [Server #554754] Sending the current model to client #486 (simulated).
[INFO][08:28:04]: [Server #554754] Sending 0.26 MB of payload data to client #486 (simulated).
[INFO][08:28:04]: [Client #74] Selected by the server.
[INFO][08:28:04]: [Client #74] Loading its data source...
[INFO][08:28:04]: Data source: FEMNIST
[INFO][08:28:04]: [Client #486] Selected by the server.
[INFO][08:28:04]: [Client #486] Loading its data source...
[INFO][08:28:04]: Data source: FEMNIST
[INFO][08:28:04]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:28:04]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/486.zip.
[INFO][08:28:04]: [Client #74] Dataset size: 164
[INFO][08:28:04]: [Client #74] Sampler: all_inclusive
[INFO][08:28:04]: [Client #74] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:04]: [93m[1m[Client #74] Started training in communication round #5.[0m

3.0%
6.1%
9.1%
12.1%
15.2%
18.2%
21.3%
24.3%
27.3%
30.4%
33.4%
36.4%
39.5%
42.5%
45.6%
48.6%
51.6%
54.7%
57.7%
60.7%
63.8%
66.8%
69.9%
72.9%
75.9%
79.0%
82.0%
85.0%
88.1%
91.1%
94.2%
97.2%
100.0%[INFO][08:28:04]: Decompressing the dataset downloaded.
[INFO][08:28:04]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/486.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:28:04]: [Client #486] Dataset size: 160
[INFO][08:28:04]: [Client #486] Sampler: all_inclusive
[INFO][08:28:04]: [Client #486] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:04]: [93m[1m[Client #486] Started training in communication round #5.[0m

[INFO][08:28:06]: [Client #74] Loading the dataset.
[INFO][08:28:06]: [Client #486] Loading the dataset.
[INFO][08:28:11]: [Client #74] Epoch: [1/5][0/17]	Loss: 2.375347
[INFO][08:28:11]: [Client #486] Epoch: [1/5][0/16]	Loss: 2.111419
[INFO][08:28:11]: [Client #74] Epoch: [1/5][10/17]	Loss: 2.090354
[INFO][08:28:11]: [Client #486] Epoch: [1/5][10/16]	Loss: 3.127815
[INFO][08:28:11]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][08:28:11]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][08:28:13]: [Client #486] Woke up.
[INFO][08:28:13]: [Client #486] Epoch: [2/5][0/16]	Loss: 2.493982
[INFO][08:28:13]: [Client #486] Epoch: [2/5][10/16]	Loss: 3.063720
[INFO][08:28:13]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][08:28:15]: [Client #486] Woke up.
[INFO][08:28:15]: [Client #486] Epoch: [3/5][0/16]	Loss: 2.827353
[INFO][08:28:15]: [Client #486] Epoch: [3/5][10/16]	Loss: 1.536364
[INFO][08:28:15]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][08:28:16]: [Client #74] Woke up.
[INFO][08:28:16]: [Client #74] Epoch: [2/5][0/17]	Loss: 2.159737
[INFO][08:28:16]: [Client #74] Epoch: [2/5][10/17]	Loss: 2.881357
[INFO][08:28:16]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][08:28:17]: [Client #486] Woke up.
[INFO][08:28:17]: [Client #486] Epoch: [4/5][0/16]	Loss: 1.800495
[INFO][08:28:17]: [Client #486] Epoch: [4/5][10/16]	Loss: 1.327702
[INFO][08:28:17]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][08:28:19]: [Client #486] Woke up.
[INFO][08:28:19]: [Client #486] Epoch: [5/5][0/16]	Loss: 1.656731
[INFO][08:28:19]: [Client #486] Epoch: [5/5][10/16]	Loss: 2.018063
[INFO][08:28:19]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][08:28:20]: [Client #74] Woke up.
[INFO][08:28:20]: [Client #74] Epoch: [3/5][0/17]	Loss: 2.463725
[INFO][08:28:20]: [Client #74] Epoch: [3/5][10/17]	Loss: 1.787538
[INFO][08:28:20]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][08:28:20]: [Client #486] Woke up.
[INFO][08:28:21]: [Client #486] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_554860.pth.
[INFO][08:28:21]: [Client #486] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_554860.pth.
[INFO][08:28:21]: [Client #486] Model trained.
[INFO][08:28:21]: [Client #486] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:21]: [Server #554754] Received 0.26 MB of payload data from client #486 (simulated).
[INFO][08:28:24]: [Client #74] Woke up.
[INFO][08:28:24]: [Client #74] Epoch: [4/5][0/17]	Loss: 2.210664
[INFO][08:28:24]: [Client #74] Epoch: [4/5][10/17]	Loss: 2.007919
[INFO][08:28:24]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][08:28:29]: [Client #74] Woke up.
[INFO][08:28:29]: [Client #74] Epoch: [5/5][0/17]	Loss: 1.639264
[INFO][08:28:29]: [Client #74] Epoch: [5/5][10/17]	Loss: 1.783096
[INFO][08:28:29]: [Client #74] Going to sleep for 4.19 seconds.
[INFO][08:28:33]: [Client #74] Woke up.
[INFO][08:28:33]: [Client #74] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_554853.pth.
[INFO][08:28:34]: [Client #74] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_74_554853.pth.
[INFO][08:28:34]: [Client #74] Model trained.
[INFO][08:28:34]: [Client #74] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:34]: [Server #554754] Received 0.26 MB of payload data from client #74 (simulated).
[INFO][08:28:34]: [Server #554754] Selecting client #94 for training.
[INFO][08:28:34]: [Server #554754] Sending the current model to client #94 (simulated).
[INFO][08:28:34]: [Server #554754] Sending 0.26 MB of payload data to client #94 (simulated).
[INFO][08:28:34]: [Server #554754] Selecting client #120 for training.
[INFO][08:28:34]: [Server #554754] Sending the current model to client #120 (simulated).
[INFO][08:28:34]: [Server #554754] Sending 0.26 MB of payload data to client #120 (simulated).
[INFO][08:28:34]: [Client #94] Selected by the server.
[INFO][08:28:34]: [Client #94] Loading its data source...
[INFO][08:28:34]: Data source: FEMNIST
[INFO][08:28:34]: [Client #120] Selected by the server.
[INFO][08:28:34]: [Client #120] Loading its data source...
[INFO][08:28:34]: Data source: FEMNIST
[INFO][08:28:34]: [Client #120] Dataset size: 154
[INFO][08:28:34]: [Client #120] Sampler: all_inclusive
[INFO][08:28:34]: [Client #120] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:34]: [93m[1m[Client #120] Started training in communication round #5.[0m
[INFO][08:28:34]: [Client #94] Dataset size: 159
[INFO][08:28:34]: [Client #94] Sampler: all_inclusive
[INFO][08:28:34]: [Client #94] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:34]: [93m[1m[Client #94] Started training in communication round #5.[0m
[INFO][08:28:36]: [Client #120] Loading the dataset.
[INFO][08:28:36]: [Client #94] Loading the dataset.
[INFO][08:28:41]: [Client #94] Epoch: [1/5][0/16]	Loss: 2.905385
[INFO][08:28:41]: [Client #120] Epoch: [1/5][0/16]	Loss: 3.371754
[INFO][08:28:41]: [Client #94] Epoch: [1/5][10/16]	Loss: 1.537007
[INFO][08:28:41]: [Client #94] Going to sleep for 1.37 seconds.
[INFO][08:28:41]: [Client #120] Epoch: [1/5][10/16]	Loss: 1.898230
[INFO][08:28:41]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][08:28:42]: [Client #120] Woke up.
[INFO][08:28:42]: [Client #120] Epoch: [2/5][0/16]	Loss: 1.885276
[INFO][08:28:42]: [Client #120] Epoch: [2/5][10/16]	Loss: 3.339566
[INFO][08:28:42]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][08:28:42]: [Client #120] Woke up.
[INFO][08:28:42]: [Client #120] Epoch: [3/5][0/16]	Loss: 1.644090
[INFO][08:28:42]: [Client #120] Epoch: [3/5][10/16]	Loss: 3.324655
[INFO][08:28:42]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][08:28:42]: [Client #120] Woke up.
[INFO][08:28:42]: [Client #120] Epoch: [4/5][0/16]	Loss: 2.809548
[INFO][08:28:42]: [Client #120] Epoch: [4/5][10/16]	Loss: 2.286792
[INFO][08:28:42]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][08:28:42]: [Client #120] Woke up.
[INFO][08:28:42]: [Client #120] Epoch: [5/5][0/16]	Loss: 2.200022
[INFO][08:28:43]: [Client #120] Epoch: [5/5][10/16]	Loss: 1.799602
[INFO][08:28:43]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][08:28:43]: [Client #94] Woke up.
[INFO][08:28:43]: [Client #94] Epoch: [2/5][0/16]	Loss: 2.118885
[INFO][08:28:43]: [Client #120] Woke up.
[INFO][08:28:43]: [Client #120] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_554860.pth.
[INFO][08:28:43]: [Client #94] Epoch: [2/5][10/16]	Loss: 1.947093
[INFO][08:28:43]: [Client #94] Going to sleep for 1.37 seconds.
[INFO][08:28:43]: [Client #120] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_554860.pth.
[INFO][08:28:43]: [Client #120] Model trained.
[INFO][08:28:43]: [Client #120] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:43]: [Server #554754] Received 0.26 MB of payload data from client #120 (simulated).
[INFO][08:28:44]: [Client #94] Woke up.
[INFO][08:28:44]: [Client #94] Epoch: [3/5][0/16]	Loss: 2.818052
[INFO][08:28:44]: [Client #94] Epoch: [3/5][10/16]	Loss: 2.733244
[INFO][08:28:44]: [Client #94] Going to sleep for 1.37 seconds.
[INFO][08:28:46]: [Client #94] Woke up.
[INFO][08:28:46]: [Client #94] Epoch: [4/5][0/16]	Loss: 1.289762
[INFO][08:28:46]: [Client #94] Epoch: [4/5][10/16]	Loss: 1.855784
[INFO][08:28:46]: [Client #94] Going to sleep for 1.37 seconds.
[INFO][08:28:47]: [Client #94] Woke up.
[INFO][08:28:47]: [Client #94] Epoch: [5/5][0/16]	Loss: 1.323564
[INFO][08:28:47]: [Client #94] Epoch: [5/5][10/16]	Loss: 1.401081
[INFO][08:28:47]: [Client #94] Going to sleep for 1.37 seconds.
[INFO][08:28:49]: [Client #94] Woke up.
[INFO][08:28:49]: [Client #94] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_94_554853.pth.
[INFO][08:28:49]: [Client #94] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_94_554853.pth.
[INFO][08:28:49]: [Client #94] Model trained.
[INFO][08:28:49]: [Client #94] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:49]: [Server #554754] Received 0.26 MB of payload data from client #94 (simulated).
[INFO][08:28:49]: [Server #554754] Selecting client #237 for training.
[INFO][08:28:49]: [Server #554754] Sending the current model to client #237 (simulated).
[INFO][08:28:49]: [Server #554754] Sending 0.26 MB of payload data to client #237 (simulated).
[INFO][08:28:49]: [Server #554754] Selecting client #72 for training.
[INFO][08:28:49]: [Server #554754] Sending the current model to client #72 (simulated).
[INFO][08:28:49]: [Server #554754] Sending 0.26 MB of payload data to client #72 (simulated).
[INFO][08:28:49]: [Client #237] Selected by the server.
[INFO][08:28:49]: [Client #237] Loading its data source...
[INFO][08:28:49]: Data source: FEMNIST
[INFO][08:28:49]: [Client #72] Selected by the server.
[INFO][08:28:49]: [Client #72] Loading its data source...
[INFO][08:28:49]: Data source: FEMNIST
[INFO][08:28:49]: [Client #72] Dataset size: 158
[INFO][08:28:49]: [Client #72] Sampler: all_inclusive
[INFO][08:28:49]: [Client #72] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:49]: [93m[1m[Client #72] Started training in communication round #5.[0m
[INFO][08:28:49]: [Client #237] Dataset size: 158
[INFO][08:28:49]: [Client #237] Sampler: all_inclusive
[INFO][08:28:49]: [Client #237] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:50]: [93m[1m[Client #237] Started training in communication round #5.[0m
[INFO][08:28:51]: [Client #237] Loading the dataset.
[INFO][08:28:51]: [Client #72] Loading the dataset.
[INFO][08:28:57]: [Client #237] Epoch: [1/5][0/16]	Loss: 2.657664
[INFO][08:28:57]: [Client #72] Epoch: [1/5][0/16]	Loss: 2.884579
[INFO][08:28:57]: [Client #237] Epoch: [1/5][10/16]	Loss: 2.676747
[INFO][08:28:57]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][08:28:57]: [Client #237] Woke up.
[INFO][08:28:57]: [Client #237] Epoch: [2/5][0/16]	Loss: 2.763359
[INFO][08:28:57]: [Client #72] Epoch: [1/5][10/16]	Loss: 2.858234
[INFO][08:28:57]: [Client #72] Going to sleep for 0.16 seconds.
[INFO][08:28:57]: [Client #237] Epoch: [2/5][10/16]	Loss: 3.366753
[INFO][08:28:57]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][08:28:57]: [Client #237] Woke up.
[INFO][08:28:57]: [Client #237] Epoch: [3/5][0/16]	Loss: 3.199390
[INFO][08:28:57]: [Client #72] Woke up.
[INFO][08:28:57]: [Client #72] Epoch: [2/5][0/16]	Loss: 2.643003
[INFO][08:28:57]: [Client #237] Epoch: [3/5][10/16]	Loss: 2.333539
[INFO][08:28:57]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][08:28:58]: [Client #237] Woke up.
[INFO][08:28:58]: [Client #237] Epoch: [4/5][0/16]	Loss: 2.426733
[INFO][08:28:58]: [Client #72] Epoch: [2/5][10/16]	Loss: 2.589628
[INFO][08:28:58]: [Client #72] Going to sleep for 0.16 seconds.
[INFO][08:28:58]: [Client #237] Epoch: [4/5][10/16]	Loss: 1.744437
[INFO][08:28:58]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][08:28:58]: [Client #237] Woke up.
[INFO][08:28:58]: [Client #237] Epoch: [5/5][0/16]	Loss: 2.834758
[INFO][08:28:58]: [Client #72] Woke up.
[INFO][08:28:58]: [Client #237] Epoch: [5/5][10/16]	Loss: 1.704294
[INFO][08:28:58]: [Client #72] Epoch: [3/5][0/16]	Loss: 2.752275
[INFO][08:28:58]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][08:28:58]: [Client #237] Woke up.
[INFO][08:28:58]: [Client #237] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_237_554853.pth.
[INFO][08:28:58]: [Client #72] Epoch: [3/5][10/16]	Loss: 2.414684
[INFO][08:28:58]: [Client #72] Going to sleep for 0.16 seconds.
[INFO][08:28:58]: [Client #72] Woke up.
[INFO][08:28:58]: [Client #72] Epoch: [4/5][0/16]	Loss: 3.147089
[INFO][08:28:58]: [Client #72] Epoch: [4/5][10/16]	Loss: 2.078355
[INFO][08:28:58]: [Client #72] Going to sleep for 0.16 seconds.
[INFO][08:28:58]: [Client #72] Woke up.
[INFO][08:28:58]: [Client #72] Epoch: [5/5][0/16]	Loss: 1.710394
[INFO][08:28:58]: [Client #237] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_237_554853.pth.
[INFO][08:28:58]: [Client #237] Model trained.
[INFO][08:28:58]: [Client #237] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:58]: [Server #554754] Received 0.26 MB of payload data from client #237 (simulated).
[INFO][08:28:58]: [Client #72] Epoch: [5/5][10/16]	Loss: 1.587925
[INFO][08:28:59]: [Client #72] Going to sleep for 0.16 seconds.
[INFO][08:28:59]: [Client #72] Woke up.
[INFO][08:28:59]: [Client #72] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_72_554860.pth.
[INFO][08:28:59]: [Client #72] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_72_554860.pth.
[INFO][08:28:59]: [Client #72] Model trained.
[INFO][08:28:59]: [Client #72] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:28:59]: [Server #554754] Received 0.26 MB of payload data from client #72 (simulated).
[INFO][08:28:59]: [Server #554754] Selecting client #363 for training.
[INFO][08:28:59]: [Server #554754] Sending the current model to client #363 (simulated).
[INFO][08:28:59]: [Server #554754] Sending 0.26 MB of payload data to client #363 (simulated).
[INFO][08:28:59]: [Server #554754] Selecting client #95 for training.
[INFO][08:28:59]: [Server #554754] Sending the current model to client #95 (simulated).
[INFO][08:28:59]: [Server #554754] Sending 0.26 MB of payload data to client #95 (simulated).
[INFO][08:28:59]: [Client #95] Selected by the server.
[INFO][08:28:59]: [Client #363] Selected by the server.
[INFO][08:28:59]: [Client #95] Loading its data source...
[INFO][08:28:59]: [Client #363] Loading its data source...
[INFO][08:28:59]: Data source: FEMNIST
[INFO][08:28:59]: Data source: FEMNIST
[INFO][08:28:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:28:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/363.zip.
[INFO][08:28:59]: [Client #95] Dataset size: 158
[INFO][08:28:59]: [Client #95] Sampler: all_inclusive
[INFO][08:28:59]: [Client #95] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:28:59]: [93m[1m[Client #95] Started training in communication round #5.[0m

2.5%
5.0%
7.4%
9.9%
12.4%
14.9%
17.4%
19.9%
22.3%
24.8%
27.3%
29.8%
32.3%
34.7%
37.2%
39.7%
42.2%
44.7%
47.1%
49.6%
52.1%
54.6%
57.1%
59.6%
62.0%
64.5%
67.0%
69.5%
72.0%
74.4%
76.9%
79.4%
81.9%
84.4%
86.8%
89.3%
91.8%
94.3%
96.8%
99.3%
100.0%[INFO][08:29:00]: Decompressing the dataset downloaded.
[INFO][08:29:00]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/363.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:29:00]: [Client #363] Dataset size: 162
[INFO][08:29:00]: [Client #363] Sampler: all_inclusive
[INFO][08:29:00]: [Client #363] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:29:00]: [93m[1m[Client #363] Started training in communication round #5.[0m

[INFO][08:29:01]: [Client #95] Loading the dataset.
[INFO][08:29:02]: [Client #363] Loading the dataset.
[INFO][08:29:07]: [Client #95] Epoch: [1/5][0/16]	Loss: 2.546238
[INFO][08:29:07]: [Client #363] Epoch: [1/5][0/17]	Loss: 1.427037
[INFO][08:29:07]: [Client #95] Epoch: [1/5][10/16]	Loss: 1.520868
[INFO][08:29:07]: [Client #363] Epoch: [1/5][10/17]	Loss: 3.139694
[INFO][08:29:07]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][08:29:07]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][08:29:08]: [Client #95] Woke up.
[INFO][08:29:08]: [Client #95] Epoch: [2/5][0/16]	Loss: 1.754939
[INFO][08:29:08]: [Client #95] Epoch: [2/5][10/16]	Loss: 2.569242
[INFO][08:29:08]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][08:29:09]: [Client #95] Woke up.
[INFO][08:29:09]: [Client #95] Epoch: [3/5][0/16]	Loss: 2.595667
[INFO][08:29:09]: [Client #95] Epoch: [3/5][10/16]	Loss: 1.897044
[INFO][08:29:09]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][08:29:10]: [Client #95] Woke up.
[INFO][08:29:10]: [Client #95] Epoch: [4/5][0/16]	Loss: 1.849833
[INFO][08:29:10]: [Client #95] Epoch: [4/5][10/16]	Loss: 2.720996
[INFO][08:29:10]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][08:29:10]: [Client #95] Woke up.
[INFO][08:29:10]: [Client #95] Epoch: [5/5][0/16]	Loss: 1.701575
[INFO][08:29:11]: [Client #95] Epoch: [5/5][10/16]	Loss: 2.089435
[INFO][08:29:11]: [Client #95] Going to sleep for 0.69 seconds.
[INFO][08:29:11]: [Client #95] Woke up.
[INFO][08:29:11]: [Client #95] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_95_554860.pth.
[INFO][08:29:12]: [Client #95] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_95_554860.pth.
[INFO][08:29:12]: [Client #95] Model trained.
[INFO][08:29:12]: [Client #95] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:29:12]: [Server #554754] Received 0.26 MB of payload data from client #95 (simulated).
[INFO][08:29:16]: [Client #363] Woke up.
[INFO][08:29:16]: [Client #363] Epoch: [2/5][0/17]	Loss: 2.711184
[INFO][08:29:16]: [Client #363] Epoch: [2/5][10/17]	Loss: 2.564660
[INFO][08:29:16]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][08:29:26]: [Client #363] Woke up.
[INFO][08:29:26]: [Client #363] Epoch: [3/5][0/17]	Loss: 3.058692
[INFO][08:29:26]: [Client #363] Epoch: [3/5][10/17]	Loss: 1.578011
[INFO][08:29:26]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][08:29:35]: [Client #363] Woke up.
[INFO][08:29:35]: [Client #363] Epoch: [4/5][0/17]	Loss: 2.418224
[INFO][08:29:35]: [Client #363] Epoch: [4/5][10/17]	Loss: 1.583487
[INFO][08:29:35]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][08:29:44]: [Client #363] Woke up.
[INFO][08:29:44]: [Client #363] Epoch: [5/5][0/17]	Loss: 1.447762
[INFO][08:29:44]: [Client #363] Epoch: [5/5][10/17]	Loss: 1.902168
[INFO][08:29:44]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][08:29:54]: [Client #363] Woke up.
[INFO][08:29:54]: [Client #363] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_554853.pth.
[INFO][08:29:54]: [Client #363] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_554853.pth.
[INFO][08:29:54]: [Client #363] Model trained.
[INFO][08:29:54]: [Client #363] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:29:54]: [Server #554754] Received 0.26 MB of payload data from client #363 (simulated).
[INFO][08:29:54]: [Server #554754] Adding client #237 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #331 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #120 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #123 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #380 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #72 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #451 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #178 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #95 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Adding client #94 to the list of clients for aggregation.
[INFO][08:29:54]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05935479
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06977144 0.11599113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09028886
 0.         0.         0.31429044 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15702436 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1043446  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10236491 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08980705 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08917957 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05935479
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06977144 0.11599113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09028886
 0.         0.         0.31429044 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15702436 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1043446  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10236491 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08980705 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08917957 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:30:38]: [Server #554754] Global model accuracy: 34.60%

[INFO][08:30:38]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_5.pth.
[INFO][08:30:38]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_5.pth.
[INFO][08:30:38]: [93m[1m
[Server #554754] Starting round 6/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.04976816 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.08719647
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.002
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04728435 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.04728435 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.002
 0.002      0.04664537 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.06964856 0.002      0.002
 0.002      0.002      0.04952077 0.002      0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04536741 0.002
 0.002      0.08774834 0.002      0.002      0.002      0.002
 0.10305344 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05111821 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08057395 0.002      0.002      0.002      0.002      0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][08:30:38]: [Server #554754] Selected clients: [320 377 106 299 374 317 297 148 366 473]
[INFO][08:30:38]: [Server #554754] Selecting client #320 for training.
[INFO][08:30:38]: [Server #554754] Sending the current model to client #320 (simulated).
[INFO][08:30:38]: [Server #554754] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][08:30:38]: [Server #554754] Selecting client #377 for training.
[INFO][08:30:38]: [Server #554754] Sending the current model to client #377 (simulated).
[INFO][08:30:38]: [Server #554754] Sending 0.26 MB of payload data to client #377 (simulated).
[INFO][08:30:38]: [Client #320] Selected by the server.
[INFO][08:30:38]: [Client #320] Loading its data source...
[INFO][08:30:38]: Data source: FEMNIST
[INFO][08:30:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:30:38]: [Client #377] Selected by the server.
[INFO][08:30:38]: [Client #377] Loading its data source...
[INFO][08:30:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/320.zip.
[INFO][08:30:38]: Data source: FEMNIST
[INFO][08:30:38]: [Client #377] Dataset size: 142
[INFO][08:30:38]: [Client #377] Sampler: all_inclusive
[INFO][08:30:38]: [Client #377] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:30:38]: [93m[1m[Client #377] Started training in communication round #6.[0m

2.9%
5.7%
8.6%
11.4%
14.3%
17.1%
20.0%
22.8%
25.7%
28.6%
31.4%
34.3%
37.1%
40.0%
42.8%
45.7%
48.6%
51.4%
54.3%
57.1%
60.0%
62.8%
65.7%
68.5%
71.4%
74.3%
77.1%
80.0%
82.8%
85.7%
88.5%
91.4%
94.2%
97.1%
100.0%
100.0%[INFO][08:30:38]: Decompressing the dataset downloaded.
[INFO][08:30:38]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/320.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:30:38]: [Client #320] Dataset size: 153
[INFO][08:30:38]: [Client #320] Sampler: all_inclusive
[INFO][08:30:38]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:30:38]: [93m[1m[Client #320] Started training in communication round #6.[0m

[INFO][08:30:40]: [Client #377] Loading the dataset.
[INFO][08:30:40]: [Client #320] Loading the dataset.
[INFO][08:30:45]: [Client #377] Epoch: [1/5][0/15]	Loss: 1.574259
[INFO][08:30:46]: [Client #377] Epoch: [1/5][10/15]	Loss: 1.105458
[INFO][08:30:46]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:30:46]: [Client #320] Epoch: [1/5][0/16]	Loss: 2.334168
[INFO][08:30:46]: [Client #320] Epoch: [1/5][10/16]	Loss: 2.148285
[INFO][08:30:46]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][08:30:51]: [Client #320] Woke up.
[INFO][08:30:51]: [Client #320] Epoch: [2/5][0/16]	Loss: 2.623275
[INFO][08:30:52]: [Client #320] Epoch: [2/5][10/16]	Loss: 2.119111
[INFO][08:30:52]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][08:30:52]: [Client #377] Woke up.
[INFO][08:30:52]: [Client #377] Epoch: [2/5][0/15]	Loss: 2.316238
[INFO][08:30:52]: [Client #377] Epoch: [2/5][10/15]	Loss: 1.145235
[INFO][08:30:52]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:30:57]: [Client #320] Woke up.
[INFO][08:30:57]: [Client #320] Epoch: [3/5][0/16]	Loss: 1.270617
[INFO][08:30:57]: [Client #320] Epoch: [3/5][10/16]	Loss: 2.697785
[INFO][08:30:58]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][08:30:58]: [Client #377] Woke up.
[INFO][08:30:58]: [Client #377] Epoch: [3/5][0/15]	Loss: 1.888908
[INFO][08:30:58]: [Client #377] Epoch: [3/5][10/15]	Loss: 0.694286
[INFO][08:30:58]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:31:03]: [Client #320] Woke up.
[INFO][08:31:03]: [Client #320] Epoch: [4/5][0/16]	Loss: 2.539438
[INFO][08:31:03]: [Client #320] Epoch: [4/5][10/16]	Loss: 1.931987
[INFO][08:31:03]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][08:31:05]: [Client #377] Woke up.
[INFO][08:31:05]: [Client #377] Epoch: [4/5][0/15]	Loss: 1.156119
[INFO][08:31:05]: [Client #377] Epoch: [4/5][10/15]	Loss: 1.060397
[INFO][08:31:05]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:31:09]: [Client #320] Woke up.
[INFO][08:31:09]: [Client #320] Epoch: [5/5][0/16]	Loss: 1.241174
[INFO][08:31:09]: [Client #320] Epoch: [5/5][10/16]	Loss: 2.391048
[INFO][08:31:09]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][08:31:11]: [Client #377] Woke up.
[INFO][08:31:11]: [Client #377] Epoch: [5/5][0/15]	Loss: 2.227518
[INFO][08:31:11]: [Client #377] Epoch: [5/5][10/15]	Loss: 1.960639
[INFO][08:31:11]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][08:31:15]: [Client #320] Woke up.
[INFO][08:31:15]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554853.pth.
[INFO][08:31:16]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554853.pth.
[INFO][08:31:16]: [Client #320] Model trained.
[INFO][08:31:16]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:31:16]: [Server #554754] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][08:31:18]: [Client #377] Woke up.
[INFO][08:31:18]: [Client #377] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554860.pth.
[INFO][08:31:18]: [Client #377] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554860.pth.
[INFO][08:31:18]: [Client #377] Model trained.
[INFO][08:31:18]: [Client #377] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:31:18]: [Server #554754] Received 0.26 MB of payload data from client #377 (simulated).
[INFO][08:31:18]: [Server #554754] Selecting client #106 for training.
[INFO][08:31:18]: [Server #554754] Sending the current model to client #106 (simulated).
[INFO][08:31:18]: [Server #554754] Sending 0.26 MB of payload data to client #106 (simulated).
[INFO][08:31:18]: [Server #554754] Selecting client #299 for training.
[INFO][08:31:18]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][08:31:18]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][08:31:18]: [Client #299] Selected by the server.
[INFO][08:31:18]: [Client #106] Selected by the server.
[INFO][08:31:18]: [Client #299] Loading its data source...
[INFO][08:31:18]: [Client #106] Loading its data source...
[INFO][08:31:18]: Data source: FEMNIST
[INFO][08:31:18]: Data source: FEMNIST
[INFO][08:31:18]: [Client #106] Dataset size: 133
[INFO][08:31:18]: [Client #106] Sampler: all_inclusive
[INFO][08:31:18]: [Client #106] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:31:18]: [93m[1m[Client #106] Started training in communication round #6.[0m
[INFO][08:31:18]: [Client #299] Dataset size: 157
[INFO][08:31:18]: [Client #299] Sampler: all_inclusive
[INFO][08:31:18]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:31:18]: [93m[1m[Client #299] Started training in communication round #6.[0m
[INFO][08:31:20]: [Client #299] Loading the dataset.
[INFO][08:31:20]: [Client #106] Loading the dataset.
[INFO][08:31:26]: [Client #106] Epoch: [1/5][0/14]	Loss: 2.756305
[INFO][08:31:26]: [Client #299] Epoch: [1/5][0/16]	Loss: 2.335898
[INFO][08:31:26]: [Client #106] Epoch: [1/5][10/14]	Loss: 1.637397
[INFO][08:31:26]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][08:31:26]: [Client #299] Epoch: [1/5][10/16]	Loss: 2.738857
[INFO][08:31:26]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:31:28]: [Client #106] Woke up.
[INFO][08:31:28]: [Client #106] Epoch: [2/5][0/14]	Loss: 1.535709
[INFO][08:31:28]: [Client #106] Epoch: [2/5][10/14]	Loss: 3.437445
[INFO][08:31:28]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][08:31:29]: [Client #106] Woke up.
[INFO][08:31:29]: [Client #106] Epoch: [3/5][0/14]	Loss: 1.927555
[INFO][08:31:29]: [Client #106] Epoch: [3/5][10/14]	Loss: 2.170261
[INFO][08:31:29]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][08:31:31]: [Client #106] Woke up.
[INFO][08:31:31]: [Client #106] Epoch: [4/5][0/14]	Loss: 1.062110
[INFO][08:31:31]: [Client #106] Epoch: [4/5][10/14]	Loss: 1.421344
[INFO][08:31:31]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][08:31:33]: [Client #106] Woke up.
[INFO][08:31:33]: [Client #106] Epoch: [5/5][0/14]	Loss: 1.524883
[INFO][08:31:33]: [Client #106] Epoch: [5/5][10/14]	Loss: 2.269729
[INFO][08:31:33]: [Client #106] Going to sleep for 1.66 seconds.
[INFO][08:31:35]: [Client #106] Woke up.
[INFO][08:31:35]: [Client #106] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_106_554853.pth.
[INFO][08:31:35]: [Client #106] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_106_554853.pth.
[INFO][08:31:35]: [Client #106] Model trained.
[INFO][08:31:35]: [Client #106] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:31:35]: [Server #554754] Received 0.26 MB of payload data from client #106 (simulated).
[INFO][08:32:23]: [Client #299] Woke up.
[INFO][08:32:23]: [Client #299] Epoch: [2/5][0/16]	Loss: 2.210709
[INFO][08:32:23]: [Client #299] Epoch: [2/5][10/16]	Loss: 1.449302
[INFO][08:32:23]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:33:21]: [Client #299] Woke up.
[INFO][08:33:21]: [Client #299] Epoch: [3/5][0/16]	Loss: 1.052019
[INFO][08:33:21]: [Client #299] Epoch: [3/5][10/16]	Loss: 2.266608
[INFO][08:33:21]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:34:18]: [Client #299] Woke up.
[INFO][08:34:18]: [Client #299] Epoch: [4/5][0/16]	Loss: 1.525117
[INFO][08:34:18]: [Client #299] Epoch: [4/5][10/16]	Loss: 1.484013
[INFO][08:34:19]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:35:16]: [Client #299] Woke up.
[INFO][08:35:16]: [Client #299] Epoch: [5/5][0/16]	Loss: 2.476597
[INFO][08:35:16]: [Client #299] Epoch: [5/5][10/16]	Loss: 2.081218
[INFO][08:35:16]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:36:13]: [Client #299] Woke up.
[INFO][08:36:13]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554860.pth.
[INFO][08:36:14]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554860.pth.
[INFO][08:36:14]: [Client #299] Model trained.
[INFO][08:36:14]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:36:14]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][08:36:14]: [Server #554754] Selecting client #374 for training.
[INFO][08:36:14]: [Server #554754] Sending the current model to client #374 (simulated).
[INFO][08:36:14]: [Server #554754] Sending 0.26 MB of payload data to client #374 (simulated).
[INFO][08:36:14]: [Server #554754] Selecting client #317 for training.
[INFO][08:36:14]: [Server #554754] Sending the current model to client #317 (simulated).
[INFO][08:36:14]: [Server #554754] Sending 0.26 MB of payload data to client #317 (simulated).
[INFO][08:36:14]: [Client #317] Selected by the server.
[INFO][08:36:14]: [Client #374] Selected by the server.
[INFO][08:36:14]: [Client #317] Loading its data source...
[INFO][08:36:14]: [Client #374] Loading its data source...
[INFO][08:36:14]: Data source: FEMNIST
[INFO][08:36:14]: Data source: FEMNIST
[INFO][08:36:14]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:36:14]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:36:14]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/317.zip.
[INFO][08:36:14]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/374.zip.

3.0%
6.0%
9.0%
12.0%
15.0%
17.9%
20.9%
23.9%
26.9%
29.9%
32.9%
35.9%
38.9%
41.9%
44.9%
2.3%
47.9%
50.8%
53.8%
56.8%
59.8%
62.8%
65.8%
68.8%
71.8%
74.8%
77.8%
80.8%
83.8%
86.7%
89.7%
92.7%
95.7%
98.7%
100.0%[INFO][08:36:14]: Decompressing the dataset downloaded.
[INFO][08:36:14]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/374.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

4.6%
7.0%
9.3%
11.6%
13.9%
16.2%
18.6%
20.9%
23.2%
25.5%
27.8%
30.1%
32.5%
34.8%
37.1%
39.4%
41.7%
44.1%
46.4%
48.7%
51.0%
53.3%
55.7%
58.0%
60.3%
62.6%
64.9%
67.3%
69.6%
71.9%
74.2%
76.5%
78.9%
81.2%
83.5%
85.8%
88.1%
90.4%
92.8%
95.1%
97.4%
99.7%
100.0%[INFO][08:36:14]: Decompressing the dataset downloaded.
[INFO][08:36:14]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/317.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:36:14]: [Client #374] Dataset size: 155
[INFO][08:36:14]: [Client #374] Sampler: all_inclusive
[INFO][08:36:14]: [Client #374] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:36:14]: [Client #317] Dataset size: 168
[INFO][08:36:14]: [Client #317] Sampler: all_inclusive
[INFO][08:36:14]: [93m[1m[Client #374] Started training in communication round #6.[0m

[INFO][08:36:14]: [Client #317] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:36:14]: [93m[1m[Client #317] Started training in communication round #6.[0m

[INFO][08:36:16]: [Client #374] Loading the dataset.
[INFO][08:36:16]: [Client #317] Loading the dataset.
[INFO][08:36:22]: [Client #374] Epoch: [1/5][0/16]	Loss: 2.803091
[INFO][08:36:22]: [Client #317] Epoch: [1/5][0/17]	Loss: 2.901005
[INFO][08:36:22]: [Client #374] Epoch: [1/5][10/16]	Loss: 1.777292
[INFO][08:36:22]: [Client #317] Epoch: [1/5][10/17]	Loss: 2.102894
[INFO][08:36:22]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][08:36:22]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][08:36:25]: [Client #317] Woke up.
[INFO][08:36:25]: [Client #317] Epoch: [2/5][0/17]	Loss: 1.795244
[INFO][08:36:25]: [Client #317] Epoch: [2/5][10/17]	Loss: 1.486969
[INFO][08:36:25]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][08:36:25]: [Client #374] Woke up.
[INFO][08:36:25]: [Client #374] Epoch: [2/5][0/16]	Loss: 1.625812
[INFO][08:36:25]: [Client #374] Epoch: [2/5][10/16]	Loss: 2.301523
[INFO][08:36:25]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][08:36:27]: [Client #317] Woke up.
[INFO][08:36:27]: [Client #317] Epoch: [3/5][0/17]	Loss: 1.853933
[INFO][08:36:27]: [Client #317] Epoch: [3/5][10/17]	Loss: 1.343706
[INFO][08:36:28]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][08:36:28]: [Client #374] Woke up.
[INFO][08:36:28]: [Client #374] Epoch: [3/5][0/16]	Loss: 2.469873
[INFO][08:36:28]: [Client #374] Epoch: [3/5][10/16]	Loss: 2.732942
[INFO][08:36:28]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][08:36:30]: [Client #317] Woke up.
[INFO][08:36:30]: [Client #317] Epoch: [4/5][0/17]	Loss: 2.720231
[INFO][08:36:30]: [Client #317] Epoch: [4/5][10/17]	Loss: 1.982018
[INFO][08:36:30]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][08:36:31]: [Client #374] Woke up.
[INFO][08:36:31]: [Client #374] Epoch: [4/5][0/16]	Loss: 2.314483
[INFO][08:36:31]: [Client #374] Epoch: [4/5][10/16]	Loss: 1.351291
[INFO][08:36:31]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][08:36:33]: [Client #317] Woke up.
[INFO][08:36:33]: [Client #317] Epoch: [5/5][0/17]	Loss: 1.332268
[INFO][08:36:33]: [Client #317] Epoch: [5/5][10/17]	Loss: 1.862697
[INFO][08:36:33]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][08:36:34]: [Client #374] Woke up.
[INFO][08:36:34]: [Client #374] Epoch: [5/5][0/16]	Loss: 1.504619
[INFO][08:36:34]: [Client #374] Epoch: [5/5][10/16]	Loss: 2.285974
[INFO][08:36:34]: [Client #374] Going to sleep for 2.93 seconds.
[INFO][08:36:36]: [Client #317] Woke up.
[INFO][08:36:36]: [Client #317] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_317_554860.pth.
[INFO][08:36:37]: [Client #317] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_317_554860.pth.
[INFO][08:36:37]: [Client #317] Model trained.
[INFO][08:36:37]: [Client #317] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:36:37]: [Server #554754] Received 0.26 MB of payload data from client #317 (simulated).
[INFO][08:36:37]: [Client #374] Woke up.
[INFO][08:36:37]: [Client #374] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_374_554853.pth.
[INFO][08:36:38]: [Client #374] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_374_554853.pth.
[INFO][08:36:38]: [Client #374] Model trained.
[INFO][08:36:38]: [Client #374] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:36:38]: [Server #554754] Received 0.26 MB of payload data from client #374 (simulated).
[INFO][08:36:38]: [Server #554754] Selecting client #297 for training.
[INFO][08:36:38]: [Server #554754] Sending the current model to client #297 (simulated).
[INFO][08:36:38]: [Server #554754] Sending 0.26 MB of payload data to client #297 (simulated).
[INFO][08:36:38]: [Server #554754] Selecting client #148 for training.
[INFO][08:36:38]: [Server #554754] Sending the current model to client #148 (simulated).
[INFO][08:36:38]: [Server #554754] Sending 0.26 MB of payload data to client #148 (simulated).
[INFO][08:36:38]: [Client #297] Selected by the server.
[INFO][08:36:38]: [Client #297] Loading its data source...
[INFO][08:36:38]: Data source: FEMNIST
[INFO][08:36:38]: [Client #148] Selected by the server.
[INFO][08:36:38]: [Client #148] Loading its data source...
[INFO][08:36:38]: Data source: FEMNIST
[INFO][08:36:38]: [Client #148] Dataset size: 148
[INFO][08:36:38]: [Client #148] Sampler: all_inclusive
[INFO][08:36:38]: [Client #148] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:36:38]: [93m[1m[Client #148] Started training in communication round #6.[0m
[INFO][08:36:38]: [Client #297] Dataset size: 161
[INFO][08:36:38]: [Client #297] Sampler: all_inclusive
[INFO][08:36:38]: [Client #297] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:36:38]: [93m[1m[Client #297] Started training in communication round #6.[0m
[INFO][08:36:40]: [Client #148] Loading the dataset.
[INFO][08:36:40]: [Client #297] Loading the dataset.
[INFO][08:36:45]: [Client #297] Epoch: [1/5][0/17]	Loss: 2.833276
[INFO][08:36:45]: [Client #148] Epoch: [1/5][0/15]	Loss: 2.100517
[INFO][08:36:45]: [Client #297] Epoch: [1/5][10/17]	Loss: 1.810380
[INFO][08:36:45]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][08:36:45]: [Client #148] Epoch: [1/5][10/15]	Loss: 2.491383
[INFO][08:36:46]: [Client #148] Going to sleep for 2.48 seconds.
[INFO][08:36:46]: [Client #297] Woke up.
[INFO][08:36:46]: [Client #297] Epoch: [2/5][0/17]	Loss: 2.221684
[INFO][08:36:46]: [Client #297] Epoch: [2/5][10/17]	Loss: 3.336798
[INFO][08:36:46]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][08:36:47]: [Client #297] Woke up.
[INFO][08:36:47]: [Client #297] Epoch: [3/5][0/17]	Loss: 1.555882
[INFO][08:36:47]: [Client #297] Epoch: [3/5][10/17]	Loss: 1.707602
[INFO][08:36:47]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][08:36:48]: [Client #297] Woke up.
[INFO][08:36:48]: [Client #297] Epoch: [4/5][0/17]	Loss: 1.534625
[INFO][08:36:48]: [Client #297] Epoch: [4/5][10/17]	Loss: 2.222733
[INFO][08:36:48]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][08:36:48]: [Client #148] Woke up.
[INFO][08:36:48]: [Client #148] Epoch: [2/5][0/15]	Loss: 1.601738
[INFO][08:36:48]: [Client #148] Epoch: [2/5][10/15]	Loss: 2.607981
[INFO][08:36:48]: [Client #148] Going to sleep for 2.48 seconds.
[INFO][08:36:48]: [Client #297] Woke up.
[INFO][08:36:48]: [Client #297] Epoch: [5/5][0/17]	Loss: 2.172757
[INFO][08:36:48]: [Client #297] Epoch: [5/5][10/17]	Loss: 1.725430
[INFO][08:36:48]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][08:36:49]: [Client #297] Woke up.
[INFO][08:36:49]: [Client #297] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_297_554853.pth.
[INFO][08:36:50]: [Client #297] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_297_554853.pth.
[INFO][08:36:50]: [Client #297] Model trained.
[INFO][08:36:50]: [Client #297] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:36:50]: [Server #554754] Received 0.26 MB of payload data from client #297 (simulated).
[INFO][08:36:51]: [Client #148] Woke up.
[INFO][08:36:51]: [Client #148] Epoch: [3/5][0/15]	Loss: 1.369552
[INFO][08:36:51]: [Client #148] Epoch: [3/5][10/15]	Loss: 1.632523
[INFO][08:36:51]: [Client #148] Going to sleep for 2.48 seconds.
[INFO][08:36:53]: [Client #148] Woke up.
[INFO][08:36:53]: [Client #148] Epoch: [4/5][0/15]	Loss: 1.248751
[INFO][08:36:53]: [Client #148] Epoch: [4/5][10/15]	Loss: 2.283330
[INFO][08:36:53]: [Client #148] Going to sleep for 2.48 seconds.
[INFO][08:36:56]: [Client #148] Woke up.
[INFO][08:36:56]: [Client #148] Epoch: [5/5][0/15]	Loss: 1.756262
[INFO][08:36:56]: [Client #148] Epoch: [5/5][10/15]	Loss: 1.350931
[INFO][08:36:56]: [Client #148] Going to sleep for 2.48 seconds.
[INFO][08:36:59]: [Client #148] Woke up.
[INFO][08:36:59]: [Client #148] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_148_554860.pth.
[INFO][08:36:59]: [Client #148] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_148_554860.pth.
[INFO][08:36:59]: [Client #148] Model trained.
[INFO][08:36:59]: [Client #148] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:36:59]: [Server #554754] Received 0.26 MB of payload data from client #148 (simulated).
[INFO][08:36:59]: [Server #554754] Selecting client #366 for training.
[INFO][08:36:59]: [Server #554754] Sending the current model to client #366 (simulated).
[INFO][08:36:59]: [Server #554754] Sending 0.26 MB of payload data to client #366 (simulated).
[INFO][08:36:59]: [Server #554754] Selecting client #473 for training.
[INFO][08:36:59]: [Server #554754] Sending the current model to client #473 (simulated).
[INFO][08:36:59]: [Server #554754] Sending 0.26 MB of payload data to client #473 (simulated).
[INFO][08:36:59]: [Client #366] Selected by the server.
[INFO][08:36:59]: [Client #366] Loading its data source...
[INFO][08:36:59]: Data source: FEMNIST
[INFO][08:36:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:36:59]: [Client #473] Selected by the server.
[INFO][08:36:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/366.zip.
[INFO][08:36:59]: [Client #473] Loading its data source...
[INFO][08:36:59]: Data source: FEMNIST
[INFO][08:36:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:36:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/473.zip.

2.5%
4.9%
7.4%
9.8%
12.3%
14.8%
17.2%
19.7%
22.1%
24.6%
27.0%
29.5%
32.0%
34.4%
36.9%
39.3%
2.8%
5.6%
8.5%
11.3%
14.1%
16.9%
19.7%
41.8%
44.3%
46.7%
49.2%
51.6%
54.1%
56.6%
59.0%
61.5%
63.9%
66.4%
68.9%
71.3%
73.8%
76.2%
78.7%
81.1%
83.6%
86.1%
88.5%
91.0%
93.4%
95.9%
98.4%
100.0%[INFO][08:36:59]: Decompressing the dataset downloaded.
[INFO][08:36:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/366.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

22.5%
25.4%
28.2%
31.0%
33.8%
36.6%
39.4%
42.3%
45.1%
47.9%
50.7%
53.5%
56.3%
59.2%
62.0%
64.8%
67.6%
70.4%
73.2%
76.1%
78.9%
81.7%
84.5%
87.3%
90.1%
93.0%
95.8%
98.6%
100.0%[INFO][08:36:59]: Decompressing the dataset downloaded.
[INFO][08:36:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/473.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:36:59]: [Client #366] Dataset size: 162
[INFO][08:36:59]: [Client #366] Sampler: all_inclusive
[INFO][08:36:59]: [Client #473] Dataset size: 163
[INFO][08:36:59]: [Client #473] Sampler: all_inclusive
[INFO][08:36:59]: [Client #366] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:36:59]: [Client #473] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:37:00]: [93m[1m[Client #366] Started training in communication round #6.[0m

[INFO][08:37:00]: [93m[1m[Client #473] Started training in communication round #6.[0m

[INFO][08:37:01]: [Client #366] Loading the dataset.
[INFO][08:37:01]: [Client #473] Loading the dataset.
[INFO][08:37:07]: [Client #473] Epoch: [1/5][0/17]	Loss: 1.964061
[INFO][08:37:07]: [Client #366] Epoch: [1/5][0/17]	Loss: 2.144946
[INFO][08:37:07]: [Client #473] Epoch: [1/5][10/17]	Loss: 2.737011
[INFO][08:37:07]: [Client #366] Epoch: [1/5][10/17]	Loss: 2.703036
[INFO][08:37:07]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][08:37:07]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][08:37:08]: [Client #473] Woke up.
[INFO][08:37:08]: [Client #473] Epoch: [2/5][0/17]	Loss: 2.736036
[INFO][08:37:08]: [Client #473] Epoch: [2/5][10/17]	Loss: 2.469846
[INFO][08:37:08]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][08:37:09]: [Client #473] Woke up.
[INFO][08:37:09]: [Client #473] Epoch: [3/5][0/17]	Loss: 1.901960
[INFO][08:37:09]: [Client #366] Woke up.
[INFO][08:37:09]: [Client #473] Epoch: [3/5][10/17]	Loss: 1.612455
[INFO][08:37:09]: [Client #366] Epoch: [2/5][0/17]	Loss: 2.019478
[INFO][08:37:09]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][08:37:09]: [Client #366] Epoch: [2/5][10/17]	Loss: 2.213526
[INFO][08:37:09]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][08:37:10]: [Client #473] Woke up.
[INFO][08:37:10]: [Client #473] Epoch: [4/5][0/17]	Loss: 2.287694
[INFO][08:37:10]: [Client #473] Epoch: [4/5][10/17]	Loss: 1.591960
[INFO][08:37:10]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][08:37:11]: [Client #473] Woke up.
[INFO][08:37:11]: [Client #473] Epoch: [5/5][0/17]	Loss: 1.626526
[INFO][08:37:11]: [Client #473] Epoch: [5/5][10/17]	Loss: 2.364498
[INFO][08:37:11]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][08:37:11]: [Client #366] Woke up.
[INFO][08:37:11]: [Client #366] Epoch: [3/5][0/17]	Loss: 2.742087
[INFO][08:37:11]: [Client #366] Epoch: [3/5][10/17]	Loss: 2.947757
[INFO][08:37:11]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][08:37:12]: [Client #473] Woke up.
[INFO][08:37:12]: [Client #473] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554860.pth.
[INFO][08:37:12]: [Client #473] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554860.pth.
[INFO][08:37:12]: [Client #473] Model trained.
[INFO][08:37:12]: [Client #473] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:37:12]: [Server #554754] Received 0.26 MB of payload data from client #473 (simulated).
[INFO][08:37:13]: [Client #366] Woke up.
[INFO][08:37:13]: [Client #366] Epoch: [4/5][0/17]	Loss: 2.173003
[INFO][08:37:13]: [Client #366] Epoch: [4/5][10/17]	Loss: 1.681291
[INFO][08:37:13]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][08:37:15]: [Client #366] Woke up.
[INFO][08:37:15]: [Client #366] Epoch: [5/5][0/17]	Loss: 1.634376
[INFO][08:37:15]: [Client #366] Epoch: [5/5][10/17]	Loss: 1.924432
[INFO][08:37:15]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][08:37:17]: [Client #366] Woke up.
[INFO][08:37:17]: [Client #366] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_554853.pth.
[INFO][08:37:17]: [Client #366] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_554853.pth.
[INFO][08:37:17]: [Client #366] Model trained.
[INFO][08:37:17]: [Client #366] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:37:17]: [Server #554754] Received 0.26 MB of payload data from client #366 (simulated).
[INFO][08:37:17]: [Server #554754] Adding client #322 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #328 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #486 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #455 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #297 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #473 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #137 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #74 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #106 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #366 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #148 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #317 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #374 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #242 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #320 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #363 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #377 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #47 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Adding client #401 to the list of clients for aggregation.
[INFO][08:37:17]: [Server #554754] Aggregating 19 clients in total.
[0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.0020407  0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204063 0.0020402  0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204049 0.00204088 0.00204088
 0.00201689 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00203873 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204033
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204032 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204047 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204053 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 327, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14412039 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06933058 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13282531 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07373625 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14260054 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13738735 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16498972 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10717687 0.
 0.         0.10778644 0.         0.16008616 0.         0.
 0.         0.         0.         0.08361066 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11703798 0.         0.         0.13858078
 0.         0.         0.         0.         0.         0.
 0.         0.10397158 0.         0.         0.11036436 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09038942 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.04716951 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08007382 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07971931
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14412039 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06933058 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13282531 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07373625 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14260054 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13738735 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16498972 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10717687 0.
 0.         0.10778644 0.         0.16008616 0.         0.
 0.         0.         0.         0.08361066 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11703798 0.         0.         0.13858078
 0.         0.         0.         0.         0.         0.
 0.         0.10397158 0.         0.         0.11036436 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09038942 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.04716951 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08007382 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07971931
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:38:01]: [Server #554754] Global model accuracy: 34.17%

[INFO][08:38:01]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_6.pth.
[INFO][08:38:01]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_6.pth.
[INFO][08:38:01]: [93m[1m
[Server #554754] Starting round 7/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.05352394 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.002
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04920213 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.04728435 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.002
 0.002      0.04853723 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.002      0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.0724734  0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05385638 0.002      0.002      0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.002      0.04720745 0.002
 0.002      0.08774834 0.002      0.002      0.002      0.002
 0.10305344 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05019947 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05111821 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05418883 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  3e-09  3e-09
 6:  6.9057e+00  6.9056e+00  1e-04  4e-09  6e-10
 7:  6.9057e+00  6.9056e+00  1e-04  4e-09  7e-10
 8:  6.9057e+00  6.9056e+00  8e-05  5e-08  8e-09
 9:  6.9056e+00  6.9056e+00  4e-05  4e-08  7e-09
10:  6.9056e+00  6.9056e+00  2e-05  5e-09  6e-10
11:  6.9056e+00  6.9056e+00  8e-06  4e-09  4e-10
12:  6.9056e+00  6.9056e+00  6e-07  9e-10  1e-10
Optimal solution found.
The calculated probability is:  [8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 1.79549925e-01 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 1.82237468e-05 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.62854124e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 1.95984546e-05 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.62757272e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 1.41598362e-03 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.62568336e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.62845315e-06
 8.63080895e-06 8.63080895e-06 8.62883267e-06 8.63080895e-06
 8.14618930e-01 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 2.35650680e-05 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 7.06996506e-05 8.63080895e-06 8.63080895e-06
 8.62714721e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.62892168e-06 8.63080895e-06 8.63080895e-06 8.62902419e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 2.73469117e-05
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 1.34592320e-05 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.62957092e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 2.18269254e-05 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06 8.63080895e-06
 8.63080895e-06 8.63080895e-06 8.63080895e-06]
current clients pool:  [INFO][08:38:02]: [Server #554754] Selected clients: [322  47 242  90 139  53 176 240  57 397]
[INFO][08:38:02]: [Server #554754] Selecting client #322 for training.
[INFO][08:38:02]: [Server #554754] Sending the current model to client #322 (simulated).
[INFO][08:38:02]: [Server #554754] Sending 0.26 MB of payload data to client #322 (simulated).
[INFO][08:38:02]: [Server #554754] Selecting client #47 for training.
[INFO][08:38:02]: [Server #554754] Sending the current model to client #47 (simulated).
[INFO][08:38:02]: [Server #554754] Sending 0.26 MB of payload data to client #47 (simulated).
[INFO][08:38:02]: [Client #322] Selected by the server.
[INFO][08:38:02]: [Client #322] Loading its data source...
[INFO][08:38:02]: Data source: FEMNIST
[INFO][08:38:02]: [Client #47] Selected by the server.
[INFO][08:38:02]: [Client #47] Loading its data source...
[INFO][08:38:02]: Data source: FEMNIST
[INFO][08:38:02]: [Client #322] Dataset size: 218
[INFO][08:38:02]: [Client #322] Sampler: all_inclusive
[INFO][08:38:02]: [Client #322] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:38:02]: [Client #47] Dataset size: 161
[INFO][08:38:02]: [Client #47] Sampler: all_inclusive
[INFO][08:38:02]: [Client #47] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:38:02]: [93m[1m[Client #322] Started training in communication round #7.[0m
[INFO][08:38:02]: [93m[1m[Client #47] Started training in communication round #7.[0m
[INFO][08:38:04]: [Client #47] Loading the dataset.
[INFO][08:38:04]: [Client #322] Loading the dataset.
[INFO][08:38:09]: [Client #322] Epoch: [1/5][0/22]	Loss: 2.605958
[INFO][08:38:09]: [Client #322] Epoch: [1/5][10/22]	Loss: 3.450231
[INFO][08:38:09]: [Client #47] Epoch: [1/5][0/17]	Loss: 1.583519
[INFO][08:38:09]: [Client #322] Epoch: [1/5][20/22]	Loss: 2.393800
[INFO][08:38:09]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:38:09]: [Client #47] Epoch: [1/5][10/17]	Loss: 2.045348
[INFO][08:38:09]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:38:11]: [Client #322] Woke up.
[INFO][08:38:11]: [Client #322] Epoch: [2/5][0/22]	Loss: 2.574806
[INFO][08:38:11]: [Client #322] Epoch: [2/5][10/22]	Loss: 3.799546
[INFO][08:38:11]: [Client #322] Epoch: [2/5][20/22]	Loss: 2.178560
[INFO][08:38:11]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:38:13]: [Client #322] Woke up.
[INFO][08:38:13]: [Client #322] Epoch: [3/5][0/22]	Loss: 2.506243
[INFO][08:38:13]: [Client #322] Epoch: [3/5][10/22]	Loss: 2.350190
[INFO][08:38:13]: [Client #322] Epoch: [3/5][20/22]	Loss: 3.240514
[INFO][08:38:13]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:38:14]: [Client #322] Woke up.
[INFO][08:38:15]: [Client #322] Epoch: [4/5][0/22]	Loss: 2.166594
[INFO][08:38:15]: [Client #322] Epoch: [4/5][10/22]	Loss: 2.738396
[INFO][08:38:15]: [Client #322] Epoch: [4/5][20/22]	Loss: 2.039615
[INFO][08:38:15]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:38:16]: [Client #322] Woke up.
[INFO][08:38:16]: [Client #322] Epoch: [5/5][0/22]	Loss: 1.609809
[INFO][08:38:16]: [Client #322] Epoch: [5/5][10/22]	Loss: 2.454882
[INFO][08:38:16]: [Client #322] Epoch: [5/5][20/22]	Loss: 2.598709
[INFO][08:38:16]: [Client #322] Going to sleep for 1.61 seconds.
[INFO][08:38:18]: [Client #322] Woke up.
[INFO][08:38:18]: [Client #322] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554853.pth.
[INFO][08:38:19]: [Client #322] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_322_554853.pth.
[INFO][08:38:19]: [Client #322] Model trained.
[INFO][08:38:19]: [Client #322] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:38:19]: [Server #554754] Received 0.26 MB of payload data from client #322 (simulated).
[INFO][08:38:19]: [Client #47] Woke up.
[INFO][08:38:19]: [Client #47] Epoch: [2/5][0/17]	Loss: 2.007006
[INFO][08:38:19]: [Client #47] Epoch: [2/5][10/17]	Loss: 1.714354
[INFO][08:38:19]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:38:29]: [Client #47] Woke up.
[INFO][08:38:29]: [Client #47] Epoch: [3/5][0/17]	Loss: 1.606199
[INFO][08:38:29]: [Client #47] Epoch: [3/5][10/17]	Loss: 1.796390
[INFO][08:38:30]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:38:39]: [Client #47] Woke up.
[INFO][08:38:40]: [Client #47] Epoch: [4/5][0/17]	Loss: 1.407614
[INFO][08:38:40]: [Client #47] Epoch: [4/5][10/17]	Loss: 1.207943
[INFO][08:38:40]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:38:50]: [Client #47] Woke up.
[INFO][08:38:50]: [Client #47] Epoch: [5/5][0/17]	Loss: 1.794863
[INFO][08:38:50]: [Client #47] Epoch: [5/5][10/17]	Loss: 1.437843
[INFO][08:38:50]: [Client #47] Going to sleep for 9.94 seconds.
[INFO][08:39:00]: [Client #47] Woke up.
[INFO][08:39:00]: [Client #47] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554860.pth.
[INFO][08:39:00]: [Client #47] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_47_554860.pth.
[INFO][08:39:00]: [Client #47] Model trained.
[INFO][08:39:00]: [Client #47] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:39:00]: [Server #554754] Received 0.26 MB of payload data from client #47 (simulated).
[INFO][08:39:00]: [Server #554754] Selecting client #242 for training.
[INFO][08:39:00]: [Server #554754] Sending the current model to client #242 (simulated).
[INFO][08:39:00]: [Server #554754] Sending 0.26 MB of payload data to client #242 (simulated).
[INFO][08:39:00]: [Server #554754] Selecting client #90 for training.
[INFO][08:39:00]: [Server #554754] Sending the current model to client #90 (simulated).
[INFO][08:39:00]: [Server #554754] Sending 0.26 MB of payload data to client #90 (simulated).
[INFO][08:39:00]: [Client #90] Selected by the server.
[INFO][08:39:00]: [Client #242] Selected by the server.
[INFO][08:39:00]: [Client #90] Loading its data source...
[INFO][08:39:00]: [Client #242] Loading its data source...
[INFO][08:39:00]: Data source: FEMNIST
[INFO][08:39:00]: Data source: FEMNIST
[INFO][08:39:00]: [Client #242] Dataset size: 146
[INFO][08:39:00]: [Client #242] Sampler: all_inclusive
[INFO][08:39:00]: [Client #242] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:39:00]: [93m[1m[Client #242] Started training in communication round #7.[0m
[INFO][08:39:00]: [Client #90] Dataset size: 162
[INFO][08:39:00]: [Client #90] Sampler: all_inclusive
[INFO][08:39:00]: [Client #90] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:39:00]: [93m[1m[Client #90] Started training in communication round #7.[0m
[INFO][08:39:02]: [Client #90] Loading the dataset.
[INFO][08:39:02]: [Client #242] Loading the dataset.
[INFO][08:39:08]: [Client #90] Epoch: [1/5][0/17]	Loss: 1.460635
[INFO][08:39:08]: [Client #242] Epoch: [1/5][0/15]	Loss: 1.990422
[INFO][08:39:08]: [Client #90] Epoch: [1/5][10/17]	Loss: 1.345045
[INFO][08:39:08]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][08:39:08]: [Client #242] Epoch: [1/5][10/15]	Loss: 1.882722
[INFO][08:39:08]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:39:10]: [Client #90] Woke up.
[INFO][08:39:10]: [Client #90] Epoch: [2/5][0/17]	Loss: 2.089031
[INFO][08:39:10]: [Client #90] Epoch: [2/5][10/17]	Loss: 2.580425
[INFO][08:39:10]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][08:39:12]: [Client #90] Woke up.
[INFO][08:39:12]: [Client #90] Epoch: [3/5][0/17]	Loss: 1.915987
[INFO][08:39:12]: [Client #90] Epoch: [3/5][10/17]	Loss: 1.892816
[INFO][08:39:12]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][08:39:13]: [Client #90] Woke up.
[INFO][08:39:13]: [Client #90] Epoch: [4/5][0/17]	Loss: 1.280733
[INFO][08:39:13]: [Client #90] Epoch: [4/5][10/17]	Loss: 2.957935
[INFO][08:39:13]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][08:39:15]: [Client #90] Woke up.
[INFO][08:39:15]: [Client #90] Epoch: [5/5][0/17]	Loss: 1.396071
[INFO][08:39:15]: [Client #90] Epoch: [5/5][10/17]	Loss: 1.767532
[INFO][08:39:15]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][08:39:16]: [Client #242] Woke up.
[INFO][08:39:16]: [Client #242] Epoch: [2/5][0/15]	Loss: 1.590012
[INFO][08:39:17]: [Client #242] Epoch: [2/5][10/15]	Loss: 1.999899
[INFO][08:39:17]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:39:17]: [Client #90] Woke up.
[INFO][08:39:17]: [Client #90] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_90_554860.pth.
[INFO][08:39:18]: [Client #90] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_90_554860.pth.
[INFO][08:39:18]: [Client #90] Model trained.
[INFO][08:39:18]: [Client #90] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:39:18]: [Server #554754] Received 0.26 MB of payload data from client #90 (simulated).
[INFO][08:39:25]: [Client #242] Woke up.
[INFO][08:39:25]: [Client #242] Epoch: [3/5][0/15]	Loss: 2.983463
[INFO][08:39:25]: [Client #242] Epoch: [3/5][10/15]	Loss: 1.111075
[INFO][08:39:25]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:39:33]: [Client #242] Woke up.
[INFO][08:39:33]: [Client #242] Epoch: [4/5][0/15]	Loss: 1.328372
[INFO][08:39:34]: [Client #242] Epoch: [4/5][10/15]	Loss: 0.731356
[INFO][08:39:34]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:39:42]: [Client #242] Woke up.
[INFO][08:39:42]: [Client #242] Epoch: [5/5][0/15]	Loss: 1.142802
[INFO][08:39:42]: [Client #242] Epoch: [5/5][10/15]	Loss: 1.882771
[INFO][08:39:42]: [Client #242] Going to sleep for 8.34 seconds.
[INFO][08:39:50]: [Client #242] Woke up.
[INFO][08:39:50]: [Client #242] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554853.pth.
[INFO][08:39:51]: [Client #242] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_242_554853.pth.
[INFO][08:39:51]: [Client #242] Model trained.
[INFO][08:39:51]: [Client #242] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:39:51]: [Server #554754] Received 0.26 MB of payload data from client #242 (simulated).
[INFO][08:39:51]: [Server #554754] Selecting client #139 for training.
[INFO][08:39:51]: [Server #554754] Sending the current model to client #139 (simulated).
[INFO][08:39:51]: [Server #554754] Sending 0.26 MB of payload data to client #139 (simulated).
[INFO][08:39:51]: [Server #554754] Selecting client #53 for training.
[INFO][08:39:51]: [Server #554754] Sending the current model to client #53 (simulated).
[INFO][08:39:51]: [Server #554754] Sending 0.26 MB of payload data to client #53 (simulated).
[INFO][08:39:51]: [Client #139] Selected by the server.
[INFO][08:39:51]: [Client #139] Loading its data source...
[INFO][08:39:51]: Data source: FEMNIST
[INFO][08:39:51]: [Client #53] Selected by the server.
[INFO][08:39:51]: [Client #53] Loading its data source...
[INFO][08:39:51]: Data source: FEMNIST
[INFO][08:39:51]: [Client #53] Dataset size: 155
[INFO][08:39:51]: [Client #53] Sampler: all_inclusive
[INFO][08:39:51]: [Client #53] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:39:51]: [93m[1m[Client #53] Started training in communication round #7.[0m
[INFO][08:39:51]: [Client #139] Dataset size: 158
[INFO][08:39:51]: [Client #139] Sampler: all_inclusive
[INFO][08:39:51]: [Client #139] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:39:51]: [93m[1m[Client #139] Started training in communication round #7.[0m
[INFO][08:39:53]: [Client #53] Loading the dataset.
[INFO][08:39:53]: [Client #139] Loading the dataset.
[INFO][08:39:59]: [Client #53] Epoch: [1/5][0/16]	Loss: 1.790139
[INFO][08:39:59]: [Client #139] Epoch: [1/5][0/16]	Loss: 1.963059
[INFO][08:39:59]: [Client #53] Epoch: [1/5][10/16]	Loss: 1.568709
[INFO][08:39:59]: [Client #139] Epoch: [1/5][10/16]	Loss: 0.818528
[INFO][08:39:59]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][08:39:59]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:39:59]: [Client #53] Woke up.
[INFO][08:39:59]: [Client #53] Epoch: [2/5][0/16]	Loss: 2.346410
[INFO][08:39:59]: [Client #53] Epoch: [2/5][10/16]	Loss: 1.079248
[INFO][08:39:59]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][08:39:59]: [Client #53] Woke up.
[INFO][08:39:59]: [Client #53] Epoch: [3/5][0/16]	Loss: 1.605011
[INFO][08:40:00]: [Client #53] Epoch: [3/5][10/16]	Loss: 1.216307
[INFO][08:40:00]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][08:40:00]: [Client #53] Woke up.
[INFO][08:40:00]: [Client #53] Epoch: [4/5][0/16]	Loss: 1.961654
[INFO][08:40:00]: [Client #53] Epoch: [4/5][10/16]	Loss: 1.036634
[INFO][08:40:00]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][08:40:00]: [Client #53] Woke up.
[INFO][08:40:00]: [Client #53] Epoch: [5/5][0/16]	Loss: 1.323317
[INFO][08:40:00]: [Client #53] Epoch: [5/5][10/16]	Loss: 0.980694
[INFO][08:40:00]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][08:40:01]: [Client #53] Woke up.
[INFO][08:40:01]: [Client #53] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_554860.pth.
[INFO][08:40:01]: [Client #53] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_554860.pth.
[INFO][08:40:01]: [Client #53] Model trained.
[INFO][08:40:01]: [Client #53] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:40:01]: [Server #554754] Received 0.26 MB of payload data from client #53 (simulated).
[INFO][08:40:05]: [Client #139] Woke up.
[INFO][08:40:05]: [Client #139] Epoch: [2/5][0/16]	Loss: 2.325989
[INFO][08:40:05]: [Client #139] Epoch: [2/5][10/16]	Loss: 2.446550
[INFO][08:40:05]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:40:12]: [Client #139] Woke up.
[INFO][08:40:12]: [Client #139] Epoch: [3/5][0/16]	Loss: 2.121942
[INFO][08:40:12]: [Client #139] Epoch: [3/5][10/16]	Loss: 1.003804
[INFO][08:40:12]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:40:18]: [Client #139] Woke up.
[INFO][08:40:18]: [Client #139] Epoch: [4/5][0/16]	Loss: 1.513893
[INFO][08:40:18]: [Client #139] Epoch: [4/5][10/16]	Loss: 1.789011
[INFO][08:40:18]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:40:25]: [Client #139] Woke up.
[INFO][08:40:25]: [Client #139] Epoch: [5/5][0/16]	Loss: 1.290310
[INFO][08:40:25]: [Client #139] Epoch: [5/5][10/16]	Loss: 1.731031
[INFO][08:40:25]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:40:31]: [Client #139] Woke up.
[INFO][08:40:31]: [Client #139] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_139_554853.pth.
[INFO][08:40:32]: [Client #139] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_139_554853.pth.
[INFO][08:40:32]: [Client #139] Model trained.
[INFO][08:40:32]: [Client #139] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:40:32]: [Server #554754] Received 0.26 MB of payload data from client #139 (simulated).
[INFO][08:40:32]: [Server #554754] Selecting client #176 for training.
[INFO][08:40:32]: [Server #554754] Sending the current model to client #176 (simulated).
[INFO][08:40:32]: [Server #554754] Sending 0.26 MB of payload data to client #176 (simulated).
[INFO][08:40:32]: [Server #554754] Selecting client #240 for training.
[INFO][08:40:32]: [Server #554754] Sending the current model to client #240 (simulated).
[INFO][08:40:32]: [Server #554754] Sending 0.26 MB of payload data to client #240 (simulated).
[INFO][08:40:32]: [Client #240] Selected by the server.
[INFO][08:40:32]: [Client #240] Loading its data source...
[INFO][08:40:32]: [Client #176] Selected by the server.
[INFO][08:40:32]: Data source: FEMNIST
[INFO][08:40:32]: [Client #176] Loading its data source...
[INFO][08:40:32]: Data source: FEMNIST
[INFO][08:40:32]: [Client #176] Dataset size: 148
[INFO][08:40:32]: [Client #176] Sampler: all_inclusive
[INFO][08:40:32]: [Client #176] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:40:32]: [93m[1m[Client #176] Started training in communication round #7.[0m
[INFO][08:40:32]: [Client #240] Dataset size: 156
[INFO][08:40:32]: [Client #240] Sampler: all_inclusive
[INFO][08:40:32]: [Client #240] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:40:32]: [93m[1m[Client #240] Started training in communication round #7.[0m
[INFO][08:40:34]: [Client #176] Loading the dataset.
[INFO][08:40:34]: [Client #240] Loading the dataset.
[INFO][08:40:39]: [Client #176] Epoch: [1/5][0/15]	Loss: 1.517761
[INFO][08:40:39]: [Client #240] Epoch: [1/5][0/16]	Loss: 1.715665
[INFO][08:40:40]: [Client #176] Epoch: [1/5][10/15]	Loss: 1.611475
[INFO][08:40:40]: [Client #240] Epoch: [1/5][10/16]	Loss: 1.427445
[INFO][08:40:40]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:40:40]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][08:40:42]: [Client #176] Woke up.
[INFO][08:40:42]: [Client #176] Epoch: [2/5][0/15]	Loss: 1.976448
[INFO][08:40:43]: [Client #176] Epoch: [2/5][10/15]	Loss: 1.871820
[INFO][08:40:43]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:40:44]: [Client #240] Woke up.
[INFO][08:40:44]: [Client #240] Epoch: [2/5][0/16]	Loss: 1.280614
[INFO][08:40:44]: [Client #240] Epoch: [2/5][10/16]	Loss: 1.992100
[INFO][08:40:44]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][08:40:46]: [Client #176] Woke up.
[INFO][08:40:46]: [Client #176] Epoch: [3/5][0/15]	Loss: 1.243173
[INFO][08:40:46]: [Client #176] Epoch: [3/5][10/15]	Loss: 2.020835
[INFO][08:40:46]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:40:48]: [Client #240] Woke up.
[INFO][08:40:48]: [Client #240] Epoch: [3/5][0/16]	Loss: 2.605401
[INFO][08:40:48]: [Client #240] Epoch: [3/5][10/16]	Loss: 2.193112
[INFO][08:40:48]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][08:40:49]: [Client #176] Woke up.
[INFO][08:40:49]: [Client #176] Epoch: [4/5][0/15]	Loss: 1.112060
[INFO][08:40:49]: [Client #176] Epoch: [4/5][10/15]	Loss: 1.707124
[INFO][08:40:49]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:40:52]: [Client #176] Woke up.
[INFO][08:40:52]: [Client #176] Epoch: [5/5][0/15]	Loss: 1.632349
[INFO][08:40:52]: [Client #176] Epoch: [5/5][10/15]	Loss: 1.304692
[INFO][08:40:52]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][08:40:52]: [Client #240] Woke up.
[INFO][08:40:52]: [Client #240] Epoch: [4/5][0/16]	Loss: 1.970145
[INFO][08:40:53]: [Client #240] Epoch: [4/5][10/16]	Loss: 1.092303
[INFO][08:40:53]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][08:40:55]: [Client #176] Woke up.
[INFO][08:40:55]: [Client #176] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554853.pth.
[INFO][08:40:55]: [Client #176] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554853.pth.
[INFO][08:40:55]: [Client #176] Model trained.
[INFO][08:40:55]: [Client #176] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:40:55]: [Server #554754] Received 0.26 MB of payload data from client #176 (simulated).
[INFO][08:40:57]: [Client #240] Woke up.
[INFO][08:40:57]: [Client #240] Epoch: [5/5][0/16]	Loss: 3.111569
[INFO][08:40:57]: [Client #240] Epoch: [5/5][10/16]	Loss: 1.965069
[INFO][08:40:57]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][08:41:01]: [Client #240] Woke up.
[INFO][08:41:01]: [Client #240] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_554860.pth.
[INFO][08:41:02]: [Client #240] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_554860.pth.
[INFO][08:41:02]: [Client #240] Model trained.
[INFO][08:41:02]: [Client #240] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:41:02]: [Server #554754] Received 0.26 MB of payload data from client #240 (simulated).
[INFO][08:41:02]: [Server #554754] Selecting client #57 for training.
[INFO][08:41:02]: [Server #554754] Sending the current model to client #57 (simulated).
[INFO][08:41:02]: [Server #554754] Sending 0.26 MB of payload data to client #57 (simulated).
[INFO][08:41:02]: [Server #554754] Selecting client #397 for training.
[INFO][08:41:02]: [Server #554754] Sending the current model to client #397 (simulated).
[INFO][08:41:02]: [Server #554754] Sending 0.26 MB of payload data to client #397 (simulated).
[INFO][08:41:02]: [Client #57] Selected by the server.
[INFO][08:41:02]: [Client #397] Selected by the server.
[INFO][08:41:02]: [Client #57] Loading its data source...
[INFO][08:41:02]: [Client #397] Loading its data source...
[INFO][08:41:02]: Data source: FEMNIST
[INFO][08:41:02]: Data source: FEMNIST
[INFO][08:41:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:41:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/397.zip.
[INFO][08:41:02]: [Client #57] Dataset size: 155
[INFO][08:41:02]: [Client #57] Sampler: all_inclusive
[INFO][08:41:02]: [Client #57] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:41:02]: [93m[1m[Client #57] Started training in communication round #7.[0m

2.4%
4.9%
7.3%
9.8%
12.2%
14.7%
17.1%
19.6%
22.0%
24.5%
26.9%
29.4%
31.8%
34.2%
36.7%
39.1%
41.6%
44.0%
46.5%
48.9%
51.4%
53.8%
56.3%
58.7%
61.2%
63.6%
66.1%
68.5%
70.9%
73.4%
75.8%
78.3%
80.7%
83.2%
85.6%
88.1%
90.5%
93.0%
95.4%
97.9%
100.0%[INFO][08:41:02]: Decompressing the dataset downloaded.
[INFO][08:41:02]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/397.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:41:02]: [Client #397] Dataset size: 164
[INFO][08:41:02]: [Client #397] Sampler: all_inclusive
[INFO][08:41:02]: [Client #397] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:41:02]: [93m[1m[Client #397] Started training in communication round #7.[0m

[INFO][08:41:04]: [Client #57] Loading the dataset.
[INFO][08:41:04]: [Client #397] Loading the dataset.
[INFO][08:41:09]: [Client #57] Epoch: [1/5][0/16]	Loss: 1.870147
[INFO][08:41:09]: [Client #57] Epoch: [1/5][10/16]	Loss: 1.667268
[INFO][08:41:09]: [Client #57] Going to sleep for 1.35 seconds.
[INFO][08:41:09]: [Client #397] Epoch: [1/5][0/17]	Loss: 2.067292
[INFO][08:41:10]: [Client #397] Epoch: [1/5][10/17]	Loss: 1.458751
[INFO][08:41:10]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][08:41:10]: [Client #397] Woke up.
[INFO][08:41:10]: [Client #397] Epoch: [2/5][0/17]	Loss: 1.590352
[INFO][08:41:10]: [Client #397] Epoch: [2/5][10/17]	Loss: 1.311075
[INFO][08:41:10]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][08:41:11]: [Client #57] Woke up.
[INFO][08:41:11]: [Client #57] Epoch: [2/5][0/16]	Loss: 0.802884
[INFO][08:41:11]: [Client #57] Epoch: [2/5][10/16]	Loss: 1.794672
[INFO][08:41:11]: [Client #57] Going to sleep for 1.35 seconds.
[INFO][08:41:11]: [Client #397] Woke up.
[INFO][08:41:11]: [Client #397] Epoch: [3/5][0/17]	Loss: 1.559961
[INFO][08:41:11]: [Client #397] Epoch: [3/5][10/17]	Loss: 2.207552
[INFO][08:41:11]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][08:41:12]: [Client #397] Woke up.
[INFO][08:41:12]: [Client #397] Epoch: [4/5][0/17]	Loss: 1.704054
[INFO][08:41:12]: [Client #397] Epoch: [4/5][10/17]	Loss: 2.055052
[INFO][08:41:12]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][08:41:12]: [Client #57] Woke up.
[INFO][08:41:12]: [Client #57] Epoch: [3/5][0/16]	Loss: 1.826722
[INFO][08:41:12]: [Client #57] Epoch: [3/5][10/16]	Loss: 1.386717
[INFO][08:41:12]: [Client #57] Going to sleep for 1.35 seconds.
[INFO][08:41:13]: [Client #397] Woke up.
[INFO][08:41:13]: [Client #397] Epoch: [5/5][0/17]	Loss: 0.741145
[INFO][08:41:13]: [Client #397] Epoch: [5/5][10/17]	Loss: 0.753358
[INFO][08:41:13]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][08:41:13]: [Client #397] Woke up.
[INFO][08:41:13]: [Client #397] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_554860.pth.
[INFO][08:41:14]: [Client #57] Woke up.
[INFO][08:41:14]: [Client #57] Epoch: [4/5][0/16]	Loss: 2.013761
[INFO][08:41:14]: [Client #57] Epoch: [4/5][10/16]	Loss: 2.151854
[INFO][08:41:14]: [Client #57] Going to sleep for 1.35 seconds.
[INFO][08:41:14]: [Client #397] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_554860.pth.
[INFO][08:41:14]: [Client #397] Model trained.
[INFO][08:41:14]: [Client #397] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:41:14]: [Server #554754] Received 0.26 MB of payload data from client #397 (simulated).
[INFO][08:41:15]: [Client #57] Woke up.
[INFO][08:41:15]: [Client #57] Epoch: [5/5][0/16]	Loss: 0.731582
[INFO][08:41:15]: [Client #57] Epoch: [5/5][10/16]	Loss: 1.524365
[INFO][08:41:15]: [Client #57] Going to sleep for 1.35 seconds.
[INFO][08:41:17]: [Client #57] Woke up.
[INFO][08:41:17]: [Client #57] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_57_554853.pth.
[INFO][08:41:17]: [Client #57] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_57_554853.pth.
[INFO][08:41:17]: [Client #57] Model trained.
[INFO][08:41:17]: [Client #57] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:41:17]: [Server #554754] Received 0.26 MB of payload data from client #57 (simulated).
[INFO][08:41:17]: [Server #554754] Adding client #53 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #397 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #57 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #322 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #90 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #176 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #240 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #139 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #242 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #47 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][08:41:17]: [Server #554754] Aggregating 11 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10123489 0.
 0.         0.         0.         0.         0.09470392 0.
 0.         0.         0.06807538 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13108475
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10842942 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10113973 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08903213
 0.         0.12828962 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13237325 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19067244 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07911911 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10123489 0.
 0.         0.         0.         0.         0.09470392 0.
 0.         0.         0.06807538 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13108475
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10842942 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10113973 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08903213
 0.         0.12828962 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13237325 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.19067244 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07911911 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:42:01]: [Server #554754] Global model accuracy: 40.27%

[INFO][08:42:01]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_7.pth.
[INFO][08:42:01]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_7.pth.
[INFO][08:42:01]: [93m[1m
[Server #554754] Starting round 8/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.002      0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.08876404 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04920213 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.08314607 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.08820225 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05385638 0.002      0.002      0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.002      0.04720745 0.002
 0.002      0.08774834 0.002      0.002      0.002      0.002
 0.10305344 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.05019947 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05111821 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05418883 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9078e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9073e+00  5e-04  8e-09  8e-09
 5:  6.9078e+00  6.9076e+00  1e-04  2e-09  2e-09
 6:  6.9077e+00  6.9076e+00  1e-04  2e-09  3e-10
 7:  6.9077e+00  6.9076e+00  1e-04  3e-09  4e-10
 8:  6.9077e+00  6.9076e+00  7e-05  3e-08  5e-09
 9:  6.9077e+00  6.9076e+00  4e-05  3e-08  5e-09
10:  6.9076e+00  6.9076e+00  3e-06  3e-08  4e-09
Optimal solution found.
The calculated probability is:  [5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.26861591e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.26965690e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27181863e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.26477456e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.26803829e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.26947875e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27012531e-05
 5.27413157e-05 5.26684968e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 9.73682912e-01 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.23844159e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27063466e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05
 5.27413157e-05 5.27413157e-05 5.27413157e-05 5.27413157e-05]
current clients pool:  [INFO][08:42:02]: [Server #554754] Selected clients: [299 380 359 494 139   2 468 430 365 258 354 391 188 386 376 307 201 349
 388 449]
[INFO][08:42:02]: [Server #554754] Selecting client #299 for training.
[INFO][08:42:02]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][08:42:02]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][08:42:02]: [Server #554754] Selecting client #380 for training.
[INFO][08:42:02]: [Server #554754] Sending the current model to client #380 (simulated).
[INFO][08:42:02]: [Server #554754] Sending 0.26 MB of payload data to client #380 (simulated).
[INFO][08:42:02]: [Client #299] Selected by the server.
[INFO][08:42:02]: [Client #299] Loading its data source...
[INFO][08:42:02]: Data source: FEMNIST
[INFO][08:42:02]: [Client #380] Selected by the server.
[INFO][08:42:02]: [Client #380] Loading its data source...
[INFO][08:42:02]: Data source: FEMNIST
[INFO][08:42:02]: [Client #299] Dataset size: 157
[INFO][08:42:02]: [Client #299] Sampler: all_inclusive
[INFO][08:42:02]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:42:02]: [Client #380] Dataset size: 159
[INFO][08:42:02]: [Client #380] Sampler: all_inclusive
[INFO][08:42:02]: [Client #380] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:42:02]: [93m[1m[Client #299] Started training in communication round #8.[0m
[INFO][08:42:02]: [93m[1m[Client #380] Started training in communication round #8.[0m
[INFO][08:42:04]: [Client #380] Loading the dataset.
[INFO][08:42:04]: [Client #299] Loading the dataset.
[INFO][08:42:09]: [Client #380] Epoch: [1/5][0/16]	Loss: 1.800717
[INFO][08:42:09]: [Client #299] Epoch: [1/5][0/16]	Loss: 2.780622
[INFO][08:42:09]: [Client #380] Epoch: [1/5][10/16]	Loss: 2.595963
[INFO][08:42:09]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:42:09]: [Client #299] Epoch: [1/5][10/16]	Loss: 1.886538
[INFO][08:42:09]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:42:10]: [Client #380] Woke up.
[INFO][08:42:10]: [Client #380] Epoch: [2/5][0/16]	Loss: 1.382019
[INFO][08:42:10]: [Client #380] Epoch: [2/5][10/16]	Loss: 1.903568
[INFO][08:42:10]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:42:10]: [Client #380] Woke up.
[INFO][08:42:10]: [Client #380] Epoch: [3/5][0/16]	Loss: 2.024064
[INFO][08:42:10]: [Client #380] Epoch: [3/5][10/16]	Loss: 1.556564
[INFO][08:42:10]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:42:10]: [Client #380] Woke up.
[INFO][08:42:10]: [Client #380] Epoch: [4/5][0/16]	Loss: 1.362347
[INFO][08:42:10]: [Client #380] Epoch: [4/5][10/16]	Loss: 1.365794
[INFO][08:42:10]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:42:11]: [Client #380] Woke up.
[INFO][08:42:11]: [Client #380] Epoch: [5/5][0/16]	Loss: 0.856922
[INFO][08:42:11]: [Client #380] Epoch: [5/5][10/16]	Loss: 1.591156
[INFO][08:42:11]: [Client #380] Going to sleep for 0.23 seconds.
[INFO][08:42:11]: [Client #380] Woke up.
[INFO][08:42:11]: [Client #380] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_554860.pth.
[INFO][08:42:12]: [Client #380] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_380_554860.pth.
[INFO][08:42:12]: [Client #380] Model trained.
[INFO][08:42:12]: [Client #380] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:42:12]: [Server #554754] Received 0.26 MB of payload data from client #380 (simulated).
[INFO][08:43:07]: [Client #299] Woke up.
[INFO][08:43:07]: [Client #299] Epoch: [2/5][0/16]	Loss: 2.473747
[INFO][08:43:07]: [Client #299] Epoch: [2/5][10/16]	Loss: 1.829668
[INFO][08:43:07]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:44:04]: [Client #299] Woke up.
[INFO][08:44:04]: [Client #299] Epoch: [3/5][0/16]	Loss: 2.532203
[INFO][08:44:04]: [Client #299] Epoch: [3/5][10/16]	Loss: 2.380913
[INFO][08:44:04]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:45:02]: [Client #299] Woke up.
[INFO][08:45:02]: [Client #299] Epoch: [4/5][0/16]	Loss: 1.242852
[INFO][08:45:02]: [Client #299] Epoch: [4/5][10/16]	Loss: 1.017000
[INFO][08:45:02]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:45:59]: [Client #299] Woke up.
[INFO][08:45:59]: [Client #299] Epoch: [5/5][0/16]	Loss: 0.712436
[INFO][08:45:59]: [Client #299] Epoch: [5/5][10/16]	Loss: 2.471593
[INFO][08:45:59]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][08:46:57]: [Client #299] Woke up.
[INFO][08:46:57]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][08:46:57]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][08:46:57]: [Client #299] Model trained.
[INFO][08:46:57]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:46:57]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][08:46:57]: [Server #554754] Selecting client #359 for training.
[INFO][08:46:57]: [Server #554754] Sending the current model to client #359 (simulated).
[INFO][08:46:57]: [Server #554754] Sending 0.26 MB of payload data to client #359 (simulated).
[INFO][08:46:57]: [Server #554754] Selecting client #494 for training.
[INFO][08:46:57]: [Server #554754] Sending the current model to client #494 (simulated).
[INFO][08:46:57]: [Server #554754] Sending 0.26 MB of payload data to client #494 (simulated).
[INFO][08:46:57]: [Client #359] Selected by the server.
[INFO][08:46:57]: [Client #359] Loading its data source...
[INFO][08:46:57]: Data source: FEMNIST
[INFO][08:46:57]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:46:57]: [Client #494] Selected by the server.
[INFO][08:46:57]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/359.zip.
[INFO][08:46:57]: [Client #494] Loading its data source...
[INFO][08:46:57]: Data source: FEMNIST
[INFO][08:46:57]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:46:57]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/494.zip.

2.4%
4.7%
7.1%
9.5%
11.8%
14.2%
16.6%
18.9%
21.3%
23.7%
26.0%
28.4%
30.8%
33.1%
35.5%
37.8%
2.4%
4.7%
7.1%
9.4%
11.8%
14.1%
16.5%
18.8%
21.2%
23.6%
25.9%
28.3%
30.6%
33.0%
35.3%
37.7%
40.0%
40.2%
42.6%
44.9%
47.3%
49.7%
52.0%
54.4%
56.8%
59.1%
61.5%
63.9%
66.2%
68.6%
71.0%
73.3%
75.7%
78.1%
80.4%
82.8%
85.2%
87.5%
89.9%
92.3%
94.6%
97.0%
99.4%
100.0%[INFO][08:46:58]: Decompressing the dataset downloaded.
[INFO][08:46:58]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/359.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

42.4%
44.8%
47.1%
49.5%
51.8%
54.2%
56.5%
58.9%
61.2%
63.6%
65.9%
68.3%
70.7%
73.0%
75.4%
77.7%
80.1%
82.4%
84.8%
87.1%
89.5%
91.9%
94.2%
96.6%
98.9%
100.0%[INFO][08:46:58]: Decompressing the dataset downloaded.
[INFO][08:46:58]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/494.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:46:58]: [Client #359] Dataset size: 161
[INFO][08:46:58]: [Client #359] Sampler: all_inclusive
[INFO][08:46:58]: [Client #359] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:46:58]: [93m[1m[Client #359] Started training in communication round #8.[0m

[INFO][08:46:58]: [Client #494] Dataset size: 161
[INFO][08:46:58]: [Client #494] Sampler: all_inclusive
[INFO][08:46:58]: [Client #494] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:46:58]: [93m[1m[Client #494] Started training in communication round #8.[0m

[INFO][08:47:00]: [Client #359] Loading the dataset.
[INFO][08:47:00]: [Client #494] Loading the dataset.
[INFO][08:47:05]: [Client #359] Epoch: [1/5][0/17]	Loss: 1.448645
[INFO][08:47:05]: [Client #494] Epoch: [1/5][0/17]	Loss: 1.116700
[INFO][08:47:05]: [Client #359] Epoch: [1/5][10/17]	Loss: 1.401005
[INFO][08:47:05]: [Client #494] Epoch: [1/5][10/17]	Loss: 3.788957
[INFO][08:47:05]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:47:05]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][08:47:05]: [Client #494] Woke up.
[INFO][08:47:05]: [Client #494] Epoch: [2/5][0/17]	Loss: 0.749459
[INFO][08:47:06]: [Client #494] Epoch: [2/5][10/17]	Loss: 2.043909
[INFO][08:47:06]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][08:47:06]: [Client #494] Woke up.
[INFO][08:47:06]: [Client #494] Epoch: [3/5][0/17]	Loss: 1.428381
[INFO][08:47:06]: [Client #494] Epoch: [3/5][10/17]	Loss: 1.804571
[INFO][08:47:06]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][08:47:06]: [Client #494] Woke up.
[INFO][08:47:06]: [Client #494] Epoch: [4/5][0/17]	Loss: 1.180095
[INFO][08:47:07]: [Client #494] Epoch: [4/5][10/17]	Loss: 3.388849
[INFO][08:47:07]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][08:47:07]: [Client #494] Woke up.
[INFO][08:47:07]: [Client #494] Epoch: [5/5][0/17]	Loss: 2.864666
[INFO][08:47:07]: [Client #494] Epoch: [5/5][10/17]	Loss: 2.224698
[INFO][08:47:07]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][08:47:07]: [Client #494] Woke up.
[INFO][08:47:07]: [Client #494] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_554860.pth.
[INFO][08:47:08]: [Client #494] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_554860.pth.
[INFO][08:47:08]: [Client #494] Model trained.
[INFO][08:47:08]: [Client #494] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:47:08]: [Server #554754] Received 0.26 MB of payload data from client #494 (simulated).
[INFO][08:47:09]: [Client #359] Woke up.
[INFO][08:47:09]: [Client #359] Epoch: [2/5][0/17]	Loss: 1.238682
[INFO][08:47:09]: [Client #359] Epoch: [2/5][10/17]	Loss: 3.271651
[INFO][08:47:09]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:47:12]: [Client #359] Woke up.
[INFO][08:47:13]: [Client #359] Epoch: [3/5][0/17]	Loss: 1.735096
[INFO][08:47:13]: [Client #359] Epoch: [3/5][10/17]	Loss: 1.398515
[INFO][08:47:13]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:47:16]: [Client #359] Woke up.
[INFO][08:47:16]: [Client #359] Epoch: [4/5][0/17]	Loss: 1.107183
[INFO][08:47:16]: [Client #359] Epoch: [4/5][10/17]	Loss: 1.190351
[INFO][08:47:16]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:47:20]: [Client #359] Woke up.
[INFO][08:47:20]: [Client #359] Epoch: [5/5][0/17]	Loss: 2.053329
[INFO][08:47:20]: [Client #359] Epoch: [5/5][10/17]	Loss: 1.310840
[INFO][08:47:20]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:47:24]: [Client #359] Woke up.
[INFO][08:47:24]: [Client #359] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_359_554853.pth.
[INFO][08:47:24]: [Client #359] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_359_554853.pth.
[INFO][08:47:24]: [Client #359] Model trained.
[INFO][08:47:24]: [Client #359] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:47:24]: [Server #554754] Received 0.26 MB of payload data from client #359 (simulated).
[INFO][08:47:24]: [Server #554754] Selecting client #139 for training.
[INFO][08:47:24]: [Server #554754] Sending the current model to client #139 (simulated).
[INFO][08:47:24]: [Server #554754] Sending 0.26 MB of payload data to client #139 (simulated).
[INFO][08:47:24]: [Server #554754] Selecting client #2 for training.
[INFO][08:47:24]: [Server #554754] Sending the current model to client #2 (simulated).
[INFO][08:47:24]: [Server #554754] Sending 0.26 MB of payload data to client #2 (simulated).
[INFO][08:47:24]: [Client #139] Selected by the server.
[INFO][08:47:24]: [Client #139] Loading its data source...
[INFO][08:47:24]: Data source: FEMNIST
[INFO][08:47:24]: [Client #2] Selected by the server.
[INFO][08:47:24]: [Client #2] Loading its data source...
[INFO][08:47:24]: Data source: FEMNIST
[INFO][08:47:24]: [Client #139] Dataset size: 158
[INFO][08:47:24]: [Client #139] Sampler: all_inclusive
[INFO][08:47:24]: [Client #139] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:47:24]: [93m[1m[Client #139] Started training in communication round #8.[0m
[INFO][08:47:24]: [Client #2] Dataset size: 153
[INFO][08:47:24]: [Client #2] Sampler: all_inclusive
[INFO][08:47:25]: [Client #2] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:47:25]: [93m[1m[Client #2] Started training in communication round #8.[0m
[INFO][08:47:26]: [Client #139] Loading the dataset.
[INFO][08:47:26]: [Client #2] Loading the dataset.
[INFO][08:47:32]: [Client #139] Epoch: [1/5][0/16]	Loss: 1.072566
[INFO][08:47:32]: [Client #2] Epoch: [1/5][0/16]	Loss: 2.361817
[INFO][08:47:32]: [Client #139] Epoch: [1/5][10/16]	Loss: 1.625971
[INFO][08:47:32]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:47:32]: [Client #2] Epoch: [1/5][10/16]	Loss: 1.777177
[INFO][08:47:32]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][08:47:35]: [Client #2] Woke up.
[INFO][08:47:35]: [Client #2] Epoch: [2/5][0/16]	Loss: 2.317597
[INFO][08:47:35]: [Client #2] Epoch: [2/5][10/16]	Loss: 1.573830
[INFO][08:47:35]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][08:47:37]: [Client #2] Woke up.
[INFO][08:47:37]: [Client #2] Epoch: [3/5][0/16]	Loss: 1.810681
[INFO][08:47:38]: [Client #2] Epoch: [3/5][10/16]	Loss: 1.950900
[INFO][08:47:38]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][08:47:38]: [Client #139] Woke up.
[INFO][08:47:38]: [Client #139] Epoch: [2/5][0/16]	Loss: 1.906928
[INFO][08:47:38]: [Client #139] Epoch: [2/5][10/16]	Loss: 1.544562
[INFO][08:47:39]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:47:40]: [Client #2] Woke up.
[INFO][08:47:40]: [Client #2] Epoch: [4/5][0/16]	Loss: 1.342153
[INFO][08:47:40]: [Client #2] Epoch: [4/5][10/16]	Loss: 1.603439
[INFO][08:47:40]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][08:47:43]: [Client #2] Woke up.
[INFO][08:47:43]: [Client #2] Epoch: [5/5][0/16]	Loss: 1.880661
[INFO][08:47:43]: [Client #2] Epoch: [5/5][10/16]	Loss: 1.574624
[INFO][08:47:43]: [Client #2] Going to sleep for 2.58 seconds.
[INFO][08:47:45]: [Client #139] Woke up.
[INFO][08:47:45]: [Client #139] Epoch: [3/5][0/16]	Loss: 1.577589
[INFO][08:47:45]: [Client #139] Epoch: [3/5][10/16]	Loss: 2.585396
[INFO][08:47:45]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:47:46]: [Client #2] Woke up.
[INFO][08:47:46]: [Client #2] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_2_554860.pth.
[INFO][08:47:46]: [Client #2] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_2_554860.pth.
[INFO][08:47:46]: [Client #2] Model trained.
[INFO][08:47:46]: [Client #2] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:47:46]: [Server #554754] Received 0.26 MB of payload data from client #2 (simulated).
[INFO][08:47:51]: [Client #139] Woke up.
[INFO][08:47:51]: [Client #139] Epoch: [4/5][0/16]	Loss: 1.251738
[INFO][08:47:51]: [Client #139] Epoch: [4/5][10/16]	Loss: 1.143364
[INFO][08:47:51]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:47:58]: [Client #139] Woke up.
[INFO][08:47:58]: [Client #139] Epoch: [5/5][0/16]	Loss: 0.802045
[INFO][08:47:58]: [Client #139] Epoch: [5/5][10/16]	Loss: 1.012475
[INFO][08:47:58]: [Client #139] Going to sleep for 6.33 seconds.
[INFO][08:48:04]: [Client #139] Woke up.
[INFO][08:48:04]: [Client #139] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_139_554853.pth.
[INFO][08:48:05]: [Client #139] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_139_554853.pth.
[INFO][08:48:05]: [Client #139] Model trained.
[INFO][08:48:05]: [Client #139] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:48:05]: [Server #554754] Received 0.26 MB of payload data from client #139 (simulated).
[INFO][08:48:05]: [Server #554754] Selecting client #468 for training.
[INFO][08:48:05]: [Server #554754] Sending the current model to client #468 (simulated).
[INFO][08:48:05]: [Server #554754] Sending 0.26 MB of payload data to client #468 (simulated).
[INFO][08:48:05]: [Server #554754] Selecting client #430 for training.
[INFO][08:48:05]: [Server #554754] Sending the current model to client #430 (simulated).
[INFO][08:48:05]: [Server #554754] Sending 0.26 MB of payload data to client #430 (simulated).
[INFO][08:48:05]: [Client #468] Selected by the server.
[INFO][08:48:05]: [Client #468] Loading its data source...
[INFO][08:48:05]: Data source: FEMNIST
[INFO][08:48:05]: [Client #430] Selected by the server.
[INFO][08:48:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:48:05]: [Client #430] Loading its data source...
[INFO][08:48:05]: Data source: FEMNIST
[INFO][08:48:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/468.zip.
[INFO][08:48:05]: [Client #430] Dataset size: 160
[INFO][08:48:05]: [Client #430] Sampler: all_inclusive
[INFO][08:48:05]: [Client #430] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:48:05]: [93m[1m[Client #430] Started training in communication round #8.[0m

3.3%
6.5%
9.8%
13.1%
16.3%
19.6%
22.9%
26.1%
29.4%
32.7%
35.9%
39.2%
42.5%
45.7%
49.0%
52.3%
55.5%
58.8%
62.1%
65.3%
68.6%
71.9%
75.1%
78.4%
81.7%
84.9%
88.2%
91.5%
94.7%
98.0%
100.0%[INFO][08:48:05]: Decompressing the dataset downloaded.
[INFO][08:48:05]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/468.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:48:05]: [Client #468] Dataset size: 150
[INFO][08:48:05]: [Client #468] Sampler: all_inclusive
[INFO][08:48:05]: [Client #468] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:48:05]: [93m[1m[Client #468] Started training in communication round #8.[0m

[INFO][08:48:07]: [Client #430] Loading the dataset.
[INFO][08:48:07]: [Client #468] Loading the dataset.
[INFO][08:48:13]: [Client #430] Epoch: [1/5][0/16]	Loss: 1.864167
[INFO][08:48:13]: [Client #430] Epoch: [1/5][10/16]	Loss: 2.588136
[INFO][08:48:13]: [Client #468] Epoch: [1/5][0/15]	Loss: 2.652581
[INFO][08:48:13]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:48:13]: [Client #468] Epoch: [1/5][10/15]	Loss: 1.449212
[INFO][08:48:13]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][08:48:13]: [Client #468] Woke up.
[INFO][08:48:13]: [Client #468] Epoch: [2/5][0/15]	Loss: 2.165799
[INFO][08:48:13]: [Client #468] Epoch: [2/5][10/15]	Loss: 1.430331
[INFO][08:48:13]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][08:48:14]: [Client #468] Woke up.
[INFO][08:48:14]: [Client #468] Epoch: [3/5][0/15]	Loss: 1.726910
[INFO][08:48:14]: [Client #468] Epoch: [3/5][10/15]	Loss: 1.779539
[INFO][08:48:14]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][08:48:14]: [Client #468] Woke up.
[INFO][08:48:14]: [Client #468] Epoch: [4/5][0/15]	Loss: 1.819409
[INFO][08:48:14]: [Client #468] Epoch: [4/5][10/15]	Loss: 2.312172
[INFO][08:48:14]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][08:48:15]: [Client #468] Woke up.
[INFO][08:48:15]: [Client #468] Epoch: [5/5][0/15]	Loss: 1.369198
[INFO][08:48:15]: [Client #468] Epoch: [5/5][10/15]	Loss: 1.812233
[INFO][08:48:15]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][08:48:15]: [Client #468] Woke up.
[INFO][08:48:15]: [Client #468] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_468_554853.pth.
[INFO][08:48:16]: [Client #430] Woke up.
[INFO][08:48:16]: [Client #430] Epoch: [2/5][0/16]	Loss: 2.807419
[INFO][08:48:16]: [Client #430] Epoch: [2/5][10/16]	Loss: 2.135535
[INFO][08:48:16]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:48:16]: [Client #468] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_468_554853.pth.
[INFO][08:48:16]: [Client #468] Model trained.
[INFO][08:48:16]: [Client #468] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:48:16]: [Server #554754] Received 0.26 MB of payload data from client #468 (simulated).
[INFO][08:48:19]: [Client #430] Woke up.
[INFO][08:48:19]: [Client #430] Epoch: [3/5][0/16]	Loss: 1.014861
[INFO][08:48:19]: [Client #430] Epoch: [3/5][10/16]	Loss: 0.716825
[INFO][08:48:19]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:48:22]: [Client #430] Woke up.
[INFO][08:48:22]: [Client #430] Epoch: [4/5][0/16]	Loss: 1.715636
[INFO][08:48:22]: [Client #430] Epoch: [4/5][10/16]	Loss: 2.508825
[INFO][08:48:22]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:48:25]: [Client #430] Woke up.
[INFO][08:48:25]: [Client #430] Epoch: [5/5][0/16]	Loss: 1.850352
[INFO][08:48:25]: [Client #430] Epoch: [5/5][10/16]	Loss: 1.803639
[INFO][08:48:25]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][08:48:28]: [Client #430] Woke up.
[INFO][08:48:28]: [Client #430] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554860.pth.
[INFO][08:48:29]: [Client #430] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554860.pth.
[INFO][08:48:29]: [Client #430] Model trained.
[INFO][08:48:29]: [Client #430] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:48:29]: [Server #554754] Received 0.26 MB of payload data from client #430 (simulated).
[INFO][08:48:29]: [Server #554754] Selecting client #365 for training.
[INFO][08:48:29]: [Server #554754] Sending the current model to client #365 (simulated).
[INFO][08:48:29]: [Server #554754] Sending 0.26 MB of payload data to client #365 (simulated).
[INFO][08:48:29]: [Server #554754] Selecting client #258 for training.
[INFO][08:48:29]: [Server #554754] Sending the current model to client #258 (simulated).
[INFO][08:48:29]: [Server #554754] Sending 0.26 MB of payload data to client #258 (simulated).
[INFO][08:48:29]: [Client #258] Selected by the server.
[INFO][08:48:29]: [Client #365] Selected by the server.
[INFO][08:48:29]: [Client #258] Loading its data source...
[INFO][08:48:29]: Data source: FEMNIST
[INFO][08:48:29]: [Client #365] Loading its data source...
[INFO][08:48:29]: Data source: FEMNIST
[INFO][08:48:29]: [Client #365] Dataset size: 164
[INFO][08:48:29]: [Client #365] Sampler: all_inclusive
[INFO][08:48:29]: [Client #365] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:48:29]: [93m[1m[Client #365] Started training in communication round #8.[0m
[INFO][08:48:29]: [Client #258] Dataset size: 165
[INFO][08:48:29]: [Client #258] Sampler: all_inclusive
[INFO][08:48:29]: [Client #258] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:48:29]: [93m[1m[Client #258] Started training in communication round #8.[0m
[INFO][08:48:31]: [Client #258] Loading the dataset.
[INFO][08:48:31]: [Client #365] Loading the dataset.
[INFO][08:48:36]: [Client #365] Epoch: [1/5][0/17]	Loss: 2.151681
[INFO][08:48:36]: [Client #258] Epoch: [1/5][0/17]	Loss: 2.308296
[INFO][08:48:36]: [Client #365] Epoch: [1/5][10/17]	Loss: 1.230113
[INFO][08:48:36]: [Client #258] Epoch: [1/5][10/17]	Loss: 1.172701
[INFO][08:48:36]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][08:48:36]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][08:48:38]: [Client #258] Woke up.
[INFO][08:48:38]: [Client #258] Epoch: [2/5][0/17]	Loss: 1.253398
[INFO][08:48:38]: [Client #258] Epoch: [2/5][10/17]	Loss: 2.407569
[INFO][08:48:38]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][08:48:40]: [Client #258] Woke up.
[INFO][08:48:40]: [Client #258] Epoch: [3/5][0/17]	Loss: 0.565217
[INFO][08:48:40]: [Client #258] Epoch: [3/5][10/17]	Loss: 1.627499
[INFO][08:48:40]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][08:48:42]: [Client #258] Woke up.
[INFO][08:48:42]: [Client #258] Epoch: [4/5][0/17]	Loss: 1.564228
[INFO][08:48:42]: [Client #258] Epoch: [4/5][10/17]	Loss: 2.480983
[INFO][08:48:42]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][08:48:44]: [Client #258] Woke up.
[INFO][08:48:44]: [Client #258] Epoch: [5/5][0/17]	Loss: 1.200934
[INFO][08:48:44]: [Client #258] Epoch: [5/5][10/17]	Loss: 1.638146
[INFO][08:48:44]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][08:48:45]: [Client #258] Woke up.
[INFO][08:48:45]: [Client #258] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][08:48:46]: [Client #258] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][08:48:46]: [Client #258] Model trained.
[INFO][08:48:46]: [Client #258] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:48:46]: [Server #554754] Received 0.26 MB of payload data from client #258 (simulated).
[INFO][08:49:15]: [Client #365] Woke up.
[INFO][08:49:15]: [Client #365] Epoch: [2/5][0/17]	Loss: 1.194406
[INFO][08:49:15]: [Client #365] Epoch: [2/5][10/17]	Loss: 1.868781
[INFO][08:49:15]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][08:49:54]: [Client #365] Woke up.
[INFO][08:49:54]: [Client #365] Epoch: [3/5][0/17]	Loss: 1.187132
[INFO][08:49:54]: [Client #365] Epoch: [3/5][10/17]	Loss: 1.343780
[INFO][08:49:54]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][08:50:33]: [Client #365] Woke up.
[INFO][08:50:33]: [Client #365] Epoch: [4/5][0/17]	Loss: 1.294384
[INFO][08:50:33]: [Client #365] Epoch: [4/5][10/17]	Loss: 1.856612
[INFO][08:50:33]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][08:51:12]: [Client #365] Woke up.
[INFO][08:51:12]: [Client #365] Epoch: [5/5][0/17]	Loss: 1.934202
[INFO][08:51:12]: [Client #365] Epoch: [5/5][10/17]	Loss: 0.791743
[INFO][08:51:12]: [Client #365] Going to sleep for 38.59 seconds.
[INFO][08:51:50]: [Client #365] Woke up.
[INFO][08:51:51]: [Client #365] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_365_554853.pth.
[INFO][08:51:51]: [Client #365] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_365_554853.pth.
[INFO][08:51:51]: [Client #365] Model trained.
[INFO][08:51:51]: [Client #365] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:51:51]: [Server #554754] Received 0.26 MB of payload data from client #365 (simulated).
[INFO][08:51:51]: [Server #554754] Selecting client #354 for training.
[INFO][08:51:51]: [Server #554754] Sending the current model to client #354 (simulated).
[INFO][08:51:51]: [Server #554754] Sending 0.26 MB of payload data to client #354 (simulated).
[INFO][08:51:51]: [Server #554754] Selecting client #391 for training.
[INFO][08:51:51]: [Server #554754] Sending the current model to client #391 (simulated).
[INFO][08:51:51]: [Server #554754] Sending 0.26 MB of payload data to client #391 (simulated).
[INFO][08:51:51]: [Client #354] Selected by the server.
[INFO][08:51:51]: [Client #354] Loading its data source...
[INFO][08:51:51]: [Client #391] Selected by the server.
[INFO][08:51:51]: Data source: FEMNIST
[INFO][08:51:51]: [Client #391] Loading its data source...
[INFO][08:51:51]: Data source: FEMNIST
[INFO][08:51:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:51:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:51:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/391.zip.
[INFO][08:51:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/354.zip.

2.0%
4.1%
6.1%
8.1%
10.2%
12.2%
14.2%
16.3%
18.3%
20.3%
22.4%
24.4%
26.4%
28.5%
30.5%
32.5%
3.1%
6.2%
9.3%
12.3%
15.4%
18.5%
21.6%
24.7%
27.8%
30.9%
33.9%
37.0%
40.1%
43.2%
46.3%
49.4%
52.5%
55.5%
58.6%
61.7%
64.8%
67.9%
71.0%
74.1%
77.1%
80.2%
83.3%
86.4%
89.5%
92.6%
95.7%
98.7%
100.0%[INFO][08:51:51]: Decompressing the dataset downloaded.
[INFO][08:51:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/354.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

34.6%
36.6%
38.6%
40.7%
42.7%
44.7%
46.8%
48.8%
50.8%
52.9%
54.9%
56.9%
59.0%
61.0%
63.0%
65.1%
67.1%
69.1%
71.2%
73.2%
75.2%
77.3%
79.3%
81.3%
83.4%
85.4%
87.4%
89.5%
91.5%
93.5%
95.6%
97.6%
99.6%[INFO][08:51:51]: [Client #354] Dataset size: 150
[INFO][08:51:51]: [Client #354] Sampler: all_inclusive

100.0%[INFO][08:51:51]: Decompressing the dataset downloaded.
[INFO][08:51:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/391.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:51:51]: [Client #354] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:51:51]: [93m[1m[Client #354] Started training in communication round #8.[0m

[INFO][08:51:51]: [Client #391] Dataset size: 155
[INFO][08:51:51]: [Client #391] Sampler: all_inclusive
[INFO][08:51:51]: [Client #391] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:51:51]: [93m[1m[Client #391] Started training in communication round #8.[0m

[INFO][08:51:53]: [Client #354] Loading the dataset.
[INFO][08:51:53]: [Client #391] Loading the dataset.
[INFO][08:51:59]: [Client #354] Epoch: [1/5][0/15]	Loss: 2.862962
[INFO][08:51:59]: [Client #391] Epoch: [1/5][0/16]	Loss: 1.523997
[INFO][08:51:59]: [Client #354] Epoch: [1/5][10/15]	Loss: 1.651324
[INFO][08:51:59]: [Client #391] Epoch: [1/5][10/16]	Loss: 1.440151
[INFO][08:51:59]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][08:51:59]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][08:51:59]: [Client #391] Woke up.
[INFO][08:51:59]: [Client #391] Epoch: [2/5][0/16]	Loss: 1.231887
[INFO][08:51:59]: [Client #354] Woke up.
[INFO][08:51:59]: [Client #354] Epoch: [2/5][0/15]	Loss: 1.639041
[INFO][08:51:59]: [Client #391] Epoch: [2/5][10/16]	Loss: 1.386594
[INFO][08:51:59]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][08:51:59]: [Client #354] Epoch: [2/5][10/15]	Loss: 1.661314
[INFO][08:51:59]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][08:52:00]: [Client #391] Woke up.
[INFO][08:52:00]: [Client #391] Epoch: [3/5][0/16]	Loss: 1.284440
[INFO][08:52:00]: [Client #391] Epoch: [3/5][10/16]	Loss: 0.693675
[INFO][08:52:00]: [Client #354] Woke up.
[INFO][08:52:00]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][08:52:00]: [Client #354] Epoch: [3/5][0/15]	Loss: 1.976180
[INFO][08:52:00]: [Client #354] Epoch: [3/5][10/15]	Loss: 2.401398
[INFO][08:52:00]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][08:52:00]: [Client #391] Woke up.
[INFO][08:52:00]: [Client #391] Epoch: [4/5][0/16]	Loss: 1.375002
[INFO][08:52:00]: [Client #391] Epoch: [4/5][10/16]	Loss: 1.799898
[INFO][08:52:00]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][08:52:00]: [Client #354] Woke up.
[INFO][08:52:00]: [Client #354] Epoch: [4/5][0/15]	Loss: 1.823380
[INFO][08:52:00]: [Client #354] Epoch: [4/5][10/15]	Loss: 1.591441
[INFO][08:52:00]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][08:52:00]: [Client #391] Woke up.
[INFO][08:52:00]: [Client #391] Epoch: [5/5][0/16]	Loss: 1.481590
[INFO][08:52:00]: [Client #391] Epoch: [5/5][10/16]	Loss: 1.501377
[INFO][08:52:01]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][08:52:01]: [Client #354] Woke up.
[INFO][08:52:01]: [Client #354] Epoch: [5/5][0/15]	Loss: 1.578061
[INFO][08:52:01]: [Client #354] Epoch: [5/5][10/15]	Loss: 1.014454
[INFO][08:52:01]: [Client #391] Woke up.
[INFO][08:52:01]: [Client #391] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_554860.pth.
[INFO][08:52:01]: [Client #354] Going to sleep for 0.35 seconds.
[INFO][08:52:01]: [Client #354] Woke up.
[INFO][08:52:01]: [Client #354] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_354_554853.pth.
[INFO][08:52:01]: [Client #391] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_554860.pth.
[INFO][08:52:01]: [Client #391] Model trained.
[INFO][08:52:01]: [Client #391] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:01]: [Server #554754] Received 0.26 MB of payload data from client #391 (simulated).
[INFO][08:52:02]: [Client #354] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_354_554853.pth.
[INFO][08:52:02]: [Client #354] Model trained.
[INFO][08:52:02]: [Client #354] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:02]: [Server #554754] Received 0.26 MB of payload data from client #354 (simulated).
[INFO][08:52:02]: [Server #554754] Selecting client #188 for training.
[INFO][08:52:02]: [Server #554754] Sending the current model to client #188 (simulated).
[INFO][08:52:02]: [Server #554754] Sending 0.26 MB of payload data to client #188 (simulated).
[INFO][08:52:02]: [Server #554754] Selecting client #386 for training.
[INFO][08:52:02]: [Server #554754] Sending the current model to client #386 (simulated).
[INFO][08:52:02]: [Server #554754] Sending 0.26 MB of payload data to client #386 (simulated).
[INFO][08:52:02]: [Client #188] Selected by the server.
[INFO][08:52:02]: [Client #188] Loading its data source...
[INFO][08:52:02]: Data source: FEMNIST
[INFO][08:52:02]: [Client #386] Selected by the server.
[INFO][08:52:02]: [Client #386] Loading its data source...
[INFO][08:52:02]: Data source: FEMNIST
[INFO][08:52:02]: [Client #386] Dataset size: 147
[INFO][08:52:02]: [Client #386] Sampler: all_inclusive
[INFO][08:52:02]: [Client #386] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:02]: [93m[1m[Client #386] Started training in communication round #8.[0m
[INFO][08:52:02]: [Client #188] Dataset size: 164
[INFO][08:52:02]: [Client #188] Sampler: all_inclusive
[INFO][08:52:02]: [Client #188] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:02]: [93m[1m[Client #188] Started training in communication round #8.[0m
[INFO][08:52:04]: [Client #386] Loading the dataset.
[INFO][08:52:04]: [Client #188] Loading the dataset.
[INFO][08:52:09]: [Client #386] Epoch: [1/5][0/15]	Loss: 0.626536
[INFO][08:52:09]: [Client #188] Epoch: [1/5][0/17]	Loss: 1.695466
[INFO][08:52:09]: [Client #386] Epoch: [1/5][10/15]	Loss: 1.064060
[INFO][08:52:09]: [Client #188] Epoch: [1/5][10/17]	Loss: 1.304024
[INFO][08:52:09]: [Client #386] Going to sleep for 0.36 seconds.
[INFO][08:52:09]: [Client #188] Going to sleep for 1.77 seconds.
[INFO][08:52:10]: [Client #386] Woke up.
[INFO][08:52:10]: [Client #386] Epoch: [2/5][0/15]	Loss: 1.460800
[INFO][08:52:10]: [Client #386] Epoch: [2/5][10/15]	Loss: 1.676604
[INFO][08:52:10]: [Client #386] Going to sleep for 0.36 seconds.
[INFO][08:52:10]: [Client #386] Woke up.
[INFO][08:52:10]: [Client #386] Epoch: [3/5][0/15]	Loss: 1.304265
[INFO][08:52:10]: [Client #386] Epoch: [3/5][10/15]	Loss: 1.660250
[INFO][08:52:10]: [Client #386] Going to sleep for 0.36 seconds.
[INFO][08:52:11]: [Client #386] Woke up.
[INFO][08:52:11]: [Client #386] Epoch: [4/5][0/15]	Loss: 1.533115
[INFO][08:52:11]: [Client #386] Epoch: [4/5][10/15]	Loss: 0.524403
[INFO][08:52:11]: [Client #386] Going to sleep for 0.36 seconds.
[INFO][08:52:11]: [Client #188] Woke up.
[INFO][08:52:11]: [Client #188] Epoch: [2/5][0/17]	Loss: 2.243002
[INFO][08:52:11]: [Client #386] Woke up.
[INFO][08:52:11]: [Client #386] Epoch: [5/5][0/15]	Loss: 2.225020
[INFO][08:52:11]: [Client #188] Epoch: [2/5][10/17]	Loss: 1.321708
[INFO][08:52:11]: [Client #188] Going to sleep for 1.77 seconds.
[INFO][08:52:11]: [Client #386] Epoch: [5/5][10/15]	Loss: 1.958765
[INFO][08:52:11]: [Client #386] Going to sleep for 0.36 seconds.
[INFO][08:52:12]: [Client #386] Woke up.
[INFO][08:52:12]: [Client #386] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_386_554860.pth.
[INFO][08:52:12]: [Client #386] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_386_554860.pth.
[INFO][08:52:12]: [Client #386] Model trained.
[INFO][08:52:12]: [Client #386] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:12]: [Server #554754] Received 0.26 MB of payload data from client #386 (simulated).
[INFO][08:52:13]: [Client #188] Woke up.
[INFO][08:52:13]: [Client #188] Epoch: [3/5][0/17]	Loss: 0.754428
[INFO][08:52:13]: [Client #188] Epoch: [3/5][10/17]	Loss: 2.010115
[INFO][08:52:13]: [Client #188] Going to sleep for 1.77 seconds.
[INFO][08:52:15]: [Client #188] Woke up.
[INFO][08:52:15]: [Client #188] Epoch: [4/5][0/17]	Loss: 1.788722
[INFO][08:52:15]: [Client #188] Epoch: [4/5][10/17]	Loss: 1.334653
[INFO][08:52:15]: [Client #188] Going to sleep for 1.77 seconds.
[INFO][08:52:17]: [Client #188] Woke up.
[INFO][08:52:17]: [Client #188] Epoch: [5/5][0/17]	Loss: 1.913851
[INFO][08:52:17]: [Client #188] Epoch: [5/5][10/17]	Loss: 2.434698
[INFO][08:52:17]: [Client #188] Going to sleep for 1.77 seconds.
[INFO][08:52:19]: [Client #188] Woke up.
[INFO][08:52:19]: [Client #188] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_188_554853.pth.
[INFO][08:52:20]: [Client #188] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_188_554853.pth.
[INFO][08:52:20]: [Client #188] Model trained.
[INFO][08:52:20]: [Client #188] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:20]: [Server #554754] Received 0.26 MB of payload data from client #188 (simulated).
[INFO][08:52:20]: [Server #554754] Selecting client #376 for training.
[INFO][08:52:20]: [Server #554754] Sending the current model to client #376 (simulated).
[INFO][08:52:20]: [Server #554754] Sending 0.26 MB of payload data to client #376 (simulated).
[INFO][08:52:20]: [Server #554754] Selecting client #307 for training.
[INFO][08:52:20]: [Server #554754] Sending the current model to client #307 (simulated).
[INFO][08:52:20]: [Server #554754] Sending 0.26 MB of payload data to client #307 (simulated).
[INFO][08:52:20]: [Client #376] Selected by the server.
[INFO][08:52:20]: [Client #376] Loading its data source...
[INFO][08:52:20]: Data source: FEMNIST
[INFO][08:52:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:52:20]: [Client #307] Selected by the server.
[INFO][08:52:20]: [Client #307] Loading its data source...
[INFO][08:52:20]: Data source: FEMNIST
[INFO][08:52:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/376.zip.
[INFO][08:52:20]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:52:20]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/307.zip.

3.5%
7.1%
10.6%
14.1%
17.7%
21.2%
24.7%
28.3%
31.8%
35.3%
38.9%
42.4%
45.9%
49.5%
53.0%
56.5%
60.1%
2.7%
63.6%
67.1%
70.7%
74.2%
77.7%
81.3%
84.8%
88.3%
91.9%
95.4%
98.9%
100.0%[INFO][08:52:20]: Decompressing the dataset downloaded.
[INFO][08:52:20]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/307.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

5.4%
8.0%
10.7%
13.4%
16.1%
18.7%
21.4%
24.1%
26.8%
29.4%
32.1%
34.8%
37.5%
40.1%
42.8%
45.5%
48.2%
50.8%
53.5%
56.2%
58.9%
61.6%
64.2%
66.9%
69.6%
72.3%
74.9%
77.6%
80.3%
83.0%
85.6%
88.3%
91.0%
93.7%
96.3%
99.0%
100.0%[INFO][08:52:20]: Decompressing the dataset downloaded.
[INFO][08:52:20]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/376.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:52:20]: [Client #307] Dataset size: 162
[INFO][08:52:20]: [Client #307] Sampler: all_inclusive
[INFO][08:52:20]: [Client #307] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:20]: [93m[1m[Client #307] Started training in communication round #8.[0m

[INFO][08:52:20]: [Client #376] Dataset size: 151
[INFO][08:52:20]: [Client #376] Sampler: all_inclusive
[INFO][08:52:20]: [Client #376] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:20]: [93m[1m[Client #376] Started training in communication round #8.[0m

[INFO][08:52:22]: [Client #376] Loading the dataset.
[INFO][08:52:22]: [Client #307] Loading the dataset.
[INFO][08:52:27]: [Client #376] Epoch: [1/5][0/16]	Loss: 2.955436
[INFO][08:52:27]: [Client #307] Epoch: [1/5][0/17]	Loss: 3.054540
[INFO][08:52:27]: [Client #376] Epoch: [1/5][10/16]	Loss: 1.894383
[INFO][08:52:27]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][08:52:27]: [Client #307] Epoch: [1/5][10/17]	Loss: 2.010509
[INFO][08:52:27]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:52:28]: [Client #376] Woke up.
[INFO][08:52:28]: [Client #376] Epoch: [2/5][0/16]	Loss: 1.998889
[INFO][08:52:28]: [Client #307] Woke up.
[INFO][08:52:28]: [Client #307] Epoch: [2/5][0/17]	Loss: 3.706182
[INFO][08:52:28]: [Client #376] Epoch: [2/5][10/16]	Loss: 2.120343
[INFO][08:52:28]: [Client #307] Epoch: [2/5][10/17]	Loss: 2.799975
[INFO][08:52:28]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][08:52:28]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:52:29]: [Client #307] Woke up.
[INFO][08:52:29]: [Client #307] Epoch: [3/5][0/17]	Loss: 3.091593
[INFO][08:52:29]: [Client #376] Woke up.
[INFO][08:52:29]: [Client #376] Epoch: [3/5][0/16]	Loss: 2.323223
[INFO][08:52:29]: [Client #307] Epoch: [3/5][10/17]	Loss: 1.266713
[INFO][08:52:29]: [Client #376] Epoch: [3/5][10/16]	Loss: 2.148041
[INFO][08:52:29]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:52:29]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][08:52:29]: [Client #307] Woke up.
[INFO][08:52:29]: [Client #307] Epoch: [4/5][0/17]	Loss: 2.152160
[INFO][08:52:29]: [Client #376] Woke up.
[INFO][08:52:29]: [Client #376] Epoch: [4/5][0/16]	Loss: 1.203698
[INFO][08:52:29]: [Client #307] Epoch: [4/5][10/17]	Loss: 1.930045
[INFO][08:52:30]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:52:30]: [Client #376] Epoch: [4/5][10/16]	Loss: 1.542915
[INFO][08:52:30]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][08:52:30]: [Client #307] Woke up.
[INFO][08:52:30]: [Client #307] Epoch: [5/5][0/17]	Loss: 2.509259
[INFO][08:52:30]: [Client #307] Epoch: [5/5][10/17]	Loss: 2.720451
[INFO][08:52:30]: [Client #376] Woke up.
[INFO][08:52:30]: [Client #376] Epoch: [5/5][0/16]	Loss: 1.304389
[INFO][08:52:30]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:52:30]: [Client #376] Epoch: [5/5][10/16]	Loss: 1.441630
[INFO][08:52:30]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][08:52:31]: [Client #307] Woke up.
[INFO][08:52:31]: [Client #307] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_554860.pth.
[INFO][08:52:31]: [Client #376] Woke up.
[INFO][08:52:31]: [Client #376] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_376_554853.pth.
[INFO][08:52:31]: [Client #307] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_554860.pth.
[INFO][08:52:31]: [Client #307] Model trained.
[INFO][08:52:31]: [Client #307] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:31]: [Server #554754] Received 0.26 MB of payload data from client #307 (simulated).
[INFO][08:52:32]: [Client #376] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_376_554853.pth.
[INFO][08:52:32]: [Client #376] Model trained.
[INFO][08:52:32]: [Client #376] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:52:32]: [Server #554754] Received 0.26 MB of payload data from client #376 (simulated).
[INFO][08:52:32]: [Server #554754] Selecting client #201 for training.
[INFO][08:52:32]: [Server #554754] Sending the current model to client #201 (simulated).
[INFO][08:52:32]: [Server #554754] Sending 0.26 MB of payload data to client #201 (simulated).
[INFO][08:52:32]: [Server #554754] Selecting client #349 for training.
[INFO][08:52:32]: [Server #554754] Sending the current model to client #349 (simulated).
[INFO][08:52:32]: [Server #554754] Sending 0.26 MB of payload data to client #349 (simulated).
[INFO][08:52:32]: [Client #201] Selected by the server.
[INFO][08:52:32]: [Client #201] Loading its data source...
[INFO][08:52:32]: Data source: FEMNIST
[INFO][08:52:32]: [Client #349] Selected by the server.
[INFO][08:52:32]: [Client #349] Loading its data source...
[INFO][08:52:32]: Data source: FEMNIST
[INFO][08:52:32]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:52:32]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/349.zip.
[INFO][08:52:32]: [Client #201] Dataset size: 154
[INFO][08:52:32]: [Client #201] Sampler: all_inclusive
[INFO][08:52:32]: [Client #201] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:32]: [93m[1m[Client #201] Started training in communication round #8.[0m

2.4%
4.7%
7.1%
9.4%
11.8%
14.1%
16.5%
18.9%
21.2%
23.6%
25.9%
28.3%
30.7%
33.0%
35.4%
37.7%
40.1%
42.4%
44.8%
47.2%
49.5%
51.9%
54.2%
56.6%
58.9%
61.3%
63.7%
66.0%
68.4%
70.7%
73.1%
75.4%
77.8%
80.2%
82.5%
84.9%
87.2%
89.6%
92.0%
94.3%
96.7%
99.0%
100.0%[INFO][08:52:32]: Decompressing the dataset downloaded.
[INFO][08:52:32]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/349.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:52:32]: [Client #349] Dataset size: 162
[INFO][08:52:32]: [Client #349] Sampler: all_inclusive
[INFO][08:52:32]: [Client #349] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:52:32]: [93m[1m[Client #349] Started training in communication round #8.[0m

[INFO][08:52:34]: [Client #201] Loading the dataset.
[INFO][08:52:34]: [Client #349] Loading the dataset.
[INFO][08:52:39]: [Client #201] Epoch: [1/5][0/16]	Loss: 1.718943
[INFO][08:52:39]: [Client #349] Epoch: [1/5][0/17]	Loss: 1.514101
[INFO][08:52:39]: [Client #201] Epoch: [1/5][10/16]	Loss: 1.473583
[INFO][08:52:39]: [Client #349] Epoch: [1/5][10/17]	Loss: 0.952995
[INFO][08:52:39]: [Client #201] Going to sleep for 19.07 seconds.
[INFO][08:52:39]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][08:52:43]: [Client #349] Woke up.
[INFO][08:52:43]: [Client #349] Epoch: [2/5][0/17]	Loss: 0.647497
[INFO][08:52:43]: [Client #349] Epoch: [2/5][10/17]	Loss: 0.481244
[INFO][08:52:43]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][08:52:47]: [Client #349] Woke up.
[INFO][08:52:47]: [Client #349] Epoch: [3/5][0/17]	Loss: 1.643776
[INFO][08:52:47]: [Client #349] Epoch: [3/5][10/17]	Loss: 1.788801
[INFO][08:52:47]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][08:52:51]: [Client #349] Woke up.
[INFO][08:52:51]: [Client #349] Epoch: [4/5][0/17]	Loss: 1.608937
[INFO][08:52:52]: [Client #349] Epoch: [4/5][10/17]	Loss: 1.198530
[INFO][08:52:52]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][08:52:56]: [Client #349] Woke up.
[INFO][08:52:56]: [Client #349] Epoch: [5/5][0/17]	Loss: 1.485971
[INFO][08:52:56]: [Client #349] Epoch: [5/5][10/17]	Loss: 0.691545
[INFO][08:52:56]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][08:52:58]: [Client #201] Woke up.
[INFO][08:52:58]: [Client #201] Epoch: [2/5][0/16]	Loss: 1.335317
[INFO][08:52:58]: [Client #201] Epoch: [2/5][10/16]	Loss: 1.580410
[INFO][08:52:58]: [Client #201] Going to sleep for 19.07 seconds.
[INFO][08:53:00]: [Client #349] Woke up.
[INFO][08:53:00]: [Client #349] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][08:53:00]: [Client #349] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][08:53:00]: [Client #349] Model trained.
[INFO][08:53:00]: [Client #349] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:53:00]: [Server #554754] Received 0.26 MB of payload data from client #349 (simulated).
[INFO][08:53:17]: [Client #201] Woke up.
[INFO][08:53:18]: [Client #201] Epoch: [3/5][0/16]	Loss: 2.373399
[INFO][08:53:18]: [Client #201] Epoch: [3/5][10/16]	Loss: 1.883243
[INFO][08:53:18]: [Client #201] Going to sleep for 19.07 seconds.
[INFO][08:53:37]: [Client #201] Woke up.
[INFO][08:53:37]: [Client #201] Epoch: [4/5][0/16]	Loss: 1.321635
[INFO][08:53:37]: [Client #201] Epoch: [4/5][10/16]	Loss: 0.772405
[INFO][08:53:37]: [Client #201] Going to sleep for 19.07 seconds.
[INFO][08:53:56]: [Client #201] Woke up.
[INFO][08:53:56]: [Client #201] Epoch: [5/5][0/16]	Loss: 1.029738
[INFO][08:53:56]: [Client #201] Epoch: [5/5][10/16]	Loss: 1.151641
[INFO][08:53:56]: [Client #201] Going to sleep for 19.07 seconds.
[INFO][08:54:15]: [Client #201] Woke up.
[INFO][08:54:16]: [Client #201] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_201_554853.pth.
[INFO][08:54:16]: [Client #201] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_201_554853.pth.
[INFO][08:54:16]: [Client #201] Model trained.
[INFO][08:54:16]: [Client #201] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:54:16]: [Server #554754] Received 0.26 MB of payload data from client #201 (simulated).
[INFO][08:54:16]: [Server #554754] Selecting client #388 for training.
[INFO][08:54:16]: [Server #554754] Sending the current model to client #388 (simulated).
[INFO][08:54:16]: [Server #554754] Sending 0.26 MB of payload data to client #388 (simulated).
[INFO][08:54:16]: [Server #554754] Selecting client #449 for training.
[INFO][08:54:16]: [Server #554754] Sending the current model to client #449 (simulated).
[INFO][08:54:16]: [Server #554754] Sending 0.26 MB of payload data to client #449 (simulated).
[INFO][08:54:16]: [Client #388] Selected by the server.
[INFO][08:54:16]: [Client #388] Loading its data source...
[INFO][08:54:16]: Data source: FEMNIST
[INFO][08:54:16]: [Client #449] Selected by the server.
[INFO][08:54:16]: [Client #449] Loading its data source...
[INFO][08:54:16]: Data source: FEMNIST
[INFO][08:54:16]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:54:16]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:54:16]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/388.zip.
[INFO][08:54:16]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/449.zip.

2.9%
2.0%
4.1%
6.1%
8.1%
10.2%
12.2%
14.2%
16.3%
18.3%
20.3%
22.4%
24.4%
26.4%
28.5%
30.5%
32.5%
5.7%
8.6%
11.5%
14.3%
17.2%
20.1%
22.9%
25.8%
28.7%
31.5%
34.4%
37.3%
40.1%
43.0%
45.9%
48.8%
51.6%
54.5%
57.4%
60.2%
63.1%
66.0%
68.8%
71.7%
74.6%
77.4%
80.3%
83.2%
86.0%
88.9%
91.8%
94.6%
97.5%
100.0%[INFO][08:54:16]: Decompressing the dataset downloaded.
[INFO][08:54:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/449.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

34.5%
36.6%
38.6%
40.6%
42.7%
44.7%
46.7%
48.8%
50.8%
52.8%
54.9%
56.9%
58.9%
61.0%
63.0%
65.0%
67.1%[INFO][08:54:16]: [Client #449] Dataset size: 162
[INFO][08:54:16]: [Client #449] Sampler: all_inclusive
[INFO][08:54:16]: [Client #449] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:54:16]: [93m[1m[Client #449] Started training in communication round #8.[0m


69.1%
71.1%
73.2%
75.2%
77.2%
79.3%
81.3%
83.3%
85.4%
87.4%
89.4%
91.5%
93.5%
95.5%
97.6%
99.6%
100.0%[INFO][08:54:16]: Decompressing the dataset downloaded.
[INFO][08:54:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/388.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:54:17]: [Client #388] Dataset size: 163
[INFO][08:54:17]: [Client #388] Sampler: all_inclusive
[INFO][08:54:17]: [Client #388] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:54:17]: [93m[1m[Client #388] Started training in communication round #8.[0m

[INFO][08:54:18]: [Client #449] Loading the dataset.
[INFO][08:54:18]: [Client #388] Loading the dataset.
[INFO][08:54:24]: [Client #449] Epoch: [1/5][0/17]	Loss: 1.729708
[INFO][08:54:24]: [Client #388] Epoch: [1/5][0/17]	Loss: 1.934554
[INFO][08:54:24]: [Client #449] Epoch: [1/5][10/17]	Loss: 1.614218
[INFO][08:54:24]: [Client #388] Epoch: [1/5][10/17]	Loss: 2.595000
[INFO][08:54:24]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][08:54:24]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][08:54:24]: [Client #449] Woke up.
[INFO][08:54:24]: [Client #449] Epoch: [2/5][0/17]	Loss: 1.756393
[INFO][08:54:24]: [Client #449] Epoch: [2/5][10/17]	Loss: 1.764806
[INFO][08:54:24]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][08:54:24]: [Client #449] Woke up.
[INFO][08:54:25]: [Client #449] Epoch: [3/5][0/17]	Loss: 2.503789
[INFO][08:54:25]: [Client #449] Epoch: [3/5][10/17]	Loss: 2.069647
[INFO][08:54:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][08:54:25]: [Client #449] Woke up.
[INFO][08:54:25]: [Client #449] Epoch: [4/5][0/17]	Loss: 0.873703
[INFO][08:54:25]: [Client #388] Woke up.
[INFO][08:54:25]: [Client #449] Epoch: [4/5][10/17]	Loss: 2.563830
[INFO][08:54:25]: [Client #388] Epoch: [2/5][0/17]	Loss: 0.872082
[INFO][08:54:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][08:54:25]: [Client #388] Epoch: [2/5][10/17]	Loss: 1.646092
[INFO][08:54:25]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][08:54:25]: [Client #449] Woke up.
[INFO][08:54:25]: [Client #449] Epoch: [5/5][0/17]	Loss: 1.852843
[INFO][08:54:25]: [Client #449] Epoch: [5/5][10/17]	Loss: 1.731823
[INFO][08:54:25]: [Client #449] Going to sleep for 0.17 seconds.
[INFO][08:54:25]: [Client #449] Woke up.
[INFO][08:54:25]: [Client #449] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_449_554860.pth.
[INFO][08:54:26]: [Client #388] Woke up.
[INFO][08:54:26]: [Client #388] Epoch: [3/5][0/17]	Loss: 0.839496
[INFO][08:54:26]: [Client #388] Epoch: [3/5][10/17]	Loss: 1.361125
[INFO][08:54:26]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][08:54:26]: [Client #449] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_449_554860.pth.
[INFO][08:54:26]: [Client #449] Model trained.
[INFO][08:54:26]: [Client #449] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:54:26]: [Server #554754] Received 0.26 MB of payload data from client #449 (simulated).
[INFO][08:54:27]: [Client #388] Woke up.
[INFO][08:54:27]: [Client #388] Epoch: [4/5][0/17]	Loss: 2.767542
[INFO][08:54:27]: [Client #388] Epoch: [4/5][10/17]	Loss: 2.765780
[INFO][08:54:27]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][08:54:28]: [Client #388] Woke up.
[INFO][08:54:28]: [Client #388] Epoch: [5/5][0/17]	Loss: 1.240022
[INFO][08:54:28]: [Client #388] Epoch: [5/5][10/17]	Loss: 0.549252
[INFO][08:54:28]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][08:54:29]: [Client #388] Woke up.
[INFO][08:54:29]: [Client #388] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_388_554853.pth.
[INFO][08:54:30]: [Client #388] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_388_554853.pth.
[INFO][08:54:30]: [Client #388] Model trained.
[INFO][08:54:30]: [Client #388] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:54:30]: [Server #554754] Received 0.26 MB of payload data from client #388 (simulated).
[INFO][08:54:30]: [Server #554754] Adding client #449 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #380 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #391 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #494 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #354 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #468 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #386 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #307 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #376 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Adding client #388 to the list of clients for aggregation.
[INFO][08:54:30]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19680183 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13056851
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.26597186 0.         0.
 0.         0.07474573 0.         0.         0.         0.
 0.         0.08699943 0.         0.1254219  0.         0.
 0.07718139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10149393 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.103429
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.3246179  0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.19680183 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13056851
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.26597186 0.         0.
 0.         0.07474573 0.         0.         0.         0.
 0.         0.08699943 0.         0.1254219  0.         0.
 0.07718139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10149393 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.103429
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.3246179  0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:55:13]: [Server #554754] Global model accuracy: 41.14%

[INFO][08:55:13]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_8.pth.
[INFO][08:55:13]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_8.pth.
[INFO][08:55:13]: [93m[1m
[Server #554754] Starting round 9/100.[0m
[0.002      0.002      0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.002      0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.002      0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.002      0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.08876404 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04920213 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.08314607 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.002
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.08820225 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.10384615 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.05385638 0.002      0.002      0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.002      0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.05019947 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.05111821 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.10384615 0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.05418883 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][08:55:14]: [Server #554754] Selected clients: [119  61 109 151 443 272 143  69 145 307]
[INFO][08:55:14]: [Server #554754] Selecting client #119 for training.
[INFO][08:55:14]: [Server #554754] Sending the current model to client #119 (simulated).
[INFO][08:55:14]: [Server #554754] Sending 0.26 MB of payload data to client #119 (simulated).
[INFO][08:55:14]: [Server #554754] Selecting client #61 for training.
[INFO][08:55:14]: [Server #554754] Sending the current model to client #61 (simulated).
[INFO][08:55:14]: [Server #554754] Sending 0.26 MB of payload data to client #61 (simulated).
[INFO][08:55:14]: [Client #119] Selected by the server.
[INFO][08:55:14]: [Client #119] Loading its data source...
[INFO][08:55:14]: Data source: FEMNIST
[INFO][08:55:14]: [Client #61] Selected by the server.
[INFO][08:55:14]: [Client #61] Loading its data source...
[INFO][08:55:14]: Data source: FEMNIST
[INFO][08:55:14]: [Client #61] Dataset size: 153
[INFO][08:55:14]: [Client #61] Sampler: all_inclusive
[INFO][08:55:14]: [Client #61] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:14]: [93m[1m[Client #61] Started training in communication round #9.[0m
[INFO][08:55:14]: [Client #119] Dataset size: 162
[INFO][08:55:14]: [Client #119] Sampler: all_inclusive
[INFO][08:55:14]: [Client #119] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:14]: [93m[1m[Client #119] Started training in communication round #9.[0m
[INFO][08:55:16]: [Client #61] Loading the dataset.
[INFO][08:55:16]: [Client #119] Loading the dataset.
[INFO][08:55:21]: [Client #61] Epoch: [1/5][0/16]	Loss: 1.918442
[INFO][08:55:21]: [Client #119] Epoch: [1/5][0/17]	Loss: 0.961221
[INFO][08:55:21]: [Client #61] Epoch: [1/5][10/16]	Loss: 2.633980
[INFO][08:55:21]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][08:55:21]: [Client #119] Epoch: [1/5][10/17]	Loss: 1.887576
[INFO][08:55:21]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][08:55:21]: [Client #61] Woke up.
[INFO][08:55:21]: [Client #61] Epoch: [2/5][0/16]	Loss: 1.402040
[INFO][08:55:22]: [Client #61] Epoch: [2/5][10/16]	Loss: 1.836717
[INFO][08:55:22]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][08:55:22]: [Client #61] Woke up.
[INFO][08:55:22]: [Client #61] Epoch: [3/5][0/16]	Loss: 2.302766
[INFO][08:55:22]: [Client #61] Epoch: [3/5][10/16]	Loss: 1.151170
[INFO][08:55:22]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][08:55:22]: [Client #61] Woke up.
[INFO][08:55:22]: [Client #61] Epoch: [4/5][0/16]	Loss: 2.382524
[INFO][08:55:22]: [Client #61] Epoch: [4/5][10/16]	Loss: 2.272655
[INFO][08:55:22]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][08:55:22]: [Client #61] Woke up.
[INFO][08:55:22]: [Client #61] Epoch: [5/5][0/16]	Loss: 1.000615
[INFO][08:55:22]: [Client #61] Epoch: [5/5][10/16]	Loss: 1.403419
[INFO][08:55:22]: [Client #61] Going to sleep for 0.11 seconds.
[INFO][08:55:22]: [Client #61] Woke up.
[INFO][08:55:22]: [Client #61] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_61_554860.pth.
[INFO][08:55:23]: [Client #61] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_61_554860.pth.
[INFO][08:55:23]: [Client #61] Model trained.
[INFO][08:55:23]: [Client #61] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:55:23]: [Server #554754] Received 0.26 MB of payload data from client #61 (simulated).
[INFO][08:55:24]: [Client #119] Woke up.
[INFO][08:55:24]: [Client #119] Epoch: [2/5][0/17]	Loss: 0.626878
[INFO][08:55:24]: [Client #119] Epoch: [2/5][10/17]	Loss: 1.434165
[INFO][08:55:24]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][08:55:27]: [Client #119] Woke up.
[INFO][08:55:27]: [Client #119] Epoch: [3/5][0/17]	Loss: 0.739715
[INFO][08:55:27]: [Client #119] Epoch: [3/5][10/17]	Loss: 0.874779
[INFO][08:55:27]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][08:55:29]: [Client #119] Woke up.
[INFO][08:55:29]: [Client #119] Epoch: [4/5][0/17]	Loss: 1.648032
[INFO][08:55:29]: [Client #119] Epoch: [4/5][10/17]	Loss: 1.300034
[INFO][08:55:29]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][08:55:32]: [Client #119] Woke up.
[INFO][08:55:32]: [Client #119] Epoch: [5/5][0/17]	Loss: 0.621272
[INFO][08:55:32]: [Client #119] Epoch: [5/5][10/17]	Loss: 1.792875
[INFO][08:55:32]: [Client #119] Going to sleep for 2.47 seconds.
[INFO][08:55:34]: [Client #119] Woke up.
[INFO][08:55:34]: [Client #119] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_119_554853.pth.
[INFO][08:55:35]: [Client #119] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_119_554853.pth.
[INFO][08:55:35]: [Client #119] Model trained.
[INFO][08:55:35]: [Client #119] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:55:35]: [Server #554754] Received 0.26 MB of payload data from client #119 (simulated).
[INFO][08:55:35]: [Server #554754] Selecting client #109 for training.
[INFO][08:55:35]: [Server #554754] Sending the current model to client #109 (simulated).
[INFO][08:55:35]: [Server #554754] Sending 0.26 MB of payload data to client #109 (simulated).
[INFO][08:55:35]: [Server #554754] Selecting client #151 for training.
[INFO][08:55:35]: [Server #554754] Sending the current model to client #151 (simulated).
[INFO][08:55:35]: [Server #554754] Sending 0.26 MB of payload data to client #151 (simulated).
[INFO][08:55:35]: [Client #109] Selected by the server.
[INFO][08:55:35]: [Client #109] Loading its data source...
[INFO][08:55:35]: Data source: FEMNIST
[INFO][08:55:35]: [Client #151] Selected by the server.
[INFO][08:55:35]: [Client #151] Loading its data source...
[INFO][08:55:35]: Data source: FEMNIST
[INFO][08:55:35]: [Client #109] Dataset size: 163
[INFO][08:55:35]: [Client #109] Sampler: all_inclusive
[INFO][08:55:35]: [Client #109] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:35]: [93m[1m[Client #109] Started training in communication round #9.[0m
[INFO][08:55:35]: [Client #151] Dataset size: 162
[INFO][08:55:35]: [Client #151] Sampler: all_inclusive
[INFO][08:55:35]: [Client #151] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:35]: [93m[1m[Client #151] Started training in communication round #9.[0m
[INFO][08:55:37]: [Client #109] Loading the dataset.
[INFO][08:55:37]: [Client #151] Loading the dataset.
[INFO][08:55:43]: [Client #109] Epoch: [1/5][0/17]	Loss: 0.957268
[INFO][08:55:43]: [Client #151] Epoch: [1/5][0/17]	Loss: 2.136604
[INFO][08:55:43]: [Client #109] Epoch: [1/5][10/17]	Loss: 1.295650
[INFO][08:55:43]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][08:55:43]: [Client #151] Epoch: [1/5][10/17]	Loss: 1.691637
[INFO][08:55:43]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][08:55:43]: [Client #151] Woke up.
[INFO][08:55:43]: [Client #151] Epoch: [2/5][0/17]	Loss: 2.225968
[INFO][08:55:43]: [Client #151] Epoch: [2/5][10/17]	Loss: 1.547030
[INFO][08:55:43]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][08:55:43]: [Client #151] Woke up.
[INFO][08:55:43]: [Client #151] Epoch: [3/5][0/17]	Loss: 1.555252
[INFO][08:55:43]: [Client #151] Epoch: [3/5][10/17]	Loss: 1.995443
[INFO][08:55:43]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][08:55:43]: [Client #151] Woke up.
[INFO][08:55:43]: [Client #151] Epoch: [4/5][0/17]	Loss: 1.305617
[INFO][08:55:43]: [Client #151] Epoch: [4/5][10/17]	Loss: 1.088639
[INFO][08:55:43]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][08:55:44]: [Client #151] Woke up.
[INFO][08:55:44]: [Client #151] Epoch: [5/5][0/17]	Loss: 1.881001
[INFO][08:55:44]: [Client #151] Epoch: [5/5][10/17]	Loss: 1.495651
[INFO][08:55:44]: [Client #151] Going to sleep for 0.08 seconds.
[INFO][08:55:44]: [Client #151] Woke up.
[INFO][08:55:44]: [Client #151] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_554860.pth.
[INFO][08:55:44]: [Client #151] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_151_554860.pth.
[INFO][08:55:44]: [Client #151] Model trained.
[INFO][08:55:44]: [Client #151] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:55:44]: [Server #554754] Received 0.26 MB of payload data from client #151 (simulated).
[INFO][08:55:45]: [Client #109] Woke up.
[INFO][08:55:45]: [Client #109] Epoch: [2/5][0/17]	Loss: 0.658579
[INFO][08:55:45]: [Client #109] Epoch: [2/5][10/17]	Loss: 1.511056
[INFO][08:55:45]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][08:55:47]: [Client #109] Woke up.
[INFO][08:55:47]: [Client #109] Epoch: [3/5][0/17]	Loss: 1.355524
[INFO][08:55:47]: [Client #109] Epoch: [3/5][10/17]	Loss: 1.774838
[INFO][08:55:48]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][08:55:50]: [Client #109] Woke up.
[INFO][08:55:50]: [Client #109] Epoch: [4/5][0/17]	Loss: 1.234735
[INFO][08:55:50]: [Client #109] Epoch: [4/5][10/17]	Loss: 1.408329
[INFO][08:55:50]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][08:55:52]: [Client #109] Woke up.
[INFO][08:55:52]: [Client #109] Epoch: [5/5][0/17]	Loss: 1.667891
[INFO][08:55:52]: [Client #109] Epoch: [5/5][10/17]	Loss: 1.950390
[INFO][08:55:52]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][08:55:55]: [Client #109] Woke up.
[INFO][08:55:55]: [Client #109] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554853.pth.
[INFO][08:55:55]: [Client #109] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554853.pth.
[INFO][08:55:55]: [Client #109] Model trained.
[INFO][08:55:55]: [Client #109] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:55:55]: [Server #554754] Received 0.26 MB of payload data from client #109 (simulated).
[INFO][08:55:55]: [Server #554754] Selecting client #443 for training.
[INFO][08:55:55]: [Server #554754] Sending the current model to client #443 (simulated).
[INFO][08:55:55]: [Server #554754] Sending 0.26 MB of payload data to client #443 (simulated).
[INFO][08:55:55]: [Server #554754] Selecting client #272 for training.
[INFO][08:55:55]: [Server #554754] Sending the current model to client #272 (simulated).
[INFO][08:55:55]: [Server #554754] Sending 0.26 MB of payload data to client #272 (simulated).
[INFO][08:55:55]: [Client #443] Selected by the server.
[INFO][08:55:55]: [Client #443] Loading its data source...
[INFO][08:55:55]: Data source: FEMNIST
[INFO][08:55:55]: [Client #272] Selected by the server.
[INFO][08:55:55]: [Client #272] Loading its data source...
[INFO][08:55:55]: Data source: FEMNIST
[INFO][08:55:55]: [Client #443] Dataset size: 164
[INFO][08:55:55]: [Client #443] Sampler: all_inclusive
[INFO][08:55:55]: [Client #443] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:55]: [93m[1m[Client #443] Started training in communication round #9.[0m
[INFO][08:55:55]: [Client #272] Dataset size: 145
[INFO][08:55:55]: [Client #272] Sampler: all_inclusive
[INFO][08:55:55]: [Client #272] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:55:55]: [93m[1m[Client #272] Started training in communication round #9.[0m
[INFO][08:55:57]: [Client #443] Loading the dataset.
[INFO][08:55:57]: [Client #272] Loading the dataset.
[INFO][08:56:03]: [Client #272] Epoch: [1/5][0/15]	Loss: 2.495809
[INFO][08:56:03]: [Client #443] Epoch: [1/5][0/17]	Loss: 1.496755
[INFO][08:56:03]: [Client #272] Epoch: [1/5][10/15]	Loss: 0.924928
[INFO][08:56:03]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][08:56:03]: [Client #443] Epoch: [1/5][10/17]	Loss: 1.804393
[INFO][08:56:03]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][08:56:03]: [Client #272] Woke up.
[INFO][08:56:03]: [Client #272] Epoch: [2/5][0/15]	Loss: 1.054949
[INFO][08:56:03]: [Client #272] Epoch: [2/5][10/15]	Loss: 1.674125
[INFO][08:56:03]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][08:56:04]: [Client #272] Woke up.
[INFO][08:56:04]: [Client #272] Epoch: [3/5][0/15]	Loss: 0.793702
[INFO][08:56:04]: [Client #272] Epoch: [3/5][10/15]	Loss: 1.142297
[INFO][08:56:04]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][08:56:04]: [Client #443] Woke up.
[INFO][08:56:04]: [Client #443] Epoch: [2/5][0/17]	Loss: 1.702103
[INFO][08:56:04]: [Client #443] Epoch: [2/5][10/17]	Loss: 0.337312
[INFO][08:56:04]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][08:56:04]: [Client #272] Woke up.
[INFO][08:56:04]: [Client #272] Epoch: [4/5][0/15]	Loss: 0.764900
[INFO][08:56:05]: [Client #272] Epoch: [4/5][10/15]	Loss: 1.932842
[INFO][08:56:05]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][08:56:05]: [Client #272] Woke up.
[INFO][08:56:05]: [Client #272] Epoch: [5/5][0/15]	Loss: 2.577745
[INFO][08:56:05]: [Client #272] Epoch: [5/5][10/15]	Loss: 1.680518
[INFO][08:56:05]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][08:56:05]: [Client #443] Woke up.
[INFO][08:56:05]: [Client #443] Epoch: [3/5][0/17]	Loss: 2.016933
[INFO][08:56:05]: [Client #443] Epoch: [3/5][10/17]	Loss: 1.683055
[INFO][08:56:06]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][08:56:06]: [Client #272] Woke up.
[INFO][08:56:06]: [Client #272] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_272_554860.pth.
[INFO][08:56:06]: [Client #272] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_272_554860.pth.
[INFO][08:56:06]: [Client #272] Model trained.
[INFO][08:56:06]: [Client #272] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:56:06]: [Server #554754] Received 0.26 MB of payload data from client #272 (simulated).
[INFO][08:56:07]: [Client #443] Woke up.
[INFO][08:56:07]: [Client #443] Epoch: [4/5][0/17]	Loss: 3.106701
[INFO][08:56:07]: [Client #443] Epoch: [4/5][10/17]	Loss: 1.404513
[INFO][08:56:07]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][08:56:08]: [Client #443] Woke up.
[INFO][08:56:08]: [Client #443] Epoch: [5/5][0/17]	Loss: 2.272854
[INFO][08:56:08]: [Client #443] Epoch: [5/5][10/17]	Loss: 0.341764
[INFO][08:56:08]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][08:56:09]: [Client #443] Woke up.
[INFO][08:56:09]: [Client #443] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554853.pth.
[INFO][08:56:10]: [Client #443] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554853.pth.
[INFO][08:56:10]: [Client #443] Model trained.
[INFO][08:56:10]: [Client #443] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:56:10]: [Server #554754] Received 0.26 MB of payload data from client #443 (simulated).
[INFO][08:56:10]: [Server #554754] Selecting client #143 for training.
[INFO][08:56:10]: [Server #554754] Sending the current model to client #143 (simulated).
[INFO][08:56:10]: [Server #554754] Sending 0.26 MB of payload data to client #143 (simulated).
[INFO][08:56:10]: [Server #554754] Selecting client #69 for training.
[INFO][08:56:10]: [Server #554754] Sending the current model to client #69 (simulated).
[INFO][08:56:10]: [Server #554754] Sending 0.26 MB of payload data to client #69 (simulated).
[INFO][08:56:10]: [Client #143] Selected by the server.
[INFO][08:56:10]: [Client #143] Loading its data source...
[INFO][08:56:10]: Data source: FEMNIST
[INFO][08:56:10]: [Client #69] Selected by the server.
[INFO][08:56:10]: [Client #69] Loading its data source...
[INFO][08:56:10]: Data source: FEMNIST
[INFO][08:56:10]: [Client #69] Dataset size: 161
[INFO][08:56:10]: [Client #69] Sampler: all_inclusive
[INFO][08:56:10]: [Client #69] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:56:10]: [93m[1m[Client #69] Started training in communication round #9.[0m
[INFO][08:56:10]: [Client #143] Dataset size: 156
[INFO][08:56:10]: [Client #143] Sampler: all_inclusive
[INFO][08:56:10]: [Client #143] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:56:10]: [93m[1m[Client #143] Started training in communication round #9.[0m
[INFO][08:56:12]: [Client #69] Loading the dataset.
[INFO][08:56:12]: [Client #143] Loading the dataset.
[INFO][08:56:17]: [Client #69] Epoch: [1/5][0/17]	Loss: 2.530554
[INFO][08:56:17]: [Client #143] Epoch: [1/5][0/16]	Loss: 1.498555
[INFO][08:56:18]: [Client #69] Epoch: [1/5][10/17]	Loss: 2.170233
[INFO][08:56:18]: [Client #143] Epoch: [1/5][10/16]	Loss: 2.577687
[INFO][08:56:18]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][08:56:18]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][08:56:18]: [Client #143] Woke up.
[INFO][08:56:18]: [Client #143] Epoch: [2/5][0/16]	Loss: 1.965833
[INFO][08:56:18]: [Client #143] Epoch: [2/5][10/16]	Loss: 1.079439
[INFO][08:56:18]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][08:56:18]: [Client #143] Woke up.
[INFO][08:56:18]: [Client #143] Epoch: [3/5][0/16]	Loss: 1.449708
[INFO][08:56:18]: [Client #143] Epoch: [3/5][10/16]	Loss: 3.533194
[INFO][08:56:18]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][08:56:18]: [Client #143] Woke up.
[INFO][08:56:18]: [Client #143] Epoch: [4/5][0/16]	Loss: 1.569706
[INFO][08:56:18]: [Client #143] Epoch: [4/5][10/16]	Loss: 1.969223
[INFO][08:56:18]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][08:56:18]: [Client #143] Woke up.
[INFO][08:56:18]: [Client #143] Epoch: [5/5][0/16]	Loss: 0.547512
[INFO][08:56:18]: [Client #143] Epoch: [5/5][10/16]	Loss: 1.388355
[INFO][08:56:18]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][08:56:18]: [Client #143] Woke up.
[INFO][08:56:18]: [Client #143] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_554853.pth.
[INFO][08:56:19]: [Client #143] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_554853.pth.
[INFO][08:56:19]: [Client #143] Model trained.
[INFO][08:56:19]: [Client #143] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:56:19]: [Server #554754] Received 0.26 MB of payload data from client #143 (simulated).
[INFO][08:56:35]: [Client #69] Woke up.
[INFO][08:56:35]: [Client #69] Epoch: [2/5][0/17]	Loss: 2.548268
[INFO][08:56:35]: [Client #69] Epoch: [2/5][10/17]	Loss: 2.488819
[INFO][08:56:35]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][08:56:52]: [Client #69] Woke up.
[INFO][08:56:52]: [Client #69] Epoch: [3/5][0/17]	Loss: 2.606708
[INFO][08:56:52]: [Client #69] Epoch: [3/5][10/17]	Loss: 2.290725
[INFO][08:56:52]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][08:57:09]: [Client #69] Woke up.
[INFO][08:57:09]: [Client #69] Epoch: [4/5][0/17]	Loss: 2.119958
[INFO][08:57:09]: [Client #69] Epoch: [4/5][10/17]	Loss: 2.189879
[INFO][08:57:09]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][08:57:26]: [Client #69] Woke up.
[INFO][08:57:26]: [Client #69] Epoch: [5/5][0/17]	Loss: 2.040424
[INFO][08:57:27]: [Client #69] Epoch: [5/5][10/17]	Loss: 2.534583
[INFO][08:57:27]: [Client #69] Going to sleep for 17.05 seconds.
[INFO][08:57:44]: [Client #69] Woke up.
[INFO][08:57:44]: [Client #69] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_69_554860.pth.
[INFO][08:57:44]: [Client #69] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_69_554860.pth.
[INFO][08:57:44]: [Client #69] Model trained.
[INFO][08:57:44]: [Client #69] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:57:44]: [Server #554754] Received 0.26 MB of payload data from client #69 (simulated).
[INFO][08:57:44]: [Server #554754] Selecting client #145 for training.
[INFO][08:57:44]: [Server #554754] Sending the current model to client #145 (simulated).
[INFO][08:57:44]: [Server #554754] Sending 0.26 MB of payload data to client #145 (simulated).
[INFO][08:57:44]: [Server #554754] Selecting client #307 for training.
[INFO][08:57:44]: [Server #554754] Sending the current model to client #307 (simulated).
[INFO][08:57:44]: [Server #554754] Sending 0.26 MB of payload data to client #307 (simulated).
[INFO][08:57:44]: [Client #145] Selected by the server.
[INFO][08:57:44]: [Client #145] Loading its data source...
[INFO][08:57:44]: [Client #307] Selected by the server.
[INFO][08:57:44]: Data source: FEMNIST
[INFO][08:57:44]: [Client #307] Loading its data source...
[INFO][08:57:44]: Data source: FEMNIST
[INFO][08:57:44]: [Client #307] Dataset size: 162
[INFO][08:57:44]: [Client #307] Sampler: all_inclusive
[INFO][08:57:44]: [Client #307] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:57:44]: [93m[1m[Client #307] Started training in communication round #9.[0m
[INFO][08:57:45]: [Client #145] Dataset size: 272
[INFO][08:57:45]: [Client #145] Sampler: all_inclusive
[INFO][08:57:45]: [Client #145] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:57:45]: [93m[1m[Client #145] Started training in communication round #9.[0m
[INFO][08:57:46]: [Client #307] Loading the dataset.
[INFO][08:57:46]: [Client #145] Loading the dataset.
[INFO][08:57:52]: [Client #307] Epoch: [1/5][0/17]	Loss: 2.040658
[INFO][08:57:52]: [Client #145] Epoch: [1/5][0/28]	Loss: 2.259849
[INFO][08:57:52]: [Client #145] Epoch: [1/5][10/28]	Loss: 1.996622
[INFO][08:57:52]: [Client #307] Epoch: [1/5][10/17]	Loss: 1.960064
[INFO][08:57:52]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:57:52]: [Client #145] Epoch: [1/5][20/28]	Loss: 2.708919
[INFO][08:57:52]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][08:57:52]: [Client #145] Woke up.
[INFO][08:57:52]: [Client #145] Epoch: [2/5][0/28]	Loss: 2.881681
[INFO][08:57:52]: [Client #145] Epoch: [2/5][10/28]	Loss: 2.803530
[INFO][08:57:52]: [Client #145] Epoch: [2/5][20/28]	Loss: 1.855299
[INFO][08:57:52]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][08:57:52]: [Client #145] Woke up.
[INFO][08:57:52]: [Client #145] Epoch: [3/5][0/28]	Loss: 1.284062
[INFO][08:57:53]: [Client #145] Epoch: [3/5][10/28]	Loss: 1.617407
[INFO][08:57:53]: [Client #307] Woke up.
[INFO][08:57:53]: [Client #307] Epoch: [2/5][0/17]	Loss: 2.949585
[INFO][08:57:53]: [Client #145] Epoch: [3/5][20/28]	Loss: 2.029197
[INFO][08:57:53]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][08:57:53]: [Client #307] Epoch: [2/5][10/17]	Loss: 2.336566
[INFO][08:57:53]: [Client #145] Woke up.
[INFO][08:57:53]: [Client #145] Epoch: [4/5][0/28]	Loss: 1.784686
[INFO][08:57:53]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:57:53]: [Client #145] Epoch: [4/5][10/28]	Loss: 2.377938
[INFO][08:57:53]: [Client #145] Epoch: [4/5][20/28]	Loss: 1.654940
[INFO][08:57:53]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][08:57:53]: [Client #145] Woke up.
[INFO][08:57:53]: [Client #145] Epoch: [5/5][0/28]	Loss: 2.348025
[INFO][08:57:53]: [Client #145] Epoch: [5/5][10/28]	Loss: 2.207724
[INFO][08:57:53]: [Client #145] Epoch: [5/5][20/28]	Loss: 1.983995
[INFO][08:57:53]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][08:57:53]: [Client #145] Woke up.
[INFO][08:57:53]: [Client #145] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_145_554853.pth.
[INFO][08:57:53]: [Client #307] Woke up.
[INFO][08:57:53]: [Client #307] Epoch: [3/5][0/17]	Loss: 2.468354
[INFO][08:57:53]: [Client #307] Epoch: [3/5][10/17]	Loss: 2.421529
[INFO][08:57:53]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:57:54]: [Client #145] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_145_554853.pth.
[INFO][08:57:54]: [Client #145] Model trained.
[INFO][08:57:54]: [Client #145] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:57:54]: [Server #554754] Received 0.26 MB of payload data from client #145 (simulated).
[INFO][08:57:54]: [Client #307] Woke up.
[INFO][08:57:54]: [Client #307] Epoch: [4/5][0/17]	Loss: 1.821541
[INFO][08:57:54]: [Client #307] Epoch: [4/5][10/17]	Loss: 2.368426
[INFO][08:57:54]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:57:55]: [Client #307] Woke up.
[INFO][08:57:55]: [Client #307] Epoch: [5/5][0/17]	Loss: 1.291489
[INFO][08:57:55]: [Client #307] Epoch: [5/5][10/17]	Loss: 1.798413
[INFO][08:57:55]: [Client #307] Going to sleep for 0.53 seconds.
[INFO][08:57:55]: [Client #307] Woke up.
[INFO][08:57:55]: [Client #307] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_554860.pth.
[INFO][08:57:56]: [Client #307] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_307_554860.pth.
[INFO][08:57:56]: [Client #307] Model trained.
[INFO][08:57:56]: [Client #307] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:57:56]: [Server #554754] Received 0.26 MB of payload data from client #307 (simulated).
[INFO][08:57:56]: [Server #554754] Adding client #258 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #188 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #2 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #143 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #61 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #151 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #145 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #430 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #272 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #307 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #359 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #443 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #349 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #109 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #119 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #139 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #201 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #69 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #365 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][08:57:56]: [Server #554754] Aggregating 20 clients in total.
[0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00203809 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00203981 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00203648 0.00204086 0.00204086 0.00204086 0.00204047 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204041 0.00204086
 0.00203972 0.00204086 0.00204086 0.00204047 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204012 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.0020402  0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00203345 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086]
current clients pool:  [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.09859125 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09775205 0.         0.         0.         0.         0.
 0.         0.         0.39584076 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08634721 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12063806 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08309878 0.         0.         0.         0.08894283 0.
 0.25720787 0.         0.         0.         0.         0.
 0.13928852 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1263916  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12565641 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08757884
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08485939 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07073239 0.
 0.         0.         0.         0.         0.         0.
 0.17912435 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09142034 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.40072415 0.
 0.         0.         0.         0.         0.0785591  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07190671 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1011173  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.09859125 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09775205 0.         0.         0.         0.         0.
 0.         0.         0.39584076 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08634721 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12063806 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08309878 0.         0.         0.         0.08894283 0.
 0.25720787 0.         0.         0.         0.         0.
 0.13928852 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1263916  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12565641 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08757884
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.08485939 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07073239 0.
 0.         0.         0.         0.         0.         0.
 0.17912435 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09142034 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.40072415 0.
 0.         0.         0.         0.         0.0785591  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07190671 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1011173  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][08:58:40]: [Server #554754] Global model accuracy: 44.06%

[INFO][08:58:40]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_9.pth.
[INFO][08:58:40]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_9.pth.
[INFO][08:58:40]: [93m[1m
[Server #554754] Starting round 10/100.[0m
[0.002      0.04639175 0.10496183 0.002      0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.002      0.002      0.002      0.04730139 0.002
 0.08247423 0.002      0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.08314607 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.002      0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.05003032
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.04912068 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.04881747 0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.002      0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.05019947 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04851425 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.002      0.002      0.002      0.002      0.10384615 0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.05418883 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.002      0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9070e+00  7e-04  1e-08  1e-08
 5:  6.9078e+00  6.9074e+00  4e-04  6e-09  6e-09
 6:  6.9077e+00  6.9073e+00  4e-04  8e-08  3e-08
 7:  6.9077e+00  6.9074e+00  3e-04  7e-08  3e-08
 8:  6.9076e+00  6.9074e+00  2e-04  2e-07  9e-08
 9:  6.9075e+00  6.9074e+00  4e-05  3e-07  1e-07
10:  6.9074e+00  6.9074e+00  6e-06  7e-08  3e-08
Optimal solution found.
The calculated probability is:  [4.31831341e-05 8.55979840e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31782413e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.30944413e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31788009e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31747801e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 7.50824544e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31789229e-05 4.31831341e-05
 4.30762916e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31719980e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 1.11874875e-04
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 1.11021068e-04 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 7.78912524e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31798222e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 6.81454803e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31647202e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 8.04435232e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 9.78089304e-01 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 7.24031721e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 6.87570283e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31771188e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05
 4.31831341e-05 4.31831341e-05 4.31831341e-05 4.31831341e-05]
current clients pool:  [INFO][08:58:40]: [Server #554754] Selected clients: [359 383 252 248 421  34 286 471 258  98 424 127 349 269 475 311 419   4
 495  39]
[INFO][08:58:40]: [Server #554754] Selecting client #359 for training.
[INFO][08:58:40]: [Server #554754] Sending the current model to client #359 (simulated).
[INFO][08:58:40]: [Server #554754] Sending 0.26 MB of payload data to client #359 (simulated).
[INFO][08:58:40]: [Server #554754] Selecting client #383 for training.
[INFO][08:58:40]: [Server #554754] Sending the current model to client #383 (simulated).
[INFO][08:58:40]: [Server #554754] Sending 0.26 MB of payload data to client #383 (simulated).
[INFO][08:58:40]: [Client #359] Selected by the server.
[INFO][08:58:40]: [Client #359] Loading its data source...
[INFO][08:58:40]: Data source: FEMNIST
[INFO][08:58:40]: [Client #383] Selected by the server.
[INFO][08:58:40]: [Client #383] Loading its data source...
[INFO][08:58:40]: Data source: FEMNIST
[INFO][08:58:40]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][08:58:40]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/383.zip.
[INFO][08:58:40]: [Client #359] Dataset size: 161
[INFO][08:58:40]: [Client #359] Sampler: all_inclusive
[INFO][08:58:40]: [Client #359] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:58:40]: [93m[1m[Client #359] Started training in communication round #10.[0m

2.3%
4.6%
6.9%
9.2%
11.5%
13.8%
16.1%
18.4%
20.7%
23.0%
25.3%
27.6%
29.9%
32.2%
34.5%
36.8%
39.1%
41.4%
43.7%
46.0%
48.3%
50.6%
52.9%
55.2%
57.5%
59.8%
62.0%
64.3%
66.6%
68.9%
71.2%
73.5%
75.8%
78.1%
80.4%
82.7%
85.0%
87.3%
89.6%
91.9%
94.2%
96.5%
98.8%
100.0%[INFO][08:58:41]: Decompressing the dataset downloaded.
[INFO][08:58:41]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/383.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][08:58:41]: [Client #383] Dataset size: 161
[INFO][08:58:41]: [Client #383] Sampler: all_inclusive
[INFO][08:58:41]: [Client #383] Received 0.26 MB of payload data from the server (simulated).
[INFO][08:58:41]: [93m[1m[Client #383] Started training in communication round #10.[0m

[INFO][08:58:42]: [Client #359] Loading the dataset.
[INFO][08:58:43]: [Client #383] Loading the dataset.
[INFO][08:58:48]: [Client #359] Epoch: [1/5][0/17]	Loss: 0.708053
[INFO][08:58:48]: [Client #383] Epoch: [1/5][0/17]	Loss: 0.765326
[INFO][08:58:48]: [Client #359] Epoch: [1/5][10/17]	Loss: 0.990308
[INFO][08:58:48]: [Client #383] Epoch: [1/5][10/17]	Loss: 2.743772
[INFO][08:58:48]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:58:48]: [Client #383] Going to sleep for 60.00 seconds.
[INFO][08:58:52]: [Client #359] Woke up.
[INFO][08:58:52]: [Client #359] Epoch: [2/5][0/17]	Loss: 0.944521
[INFO][08:58:52]: [Client #359] Epoch: [2/5][10/17]	Loss: 1.339121
[INFO][08:58:52]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:58:55]: [Client #359] Woke up.
[INFO][08:58:55]: [Client #359] Epoch: [3/5][0/17]	Loss: 1.377608
[INFO][08:58:55]: [Client #359] Epoch: [3/5][10/17]	Loss: 1.573023
[INFO][08:58:55]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:58:59]: [Client #359] Woke up.
[INFO][08:58:59]: [Client #359] Epoch: [4/5][0/17]	Loss: 0.399773
[INFO][08:58:59]: [Client #359] Epoch: [4/5][10/17]	Loss: 1.151570
[INFO][08:58:59]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:59:03]: [Client #359] Woke up.
[INFO][08:59:03]: [Client #359] Epoch: [5/5][0/17]	Loss: 0.140693
[INFO][08:59:03]: [Client #359] Epoch: [5/5][10/17]	Loss: 2.210684
[INFO][08:59:03]: [Client #359] Going to sleep for 3.60 seconds.
[INFO][08:59:07]: [Client #359] Woke up.
[INFO][08:59:07]: [Client #359] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_359_554853.pth.
[INFO][08:59:07]: [Client #359] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_359_554853.pth.
[INFO][08:59:07]: [Client #359] Model trained.
[INFO][08:59:07]: [Client #359] Sent 0.26 MB of payload data to the server (simulated).
[INFO][08:59:07]: [Server #554754] Received 0.26 MB of payload data from client #359 (simulated).
[INFO][08:59:48]: [Client #383] Woke up.
[INFO][08:59:48]: [Client #383] Epoch: [2/5][0/17]	Loss: 1.135798
[INFO][08:59:48]: [Client #383] Epoch: [2/5][10/17]	Loss: 1.870095
[INFO][08:59:48]: [Client #383] Going to sleep for 60.00 seconds.
[INFO][09:00:48]: [Client #383] Woke up.
[INFO][09:00:48]: [Client #383] Epoch: [3/5][0/17]	Loss: 1.615350
[INFO][09:00:48]: [Client #383] Epoch: [3/5][10/17]	Loss: 2.167695
[INFO][09:00:49]: [Client #383] Going to sleep for 60.00 seconds.
[INFO][09:01:49]: [Client #383] Woke up.
[INFO][09:01:49]: [Client #383] Epoch: [4/5][0/17]	Loss: 1.453809
[INFO][09:01:49]: [Client #383] Epoch: [4/5][10/17]	Loss: 0.969469
[INFO][09:01:49]: [Client #383] Going to sleep for 60.00 seconds.
[INFO][09:02:49]: [Client #383] Woke up.
[INFO][09:02:49]: [Client #383] Epoch: [5/5][0/17]	Loss: 0.816083
[INFO][09:02:49]: [Client #383] Epoch: [5/5][10/17]	Loss: 1.258086
[INFO][09:02:49]: [Client #383] Going to sleep for 60.00 seconds.
[INFO][09:03:49]: [Client #383] Woke up.
[INFO][09:03:49]: [Client #383] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_383_554860.pth.
[INFO][09:03:50]: [Client #383] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_383_554860.pth.
[INFO][09:03:50]: [Client #383] Model trained.
[INFO][09:03:50]: [Client #383] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:03:50]: [Server #554754] Received 0.26 MB of payload data from client #383 (simulated).
[INFO][09:03:50]: [Server #554754] Selecting client #252 for training.
[INFO][09:03:50]: [Server #554754] Sending the current model to client #252 (simulated).
[INFO][09:03:50]: [Server #554754] Sending 0.26 MB of payload data to client #252 (simulated).
[INFO][09:03:50]: [Server #554754] Selecting client #248 for training.
[INFO][09:03:50]: [Server #554754] Sending the current model to client #248 (simulated).
[INFO][09:03:50]: [Server #554754] Sending 0.26 MB of payload data to client #248 (simulated).
[INFO][09:03:50]: [Client #252] Selected by the server.
[INFO][09:03:50]: [Client #248] Selected by the server.
[INFO][09:03:50]: [Client #252] Loading its data source...
[INFO][09:03:50]: [Client #248] Loading its data source...
[INFO][09:03:50]: Data source: FEMNIST
[INFO][09:03:50]: Data source: FEMNIST
[INFO][09:03:50]: [Client #252] Dataset size: 149
[INFO][09:03:50]: [Client #252] Sampler: all_inclusive
[INFO][09:03:50]: [Client #252] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:03:50]: [93m[1m[Client #252] Started training in communication round #10.[0m
[INFO][09:03:50]: [Client #248] Dataset size: 164
[INFO][09:03:50]: [Client #248] Sampler: all_inclusive
[INFO][09:03:50]: [Client #248] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:03:50]: [93m[1m[Client #248] Started training in communication round #10.[0m
[INFO][09:03:52]: [Client #252] Loading the dataset.
[INFO][09:03:52]: [Client #248] Loading the dataset.
[INFO][09:03:57]: [Client #252] Epoch: [1/5][0/15]	Loss: 1.589240
[INFO][09:03:57]: [Client #248] Epoch: [1/5][0/17]	Loss: 0.608834
[INFO][09:03:57]: [Client #252] Epoch: [1/5][10/15]	Loss: 1.704075
[INFO][09:03:58]: [Client #248] Epoch: [1/5][10/17]	Loss: 1.073547
[INFO][09:03:58]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][09:03:58]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][09:03:58]: [Client #248] Woke up.
[INFO][09:03:58]: [Client #248] Epoch: [2/5][0/17]	Loss: 1.067815
[INFO][09:03:58]: [Client #248] Epoch: [2/5][10/17]	Loss: 1.060769
[INFO][09:03:58]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][09:03:59]: [Client #248] Woke up.
[INFO][09:03:59]: [Client #248] Epoch: [3/5][0/17]	Loss: 0.793464
[INFO][09:03:59]: [Client #248] Epoch: [3/5][10/17]	Loss: 1.798711
[INFO][09:03:59]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][09:04:00]: [Client #248] Woke up.
[INFO][09:04:00]: [Client #248] Epoch: [4/5][0/17]	Loss: 0.867827
[INFO][09:04:00]: [Client #248] Epoch: [4/5][10/17]	Loss: 2.705317
[INFO][09:04:00]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][09:04:01]: [Client #248] Woke up.
[INFO][09:04:01]: [Client #248] Epoch: [5/5][0/17]	Loss: 0.643120
[INFO][09:04:01]: [Client #248] Epoch: [5/5][10/17]	Loss: 1.689349
[INFO][09:04:01]: [Client #248] Going to sleep for 0.72 seconds.
[INFO][09:04:02]: [Client #248] Woke up.
[INFO][09:04:02]: [Client #248] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_248_554860.pth.
[INFO][09:04:02]: [Client #248] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_248_554860.pth.
[INFO][09:04:02]: [Client #248] Model trained.
[INFO][09:04:02]: [Client #248] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:04:02]: [Server #554754] Received 0.26 MB of payload data from client #248 (simulated).
[INFO][09:04:40]: [Client #252] Woke up.
[INFO][09:04:40]: [Client #252] Epoch: [2/5][0/15]	Loss: 1.273418
[INFO][09:04:40]: [Client #252] Epoch: [2/5][10/15]	Loss: 1.739393
[INFO][09:04:40]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][09:05:22]: [Client #252] Woke up.
[INFO][09:05:22]: [Client #252] Epoch: [3/5][0/15]	Loss: 2.632468
[INFO][09:05:22]: [Client #252] Epoch: [3/5][10/15]	Loss: 1.640498
[INFO][09:05:22]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][09:06:04]: [Client #252] Woke up.
[INFO][09:06:04]: [Client #252] Epoch: [4/5][0/15]	Loss: 1.549311
[INFO][09:06:04]: [Client #252] Epoch: [4/5][10/15]	Loss: 2.016351
[INFO][09:06:04]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][09:06:46]: [Client #252] Woke up.
[INFO][09:06:47]: [Client #252] Epoch: [5/5][0/15]	Loss: 1.422702
[INFO][09:06:47]: [Client #252] Epoch: [5/5][10/15]	Loss: 2.577002
[INFO][09:06:47]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][09:07:29]: [Client #252] Woke up.
[INFO][09:07:29]: [Client #252] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554853.pth.
[INFO][09:07:30]: [Client #252] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554853.pth.
[INFO][09:07:30]: [Client #252] Model trained.
[INFO][09:07:30]: [Client #252] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:07:30]: [Server #554754] Received 0.26 MB of payload data from client #252 (simulated).
[INFO][09:07:30]: [Server #554754] Selecting client #421 for training.
[INFO][09:07:30]: [Server #554754] Sending the current model to client #421 (simulated).
[INFO][09:07:30]: [Server #554754] Sending 0.26 MB of payload data to client #421 (simulated).
[INFO][09:07:30]: [Server #554754] Selecting client #34 for training.
[INFO][09:07:30]: [Server #554754] Sending the current model to client #34 (simulated).
[INFO][09:07:30]: [Server #554754] Sending 0.26 MB of payload data to client #34 (simulated).
[INFO][09:07:30]: [Client #421] Selected by the server.
[INFO][09:07:30]: [Client #421] Loading its data source...
[INFO][09:07:30]: Data source: FEMNIST
[INFO][09:07:30]: [Client #34] Selected by the server.
[INFO][09:07:30]: [Client #34] Loading its data source...
[INFO][09:07:30]: Data source: FEMNIST
[INFO][09:07:30]: [Client #421] Dataset size: 160
[INFO][09:07:30]: [Client #421] Sampler: all_inclusive
[INFO][09:07:30]: [Client #421] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:07:30]: [93m[1m[Client #421] Started training in communication round #10.[0m
[INFO][09:07:30]: [Client #34] Dataset size: 309
[INFO][09:07:30]: [Client #34] Sampler: all_inclusive
[INFO][09:07:30]: [Client #34] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:07:30]: [93m[1m[Client #34] Started training in communication round #10.[0m
[INFO][09:07:32]: [Client #421] Loading the dataset.
[INFO][09:07:32]: [Client #34] Loading the dataset.
[INFO][09:07:37]: [Client #421] Epoch: [1/5][0/16]	Loss: 1.842406
[INFO][09:07:37]: [Client #34] Epoch: [1/5][0/31]	Loss: 2.848396
[INFO][09:07:37]: [Client #421] Epoch: [1/5][10/16]	Loss: 1.021352
[INFO][09:07:37]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][09:07:37]: [Client #34] Epoch: [1/5][10/31]	Loss: 1.999929
[INFO][09:07:37]: [Client #34] Epoch: [1/5][20/31]	Loss: 2.295183
[INFO][09:07:38]: [Client #421] Woke up.
[INFO][09:07:38]: [Client #421] Epoch: [2/5][0/16]	Loss: 1.090943
[INFO][09:07:38]: [Client #34] Epoch: [1/5][30/31]	Loss: 1.968022
[INFO][09:07:38]: [Client #34] Going to sleep for 1.14 seconds.
[INFO][09:07:38]: [Client #421] Epoch: [2/5][10/16]	Loss: 1.362331
[INFO][09:07:38]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][09:07:38]: [Client #421] Woke up.
[INFO][09:07:38]: [Client #421] Epoch: [3/5][0/16]	Loss: 1.555414
[INFO][09:07:38]: [Client #421] Epoch: [3/5][10/16]	Loss: 1.990993
[INFO][09:07:38]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][09:07:38]: [Client #421] Woke up.
[INFO][09:07:38]: [Client #421] Epoch: [4/5][0/16]	Loss: 1.317141
[INFO][09:07:38]: [Client #421] Epoch: [4/5][10/16]	Loss: 1.753465
[INFO][09:07:38]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][09:07:38]: [Client #421] Woke up.
[INFO][09:07:38]: [Client #421] Epoch: [5/5][0/16]	Loss: 0.417396
[INFO][09:07:39]: [Client #421] Epoch: [5/5][10/16]	Loss: 1.749845
[INFO][09:07:39]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][09:07:39]: [Client #34] Woke up.
[INFO][09:07:39]: [Client #34] Epoch: [2/5][0/31]	Loss: 2.796939
[INFO][09:07:39]: [Client #421] Woke up.
[INFO][09:07:39]: [Client #421] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_421_554853.pth.
[INFO][09:07:39]: [Client #34] Epoch: [2/5][10/31]	Loss: 1.438401
[INFO][09:07:39]: [Client #34] Epoch: [2/5][20/31]	Loss: 1.964327
[INFO][09:07:39]: [Client #34] Epoch: [2/5][30/31]	Loss: 1.828248
[INFO][09:07:39]: [Client #34] Going to sleep for 1.14 seconds.
[INFO][09:07:39]: [Client #421] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_421_554853.pth.
[INFO][09:07:39]: [Client #421] Model trained.
[INFO][09:07:39]: [Client #421] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:07:39]: [Server #554754] Received 0.26 MB of payload data from client #421 (simulated).
[INFO][09:07:40]: [Client #34] Woke up.
[INFO][09:07:40]: [Client #34] Epoch: [3/5][0/31]	Loss: 1.293837
[INFO][09:07:40]: [Client #34] Epoch: [3/5][10/31]	Loss: 1.854992
[INFO][09:07:40]: [Client #34] Epoch: [3/5][20/31]	Loss: 1.097436
[INFO][09:07:40]: [Client #34] Epoch: [3/5][30/31]	Loss: 2.069778
[INFO][09:07:40]: [Client #34] Going to sleep for 1.14 seconds.
[INFO][09:07:42]: [Client #34] Woke up.
[INFO][09:07:42]: [Client #34] Epoch: [4/5][0/31]	Loss: 1.353345
[INFO][09:07:42]: [Client #34] Epoch: [4/5][10/31]	Loss: 0.895316
[INFO][09:07:42]: [Client #34] Epoch: [4/5][20/31]	Loss: 2.109859
[INFO][09:07:42]: [Client #34] Epoch: [4/5][30/31]	Loss: 1.523924
[INFO][09:07:42]: [Client #34] Going to sleep for 1.14 seconds.
[INFO][09:07:43]: [Client #34] Woke up.
[INFO][09:07:43]: [Client #34] Epoch: [5/5][0/31]	Loss: 0.911350
[INFO][09:07:43]: [Client #34] Epoch: [5/5][10/31]	Loss: 1.721080
[INFO][09:07:43]: [Client #34] Epoch: [5/5][20/31]	Loss: 2.384963
[INFO][09:07:43]: [Client #34] Epoch: [5/5][30/31]	Loss: 2.172857
[INFO][09:07:43]: [Client #34] Going to sleep for 1.14 seconds.
[INFO][09:07:44]: [Client #34] Woke up.
[INFO][09:07:44]: [Client #34] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_34_554860.pth.
[INFO][09:07:45]: [Client #34] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_34_554860.pth.
[INFO][09:07:45]: [Client #34] Model trained.
[INFO][09:07:45]: [Client #34] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:07:45]: [Server #554754] Received 0.26 MB of payload data from client #34 (simulated).
[INFO][09:07:45]: [Server #554754] Selecting client #286 for training.
[INFO][09:07:45]: [Server #554754] Sending the current model to client #286 (simulated).
[INFO][09:07:45]: [Server #554754] Sending 0.26 MB of payload data to client #286 (simulated).
[INFO][09:07:45]: [Server #554754] Selecting client #471 for training.
[INFO][09:07:45]: [Server #554754] Sending the current model to client #471 (simulated).
[INFO][09:07:45]: [Server #554754] Sending 0.26 MB of payload data to client #471 (simulated).
[INFO][09:07:45]: [Client #471] Selected by the server.
[INFO][09:07:45]: [Client #471] Loading its data source...
[INFO][09:07:45]: [Client #286] Selected by the server.
[INFO][09:07:45]: Data source: FEMNIST
[INFO][09:07:45]: [Client #286] Loading its data source...
[INFO][09:07:45]: Data source: FEMNIST
[INFO][09:07:45]: [Client #471] Dataset size: 153
[INFO][09:07:45]: [Client #471] Sampler: all_inclusive
[INFO][09:07:45]: [Client #286] Dataset size: 154
[INFO][09:07:45]: [Client #286] Sampler: all_inclusive
[INFO][09:07:45]: [Client #471] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:07:45]: [Client #286] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:07:45]: [93m[1m[Client #471] Started training in communication round #10.[0m
[INFO][09:07:45]: [93m[1m[Client #286] Started training in communication round #10.[0m
[INFO][09:07:47]: [Client #471] Loading the dataset.
[INFO][09:07:47]: [Client #286] Loading the dataset.
[INFO][09:07:52]: [Client #471] Epoch: [1/5][0/16]	Loss: 1.612364
[INFO][09:07:53]: [Client #286] Epoch: [1/5][0/16]	Loss: 1.354912
[INFO][09:07:53]: [Client #471] Epoch: [1/5][10/16]	Loss: 1.771451
[INFO][09:07:53]: [Client #471] Going to sleep for 10.21 seconds.
[INFO][09:07:53]: [Client #286] Epoch: [1/5][10/16]	Loss: 0.727694
[INFO][09:07:53]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:07:59]: [Client #286] Woke up.
[INFO][09:07:59]: [Client #286] Epoch: [2/5][0/16]	Loss: 0.680610
[INFO][09:07:59]: [Client #286] Epoch: [2/5][10/16]	Loss: 1.698426
[INFO][09:07:59]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:08:03]: [Client #471] Woke up.
[INFO][09:08:03]: [Client #471] Epoch: [2/5][0/16]	Loss: 1.535636
[INFO][09:08:03]: [Client #471] Epoch: [2/5][10/16]	Loss: 2.140846
[INFO][09:08:03]: [Client #471] Going to sleep for 10.21 seconds.
[INFO][09:08:05]: [Client #286] Woke up.
[INFO][09:08:05]: [Client #286] Epoch: [3/5][0/16]	Loss: 1.236309
[INFO][09:08:05]: [Client #286] Epoch: [3/5][10/16]	Loss: 1.217449
[INFO][09:08:05]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:08:11]: [Client #286] Woke up.
[INFO][09:08:11]: [Client #286] Epoch: [4/5][0/16]	Loss: 0.616861
[INFO][09:08:11]: [Client #286] Epoch: [4/5][10/16]	Loss: 1.755759
[INFO][09:08:11]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:08:13]: [Client #471] Woke up.
[INFO][09:08:13]: [Client #471] Epoch: [3/5][0/16]	Loss: 1.778589
[INFO][09:08:13]: [Client #471] Epoch: [3/5][10/16]	Loss: 1.294355
[INFO][09:08:13]: [Client #471] Going to sleep for 10.21 seconds.
[INFO][09:08:17]: [Client #286] Woke up.
[INFO][09:08:17]: [Client #286] Epoch: [5/5][0/16]	Loss: 0.458830
[INFO][09:08:17]: [Client #286] Epoch: [5/5][10/16]	Loss: 1.033944
[INFO][09:08:17]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:08:23]: [Client #286] Woke up.
[INFO][09:08:23]: [Client #286] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554853.pth.
[INFO][09:08:23]: [Client #286] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554853.pth.
[INFO][09:08:23]: [Client #286] Model trained.
[INFO][09:08:23]: [Client #286] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:08:23]: [Server #554754] Received 0.26 MB of payload data from client #286 (simulated).
[INFO][09:08:24]: [Client #471] Woke up.
[INFO][09:08:24]: [Client #471] Epoch: [4/5][0/16]	Loss: 1.074670
[INFO][09:08:24]: [Client #471] Epoch: [4/5][10/16]	Loss: 3.002466
[INFO][09:08:24]: [Client #471] Going to sleep for 10.21 seconds.
[INFO][09:08:34]: [Client #471] Woke up.
[INFO][09:08:34]: [Client #471] Epoch: [5/5][0/16]	Loss: 2.171828
[INFO][09:08:34]: [Client #471] Epoch: [5/5][10/16]	Loss: 1.591534
[INFO][09:08:34]: [Client #471] Going to sleep for 10.21 seconds.
[INFO][09:08:44]: [Client #471] Woke up.
[INFO][09:08:44]: [Client #471] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_471_554860.pth.
[INFO][09:08:45]: [Client #471] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_471_554860.pth.
[INFO][09:08:45]: [Client #471] Model trained.
[INFO][09:08:45]: [Client #471] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:08:45]: [Server #554754] Received 0.26 MB of payload data from client #471 (simulated).
[INFO][09:08:45]: [Server #554754] Selecting client #258 for training.
[INFO][09:08:45]: [Server #554754] Sending the current model to client #258 (simulated).
[INFO][09:08:45]: [Server #554754] Sending 0.26 MB of payload data to client #258 (simulated).
[INFO][09:08:45]: [Server #554754] Selecting client #98 for training.
[INFO][09:08:45]: [Server #554754] Sending the current model to client #98 (simulated).
[INFO][09:08:45]: [Server #554754] Sending 0.26 MB of payload data to client #98 (simulated).
[INFO][09:08:45]: [Client #258] Selected by the server.
[INFO][09:08:45]: [Client #258] Loading its data source...
[INFO][09:08:45]: Data source: FEMNIST
[INFO][09:08:45]: [Client #98] Selected by the server.
[INFO][09:08:45]: [Client #98] Loading its data source...
[INFO][09:08:45]: Data source: FEMNIST
[INFO][09:08:45]: [Client #258] Dataset size: 165
[INFO][09:08:45]: [Client #258] Sampler: all_inclusive
[INFO][09:08:45]: [Client #258] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:08:45]: [93m[1m[Client #258] Started training in communication round #10.[0m
[INFO][09:08:45]: [Client #98] Dataset size: 160
[INFO][09:08:45]: [Client #98] Sampler: all_inclusive
[INFO][09:08:45]: [Client #98] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:08:45]: [93m[1m[Client #98] Started training in communication round #10.[0m
[INFO][09:08:47]: [Client #258] Loading the dataset.
[INFO][09:08:47]: [Client #98] Loading the dataset.
[INFO][09:08:52]: [Client #258] Epoch: [1/5][0/17]	Loss: 1.408868
[INFO][09:08:52]: [Client #98] Epoch: [1/5][0/16]	Loss: 1.316906
[INFO][09:08:52]: [Client #258] Epoch: [1/5][10/17]	Loss: 1.005099
[INFO][09:08:52]: [Client #98] Epoch: [1/5][10/16]	Loss: 2.433451
[INFO][09:08:53]: [Client #98] Going to sleep for 1.35 seconds.
[INFO][09:08:53]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:08:54]: [Client #98] Woke up.
[INFO][09:08:54]: [Client #98] Epoch: [2/5][0/16]	Loss: 1.454641
[INFO][09:08:54]: [Client #98] Epoch: [2/5][10/16]	Loss: 1.169112
[INFO][09:08:54]: [Client #98] Going to sleep for 1.35 seconds.
[INFO][09:08:54]: [Client #258] Woke up.
[INFO][09:08:54]: [Client #258] Epoch: [2/5][0/17]	Loss: 1.595904
[INFO][09:08:54]: [Client #258] Epoch: [2/5][10/17]	Loss: 2.134333
[INFO][09:08:54]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:08:55]: [Client #98] Woke up.
[INFO][09:08:55]: [Client #98] Epoch: [3/5][0/16]	Loss: 1.605752
[INFO][09:08:55]: [Client #98] Epoch: [3/5][10/16]	Loss: 1.804221
[INFO][09:08:56]: [Client #98] Going to sleep for 1.35 seconds.
[INFO][09:08:56]: [Client #258] Woke up.
[INFO][09:08:56]: [Client #258] Epoch: [3/5][0/17]	Loss: 2.024469
[INFO][09:08:56]: [Client #258] Epoch: [3/5][10/17]	Loss: 1.560894
[INFO][09:08:56]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:08:57]: [Client #98] Woke up.
[INFO][09:08:57]: [Client #98] Epoch: [4/5][0/16]	Loss: 1.493805
[INFO][09:08:57]: [Client #98] Epoch: [4/5][10/16]	Loss: 1.533551
[INFO][09:08:57]: [Client #98] Going to sleep for 1.35 seconds.
[INFO][09:08:58]: [Client #258] Woke up.
[INFO][09:08:58]: [Client #258] Epoch: [4/5][0/17]	Loss: 1.624209
[INFO][09:08:58]: [Client #258] Epoch: [4/5][10/17]	Loss: 0.954279
[INFO][09:08:58]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:08:58]: [Client #98] Woke up.
[INFO][09:08:58]: [Client #98] Epoch: [5/5][0/16]	Loss: 2.151226
[INFO][09:08:58]: [Client #98] Epoch: [5/5][10/16]	Loss: 1.199714
[INFO][09:08:59]: [Client #98] Going to sleep for 1.35 seconds.
[INFO][09:09:00]: [Client #258] Woke up.
[INFO][09:09:00]: [Client #258] Epoch: [5/5][0/17]	Loss: 1.343133
[INFO][09:09:00]: [Client #258] Epoch: [5/5][10/17]	Loss: 2.411094
[INFO][09:09:00]: [Client #98] Woke up.
[INFO][09:09:00]: [Client #98] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_98_554860.pth.
[INFO][09:09:00]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:09:00]: [Client #98] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_98_554860.pth.
[INFO][09:09:00]: [Client #98] Model trained.
[INFO][09:09:01]: [Client #98] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:01]: [Server #554754] Received 0.26 MB of payload data from client #98 (simulated).
[INFO][09:09:02]: [Client #258] Woke up.
[INFO][09:09:02]: [Client #258] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554853.pth.
[INFO][09:09:02]: [Client #258] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554853.pth.
[INFO][09:09:02]: [Client #258] Model trained.
[INFO][09:09:02]: [Client #258] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:02]: [Server #554754] Received 0.26 MB of payload data from client #258 (simulated).
[INFO][09:09:02]: [Server #554754] Selecting client #424 for training.
[INFO][09:09:02]: [Server #554754] Sending the current model to client #424 (simulated).
[INFO][09:09:02]: [Server #554754] Sending 0.26 MB of payload data to client #424 (simulated).
[INFO][09:09:02]: [Server #554754] Selecting client #127 for training.
[INFO][09:09:02]: [Server #554754] Sending the current model to client #127 (simulated).
[INFO][09:09:02]: [Server #554754] Sending 0.26 MB of payload data to client #127 (simulated).
[INFO][09:09:02]: [Client #424] Selected by the server.
[INFO][09:09:02]: [Client #424] Loading its data source...
[INFO][09:09:02]: Data source: FEMNIST
[INFO][09:09:02]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:09:02]: [Client #127] Selected by the server.
[INFO][09:09:02]: [Client #127] Loading its data source...
[INFO][09:09:02]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/424.zip.
[INFO][09:09:02]: Data source: FEMNIST
[INFO][09:09:02]: [Client #127] Dataset size: 161
[INFO][09:09:02]: [Client #127] Sampler: all_inclusive
[INFO][09:09:02]: [Client #127] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:02]: [93m[1m[Client #127] Started training in communication round #10.[0m

2.7%
5.5%
8.2%
11.0%
13.7%
16.4%
19.2%
21.9%
24.7%
27.4%
30.1%
32.9%
35.6%
38.4%
41.1%
43.8%
46.6%
49.3%
52.1%
54.8%
57.5%
60.3%
63.0%
65.7%
68.5%
71.2%
74.0%
76.7%
79.4%
82.2%
84.9%
87.7%
90.4%
93.1%
95.9%
98.6%
100.0%[INFO][09:09:03]: Decompressing the dataset downloaded.
[INFO][09:09:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/424.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:09:03]: [Client #424] Dataset size: 160
[INFO][09:09:03]: [Client #424] Sampler: all_inclusive
[INFO][09:09:03]: [Client #424] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:03]: [93m[1m[Client #424] Started training in communication round #10.[0m

[INFO][09:09:04]: [Client #127] Loading the dataset.
[INFO][09:09:04]: [Client #424] Loading the dataset.
[INFO][09:09:10]: [Client #127] Epoch: [1/5][0/17]	Loss: 1.361782
[INFO][09:09:10]: [Client #127] Epoch: [1/5][10/17]	Loss: 1.615669
[INFO][09:09:10]: [Client #424] Epoch: [1/5][0/16]	Loss: 2.065506
[INFO][09:09:10]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][09:09:10]: [Client #424] Epoch: [1/5][10/16]	Loss: 0.489010
[INFO][09:09:10]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][09:09:10]: [Client #424] Woke up.
[INFO][09:09:10]: [Client #424] Epoch: [2/5][0/16]	Loss: 1.029191
[INFO][09:09:10]: [Client #424] Epoch: [2/5][10/16]	Loss: 1.793844
[INFO][09:09:10]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][09:09:10]: [Client #424] Woke up.
[INFO][09:09:10]: [Client #424] Epoch: [3/5][0/16]	Loss: 0.846647
[INFO][09:09:10]: [Client #424] Epoch: [3/5][10/16]	Loss: 1.766591
[INFO][09:09:11]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][09:09:11]: [Client #424] Woke up.
[INFO][09:09:11]: [Client #424] Epoch: [4/5][0/16]	Loss: 2.452119
[INFO][09:09:11]: [Client #424] Epoch: [4/5][10/16]	Loss: 1.500983
[INFO][09:09:11]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][09:09:11]: [Client #424] Woke up.
[INFO][09:09:11]: [Client #424] Epoch: [5/5][0/16]	Loss: 1.042100
[INFO][09:09:11]: [Client #424] Epoch: [5/5][10/16]	Loss: 1.914664
[INFO][09:09:11]: [Client #424] Going to sleep for 0.07 seconds.
[INFO][09:09:11]: [Client #424] Woke up.
[INFO][09:09:11]: [Client #424] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_424_554853.pth.
[INFO][09:09:11]: [Client #127] Woke up.
[INFO][09:09:11]: [Client #127] Epoch: [2/5][0/17]	Loss: 1.582234
[INFO][09:09:11]: [Client #127] Epoch: [2/5][10/17]	Loss: 1.772623
[INFO][09:09:11]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][09:09:12]: [Client #424] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_424_554853.pth.
[INFO][09:09:12]: [Client #424] Model trained.
[INFO][09:09:12]: [Client #424] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:12]: [Server #554754] Received 0.26 MB of payload data from client #424 (simulated).
[INFO][09:09:13]: [Client #127] Woke up.
[INFO][09:09:13]: [Client #127] Epoch: [3/5][0/17]	Loss: 2.277732
[INFO][09:09:13]: [Client #127] Epoch: [3/5][10/17]	Loss: 1.205575
[INFO][09:09:13]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][09:09:14]: [Client #127] Woke up.
[INFO][09:09:14]: [Client #127] Epoch: [4/5][0/17]	Loss: 1.237870
[INFO][09:09:14]: [Client #127] Epoch: [4/5][10/17]	Loss: 1.317141
[INFO][09:09:14]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][09:09:15]: [Client #127] Woke up.
[INFO][09:09:15]: [Client #127] Epoch: [5/5][0/17]	Loss: 2.300605
[INFO][09:09:15]: [Client #127] Epoch: [5/5][10/17]	Loss: 2.949301
[INFO][09:09:15]: [Client #127] Going to sleep for 1.24 seconds.
[INFO][09:09:17]: [Client #127] Woke up.
[INFO][09:09:17]: [Client #127] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_127_554860.pth.
[INFO][09:09:17]: [Client #127] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_127_554860.pth.
[INFO][09:09:17]: [Client #127] Model trained.
[INFO][09:09:17]: [Client #127] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:17]: [Server #554754] Received 0.26 MB of payload data from client #127 (simulated).
[INFO][09:09:17]: [Server #554754] Selecting client #349 for training.
[INFO][09:09:17]: [Server #554754] Sending the current model to client #349 (simulated).
[INFO][09:09:17]: [Server #554754] Sending 0.26 MB of payload data to client #349 (simulated).
[INFO][09:09:17]: [Server #554754] Selecting client #269 for training.
[INFO][09:09:17]: [Server #554754] Sending the current model to client #269 (simulated).
[INFO][09:09:17]: [Server #554754] Sending 0.26 MB of payload data to client #269 (simulated).
[INFO][09:09:17]: [Client #269] Selected by the server.
[INFO][09:09:17]: [Client #349] Selected by the server.
[INFO][09:09:17]: [Client #269] Loading its data source...
[INFO][09:09:17]: [Client #349] Loading its data source...
[INFO][09:09:17]: Data source: FEMNIST
[INFO][09:09:17]: Data source: FEMNIST
[INFO][09:09:17]: [Client #349] Dataset size: 162
[INFO][09:09:17]: [Client #349] Sampler: all_inclusive
[INFO][09:09:17]: [Client #349] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:17]: [93m[1m[Client #349] Started training in communication round #10.[0m
[INFO][09:09:17]: [Client #269] Dataset size: 163
[INFO][09:09:17]: [Client #269] Sampler: all_inclusive
[INFO][09:09:17]: [Client #269] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:17]: [93m[1m[Client #269] Started training in communication round #10.[0m
[INFO][09:09:19]: [Client #349] Loading the dataset.
[INFO][09:09:19]: [Client #269] Loading the dataset.
[INFO][09:09:25]: [Client #349] Epoch: [1/5][0/17]	Loss: 1.491754
[INFO][09:09:25]: [Client #349] Epoch: [1/5][10/17]	Loss: 0.738146
[INFO][09:09:25]: [Client #269] Epoch: [1/5][0/17]	Loss: 1.298540
[INFO][09:09:25]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:09:25]: [Client #269] Epoch: [1/5][10/17]	Loss: 1.757213
[INFO][09:09:25]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][09:09:26]: [Client #269] Woke up.
[INFO][09:09:26]: [Client #269] Epoch: [2/5][0/17]	Loss: 1.511842
[INFO][09:09:26]: [Client #269] Epoch: [2/5][10/17]	Loss: 1.698249
[INFO][09:09:26]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][09:09:26]: [Client #269] Woke up.
[INFO][09:09:26]: [Client #269] Epoch: [3/5][0/17]	Loss: 1.329308
[INFO][09:09:26]: [Client #269] Epoch: [3/5][10/17]	Loss: 0.867917
[INFO][09:09:27]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][09:09:27]: [Client #269] Woke up.
[INFO][09:09:27]: [Client #269] Epoch: [4/5][0/17]	Loss: 1.293534
[INFO][09:09:27]: [Client #269] Epoch: [4/5][10/17]	Loss: 1.437092
[INFO][09:09:27]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][09:09:28]: [Client #269] Woke up.
[INFO][09:09:28]: [Client #269] Epoch: [5/5][0/17]	Loss: 1.067512
[INFO][09:09:28]: [Client #269] Epoch: [5/5][10/17]	Loss: 1.368784
[INFO][09:09:28]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][09:09:29]: [Client #269] Woke up.
[INFO][09:09:29]: [Client #269] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_269_554860.pth.
[INFO][09:09:29]: [Client #349] Woke up.
[INFO][09:09:29]: [Client #349] Epoch: [2/5][0/17]	Loss: 0.507350
[INFO][09:09:29]: [Client #349] Epoch: [2/5][10/17]	Loss: 0.592064
[INFO][09:09:29]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:09:29]: [Client #269] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_269_554860.pth.
[INFO][09:09:29]: [Client #269] Model trained.
[INFO][09:09:29]: [Client #269] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:29]: [Server #554754] Received 0.26 MB of payload data from client #269 (simulated).
[INFO][09:09:33]: [Client #349] Woke up.
[INFO][09:09:33]: [Client #349] Epoch: [3/5][0/17]	Loss: 0.713615
[INFO][09:09:33]: [Client #349] Epoch: [3/5][10/17]	Loss: 1.629674
[INFO][09:09:33]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:09:37]: [Client #349] Woke up.
[INFO][09:09:37]: [Client #349] Epoch: [4/5][0/17]	Loss: 1.471395
[INFO][09:09:37]: [Client #349] Epoch: [4/5][10/17]	Loss: 1.411543
[INFO][09:09:37]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:09:41]: [Client #349] Woke up.
[INFO][09:09:41]: [Client #349] Epoch: [5/5][0/17]	Loss: 0.732265
[INFO][09:09:41]: [Client #349] Epoch: [5/5][10/17]	Loss: 0.878515
[INFO][09:09:41]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:09:45]: [Client #349] Woke up.
[INFO][09:09:45]: [Client #349] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554853.pth.
[INFO][09:09:46]: [Client #349] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554853.pth.
[INFO][09:09:46]: [Client #349] Model trained.
[INFO][09:09:46]: [Client #349] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:09:46]: [Server #554754] Received 0.26 MB of payload data from client #349 (simulated).
[INFO][09:09:46]: [Server #554754] Selecting client #475 for training.
[INFO][09:09:46]: [Server #554754] Sending the current model to client #475 (simulated).
[INFO][09:09:46]: [Server #554754] Sending 0.26 MB of payload data to client #475 (simulated).
[INFO][09:09:46]: [Server #554754] Selecting client #311 for training.
[INFO][09:09:46]: [Server #554754] Sending the current model to client #311 (simulated).
[INFO][09:09:46]: [Server #554754] Sending 0.26 MB of payload data to client #311 (simulated).
[INFO][09:09:46]: [Client #475] Selected by the server.
[INFO][09:09:46]: [Client #475] Loading its data source...
[INFO][09:09:46]: Data source: FEMNIST
[INFO][09:09:46]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:09:46]: [Client #311] Selected by the server.
[INFO][09:09:46]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/475.zip.
[INFO][09:09:46]: [Client #311] Loading its data source...
[INFO][09:09:46]: Data source: FEMNIST
[INFO][09:09:46]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:09:46]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/311.zip.

1.6%
3.2%
4.8%
6.4%
8.0%
9.6%
11.2%
12.8%
14.4%
15.9%
17.5%
19.1%
20.7%
22.3%
23.9%
25.5%
2.7%
5.4%
8.1%
10.9%
13.6%
16.3%
19.0%
21.7%
24.4%
27.2%
29.9%
32.6%
35.3%
38.0%
40.7%
43.5%
27.1%
28.7%
30.3%
31.9%
46.2%
33.5%
35.1%
48.9%
36.7%
38.3%
51.6%
39.9%
54.3%
41.5%
57.0%
43.1%
59.8%
44.7%
62.5%
46.2%
65.2%
47.8%
67.9%
49.4%
51.0%
52.6%
54.2%
55.8%
57.4%
59.0%
60.6%
62.2%
63.8%
65.4%
67.0%
68.6%
70.2%
71.8%
73.4%
75.0%
76.5%
78.1%
79.7%
81.3%
82.9%
84.5%
86.1%
70.6%
87.7%
89.3%
73.3%
90.9%
76.1%
92.5%
94.1%
78.8%
81.5%
95.7%
84.2%
97.3%
86.9%
98.9%
89.6%
92.4%
95.1%
97.8%
100.0%
100.0%[INFO][09:09:46]: Decompressing the dataset downloaded.
[INFO][09:09:46]: Decompressing the dataset downloaded.
[INFO][09:09:46]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/311.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:09:46]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/475.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:09:46]: [Client #475] Dataset size: 153
[INFO][09:09:46]: [Client #475] Sampler: all_inclusive
[INFO][09:09:46]: [Client #475] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:46]: [93m[1m[Client #475] Started training in communication round #10.[0m

[INFO][09:09:46]: [Client #311] Dataset size: 288
[INFO][09:09:46]: [Client #311] Sampler: all_inclusive
[INFO][09:09:46]: [Client #311] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:09:46]: [93m[1m[Client #311] Started training in communication round #10.[0m

[INFO][09:09:48]: [Client #475] Loading the dataset.
[INFO][09:09:48]: [Client #311] Loading the dataset.
[INFO][09:09:54]: [Client #475] Epoch: [1/5][0/16]	Loss: 1.063179
[INFO][09:09:54]: [Client #311] Epoch: [1/5][0/29]	Loss: 3.217496
[INFO][09:09:54]: [Client #475] Epoch: [1/5][10/16]	Loss: 1.448341
[INFO][09:09:54]: [Client #311] Epoch: [1/5][10/29]	Loss: 1.996269
[INFO][09:09:54]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:09:54]: [Client #311] Epoch: [1/5][20/29]	Loss: 1.919609
[INFO][09:09:54]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:10:05]: [Client #311] Woke up.
[INFO][09:10:05]: [Client #311] Epoch: [2/5][0/29]	Loss: 2.975988
[INFO][09:10:05]: [Client #311] Epoch: [2/5][10/29]	Loss: 2.618389
[INFO][09:10:05]: [Client #311] Epoch: [2/5][20/29]	Loss: 2.555252
[INFO][09:10:05]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:10:09]: [Client #475] Woke up.
[INFO][09:10:09]: [Client #475] Epoch: [2/5][0/16]	Loss: 0.762521
[INFO][09:10:09]: [Client #475] Epoch: [2/5][10/16]	Loss: 1.902313
[INFO][09:10:09]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:10:16]: [Client #311] Woke up.
[INFO][09:10:16]: [Client #311] Epoch: [3/5][0/29]	Loss: 1.917963
[INFO][09:10:16]: [Client #311] Epoch: [3/5][10/29]	Loss: 2.670829
[INFO][09:10:16]: [Client #311] Epoch: [3/5][20/29]	Loss: 1.599478
[INFO][09:10:16]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:10:25]: [Client #475] Woke up.
[INFO][09:10:25]: [Client #475] Epoch: [3/5][0/16]	Loss: 1.062840
[INFO][09:10:25]: [Client #475] Epoch: [3/5][10/16]	Loss: 2.856574
[INFO][09:10:25]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:10:27]: [Client #311] Woke up.
[INFO][09:10:27]: [Client #311] Epoch: [4/5][0/29]	Loss: 1.704261
[INFO][09:10:28]: [Client #311] Epoch: [4/5][10/29]	Loss: 2.076366
[INFO][09:10:28]: [Client #311] Epoch: [4/5][20/29]	Loss: 1.524983
[INFO][09:10:28]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:10:39]: [Client #311] Woke up.
[INFO][09:10:39]: [Client #311] Epoch: [5/5][0/29]	Loss: 1.210948
[INFO][09:10:39]: [Client #311] Epoch: [5/5][10/29]	Loss: 1.704433
[INFO][09:10:39]: [Client #311] Epoch: [5/5][20/29]	Loss: 0.670106
[INFO][09:10:39]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:10:40]: [Client #475] Woke up.
[INFO][09:10:40]: [Client #475] Epoch: [4/5][0/16]	Loss: 1.820953
[INFO][09:10:40]: [Client #475] Epoch: [4/5][10/16]	Loss: 1.651826
[INFO][09:10:40]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:10:50]: [Client #311] Woke up.
[INFO][09:10:50]: [Client #311] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:10:51]: [Client #311] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:10:51]: [Client #311] Model trained.
[INFO][09:10:51]: [Client #311] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:10:51]: [Server #554754] Received 0.26 MB of payload data from client #311 (simulated).
[INFO][09:10:56]: [Client #475] Woke up.
[INFO][09:10:56]: [Client #475] Epoch: [5/5][0/16]	Loss: 1.693164
[INFO][09:10:56]: [Client #475] Epoch: [5/5][10/16]	Loss: 2.034696
[INFO][09:10:56]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:11:11]: [Client #475] Woke up.
[INFO][09:11:11]: [Client #475] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:11:12]: [Client #475] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:11:12]: [Client #475] Model trained.
[INFO][09:11:12]: [Client #475] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:11:12]: [Server #554754] Received 0.26 MB of payload data from client #475 (simulated).
[INFO][09:11:12]: [Server #554754] Selecting client #419 for training.
[INFO][09:11:12]: [Server #554754] Sending the current model to client #419 (simulated).
[INFO][09:11:12]: [Server #554754] Sending 0.26 MB of payload data to client #419 (simulated).
[INFO][09:11:12]: [Server #554754] Selecting client #4 for training.
[INFO][09:11:12]: [Server #554754] Sending the current model to client #4 (simulated).
[INFO][09:11:12]: [Server #554754] Sending 0.26 MB of payload data to client #4 (simulated).
[INFO][09:11:12]: [Client #419] Selected by the server.
[INFO][09:11:12]: [Client #419] Loading its data source...
[INFO][09:11:12]: Data source: FEMNIST
[INFO][09:11:12]: [Client #4] Selected by the server.
[INFO][09:11:12]: [Client #4] Loading its data source...
[INFO][09:11:12]: Data source: FEMNIST
[INFO][09:11:12]: [Client #419] Dataset size: 145
[INFO][09:11:12]: [Client #419] Sampler: all_inclusive
[INFO][09:11:12]: [Client #419] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:11:12]: [93m[1m[Client #419] Started training in communication round #10.[0m
[INFO][09:11:12]: [Client #4] Dataset size: 159
[INFO][09:11:12]: [Client #4] Sampler: all_inclusive
[INFO][09:11:12]: [Client #4] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:11:12]: [93m[1m[Client #4] Started training in communication round #10.[0m
[INFO][09:11:14]: [Client #419] Loading the dataset.
[INFO][09:11:14]: [Client #4] Loading the dataset.
[INFO][09:11:19]: [Client #419] Epoch: [1/5][0/15]	Loss: 2.020509
[INFO][09:11:19]: [Client #4] Epoch: [1/5][0/16]	Loss: 1.881718
[INFO][09:11:19]: [Client #419] Epoch: [1/5][10/15]	Loss: 1.717043
[INFO][09:11:20]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:11:20]: [Client #4] Epoch: [1/5][10/16]	Loss: 1.832598
[INFO][09:11:20]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][09:11:20]: [Client #4] Woke up.
[INFO][09:11:20]: [Client #4] Epoch: [2/5][0/16]	Loss: 1.473593
[INFO][09:11:20]: [Client #4] Epoch: [2/5][10/16]	Loss: 1.948683
[INFO][09:11:20]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][09:11:21]: [Client #4] Woke up.
[INFO][09:11:21]: [Client #4] Epoch: [3/5][0/16]	Loss: 2.014960
[INFO][09:11:21]: [Client #4] Epoch: [3/5][10/16]	Loss: 1.167596
[INFO][09:11:21]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][09:11:21]: [Client #4] Woke up.
[INFO][09:11:21]: [Client #4] Epoch: [4/5][0/16]	Loss: 2.077307
[INFO][09:11:21]: [Client #4] Epoch: [4/5][10/16]	Loss: 1.382368
[INFO][09:11:21]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][09:11:22]: [Client #4] Woke up.
[INFO][09:11:22]: [Client #4] Epoch: [5/5][0/16]	Loss: 1.410365
[INFO][09:11:22]: [Client #4] Epoch: [5/5][10/16]	Loss: 1.345665
[INFO][09:11:22]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][09:11:22]: [Client #4] Woke up.
[INFO][09:11:22]: [Client #4] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_4_554860.pth.
[INFO][09:11:23]: [Client #4] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_4_554860.pth.
[INFO][09:11:23]: [Client #4] Model trained.
[INFO][09:11:23]: [Client #4] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:11:23]: [Server #554754] Received 0.26 MB of payload data from client #4 (simulated).
[INFO][09:11:24]: [Client #419] Woke up.
[INFO][09:11:24]: [Client #419] Epoch: [2/5][0/15]	Loss: 1.029498
[INFO][09:11:24]: [Client #419] Epoch: [2/5][10/15]	Loss: 1.238669
[INFO][09:11:24]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:11:29]: [Client #419] Woke up.
[INFO][09:11:29]: [Client #419] Epoch: [3/5][0/15]	Loss: 1.252683
[INFO][09:11:29]: [Client #419] Epoch: [3/5][10/15]	Loss: 1.703617
[INFO][09:11:29]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:11:34]: [Client #419] Woke up.
[INFO][09:11:34]: [Client #419] Epoch: [4/5][0/15]	Loss: 1.380498
[INFO][09:11:34]: [Client #419] Epoch: [4/5][10/15]	Loss: 1.625645
[INFO][09:11:34]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:11:39]: [Client #419] Woke up.
[INFO][09:11:39]: [Client #419] Epoch: [5/5][0/15]	Loss: 1.368969
[INFO][09:11:39]: [Client #419] Epoch: [5/5][10/15]	Loss: 1.735559
[INFO][09:11:39]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:11:44]: [Client #419] Woke up.
[INFO][09:11:44]: [Client #419] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:11:44]: [Client #419] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:11:44]: [Client #419] Model trained.
[INFO][09:11:44]: [Client #419] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:11:44]: [Server #554754] Received 0.26 MB of payload data from client #419 (simulated).
[INFO][09:11:44]: [Server #554754] Selecting client #495 for training.
[INFO][09:11:44]: [Server #554754] Sending the current model to client #495 (simulated).
[INFO][09:11:44]: [Server #554754] Sending 0.26 MB of payload data to client #495 (simulated).
[INFO][09:11:44]: [Server #554754] Selecting client #39 for training.
[INFO][09:11:44]: [Server #554754] Sending the current model to client #39 (simulated).
[INFO][09:11:44]: [Server #554754] Sending 0.26 MB of payload data to client #39 (simulated).
[INFO][09:11:44]: [Client #495] Selected by the server.
[INFO][09:11:44]: [Client #495] Loading its data source...
[INFO][09:11:44]: Data source: FEMNIST
[INFO][09:11:44]: [Client #39] Selected by the server.
[INFO][09:11:44]: [Client #39] Loading its data source...
[INFO][09:11:44]: Data source: FEMNIST
[INFO][09:11:44]: [Client #495] Dataset size: 152
[INFO][09:11:44]: [Client #495] Sampler: all_inclusive
[INFO][09:11:44]: [Client #495] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:11:44]: [93m[1m[Client #495] Started training in communication round #10.[0m
[INFO][09:11:44]: [Client #39] Dataset size: 165
[INFO][09:11:44]: [Client #39] Sampler: all_inclusive
[INFO][09:11:44]: [Client #39] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:11:44]: [93m[1m[Client #39] Started training in communication round #10.[0m
[INFO][09:11:46]: [Client #39] Loading the dataset.
[INFO][09:11:46]: [Client #495] Loading the dataset.
[INFO][09:11:51]: [Client #39] Epoch: [1/5][0/17]	Loss: 1.971442
[INFO][09:11:52]: [Client #495] Epoch: [1/5][0/16]	Loss: 0.858720
[INFO][09:11:52]: [Client #39] Epoch: [1/5][10/17]	Loss: 0.884942
[INFO][09:11:52]: [Client #495] Epoch: [1/5][10/16]	Loss: 1.695362
[INFO][09:11:52]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][09:11:52]: [Client #39] Woke up.
[INFO][09:11:52]: [Client #495] Going to sleep for 0.59 seconds.
[INFO][09:11:52]: [Client #39] Epoch: [2/5][0/17]	Loss: 2.537742
[INFO][09:11:52]: [Client #39] Epoch: [2/5][10/17]	Loss: 0.974559
[INFO][09:11:52]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][09:11:52]: [Client #39] Woke up.
[INFO][09:11:52]: [Client #39] Epoch: [3/5][0/17]	Loss: 0.197464
[INFO][09:11:52]: [Client #39] Epoch: [3/5][10/17]	Loss: 0.755895
[INFO][09:11:52]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][09:11:52]: [Client #39] Woke up.
[INFO][09:11:52]: [Client #39] Epoch: [4/5][0/17]	Loss: 1.997156
[INFO][09:11:52]: [Client #39] Epoch: [4/5][10/17]	Loss: 1.300650
[INFO][09:11:52]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][09:11:52]: [Client #39] Woke up.
[INFO][09:11:52]: [Client #39] Epoch: [5/5][0/17]	Loss: 0.515172
[INFO][09:11:52]: [Client #39] Epoch: [5/5][10/17]	Loss: 0.730007
[INFO][09:11:52]: [Client #495] Woke up.
[INFO][09:11:52]: [Client #495] Epoch: [2/5][0/16]	Loss: 0.972526
[INFO][09:11:52]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][09:11:52]: [Client #39] Woke up.
[INFO][09:11:52]: [Client #39] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_39_554860.pth.
[INFO][09:11:52]: [Client #495] Epoch: [2/5][10/16]	Loss: 0.979665
[INFO][09:11:52]: [Client #495] Going to sleep for 0.59 seconds.
[INFO][09:11:53]: [Client #39] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_39_554860.pth.
[INFO][09:11:53]: [Client #39] Model trained.
[INFO][09:11:53]: [Client #39] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:11:53]: [Client #495] Woke up.
[INFO][09:11:53]: [Server #554754] Received 0.26 MB of payload data from client #39 (simulated).
[INFO][09:11:53]: [Client #495] Epoch: [3/5][0/16]	Loss: 1.321078
[INFO][09:11:53]: [Client #495] Epoch: [3/5][10/16]	Loss: 1.525223
[INFO][09:11:53]: [Client #495] Going to sleep for 0.59 seconds.
[INFO][09:11:54]: [Client #495] Woke up.
[INFO][09:11:54]: [Client #495] Epoch: [4/5][0/16]	Loss: 1.644027
[INFO][09:11:54]: [Client #495] Epoch: [4/5][10/16]	Loss: 1.757272
[INFO][09:11:54]: [Client #495] Going to sleep for 0.59 seconds.
[INFO][09:11:54]: [Client #495] Woke up.
[INFO][09:11:54]: [Client #495] Epoch: [5/5][0/16]	Loss: 2.596151
[INFO][09:11:55]: [Client #495] Epoch: [5/5][10/16]	Loss: 0.833563
[INFO][09:11:55]: [Client #495] Going to sleep for 0.59 seconds.
[INFO][09:11:55]: [Client #495] Woke up.
[INFO][09:11:55]: [Client #495] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_495_554853.pth.
[INFO][09:11:56]: [Client #495] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_495_554853.pth.
[INFO][09:11:56]: [Client #495] Model trained.
[INFO][09:11:56]: [Client #495] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:11:56]: [Server #554754] Received 0.26 MB of payload data from client #495 (simulated).
[INFO][09:11:56]: [Server #554754] Adding client #39 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #424 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #421 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #4 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #495 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #269 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #248 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #127 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #98 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Adding client #34 to the list of clients for aggregation.
[INFO][09:11:56]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.13153269 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18329053 0.         0.
 0.         0.         0.11789234 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07598256 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.62965017 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0883066  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17590541 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09451874 0.         0.         0.12220119 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1762402  0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.13153269 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18329053 0.         0.
 0.         0.         0.11789234 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07598256 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.62965017 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0883066  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17590541 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09451874 0.         0.         0.12220119 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1762402  0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:12:40]: [Server #554754] Global model accuracy: 46.99%

[INFO][09:12:40]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_10.pth.
[INFO][09:12:40]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_10.pth.
[INFO][09:12:40]: [93m[1m
[Server #554754] Starting round 11/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.002      0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.10305344
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.002
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.002      0.002      0.002      0.04730139 0.002
 0.08247423 0.002      0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.09557522 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.08314607 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.002      0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.09355391 0.04451314 0.002      0.002      0.04760383
 0.002      0.002      0.002      0.002      0.002      0.05003032
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.002      0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04760433 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.04912068 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.04881747 0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.002      0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.05019947 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.18702065 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.002      0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.002      0.04851425 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.002      0.002      0.002      0.002      0.10384615 0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.05418883 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][09:12:41]: [Server #554754] Selected clients: [158 473   5 411 430 216 126 401 235  66]
[INFO][09:12:41]: [Server #554754] Selecting client #158 for training.
[INFO][09:12:41]: [Server #554754] Sending the current model to client #158 (simulated).
[INFO][09:12:41]: [Server #554754] Sending 0.26 MB of payload data to client #158 (simulated).
[INFO][09:12:41]: [Server #554754] Selecting client #473 for training.
[INFO][09:12:41]: [Server #554754] Sending the current model to client #473 (simulated).
[INFO][09:12:41]: [Server #554754] Sending 0.26 MB of payload data to client #473 (simulated).
[INFO][09:12:41]: [Client #158] Selected by the server.
[INFO][09:12:41]: [Client #158] Loading its data source...
[INFO][09:12:41]: Data source: FEMNIST
[INFO][09:12:41]: [Client #473] Selected by the server.
[INFO][09:12:41]: [Client #473] Loading its data source...
[INFO][09:12:41]: Data source: FEMNIST
[INFO][09:12:41]: [Client #473] Dataset size: 163
[INFO][09:12:41]: [Client #473] Sampler: all_inclusive
[INFO][09:12:41]: [Client #473] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:12:41]: [Client #158] Dataset size: 162
[INFO][09:12:41]: [Client #158] Sampler: all_inclusive
[INFO][09:12:41]: [93m[1m[Client #473] Started training in communication round #11.[0m
[INFO][09:12:41]: [Client #158] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:12:41]: [93m[1m[Client #158] Started training in communication round #11.[0m
[INFO][09:12:43]: [Client #158] Loading the dataset.
[INFO][09:12:43]: [Client #473] Loading the dataset.
[INFO][09:12:48]: [Client #473] Epoch: [1/5][0/17]	Loss: 1.871362
[INFO][09:12:48]: [Client #158] Epoch: [1/5][0/17]	Loss: 1.623919
[INFO][09:12:48]: [Client #473] Epoch: [1/5][10/17]	Loss: 1.731919
[INFO][09:12:48]: [Client #158] Epoch: [1/5][10/17]	Loss: 0.417384
[INFO][09:12:48]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][09:12:48]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][09:12:49]: [Client #473] Woke up.
[INFO][09:12:49]: [Client #473] Epoch: [2/5][0/17]	Loss: 1.284293
[INFO][09:12:49]: [Client #473] Epoch: [2/5][10/17]	Loss: 1.939871
[INFO][09:12:49]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][09:12:50]: [Client #158] Woke up.
[INFO][09:12:50]: [Client #158] Epoch: [2/5][0/17]	Loss: 1.925977
[INFO][09:12:50]: [Client #158] Epoch: [2/5][10/17]	Loss: 1.533710
[INFO][09:12:50]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][09:12:50]: [Client #473] Woke up.
[INFO][09:12:50]: [Client #473] Epoch: [3/5][0/17]	Loss: 0.626400
[INFO][09:12:50]: [Client #473] Epoch: [3/5][10/17]	Loss: 1.211842
[INFO][09:12:50]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][09:12:51]: [Client #473] Woke up.
[INFO][09:12:51]: [Client #473] Epoch: [4/5][0/17]	Loss: 1.478872
[INFO][09:12:51]: [Client #473] Epoch: [4/5][10/17]	Loss: 1.004738
[INFO][09:12:51]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][09:12:51]: [Client #158] Woke up.
[INFO][09:12:51]: [Client #158] Epoch: [3/5][0/17]	Loss: 0.797729
[INFO][09:12:51]: [Client #158] Epoch: [3/5][10/17]	Loss: 0.415272
[INFO][09:12:51]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][09:12:52]: [Client #473] Woke up.
[INFO][09:12:52]: [Client #473] Epoch: [5/5][0/17]	Loss: 1.494268
[INFO][09:12:52]: [Client #473] Epoch: [5/5][10/17]	Loss: 1.688403
[INFO][09:12:52]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][09:12:53]: [Client #473] Woke up.
[INFO][09:12:53]: [Client #473] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554860.pth.
[INFO][09:12:53]: [Client #158] Woke up.
[INFO][09:12:53]: [Client #158] Epoch: [4/5][0/17]	Loss: 0.152371
[INFO][09:12:53]: [Client #158] Epoch: [4/5][10/17]	Loss: 1.732717
[INFO][09:12:53]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][09:12:53]: [Client #473] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554860.pth.
[INFO][09:12:53]: [Client #473] Model trained.
[INFO][09:12:53]: [Client #473] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:12:53]: [Server #554754] Received 0.26 MB of payload data from client #473 (simulated).
[INFO][09:12:54]: [Client #158] Woke up.
[INFO][09:12:54]: [Client #158] Epoch: [5/5][0/17]	Loss: 1.860362
[INFO][09:12:54]: [Client #158] Epoch: [5/5][10/17]	Loss: 0.753541
[INFO][09:12:54]: [Client #158] Going to sleep for 1.39 seconds.
[INFO][09:12:56]: [Client #158] Woke up.
[INFO][09:12:56]: [Client #158] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_158_554853.pth.
[INFO][09:12:57]: [Client #158] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_158_554853.pth.
[INFO][09:12:57]: [Client #158] Model trained.
[INFO][09:12:57]: [Client #158] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:12:57]: [Server #554754] Received 0.26 MB of payload data from client #158 (simulated).
[INFO][09:12:57]: [Server #554754] Selecting client #5 for training.
[INFO][09:12:57]: [Server #554754] Sending the current model to client #5 (simulated).
[INFO][09:12:57]: [Server #554754] Sending 0.26 MB of payload data to client #5 (simulated).
[INFO][09:12:57]: [Server #554754] Selecting client #411 for training.
[INFO][09:12:57]: [Server #554754] Sending the current model to client #411 (simulated).
[INFO][09:12:57]: [Server #554754] Sending 0.26 MB of payload data to client #411 (simulated).
[INFO][09:12:57]: [Client #5] Selected by the server.
[INFO][09:12:57]: [Client #5] Loading its data source...
[INFO][09:12:57]: Data source: FEMNIST
[INFO][09:12:57]: [Client #411] Selected by the server.
[INFO][09:12:57]: [Client #411] Loading its data source...
[INFO][09:12:57]: Data source: FEMNIST
[INFO][09:12:57]: [Client #5] Dataset size: 162
[INFO][09:12:57]: [Client #5] Sampler: all_inclusive
[INFO][09:12:57]: [Client #5] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:12:57]: [93m[1m[Client #5] Started training in communication round #11.[0m
[INFO][09:12:57]: [Client #411] Dataset size: 317
[INFO][09:12:57]: [Client #411] Sampler: all_inclusive
[INFO][09:12:57]: [Client #411] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:12:57]: [93m[1m[Client #411] Started training in communication round #11.[0m
[INFO][09:12:58]: [Client #5] Loading the dataset.
[INFO][09:12:59]: [Client #411] Loading the dataset.
[INFO][09:13:04]: [Client #5] Epoch: [1/5][0/17]	Loss: 2.314873
[INFO][09:13:04]: [Client #411] Epoch: [1/5][0/32]	Loss: 2.624423
[INFO][09:13:04]: [Client #5] Epoch: [1/5][10/17]	Loss: 1.646347
[INFO][09:13:04]: [Client #411] Epoch: [1/5][10/32]	Loss: 1.980187
[INFO][09:13:04]: [Client #5] Going to sleep for 0.17 seconds.
[INFO][09:13:04]: [Client #411] Epoch: [1/5][20/32]	Loss: 3.007886
[INFO][09:13:04]: [Client #411] Epoch: [1/5][30/32]	Loss: 2.207804
[INFO][09:13:04]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][09:13:04]: [Client #5] Woke up.
[INFO][09:13:04]: [Client #5] Epoch: [2/5][0/17]	Loss: 0.693427
[INFO][09:13:04]: [Client #411] Woke up.
[INFO][09:13:04]: [Client #411] Epoch: [2/5][0/32]	Loss: 1.938529
[INFO][09:13:04]: [Client #5] Epoch: [2/5][10/17]	Loss: 0.712651
[INFO][09:13:04]: [Client #5] Going to sleep for 0.17 seconds.
[INFO][09:13:04]: [Client #411] Epoch: [2/5][10/32]	Loss: 2.629290
[INFO][09:13:05]: [Client #411] Epoch: [2/5][20/32]	Loss: 2.426711
[INFO][09:13:05]: [Client #5] Woke up.
[INFO][09:13:05]: [Client #411] Epoch: [2/5][30/32]	Loss: 1.725855
[INFO][09:13:05]: [Client #5] Epoch: [3/5][0/17]	Loss: 0.961527
[INFO][09:13:05]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][09:13:05]: [Client #5] Epoch: [3/5][10/17]	Loss: 1.205531
[INFO][09:13:05]: [Client #411] Woke up.
[INFO][09:13:05]: [Client #5] Going to sleep for 0.17 seconds.
[INFO][09:13:05]: [Client #411] Epoch: [3/5][0/32]	Loss: 1.469794
[INFO][09:13:05]: [Client #411] Epoch: [3/5][10/32]	Loss: 1.285722
[INFO][09:13:05]: [Client #411] Epoch: [3/5][20/32]	Loss: 0.827045
[INFO][09:13:05]: [Client #5] Woke up.
[INFO][09:13:05]: [Client #5] Epoch: [4/5][0/17]	Loss: 1.412733
[INFO][09:13:05]: [Client #411] Epoch: [3/5][30/32]	Loss: 1.274761
[INFO][09:13:05]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][09:13:05]: [Client #5] Epoch: [4/5][10/17]	Loss: 0.635307
[INFO][09:13:05]: [Client #5] Going to sleep for 0.17 seconds.
[INFO][09:13:05]: [Client #411] Woke up.
[INFO][09:13:05]: [Client #411] Epoch: [4/5][0/32]	Loss: 2.609973
[INFO][09:13:05]: [Client #411] Epoch: [4/5][10/32]	Loss: 1.356493
[INFO][09:13:05]: [Client #5] Woke up.
[INFO][09:13:05]: [Client #5] Epoch: [5/5][0/17]	Loss: 1.286063
[INFO][09:13:05]: [Client #411] Epoch: [4/5][20/32]	Loss: 1.400779
[INFO][09:13:05]: [Client #5] Epoch: [5/5][10/17]	Loss: 2.488541
[INFO][09:13:05]: [Client #411] Epoch: [4/5][30/32]	Loss: 1.120822
[INFO][09:13:05]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][09:13:05]: [Client #5] Going to sleep for 0.17 seconds.
[INFO][09:13:06]: [Client #411] Woke up.
[INFO][09:13:06]: [Client #411] Epoch: [5/5][0/32]	Loss: 1.812794
[INFO][09:13:06]: [Client #5] Woke up.
[INFO][09:13:06]: [Client #5] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_5_554853.pth.
[INFO][09:13:06]: [Client #411] Epoch: [5/5][10/32]	Loss: 1.482597
[INFO][09:13:06]: [Client #411] Epoch: [5/5][20/32]	Loss: 1.020241
[INFO][09:13:06]: [Client #411] Epoch: [5/5][30/32]	Loss: 1.579892
[INFO][09:13:06]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][09:13:06]: [Client #411] Woke up.
[INFO][09:13:06]: [Client #411] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554860.pth.
[INFO][09:13:06]: [Client #5] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_5_554853.pth.
[INFO][09:13:06]: [Client #5] Model trained.
[INFO][09:13:06]: [Client #5] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:13:06]: [Server #554754] Received 0.26 MB of payload data from client #5 (simulated).
[INFO][09:13:07]: [Client #411] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554860.pth.
[INFO][09:13:07]: [Client #411] Model trained.
[INFO][09:13:07]: [Client #411] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:13:07]: [Server #554754] Received 0.26 MB of payload data from client #411 (simulated).
[INFO][09:13:07]: [Server #554754] Selecting client #430 for training.
[INFO][09:13:07]: [Server #554754] Sending the current model to client #430 (simulated).
[INFO][09:13:07]: [Server #554754] Sending 0.26 MB of payload data to client #430 (simulated).
[INFO][09:13:07]: [Server #554754] Selecting client #216 for training.
[INFO][09:13:07]: [Server #554754] Sending the current model to client #216 (simulated).
[INFO][09:13:07]: [Server #554754] Sending 0.26 MB of payload data to client #216 (simulated).
[INFO][09:13:07]: [Client #430] Selected by the server.
[INFO][09:13:07]: [Client #216] Selected by the server.
[INFO][09:13:07]: [Client #216] Loading its data source...
[INFO][09:13:07]: [Client #430] Loading its data source...
[INFO][09:13:07]: Data source: FEMNIST
[INFO][09:13:07]: Data source: FEMNIST
[INFO][09:13:07]: [Client #430] Dataset size: 160
[INFO][09:13:07]: [Client #430] Sampler: all_inclusive
[INFO][09:13:07]: [Client #430] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:13:07]: [93m[1m[Client #430] Started training in communication round #11.[0m
[INFO][09:13:07]: [Client #216] Dataset size: 162
[INFO][09:13:07]: [Client #216] Sampler: all_inclusive
[INFO][09:13:07]: [Client #216] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:13:07]: [93m[1m[Client #216] Started training in communication round #11.[0m
[INFO][09:13:09]: [Client #430] Loading the dataset.
[INFO][09:13:09]: [Client #216] Loading the dataset.
[INFO][09:13:14]: [Client #216] Epoch: [1/5][0/17]	Loss: 1.390678
[INFO][09:13:14]: [Client #430] Epoch: [1/5][0/16]	Loss: 1.486065
[INFO][09:13:14]: [Client #216] Epoch: [1/5][10/17]	Loss: 0.390144
[INFO][09:13:14]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][09:13:14]: [Client #430] Epoch: [1/5][10/16]	Loss: 1.094954
[INFO][09:13:14]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][09:13:15]: [Client #216] Woke up.
[INFO][09:13:15]: [Client #216] Epoch: [2/5][0/17]	Loss: 1.749360
[INFO][09:13:15]: [Client #216] Epoch: [2/5][10/17]	Loss: 1.195349
[INFO][09:13:15]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][09:13:16]: [Client #216] Woke up.
[INFO][09:13:16]: [Client #216] Epoch: [3/5][0/17]	Loss: 0.946221
[INFO][09:13:16]: [Client #216] Epoch: [3/5][10/17]	Loss: 1.816779
[INFO][09:13:16]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][09:13:17]: [Client #430] Woke up.
[INFO][09:13:17]: [Client #430] Epoch: [2/5][0/16]	Loss: 0.958580
[INFO][09:13:17]: [Client #430] Epoch: [2/5][10/16]	Loss: 0.626613
[INFO][09:13:17]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][09:13:18]: [Client #216] Woke up.
[INFO][09:13:18]: [Client #216] Epoch: [4/5][0/17]	Loss: 0.616120
[INFO][09:13:18]: [Client #216] Epoch: [4/5][10/17]	Loss: 0.387430
[INFO][09:13:18]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][09:13:19]: [Client #216] Woke up.
[INFO][09:13:19]: [Client #216] Epoch: [5/5][0/17]	Loss: 1.298336
[INFO][09:13:19]: [Client #216] Epoch: [5/5][10/17]	Loss: 0.732929
[INFO][09:13:19]: [Client #216] Going to sleep for 1.02 seconds.
[INFO][09:13:20]: [Client #216] Woke up.
[INFO][09:13:20]: [Client #216] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_216_554860.pth.
[INFO][09:13:20]: [Client #430] Woke up.
[INFO][09:13:20]: [Client #430] Epoch: [3/5][0/16]	Loss: 0.182317
[INFO][09:13:20]: [Client #430] Epoch: [3/5][10/16]	Loss: 1.369775
[INFO][09:13:20]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][09:13:20]: [Client #216] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_216_554860.pth.
[INFO][09:13:21]: [Client #216] Model trained.
[INFO][09:13:21]: [Client #216] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:13:21]: [Server #554754] Received 0.26 MB of payload data from client #216 (simulated).
[INFO][09:13:23]: [Client #430] Woke up.
[INFO][09:13:23]: [Client #430] Epoch: [4/5][0/16]	Loss: 1.980562
[INFO][09:13:23]: [Client #430] Epoch: [4/5][10/16]	Loss: 1.517375
[INFO][09:13:24]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][09:13:26]: [Client #430] Woke up.
[INFO][09:13:26]: [Client #430] Epoch: [5/5][0/16]	Loss: 0.904815
[INFO][09:13:27]: [Client #430] Epoch: [5/5][10/16]	Loss: 2.036900
[INFO][09:13:27]: [Client #430] Going to sleep for 2.95 seconds.
[INFO][09:13:30]: [Client #430] Woke up.
[INFO][09:13:30]: [Client #430] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554853.pth.
[INFO][09:13:30]: [Client #430] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_430_554853.pth.
[INFO][09:13:30]: [Client #430] Model trained.
[INFO][09:13:30]: [Client #430] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:13:30]: [Server #554754] Received 0.26 MB of payload data from client #430 (simulated).
[INFO][09:13:30]: [Server #554754] Selecting client #126 for training.
[INFO][09:13:30]: [Server #554754] Sending the current model to client #126 (simulated).
[INFO][09:13:30]: [Server #554754] Sending 0.26 MB of payload data to client #126 (simulated).
[INFO][09:13:30]: [Server #554754] Selecting client #401 for training.
[INFO][09:13:30]: [Server #554754] Sending the current model to client #401 (simulated).
[INFO][09:13:30]: [Server #554754] Sending 0.26 MB of payload data to client #401 (simulated).
[INFO][09:13:30]: [Client #126] Selected by the server.
[INFO][09:13:30]: [Client #126] Loading its data source...
[INFO][09:13:30]: Data source: FEMNIST
[INFO][09:13:30]: [Client #401] Selected by the server.
[INFO][09:13:30]: [Client #401] Loading its data source...
[INFO][09:13:30]: Data source: FEMNIST
[INFO][09:13:30]: [Client #401] Dataset size: 151
[INFO][09:13:30]: [Client #401] Sampler: all_inclusive
[INFO][09:13:30]: [Client #401] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:13:30]: [93m[1m[Client #401] Started training in communication round #11.[0m
[INFO][09:13:30]: [Client #126] Dataset size: 164
[INFO][09:13:30]: [Client #126] Sampler: all_inclusive
[INFO][09:13:30]: [Client #126] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:13:30]: [93m[1m[Client #126] Started training in communication round #11.[0m
[INFO][09:13:32]: [Client #126] Loading the dataset.
[INFO][09:13:32]: [Client #401] Loading the dataset.
[INFO][09:13:38]: [Client #126] Epoch: [1/5][0/17]	Loss: 1.507508
[INFO][09:13:38]: [Client #401] Epoch: [1/5][0/16]	Loss: 1.590910
[INFO][09:13:38]: [Client #401] Epoch: [1/5][10/16]	Loss: 1.406263
[INFO][09:13:38]: [Client #126] Epoch: [1/5][10/17]	Loss: 1.997767
[INFO][09:13:38]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][09:13:38]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][09:13:39]: [Client #126] Woke up.
[INFO][09:13:39]: [Client #126] Epoch: [2/5][0/17]	Loss: 2.207730
[INFO][09:13:39]: [Client #126] Epoch: [2/5][10/17]	Loss: 1.788730
[INFO][09:13:39]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][09:13:40]: [Client #126] Woke up.
[INFO][09:13:40]: [Client #126] Epoch: [3/5][0/17]	Loss: 1.055622
[INFO][09:13:40]: [Client #126] Epoch: [3/5][10/17]	Loss: 1.303746
[INFO][09:13:41]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][09:13:42]: [Client #126] Woke up.
[INFO][09:13:42]: [Client #126] Epoch: [4/5][0/17]	Loss: 1.890423
[INFO][09:13:42]: [Client #126] Epoch: [4/5][10/17]	Loss: 2.692316
[INFO][09:13:42]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][09:13:43]: [Client #126] Woke up.
[INFO][09:13:43]: [Client #126] Epoch: [5/5][0/17]	Loss: 2.586441
[INFO][09:13:43]: [Client #126] Epoch: [5/5][10/17]	Loss: 1.759752
[INFO][09:13:43]: [Client #126] Going to sleep for 1.17 seconds.
[INFO][09:13:44]: [Client #126] Woke up.
[INFO][09:13:44]: [Client #126] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_554853.pth.
[INFO][09:13:45]: [Client #126] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_126_554853.pth.
[INFO][09:13:45]: [Client #126] Model trained.
[INFO][09:13:45]: [Client #126] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:13:45]: [Server #554754] Received 0.26 MB of payload data from client #126 (simulated).
[INFO][09:14:01]: [Client #401] Woke up.
[INFO][09:14:02]: [Client #401] Epoch: [2/5][0/16]	Loss: 1.363947
[INFO][09:14:02]: [Client #401] Epoch: [2/5][10/16]	Loss: 1.460301
[INFO][09:14:02]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][09:14:25]: [Client #401] Woke up.
[INFO][09:14:26]: [Client #401] Epoch: [3/5][0/16]	Loss: 0.777378
[INFO][09:14:26]: [Client #401] Epoch: [3/5][10/16]	Loss: 1.991404
[INFO][09:14:26]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][09:14:49]: [Client #401] Woke up.
[INFO][09:14:49]: [Client #401] Epoch: [4/5][0/16]	Loss: 1.530013
[INFO][09:14:50]: [Client #401] Epoch: [4/5][10/16]	Loss: 1.970264
[INFO][09:14:50]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][09:15:13]: [Client #401] Woke up.
[INFO][09:15:13]: [Client #401] Epoch: [5/5][0/16]	Loss: 0.534085
[INFO][09:15:13]: [Client #401] Epoch: [5/5][10/16]	Loss: 1.669076
[INFO][09:15:13]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][09:15:37]: [Client #401] Woke up.
[INFO][09:15:37]: [Client #401] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554860.pth.
[INFO][09:15:38]: [Client #401] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554860.pth.
[INFO][09:15:38]: [Client #401] Model trained.
[INFO][09:15:38]: [Client #401] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:15:38]: [Server #554754] Received 0.26 MB of payload data from client #401 (simulated).
[INFO][09:15:38]: [Server #554754] Selecting client #235 for training.
[INFO][09:15:38]: [Server #554754] Sending the current model to client #235 (simulated).
[INFO][09:15:38]: [Server #554754] Sending 0.26 MB of payload data to client #235 (simulated).
[INFO][09:15:38]: [Server #554754] Selecting client #66 for training.
[INFO][09:15:38]: [Server #554754] Sending the current model to client #66 (simulated).
[INFO][09:15:38]: [Server #554754] Sending 0.26 MB of payload data to client #66 (simulated).
[INFO][09:15:38]: [Client #235] Selected by the server.
[INFO][09:15:38]: [Client #66] Selected by the server.
[INFO][09:15:38]: [Client #235] Loading its data source...
[INFO][09:15:38]: [Client #66] Loading its data source...
[INFO][09:15:38]: Data source: FEMNIST
[INFO][09:15:38]: Data source: FEMNIST
[INFO][09:15:38]: [Client #66] Dataset size: 162
[INFO][09:15:38]: [Client #66] Sampler: all_inclusive
[INFO][09:15:38]: [Client #66] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:15:38]: [93m[1m[Client #66] Started training in communication round #11.[0m
[INFO][09:15:38]: [Client #235] Dataset size: 140
[INFO][09:15:38]: [Client #235] Sampler: all_inclusive
[INFO][09:15:38]: [Client #235] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:15:38]: [93m[1m[Client #235] Started training in communication round #11.[0m
[INFO][09:15:40]: [Client #66] Loading the dataset.
[INFO][09:15:40]: [Client #235] Loading the dataset.
[INFO][09:15:45]: [Client #66] Epoch: [1/5][0/17]	Loss: 2.197866
[INFO][09:15:45]: [Client #235] Epoch: [1/5][0/14]	Loss: 3.130239
[INFO][09:15:45]: [Client #66] Epoch: [1/5][10/17]	Loss: 0.716579
[INFO][09:15:46]: [Client #235] Epoch: [1/5][10/14]	Loss: 1.494432
[INFO][09:15:46]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][09:15:46]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][09:15:46]: [Client #235] Woke up.
[INFO][09:15:47]: [Client #235] Epoch: [2/5][0/14]	Loss: 2.294214
[INFO][09:15:47]: [Client #235] Epoch: [2/5][10/14]	Loss: 1.674322
[INFO][09:15:47]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][09:15:47]: [Client #66] Woke up.
[INFO][09:15:47]: [Client #66] Epoch: [2/5][0/17]	Loss: 0.734568
[INFO][09:15:47]: [Client #66] Epoch: [2/5][10/17]	Loss: 2.157186
[INFO][09:15:47]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][09:15:48]: [Client #235] Woke up.
[INFO][09:15:48]: [Client #235] Epoch: [3/5][0/14]	Loss: 1.133819
[INFO][09:15:48]: [Client #235] Epoch: [3/5][10/14]	Loss: 1.150109
[INFO][09:15:48]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][09:15:48]: [Client #66] Woke up.
[INFO][09:15:48]: [Client #66] Epoch: [3/5][0/17]	Loss: 1.484180
[INFO][09:15:48]: [Client #66] Epoch: [3/5][10/17]	Loss: 0.808061
[INFO][09:15:48]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][09:15:49]: [Client #235] Woke up.
[INFO][09:15:49]: [Client #235] Epoch: [4/5][0/14]	Loss: 1.551520
[INFO][09:15:49]: [Client #235] Epoch: [4/5][10/14]	Loss: 0.930687
[INFO][09:15:49]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][09:15:49]: [Client #66] Woke up.
[INFO][09:15:49]: [Client #66] Epoch: [4/5][0/17]	Loss: 1.547041
[INFO][09:15:49]: [Client #66] Epoch: [4/5][10/17]	Loss: 1.017640
[INFO][09:15:49]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][09:15:50]: [Client #235] Woke up.
[INFO][09:15:50]: [Client #235] Epoch: [5/5][0/14]	Loss: 1.413202
[INFO][09:15:50]: [Client #235] Epoch: [5/5][10/14]	Loss: 1.126543
[INFO][09:15:50]: [Client #235] Going to sleep for 0.96 seconds.
[INFO][09:15:51]: [Client #66] Woke up.
[INFO][09:15:51]: [Client #66] Epoch: [5/5][0/17]	Loss: 1.673586
[INFO][09:15:51]: [Client #66] Epoch: [5/5][10/17]	Loss: 1.509392
[INFO][09:15:51]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][09:15:51]: [Client #235] Woke up.
[INFO][09:15:51]: [Client #235] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_554853.pth.
[INFO][09:15:52]: [Client #235] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_235_554853.pth.
[INFO][09:15:52]: [Client #235] Model trained.
[INFO][09:15:52]: [Client #235] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:15:52]: [Server #554754] Received 0.26 MB of payload data from client #235 (simulated).
[INFO][09:15:52]: [Client #66] Woke up.
[INFO][09:15:52]: [Client #66] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][09:15:53]: [Client #66] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][09:15:53]: [Client #66] Model trained.
[INFO][09:15:53]: [Client #66] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:15:53]: [Server #554754] Received 0.26 MB of payload data from client #66 (simulated).
[INFO][09:15:53]: [Server #554754] Adding client #258 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #5 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #411 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #359 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #473 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #349 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #235 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #216 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #66 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #126 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #158 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #419 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #286 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #430 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #471 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #311 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #475 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #401 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #252 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Adding client #383 to the list of clients for aggregation.
[INFO][09:15:53]: [Server #554754] Aggregating 20 clients in total.
[0.00204089 0.00204089 0.00204089 0.00203995 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.002034   0.00204089 0.00204089
 0.00204089 0.00204089 0.00204007 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204057 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00201898 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204044 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00203912 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.0020404  0.00204089
 0.00204089 0.00204007 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00203934 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.15863072 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20281706
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.19195118
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14989199 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08496907
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13269547 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11901128
 0.         0.         0.         0.         0.         0.14077371
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13463396 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17624352 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15732547 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11046383 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09287242 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.26428561 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.2735148  0.         0.         0.
 0.         0.         0.         0.         0.15224143 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14250805 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10768277 0.         0.09649926 0.
 0.16691826 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.15863072 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20281706
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.19195118
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14989199 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08496907
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.13269547 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11901128
 0.         0.         0.         0.         0.         0.14077371
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13463396 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17624352 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15732547 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11046383 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09287242 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.26428561 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.2735148  0.         0.         0.
 0.         0.         0.         0.         0.15224143 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14250805 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10768277 0.         0.09649926 0.
 0.16691826 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:16:37]: [Server #554754] Global model accuracy: 49.11%

[INFO][09:16:37]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_11.pth.
[INFO][09:16:37]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_11.pth.
[INFO][09:16:37]: [93m[1m
[Server #554754] Starting round 12/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.002      0.002      0.002      0.04730139 0.002
 0.08247423 0.002      0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.08554572 0.08314607 0.002      0.11479029 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04717531
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.04076878 0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.09355391 0.04451314 0.002      0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.04804892
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.002      0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.002      0.05207668 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.08386721 0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.002      0.002      0.002      0.002
 0.04717531 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.002      0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.04222481 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.002      0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.002      0.002      0.002      0.002      0.10384615 0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.04455446 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9073e+00  5e-04  8e-09  8e-09
 5:  6.9078e+00  6.9076e+00  2e-04  3e-09  3e-09
 6:  6.9077e+00  6.9076e+00  2e-04  5e-09  9e-10
 7:  6.9077e+00  6.9076e+00  1e-04  5e-09  9e-10
 8:  6.9077e+00  6.9076e+00  9e-05  3e-08  6e-09
 9:  6.9076e+00  6.9076e+00  5e-05  2e-08  2e-09
10:  6.9076e+00  6.9076e+00  2e-05  2e-08  2e-09
11:  6.9076e+00  6.9076e+00  3e-06  6e-09  7e-10
Optimal solution found.
The calculated probability is:  [3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60472396e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60383925e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60402612e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60487336e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60571848e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60538972e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 1.86265420e-04
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 5.57092442e-04 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.66109652e-04 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 6.24448373e-01 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 1.40319059e-02 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 1.45065766e-04 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 9.88481059e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60275693e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.59030397e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 2.51560029e-03 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60502062e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 1.35206141e-04 3.60611878e-05
 3.60559609e-05 3.60611878e-05 3.39845840e-01 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05
 3.60611878e-05 3.60611878e-05 3.60611878e-05 3.60611878e-05]
current clients pool:  [INFO][09:16:37]: [Server #554754] Selected clients: [475 311 356 349 179 291 171 240 476 290 483 345 419 250 368 228 189 173
 343 140]
[INFO][09:16:37]: [Server #554754] Selecting client #475 for training.
[INFO][09:16:37]: [Server #554754] Sending the current model to client #475 (simulated).
[INFO][09:16:37]: [Server #554754] Sending 0.26 MB of payload data to client #475 (simulated).
[INFO][09:16:37]: [Server #554754] Selecting client #311 for training.
[INFO][09:16:37]: [Server #554754] Sending the current model to client #311 (simulated).
[INFO][09:16:37]: [Server #554754] Sending 0.26 MB of payload data to client #311 (simulated).
[INFO][09:16:37]: [Client #475] Selected by the server.
[INFO][09:16:37]: [Client #475] Loading its data source...
[INFO][09:16:37]: Data source: FEMNIST
[INFO][09:16:37]: [Client #311] Selected by the server.
[INFO][09:16:37]: [Client #311] Loading its data source...
[INFO][09:16:37]: Data source: FEMNIST
[INFO][09:16:37]: [Client #475] Dataset size: 153
[INFO][09:16:37]: [Client #475] Sampler: all_inclusive
[INFO][09:16:37]: [Client #475] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:16:37]: [93m[1m[Client #475] Started training in communication round #12.[0m
[INFO][09:16:37]: [Client #311] Dataset size: 288
[INFO][09:16:37]: [Client #311] Sampler: all_inclusive
[INFO][09:16:37]: [Client #311] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:16:37]: [93m[1m[Client #311] Started training in communication round #12.[0m
[INFO][09:16:39]: [Client #475] Loading the dataset.
[INFO][09:16:39]: [Client #311] Loading the dataset.
[INFO][09:16:45]: [Client #475] Epoch: [1/5][0/16]	Loss: 1.054780
[INFO][09:16:45]: [Client #311] Epoch: [1/5][0/29]	Loss: 2.407771
[INFO][09:16:45]: [Client #475] Epoch: [1/5][10/16]	Loss: 0.582728
[INFO][09:16:45]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:16:45]: [Client #311] Epoch: [1/5][10/29]	Loss: 3.019230
[INFO][09:16:45]: [Client #311] Epoch: [1/5][20/29]	Loss: 2.042199
[INFO][09:16:45]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:16:56]: [Client #311] Woke up.
[INFO][09:16:56]: [Client #311] Epoch: [2/5][0/29]	Loss: 1.631610
[INFO][09:16:56]: [Client #311] Epoch: [2/5][10/29]	Loss: 0.812048
[INFO][09:16:56]: [Client #311] Epoch: [2/5][20/29]	Loss: 0.312975
[INFO][09:16:56]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:17:00]: [Client #475] Woke up.
[INFO][09:17:00]: [Client #475] Epoch: [2/5][0/16]	Loss: 0.663449
[INFO][09:17:00]: [Client #475] Epoch: [2/5][10/16]	Loss: 1.351979
[INFO][09:17:00]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:17:07]: [Client #311] Woke up.
[INFO][09:17:07]: [Client #311] Epoch: [3/5][0/29]	Loss: 1.784979
[INFO][09:17:07]: [Client #311] Epoch: [3/5][10/29]	Loss: 1.555608
[INFO][09:17:08]: [Client #311] Epoch: [3/5][20/29]	Loss: 2.045770
[INFO][09:17:08]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:17:16]: [Client #475] Woke up.
[INFO][09:17:16]: [Client #475] Epoch: [3/5][0/16]	Loss: 2.666274
[INFO][09:17:16]: [Client #475] Epoch: [3/5][10/16]	Loss: 1.504661
[INFO][09:17:16]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:17:19]: [Client #311] Woke up.
[INFO][09:17:19]: [Client #311] Epoch: [4/5][0/29]	Loss: 1.535578
[INFO][09:17:19]: [Client #311] Epoch: [4/5][10/29]	Loss: 1.537347
[INFO][09:17:19]: [Client #311] Epoch: [4/5][20/29]	Loss: 1.510363
[INFO][09:17:19]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:17:30]: [Client #311] Woke up.
[INFO][09:17:30]: [Client #311] Epoch: [5/5][0/29]	Loss: 2.306051
[INFO][09:17:30]: [Client #311] Epoch: [5/5][10/29]	Loss: 1.487654
[INFO][09:17:30]: [Client #311] Epoch: [5/5][20/29]	Loss: 0.655542
[INFO][09:17:30]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:17:31]: [Client #475] Woke up.
[INFO][09:17:31]: [Client #475] Epoch: [4/5][0/16]	Loss: 0.404062
[INFO][09:17:31]: [Client #475] Epoch: [4/5][10/16]	Loss: 1.714302
[INFO][09:17:32]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:17:41]: [Client #311] Woke up.
[INFO][09:17:41]: [Client #311] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:17:42]: [Client #311] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:17:42]: [Client #311] Model trained.
[INFO][09:17:42]: [Client #311] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:17:42]: [Server #554754] Received 0.26 MB of payload data from client #311 (simulated).
[INFO][09:17:47]: [Client #475] Woke up.
[INFO][09:17:47]: [Client #475] Epoch: [5/5][0/16]	Loss: 2.058825
[INFO][09:17:47]: [Client #475] Epoch: [5/5][10/16]	Loss: 0.788904
[INFO][09:17:47]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:18:02]: [Client #475] Woke up.
[INFO][09:18:02]: [Client #475] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:18:03]: [Client #475] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:18:03]: [Client #475] Model trained.
[INFO][09:18:03]: [Client #475] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:03]: [Server #554754] Received 0.26 MB of payload data from client #475 (simulated).
[INFO][09:18:03]: [Server #554754] Selecting client #356 for training.
[INFO][09:18:03]: [Server #554754] Sending the current model to client #356 (simulated).
[INFO][09:18:03]: [Server #554754] Sending 0.26 MB of payload data to client #356 (simulated).
[INFO][09:18:03]: [Server #554754] Selecting client #349 for training.
[INFO][09:18:03]: [Server #554754] Sending the current model to client #349 (simulated).
[INFO][09:18:03]: [Server #554754] Sending 0.26 MB of payload data to client #349 (simulated).
[INFO][09:18:03]: [Client #356] Selected by the server.
[INFO][09:18:03]: [Client #356] Loading its data source...
[INFO][09:18:03]: Data source: FEMNIST
[INFO][09:18:03]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:18:03]: [Client #349] Selected by the server.
[INFO][09:18:03]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/356.zip.
[INFO][09:18:03]: [Client #349] Loading its data source...
[INFO][09:18:03]: Data source: FEMNIST
[INFO][09:18:03]: [Client #349] Dataset size: 162
[INFO][09:18:03]: [Client #349] Sampler: all_inclusive
[INFO][09:18:03]: [Client #349] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:03]: [93m[1m[Client #349] Started training in communication round #12.[0m

1.4%
2.8%
4.1%
5.5%
6.9%
8.3%
9.6%
11.0%
12.4%
13.8%
15.1%
16.5%
17.9%
19.3%
20.6%
22.0%
23.4%
24.8%
26.1%
27.5%
28.9%
30.3%
31.6%
33.0%
34.4%
35.8%
37.1%
38.5%
39.9%
41.3%
42.6%
44.0%
45.4%
46.8%
48.1%
49.5%
50.9%
52.3%
53.6%
55.0%
56.4%
57.8%
59.1%
60.5%
61.9%
63.3%
64.6%
66.0%
67.4%
68.8%
70.1%
71.5%
72.9%
74.3%
75.6%
77.0%
78.4%
79.8%
81.1%
82.5%
83.9%
85.3%
86.6%
88.0%
89.4%
90.8%
92.1%
93.5%
94.9%
96.3%
97.6%
99.0%
100.0%[INFO][09:18:03]: Decompressing the dataset downloaded.
[INFO][09:18:03]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/356.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:18:03]: [Client #356] Dataset size: 286
[INFO][09:18:03]: [Client #356] Sampler: all_inclusive
[INFO][09:18:03]: [Client #356] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:03]: [93m[1m[Client #356] Started training in communication round #12.[0m

[INFO][09:18:05]: [Client #349] Loading the dataset.
[INFO][09:18:05]: [Client #356] Loading the dataset.
[INFO][09:18:10]: [Client #349] Epoch: [1/5][0/17]	Loss: 0.707950
[INFO][09:18:11]: [Client #349] Epoch: [1/5][10/17]	Loss: 1.064521
[INFO][09:18:11]: [Client #356] Epoch: [1/5][0/29]	Loss: 1.661656
[INFO][09:18:11]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:18:11]: [Client #356] Epoch: [1/5][10/29]	Loss: 1.961298
[INFO][09:18:11]: [Client #356] Epoch: [1/5][20/29]	Loss: 1.783763
[INFO][09:18:11]: [Client #356] Going to sleep for 0.53 seconds.
[INFO][09:18:11]: [Client #356] Woke up.
[INFO][09:18:11]: [Client #356] Epoch: [2/5][0/29]	Loss: 1.023570
[INFO][09:18:11]: [Client #356] Epoch: [2/5][10/29]	Loss: 2.119841
[INFO][09:18:11]: [Client #356] Epoch: [2/5][20/29]	Loss: 1.862888
[INFO][09:18:12]: [Client #356] Going to sleep for 0.53 seconds.
[INFO][09:18:12]: [Client #356] Woke up.
[INFO][09:18:12]: [Client #356] Epoch: [3/5][0/29]	Loss: 1.153620
[INFO][09:18:12]: [Client #356] Epoch: [3/5][10/29]	Loss: 1.088991
[INFO][09:18:12]: [Client #356] Epoch: [3/5][20/29]	Loss: 0.790955
[INFO][09:18:12]: [Client #356] Going to sleep for 0.53 seconds.
[INFO][09:18:13]: [Client #356] Woke up.
[INFO][09:18:13]: [Client #356] Epoch: [4/5][0/29]	Loss: 1.499457
[INFO][09:18:13]: [Client #356] Epoch: [4/5][10/29]	Loss: 1.238565
[INFO][09:18:13]: [Client #356] Epoch: [4/5][20/29]	Loss: 0.485709
[INFO][09:18:13]: [Client #356] Going to sleep for 0.53 seconds.
[INFO][09:18:14]: [Client #356] Woke up.
[INFO][09:18:14]: [Client #356] Epoch: [5/5][0/29]	Loss: 1.217803
[INFO][09:18:14]: [Client #356] Epoch: [5/5][10/29]	Loss: 0.636013
[INFO][09:18:14]: [Client #356] Epoch: [5/5][20/29]	Loss: 1.345375
[INFO][09:18:14]: [Client #356] Going to sleep for 0.53 seconds.
[INFO][09:18:14]: [Client #356] Woke up.
[INFO][09:18:14]: [Client #356] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_356_554853.pth.
[INFO][09:18:15]: [Client #349] Woke up.
[INFO][09:18:15]: [Client #349] Epoch: [2/5][0/17]	Loss: 0.379279
[INFO][09:18:15]: [Client #349] Epoch: [2/5][10/17]	Loss: 1.182250
[INFO][09:18:15]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:18:15]: [Client #356] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_356_554853.pth.
[INFO][09:18:15]: [Client #356] Model trained.
[INFO][09:18:15]: [Client #356] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:15]: [Server #554754] Received 0.26 MB of payload data from client #356 (simulated).
[INFO][09:18:19]: [Client #349] Woke up.
[INFO][09:18:19]: [Client #349] Epoch: [3/5][0/17]	Loss: 0.041784
[INFO][09:18:19]: [Client #349] Epoch: [3/5][10/17]	Loss: 1.040046
[INFO][09:18:19]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:18:23]: [Client #349] Woke up.
[INFO][09:18:23]: [Client #349] Epoch: [4/5][0/17]	Loss: 1.351449
[INFO][09:18:23]: [Client #349] Epoch: [4/5][10/17]	Loss: 2.274364
[INFO][09:18:23]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:18:27]: [Client #349] Woke up.
[INFO][09:18:27]: [Client #349] Epoch: [5/5][0/17]	Loss: 1.176063
[INFO][09:18:27]: [Client #349] Epoch: [5/5][10/17]	Loss: 1.530773
[INFO][09:18:27]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:18:31]: [Client #349] Woke up.
[INFO][09:18:31]: [Client #349] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][09:18:32]: [Client #349] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][09:18:32]: [Client #349] Model trained.
[INFO][09:18:32]: [Client #349] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:32]: [Server #554754] Received 0.26 MB of payload data from client #349 (simulated).
[INFO][09:18:32]: [Server #554754] Selecting client #179 for training.
[INFO][09:18:32]: [Server #554754] Sending the current model to client #179 (simulated).
[INFO][09:18:32]: [Server #554754] Sending 0.26 MB of payload data to client #179 (simulated).
[INFO][09:18:32]: [Server #554754] Selecting client #291 for training.
[INFO][09:18:32]: [Server #554754] Sending the current model to client #291 (simulated).
[INFO][09:18:32]: [Server #554754] Sending 0.26 MB of payload data to client #291 (simulated).
[INFO][09:18:32]: [Client #291] Selected by the server.
[INFO][09:18:32]: [Client #291] Loading its data source...
[INFO][09:18:32]: Data source: FEMNIST
[INFO][09:18:32]: [Client #179] Selected by the server.
[INFO][09:18:32]: [Client #179] Loading its data source...
[INFO][09:18:32]: Data source: FEMNIST
[INFO][09:18:32]: [Client #291] Dataset size: 163
[INFO][09:18:32]: [Client #291] Sampler: all_inclusive
[INFO][09:18:32]: [Client #291] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:32]: [93m[1m[Client #291] Started training in communication round #12.[0m
[INFO][09:18:32]: [Client #179] Dataset size: 159
[INFO][09:18:32]: [Client #179] Sampler: all_inclusive
[INFO][09:18:32]: [Client #179] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:32]: [93m[1m[Client #179] Started training in communication round #12.[0m
[INFO][09:18:34]: [Client #291] Loading the dataset.
[INFO][09:18:34]: [Client #179] Loading the dataset.
[INFO][09:18:39]: [Client #291] Epoch: [1/5][0/17]	Loss: 0.978419
[INFO][09:18:39]: [Client #179] Epoch: [1/5][0/16]	Loss: 1.757478
[INFO][09:18:39]: [Client #291] Epoch: [1/5][10/17]	Loss: 1.087314
[INFO][09:18:39]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][09:18:39]: [Client #179] Epoch: [1/5][10/16]	Loss: 0.684280
[INFO][09:18:39]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][09:18:39]: [Client #179] Woke up.
[INFO][09:18:39]: [Client #179] Epoch: [2/5][0/16]	Loss: 1.060685
[INFO][09:18:40]: [Client #179] Epoch: [2/5][10/16]	Loss: 1.888893
[INFO][09:18:40]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][09:18:40]: [Client #179] Woke up.
[INFO][09:18:40]: [Client #179] Epoch: [3/5][0/16]	Loss: 0.761002
[INFO][09:18:40]: [Client #179] Epoch: [3/5][10/16]	Loss: 1.206457
[INFO][09:18:40]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][09:18:40]: [Client #179] Woke up.
[INFO][09:18:40]: [Client #179] Epoch: [4/5][0/16]	Loss: 1.340189
[INFO][09:18:40]: [Client #179] Epoch: [4/5][10/16]	Loss: 2.175826
[INFO][09:18:40]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][09:18:40]: [Client #179] Woke up.
[INFO][09:18:40]: [Client #179] Epoch: [5/5][0/16]	Loss: 1.099316
[INFO][09:18:40]: [Client #179] Epoch: [5/5][10/16]	Loss: 0.381267
[INFO][09:18:40]: [Client #179] Going to sleep for 0.07 seconds.
[INFO][09:18:40]: [Client #291] Woke up.
[INFO][09:18:40]: [Client #179] Woke up.
[INFO][09:18:40]: [Client #291] Epoch: [2/5][0/17]	Loss: 0.546740
[INFO][09:18:40]: [Client #179] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_179_554853.pth.
[INFO][09:18:40]: [Client #291] Epoch: [2/5][10/17]	Loss: 0.900935
[INFO][09:18:41]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][09:18:41]: [Client #179] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_179_554853.pth.
[INFO][09:18:41]: [Client #179] Model trained.
[INFO][09:18:41]: [Client #179] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:41]: [Server #554754] Received 0.26 MB of payload data from client #179 (simulated).
[INFO][09:18:42]: [Client #291] Woke up.
[INFO][09:18:42]: [Client #291] Epoch: [3/5][0/17]	Loss: 0.133072
[INFO][09:18:42]: [Client #291] Epoch: [3/5][10/17]	Loss: 1.138118
[INFO][09:18:42]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][09:18:43]: [Client #291] Woke up.
[INFO][09:18:43]: [Client #291] Epoch: [4/5][0/17]	Loss: 0.889375
[INFO][09:18:43]: [Client #291] Epoch: [4/5][10/17]	Loss: 0.463585
[INFO][09:18:43]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][09:18:44]: [Client #291] Woke up.
[INFO][09:18:44]: [Client #291] Epoch: [5/5][0/17]	Loss: 0.340923
[INFO][09:18:44]: [Client #291] Epoch: [5/5][10/17]	Loss: 0.294713
[INFO][09:18:44]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][09:18:45]: [Client #291] Woke up.
[INFO][09:18:45]: [Client #291] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554860.pth.
[INFO][09:18:46]: [Client #291] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554860.pth.
[INFO][09:18:46]: [Client #291] Model trained.
[INFO][09:18:46]: [Client #291] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:46]: [Server #554754] Received 0.26 MB of payload data from client #291 (simulated).
[INFO][09:18:46]: [Server #554754] Selecting client #171 for training.
[INFO][09:18:46]: [Server #554754] Sending the current model to client #171 (simulated).
[INFO][09:18:46]: [Server #554754] Sending 0.26 MB of payload data to client #171 (simulated).
[INFO][09:18:46]: [Server #554754] Selecting client #240 for training.
[INFO][09:18:46]: [Server #554754] Sending the current model to client #240 (simulated).
[INFO][09:18:46]: [Server #554754] Sending 0.26 MB of payload data to client #240 (simulated).
[INFO][09:18:46]: [Client #240] Selected by the server.
[INFO][09:18:46]: [Client #171] Selected by the server.
[INFO][09:18:46]: [Client #240] Loading its data source...
[INFO][09:18:46]: [Client #171] Loading its data source...
[INFO][09:18:46]: Data source: FEMNIST
[INFO][09:18:46]: Data source: FEMNIST
[INFO][09:18:46]: [Client #240] Dataset size: 156
[INFO][09:18:46]: [Client #240] Sampler: all_inclusive
[INFO][09:18:46]: [Client #240] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:46]: [93m[1m[Client #240] Started training in communication round #12.[0m
[INFO][09:18:46]: [Client #171] Dataset size: 137
[INFO][09:18:46]: [Client #171] Sampler: all_inclusive
[INFO][09:18:46]: [Client #171] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:18:46]: [93m[1m[Client #171] Started training in communication round #12.[0m
[INFO][09:18:48]: [Client #171] Loading the dataset.
[INFO][09:18:48]: [Client #240] Loading the dataset.
[INFO][09:18:53]: [Client #240] Epoch: [1/5][0/16]	Loss: 0.728419
[INFO][09:18:53]: [Client #171] Epoch: [1/5][0/14]	Loss: 0.280644
[INFO][09:18:54]: [Client #171] Epoch: [1/5][10/14]	Loss: 1.886014
[INFO][09:18:54]: [Client #240] Epoch: [1/5][10/16]	Loss: 1.474139
[INFO][09:18:54]: [Client #171] Going to sleep for 0.46 seconds.
[INFO][09:18:54]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][09:18:54]: [Client #171] Woke up.
[INFO][09:18:54]: [Client #171] Epoch: [2/5][0/14]	Loss: 1.156174
[INFO][09:18:54]: [Client #171] Epoch: [2/5][10/14]	Loss: 0.532243
[INFO][09:18:54]: [Client #171] Going to sleep for 0.46 seconds.
[INFO][09:18:55]: [Client #171] Woke up.
[INFO][09:18:55]: [Client #171] Epoch: [3/5][0/14]	Loss: 0.428840
[INFO][09:18:55]: [Client #171] Epoch: [3/5][10/14]	Loss: 1.370077
[INFO][09:18:55]: [Client #171] Going to sleep for 0.46 seconds.
[INFO][09:18:55]: [Client #171] Woke up.
[INFO][09:18:55]: [Client #171] Epoch: [4/5][0/14]	Loss: 1.954533
[INFO][09:18:55]: [Client #171] Epoch: [4/5][10/14]	Loss: 0.668586
[INFO][09:18:55]: [Client #171] Going to sleep for 0.46 seconds.
[INFO][09:18:56]: [Client #171] Woke up.
[INFO][09:18:56]: [Client #171] Epoch: [5/5][0/14]	Loss: 1.131750
[INFO][09:18:56]: [Client #171] Epoch: [5/5][10/14]	Loss: 0.936868
[INFO][09:18:56]: [Client #171] Going to sleep for 0.46 seconds.
[INFO][09:18:56]: [Client #171] Woke up.
[INFO][09:18:56]: [Client #171] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_171_554853.pth.
[INFO][09:18:57]: [Client #171] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_171_554853.pth.
[INFO][09:18:57]: [Client #171] Model trained.
[INFO][09:18:57]: [Client #171] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:18:57]: [Server #554754] Received 0.26 MB of payload data from client #171 (simulated).
[INFO][09:18:58]: [Client #240] Woke up.
[INFO][09:18:58]: [Client #240] Epoch: [2/5][0/16]	Loss: 0.849574
[INFO][09:18:58]: [Client #240] Epoch: [2/5][10/16]	Loss: 0.403926
[INFO][09:18:58]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][09:19:02]: [Client #240] Woke up.
[INFO][09:19:02]: [Client #240] Epoch: [3/5][0/16]	Loss: 0.220741
[INFO][09:19:02]: [Client #240] Epoch: [3/5][10/16]	Loss: 0.624901
[INFO][09:19:02]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][09:19:07]: [Client #240] Woke up.
[INFO][09:19:07]: [Client #240] Epoch: [4/5][0/16]	Loss: 1.507139
[INFO][09:19:07]: [Client #240] Epoch: [4/5][10/16]	Loss: 0.648697
[INFO][09:19:07]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][09:19:11]: [Client #240] Woke up.
[INFO][09:19:11]: [Client #240] Epoch: [5/5][0/16]	Loss: 0.717811
[INFO][09:19:11]: [Client #240] Epoch: [5/5][10/16]	Loss: 0.436138
[INFO][09:19:11]: [Client #240] Going to sleep for 4.19 seconds.
[INFO][09:19:15]: [Client #240] Woke up.
[INFO][09:19:15]: [Client #240] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_554860.pth.
[INFO][09:19:16]: [Client #240] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_240_554860.pth.
[INFO][09:19:16]: [Client #240] Model trained.
[INFO][09:19:16]: [Client #240] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:19:16]: [Server #554754] Received 0.26 MB of payload data from client #240 (simulated).
[INFO][09:19:16]: [Server #554754] Selecting client #476 for training.
[INFO][09:19:16]: [Server #554754] Sending the current model to client #476 (simulated).
[INFO][09:19:16]: [Server #554754] Sending 0.26 MB of payload data to client #476 (simulated).
[INFO][09:19:16]: [Server #554754] Selecting client #290 for training.
[INFO][09:19:16]: [Server #554754] Sending the current model to client #290 (simulated).
[INFO][09:19:16]: [Server #554754] Sending 0.26 MB of payload data to client #290 (simulated).
[INFO][09:19:16]: [Client #476] Selected by the server.
[INFO][09:19:16]: [Client #476] Loading its data source...
[INFO][09:19:16]: Data source: FEMNIST
[INFO][09:19:16]: [Client #290] Selected by the server.
[INFO][09:19:16]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:19:16]: [Client #290] Loading its data source...
[INFO][09:19:16]: Data source: FEMNIST
[INFO][09:19:16]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/476.zip.
[INFO][09:19:16]: [Client #290] Dataset size: 156
[INFO][09:19:16]: [Client #290] Sampler: all_inclusive
[INFO][09:19:16]: [Client #290] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:16]: [93m[1m[Client #290] Started training in communication round #12.[0m

3.1%
6.2%
9.3%
12.3%
15.4%
18.5%
21.6%
24.7%
27.8%
30.8%
33.9%
37.0%
40.1%
43.2%
46.3%
49.3%
52.4%
55.5%
58.6%
61.7%
64.8%
67.8%
70.9%
74.0%
77.1%
80.2%
83.3%
86.3%
89.4%
92.5%
95.6%
98.7%
100.0%[INFO][09:19:16]: Decompressing the dataset downloaded.
[INFO][09:19:16]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/476.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:19:16]: [Client #476] Dataset size: 138
[INFO][09:19:16]: [Client #476] Sampler: all_inclusive
[INFO][09:19:16]: [Client #476] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:16]: [93m[1m[Client #476] Started training in communication round #12.[0m

[INFO][09:19:18]: [Client #290] Loading the dataset.
[INFO][09:19:18]: [Client #476] Loading the dataset.
[INFO][09:19:23]: [Client #290] Epoch: [1/5][0/16]	Loss: 1.213386
[INFO][09:19:23]: [Client #290] Epoch: [1/5][10/16]	Loss: 1.496254
[INFO][09:19:23]: [Client #290] Going to sleep for 2.75 seconds.
[INFO][09:19:23]: [Client #476] Epoch: [1/5][0/14]	Loss: 1.790136
[INFO][09:19:24]: [Client #476] Epoch: [1/5][10/14]	Loss: 2.084660
[INFO][09:19:24]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][09:19:24]: [Client #476] Woke up.
[INFO][09:19:24]: [Client #476] Epoch: [2/5][0/14]	Loss: 0.701275
[INFO][09:19:24]: [Client #476] Epoch: [2/5][10/14]	Loss: 1.697937
[INFO][09:19:24]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][09:19:24]: [Client #476] Woke up.
[INFO][09:19:24]: [Client #476] Epoch: [3/5][0/14]	Loss: 0.733607
[INFO][09:19:24]: [Client #476] Epoch: [3/5][10/14]	Loss: 0.937666
[INFO][09:19:24]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][09:19:24]: [Client #476] Woke up.
[INFO][09:19:24]: [Client #476] Epoch: [4/5][0/14]	Loss: 1.048392
[INFO][09:19:24]: [Client #476] Epoch: [4/5][10/14]	Loss: 1.051311
[INFO][09:19:24]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][09:19:24]: [Client #476] Woke up.
[INFO][09:19:24]: [Client #476] Epoch: [5/5][0/14]	Loss: 1.420771
[INFO][09:19:24]: [Client #476] Epoch: [5/5][10/14]	Loss: 1.476258
[INFO][09:19:24]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][09:19:24]: [Client #476] Woke up.
[INFO][09:19:24]: [Client #476] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_554853.pth.
[INFO][09:19:25]: [Client #476] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_554853.pth.
[INFO][09:19:25]: [Client #476] Model trained.
[INFO][09:19:25]: [Client #476] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:19:25]: [Server #554754] Received 0.26 MB of payload data from client #476 (simulated).
[INFO][09:19:26]: [Client #290] Woke up.
[INFO][09:19:26]: [Client #290] Epoch: [2/5][0/16]	Loss: 0.854280
[INFO][09:19:26]: [Client #290] Epoch: [2/5][10/16]	Loss: 1.222282
[INFO][09:19:26]: [Client #290] Going to sleep for 2.75 seconds.
[INFO][09:19:29]: [Client #290] Woke up.
[INFO][09:19:29]: [Client #290] Epoch: [3/5][0/16]	Loss: 1.262454
[INFO][09:19:29]: [Client #290] Epoch: [3/5][10/16]	Loss: 0.810478
[INFO][09:19:29]: [Client #290] Going to sleep for 2.75 seconds.
[INFO][09:19:32]: [Client #290] Woke up.
[INFO][09:19:32]: [Client #290] Epoch: [4/5][0/16]	Loss: 0.690395
[INFO][09:19:32]: [Client #290] Epoch: [4/5][10/16]	Loss: 0.750535
[INFO][09:19:32]: [Client #290] Going to sleep for 2.75 seconds.
[INFO][09:19:35]: [Client #290] Woke up.
[INFO][09:19:35]: [Client #290] Epoch: [5/5][0/16]	Loss: 0.068112
[INFO][09:19:35]: [Client #290] Epoch: [5/5][10/16]	Loss: 1.433512
[INFO][09:19:35]: [Client #290] Going to sleep for 2.75 seconds.
[INFO][09:19:38]: [Client #290] Woke up.
[INFO][09:19:38]: [Client #290] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_290_554860.pth.
[INFO][09:19:38]: [Client #290] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_290_554860.pth.
[INFO][09:19:38]: [Client #290] Model trained.
[INFO][09:19:38]: [Client #290] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:19:38]: [Server #554754] Received 0.26 MB of payload data from client #290 (simulated).
[INFO][09:19:38]: [Server #554754] Selecting client #483 for training.
[INFO][09:19:38]: [Server #554754] Sending the current model to client #483 (simulated).
[INFO][09:19:38]: [Server #554754] Sending 0.26 MB of payload data to client #483 (simulated).
[INFO][09:19:38]: [Server #554754] Selecting client #345 for training.
[INFO][09:19:38]: [Server #554754] Sending the current model to client #345 (simulated).
[INFO][09:19:38]: [Server #554754] Sending 0.26 MB of payload data to client #345 (simulated).
[INFO][09:19:38]: [Client #345] Selected by the server.
[INFO][09:19:38]: [Client #345] Loading its data source...
[INFO][09:19:38]: [Client #483] Selected by the server.
[INFO][09:19:38]: Data source: FEMNIST
[INFO][09:19:38]: [Client #483] Loading its data source...
[INFO][09:19:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:19:38]: Data source: FEMNIST
[INFO][09:19:38]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:19:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/345.zip.
[INFO][09:19:38]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/483.zip.

2.5%
5.0%
7.4%
9.9%
12.4%
14.9%
17.4%
19.8%
22.3%
24.8%
27.3%
29.8%
32.3%
34.7%
37.2%
39.7%
1.9%
42.2%
44.7%
47.1%
49.6%
52.1%
54.6%
57.1%
59.5%
62.0%
64.5%
67.0%
69.5%
72.0%
74.4%
76.9%
79.4%
3.8%
5.7%
7.6%
9.5%
11.4%
13.3%
15.2%
17.1%
19.0%
20.9%
22.8%
24.7%
26.6%
28.5%
30.4%
32.3%
34.2%
36.1%
38.0%
39.9%
41.8%
43.7%
45.6%
47.5%
49.4%
51.3%
53.2%
55.1%
57.0%
58.9%
60.8%
62.7%
64.6%
66.5%
68.4%
70.3%
72.2%
74.1%
76.0%
77.9%
79.8%
81.7%
83.6%
85.5%
87.4%
89.3%
91.2%
93.1%
95.0%
96.9%
98.8%
81.9%
84.4%
86.8%
89.3%
91.8%
94.3%
96.8%
99.2%
100.0%[INFO][09:19:39]: Decompressing the dataset downloaded.
[INFO][09:19:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/345.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

100.0%[INFO][09:19:39]: Decompressing the dataset downloaded.
[INFO][09:19:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/483.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:19:39]: [Client #483] Dataset size: 137
[INFO][09:19:39]: [Client #483] Sampler: all_inclusive
[INFO][09:19:39]: [Client #483] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:39]: [93m[1m[Client #483] Started training in communication round #12.[0m

[INFO][09:19:39]: [Client #345] Dataset size: 239
[INFO][09:19:39]: [Client #345] Sampler: all_inclusive
[INFO][09:19:39]: [Client #345] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:39]: [93m[1m[Client #345] Started training in communication round #12.[0m

[INFO][09:19:41]: [Client #483] Loading the dataset.
[INFO][09:19:41]: [Client #345] Loading the dataset.
[INFO][09:19:46]: [Client #483] Epoch: [1/5][0/14]	Loss: 1.961964
[INFO][09:19:46]: [Client #345] Epoch: [1/5][0/24]	Loss: 2.884778
[INFO][09:19:46]: [Client #483] Epoch: [1/5][10/14]	Loss: 1.720886
[INFO][09:19:46]: [Client #483] Going to sleep for 1.27 seconds.
[INFO][09:19:46]: [Client #345] Epoch: [1/5][10/24]	Loss: 0.822848
[INFO][09:19:46]: [Client #345] Epoch: [1/5][20/24]	Loss: 1.408997
[INFO][09:19:46]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][09:19:47]: [Client #345] Woke up.
[INFO][09:19:47]: [Client #345] Epoch: [2/5][0/24]	Loss: 1.525161
[INFO][09:19:47]: [Client #345] Epoch: [2/5][10/24]	Loss: 0.895347
[INFO][09:19:47]: [Client #345] Epoch: [2/5][20/24]	Loss: 1.145463
[INFO][09:19:47]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][09:19:47]: [Client #345] Woke up.
[INFO][09:19:47]: [Client #345] Epoch: [3/5][0/24]	Loss: 0.630867
[INFO][09:19:47]: [Client #345] Epoch: [3/5][10/24]	Loss: 1.678416
[INFO][09:19:47]: [Client #345] Epoch: [3/5][20/24]	Loss: 1.194373
[INFO][09:19:47]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][09:19:47]: [Client #345] Woke up.
[INFO][09:19:47]: [Client #345] Epoch: [4/5][0/24]	Loss: 1.089771
[INFO][09:19:47]: [Client #345] Epoch: [4/5][10/24]	Loss: 0.834824
[INFO][09:19:47]: [Client #345] Epoch: [4/5][20/24]	Loss: 1.442418
[INFO][09:19:47]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][09:19:48]: [Client #483] Woke up.
[INFO][09:19:48]: [Client #483] Epoch: [2/5][0/14]	Loss: 1.572837
[INFO][09:19:48]: [Client #345] Woke up.
[INFO][09:19:48]: [Client #345] Epoch: [5/5][0/24]	Loss: 0.643836
[INFO][09:19:48]: [Client #483] Epoch: [2/5][10/14]	Loss: 2.176097
[INFO][09:19:48]: [Client #483] Going to sleep for 1.27 seconds.
[INFO][09:19:48]: [Client #345] Epoch: [5/5][10/24]	Loss: 1.296053
[INFO][09:19:48]: [Client #345] Epoch: [5/5][20/24]	Loss: 1.762243
[INFO][09:19:48]: [Client #345] Going to sleep for 0.11 seconds.
[INFO][09:19:48]: [Client #345] Woke up.
[INFO][09:19:48]: [Client #345] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_554860.pth.
[INFO][09:19:49]: [Client #345] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_345_554860.pth.
[INFO][09:19:49]: [Client #345] Model trained.
[INFO][09:19:49]: [Client #345] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:19:49]: [Server #554754] Received 0.26 MB of payload data from client #345 (simulated).
[INFO][09:19:49]: [Client #483] Woke up.
[INFO][09:19:49]: [Client #483] Epoch: [3/5][0/14]	Loss: 0.970153
[INFO][09:19:49]: [Client #483] Epoch: [3/5][10/14]	Loss: 1.126264
[INFO][09:19:49]: [Client #483] Going to sleep for 1.27 seconds.
[INFO][09:19:50]: [Client #483] Woke up.
[INFO][09:19:50]: [Client #483] Epoch: [4/5][0/14]	Loss: 1.199957
[INFO][09:19:50]: [Client #483] Epoch: [4/5][10/14]	Loss: 0.864116
[INFO][09:19:50]: [Client #483] Going to sleep for 1.27 seconds.
[INFO][09:19:52]: [Client #483] Woke up.
[INFO][09:19:52]: [Client #483] Epoch: [5/5][0/14]	Loss: 1.246085
[INFO][09:19:52]: [Client #483] Epoch: [5/5][10/14]	Loss: 0.805047
[INFO][09:19:52]: [Client #483] Going to sleep for 1.27 seconds.
[INFO][09:19:53]: [Client #483] Woke up.
[INFO][09:19:53]: [Client #483] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_483_554853.pth.
[INFO][09:19:54]: [Client #483] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_483_554853.pth.
[INFO][09:19:54]: [Client #483] Model trained.
[INFO][09:19:54]: [Client #483] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:19:54]: [Server #554754] Received 0.26 MB of payload data from client #483 (simulated).
[INFO][09:19:54]: [Server #554754] Selecting client #419 for training.
[INFO][09:19:54]: [Server #554754] Sending the current model to client #419 (simulated).
[INFO][09:19:54]: [Server #554754] Sending 0.26 MB of payload data to client #419 (simulated).
[INFO][09:19:54]: [Server #554754] Selecting client #250 for training.
[INFO][09:19:54]: [Server #554754] Sending the current model to client #250 (simulated).
[INFO][09:19:54]: [Server #554754] Sending 0.26 MB of payload data to client #250 (simulated).
[INFO][09:19:54]: [Client #419] Selected by the server.
[INFO][09:19:54]: [Client #419] Loading its data source...
[INFO][09:19:54]: Data source: FEMNIST
[INFO][09:19:54]: [Client #250] Selected by the server.
[INFO][09:19:54]: [Client #250] Loading its data source...
[INFO][09:19:54]: Data source: FEMNIST
[INFO][09:19:54]: [Client #250] Dataset size: 145
[INFO][09:19:54]: [Client #250] Sampler: all_inclusive
[INFO][09:19:54]: [Client #419] Dataset size: 145
[INFO][09:19:54]: [Client #419] Sampler: all_inclusive
[INFO][09:19:54]: [Client #250] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:54]: [Client #419] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:19:54]: [93m[1m[Client #419] Started training in communication round #12.[0m
[INFO][09:19:54]: [93m[1m[Client #250] Started training in communication round #12.[0m
[INFO][09:19:56]: [Client #250] Loading the dataset.
[INFO][09:19:56]: [Client #419] Loading the dataset.
[INFO][09:20:01]: [Client #250] Epoch: [1/5][0/15]	Loss: 1.323608
[INFO][09:20:01]: [Client #250] Epoch: [1/5][10/15]	Loss: 0.635598
[INFO][09:20:01]: [Client #419] Epoch: [1/5][0/15]	Loss: 1.536964
[INFO][09:20:01]: [Client #250] Going to sleep for 11.29 seconds.
[INFO][09:20:01]: [Client #419] Epoch: [1/5][10/15]	Loss: 0.785361
[INFO][09:20:01]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:20:06]: [Client #419] Woke up.
[INFO][09:20:06]: [Client #419] Epoch: [2/5][0/15]	Loss: 1.520111
[INFO][09:20:06]: [Client #419] Epoch: [2/5][10/15]	Loss: 0.255194
[INFO][09:20:06]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:20:11]: [Client #419] Woke up.
[INFO][09:20:11]: [Client #419] Epoch: [3/5][0/15]	Loss: 1.403730
[INFO][09:20:11]: [Client #419] Epoch: [3/5][10/15]	Loss: 1.258797
[INFO][09:20:11]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:20:13]: [Client #250] Woke up.
[INFO][09:20:13]: [Client #250] Epoch: [2/5][0/15]	Loss: 0.639405
[INFO][09:20:13]: [Client #250] Epoch: [2/5][10/15]	Loss: 0.192393
[INFO][09:20:13]: [Client #250] Going to sleep for 11.29 seconds.
[INFO][09:20:16]: [Client #419] Woke up.
[INFO][09:20:16]: [Client #419] Epoch: [4/5][0/15]	Loss: 1.798021
[INFO][09:20:16]: [Client #419] Epoch: [4/5][10/15]	Loss: 1.926682
[INFO][09:20:16]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:20:21]: [Client #419] Woke up.
[INFO][09:20:21]: [Client #419] Epoch: [5/5][0/15]	Loss: 1.038976
[INFO][09:20:21]: [Client #419] Epoch: [5/5][10/15]	Loss: 0.707794
[INFO][09:20:21]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:20:24]: [Client #250] Woke up.
[INFO][09:20:24]: [Client #250] Epoch: [3/5][0/15]	Loss: 1.126889
[INFO][09:20:24]: [Client #250] Epoch: [3/5][10/15]	Loss: 0.901804
[INFO][09:20:24]: [Client #250] Going to sleep for 11.29 seconds.
[INFO][09:20:26]: [Client #419] Woke up.
[INFO][09:20:26]: [Client #419] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:20:26]: [Client #419] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:20:26]: [Client #419] Model trained.
[INFO][09:20:26]: [Client #419] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:20:26]: [Server #554754] Received 0.26 MB of payload data from client #419 (simulated).
[INFO][09:20:36]: [Client #250] Woke up.
[INFO][09:20:36]: [Client #250] Epoch: [4/5][0/15]	Loss: 0.570900
[INFO][09:20:36]: [Client #250] Epoch: [4/5][10/15]	Loss: 1.285447
[INFO][09:20:36]: [Client #250] Going to sleep for 11.29 seconds.
[INFO][09:20:47]: [Client #250] Woke up.
[INFO][09:20:47]: [Client #250] Epoch: [5/5][0/15]	Loss: 0.947425
[INFO][09:20:47]: [Client #250] Epoch: [5/5][10/15]	Loss: 2.844886
[INFO][09:20:47]: [Client #250] Going to sleep for 11.29 seconds.
[INFO][09:20:58]: [Client #250] Woke up.
[INFO][09:20:58]: [Client #250] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_250_554860.pth.
[INFO][09:20:59]: [Client #250] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_250_554860.pth.
[INFO][09:20:59]: [Client #250] Model trained.
[INFO][09:20:59]: [Client #250] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:20:59]: [Server #554754] Received 0.26 MB of payload data from client #250 (simulated).
[INFO][09:20:59]: [Server #554754] Selecting client #368 for training.
[INFO][09:20:59]: [Server #554754] Sending the current model to client #368 (simulated).
[INFO][09:20:59]: [Server #554754] Sending 0.26 MB of payload data to client #368 (simulated).
[INFO][09:20:59]: [Server #554754] Selecting client #228 for training.
[INFO][09:20:59]: [Server #554754] Sending the current model to client #228 (simulated).
[INFO][09:20:59]: [Server #554754] Sending 0.26 MB of payload data to client #228 (simulated).
[INFO][09:20:59]: [Client #368] Selected by the server.
[INFO][09:20:59]: [Client #228] Selected by the server.
[INFO][09:20:59]: [Client #368] Loading its data source...
[INFO][09:20:59]: [Client #228] Loading its data source...
[INFO][09:20:59]: Data source: FEMNIST
[INFO][09:20:59]: Data source: FEMNIST
[INFO][09:20:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:20:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/368.zip.
[INFO][09:20:59]: [Client #228] Dataset size: 156
[INFO][09:20:59]: [Client #228] Sampler: all_inclusive
[INFO][09:20:59]: [Client #228] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:20:59]: [93m[1m[Client #228] Started training in communication round #12.[0m

2.7%
5.4%
8.2%
10.9%
13.6%
16.3%
19.1%
21.8%
24.5%
27.2%
30.0%
32.7%
35.4%
38.1%
40.8%
43.6%
46.3%
49.0%
51.7%
54.5%
57.2%
59.9%
62.6%
65.4%
68.1%
70.8%
73.5%
76.2%
79.0%
81.7%
84.4%
87.1%
89.9%
92.6%
95.3%
98.0%
100.0%[INFO][09:20:59]: Decompressing the dataset downloaded.
[INFO][09:20:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/368.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:20:59]: [Client #368] Dataset size: 155
[INFO][09:20:59]: [Client #368] Sampler: all_inclusive
[INFO][09:20:59]: [Client #368] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:20:59]: [93m[1m[Client #368] Started training in communication round #12.[0m

[INFO][09:21:01]: [Client #228] Loading the dataset.
[INFO][09:21:01]: [Client #368] Loading the dataset.
[INFO][09:21:06]: [Client #228] Epoch: [1/5][0/16]	Loss: 0.978098
[INFO][09:21:06]: [Client #368] Epoch: [1/5][0/16]	Loss: 0.982908
[INFO][09:21:06]: [Client #228] Epoch: [1/5][10/16]	Loss: 0.951458
[INFO][09:21:06]: [Client #228] Going to sleep for 7.25 seconds.
[INFO][09:21:06]: [Client #368] Epoch: [1/5][10/16]	Loss: 1.973071
[INFO][09:21:07]: [Client #368] Going to sleep for 1.20 seconds.
[INFO][09:21:08]: [Client #368] Woke up.
[INFO][09:21:08]: [Client #368] Epoch: [2/5][0/16]	Loss: 1.490103
[INFO][09:21:08]: [Client #368] Epoch: [2/5][10/16]	Loss: 2.576714
[INFO][09:21:08]: [Client #368] Going to sleep for 1.20 seconds.
[INFO][09:21:09]: [Client #368] Woke up.
[INFO][09:21:09]: [Client #368] Epoch: [3/5][0/16]	Loss: 1.856679
[INFO][09:21:09]: [Client #368] Epoch: [3/5][10/16]	Loss: 0.841869
[INFO][09:21:09]: [Client #368] Going to sleep for 1.20 seconds.
[INFO][09:21:10]: [Client #368] Woke up.
[INFO][09:21:10]: [Client #368] Epoch: [4/5][0/16]	Loss: 0.814123
[INFO][09:21:11]: [Client #368] Epoch: [4/5][10/16]	Loss: 0.554510
[INFO][09:21:11]: [Client #368] Going to sleep for 1.20 seconds.
[INFO][09:21:12]: [Client #368] Woke up.
[INFO][09:21:12]: [Client #368] Epoch: [5/5][0/16]	Loss: 2.091801
[INFO][09:21:12]: [Client #368] Epoch: [5/5][10/16]	Loss: 1.103776
[INFO][09:21:12]: [Client #368] Going to sleep for 1.20 seconds.
[INFO][09:21:13]: [Client #368] Woke up.
[INFO][09:21:13]: [Client #368] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_368_554853.pth.
[INFO][09:21:14]: [Client #228] Woke up.
[INFO][09:21:14]: [Client #228] Epoch: [2/5][0/16]	Loss: 0.423896
[INFO][09:21:14]: [Client #368] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_368_554853.pth.
[INFO][09:21:14]: [Client #368] Model trained.
[INFO][09:21:14]: [Client #368] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:21:14]: [Server #554754] Received 0.26 MB of payload data from client #368 (simulated).
[INFO][09:21:14]: [Client #228] Epoch: [2/5][10/16]	Loss: 0.730324
[INFO][09:21:14]: [Client #228] Going to sleep for 7.25 seconds.
[INFO][09:21:21]: [Client #228] Woke up.
[INFO][09:21:21]: [Client #228] Epoch: [3/5][0/16]	Loss: 0.376724
[INFO][09:21:21]: [Client #228] Epoch: [3/5][10/16]	Loss: 2.109724
[INFO][09:21:21]: [Client #228] Going to sleep for 7.25 seconds.
[INFO][09:21:29]: [Client #228] Woke up.
[INFO][09:21:29]: [Client #228] Epoch: [4/5][0/16]	Loss: 1.275598
[INFO][09:21:29]: [Client #228] Epoch: [4/5][10/16]	Loss: 1.320639
[INFO][09:21:29]: [Client #228] Going to sleep for 7.25 seconds.
[INFO][09:21:36]: [Client #228] Woke up.
[INFO][09:21:36]: [Client #228] Epoch: [5/5][0/16]	Loss: 0.676380
[INFO][09:21:36]: [Client #228] Epoch: [5/5][10/16]	Loss: 1.388909
[INFO][09:21:36]: [Client #228] Going to sleep for 7.25 seconds.
[INFO][09:21:43]: [Client #228] Woke up.
[INFO][09:21:43]: [Client #228] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_228_554860.pth.
[INFO][09:21:44]: [Client #228] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_228_554860.pth.
[INFO][09:21:44]: [Client #228] Model trained.
[INFO][09:21:44]: [Client #228] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:21:44]: [Server #554754] Received 0.26 MB of payload data from client #228 (simulated).
[INFO][09:21:44]: [Server #554754] Selecting client #189 for training.
[INFO][09:21:44]: [Server #554754] Sending the current model to client #189 (simulated).
[INFO][09:21:44]: [Server #554754] Sending 0.26 MB of payload data to client #189 (simulated).
[INFO][09:21:44]: [Server #554754] Selecting client #173 for training.
[INFO][09:21:44]: [Server #554754] Sending the current model to client #173 (simulated).
[INFO][09:21:44]: [Server #554754] Sending 0.26 MB of payload data to client #173 (simulated).
[INFO][09:21:44]: [Client #189] Selected by the server.
[INFO][09:21:44]: [Client #189] Loading its data source...
[INFO][09:21:44]: [Client #173] Selected by the server.
[INFO][09:21:44]: Data source: FEMNIST
[INFO][09:21:44]: [Client #173] Loading its data source...
[INFO][09:21:44]: Data source: FEMNIST
[INFO][09:21:44]: [Client #173] Dataset size: 163
[INFO][09:21:44]: [Client #173] Sampler: all_inclusive
[INFO][09:21:44]: [Client #173] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:21:44]: [93m[1m[Client #173] Started training in communication round #12.[0m
[INFO][09:21:44]: [Client #189] Dataset size: 302
[INFO][09:21:44]: [Client #189] Sampler: all_inclusive
[INFO][09:21:44]: [Client #189] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:21:44]: [93m[1m[Client #189] Started training in communication round #12.[0m
[INFO][09:21:46]: [Client #173] Loading the dataset.
[INFO][09:21:46]: [Client #189] Loading the dataset.
[INFO][09:21:51]: [Client #173] Epoch: [1/5][0/17]	Loss: 1.203271
[INFO][09:21:52]: [Client #173] Epoch: [1/5][10/17]	Loss: 0.203112
[INFO][09:21:52]: [Client #189] Epoch: [1/5][0/31]	Loss: 2.743688
[INFO][09:21:52]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][09:21:52]: [Client #189] Epoch: [1/5][10/31]	Loss: 2.508064
[INFO][09:21:52]: [Client #189] Epoch: [1/5][20/31]	Loss: 2.350994
[INFO][09:21:52]: [Client #189] Epoch: [1/5][30/31]	Loss: 2.777336
[INFO][09:21:52]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][09:21:53]: [Client #189] Woke up.
[INFO][09:21:53]: [Client #189] Epoch: [2/5][0/31]	Loss: 2.422199
[INFO][09:21:53]: [Client #173] Woke up.
[INFO][09:21:53]: [Client #173] Epoch: [2/5][0/17]	Loss: 0.802299
[INFO][09:21:53]: [Client #189] Epoch: [2/5][10/31]	Loss: 2.406094
[INFO][09:21:53]: [Client #173] Epoch: [2/5][10/17]	Loss: 1.328712
[INFO][09:21:53]: [Client #189] Epoch: [2/5][20/31]	Loss: 2.540742
[INFO][09:21:53]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][09:21:53]: [Client #189] Epoch: [2/5][30/31]	Loss: 0.405415
[INFO][09:21:53]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][09:21:54]: [Client #189] Woke up.
[INFO][09:21:54]: [Client #189] Epoch: [3/5][0/31]	Loss: 1.596973
[INFO][09:21:54]: [Client #189] Epoch: [3/5][10/31]	Loss: 2.445034
[INFO][09:21:54]: [Client #189] Epoch: [3/5][20/31]	Loss: 2.230470
[INFO][09:21:55]: [Client #173] Woke up.
[INFO][09:21:55]: [Client #189] Epoch: [3/5][30/31]	Loss: 2.191060
[INFO][09:21:55]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][09:21:55]: [Client #173] Epoch: [3/5][0/17]	Loss: 0.289578
[INFO][09:21:55]: [Client #173] Epoch: [3/5][10/17]	Loss: 1.349430
[INFO][09:21:55]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][09:21:56]: [Client #189] Woke up.
[INFO][09:21:56]: [Client #189] Epoch: [4/5][0/31]	Loss: 1.384466
[INFO][09:21:56]: [Client #189] Epoch: [4/5][10/31]	Loss: 2.232424
[INFO][09:21:56]: [Client #189] Epoch: [4/5][20/31]	Loss: 1.751457
[INFO][09:21:56]: [Client #189] Epoch: [4/5][30/31]	Loss: 1.704878
[INFO][09:21:56]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][09:21:56]: [Client #173] Woke up.
[INFO][09:21:56]: [Client #173] Epoch: [4/5][0/17]	Loss: 0.736296
[INFO][09:21:56]: [Client #173] Epoch: [4/5][10/17]	Loss: 1.378829
[INFO][09:21:56]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][09:21:57]: [Client #189] Woke up.
[INFO][09:21:57]: [Client #189] Epoch: [5/5][0/31]	Loss: 1.641625
[INFO][09:21:57]: [Client #189] Epoch: [5/5][10/31]	Loss: 1.998166
[INFO][09:21:57]: [Client #189] Epoch: [5/5][20/31]	Loss: 1.378872
[INFO][09:21:57]: [Client #189] Epoch: [5/5][30/31]	Loss: 1.068260
[INFO][09:21:57]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][09:21:58]: [Client #173] Woke up.
[INFO][09:21:58]: [Client #173] Epoch: [5/5][0/17]	Loss: 0.992658
[INFO][09:21:58]: [Client #173] Epoch: [5/5][10/17]	Loss: 1.479469
[INFO][09:21:58]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][09:21:58]: [Client #189] Woke up.
[INFO][09:21:58]: [Client #189] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_189_554853.pth.
[INFO][09:21:59]: [Client #189] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_189_554853.pth.
[INFO][09:21:59]: [Client #189] Model trained.
[INFO][09:21:59]: [Client #189] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:21:59]: [Server #554754] Received 0.26 MB of payload data from client #189 (simulated).
[INFO][09:21:59]: [Client #173] Woke up.
[INFO][09:21:59]: [Client #173] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554860.pth.
[INFO][09:22:00]: [Client #173] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554860.pth.
[INFO][09:22:00]: [Client #173] Model trained.
[INFO][09:22:00]: [Client #173] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:22:00]: [Server #554754] Received 0.26 MB of payload data from client #173 (simulated).
[INFO][09:22:00]: [Server #554754] Selecting client #343 for training.
[INFO][09:22:00]: [Server #554754] Sending the current model to client #343 (simulated).
[INFO][09:22:00]: [Server #554754] Sending 0.26 MB of payload data to client #343 (simulated).
[INFO][09:22:00]: [Server #554754] Selecting client #140 for training.
[INFO][09:22:00]: [Server #554754] Sending the current model to client #140 (simulated).
[INFO][09:22:00]: [Server #554754] Sending 0.26 MB of payload data to client #140 (simulated).
[INFO][09:22:00]: [Client #140] Selected by the server.
[INFO][09:22:00]: [Client #343] Selected by the server.
[INFO][09:22:00]: [Client #140] Loading its data source...
[INFO][09:22:00]: [Client #343] Loading its data source...
[INFO][09:22:00]: Data source: FEMNIST
[INFO][09:22:00]: Data source: FEMNIST
[INFO][09:22:00]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:22:00]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/343.zip.
[INFO][09:22:00]: [Client #140] Dataset size: 152
[INFO][09:22:00]: [Client #140] Sampler: all_inclusive
[INFO][09:22:00]: [Client #140] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:22:00]: [93m[1m[Client #140] Started training in communication round #12.[0m

2.6%
5.2%
7.8%
10.4%
13.0%
15.6%
18.2%
20.8%
23.4%
26.0%
28.6%
31.2%
33.8%
36.4%
39.0%
41.6%
44.2%
46.8%
49.4%
52.0%
54.6%
57.2%
59.8%
62.4%
65.0%
67.6%
70.2%
72.8%
75.4%
78.0%
80.6%
83.2%
85.8%
88.4%
91.0%
93.6%
96.2%
98.8%
100.0%[INFO][09:22:00]: Decompressing the dataset downloaded.
[INFO][09:22:00]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/343.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:22:00]: [Client #343] Dataset size: 155
[INFO][09:22:00]: [Client #343] Sampler: all_inclusive
[INFO][09:22:00]: [Client #343] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:22:00]: [93m[1m[Client #343] Started training in communication round #12.[0m

[INFO][09:22:02]: [Client #140] Loading the dataset.
[INFO][09:22:02]: [Client #343] Loading the dataset.
[INFO][09:22:07]: [Client #140] Epoch: [1/5][0/16]	Loss: 1.150862
[INFO][09:22:07]: [Client #140] Epoch: [1/5][10/16]	Loss: 1.007606
[INFO][09:22:07]: [Client #343] Epoch: [1/5][0/16]	Loss: 1.140047
[INFO][09:22:07]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:22:08]: [Client #343] Epoch: [1/5][10/16]	Loss: 2.003438
[INFO][09:22:08]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][09:22:10]: [Client #140] Woke up.
[INFO][09:22:10]: [Client #140] Epoch: [2/5][0/16]	Loss: 0.885923
[INFO][09:22:10]: [Client #140] Epoch: [2/5][10/16]	Loss: 1.179881
[INFO][09:22:11]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:22:12]: [Client #343] Woke up.
[INFO][09:22:12]: [Client #343] Epoch: [2/5][0/16]	Loss: 0.816311
[INFO][09:22:12]: [Client #343] Epoch: [2/5][10/16]	Loss: 1.740062
[INFO][09:22:12]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][09:22:13]: [Client #140] Woke up.
[INFO][09:22:14]: [Client #140] Epoch: [3/5][0/16]	Loss: 1.288328
[INFO][09:22:14]: [Client #140] Epoch: [3/5][10/16]	Loss: 2.095286
[INFO][09:22:14]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:22:17]: [Client #140] Woke up.
[INFO][09:22:17]: [Client #140] Epoch: [4/5][0/16]	Loss: 1.099509
[INFO][09:22:17]: [Client #140] Epoch: [4/5][10/16]	Loss: 0.535564
[INFO][09:22:17]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:22:17]: [Client #343] Woke up.
[INFO][09:22:17]: [Client #343] Epoch: [3/5][0/16]	Loss: 1.168427
[INFO][09:22:17]: [Client #343] Epoch: [3/5][10/16]	Loss: 0.755089
[INFO][09:22:17]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][09:22:20]: [Client #140] Woke up.
[INFO][09:22:20]: [Client #140] Epoch: [5/5][0/16]	Loss: 1.849340
[INFO][09:22:20]: [Client #140] Epoch: [5/5][10/16]	Loss: 1.196490
[INFO][09:22:20]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:22:22]: [Client #343] Woke up.
[INFO][09:22:22]: [Client #343] Epoch: [4/5][0/16]	Loss: 1.072867
[INFO][09:22:22]: [Client #343] Epoch: [4/5][10/16]	Loss: 1.427083
[INFO][09:22:22]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][09:22:23]: [Client #140] Woke up.
[INFO][09:22:23]: [Client #140] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_554860.pth.
[INFO][09:22:23]: [Client #140] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_554860.pth.
[INFO][09:22:23]: [Client #140] Model trained.
[INFO][09:22:23]: [Client #140] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:22:23]: [Server #554754] Received 0.26 MB of payload data from client #140 (simulated).
[INFO][09:22:27]: [Client #343] Woke up.
[INFO][09:22:27]: [Client #343] Epoch: [5/5][0/16]	Loss: 1.786464
[INFO][09:22:27]: [Client #343] Epoch: [5/5][10/16]	Loss: 1.265401
[INFO][09:22:27]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][09:22:32]: [Client #343] Woke up.
[INFO][09:22:32]: [Client #343] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_343_554853.pth.
[INFO][09:22:33]: [Client #343] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_343_554853.pth.
[INFO][09:22:33]: [Client #343] Model trained.
[INFO][09:22:33]: [Client #343] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:22:33]: [Server #554754] Received 0.26 MB of payload data from client #343 (simulated).
[INFO][09:22:33]: [Server #554754] Adding client #476 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #179 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #345 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #171 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #356 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #291 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #368 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #189 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #483 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Adding client #173 to the list of clients for aggregation.
[INFO][09:22:33]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09191972 0.         0.10522108 0.
 0.         0.         0.         0.         0.07624721 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.24431442 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07899809 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12594998 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.2388096  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12770762 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0726294  0.         0.         0.         0.
 0.         0.         0.08862546 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09191972 0.         0.10522108 0.
 0.         0.         0.         0.         0.07624721 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.24431442 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07899809 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12594998 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.2388096  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12770762 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0726294  0.         0.         0.         0.
 0.         0.         0.08862546 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:23:16]: [Server #554754] Global model accuracy: 54.45%

[INFO][09:23:16]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_12.pth.
[INFO][09:23:16]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_12.pth.
[INFO][09:23:16]: [93m[1m
[Server #554754] Starting round 13/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.002      0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.002      0.002      0.002      0.04730139 0.002
 0.08247423 0.002      0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04717531
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.002
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.04076878 0.002      0.08719647 0.002      0.002      0.08764045
 0.002      0.08202247 0.002      0.002      0.002      0.002
 0.002      0.09355391 0.04451314 0.002      0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.04804892
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.002      0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.002      0.08674827 0.002      0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.08386721 0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.002      0.04888179 0.12719532 0.002      0.002      0.002
 0.04717531 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.002      0.10114504 0.002      0.002      0.002
 0.09144543 0.002      0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.04222481 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.002      0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.002      0.002      0.002      0.002      0.10384615 0.002
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.04455446 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][09:23:16]: [Server #554754] Selected clients: [405 146 271 243 429 445  91 292 450 220]
[INFO][09:23:16]: [Server #554754] Selecting client #405 for training.
[INFO][09:23:16]: [Server #554754] Sending the current model to client #405 (simulated).
[INFO][09:23:16]: [Server #554754] Sending 0.26 MB of payload data to client #405 (simulated).
[INFO][09:23:16]: [Server #554754] Selecting client #146 for training.
[INFO][09:23:16]: [Server #554754] Sending the current model to client #146 (simulated).
[INFO][09:23:16]: [Server #554754] Sending 0.26 MB of payload data to client #146 (simulated).
[INFO][09:23:16]: [Client #405] Selected by the server.
[INFO][09:23:16]: [Client #405] Loading its data source...
[INFO][09:23:16]: Data source: FEMNIST
[INFO][09:23:16]: [Client #146] Selected by the server.
[INFO][09:23:16]: [Client #146] Loading its data source...
[INFO][09:23:16]: Data source: FEMNIST
[INFO][09:23:16]: [Client #405] Dataset size: 159
[INFO][09:23:16]: [Client #405] Sampler: all_inclusive
[INFO][09:23:16]: [Client #405] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:16]: [Client #146] Dataset size: 156
[INFO][09:23:16]: [Client #146] Sampler: all_inclusive
[INFO][09:23:16]: [93m[1m[Client #405] Started training in communication round #13.[0m
[INFO][09:23:17]: [Client #146] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:17]: [93m[1m[Client #146] Started training in communication round #13.[0m
[INFO][09:23:18]: [Client #405] Loading the dataset.
[INFO][09:23:18]: [Client #146] Loading the dataset.
[INFO][09:23:24]: [Client #146] Epoch: [1/5][0/16]	Loss: 1.395076
[INFO][09:23:24]: [Client #405] Epoch: [1/5][0/16]	Loss: 0.185918
[INFO][09:23:24]: [Client #146] Epoch: [1/5][10/16]	Loss: 0.839672
[INFO][09:23:24]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][09:23:24]: [Client #405] Epoch: [1/5][10/16]	Loss: 1.584409
[INFO][09:23:24]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][09:23:24]: [Client #146] Woke up.
[INFO][09:23:24]: [Client #146] Epoch: [2/5][0/16]	Loss: 0.759811
[INFO][09:23:24]: [Client #146] Epoch: [2/5][10/16]	Loss: 1.348798
[INFO][09:23:24]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][09:23:24]: [Client #146] Woke up.
[INFO][09:23:24]: [Client #146] Epoch: [3/5][0/16]	Loss: 1.175346
[INFO][09:23:24]: [Client #146] Epoch: [3/5][10/16]	Loss: 0.934173
[INFO][09:23:24]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][09:23:25]: [Client #146] Woke up.
[INFO][09:23:25]: [Client #146] Epoch: [4/5][0/16]	Loss: 0.162971
[INFO][09:23:25]: [Client #146] Epoch: [4/5][10/16]	Loss: 1.930933
[INFO][09:23:25]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][09:23:25]: [Client #405] Woke up.
[INFO][09:23:25]: [Client #405] Epoch: [2/5][0/16]	Loss: 0.804543
[INFO][09:23:25]: [Client #146] Woke up.
[INFO][09:23:25]: [Client #146] Epoch: [5/5][0/16]	Loss: 0.580072
[INFO][09:23:25]: [Client #405] Epoch: [2/5][10/16]	Loss: 1.130432
[INFO][09:23:25]: [Client #146] Epoch: [5/5][10/16]	Loss: 1.621606
[INFO][09:23:25]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][09:23:25]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][09:23:25]: [Client #146] Woke up.
[INFO][09:23:25]: [Client #146] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554860.pth.
[INFO][09:23:26]: [Client #146] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554860.pth.
[INFO][09:23:26]: [Client #146] Model trained.
[INFO][09:23:26]: [Client #146] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:23:26]: [Server #554754] Received 0.26 MB of payload data from client #146 (simulated).
[INFO][09:23:26]: [Client #405] Woke up.
[INFO][09:23:26]: [Client #405] Epoch: [3/5][0/16]	Loss: 0.608085
[INFO][09:23:26]: [Client #405] Epoch: [3/5][10/16]	Loss: 0.067779
[INFO][09:23:26]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][09:23:27]: [Client #405] Woke up.
[INFO][09:23:27]: [Client #405] Epoch: [4/5][0/16]	Loss: 1.243622
[INFO][09:23:27]: [Client #405] Epoch: [4/5][10/16]	Loss: 0.492961
[INFO][09:23:27]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][09:23:28]: [Client #405] Woke up.
[INFO][09:23:28]: [Client #405] Epoch: [5/5][0/16]	Loss: 0.845638
[INFO][09:23:28]: [Client #405] Epoch: [5/5][10/16]	Loss: 0.872101
[INFO][09:23:28]: [Client #405] Going to sleep for 0.87 seconds.
[INFO][09:23:29]: [Client #405] Woke up.
[INFO][09:23:29]: [Client #405] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_554853.pth.
[INFO][09:23:30]: [Client #405] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_405_554853.pth.
[INFO][09:23:30]: [Client #405] Model trained.
[INFO][09:23:30]: [Client #405] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:23:30]: [Server #554754] Received 0.26 MB of payload data from client #405 (simulated).
[INFO][09:23:30]: [Server #554754] Selecting client #271 for training.
[INFO][09:23:30]: [Server #554754] Sending the current model to client #271 (simulated).
[INFO][09:23:30]: [Server #554754] Sending 0.26 MB of payload data to client #271 (simulated).
[INFO][09:23:30]: [Server #554754] Selecting client #243 for training.
[INFO][09:23:30]: [Server #554754] Sending the current model to client #243 (simulated).
[INFO][09:23:30]: [Server #554754] Sending 0.26 MB of payload data to client #243 (simulated).
[INFO][09:23:30]: [Client #243] Selected by the server.
[INFO][09:23:30]: [Client #243] Loading its data source...
[INFO][09:23:30]: Data source: FEMNIST
[INFO][09:23:30]: [Client #271] Selected by the server.
[INFO][09:23:30]: [Client #271] Loading its data source...
[INFO][09:23:30]: Data source: FEMNIST
[INFO][09:23:30]: [Client #271] Dataset size: 145
[INFO][09:23:30]: [Client #271] Sampler: all_inclusive
[INFO][09:23:30]: [Client #271] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:30]: [93m[1m[Client #271] Started training in communication round #13.[0m
[INFO][09:23:30]: [Client #243] Dataset size: 159
[INFO][09:23:30]: [Client #243] Sampler: all_inclusive
[INFO][09:23:30]: [Client #243] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:30]: [93m[1m[Client #243] Started training in communication round #13.[0m
[INFO][09:23:31]: [Client #271] Loading the dataset.
[INFO][09:23:31]: [Client #243] Loading the dataset.
[INFO][09:23:37]: [Client #271] Epoch: [1/5][0/15]	Loss: 1.230127
[INFO][09:23:37]: [Client #243] Epoch: [1/5][0/16]	Loss: 0.531546
[INFO][09:23:37]: [Client #271] Epoch: [1/5][10/15]	Loss: 1.412942
[INFO][09:23:37]: [Client #243] Epoch: [1/5][10/16]	Loss: 1.739532
[INFO][09:23:37]: [Client #271] Going to sleep for 0.67 seconds.
[INFO][09:23:37]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][09:23:38]: [Client #271] Woke up.
[INFO][09:23:38]: [Client #271] Epoch: [2/5][0/15]	Loss: 1.298073
[INFO][09:23:38]: [Client #271] Epoch: [2/5][10/15]	Loss: 0.464892
[INFO][09:23:38]: [Client #271] Going to sleep for 0.67 seconds.
[INFO][09:23:38]: [Client #243] Woke up.
[INFO][09:23:38]: [Client #243] Epoch: [2/5][0/16]	Loss: 1.004767
[INFO][09:23:38]: [Client #243] Epoch: [2/5][10/16]	Loss: 1.261856
[INFO][09:23:39]: [Client #271] Woke up.
[INFO][09:23:39]: [Client #271] Epoch: [3/5][0/15]	Loss: 1.102218
[INFO][09:23:39]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][09:23:39]: [Client #271] Epoch: [3/5][10/15]	Loss: 0.886536
[INFO][09:23:39]: [Client #271] Going to sleep for 0.67 seconds.
[INFO][09:23:39]: [Client #271] Woke up.
[INFO][09:23:39]: [Client #271] Epoch: [4/5][0/15]	Loss: 0.182292
[INFO][09:23:39]: [Client #271] Epoch: [4/5][10/15]	Loss: 0.894845
[INFO][09:23:39]: [Client #271] Going to sleep for 0.67 seconds.
[INFO][09:23:40]: [Client #243] Woke up.
[INFO][09:23:40]: [Client #243] Epoch: [3/5][0/16]	Loss: 0.940344
[INFO][09:23:40]: [Client #243] Epoch: [3/5][10/16]	Loss: 0.810632
[INFO][09:23:40]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][09:23:40]: [Client #271] Woke up.
[INFO][09:23:40]: [Client #271] Epoch: [5/5][0/15]	Loss: 0.525947
[INFO][09:23:40]: [Client #271] Epoch: [5/5][10/15]	Loss: 1.373692
[INFO][09:23:40]: [Client #271] Going to sleep for 0.67 seconds.
[INFO][09:23:41]: [Client #271] Woke up.
[INFO][09:23:41]: [Client #271] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_271_554853.pth.
[INFO][09:23:41]: [Client #243] Woke up.
[INFO][09:23:41]: [Client #243] Epoch: [4/5][0/16]	Loss: 0.938148
[INFO][09:23:42]: [Client #243] Epoch: [4/5][10/16]	Loss: 1.625779
[INFO][09:23:42]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][09:23:42]: [Client #271] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_271_554853.pth.
[INFO][09:23:42]: [Client #271] Model trained.
[INFO][09:23:42]: [Client #271] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:23:42]: [Server #554754] Received 0.26 MB of payload data from client #271 (simulated).
[INFO][09:23:43]: [Client #243] Woke up.
[INFO][09:23:43]: [Client #243] Epoch: [5/5][0/16]	Loss: 1.300612
[INFO][09:23:43]: [Client #243] Epoch: [5/5][10/16]	Loss: 1.389370
[INFO][09:23:43]: [Client #243] Going to sleep for 1.37 seconds.
[INFO][09:23:44]: [Client #243] Woke up.
[INFO][09:23:44]: [Client #243] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_243_554860.pth.
[INFO][09:23:45]: [Client #243] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_243_554860.pth.
[INFO][09:23:45]: [Client #243] Model trained.
[INFO][09:23:45]: [Client #243] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:23:45]: [Server #554754] Received 0.26 MB of payload data from client #243 (simulated).
[INFO][09:23:45]: [Server #554754] Selecting client #429 for training.
[INFO][09:23:45]: [Server #554754] Sending the current model to client #429 (simulated).
[INFO][09:23:45]: [Server #554754] Sending 0.26 MB of payload data to client #429 (simulated).
[INFO][09:23:45]: [Server #554754] Selecting client #445 for training.
[INFO][09:23:45]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][09:23:45]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][09:23:45]: [Client #445] Selected by the server.
[INFO][09:23:45]: [Client #429] Selected by the server.
[INFO][09:23:45]: [Client #445] Loading its data source...
[INFO][09:23:45]: [Client #429] Loading its data source...
[INFO][09:23:45]: Data source: FEMNIST
[INFO][09:23:45]: Data source: FEMNIST
[INFO][09:23:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:23:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:23:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/445.zip.
[INFO][09:23:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/429.zip.

2.8%
1.6%
3.2%
4.7%
6.3%
7.9%
9.5%
11.0%
12.6%
14.2%
15.8%
17.3%
18.9%
20.5%
22.1%
23.6%
25.2%
5.6%
8.4%
11.1%
13.9%
16.7%
19.5%
22.3%
25.1%
27.9%
30.6%
33.4%
36.2%
39.0%
41.8%
44.6%
47.4%
50.1%
52.9%
55.7%
58.5%
61.3%
64.1%
66.9%
69.6%
72.4%
75.2%
78.0%
80.8%
83.6%
86.4%
89.2%
91.9%
94.7%
97.5%
100.0%[INFO][09:23:45]: Decompressing the dataset downloaded.
[INFO][09:23:45]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/429.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.

26.8%
28.4%
29.9%
31.5%
33.1%
34.7%
36.2%
37.8%
39.4%
41.0%
42.5%
44.1%
45.7%
47.3%
48.8%
50.4%
52.0%[INFO][09:23:45]: [Client #429] Dataset size: 167
[INFO][09:23:45]: [Client #429] Sampler: all_inclusive
[INFO][09:23:45]: [Client #429] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:45]: [93m[1m[Client #429] Started training in communication round #13.[0m


53.6%
55.1%
56.7%
58.3%
59.9%
61.4%
63.0%
64.6%
66.2%
67.7%
69.3%
70.9%
72.5%
74.0%
75.6%
77.2%
78.8%
80.3%
81.9%
83.5%
85.1%
86.6%
88.2%
89.8%
91.4%
92.9%
94.5%
96.1%
97.7%
99.2%
100.0%[INFO][09:23:45]: Decompressing the dataset downloaded.
[INFO][09:23:45]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/445.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:23:45]: [Client #445] Dataset size: 292
[INFO][09:23:45]: [Client #445] Sampler: all_inclusive
[INFO][09:23:45]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:23:45]: [93m[1m[Client #445] Started training in communication round #13.[0m

[INFO][09:23:47]: [Client #429] Loading the dataset.
[INFO][09:23:47]: [Client #445] Loading the dataset.
[INFO][09:23:53]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.272406
[INFO][09:23:53]: [Client #429] Epoch: [1/5][0/17]	Loss: 2.425975
[INFO][09:23:53]: [Client #429] Epoch: [1/5][10/17]	Loss: 1.344211
[INFO][09:23:53]: [Client #445] Epoch: [1/5][10/30]	Loss: 1.496573
[INFO][09:23:53]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][09:23:53]: [Client #445] Epoch: [1/5][20/30]	Loss: 1.655147
[INFO][09:23:53]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:23:54]: [Client #429] Woke up.
[INFO][09:23:54]: [Client #429] Epoch: [2/5][0/17]	Loss: 0.439190
[INFO][09:23:54]: [Client #429] Epoch: [2/5][10/17]	Loss: 0.538628
[INFO][09:23:54]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][09:23:54]: [Client #429] Woke up.
[INFO][09:23:54]: [Client #429] Epoch: [3/5][0/17]	Loss: 0.985633
[INFO][09:23:55]: [Client #429] Epoch: [3/5][10/17]	Loss: 1.280942
[INFO][09:23:55]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][09:23:55]: [Client #429] Woke up.
[INFO][09:23:55]: [Client #429] Epoch: [4/5][0/17]	Loss: 1.055077
[INFO][09:23:55]: [Client #429] Epoch: [4/5][10/17]	Loss: 0.852861
[INFO][09:23:55]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][09:23:56]: [Client #429] Woke up.
[INFO][09:23:56]: [Client #429] Epoch: [5/5][0/17]	Loss: 2.970256
[INFO][09:23:56]: [Client #429] Epoch: [5/5][10/17]	Loss: 1.010531
[INFO][09:23:56]: [Client #429] Going to sleep for 0.65 seconds.
[INFO][09:23:57]: [Client #429] Woke up.
[INFO][09:23:57]: [Client #429] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_429_554853.pth.
[INFO][09:23:57]: [Client #429] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_429_554853.pth.
[INFO][09:23:57]: [Client #429] Model trained.
[INFO][09:23:57]: [Client #429] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:23:57]: [Server #554754] Received 0.26 MB of payload data from client #429 (simulated).
[INFO][09:24:13]: [Client #445] Woke up.
[INFO][09:24:13]: [Client #445] Epoch: [2/5][0/30]	Loss: 0.979617
[INFO][09:24:13]: [Client #445] Epoch: [2/5][10/30]	Loss: 1.274095
[INFO][09:24:13]: [Client #445] Epoch: [2/5][20/30]	Loss: 1.426384
[INFO][09:24:13]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:24:32]: [Client #445] Woke up.
[INFO][09:24:33]: [Client #445] Epoch: [3/5][0/30]	Loss: 2.552152
[INFO][09:24:33]: [Client #445] Epoch: [3/5][10/30]	Loss: 1.432966
[INFO][09:24:33]: [Client #445] Epoch: [3/5][20/30]	Loss: 1.188458
[INFO][09:24:33]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:24:52]: [Client #445] Woke up.
[INFO][09:24:52]: [Client #445] Epoch: [4/5][0/30]	Loss: 1.683270
[INFO][09:24:53]: [Client #445] Epoch: [4/5][10/30]	Loss: 1.712494
[INFO][09:24:53]: [Client #445] Epoch: [4/5][20/30]	Loss: 1.175833
[INFO][09:24:53]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:25:12]: [Client #445] Woke up.
[INFO][09:25:12]: [Client #445] Epoch: [5/5][0/30]	Loss: 1.664747
[INFO][09:25:12]: [Client #445] Epoch: [5/5][10/30]	Loss: 1.166722
[INFO][09:25:13]: [Client #445] Epoch: [5/5][20/30]	Loss: 1.795200
[INFO][09:25:13]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:25:32]: [Client #445] Woke up.
[INFO][09:25:32]: [Client #445] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][09:25:33]: [Client #445] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][09:25:33]: [Client #445] Model trained.
[INFO][09:25:33]: [Client #445] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:25:33]: [Server #554754] Received 0.26 MB of payload data from client #445 (simulated).
[INFO][09:25:33]: [Server #554754] Selecting client #91 for training.
[INFO][09:25:33]: [Server #554754] Sending the current model to client #91 (simulated).
[INFO][09:25:33]: [Server #554754] Sending 0.26 MB of payload data to client #91 (simulated).
[INFO][09:25:33]: [Server #554754] Selecting client #292 for training.
[INFO][09:25:33]: [Server #554754] Sending the current model to client #292 (simulated).
[INFO][09:25:33]: [Server #554754] Sending 0.26 MB of payload data to client #292 (simulated).
[INFO][09:25:33]: [Client #91] Selected by the server.
[INFO][09:25:33]: [Client #292] Selected by the server.
[INFO][09:25:33]: [Client #91] Loading its data source...
[INFO][09:25:33]: [Client #292] Loading its data source...
[INFO][09:25:33]: Data source: FEMNIST
[INFO][09:25:33]: Data source: FEMNIST
[INFO][09:25:33]: [Client #292] Dataset size: 142
[INFO][09:25:33]: [Client #292] Sampler: all_inclusive
[INFO][09:25:33]: [Client #292] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:25:33]: [93m[1m[Client #292] Started training in communication round #13.[0m
[INFO][09:25:33]: [Client #91] Dataset size: 162
[INFO][09:25:33]: [Client #91] Sampler: all_inclusive
[INFO][09:25:33]: [Client #91] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:25:33]: [93m[1m[Client #91] Started training in communication round #13.[0m
[INFO][09:25:35]: [Client #292] Loading the dataset.
[INFO][09:25:35]: [Client #91] Loading the dataset.
[INFO][09:25:40]: [Client #292] Epoch: [1/5][0/15]	Loss: 0.723450
[INFO][09:25:40]: [Client #292] Epoch: [1/5][10/15]	Loss: 0.692240
[INFO][09:25:40]: [Client #91] Epoch: [1/5][0/17]	Loss: 2.227742
[INFO][09:25:40]: [Client #292] Going to sleep for 3.36 seconds.
[INFO][09:25:40]: [Client #91] Epoch: [1/5][10/17]	Loss: 3.587161
[INFO][09:25:40]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][09:25:41]: [Client #91] Woke up.
[INFO][09:25:41]: [Client #91] Epoch: [2/5][0/17]	Loss: 1.976342
[INFO][09:25:41]: [Client #91] Epoch: [2/5][10/17]	Loss: 1.069934
[INFO][09:25:41]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][09:25:41]: [Client #91] Woke up.
[INFO][09:25:41]: [Client #91] Epoch: [3/5][0/17]	Loss: 1.195774
[INFO][09:25:41]: [Client #91] Epoch: [3/5][10/17]	Loss: 1.360705
[INFO][09:25:41]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][09:25:41]: [Client #91] Woke up.
[INFO][09:25:41]: [Client #91] Epoch: [4/5][0/17]	Loss: 1.388642
[INFO][09:25:41]: [Client #91] Epoch: [4/5][10/17]	Loss: 1.790431
[INFO][09:25:41]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][09:25:41]: [Client #91] Woke up.
[INFO][09:25:41]: [Client #91] Epoch: [5/5][0/17]	Loss: 0.722439
[INFO][09:25:42]: [Client #91] Epoch: [5/5][10/17]	Loss: 1.617800
[INFO][09:25:42]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][09:25:42]: [Client #91] Woke up.
[INFO][09:25:42]: [Client #91] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_91_554853.pth.
[INFO][09:25:42]: [Client #91] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_91_554853.pth.
[INFO][09:25:42]: [Client #91] Model trained.
[INFO][09:25:42]: [Client #91] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:25:42]: [Server #554754] Received 0.26 MB of payload data from client #91 (simulated).
[INFO][09:25:44]: [Client #292] Woke up.
[INFO][09:25:44]: [Client #292] Epoch: [2/5][0/15]	Loss: 1.175675
[INFO][09:25:44]: [Client #292] Epoch: [2/5][10/15]	Loss: 0.692879
[INFO][09:25:44]: [Client #292] Going to sleep for 3.36 seconds.
[INFO][09:25:47]: [Client #292] Woke up.
[INFO][09:25:47]: [Client #292] Epoch: [3/5][0/15]	Loss: 1.655354
[INFO][09:25:47]: [Client #292] Epoch: [3/5][10/15]	Loss: 1.329574
[INFO][09:25:47]: [Client #292] Going to sleep for 3.36 seconds.
[INFO][09:25:51]: [Client #292] Woke up.
[INFO][09:25:51]: [Client #292] Epoch: [4/5][0/15]	Loss: 0.915056
[INFO][09:25:51]: [Client #292] Epoch: [4/5][10/15]	Loss: 1.263157
[INFO][09:25:51]: [Client #292] Going to sleep for 3.36 seconds.
[INFO][09:25:54]: [Client #292] Woke up.
[INFO][09:25:54]: [Client #292] Epoch: [5/5][0/15]	Loss: 0.680376
[INFO][09:25:54]: [Client #292] Epoch: [5/5][10/15]	Loss: 1.646011
[INFO][09:25:54]: [Client #292] Going to sleep for 3.36 seconds.
[INFO][09:25:58]: [Client #292] Woke up.
[INFO][09:25:58]: [Client #292] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_292_554860.pth.
[INFO][09:25:58]: [Client #292] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_292_554860.pth.
[INFO][09:25:58]: [Client #292] Model trained.
[INFO][09:25:58]: [Client #292] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:25:58]: [Server #554754] Received 0.26 MB of payload data from client #292 (simulated).
[INFO][09:25:58]: [Server #554754] Selecting client #450 for training.
[INFO][09:25:58]: [Server #554754] Sending the current model to client #450 (simulated).
[INFO][09:25:58]: [Server #554754] Sending 0.26 MB of payload data to client #450 (simulated).
[INFO][09:25:58]: [Server #554754] Selecting client #220 for training.
[INFO][09:25:58]: [Server #554754] Sending the current model to client #220 (simulated).
[INFO][09:25:58]: [Server #554754] Sending 0.26 MB of payload data to client #220 (simulated).
[INFO][09:25:58]: [Client #450] Selected by the server.
[INFO][09:25:58]: [Client #220] Selected by the server.
[INFO][09:25:58]: [Client #450] Loading its data source...
[INFO][09:25:58]: [Client #220] Loading its data source...
[INFO][09:25:58]: Data source: FEMNIST
[INFO][09:25:58]: Data source: FEMNIST
[INFO][09:25:58]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:25:58]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/450.zip.
[INFO][09:25:58]: [Client #220] Dataset size: 164
[INFO][09:25:58]: [Client #220] Sampler: all_inclusive
[INFO][09:25:58]: [Client #220] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:25:58]: [93m[1m[Client #220] Started training in communication round #13.[0m

2.1%
4.2%
6.3%
8.4%
10.5%
12.7%
14.8%
16.9%
19.0%
21.1%
23.2%
25.3%
27.4%
29.5%
31.6%
33.7%
35.8%
38.0%
40.1%
42.2%
44.3%
46.4%
48.5%
50.6%
52.7%
54.8%
56.9%
59.0%
61.1%
63.3%
65.4%
67.5%
69.6%
71.7%
73.8%
75.9%
78.0%
80.1%
82.2%
84.3%
86.5%
88.6%
90.7%
92.8%
94.9%
97.0%
99.1%
100.0%[INFO][09:25:59]: Decompressing the dataset downloaded.
[INFO][09:25:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/450.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:25:59]: [Client #450] Dataset size: 162
[INFO][09:25:59]: [Client #450] Sampler: all_inclusive
[INFO][09:25:59]: [Client #450] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:25:59]: [93m[1m[Client #450] Started training in communication round #13.[0m

[INFO][09:26:00]: [Client #220] Loading the dataset.
[INFO][09:26:01]: [Client #450] Loading the dataset.
[INFO][09:26:06]: [Client #450] Epoch: [1/5][0/17]	Loss: 1.953480
[INFO][09:26:06]: [Client #220] Epoch: [1/5][0/17]	Loss: 0.682365
[INFO][09:26:06]: [Client #450] Epoch: [1/5][10/17]	Loss: 1.579410
[INFO][09:26:06]: [Client #220] Epoch: [1/5][10/17]	Loss: 0.643026
[INFO][09:26:06]: [Client #450] Going to sleep for 0.19 seconds.
[INFO][09:26:06]: [Client #220] Going to sleep for 0.02 seconds.
[INFO][09:26:06]: [Client #220] Woke up.
[INFO][09:26:06]: [Client #220] Epoch: [2/5][0/17]	Loss: 0.490429
[INFO][09:26:06]: [Client #220] Epoch: [2/5][10/17]	Loss: 1.289390
[INFO][09:26:06]: [Client #450] Woke up.
[INFO][09:26:06]: [Client #450] Epoch: [2/5][0/17]	Loss: 0.999211
[INFO][09:26:06]: [Client #220] Going to sleep for 0.02 seconds.
[INFO][09:26:06]: [Client #220] Woke up.
[INFO][09:26:06]: [Client #220] Epoch: [3/5][0/17]	Loss: 0.813908
[INFO][09:26:06]: [Client #450] Epoch: [2/5][10/17]	Loss: 1.420588
[INFO][09:26:06]: [Client #220] Epoch: [3/5][10/17]	Loss: 0.782271
[INFO][09:26:06]: [Client #450] Going to sleep for 0.19 seconds.
[INFO][09:26:06]: [Client #220] Going to sleep for 0.02 seconds.
[INFO][09:26:06]: [Client #220] Woke up.
[INFO][09:26:06]: [Client #220] Epoch: [4/5][0/17]	Loss: 1.448665
[INFO][09:26:06]: [Client #220] Epoch: [4/5][10/17]	Loss: 1.516655
[INFO][09:26:06]: [Client #450] Woke up.
[INFO][09:26:07]: [Client #220] Going to sleep for 0.02 seconds.
[INFO][09:26:07]: [Client #450] Epoch: [3/5][0/17]	Loss: 1.657305
[INFO][09:26:07]: [Client #220] Woke up.
[INFO][09:26:07]: [Client #220] Epoch: [5/5][0/17]	Loss: 1.829136
[INFO][09:26:07]: [Client #450] Epoch: [3/5][10/17]	Loss: 3.101981
[INFO][09:26:07]: [Client #220] Epoch: [5/5][10/17]	Loss: 0.387794
[INFO][09:26:07]: [Client #450] Going to sleep for 0.19 seconds.
[INFO][09:26:07]: [Client #220] Going to sleep for 0.02 seconds.
[INFO][09:26:07]: [Client #220] Woke up.
[INFO][09:26:07]: [Client #220] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_220_554860.pth.
[INFO][09:26:07]: [Client #450] Woke up.
[INFO][09:26:07]: [Client #450] Epoch: [4/5][0/17]	Loss: 0.563627
[INFO][09:26:07]: [Client #450] Epoch: [4/5][10/17]	Loss: 1.362532
[INFO][09:26:07]: [Client #450] Going to sleep for 0.19 seconds.
[INFO][09:26:07]: [Client #450] Woke up.
[INFO][09:26:07]: [Client #450] Epoch: [5/5][0/17]	Loss: 1.681002
[INFO][09:26:07]: [Client #450] Epoch: [5/5][10/17]	Loss: 0.571471
[INFO][09:26:07]: [Client #450] Going to sleep for 0.19 seconds.
[INFO][09:26:07]: [Client #220] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_220_554860.pth.
[INFO][09:26:07]: [Client #220] Model trained.
[INFO][09:26:07]: [Client #220] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:26:07]: [Server #554754] Received 0.26 MB of payload data from client #220 (simulated).
[INFO][09:26:07]: [Client #450] Woke up.
[INFO][09:26:08]: [Client #450] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_450_554853.pth.
[INFO][09:26:08]: [Client #450] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_450_554853.pth.
[INFO][09:26:08]: [Client #450] Model trained.
[INFO][09:26:08]: [Client #450] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:26:08]: [Server #554754] Received 0.26 MB of payload data from client #450 (simulated).
[INFO][09:26:08]: [Server #554754] Adding client #290 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #140 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #220 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #146 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #91 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #450 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #271 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #429 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #349 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #405 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #240 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #243 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #419 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #343 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #292 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #228 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #311 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #250 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Adding client #475 to the list of clients for aggregation.
[INFO][09:26:08]: [Server #554754] Aggregating 19 clients in total.
[0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204057 0.00204086 0.00204031 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204059 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.0020307  0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204055 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00203917 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00203215
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204013
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204068 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204059 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086 0.00204086
 0.00204086 0.00204086 0.00204086 0.00204086]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16549773 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15939213 0.         0.         0.         0.
 0.         0.13736927 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10070527 0.         0.
 0.         0.         0.         0.         0.         0.10655182
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09607273
 0.         0.         0.07970565 0.         0.         0.
 0.         0.         0.         0.08564908 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10387658 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09750212 0.         0.10107754 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18170269 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09558476 0.         0.         0.         0.         0.
 0.16592172 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07797458 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1460451  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1011058  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17309507
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1528534  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16549773 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15939213 0.         0.         0.         0.
 0.         0.13736927 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.10070527 0.         0.
 0.         0.         0.         0.         0.         0.10655182
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09607273
 0.         0.         0.07970565 0.         0.         0.
 0.         0.         0.         0.08564908 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10387658 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09750212 0.         0.10107754 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18170269 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09558476 0.         0.         0.         0.         0.
 0.16592172 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.07797458 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1460451  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1011058  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17309507
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1528534  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:26:52]: [Server #554754] Global model accuracy: 53.76%

[INFO][09:26:52]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_13.pth.
[INFO][09:26:52]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_13.pth.
[INFO][09:26:52]: [93m[1m
[Server #554754] Starting round 14/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.002      0.05007728 0.002      0.09101124
 0.05252918 0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.04928664 0.002      0.002      0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.002      0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04717531
 0.002      0.002      0.002      0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.04076878 0.002      0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.04451314 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.04804892
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.09338521 0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.05252918 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.002      0.05155642 0.002      0.002      0.002
 0.09144543 0.002      0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.04701686 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.002      0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.04961089 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9052e+00  5e-04  9e-09  9e-09
 5:  6.9058e+00  6.9056e+00  2e-04  3e-09  3e-09
 6:  6.9057e+00  6.9056e+00  2e-04  6e-09  1e-09
 7:  6.9057e+00  6.9056e+00  1e-04  6e-09  1e-09
 8:  6.9057e+00  6.9056e+00  8e-05  6e-08  1e-08
 9:  6.9056e+00  6.9056e+00  6e-05  4e-08  7e-09
10:  6.9056e+00  6.9056e+00  2e-05  1e-08  2e-09
11:  6.9056e+00  6.9056e+00  7e-06  7e-09  1e-09
12:  6.9056e+00  6.9056e+00  8e-07  1e-09  2e-10
Optimal solution found.
The calculated probability is:  [9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.58778933e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 1.71787849e-02
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.58956507e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59084101e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 3.38132836e-05
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 2.71975279e-05
 9.59270815e-06 9.59270815e-06 9.59160866e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 2.27334259e-05 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59115516e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 2.79468571e-05 9.59270815e-06 9.59129792e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 7.23911587e-01 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 2.69507852e-05 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 2.53198949e-01 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59165589e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 2.20077164e-04 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59075666e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.58732761e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 6.61148483e-04 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06 9.59270815e-06
 9.59270815e-06 9.59270815e-06 9.59270815e-06]
current clients pool:  [INFO][09:26:53]: [Server #554754] Selected clients: [349 311 140 105 205  87 419 410 404 152]
[INFO][09:26:53]: [Server #554754] Selecting client #349 for training.
[INFO][09:26:53]: [Server #554754] Sending the current model to client #349 (simulated).
[INFO][09:26:53]: [Server #554754] Sending 0.26 MB of payload data to client #349 (simulated).
[INFO][09:26:53]: [Server #554754] Selecting client #311 for training.
[INFO][09:26:53]: [Server #554754] Sending the current model to client #311 (simulated).
[INFO][09:26:53]: [Server #554754] Sending 0.26 MB of payload data to client #311 (simulated).
[INFO][09:26:53]: [Client #349] Selected by the server.
[INFO][09:26:53]: [Client #349] Loading its data source...
[INFO][09:26:53]: Data source: FEMNIST
[INFO][09:26:53]: [Client #311] Selected by the server.
[INFO][09:26:53]: [Client #311] Loading its data source...
[INFO][09:26:53]: Data source: FEMNIST
[INFO][09:26:53]: [Client #349] Dataset size: 162
[INFO][09:26:53]: [Client #349] Sampler: all_inclusive
[INFO][09:26:53]: [Client #349] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:26:53]: [93m[1m[Client #349] Started training in communication round #14.[0m
[INFO][09:26:53]: [Client #311] Dataset size: 288
[INFO][09:26:53]: [Client #311] Sampler: all_inclusive
[INFO][09:26:53]: [Client #311] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:26:53]: [93m[1m[Client #311] Started training in communication round #14.[0m
[INFO][09:26:55]: [Client #311] Loading the dataset.
[INFO][09:26:55]: [Client #349] Loading the dataset.
[INFO][09:27:00]: [Client #311] Epoch: [1/5][0/29]	Loss: 1.973699
[INFO][09:27:00]: [Client #349] Epoch: [1/5][0/17]	Loss: 0.713084
[INFO][09:27:00]: [Client #311] Epoch: [1/5][10/29]	Loss: 1.181635
[INFO][09:27:00]: [Client #349] Epoch: [1/5][10/17]	Loss: 0.868606
[INFO][09:27:00]: [Client #311] Epoch: [1/5][20/29]	Loss: 0.970524
[INFO][09:27:00]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:27:00]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:27:04]: [Client #349] Woke up.
[INFO][09:27:04]: [Client #349] Epoch: [2/5][0/17]	Loss: 1.516986
[INFO][09:27:04]: [Client #349] Epoch: [2/5][10/17]	Loss: 0.565780
[INFO][09:27:04]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:27:08]: [Client #349] Woke up.
[INFO][09:27:08]: [Client #349] Epoch: [3/5][0/17]	Loss: 1.221240
[INFO][09:27:08]: [Client #349] Epoch: [3/5][10/17]	Loss: 0.587643
[INFO][09:27:08]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:27:11]: [Client #311] Woke up.
[INFO][09:27:11]: [Client #311] Epoch: [2/5][0/29]	Loss: 1.366622
[INFO][09:27:11]: [Client #311] Epoch: [2/5][10/29]	Loss: 1.308500
[INFO][09:27:11]: [Client #311] Epoch: [2/5][20/29]	Loss: 1.823148
[INFO][09:27:11]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:27:12]: [Client #349] Woke up.
[INFO][09:27:12]: [Client #349] Epoch: [4/5][0/17]	Loss: 0.317940
[INFO][09:27:12]: [Client #349] Epoch: [4/5][10/17]	Loss: 1.224259
[INFO][09:27:12]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:27:16]: [Client #349] Woke up.
[INFO][09:27:16]: [Client #349] Epoch: [5/5][0/17]	Loss: 0.286627
[INFO][09:27:17]: [Client #349] Epoch: [5/5][10/17]	Loss: 0.875750
[INFO][09:27:17]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][09:27:21]: [Client #349] Woke up.
[INFO][09:27:21]: [Client #349] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554853.pth.
[INFO][09:27:21]: [Client #349] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554853.pth.
[INFO][09:27:21]: [Client #349] Model trained.
[INFO][09:27:21]: [Client #349] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:27:21]: [Server #554754] Received 0.26 MB of payload data from client #349 (simulated).
[INFO][09:27:22]: [Client #311] Woke up.
[INFO][09:27:22]: [Client #311] Epoch: [3/5][0/29]	Loss: 1.344214
[INFO][09:27:22]: [Client #311] Epoch: [3/5][10/29]	Loss: 0.967482
[INFO][09:27:22]: [Client #311] Epoch: [3/5][20/29]	Loss: 1.560578
[INFO][09:27:22]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:27:33]: [Client #311] Woke up.
[INFO][09:27:33]: [Client #311] Epoch: [4/5][0/29]	Loss: 0.835989
[INFO][09:27:34]: [Client #311] Epoch: [4/5][10/29]	Loss: 1.560804
[INFO][09:27:34]: [Client #311] Epoch: [4/5][20/29]	Loss: 0.922014
[INFO][09:27:34]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:27:45]: [Client #311] Woke up.
[INFO][09:27:45]: [Client #311] Epoch: [5/5][0/29]	Loss: 1.303842
[INFO][09:27:45]: [Client #311] Epoch: [5/5][10/29]	Loss: 1.743267
[INFO][09:27:45]: [Client #311] Epoch: [5/5][20/29]	Loss: 1.164542
[INFO][09:27:45]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][09:27:56]: [Client #311] Woke up.
[INFO][09:27:56]: [Client #311] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:27:57]: [Client #311] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][09:27:57]: [Client #311] Model trained.
[INFO][09:27:57]: [Client #311] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:27:57]: [Server #554754] Received 0.26 MB of payload data from client #311 (simulated).
[INFO][09:27:57]: [Server #554754] Selecting client #140 for training.
[INFO][09:27:57]: [Server #554754] Sending the current model to client #140 (simulated).
[INFO][09:27:57]: [Server #554754] Sending 0.26 MB of payload data to client #140 (simulated).
[INFO][09:27:57]: [Server #554754] Selecting client #105 for training.
[INFO][09:27:57]: [Server #554754] Sending the current model to client #105 (simulated).
[INFO][09:27:57]: [Server #554754] Sending 0.26 MB of payload data to client #105 (simulated).
[INFO][09:27:57]: [Client #140] Selected by the server.
[INFO][09:27:57]: [Client #140] Loading its data source...
[INFO][09:27:57]: Data source: FEMNIST
[INFO][09:27:57]: [Client #105] Selected by the server.
[INFO][09:27:57]: [Client #105] Loading its data source...
[INFO][09:27:57]: Data source: FEMNIST
[INFO][09:27:57]: [Client #140] Dataset size: 152
[INFO][09:27:57]: [Client #140] Sampler: all_inclusive
[INFO][09:27:57]: [Client #140] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:27:57]: [93m[1m[Client #140] Started training in communication round #14.[0m
[INFO][09:27:57]: [Client #105] Dataset size: 157
[INFO][09:27:57]: [Client #105] Sampler: all_inclusive
[INFO][09:27:57]: [Client #105] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:27:57]: [93m[1m[Client #105] Started training in communication round #14.[0m
[INFO][09:27:59]: [Client #140] Loading the dataset.
[INFO][09:27:59]: [Client #105] Loading the dataset.
[INFO][09:28:04]: [Client #105] Epoch: [1/5][0/16]	Loss: 1.057695
[INFO][09:28:04]: [Client #140] Epoch: [1/5][0/16]	Loss: 0.782966
[INFO][09:28:04]: [Client #105] Epoch: [1/5][10/16]	Loss: 1.748779
[INFO][09:28:04]: [Client #140] Epoch: [1/5][10/16]	Loss: 1.975739
[INFO][09:28:04]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][09:28:04]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:28:07]: [Client #140] Woke up.
[INFO][09:28:07]: [Client #140] Epoch: [2/5][0/16]	Loss: 0.509403
[INFO][09:28:07]: [Client #140] Epoch: [2/5][10/16]	Loss: 0.786721
[INFO][09:28:07]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:28:10]: [Client #140] Woke up.
[INFO][09:28:10]: [Client #140] Epoch: [3/5][0/16]	Loss: 0.916996
[INFO][09:28:10]: [Client #140] Epoch: [3/5][10/16]	Loss: 1.106607
[INFO][09:28:10]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:28:13]: [Client #140] Woke up.
[INFO][09:28:13]: [Client #140] Epoch: [4/5][0/16]	Loss: 0.512822
[INFO][09:28:13]: [Client #140] Epoch: [4/5][10/16]	Loss: 1.163229
[INFO][09:28:13]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:28:14]: [Client #105] Woke up.
[INFO][09:28:14]: [Client #105] Epoch: [2/5][0/16]	Loss: 0.543601
[INFO][09:28:14]: [Client #105] Epoch: [2/5][10/16]	Loss: 1.242336
[INFO][09:28:14]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][09:28:16]: [Client #140] Woke up.
[INFO][09:28:16]: [Client #140] Epoch: [5/5][0/16]	Loss: 1.552996
[INFO][09:28:17]: [Client #140] Epoch: [5/5][10/16]	Loss: 1.461833
[INFO][09:28:17]: [Client #140] Going to sleep for 2.95 seconds.
[INFO][09:28:20]: [Client #140] Woke up.
[INFO][09:28:20]: [Client #140] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_554853.pth.
[INFO][09:28:20]: [Client #140] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_140_554853.pth.
[INFO][09:28:20]: [Client #140] Model trained.
[INFO][09:28:20]: [Client #140] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:28:20]: [Server #554754] Received 0.26 MB of payload data from client #140 (simulated).
[INFO][09:28:24]: [Client #105] Woke up.
[INFO][09:28:24]: [Client #105] Epoch: [3/5][0/16]	Loss: 1.152188
[INFO][09:28:24]: [Client #105] Epoch: [3/5][10/16]	Loss: 1.060169
[INFO][09:28:24]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][09:28:34]: [Client #105] Woke up.
[INFO][09:28:34]: [Client #105] Epoch: [4/5][0/16]	Loss: 0.131293
[INFO][09:28:34]: [Client #105] Epoch: [4/5][10/16]	Loss: 1.047876
[INFO][09:28:34]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][09:28:44]: [Client #105] Woke up.
[INFO][09:28:44]: [Client #105] Epoch: [5/5][0/16]	Loss: 0.215093
[INFO][09:28:44]: [Client #105] Epoch: [5/5][10/16]	Loss: 1.278937
[INFO][09:28:44]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][09:28:54]: [Client #105] Woke up.
[INFO][09:28:54]: [Client #105] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_105_554860.pth.
[INFO][09:28:55]: [Client #105] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_105_554860.pth.
[INFO][09:28:55]: [Client #105] Model trained.
[INFO][09:28:55]: [Client #105] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:28:55]: [Server #554754] Received 0.26 MB of payload data from client #105 (simulated).
[INFO][09:28:55]: [Server #554754] Selecting client #205 for training.
[INFO][09:28:55]: [Server #554754] Sending the current model to client #205 (simulated).
[INFO][09:28:55]: [Server #554754] Sending 0.26 MB of payload data to client #205 (simulated).
[INFO][09:28:55]: [Server #554754] Selecting client #87 for training.
[INFO][09:28:55]: [Server #554754] Sending the current model to client #87 (simulated).
[INFO][09:28:55]: [Server #554754] Sending 0.26 MB of payload data to client #87 (simulated).
[INFO][09:28:55]: [Client #87] Selected by the server.
[INFO][09:28:55]: [Client #205] Selected by the server.
[INFO][09:28:55]: [Client #87] Loading its data source...
[INFO][09:28:55]: [Client #205] Loading its data source...
[INFO][09:28:55]: Data source: FEMNIST
[INFO][09:28:55]: Data source: FEMNIST
[INFO][09:28:55]: [Client #87] Dataset size: 160
[INFO][09:28:55]: [Client #87] Sampler: all_inclusive
[INFO][09:28:55]: [Client #87] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:28:55]: [93m[1m[Client #87] Started training in communication round #14.[0m
[INFO][09:28:55]: [Client #205] Dataset size: 153
[INFO][09:28:55]: [Client #205] Sampler: all_inclusive
[INFO][09:28:55]: [Client #205] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:28:55]: [93m[1m[Client #205] Started training in communication round #14.[0m
[INFO][09:28:57]: [Client #205] Loading the dataset.
[INFO][09:28:57]: [Client #87] Loading the dataset.
[INFO][09:29:02]: [Client #205] Epoch: [1/5][0/16]	Loss: 0.877049
[INFO][09:29:03]: [Client #87] Epoch: [1/5][0/16]	Loss: 0.770961
[INFO][09:29:03]: [Client #205] Epoch: [1/5][10/16]	Loss: 0.953207
[INFO][09:29:03]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][09:29:03]: [Client #87] Epoch: [1/5][10/16]	Loss: 0.388100
[INFO][09:29:03]: [Client #87] Going to sleep for 0.75 seconds.
[INFO][09:29:03]: [Client #205] Woke up.
[INFO][09:29:03]: [Client #205] Epoch: [2/5][0/16]	Loss: 0.750054
[INFO][09:29:03]: [Client #205] Epoch: [2/5][10/16]	Loss: 1.043288
[INFO][09:29:03]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][09:29:03]: [Client #87] Woke up.
[INFO][09:29:03]: [Client #87] Epoch: [2/5][0/16]	Loss: 0.887627
[INFO][09:29:04]: [Client #87] Epoch: [2/5][10/16]	Loss: 1.111970
[INFO][09:29:04]: [Client #87] Going to sleep for 0.75 seconds.
[INFO][09:29:04]: [Client #205] Woke up.
[INFO][09:29:04]: [Client #205] Epoch: [3/5][0/16]	Loss: 1.455180
[INFO][09:29:04]: [Client #205] Epoch: [3/5][10/16]	Loss: 0.849013
[INFO][09:29:04]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][09:29:04]: [Client #87] Woke up.
[INFO][09:29:04]: [Client #87] Epoch: [3/5][0/16]	Loss: 0.628976
[INFO][09:29:04]: [Client #87] Epoch: [3/5][10/16]	Loss: 0.425896
[INFO][09:29:04]: [Client #87] Going to sleep for 0.75 seconds.
[INFO][09:29:05]: [Client #205] Woke up.
[INFO][09:29:05]: [Client #205] Epoch: [4/5][0/16]	Loss: 1.426022
[INFO][09:29:05]: [Client #205] Epoch: [4/5][10/16]	Loss: 1.000330
[INFO][09:29:05]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][09:29:05]: [Client #87] Woke up.
[INFO][09:29:05]: [Client #87] Epoch: [4/5][0/16]	Loss: 1.737365
[INFO][09:29:05]: [Client #87] Epoch: [4/5][10/16]	Loss: 1.301486
[INFO][09:29:05]: [Client #87] Going to sleep for 0.75 seconds.
[INFO][09:29:06]: [Client #205] Woke up.
[INFO][09:29:06]: [Client #205] Epoch: [5/5][0/16]	Loss: 0.816419
[INFO][09:29:06]: [Client #205] Epoch: [5/5][10/16]	Loss: 0.830083
[INFO][09:29:06]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][09:29:06]: [Client #87] Woke up.
[INFO][09:29:06]: [Client #87] Epoch: [5/5][0/16]	Loss: 0.806311
[INFO][09:29:06]: [Client #87] Epoch: [5/5][10/16]	Loss: 0.861999
[INFO][09:29:06]: [Client #87] Going to sleep for 0.75 seconds.
[INFO][09:29:06]: [Client #205] Woke up.
[INFO][09:29:06]: [Client #205] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_205_554853.pth.
[INFO][09:29:07]: [Client #205] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_205_554853.pth.
[INFO][09:29:07]: [Client #205] Model trained.
[INFO][09:29:07]: [Client #205] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:29:07]: [Server #554754] Received 0.26 MB of payload data from client #205 (simulated).
[INFO][09:29:07]: [Client #87] Woke up.
[INFO][09:29:07]: [Client #87] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_87_554860.pth.
[INFO][09:29:08]: [Client #87] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_87_554860.pth.
[INFO][09:29:08]: [Client #87] Model trained.
[INFO][09:29:08]: [Client #87] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:29:08]: [Server #554754] Received 0.26 MB of payload data from client #87 (simulated).
[INFO][09:29:08]: [Server #554754] Selecting client #419 for training.
[INFO][09:29:08]: [Server #554754] Sending the current model to client #419 (simulated).
[INFO][09:29:08]: [Server #554754] Sending 0.26 MB of payload data to client #419 (simulated).
[INFO][09:29:08]: [Server #554754] Selecting client #410 for training.
[INFO][09:29:08]: [Server #554754] Sending the current model to client #410 (simulated).
[INFO][09:29:08]: [Server #554754] Sending 0.26 MB of payload data to client #410 (simulated).
[INFO][09:29:08]: [Client #410] Selected by the server.
[INFO][09:29:08]: [Client #419] Selected by the server.
[INFO][09:29:08]: [Client #410] Loading its data source...
[INFO][09:29:08]: [Client #419] Loading its data source...
[INFO][09:29:08]: Data source: FEMNIST
[INFO][09:29:08]: Data source: FEMNIST
[INFO][09:29:08]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:29:08]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/410.zip.
[INFO][09:29:08]: [Client #419] Dataset size: 145
[INFO][09:29:08]: [Client #419] Sampler: all_inclusive
[INFO][09:29:08]: [Client #419] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:29:08]: [93m[1m[Client #419] Started training in communication round #14.[0m

2.2%
4.4%
6.6%
8.8%
11.0%
13.2%
15.4%
17.7%
19.9%
22.1%
24.3%
26.5%
28.7%
30.9%
33.1%
35.3%
37.5%
39.7%
41.9%
44.1%
46.3%
48.6%
50.8%
53.0%
55.2%
57.4%
59.6%
61.8%
64.0%
66.2%
68.4%
70.6%
72.8%
75.0%
77.2%
79.5%
81.7%
83.9%
86.1%
88.3%
90.5%
92.7%
94.9%
97.1%
99.3%
100.0%[INFO][09:29:08]: Decompressing the dataset downloaded.
[INFO][09:29:08]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/410.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:29:08]: [Client #410] Dataset size: 156
[INFO][09:29:08]: [Client #410] Sampler: all_inclusive
[INFO][09:29:08]: [Client #410] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:29:08]: [93m[1m[Client #410] Started training in communication round #14.[0m

[INFO][09:29:10]: [Client #419] Loading the dataset.
[INFO][09:29:10]: [Client #410] Loading the dataset.
[INFO][09:29:15]: [Client #419] Epoch: [1/5][0/15]	Loss: 2.502213
[INFO][09:29:15]: [Client #419] Epoch: [1/5][10/15]	Loss: 1.892920
[INFO][09:29:15]: [Client #410] Epoch: [1/5][0/16]	Loss: 0.197689
[INFO][09:29:15]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:29:15]: [Client #410] Epoch: [1/5][10/16]	Loss: 1.188674
[INFO][09:29:15]: [Client #410] Going to sleep for 0.75 seconds.
[INFO][09:29:16]: [Client #410] Woke up.
[INFO][09:29:16]: [Client #410] Epoch: [2/5][0/16]	Loss: 0.181560
[INFO][09:29:16]: [Client #410] Epoch: [2/5][10/16]	Loss: 0.838633
[INFO][09:29:16]: [Client #410] Going to sleep for 0.75 seconds.
[INFO][09:29:17]: [Client #410] Woke up.
[INFO][09:29:17]: [Client #410] Epoch: [3/5][0/16]	Loss: 0.494373
[INFO][09:29:17]: [Client #410] Epoch: [3/5][10/16]	Loss: 1.378900
[INFO][09:29:17]: [Client #410] Going to sleep for 0.75 seconds.
[INFO][09:29:18]: [Client #410] Woke up.
[INFO][09:29:18]: [Client #410] Epoch: [4/5][0/16]	Loss: 0.695586
[INFO][09:29:18]: [Client #410] Epoch: [4/5][10/16]	Loss: 0.855144
[INFO][09:29:18]: [Client #410] Going to sleep for 0.75 seconds.
[INFO][09:29:19]: [Client #410] Woke up.
[INFO][09:29:19]: [Client #410] Epoch: [5/5][0/16]	Loss: 0.171023
[INFO][09:29:19]: [Client #410] Epoch: [5/5][10/16]	Loss: 0.994437
[INFO][09:29:19]: [Client #410] Going to sleep for 0.75 seconds.
[INFO][09:29:20]: [Client #410] Woke up.
[INFO][09:29:20]: [Client #410] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_410_554860.pth.
[INFO][09:29:20]: [Client #419] Woke up.
[INFO][09:29:20]: [Client #419] Epoch: [2/5][0/15]	Loss: 0.827588
[INFO][09:29:20]: [Client #419] Epoch: [2/5][10/15]	Loss: 0.867793
[INFO][09:29:20]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:29:20]: [Client #410] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_410_554860.pth.
[INFO][09:29:20]: [Client #410] Model trained.
[INFO][09:29:20]: [Client #410] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:29:20]: [Server #554754] Received 0.26 MB of payload data from client #410 (simulated).
[INFO][09:29:25]: [Client #419] Woke up.
[INFO][09:29:25]: [Client #419] Epoch: [3/5][0/15]	Loss: 1.058437
[INFO][09:29:25]: [Client #419] Epoch: [3/5][10/15]	Loss: 0.496819
[INFO][09:29:25]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:29:29]: [Client #419] Woke up.
[INFO][09:29:30]: [Client #419] Epoch: [4/5][0/15]	Loss: 1.003163
[INFO][09:29:30]: [Client #419] Epoch: [4/5][10/15]	Loss: 1.259460
[INFO][09:29:30]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:29:34]: [Client #419] Woke up.
[INFO][09:29:34]: [Client #419] Epoch: [5/5][0/15]	Loss: 0.693240
[INFO][09:29:34]: [Client #419] Epoch: [5/5][10/15]	Loss: 1.570216
[INFO][09:29:34]: [Client #419] Going to sleep for 4.68 seconds.
[INFO][09:29:39]: [Client #419] Woke up.
[INFO][09:29:39]: [Client #419] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:29:40]: [Client #419] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_419_554853.pth.
[INFO][09:29:40]: [Client #419] Model trained.
[INFO][09:29:40]: [Client #419] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:29:40]: [Server #554754] Received 0.26 MB of payload data from client #419 (simulated).
[INFO][09:29:40]: [Server #554754] Selecting client #404 for training.
[INFO][09:29:40]: [Server #554754] Sending the current model to client #404 (simulated).
[INFO][09:29:40]: [Server #554754] Sending 0.26 MB of payload data to client #404 (simulated).
[INFO][09:29:40]: [Server #554754] Selecting client #152 for training.
[INFO][09:29:40]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][09:29:40]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][09:29:40]: [Client #404] Selected by the server.
[INFO][09:29:40]: [Client #404] Loading its data source...
[INFO][09:29:40]: Data source: FEMNIST
[INFO][09:29:40]: [Client #152] Selected by the server.
[INFO][09:29:40]: [Client #152] Loading its data source...
[INFO][09:29:40]: Data source: FEMNIST
[INFO][09:29:40]: [Client #404] Dataset size: 161
[INFO][09:29:40]: [Client #404] Sampler: all_inclusive
[INFO][09:29:40]: [Client #404] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:29:40]: [93m[1m[Client #404] Started training in communication round #14.[0m
[INFO][09:29:40]: [Client #152] Dataset size: 151
[INFO][09:29:40]: [Client #152] Sampler: all_inclusive
[INFO][09:29:40]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:29:40]: [93m[1m[Client #152] Started training in communication round #14.[0m
[INFO][09:29:42]: [Client #404] Loading the dataset.
[INFO][09:29:42]: [Client #152] Loading the dataset.
[INFO][09:29:47]: [Client #404] Epoch: [1/5][0/17]	Loss: 2.263590
[INFO][09:29:47]: [Client #152] Epoch: [1/5][0/16]	Loss: 1.199521
[INFO][09:29:47]: [Client #404] Epoch: [1/5][10/17]	Loss: 1.033132
[INFO][09:29:47]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][09:29:47]: [Client #152] Epoch: [1/5][10/16]	Loss: 3.445022
[INFO][09:29:47]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:29:50]: [Client #404] Woke up.
[INFO][09:29:50]: [Client #404] Epoch: [2/5][0/17]	Loss: 1.417032
[INFO][09:29:50]: [Client #404] Epoch: [2/5][10/17]	Loss: 1.078135
[INFO][09:29:50]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][09:29:52]: [Client #404] Woke up.
[INFO][09:29:52]: [Client #404] Epoch: [3/5][0/17]	Loss: 1.602659
[INFO][09:29:52]: [Client #404] Epoch: [3/5][10/17]	Loss: 2.132198
[INFO][09:29:52]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][09:29:55]: [Client #404] Woke up.
[INFO][09:29:55]: [Client #404] Epoch: [4/5][0/17]	Loss: 0.900681
[INFO][09:29:55]: [Client #404] Epoch: [4/5][10/17]	Loss: 1.370402
[INFO][09:29:55]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][09:29:57]: [Client #404] Woke up.
[INFO][09:29:58]: [Client #404] Epoch: [5/5][0/17]	Loss: 1.638104
[INFO][09:29:58]: [Client #404] Epoch: [5/5][10/17]	Loss: 1.086531
[INFO][09:29:58]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][09:30:00]: [Client #404] Woke up.
[INFO][09:30:00]: [Client #404] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_404_554853.pth.
[INFO][09:30:01]: [Client #404] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_404_554853.pth.
[INFO][09:30:01]: [Client #404] Model trained.
[INFO][09:30:01]: [Client #404] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:30:01]: [Server #554754] Received 0.26 MB of payload data from client #404 (simulated).
[INFO][09:30:17]: [Client #152] Woke up.
[INFO][09:30:17]: [Client #152] Epoch: [2/5][0/16]	Loss: 2.236389
[INFO][09:30:17]: [Client #152] Epoch: [2/5][10/16]	Loss: 1.769670
[INFO][09:30:17]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:30:47]: [Client #152] Woke up.
[INFO][09:30:47]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.397222
[INFO][09:30:47]: [Client #152] Epoch: [3/5][10/16]	Loss: 3.239493
[INFO][09:30:47]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:31:17]: [Client #152] Woke up.
[INFO][09:31:17]: [Client #152] Epoch: [4/5][0/16]	Loss: 1.788190
[INFO][09:31:17]: [Client #152] Epoch: [4/5][10/16]	Loss: 1.869872
[INFO][09:31:17]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:31:46]: [Client #152] Woke up.
[INFO][09:31:46]: [Client #152] Epoch: [5/5][0/16]	Loss: 1.533321
[INFO][09:31:47]: [Client #152] Epoch: [5/5][10/16]	Loss: 0.904641
[INFO][09:31:47]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:32:16]: [Client #152] Woke up.
[INFO][09:32:16]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554860.pth.
[INFO][09:32:17]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554860.pth.
[INFO][09:32:17]: [Client #152] Model trained.
[INFO][09:32:17]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:32:17]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][09:32:17]: [Server #554754] Adding client #205 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #410 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #87 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #404 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #140 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #349 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #419 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #445 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #105 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Adding client #311 to the list of clients for aggregation.
[INFO][09:32:17]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12649302 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10718083 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1566976  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.101461   0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22532564 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08138758 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.20322674 0.         0.         0.         0.
 0.         0.07164886 0.         0.         0.         0.
 0.         0.         0.         0.         0.09257555 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30869341 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12649302 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10718083 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1566976  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.101461   0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22532564 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08138758 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.20322674 0.         0.         0.         0.
 0.         0.07164886 0.         0.         0.         0.
 0.         0.         0.         0.         0.09257555 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30869341 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:33:08]: [Server #554754] Global model accuracy: 55.65%

[INFO][09:33:08]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_14.pth.
[INFO][09:33:08]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_14.pth.
[INFO][09:33:08]: [93m[1m
[Server #554754] Starting round 15/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.04791345 0.002      0.08762322 0.05007728 0.002      0.09101124
 0.05252918 0.002      0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.002      0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.04717531
 0.002      0.002      0.002      0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10305344 0.002      0.002
 0.04076878 0.002      0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.04451314 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.04804892
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.15991238 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.04961089 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9051e+00  6e-04  1e-08  1e-08
 5:  6.9058e+00  6.9054e+00  3e-04  5e-09  5e-09
 6:  6.9057e+00  6.9054e+00  3e-04  4e-08  1e-08
 7:  6.9057e+00  6.9055e+00  2e-04  4e-08  1e-08
 8:  6.9056e+00  6.9055e+00  1e-04  2e-07  8e-08
 9:  6.9055e+00  6.9055e+00  4e-05  2e-07  5e-08
10:  6.9055e+00  6.9055e+00  2e-06  3e-08  1e-08
Optimal solution found.
The calculated probability is:  [1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46239437e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46286494e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46180791e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46302196e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.44835746e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46327195e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.45993862e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46345409e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46324830e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 9.92709950e-01
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05 1.46391952e-05
 1.46391952e-05 1.46391952e-05 1.46391952e-05]
current clients pool:  [INFO][09:33:08]: [Server #554754] Selected clients: [445  85  75 258 437  92 232 215 249  81]
[INFO][09:33:08]: [Server #554754] Selecting client #445 for training.
[INFO][09:33:08]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][09:33:08]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][09:33:08]: [Server #554754] Selecting client #85 for training.
[INFO][09:33:08]: [Server #554754] Sending the current model to client #85 (simulated).
[INFO][09:33:08]: [Server #554754] Sending 0.26 MB of payload data to client #85 (simulated).
[INFO][09:33:08]: [Client #445] Selected by the server.
[INFO][09:33:08]: [Client #445] Loading its data source...
[INFO][09:33:08]: Data source: FEMNIST
[INFO][09:33:08]: [Client #85] Selected by the server.
[INFO][09:33:08]: [Client #85] Loading its data source...
[INFO][09:33:08]: Data source: FEMNIST
[INFO][09:33:08]: [Client #85] Dataset size: 155
[INFO][09:33:08]: [Client #85] Sampler: all_inclusive
[INFO][09:33:08]: [Client #85] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:33:08]: [Client #445] Dataset size: 292
[INFO][09:33:08]: [Client #445] Sampler: all_inclusive
[INFO][09:33:08]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:33:08]: [93m[1m[Client #85] Started training in communication round #15.[0m
[INFO][09:33:08]: [93m[1m[Client #445] Started training in communication round #15.[0m
[INFO][09:33:10]: [Client #85] Loading the dataset.
[INFO][09:33:10]: [Client #445] Loading the dataset.
[INFO][09:33:16]: [Client #85] Epoch: [1/5][0/16]	Loss: 0.810051
[INFO][09:33:16]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.901679
[INFO][09:33:16]: [Client #85] Epoch: [1/5][10/16]	Loss: 0.904498
[INFO][09:33:16]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][09:33:16]: [Client #445] Epoch: [1/5][10/30]	Loss: 1.690188
[INFO][09:33:16]: [Client #445] Epoch: [1/5][20/30]	Loss: 1.151557
[INFO][09:33:16]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:33:16]: [Client #85] Woke up.
[INFO][09:33:16]: [Client #85] Epoch: [2/5][0/16]	Loss: 0.768002
[INFO][09:33:16]: [Client #85] Epoch: [2/5][10/16]	Loss: 0.851633
[INFO][09:33:16]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][09:33:17]: [Client #85] Woke up.
[INFO][09:33:17]: [Client #85] Epoch: [3/5][0/16]	Loss: 1.296425
[INFO][09:33:17]: [Client #85] Epoch: [3/5][10/16]	Loss: 0.881928
[INFO][09:33:17]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][09:33:17]: [Client #85] Woke up.
[INFO][09:33:17]: [Client #85] Epoch: [4/5][0/16]	Loss: 0.160376
[INFO][09:33:17]: [Client #85] Epoch: [4/5][10/16]	Loss: 0.831790
[INFO][09:33:17]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][09:33:18]: [Client #85] Woke up.
[INFO][09:33:18]: [Client #85] Epoch: [5/5][0/16]	Loss: 0.648616
[INFO][09:33:18]: [Client #85] Epoch: [5/5][10/16]	Loss: 1.445948
[INFO][09:33:18]: [Client #85] Going to sleep for 0.37 seconds.
[INFO][09:33:18]: [Client #85] Woke up.
[INFO][09:33:18]: [Client #85] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_554860.pth.
[INFO][09:33:19]: [Client #85] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_85_554860.pth.
[INFO][09:33:19]: [Client #85] Model trained.
[INFO][09:33:19]: [Client #85] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:33:19]: [Server #554754] Received 0.26 MB of payload data from client #85 (simulated).
[INFO][09:33:35]: [Client #445] Woke up.
[INFO][09:33:36]: [Client #445] Epoch: [2/5][0/30]	Loss: 2.593166
[INFO][09:33:36]: [Client #445] Epoch: [2/5][10/30]	Loss: 2.443640
[INFO][09:33:36]: [Client #445] Epoch: [2/5][20/30]	Loss: 2.790444
[INFO][09:33:36]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:33:55]: [Client #445] Woke up.
[INFO][09:33:55]: [Client #445] Epoch: [3/5][0/30]	Loss: 1.098936
[INFO][09:33:56]: [Client #445] Epoch: [3/5][10/30]	Loss: 0.523294
[INFO][09:33:56]: [Client #445] Epoch: [3/5][20/30]	Loss: 1.749009
[INFO][09:33:56]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:34:15]: [Client #445] Woke up.
[INFO][09:34:15]: [Client #445] Epoch: [4/5][0/30]	Loss: 1.921894
[INFO][09:34:15]: [Client #445] Epoch: [4/5][10/30]	Loss: 1.251304
[INFO][09:34:15]: [Client #445] Epoch: [4/5][20/30]	Loss: 0.668747
[INFO][09:34:16]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:34:35]: [Client #445] Woke up.
[INFO][09:34:35]: [Client #445] Epoch: [5/5][0/30]	Loss: 0.870827
[INFO][09:34:35]: [Client #445] Epoch: [5/5][10/30]	Loss: 0.996541
[INFO][09:34:35]: [Client #445] Epoch: [5/5][20/30]	Loss: 1.708250
[INFO][09:34:35]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:34:55]: [Client #445] Woke up.
[INFO][09:34:55]: [Client #445] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554853.pth.
[INFO][09:34:56]: [Client #445] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554853.pth.
[INFO][09:34:56]: [Client #445] Model trained.
[INFO][09:34:56]: [Client #445] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:34:56]: [Server #554754] Received 0.26 MB of payload data from client #445 (simulated).
[INFO][09:34:56]: [Server #554754] Selecting client #75 for training.
[INFO][09:34:56]: [Server #554754] Sending the current model to client #75 (simulated).
[INFO][09:34:56]: [Server #554754] Sending 0.26 MB of payload data to client #75 (simulated).
[INFO][09:34:56]: [Server #554754] Selecting client #258 for training.
[INFO][09:34:56]: [Server #554754] Sending the current model to client #258 (simulated).
[INFO][09:34:56]: [Server #554754] Sending 0.26 MB of payload data to client #258 (simulated).
[INFO][09:34:56]: [Client #75] Selected by the server.
[INFO][09:34:56]: [Client #75] Loading its data source...
[INFO][09:34:56]: Data source: FEMNIST
[INFO][09:34:56]: [Client #258] Selected by the server.
[INFO][09:34:56]: [Client #258] Loading its data source...
[INFO][09:34:56]: Data source: FEMNIST
[INFO][09:34:56]: [Client #258] Dataset size: 165
[INFO][09:34:56]: [Client #258] Sampler: all_inclusive
[INFO][09:34:56]: [Client #258] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:34:56]: [93m[1m[Client #258] Started training in communication round #15.[0m
[INFO][09:34:56]: [Client #75] Dataset size: 153
[INFO][09:34:56]: [Client #75] Sampler: all_inclusive
[INFO][09:34:56]: [Client #75] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:34:56]: [93m[1m[Client #75] Started training in communication round #15.[0m
[INFO][09:34:58]: [Client #258] Loading the dataset.
[INFO][09:34:58]: [Client #75] Loading the dataset.
[INFO][09:35:03]: [Client #258] Epoch: [1/5][0/17]	Loss: 1.028281
[INFO][09:35:03]: [Client #75] Epoch: [1/5][0/16]	Loss: 2.278476
[INFO][09:35:03]: [Client #258] Epoch: [1/5][10/17]	Loss: 0.316211
[INFO][09:35:03]: [Client #75] Epoch: [1/5][10/16]	Loss: 1.592801
[INFO][09:35:03]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:35:03]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][09:35:04]: [Client #75] Woke up.
[INFO][09:35:04]: [Client #75] Epoch: [2/5][0/16]	Loss: 0.519424
[INFO][09:35:04]: [Client #75] Epoch: [2/5][10/16]	Loss: 2.128891
[INFO][09:35:04]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][09:35:05]: [Client #75] Woke up.
[INFO][09:35:05]: [Client #75] Epoch: [3/5][0/16]	Loss: 0.957514
[INFO][09:35:05]: [Client #75] Epoch: [3/5][10/16]	Loss: 0.226779
[INFO][09:35:05]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][09:35:05]: [Client #258] Woke up.
[INFO][09:35:05]: [Client #258] Epoch: [2/5][0/17]	Loss: 0.768914
[INFO][09:35:05]: [Client #258] Epoch: [2/5][10/17]	Loss: 0.890066
[INFO][09:35:05]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:35:06]: [Client #75] Woke up.
[INFO][09:35:06]: [Client #75] Epoch: [4/5][0/16]	Loss: 1.678784
[INFO][09:35:06]: [Client #75] Epoch: [4/5][10/16]	Loss: 0.711822
[INFO][09:35:06]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][09:35:06]: [Client #75] Woke up.
[INFO][09:35:06]: [Client #75] Epoch: [5/5][0/16]	Loss: 1.631445
[INFO][09:35:07]: [Client #75] Epoch: [5/5][10/16]	Loss: 1.003796
[INFO][09:35:07]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][09:35:07]: [Client #258] Woke up.
[INFO][09:35:07]: [Client #258] Epoch: [3/5][0/17]	Loss: 0.837834
[INFO][09:35:07]: [Client #258] Epoch: [3/5][10/17]	Loss: 1.053697
[INFO][09:35:07]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:35:07]: [Client #75] Woke up.
[INFO][09:35:07]: [Client #75] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_554853.pth.
[INFO][09:35:08]: [Client #75] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_554853.pth.
[INFO][09:35:08]: [Client #75] Model trained.
[INFO][09:35:08]: [Client #75] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:35:08]: [Server #554754] Received 0.26 MB of payload data from client #75 (simulated).
[INFO][09:35:09]: [Client #258] Woke up.
[INFO][09:35:09]: [Client #258] Epoch: [4/5][0/17]	Loss: 1.493704
[INFO][09:35:09]: [Client #258] Epoch: [4/5][10/17]	Loss: 1.517663
[INFO][09:35:09]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:35:10]: [Client #258] Woke up.
[INFO][09:35:10]: [Client #258] Epoch: [5/5][0/17]	Loss: 0.713351
[INFO][09:35:11]: [Client #258] Epoch: [5/5][10/17]	Loss: 1.258135
[INFO][09:35:11]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][09:35:12]: [Client #258] Woke up.
[INFO][09:35:12]: [Client #258] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][09:35:13]: [Client #258] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][09:35:13]: [Client #258] Model trained.
[INFO][09:35:13]: [Client #258] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:35:13]: [Server #554754] Received 0.26 MB of payload data from client #258 (simulated).
[INFO][09:35:13]: [Server #554754] Selecting client #437 for training.
[INFO][09:35:13]: [Server #554754] Sending the current model to client #437 (simulated).
[INFO][09:35:13]: [Server #554754] Sending 0.26 MB of payload data to client #437 (simulated).
[INFO][09:35:13]: [Server #554754] Selecting client #92 for training.
[INFO][09:35:13]: [Server #554754] Sending the current model to client #92 (simulated).
[INFO][09:35:13]: [Server #554754] Sending 0.26 MB of payload data to client #92 (simulated).
[INFO][09:35:13]: [Client #437] Selected by the server.
[INFO][09:35:13]: [Client #437] Loading its data source...
[INFO][09:35:13]: Data source: FEMNIST
[INFO][09:35:13]: [Client #92] Selected by the server.
[INFO][09:35:13]: [Client #92] Loading its data source...
[INFO][09:35:13]: Data source: FEMNIST
[INFO][09:35:13]: [Client #437] Dataset size: 145
[INFO][09:35:13]: [Client #437] Sampler: all_inclusive
[INFO][09:35:13]: [Client #437] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:35:13]: [93m[1m[Client #437] Started training in communication round #15.[0m
[INFO][09:35:13]: [Client #92] Dataset size: 163
[INFO][09:35:13]: [Client #92] Sampler: all_inclusive
[INFO][09:35:13]: [Client #92] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:35:13]: [93m[1m[Client #92] Started training in communication round #15.[0m
[INFO][09:35:15]: [Client #437] Loading the dataset.
[INFO][09:35:15]: [Client #92] Loading the dataset.
[INFO][09:35:20]: [Client #437] Epoch: [1/5][0/15]	Loss: 1.798578
[INFO][09:35:20]: [Client #92] Epoch: [1/5][0/17]	Loss: 1.782675
[INFO][09:35:21]: [Client #437] Epoch: [1/5][10/15]	Loss: 0.849859
[INFO][09:35:21]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][09:35:21]: [Client #92] Epoch: [1/5][10/17]	Loss: 0.256573
[INFO][09:35:21]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][09:35:30]: [Client #437] Woke up.
[INFO][09:35:30]: [Client #437] Epoch: [2/5][0/15]	Loss: 1.248725
[INFO][09:35:30]: [Client #437] Epoch: [2/5][10/15]	Loss: 2.814375
[INFO][09:35:30]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][09:35:39]: [Client #92] Woke up.
[INFO][09:35:39]: [Client #92] Epoch: [2/5][0/17]	Loss: 0.742461
[INFO][09:35:40]: [Client #92] Epoch: [2/5][10/17]	Loss: 0.309317
[INFO][09:35:40]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][09:35:40]: [Client #437] Woke up.
[INFO][09:35:40]: [Client #437] Epoch: [3/5][0/15]	Loss: 1.332440
[INFO][09:35:40]: [Client #437] Epoch: [3/5][10/15]	Loss: 2.192526
[INFO][09:35:40]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][09:35:49]: [Client #437] Woke up.
[INFO][09:35:49]: [Client #437] Epoch: [4/5][0/15]	Loss: 1.889109
[INFO][09:35:49]: [Client #437] Epoch: [4/5][10/15]	Loss: 1.614238
[INFO][09:35:49]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][09:35:58]: [Client #92] Woke up.
[INFO][09:35:58]: [Client #92] Epoch: [3/5][0/17]	Loss: 0.510550
[INFO][09:35:59]: [Client #92] Epoch: [3/5][10/17]	Loss: 0.687066
[INFO][09:35:59]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][09:35:59]: [Client #437] Woke up.
[INFO][09:35:59]: [Client #437] Epoch: [5/5][0/15]	Loss: 1.226674
[INFO][09:35:59]: [Client #437] Epoch: [5/5][10/15]	Loss: 0.990182
[INFO][09:35:59]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][09:36:09]: [Client #437] Woke up.
[INFO][09:36:09]: [Client #437] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_437_554853.pth.
[INFO][09:36:09]: [Client #437] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_437_554853.pth.
[INFO][09:36:09]: [Client #437] Model trained.
[INFO][09:36:09]: [Client #437] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:36:09]: [Server #554754] Received 0.26 MB of payload data from client #437 (simulated).
[INFO][09:36:17]: [Client #92] Woke up.
[INFO][09:36:18]: [Client #92] Epoch: [4/5][0/17]	Loss: 0.218812
[INFO][09:36:18]: [Client #92] Epoch: [4/5][10/17]	Loss: 1.117813
[INFO][09:36:18]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][09:36:36]: [Client #92] Woke up.
[INFO][09:36:37]: [Client #92] Epoch: [5/5][0/17]	Loss: 0.654041
[INFO][09:36:37]: [Client #92] Epoch: [5/5][10/17]	Loss: 0.906674
[INFO][09:36:37]: [Client #92] Going to sleep for 18.80 seconds.
[INFO][09:36:56]: [Client #92] Woke up.
[INFO][09:36:56]: [Client #92] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_92_554860.pth.
[INFO][09:36:56]: [Client #92] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_92_554860.pth.
[INFO][09:36:56]: [Client #92] Model trained.
[INFO][09:36:56]: [Client #92] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:36:56]: [Server #554754] Received 0.26 MB of payload data from client #92 (simulated).
[INFO][09:36:56]: [Server #554754] Selecting client #232 for training.
[INFO][09:36:56]: [Server #554754] Sending the current model to client #232 (simulated).
[INFO][09:36:56]: [Server #554754] Sending 0.26 MB of payload data to client #232 (simulated).
[INFO][09:36:56]: [Server #554754] Selecting client #215 for training.
[INFO][09:36:56]: [Server #554754] Sending the current model to client #215 (simulated).
[INFO][09:36:56]: [Server #554754] Sending 0.26 MB of payload data to client #215 (simulated).
[INFO][09:36:56]: [Client #232] Selected by the server.
[INFO][09:36:56]: [Client #215] Selected by the server.
[INFO][09:36:56]: [Client #232] Loading its data source...
[INFO][09:36:56]: [Client #215] Loading its data source...
[INFO][09:36:56]: Data source: FEMNIST
[INFO][09:36:56]: Data source: FEMNIST
[INFO][09:36:56]: [Client #232] Dataset size: 162
[INFO][09:36:56]: [Client #232] Sampler: all_inclusive
[INFO][09:36:56]: [Client #232] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:36:56]: [93m[1m[Client #232] Started training in communication round #15.[0m
[INFO][09:36:56]: [Client #215] Dataset size: 161
[INFO][09:36:56]: [Client #215] Sampler: all_inclusive
[INFO][09:36:56]: [Client #215] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:36:56]: [93m[1m[Client #215] Started training in communication round #15.[0m
[INFO][09:36:58]: [Client #232] Loading the dataset.
[INFO][09:36:58]: [Client #215] Loading the dataset.
[INFO][09:37:04]: [Client #232] Epoch: [1/5][0/17]	Loss: 1.942772
[INFO][09:37:04]: [Client #215] Epoch: [1/5][0/17]	Loss: 1.812758
[INFO][09:37:04]: [Client #232] Epoch: [1/5][10/17]	Loss: 1.517163
[INFO][09:37:04]: [Client #215] Epoch: [1/5][10/17]	Loss: 1.564166
[INFO][09:37:04]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][09:37:04]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][09:37:04]: [Client #215] Woke up.
[INFO][09:37:04]: [Client #215] Epoch: [2/5][0/17]	Loss: 1.219899
[INFO][09:37:04]: [Client #215] Epoch: [2/5][10/17]	Loss: 2.746785
[INFO][09:37:04]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][09:37:04]: [Client #215] Woke up.
[INFO][09:37:04]: [Client #215] Epoch: [3/5][0/17]	Loss: 1.273600
[INFO][09:37:04]: [Client #215] Epoch: [3/5][10/17]	Loss: 1.792262
[INFO][09:37:05]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][09:37:05]: [Client #215] Woke up.
[INFO][09:37:05]: [Client #215] Epoch: [4/5][0/17]	Loss: 1.657748
[INFO][09:37:05]: [Client #215] Epoch: [4/5][10/17]	Loss: 1.020905
[INFO][09:37:05]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][09:37:05]: [Client #215] Woke up.
[INFO][09:37:05]: [Client #215] Epoch: [5/5][0/17]	Loss: 1.670548
[INFO][09:37:05]: [Client #215] Epoch: [5/5][10/17]	Loss: 1.341313
[INFO][09:37:05]: [Client #232] Woke up.
[INFO][09:37:05]: [Client #232] Epoch: [2/5][0/17]	Loss: 1.963134
[INFO][09:37:05]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][09:37:05]: [Client #232] Epoch: [2/5][10/17]	Loss: 1.948335
[INFO][09:37:05]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][09:37:05]: [Client #215] Woke up.
[INFO][09:37:05]: [Client #215] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][09:37:06]: [Client #215] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][09:37:06]: [Client #215] Model trained.
[INFO][09:37:06]: [Client #215] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:37:06]: [Server #554754] Received 0.26 MB of payload data from client #215 (simulated).
[INFO][09:37:06]: [Client #232] Woke up.
[INFO][09:37:06]: [Client #232] Epoch: [3/5][0/17]	Loss: 2.318340
[INFO][09:37:07]: [Client #232] Epoch: [3/5][10/17]	Loss: 1.072794
[INFO][09:37:07]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][09:37:08]: [Client #232] Woke up.
[INFO][09:37:08]: [Client #232] Epoch: [4/5][0/17]	Loss: 1.112177
[INFO][09:37:08]: [Client #232] Epoch: [4/5][10/17]	Loss: 1.434920
[INFO][09:37:08]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][09:37:09]: [Client #232] Woke up.
[INFO][09:37:09]: [Client #232] Epoch: [5/5][0/17]	Loss: 2.034322
[INFO][09:37:09]: [Client #232] Epoch: [5/5][10/17]	Loss: 2.099289
[INFO][09:37:09]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][09:37:11]: [Client #232] Woke up.
[INFO][09:37:11]: [Client #232] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][09:37:11]: [Client #232] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][09:37:11]: [Client #232] Model trained.
[INFO][09:37:11]: [Client #232] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:37:11]: [Server #554754] Received 0.26 MB of payload data from client #232 (simulated).
[INFO][09:37:11]: [Server #554754] Selecting client #249 for training.
[INFO][09:37:11]: [Server #554754] Sending the current model to client #249 (simulated).
[INFO][09:37:11]: [Server #554754] Sending 0.26 MB of payload data to client #249 (simulated).
[INFO][09:37:11]: [Server #554754] Selecting client #81 for training.
[INFO][09:37:11]: [Server #554754] Sending the current model to client #81 (simulated).
[INFO][09:37:11]: [Server #554754] Sending 0.26 MB of payload data to client #81 (simulated).
[INFO][09:37:11]: [Client #249] Selected by the server.
[INFO][09:37:11]: [Client #249] Loading its data source...
[INFO][09:37:11]: Data source: FEMNIST
[INFO][09:37:11]: [Client #81] Selected by the server.
[INFO][09:37:11]: [Client #81] Loading its data source...
[INFO][09:37:11]: Data source: FEMNIST
[INFO][09:37:11]: [Client #249] Dataset size: 144
[INFO][09:37:11]: [Client #249] Sampler: all_inclusive
[INFO][09:37:11]: [Client #249] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:37:11]: [93m[1m[Client #249] Started training in communication round #15.[0m
[INFO][09:37:11]: [Client #81] Dataset size: 153
[INFO][09:37:11]: [Client #81] Sampler: all_inclusive
[INFO][09:37:11]: [Client #81] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:37:11]: [93m[1m[Client #81] Started training in communication round #15.[0m
[INFO][09:37:13]: [Client #249] Loading the dataset.
[INFO][09:37:13]: [Client #81] Loading the dataset.
[INFO][09:37:19]: [Client #249] Epoch: [1/5][0/15]	Loss: 2.260578
[INFO][09:37:19]: [Client #249] Epoch: [1/5][10/15]	Loss: 1.891327
[INFO][09:37:19]: [Client #81] Epoch: [1/5][0/16]	Loss: 1.183457
[INFO][09:37:19]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][09:37:19]: [Client #81] Epoch: [1/5][10/16]	Loss: 1.402647
[INFO][09:37:19]: [Client #81] Going to sleep for 7.57 seconds.
[INFO][09:37:21]: [Client #249] Woke up.
[INFO][09:37:21]: [Client #249] Epoch: [2/5][0/15]	Loss: 1.032780
[INFO][09:37:21]: [Client #249] Epoch: [2/5][10/15]	Loss: 1.915604
[INFO][09:37:21]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][09:37:23]: [Client #249] Woke up.
[INFO][09:37:23]: [Client #249] Epoch: [3/5][0/15]	Loss: 2.376734
[INFO][09:37:23]: [Client #249] Epoch: [3/5][10/15]	Loss: 1.088087
[INFO][09:37:23]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][09:37:25]: [Client #249] Woke up.
[INFO][09:37:25]: [Client #249] Epoch: [4/5][0/15]	Loss: 1.060696
[INFO][09:37:25]: [Client #249] Epoch: [4/5][10/15]	Loss: 1.806873
[INFO][09:37:25]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][09:37:26]: [Client #81] Woke up.
[INFO][09:37:26]: [Client #81] Epoch: [2/5][0/16]	Loss: 0.707939
[INFO][09:37:26]: [Client #81] Epoch: [2/5][10/16]	Loss: 1.219777
[INFO][09:37:26]: [Client #81] Going to sleep for 7.57 seconds.
[INFO][09:37:28]: [Client #249] Woke up.
[INFO][09:37:28]: [Client #249] Epoch: [5/5][0/15]	Loss: 1.011764
[INFO][09:37:28]: [Client #249] Epoch: [5/5][10/15]	Loss: 0.559409
[INFO][09:37:28]: [Client #249] Going to sleep for 2.12 seconds.
[INFO][09:37:30]: [Client #249] Woke up.
[INFO][09:37:30]: [Client #249] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_249_554853.pth.
[INFO][09:37:31]: [Client #249] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_249_554853.pth.
[INFO][09:37:31]: [Client #249] Model trained.
[INFO][09:37:31]: [Client #249] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:37:31]: [Server #554754] Received 0.26 MB of payload data from client #249 (simulated).
[INFO][09:37:34]: [Client #81] Woke up.
[INFO][09:37:34]: [Client #81] Epoch: [3/5][0/16]	Loss: 1.192795
[INFO][09:37:34]: [Client #81] Epoch: [3/5][10/16]	Loss: 1.155855
[INFO][09:37:34]: [Client #81] Going to sleep for 7.57 seconds.
[INFO][09:37:42]: [Client #81] Woke up.
[INFO][09:37:42]: [Client #81] Epoch: [4/5][0/16]	Loss: 0.953240
[INFO][09:37:42]: [Client #81] Epoch: [4/5][10/16]	Loss: 1.201974
[INFO][09:37:42]: [Client #81] Going to sleep for 7.57 seconds.
[INFO][09:37:49]: [Client #81] Woke up.
[INFO][09:37:50]: [Client #81] Epoch: [5/5][0/16]	Loss: 1.352049
[INFO][09:37:50]: [Client #81] Epoch: [5/5][10/16]	Loss: 1.789007
[INFO][09:37:50]: [Client #81] Going to sleep for 7.57 seconds.
[INFO][09:37:57]: [Client #81] Woke up.
[INFO][09:37:57]: [Client #81] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_81_554860.pth.
[INFO][09:37:58]: [Client #81] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_81_554860.pth.
[INFO][09:37:58]: [Client #81] Model trained.
[INFO][09:37:58]: [Client #81] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:37:58]: [Server #554754] Received 0.26 MB of payload data from client #81 (simulated).
[INFO][09:37:58]: [Server #554754] Adding client #215 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #85 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #75 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #232 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #258 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #249 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #81 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #437 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Adding client #92 to the list of clients for aggregation.
[INFO][09:37:58]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1521032  0.         0.         0.
 0.         0.         0.1299127  0.         0.         0.
 0.08501685 0.         0.         0.         0.         0.
 0.         0.07667218 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25575435 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.19393576 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20437355 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12223853 0.         0.         0.
 0.         0.         0.         0.         0.         0.1128606
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12348424 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1521032  0.         0.         0.
 0.         0.         0.1299127  0.         0.         0.
 0.08501685 0.         0.         0.         0.         0.
 0.         0.07667218 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25575435 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.19393576 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20437355 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12223853 0.         0.         0.
 0.         0.         0.         0.         0.         0.1128606
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12348424 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:38:42]: [Server #554754] Global model accuracy: 53.61%

[INFO][09:38:42]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_15.pth.
[INFO][09:38:42]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_15.pth.
[INFO][09:38:42]: [93m[1m
[Server #554754] Starting round 16/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.04920128 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.002      0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.09101124
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.002      0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.09729381 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.002      0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.002      0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.10631443
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.002
 0.002      0.002      0.002      0.002      0.05585106 0.002
 0.002      0.05086436 0.002      0.12247191 0.002      0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.10178117
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.15991238 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.04961089 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.10320513 0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9052e+00  6e-04  1e-08  1e-08
 5:  6.9058e+00  6.9055e+00  3e-04  4e-09  4e-09
 6:  6.9057e+00  6.9055e+00  2e-04  2e-08  6e-09
 7:  6.9057e+00  6.9055e+00  2e-04  2e-08  6e-09
 8:  6.9056e+00  6.9055e+00  1e-04  2e-07  4e-08
 9:  6.9056e+00  6.9055e+00  4e-05  1e-07  3e-08
10:  6.9055e+00  6.9055e+00  2e-06  4e-08  1e-08
Optimal solution found.
The calculated probability is:  [2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52085304e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52222935e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52431198e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52447632e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 9.87421189e-01
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.51678890e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.51565356e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52303071e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52268341e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52292959e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05 2.52594715e-05
 2.52594715e-05 2.52594715e-05 2.52594715e-05]
current clients pool:  [INFO][09:38:42]: [Server #554754] Selected clients: [152 336 317  63 236 494 475 323  76 320]
[INFO][09:38:42]: [Server #554754] Selecting client #152 for training.
[INFO][09:38:42]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][09:38:42]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][09:38:42]: [Server #554754] Selecting client #336 for training.
[INFO][09:38:42]: [Server #554754] Sending the current model to client #336 (simulated).
[INFO][09:38:42]: [Server #554754] Sending 0.26 MB of payload data to client #336 (simulated).
[INFO][09:38:42]: [Client #152] Selected by the server.
[INFO][09:38:42]: [Client #152] Loading its data source...
[INFO][09:38:42]: Data source: FEMNIST
[INFO][09:38:42]: [Client #336] Selected by the server.
[INFO][09:38:42]: [Client #336] Loading its data source...
[INFO][09:38:42]: Data source: FEMNIST
[INFO][09:38:42]: [Client #152] Dataset size: 151
[INFO][09:38:42]: [Client #152] Sampler: all_inclusive
[INFO][09:38:42]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:38:42]: [Client #336] Dataset size: 160
[INFO][09:38:42]: [Client #336] Sampler: all_inclusive
[INFO][09:38:42]: [Client #336] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:38:42]: [93m[1m[Client #152] Started training in communication round #16.[0m
[INFO][09:38:42]: [93m[1m[Client #336] Started training in communication round #16.[0m
[INFO][09:38:44]: [Client #152] Loading the dataset.
[INFO][09:38:44]: [Client #336] Loading the dataset.
[INFO][09:38:50]: [Client #336] Epoch: [1/5][0/16]	Loss: 1.367693
[INFO][09:38:50]: [Client #152] Epoch: [1/5][0/16]	Loss: 1.826472
[INFO][09:38:50]: [Client #336] Epoch: [1/5][10/16]	Loss: 0.874691
[INFO][09:38:50]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][09:38:50]: [Client #152] Epoch: [1/5][10/16]	Loss: 1.013011
[INFO][09:38:50]: [Client #336] Woke up.
[INFO][09:38:50]: [Client #336] Epoch: [2/5][0/16]	Loss: 0.102500
[INFO][09:38:50]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:38:50]: [Client #336] Epoch: [2/5][10/16]	Loss: 0.900936
[INFO][09:38:50]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][09:38:50]: [Client #336] Woke up.
[INFO][09:38:50]: [Client #336] Epoch: [3/5][0/16]	Loss: 0.869562
[INFO][09:38:50]: [Client #336] Epoch: [3/5][10/16]	Loss: 0.310688
[INFO][09:38:50]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][09:38:50]: [Client #336] Woke up.
[INFO][09:38:50]: [Client #336] Epoch: [4/5][0/16]	Loss: 0.419734
[INFO][09:38:50]: [Client #336] Epoch: [4/5][10/16]	Loss: 0.915468
[INFO][09:38:50]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][09:38:50]: [Client #336] Woke up.
[INFO][09:38:50]: [Client #336] Epoch: [5/5][0/16]	Loss: 1.611586
[INFO][09:38:51]: [Client #336] Epoch: [5/5][10/16]	Loss: 0.934335
[INFO][09:38:51]: [Client #336] Going to sleep for 0.02 seconds.
[INFO][09:38:51]: [Client #336] Woke up.
[INFO][09:38:51]: [Client #336] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_554860.pth.
[INFO][09:38:51]: [Client #336] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_336_554860.pth.
[INFO][09:38:51]: [Client #336] Model trained.
[INFO][09:38:51]: [Client #336] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:38:51]: [Server #554754] Received 0.26 MB of payload data from client #336 (simulated).
[INFO][09:39:20]: [Client #152] Woke up.
[INFO][09:39:20]: [Client #152] Epoch: [2/5][0/16]	Loss: 1.074584
[INFO][09:39:20]: [Client #152] Epoch: [2/5][10/16]	Loss: 1.701612
[INFO][09:39:20]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:39:49]: [Client #152] Woke up.
[INFO][09:39:50]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.259110
[INFO][09:39:50]: [Client #152] Epoch: [3/5][10/16]	Loss: 2.088600
[INFO][09:39:50]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:40:19]: [Client #152] Woke up.
[INFO][09:40:19]: [Client #152] Epoch: [4/5][0/16]	Loss: 2.209365
[INFO][09:40:19]: [Client #152] Epoch: [4/5][10/16]	Loss: 3.595706
[INFO][09:40:20]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:40:49]: [Client #152] Woke up.
[INFO][09:40:49]: [Client #152] Epoch: [5/5][0/16]	Loss: 1.794526
[INFO][09:40:49]: [Client #152] Epoch: [5/5][10/16]	Loss: 1.407260
[INFO][09:40:49]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:41:19]: [Client #152] Woke up.
[INFO][09:41:19]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][09:41:20]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][09:41:20]: [Client #152] Model trained.
[INFO][09:41:20]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:41:20]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][09:41:20]: [Server #554754] Selecting client #317 for training.
[INFO][09:41:20]: [Server #554754] Sending the current model to client #317 (simulated).
[INFO][09:41:20]: [Server #554754] Sending 0.26 MB of payload data to client #317 (simulated).
[INFO][09:41:20]: [Server #554754] Selecting client #63 for training.
[INFO][09:41:20]: [Server #554754] Sending the current model to client #63 (simulated).
[INFO][09:41:20]: [Server #554754] Sending 0.26 MB of payload data to client #63 (simulated).
[INFO][09:41:20]: [Client #317] Selected by the server.
[INFO][09:41:20]: [Client #317] Loading its data source...
[INFO][09:41:20]: Data source: FEMNIST
[INFO][09:41:20]: [Client #63] Selected by the server.
[INFO][09:41:20]: [Client #63] Loading its data source...
[INFO][09:41:20]: Data source: FEMNIST
[INFO][09:41:20]: [Client #63] Dataset size: 154
[INFO][09:41:20]: [Client #63] Sampler: all_inclusive
[INFO][09:41:20]: [Client #317] Dataset size: 168
[INFO][09:41:20]: [Client #317] Sampler: all_inclusive
[INFO][09:41:20]: [Client #63] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:20]: [Client #317] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:20]: [93m[1m[Client #63] Started training in communication round #16.[0m
[INFO][09:41:20]: [93m[1m[Client #317] Started training in communication round #16.[0m
[INFO][09:41:22]: [Client #317] Loading the dataset.
[INFO][09:41:22]: [Client #63] Loading the dataset.
[INFO][09:41:27]: [Client #63] Epoch: [1/5][0/16]	Loss: 1.095789
[INFO][09:41:27]: [Client #317] Epoch: [1/5][0/17]	Loss: 0.835994
[INFO][09:41:27]: [Client #63] Epoch: [1/5][10/16]	Loss: 1.773775
[INFO][09:41:27]: [Client #317] Epoch: [1/5][10/17]	Loss: 0.688629
[INFO][09:41:27]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][09:41:27]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][09:41:29]: [Client #63] Woke up.
[INFO][09:41:30]: [Client #63] Epoch: [2/5][0/16]	Loss: 1.334323
[INFO][09:41:30]: [Client #63] Epoch: [2/5][10/16]	Loss: 1.337336
[INFO][09:41:30]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][09:41:30]: [Client #317] Woke up.
[INFO][09:41:30]: [Client #317] Epoch: [2/5][0/17]	Loss: 0.604029
[INFO][09:41:30]: [Client #317] Epoch: [2/5][10/17]	Loss: 0.268556
[INFO][09:41:30]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][09:41:32]: [Client #63] Woke up.
[INFO][09:41:32]: [Client #63] Epoch: [3/5][0/16]	Loss: 1.240469
[INFO][09:41:32]: [Client #63] Epoch: [3/5][10/16]	Loss: 0.535426
[INFO][09:41:32]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][09:41:33]: [Client #317] Woke up.
[INFO][09:41:33]: [Client #317] Epoch: [3/5][0/17]	Loss: 0.479322
[INFO][09:41:33]: [Client #317] Epoch: [3/5][10/17]	Loss: 0.602645
[INFO][09:41:33]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][09:41:34]: [Client #63] Woke up.
[INFO][09:41:34]: [Client #63] Epoch: [4/5][0/16]	Loss: 0.514143
[INFO][09:41:34]: [Client #63] Epoch: [4/5][10/16]	Loss: 0.923117
[INFO][09:41:35]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][09:41:36]: [Client #317] Woke up.
[INFO][09:41:36]: [Client #317] Epoch: [4/5][0/17]	Loss: 0.787227
[INFO][09:41:36]: [Client #317] Epoch: [4/5][10/17]	Loss: 0.629887
[INFO][09:41:36]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][09:41:37]: [Client #63] Woke up.
[INFO][09:41:37]: [Client #63] Epoch: [5/5][0/16]	Loss: 1.640286
[INFO][09:41:37]: [Client #63] Epoch: [5/5][10/16]	Loss: 0.305852
[INFO][09:41:37]: [Client #63] Going to sleep for 2.27 seconds.
[INFO][09:41:39]: [Client #317] Woke up.
[INFO][09:41:39]: [Client #317] Epoch: [5/5][0/17]	Loss: 0.586503
[INFO][09:41:39]: [Client #317] Epoch: [5/5][10/17]	Loss: 0.604370
[INFO][09:41:39]: [Client #317] Going to sleep for 2.68 seconds.
[INFO][09:41:39]: [Client #63] Woke up.
[INFO][09:41:39]: [Client #63] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_63_554860.pth.
[INFO][09:41:40]: [Client #63] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_63_554860.pth.
[INFO][09:41:40]: [Client #63] Model trained.
[INFO][09:41:40]: [Client #63] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:41:40]: [Server #554754] Received 0.26 MB of payload data from client #63 (simulated).
[INFO][09:41:41]: [Client #317] Woke up.
[INFO][09:41:41]: [Client #317] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_317_554853.pth.
[INFO][09:41:42]: [Client #317] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_317_554853.pth.
[INFO][09:41:42]: [Client #317] Model trained.
[INFO][09:41:42]: [Client #317] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:41:42]: [Server #554754] Received 0.26 MB of payload data from client #317 (simulated).
[INFO][09:41:42]: [Server #554754] Selecting client #236 for training.
[INFO][09:41:42]: [Server #554754] Sending the current model to client #236 (simulated).
[INFO][09:41:42]: [Server #554754] Sending 0.26 MB of payload data to client #236 (simulated).
[INFO][09:41:42]: [Server #554754] Selecting client #494 for training.
[INFO][09:41:42]: [Server #554754] Sending the current model to client #494 (simulated).
[INFO][09:41:42]: [Server #554754] Sending 0.26 MB of payload data to client #494 (simulated).
[INFO][09:41:42]: [Client #494] Selected by the server.
[INFO][09:41:42]: [Client #494] Loading its data source...
[INFO][09:41:42]: Data source: FEMNIST
[INFO][09:41:42]: [Client #236] Selected by the server.
[INFO][09:41:42]: [Client #236] Loading its data source...
[INFO][09:41:42]: Data source: FEMNIST
[INFO][09:41:42]: [Client #494] Dataset size: 161
[INFO][09:41:42]: [Client #494] Sampler: all_inclusive
[INFO][09:41:42]: [Client #494] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:42]: [93m[1m[Client #494] Started training in communication round #16.[0m
[INFO][09:41:42]: [Client #236] Dataset size: 161
[INFO][09:41:42]: [Client #236] Sampler: all_inclusive
[INFO][09:41:42]: [Client #236] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:42]: [93m[1m[Client #236] Started training in communication round #16.[0m
[INFO][09:41:44]: [Client #236] Loading the dataset.
[INFO][09:41:44]: [Client #494] Loading the dataset.
[INFO][09:41:49]: [Client #236] Epoch: [1/5][0/17]	Loss: 1.153001
[INFO][09:41:50]: [Client #494] Epoch: [1/5][0/17]	Loss: 0.092997
[INFO][09:41:50]: [Client #236] Epoch: [1/5][10/17]	Loss: 1.961687
[INFO][09:41:50]: [Client #494] Epoch: [1/5][10/17]	Loss: 0.754840
[INFO][09:41:50]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:41:50]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][09:41:50]: [Client #494] Woke up.
[INFO][09:41:50]: [Client #494] Epoch: [2/5][0/17]	Loss: 0.421186
[INFO][09:41:50]: [Client #494] Epoch: [2/5][10/17]	Loss: 1.297018
[INFO][09:41:50]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][09:41:50]: [Client #494] Woke up.
[INFO][09:41:50]: [Client #494] Epoch: [3/5][0/17]	Loss: 0.397212
[INFO][09:41:51]: [Client #494] Epoch: [3/5][10/17]	Loss: 2.091580
[INFO][09:41:51]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][09:41:51]: [Client #494] Woke up.
[INFO][09:41:51]: [Client #494] Epoch: [4/5][0/17]	Loss: 2.904192
[INFO][09:41:51]: [Client #494] Epoch: [4/5][10/17]	Loss: 1.268950
[INFO][09:41:51]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][09:41:51]: [Client #236] Woke up.
[INFO][09:41:51]: [Client #236] Epoch: [2/5][0/17]	Loss: 1.356369
[INFO][09:41:51]: [Client #236] Epoch: [2/5][10/17]	Loss: 2.404591
[INFO][09:41:51]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:41:51]: [Client #494] Woke up.
[INFO][09:41:51]: [Client #494] Epoch: [5/5][0/17]	Loss: 0.783358
[INFO][09:41:52]: [Client #494] Epoch: [5/5][10/17]	Loss: 0.319995
[INFO][09:41:52]: [Client #494] Going to sleep for 0.33 seconds.
[INFO][09:41:52]: [Client #494] Woke up.
[INFO][09:41:52]: [Client #494] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_554860.pth.
[INFO][09:41:53]: [Client #494] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_494_554860.pth.
[INFO][09:41:53]: [Client #494] Model trained.
[INFO][09:41:53]: [Client #494] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:41:53]: [Server #554754] Received 0.26 MB of payload data from client #494 (simulated).
[INFO][09:41:53]: [Client #236] Woke up.
[INFO][09:41:53]: [Client #236] Epoch: [3/5][0/17]	Loss: 0.813852
[INFO][09:41:53]: [Client #236] Epoch: [3/5][10/17]	Loss: 1.577485
[INFO][09:41:53]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:41:54]: [Client #236] Woke up.
[INFO][09:41:54]: [Client #236] Epoch: [4/5][0/17]	Loss: 2.087987
[INFO][09:41:55]: [Client #236] Epoch: [4/5][10/17]	Loss: 1.022234
[INFO][09:41:55]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:41:56]: [Client #236] Woke up.
[INFO][09:41:56]: [Client #236] Epoch: [5/5][0/17]	Loss: 0.596102
[INFO][09:41:56]: [Client #236] Epoch: [5/5][10/17]	Loss: 1.494888
[INFO][09:41:56]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:41:58]: [Client #236] Woke up.
[INFO][09:41:58]: [Client #236] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554853.pth.
[INFO][09:41:58]: [Client #236] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554853.pth.
[INFO][09:41:58]: [Client #236] Model trained.
[INFO][09:41:58]: [Client #236] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:41:58]: [Server #554754] Received 0.26 MB of payload data from client #236 (simulated).
[INFO][09:41:58]: [Server #554754] Selecting client #475 for training.
[INFO][09:41:58]: [Server #554754] Sending the current model to client #475 (simulated).
[INFO][09:41:58]: [Server #554754] Sending 0.26 MB of payload data to client #475 (simulated).
[INFO][09:41:58]: [Server #554754] Selecting client #323 for training.
[INFO][09:41:58]: [Server #554754] Sending the current model to client #323 (simulated).
[INFO][09:41:58]: [Server #554754] Sending 0.26 MB of payload data to client #323 (simulated).
[INFO][09:41:58]: [Client #475] Selected by the server.
[INFO][09:41:58]: [Client #475] Loading its data source...
[INFO][09:41:58]: Data source: FEMNIST
[INFO][09:41:58]: [Client #323] Selected by the server.
[INFO][09:41:58]: [Client #323] Loading its data source...
[INFO][09:41:58]: Data source: FEMNIST
[INFO][09:41:58]: [Client #323] Dataset size: 154
[INFO][09:41:58]: [Client #323] Sampler: all_inclusive
[INFO][09:41:58]: [Client #475] Dataset size: 153
[INFO][09:41:58]: [Client #475] Sampler: all_inclusive
[INFO][09:41:58]: [Client #323] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:58]: [Client #475] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:41:58]: [93m[1m[Client #323] Started training in communication round #16.[0m
[INFO][09:41:58]: [93m[1m[Client #475] Started training in communication round #16.[0m
[INFO][09:42:00]: [Client #475] Loading the dataset.
[INFO][09:42:00]: [Client #323] Loading the dataset.
[INFO][09:42:06]: [Client #475] Epoch: [1/5][0/16]	Loss: 1.685777
[INFO][09:42:06]: [Client #323] Epoch: [1/5][0/16]	Loss: 0.455870
[INFO][09:42:06]: [Client #475] Epoch: [1/5][10/16]	Loss: 2.095499
[INFO][09:42:06]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:42:06]: [Client #323] Epoch: [1/5][10/16]	Loss: 0.805690
[INFO][09:42:06]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][09:42:06]: [Client #323] Woke up.
[INFO][09:42:06]: [Client #323] Epoch: [2/5][0/16]	Loss: 0.527302
[INFO][09:42:06]: [Client #323] Epoch: [2/5][10/16]	Loss: 0.717258
[INFO][09:42:06]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][09:42:07]: [Client #323] Woke up.
[INFO][09:42:07]: [Client #323] Epoch: [3/5][0/16]	Loss: 2.418762
[INFO][09:42:07]: [Client #323] Epoch: [3/5][10/16]	Loss: 0.592593
[INFO][09:42:07]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][09:42:07]: [Client #323] Woke up.
[INFO][09:42:07]: [Client #323] Epoch: [4/5][0/16]	Loss: 1.358462
[INFO][09:42:07]: [Client #323] Epoch: [4/5][10/16]	Loss: 0.512729
[INFO][09:42:07]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][09:42:08]: [Client #323] Woke up.
[INFO][09:42:08]: [Client #323] Epoch: [5/5][0/16]	Loss: 0.826442
[INFO][09:42:08]: [Client #323] Epoch: [5/5][10/16]	Loss: 1.130236
[INFO][09:42:08]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][09:42:08]: [Client #323] Woke up.
[INFO][09:42:08]: [Client #323] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_323_554860.pth.
[INFO][09:42:09]: [Client #323] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_323_554860.pth.
[INFO][09:42:09]: [Client #323] Model trained.
[INFO][09:42:09]: [Client #323] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:42:09]: [Server #554754] Received 0.26 MB of payload data from client #323 (simulated).
[INFO][09:42:21]: [Client #475] Woke up.
[INFO][09:42:21]: [Client #475] Epoch: [2/5][0/16]	Loss: 0.962875
[INFO][09:42:21]: [Client #475] Epoch: [2/5][10/16]	Loss: 1.543180
[INFO][09:42:21]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:42:37]: [Client #475] Woke up.
[INFO][09:42:37]: [Client #475] Epoch: [3/5][0/16]	Loss: 1.550969
[INFO][09:42:37]: [Client #475] Epoch: [3/5][10/16]	Loss: 2.319292
[INFO][09:42:37]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:42:52]: [Client #475] Woke up.
[INFO][09:42:52]: [Client #475] Epoch: [4/5][0/16]	Loss: 0.640335
[INFO][09:42:52]: [Client #475] Epoch: [4/5][10/16]	Loss: 1.613506
[INFO][09:42:53]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:43:08]: [Client #475] Woke up.
[INFO][09:43:08]: [Client #475] Epoch: [5/5][0/16]	Loss: 0.715306
[INFO][09:43:08]: [Client #475] Epoch: [5/5][10/16]	Loss: 0.392259
[INFO][09:43:08]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][09:43:23]: [Client #475] Woke up.
[INFO][09:43:23]: [Client #475] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:43:24]: [Client #475] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554853.pth.
[INFO][09:43:24]: [Client #475] Model trained.
[INFO][09:43:24]: [Client #475] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:43:24]: [Server #554754] Received 0.26 MB of payload data from client #475 (simulated).
[INFO][09:43:24]: [Server #554754] Selecting client #76 for training.
[INFO][09:43:24]: [Server #554754] Sending the current model to client #76 (simulated).
[INFO][09:43:24]: [Server #554754] Sending 0.26 MB of payload data to client #76 (simulated).
[INFO][09:43:24]: [Server #554754] Selecting client #320 for training.
[INFO][09:43:24]: [Server #554754] Sending the current model to client #320 (simulated).
[INFO][09:43:24]: [Server #554754] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][09:43:24]: [Client #76] Selected by the server.
[INFO][09:43:24]: [Client #76] Loading its data source...
[INFO][09:43:24]: Data source: FEMNIST
[INFO][09:43:24]: [Client #320] Selected by the server.
[INFO][09:43:24]: [Client #320] Loading its data source...
[INFO][09:43:24]: Data source: FEMNIST
[INFO][09:43:24]: [Client #320] Dataset size: 153
[INFO][09:43:24]: [Client #320] Sampler: all_inclusive
[INFO][09:43:24]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:43:24]: [93m[1m[Client #320] Started training in communication round #16.[0m
[INFO][09:43:24]: [Client #76] Dataset size: 163
[INFO][09:43:24]: [Client #76] Sampler: all_inclusive
[INFO][09:43:24]: [Client #76] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:43:24]: [93m[1m[Client #76] Started training in communication round #16.[0m
[INFO][09:43:26]: [Client #76] Loading the dataset.
[INFO][09:43:26]: [Client #320] Loading the dataset.
[INFO][09:43:32]: [Client #76] Epoch: [1/5][0/17]	Loss: 0.590291
[INFO][09:43:32]: [Client #320] Epoch: [1/5][0/16]	Loss: 1.295775
[INFO][09:43:32]: [Client #76] Epoch: [1/5][10/17]	Loss: 0.753257
[INFO][09:43:32]: [Client #320] Epoch: [1/5][10/16]	Loss: 0.430089
[INFO][09:43:32]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][09:43:32]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][09:43:32]: [Client #76] Woke up.
[INFO][09:43:32]: [Client #76] Epoch: [2/5][0/17]	Loss: 1.089794
[INFO][09:43:32]: [Client #76] Epoch: [2/5][10/17]	Loss: 0.343103
[INFO][09:43:32]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][09:43:32]: [Client #76] Woke up.
[INFO][09:43:32]: [Client #76] Epoch: [3/5][0/17]	Loss: 1.150402
[INFO][09:43:32]: [Client #76] Epoch: [3/5][10/17]	Loss: 0.682427
[INFO][09:43:32]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][09:43:33]: [Client #76] Woke up.
[INFO][09:43:33]: [Client #76] Epoch: [4/5][0/17]	Loss: 1.368307
[INFO][09:43:33]: [Client #76] Epoch: [4/5][10/17]	Loss: 1.401022
[INFO][09:43:33]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][09:43:33]: [Client #76] Woke up.
[INFO][09:43:33]: [Client #76] Epoch: [5/5][0/17]	Loss: 0.538178
[INFO][09:43:33]: [Client #76] Epoch: [5/5][10/17]	Loss: 0.839665
[INFO][09:43:33]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][09:43:33]: [Client #76] Woke up.
[INFO][09:43:33]: [Client #76] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_76_554853.pth.
[INFO][09:43:34]: [Client #76] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_76_554853.pth.
[INFO][09:43:34]: [Client #76] Model trained.
[INFO][09:43:34]: [Client #76] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:43:34]: [Server #554754] Received 0.26 MB of payload data from client #76 (simulated).
[INFO][09:43:37]: [Client #320] Woke up.
[INFO][09:43:37]: [Client #320] Epoch: [2/5][0/16]	Loss: 0.960466
[INFO][09:43:38]: [Client #320] Epoch: [2/5][10/16]	Loss: 1.008468
[INFO][09:43:38]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][09:43:43]: [Client #320] Woke up.
[INFO][09:43:43]: [Client #320] Epoch: [3/5][0/16]	Loss: 0.932397
[INFO][09:43:43]: [Client #320] Epoch: [3/5][10/16]	Loss: 1.174933
[INFO][09:43:43]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][09:43:49]: [Client #320] Woke up.
[INFO][09:43:49]: [Client #320] Epoch: [4/5][0/16]	Loss: 0.393440
[INFO][09:43:49]: [Client #320] Epoch: [4/5][10/16]	Loss: 1.034515
[INFO][09:43:49]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][09:43:55]: [Client #320] Woke up.
[INFO][09:43:55]: [Client #320] Epoch: [5/5][0/16]	Loss: 1.157177
[INFO][09:43:55]: [Client #320] Epoch: [5/5][10/16]	Loss: 0.779054
[INFO][09:43:55]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][09:44:01]: [Client #320] Woke up.
[INFO][09:44:01]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554860.pth.
[INFO][09:44:02]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554860.pth.
[INFO][09:44:02]: [Client #320] Model trained.
[INFO][09:44:02]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:44:02]: [Server #554754] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][09:44:02]: [Server #554754] Adding client #445 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #336 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #76 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #323 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #494 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #236 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #63 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #317 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #320 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Adding client #475 to the list of clients for aggregation.
[INFO][09:44:02]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09254532 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11048057 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10239611 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09994259 0.
 0.         0.15087508 0.         0.         0.07885495 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08274829
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.35956213 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.34589402 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26181062 0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09254532 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11048057 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10239611 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09994259 0.
 0.         0.15087508 0.         0.         0.07885495 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08274829
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.35956213 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.34589402 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26181062 0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:44:45]: [Server #554754] Global model accuracy: 56.65%

[INFO][09:44:45]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_16.pth.
[INFO][09:44:45]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_16.pth.
[INFO][09:44:45]: [93m[1m
[Server #554754] Starting round 17/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09675516 0.002
 0.002      0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.002
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.09482257 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.09101124
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.002      0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.002      0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.09729381 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.002      0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.0936591  0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.10631443
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.002
 0.002      0.002      0.002      0.002      0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.002      0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.1698662  0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9051e+00  7e-04  1e-08  1e-08
 5:  6.9058e+00  6.9054e+00  4e-04  5e-09  5e-09
 6:  6.9057e+00  6.9054e+00  3e-04  6e-08  2e-08
 7:  6.9057e+00  6.9054e+00  2e-04  5e-08  2e-08
 8:  6.9056e+00  6.9054e+00  1e-04  2e-07  9e-08
 9:  6.9055e+00  6.9055e+00  3e-05  3e-07  1e-07
10:  6.9055e+00  6.9055e+00  4e-06  5e-08  2e-08
Optimal solution found.
The calculated probability is:  [2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86762072e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86689831e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86721136e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86715094e-05
 2.86883230e-05 2.86883230e-05 2.86565569e-05 2.86883230e-05
 2.86883230e-05 2.86795258e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86778666e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 9.85713603e-01
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.85220369e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.85826397e-05 2.86883230e-05 2.86883230e-05 2.86883230e-05
 2.86883230e-05 2.86883230e-05 2.86883230e-05]
current clients pool:  [INFO][09:44:46]: [Server #554754] Selected clients: [445  27 100 212  54 312  24 142  31 352]
[INFO][09:44:46]: [Server #554754] Selecting client #445 for training.
[INFO][09:44:46]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][09:44:46]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][09:44:46]: [Server #554754] Selecting client #27 for training.
[INFO][09:44:46]: [Server #554754] Sending the current model to client #27 (simulated).
[INFO][09:44:46]: [Server #554754] Sending 0.26 MB of payload data to client #27 (simulated).
[INFO][09:44:46]: [Client #445] Selected by the server.
[INFO][09:44:46]: [Client #445] Loading its data source...
[INFO][09:44:46]: Data source: FEMNIST
[INFO][09:44:46]: [Client #27] Selected by the server.
[INFO][09:44:46]: [Client #27] Loading its data source...
[INFO][09:44:46]: Data source: FEMNIST
[INFO][09:44:46]: [Client #27] Dataset size: 162
[INFO][09:44:46]: [Client #27] Sampler: all_inclusive
[INFO][09:44:46]: [Client #445] Dataset size: 292
[INFO][09:44:46]: [Client #445] Sampler: all_inclusive
[INFO][09:44:46]: [Client #27] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:44:46]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:44:46]: [93m[1m[Client #27] Started training in communication round #17.[0m
[INFO][09:44:46]: [93m[1m[Client #445] Started training in communication round #17.[0m
[INFO][09:44:48]: [Client #445] Loading the dataset.
[INFO][09:44:48]: [Client #27] Loading the dataset.
[INFO][09:44:53]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.543429
[INFO][09:44:53]: [Client #27] Epoch: [1/5][0/17]	Loss: 1.533851
[INFO][09:44:53]: [Client #445] Epoch: [1/5][10/30]	Loss: 1.617917
[INFO][09:44:53]: [Client #27] Epoch: [1/5][10/17]	Loss: 0.725358
[INFO][09:44:53]: [Client #445] Epoch: [1/5][20/30]	Loss: 0.913825
[INFO][09:44:53]: [Client #27] Going to sleep for 0.09 seconds.
[INFO][09:44:54]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:44:54]: [Client #27] Woke up.
[INFO][09:44:54]: [Client #27] Epoch: [2/5][0/17]	Loss: 0.394725
[INFO][09:44:54]: [Client #27] Epoch: [2/5][10/17]	Loss: 1.148622
[INFO][09:44:54]: [Client #27] Going to sleep for 0.09 seconds.
[INFO][09:44:54]: [Client #27] Woke up.
[INFO][09:44:54]: [Client #27] Epoch: [3/5][0/17]	Loss: 1.831387
[INFO][09:44:54]: [Client #27] Epoch: [3/5][10/17]	Loss: 1.321756
[INFO][09:44:54]: [Client #27] Going to sleep for 0.09 seconds.
[INFO][09:44:54]: [Client #27] Woke up.
[INFO][09:44:54]: [Client #27] Epoch: [4/5][0/17]	Loss: 1.201639
[INFO][09:44:54]: [Client #27] Epoch: [4/5][10/17]	Loss: 0.532328
[INFO][09:44:54]: [Client #27] Going to sleep for 0.09 seconds.
[INFO][09:44:54]: [Client #27] Woke up.
[INFO][09:44:54]: [Client #27] Epoch: [5/5][0/17]	Loss: 0.772052
[INFO][09:44:54]: [Client #27] Epoch: [5/5][10/17]	Loss: 2.661104
[INFO][09:44:55]: [Client #27] Going to sleep for 0.09 seconds.
[INFO][09:44:55]: [Client #27] Woke up.
[INFO][09:44:55]: [Client #27] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_27_554860.pth.
[INFO][09:44:55]: [Client #27] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_27_554860.pth.
[INFO][09:44:55]: [Client #27] Model trained.
[INFO][09:44:55]: [Client #27] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:44:55]: [Server #554754] Received 0.26 MB of payload data from client #27 (simulated).
[INFO][09:45:13]: [Client #445] Woke up.
[INFO][09:45:13]: [Client #445] Epoch: [2/5][0/30]	Loss: 1.111644
[INFO][09:45:13]: [Client #445] Epoch: [2/5][10/30]	Loss: 0.786060
[INFO][09:45:13]: [Client #445] Epoch: [2/5][20/30]	Loss: 0.461463
[INFO][09:45:13]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:45:33]: [Client #445] Woke up.
[INFO][09:45:33]: [Client #445] Epoch: [3/5][0/30]	Loss: 0.607118
[INFO][09:45:33]: [Client #445] Epoch: [3/5][10/30]	Loss: 1.777056
[INFO][09:45:33]: [Client #445] Epoch: [3/5][20/30]	Loss: 1.452127
[INFO][09:45:33]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:45:53]: [Client #445] Woke up.
[INFO][09:45:53]: [Client #445] Epoch: [4/5][0/30]	Loss: 0.532943
[INFO][09:45:53]: [Client #445] Epoch: [4/5][10/30]	Loss: 1.252667
[INFO][09:45:53]: [Client #445] Epoch: [4/5][20/30]	Loss: 0.934256
[INFO][09:45:53]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:46:13]: [Client #445] Woke up.
[INFO][09:46:13]: [Client #445] Epoch: [5/5][0/30]	Loss: 1.503729
[INFO][09:46:13]: [Client #445] Epoch: [5/5][10/30]	Loss: 0.819056
[INFO][09:46:13]: [Client #445] Epoch: [5/5][20/30]	Loss: 1.093627
[INFO][09:46:13]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][09:46:32]: [Client #445] Woke up.
[INFO][09:46:33]: [Client #445] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554853.pth.
[INFO][09:46:33]: [Client #445] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554853.pth.
[INFO][09:46:33]: [Client #445] Model trained.
[INFO][09:46:33]: [Client #445] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:46:33]: [Server #554754] Received 0.26 MB of payload data from client #445 (simulated).
[INFO][09:46:33]: [Server #554754] Selecting client #100 for training.
[INFO][09:46:33]: [Server #554754] Sending the current model to client #100 (simulated).
[INFO][09:46:33]: [Server #554754] Sending 0.26 MB of payload data to client #100 (simulated).
[INFO][09:46:33]: [Server #554754] Selecting client #212 for training.
[INFO][09:46:33]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][09:46:33]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][09:46:33]: [Client #100] Selected by the server.
[INFO][09:46:33]: [Client #100] Loading its data source...
[INFO][09:46:33]: Data source: FEMNIST
[INFO][09:46:33]: [Client #212] Selected by the server.
[INFO][09:46:33]: [Client #212] Loading its data source...
[INFO][09:46:33]: Data source: FEMNIST
[INFO][09:46:33]: [Client #100] Dataset size: 219
[INFO][09:46:33]: [Client #100] Sampler: all_inclusive
[INFO][09:46:33]: [Client #100] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:46:33]: [Client #212] Dataset size: 160
[INFO][09:46:33]: [Client #212] Sampler: all_inclusive
[INFO][09:46:33]: [93m[1m[Client #100] Started training in communication round #17.[0m
[INFO][09:46:33]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:46:33]: [93m[1m[Client #212] Started training in communication round #17.[0m
[INFO][09:46:35]: [Client #212] Loading the dataset.
[INFO][09:46:35]: [Client #100] Loading the dataset.
[INFO][09:46:41]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.683526
[INFO][09:46:41]: [Client #100] Epoch: [1/5][0/22]	Loss: 1.402646
[INFO][09:46:41]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.812428
[INFO][09:46:41]: [Client #100] Epoch: [1/5][10/22]	Loss: 1.332588
[INFO][09:46:41]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:46:41]: [Client #100] Epoch: [1/5][20/22]	Loss: 1.991227
[INFO][09:46:41]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][09:46:42]: [Client #100] Woke up.
[INFO][09:46:42]: [Client #100] Epoch: [2/5][0/22]	Loss: 1.464158
[INFO][09:46:43]: [Client #100] Epoch: [2/5][10/22]	Loss: 1.500886
[INFO][09:46:43]: [Client #100] Epoch: [2/5][20/22]	Loss: 0.678356
[INFO][09:46:43]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][09:46:44]: [Client #100] Woke up.
[INFO][09:46:44]: [Client #100] Epoch: [3/5][0/22]	Loss: 1.058176
[INFO][09:46:44]: [Client #100] Epoch: [3/5][10/22]	Loss: 1.928439
[INFO][09:46:44]: [Client #100] Epoch: [3/5][20/22]	Loss: 2.210244
[INFO][09:46:44]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][09:46:46]: [Client #100] Woke up.
[INFO][09:46:46]: [Client #100] Epoch: [4/5][0/22]	Loss: 0.379711
[INFO][09:46:46]: [Client #100] Epoch: [4/5][10/22]	Loss: 0.446497
[INFO][09:46:46]: [Client #100] Epoch: [4/5][20/22]	Loss: 2.293275
[INFO][09:46:46]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][09:46:48]: [Client #100] Woke up.
[INFO][09:46:48]: [Client #100] Epoch: [5/5][0/22]	Loss: 0.429967
[INFO][09:46:48]: [Client #100] Epoch: [5/5][10/22]	Loss: 0.763919
[INFO][09:46:48]: [Client #100] Epoch: [5/5][20/22]	Loss: 0.782672
[INFO][09:46:48]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][09:46:50]: [Client #100] Woke up.
[INFO][09:46:50]: [Client #100] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_100_554853.pth.
[INFO][09:46:50]: [Client #100] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_100_554853.pth.
[INFO][09:46:50]: [Client #100] Model trained.
[INFO][09:46:50]: [Client #100] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:46:50]: [Server #554754] Received 0.26 MB of payload data from client #100 (simulated).
[INFO][09:47:07]: [Client #212] Woke up.
[INFO][09:47:07]: [Client #212] Epoch: [2/5][0/16]	Loss: 0.936578
[INFO][09:47:07]: [Client #212] Epoch: [2/5][10/16]	Loss: 2.132684
[INFO][09:47:07]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:47:33]: [Client #212] Woke up.
[INFO][09:47:34]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.423743
[INFO][09:47:34]: [Client #212] Epoch: [3/5][10/16]	Loss: 1.652297
[INFO][09:47:34]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:48:00]: [Client #212] Woke up.
[INFO][09:48:00]: [Client #212] Epoch: [4/5][0/16]	Loss: 1.368770
[INFO][09:48:00]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.459705
[INFO][09:48:00]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:48:26]: [Client #212] Woke up.
[INFO][09:48:27]: [Client #212] Epoch: [5/5][0/16]	Loss: 0.736794
[INFO][09:48:27]: [Client #212] Epoch: [5/5][10/16]	Loss: 1.275322
[INFO][09:48:27]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:48:53]: [Client #212] Woke up.
[INFO][09:48:53]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554860.pth.
[INFO][09:48:54]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554860.pth.
[INFO][09:48:54]: [Client #212] Model trained.
[INFO][09:48:54]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:48:54]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][09:48:54]: [Server #554754] Selecting client #54 for training.
[INFO][09:48:54]: [Server #554754] Sending the current model to client #54 (simulated).
[INFO][09:48:54]: [Server #554754] Sending 0.26 MB of payload data to client #54 (simulated).
[INFO][09:48:54]: [Server #554754] Selecting client #312 for training.
[INFO][09:48:54]: [Server #554754] Sending the current model to client #312 (simulated).
[INFO][09:48:54]: [Server #554754] Sending 0.26 MB of payload data to client #312 (simulated).
[INFO][09:48:54]: [Client #54] Selected by the server.
[INFO][09:48:54]: [Client #312] Selected by the server.
[INFO][09:48:54]: [Client #54] Loading its data source...
[INFO][09:48:54]: [Client #312] Loading its data source...
[INFO][09:48:54]: Data source: FEMNIST
[INFO][09:48:54]: Data source: FEMNIST
[INFO][09:48:54]: [Client #54] Dataset size: 136
[INFO][09:48:54]: [Client #54] Sampler: all_inclusive
[INFO][09:48:54]: [Client #312] Dataset size: 154
[INFO][09:48:54]: [Client #312] Sampler: all_inclusive
[INFO][09:48:54]: [Client #312] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:48:54]: [Client #54] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:48:54]: [93m[1m[Client #312] Started training in communication round #17.[0m
[INFO][09:48:54]: [93m[1m[Client #54] Started training in communication round #17.[0m
[INFO][09:48:56]: [Client #54] Loading the dataset.
[INFO][09:48:56]: [Client #312] Loading the dataset.
[INFO][09:49:01]: [Client #54] Epoch: [1/5][0/14]	Loss: 2.231822
[INFO][09:49:01]: [Client #312] Epoch: [1/5][0/16]	Loss: 1.439544
[INFO][09:49:01]: [Client #54] Epoch: [1/5][10/14]	Loss: 1.212486
[INFO][09:49:01]: [Client #312] Epoch: [1/5][10/16]	Loss: 0.346623
[INFO][09:49:01]: [Client #54] Going to sleep for 0.36 seconds.
[INFO][09:49:01]: [Client #312] Going to sleep for 10.07 seconds.
[INFO][09:49:02]: [Client #54] Woke up.
[INFO][09:49:02]: [Client #54] Epoch: [2/5][0/14]	Loss: 0.739638
[INFO][09:49:02]: [Client #54] Epoch: [2/5][10/14]	Loss: 1.601583
[INFO][09:49:02]: [Client #54] Going to sleep for 0.36 seconds.
[INFO][09:49:02]: [Client #54] Woke up.
[INFO][09:49:02]: [Client #54] Epoch: [3/5][0/14]	Loss: 0.604444
[INFO][09:49:02]: [Client #54] Epoch: [3/5][10/14]	Loss: 1.071448
[INFO][09:49:02]: [Client #54] Going to sleep for 0.36 seconds.
[INFO][09:49:03]: [Client #54] Woke up.
[INFO][09:49:03]: [Client #54] Epoch: [4/5][0/14]	Loss: 3.144961
[INFO][09:49:03]: [Client #54] Epoch: [4/5][10/14]	Loss: 1.221421
[INFO][09:49:03]: [Client #54] Going to sleep for 0.36 seconds.
[INFO][09:49:03]: [Client #54] Woke up.
[INFO][09:49:03]: [Client #54] Epoch: [5/5][0/14]	Loss: 1.536836
[INFO][09:49:03]: [Client #54] Epoch: [5/5][10/14]	Loss: 0.588024
[INFO][09:49:03]: [Client #54] Going to sleep for 0.36 seconds.
[INFO][09:49:03]: [Client #54] Woke up.
[INFO][09:49:03]: [Client #54] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_54_554853.pth.
[INFO][09:49:04]: [Client #54] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_54_554853.pth.
[INFO][09:49:04]: [Client #54] Model trained.
[INFO][09:49:04]: [Client #54] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:49:04]: [Server #554754] Received 0.26 MB of payload data from client #54 (simulated).
[INFO][09:49:11]: [Client #312] Woke up.
[INFO][09:49:11]: [Client #312] Epoch: [2/5][0/16]	Loss: 0.703239
[INFO][09:49:11]: [Client #312] Epoch: [2/5][10/16]	Loss: 2.462256
[INFO][09:49:11]: [Client #312] Going to sleep for 10.07 seconds.
[INFO][09:49:21]: [Client #312] Woke up.
[INFO][09:49:21]: [Client #312] Epoch: [3/5][0/16]	Loss: 0.946667
[INFO][09:49:22]: [Client #312] Epoch: [3/5][10/16]	Loss: 2.378129
[INFO][09:49:22]: [Client #312] Going to sleep for 10.07 seconds.
[INFO][09:49:32]: [Client #312] Woke up.
[INFO][09:49:32]: [Client #312] Epoch: [4/5][0/16]	Loss: 0.215391
[INFO][09:49:32]: [Client #312] Epoch: [4/5][10/16]	Loss: 1.580273
[INFO][09:49:32]: [Client #312] Going to sleep for 10.07 seconds.
[INFO][09:49:42]: [Client #312] Woke up.
[INFO][09:49:42]: [Client #312] Epoch: [5/5][0/16]	Loss: 1.345941
[INFO][09:49:42]: [Client #312] Epoch: [5/5][10/16]	Loss: 1.926678
[INFO][09:49:42]: [Client #312] Going to sleep for 10.07 seconds.
[INFO][09:49:52]: [Client #312] Woke up.
[INFO][09:49:52]: [Client #312] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_312_554860.pth.
[INFO][09:49:53]: [Client #312] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_312_554860.pth.
[INFO][09:49:53]: [Client #312] Model trained.
[INFO][09:49:53]: [Client #312] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:49:53]: [Server #554754] Received 0.26 MB of payload data from client #312 (simulated).
[INFO][09:49:53]: [Server #554754] Selecting client #24 for training.
[INFO][09:49:53]: [Server #554754] Sending the current model to client #24 (simulated).
[INFO][09:49:53]: [Server #554754] Sending 0.26 MB of payload data to client #24 (simulated).
[INFO][09:49:53]: [Server #554754] Selecting client #142 for training.
[INFO][09:49:53]: [Server #554754] Sending the current model to client #142 (simulated).
[INFO][09:49:53]: [Server #554754] Sending 0.26 MB of payload data to client #142 (simulated).
[INFO][09:49:53]: [Client #24] Selected by the server.
[INFO][09:49:53]: [Client #142] Selected by the server.
[INFO][09:49:53]: [Client #142] Loading its data source...
[INFO][09:49:53]: [Client #24] Loading its data source...
[INFO][09:49:53]: Data source: FEMNIST
[INFO][09:49:53]: Data source: FEMNIST
[INFO][09:49:53]: [Client #142] Dataset size: 159
[INFO][09:49:53]: [Client #142] Sampler: all_inclusive
[INFO][09:49:53]: [Client #142] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:49:53]: [Client #24] Dataset size: 146
[INFO][09:49:53]: [93m[1m[Client #142] Started training in communication round #17.[0m
[INFO][09:49:53]: [Client #24] Sampler: all_inclusive
[INFO][09:49:53]: [Client #24] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:49:53]: [93m[1m[Client #24] Started training in communication round #17.[0m
[INFO][09:49:55]: [Client #142] Loading the dataset.
[INFO][09:49:55]: [Client #24] Loading the dataset.
[INFO][09:50:00]: [Client #24] Epoch: [1/5][0/15]	Loss: 0.811168
[INFO][09:50:00]: [Client #142] Epoch: [1/5][0/16]	Loss: 0.313100
[INFO][09:50:00]: [Client #24] Epoch: [1/5][10/15]	Loss: 2.241420
[INFO][09:50:00]: [Client #142] Epoch: [1/5][10/16]	Loss: 0.552638
[INFO][09:50:00]: [Client #24] Going to sleep for 2.25 seconds.
[INFO][09:50:00]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][09:50:00]: [Client #142] Woke up.
[INFO][09:50:00]: [Client #142] Epoch: [2/5][0/16]	Loss: 0.137902
[INFO][09:50:01]: [Client #142] Epoch: [2/5][10/16]	Loss: 0.742773
[INFO][09:50:01]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][09:50:01]: [Client #142] Woke up.
[INFO][09:50:01]: [Client #142] Epoch: [3/5][0/16]	Loss: 0.247544
[INFO][09:50:01]: [Client #142] Epoch: [3/5][10/16]	Loss: 0.299433
[INFO][09:50:01]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][09:50:01]: [Client #142] Woke up.
[INFO][09:50:01]: [Client #142] Epoch: [4/5][0/16]	Loss: 0.189785
[INFO][09:50:01]: [Client #142] Epoch: [4/5][10/16]	Loss: 0.384628
[INFO][09:50:01]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][09:50:01]: [Client #142] Woke up.
[INFO][09:50:01]: [Client #142] Epoch: [5/5][0/16]	Loss: 0.183151
[INFO][09:50:01]: [Client #142] Epoch: [5/5][10/16]	Loss: 1.312650
[INFO][09:50:02]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][09:50:02]: [Client #142] Woke up.
[INFO][09:50:02]: [Client #142] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_554860.pth.
[INFO][09:50:02]: [Client #142] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_554860.pth.
[INFO][09:50:02]: [Client #142] Model trained.
[INFO][09:50:02]: [Client #142] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:50:02]: [Server #554754] Received 0.26 MB of payload data from client #142 (simulated).
[INFO][09:50:03]: [Client #24] Woke up.
[INFO][09:50:03]: [Client #24] Epoch: [2/5][0/15]	Loss: 0.513777
[INFO][09:50:03]: [Client #24] Epoch: [2/5][10/15]	Loss: 1.141392
[INFO][09:50:03]: [Client #24] Going to sleep for 2.25 seconds.
[INFO][09:50:05]: [Client #24] Woke up.
[INFO][09:50:05]: [Client #24] Epoch: [3/5][0/15]	Loss: 1.051301
[INFO][09:50:05]: [Client #24] Epoch: [3/5][10/15]	Loss: 0.579600
[INFO][09:50:05]: [Client #24] Going to sleep for 2.25 seconds.
[INFO][09:50:07]: [Client #24] Woke up.
[INFO][09:50:07]: [Client #24] Epoch: [4/5][0/15]	Loss: 1.658902
[INFO][09:50:07]: [Client #24] Epoch: [4/5][10/15]	Loss: 0.360965
[INFO][09:50:07]: [Client #24] Going to sleep for 2.25 seconds.
[INFO][09:50:10]: [Client #24] Woke up.
[INFO][09:50:10]: [Client #24] Epoch: [5/5][0/15]	Loss: 0.138939
[INFO][09:50:10]: [Client #24] Epoch: [5/5][10/15]	Loss: 0.370387
[INFO][09:50:10]: [Client #24] Going to sleep for 2.25 seconds.
[INFO][09:50:12]: [Client #24] Woke up.
[INFO][09:50:12]: [Client #24] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_24_554853.pth.
[INFO][09:50:13]: [Client #24] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_24_554853.pth.
[INFO][09:50:13]: [Client #24] Model trained.
[INFO][09:50:13]: [Client #24] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:50:13]: [Server #554754] Received 0.26 MB of payload data from client #24 (simulated).
[INFO][09:50:13]: [Server #554754] Selecting client #31 for training.
[INFO][09:50:13]: [Server #554754] Sending the current model to client #31 (simulated).
[INFO][09:50:13]: [Server #554754] Sending 0.26 MB of payload data to client #31 (simulated).
[INFO][09:50:13]: [Server #554754] Selecting client #352 for training.
[INFO][09:50:13]: [Server #554754] Sending the current model to client #352 (simulated).
[INFO][09:50:13]: [Server #554754] Sending 0.26 MB of payload data to client #352 (simulated).
[INFO][09:50:13]: [Client #31] Selected by the server.
[INFO][09:50:13]: [Client #31] Loading its data source...
[INFO][09:50:13]: Data source: FEMNIST
[INFO][09:50:13]: [Client #352] Selected by the server.
[INFO][09:50:13]: [Client #352] Loading its data source...
[INFO][09:50:13]: Data source: FEMNIST
[INFO][09:50:13]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:50:13]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/352.zip.
[INFO][09:50:13]: [Client #31] Dataset size: 148
[INFO][09:50:13]: [Client #31] Sampler: all_inclusive
[INFO][09:50:13]: [Client #31] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:50:13]: [93m[1m[Client #31] Started training in communication round #17.[0m

3.1%
6.3%
9.4%
12.5%
15.6%
18.8%
21.9%
25.0%
28.2%
31.3%
34.4%
37.6%
40.7%
43.8%
46.9%
50.1%
53.2%
56.3%
59.5%
62.6%
65.7%
68.8%
72.0%
75.1%
78.2%
81.4%
84.5%
87.6%
90.7%
93.9%
97.0%
100.0%[INFO][09:50:13]: Decompressing the dataset downloaded.
[INFO][09:50:13]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/352.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:50:13]: [Client #352] Dataset size: 163
[INFO][09:50:13]: [Client #352] Sampler: all_inclusive
[INFO][09:50:13]: [Client #352] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:50:13]: [93m[1m[Client #352] Started training in communication round #17.[0m

[INFO][09:50:15]: [Client #31] Loading the dataset.
[INFO][09:50:15]: [Client #352] Loading the dataset.
[INFO][09:50:20]: [Client #31] Epoch: [1/5][0/15]	Loss: 2.092540
[INFO][09:50:20]: [Client #352] Epoch: [1/5][0/17]	Loss: 1.345007
[INFO][09:50:20]: [Client #31] Epoch: [1/5][10/15]	Loss: 0.355956
[INFO][09:50:20]: [Client #352] Epoch: [1/5][10/17]	Loss: 0.498336
[INFO][09:50:20]: [Client #31] Going to sleep for 0.11 seconds.
[INFO][09:50:20]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][09:50:20]: [Client #31] Woke up.
[INFO][09:50:20]: [Client #31] Epoch: [2/5][0/15]	Loss: 0.740893
[INFO][09:50:20]: [Client #31] Epoch: [2/5][10/15]	Loss: 1.298499
[INFO][09:50:20]: [Client #31] Going to sleep for 0.11 seconds.
[INFO][09:50:21]: [Client #31] Woke up.
[INFO][09:50:21]: [Client #31] Epoch: [3/5][0/15]	Loss: 0.685841
[INFO][09:50:21]: [Client #31] Epoch: [3/5][10/15]	Loss: 2.982173
[INFO][09:50:21]: [Client #31] Going to sleep for 0.11 seconds.
[INFO][09:50:21]: [Client #31] Woke up.
[INFO][09:50:21]: [Client #31] Epoch: [4/5][0/15]	Loss: 1.098443
[INFO][09:50:21]: [Client #31] Epoch: [4/5][10/15]	Loss: 1.533553
[INFO][09:50:21]: [Client #31] Going to sleep for 0.11 seconds.
[INFO][09:50:21]: [Client #31] Woke up.
[INFO][09:50:21]: [Client #31] Epoch: [5/5][0/15]	Loss: 0.778237
[INFO][09:50:21]: [Client #31] Epoch: [5/5][10/15]	Loss: 1.539836
[INFO][09:50:21]: [Client #31] Going to sleep for 0.11 seconds.
[INFO][09:50:21]: [Client #31] Woke up.
[INFO][09:50:21]: [Client #31] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_31_554853.pth.
[INFO][09:50:22]: [Client #31] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_31_554853.pth.
[INFO][09:50:22]: [Client #31] Model trained.
[INFO][09:50:22]: [Client #31] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:50:22]: [Server #554754] Received 0.26 MB of payload data from client #31 (simulated).
[INFO][09:50:23]: [Client #352] Woke up.
[INFO][09:50:23]: [Client #352] Epoch: [2/5][0/17]	Loss: 0.648844
[INFO][09:50:23]: [Client #352] Epoch: [2/5][10/17]	Loss: 0.301532
[INFO][09:50:23]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][09:50:26]: [Client #352] Woke up.
[INFO][09:50:26]: [Client #352] Epoch: [3/5][0/17]	Loss: 0.906357
[INFO][09:50:26]: [Client #352] Epoch: [3/5][10/17]	Loss: 0.799752
[INFO][09:50:26]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][09:50:29]: [Client #352] Woke up.
[INFO][09:50:29]: [Client #352] Epoch: [4/5][0/17]	Loss: 0.247573
[INFO][09:50:29]: [Client #352] Epoch: [4/5][10/17]	Loss: 1.170182
[INFO][09:50:29]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][09:50:32]: [Client #352] Woke up.
[INFO][09:50:32]: [Client #352] Epoch: [5/5][0/17]	Loss: 1.542478
[INFO][09:50:32]: [Client #352] Epoch: [5/5][10/17]	Loss: 1.481576
[INFO][09:50:32]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][09:50:35]: [Client #352] Woke up.
[INFO][09:50:35]: [Client #352] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_554860.pth.
[INFO][09:50:35]: [Client #352] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_554860.pth.
[INFO][09:50:35]: [Client #352] Model trained.
[INFO][09:50:35]: [Client #352] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:50:35]: [Server #554754] Received 0.26 MB of payload data from client #352 (simulated).
[INFO][09:50:35]: [Server #554754] Adding client #31 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #27 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #142 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #54 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #100 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #24 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #352 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #312 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Adding client #445 to the list of clients for aggregation.
[INFO][09:50:35]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10593127
 0.         0.         0.1197428  0.         0.         0.
 0.09618832 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11830401
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14868004 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.05974762 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.32463286 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1061435
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17716202 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16643446 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10593127
 0.         0.         0.1197428  0.         0.         0.
 0.09618832 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11830401
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14868004 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.05974762 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.32463286 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1061435
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.17716202 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16643446 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:51:19]: [Server #554754] Global model accuracy: 57.51%

[INFO][09:51:19]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_17.pth.
[INFO][09:51:19]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_17.pth.
[INFO][09:51:19]: [93m[1m
[Server #554754] Starting round 18/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.09482257 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.09101124
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.07433628 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.08728324 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.08314607 0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.002      0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.0936591  0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.10631443
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.002      0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10448718 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.16878613 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.002      0.002      0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9051e+00  6e-04  1e-08  1e-08
 5:  6.9058e+00  6.9054e+00  3e-04  5e-09  5e-09
 6:  6.9057e+00  6.9054e+00  3e-04  4e-08  2e-08
 7:  6.9057e+00  6.9054e+00  2e-04  4e-08  1e-08
 8:  6.9056e+00  6.9055e+00  1e-04  3e-07  9e-08
 9:  6.9055e+00  6.9055e+00  2e-05  2e-07  7e-08
10:  6.9055e+00  6.9055e+00  2e-06  2e-08  7e-09
Optimal solution found.
The calculated probability is:  [1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31425402e-05
 1.31497196e-05 1.31497196e-05 1.31384283e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31436364e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31419501e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31179486e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31470100e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 9.93451610e-01
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31417003e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31247193e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.30791214e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05 1.31497196e-05
 1.31497196e-05 1.31497196e-05 1.31497196e-05]
current clients pool:  [INFO][09:51:20]: [Server #554754] Selected clients: [152 176 115 219 192 236 490 183 388 278]
[INFO][09:51:20]: [Server #554754] Selecting client #152 for training.
[INFO][09:51:20]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][09:51:20]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][09:51:20]: [Server #554754] Selecting client #176 for training.
[INFO][09:51:20]: [Server #554754] Sending the current model to client #176 (simulated).
[INFO][09:51:20]: [Server #554754] Sending 0.26 MB of payload data to client #176 (simulated).
[INFO][09:51:20]: [Client #152] Selected by the server.
[INFO][09:51:20]: [Client #152] Loading its data source...
[INFO][09:51:20]: Data source: FEMNIST
[INFO][09:51:20]: [Client #176] Selected by the server.
[INFO][09:51:20]: [Client #176] Loading its data source...
[INFO][09:51:20]: Data source: FEMNIST
[INFO][09:51:20]: [Client #152] Dataset size: 151
[INFO][09:51:20]: [Client #152] Sampler: all_inclusive
[INFO][09:51:20]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:51:20]: [Client #176] Dataset size: 148
[INFO][09:51:20]: [Client #176] Sampler: all_inclusive
[INFO][09:51:20]: [Client #176] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:51:20]: [93m[1m[Client #176] Started training in communication round #18.[0m
[INFO][09:51:20]: [93m[1m[Client #152] Started training in communication round #18.[0m
[INFO][09:51:22]: [Client #152] Loading the dataset.
[INFO][09:51:22]: [Client #176] Loading the dataset.
[INFO][09:51:27]: [Client #152] Epoch: [1/5][0/16]	Loss: 2.049667
[INFO][09:51:27]: [Client #176] Epoch: [1/5][0/15]	Loss: 0.614747
[INFO][09:51:28]: [Client #152] Epoch: [1/5][10/16]	Loss: 1.070728
[INFO][09:51:28]: [Client #176] Epoch: [1/5][10/15]	Loss: 1.251079
[INFO][09:51:28]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:51:28]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][09:51:31]: [Client #176] Woke up.
[INFO][09:51:31]: [Client #176] Epoch: [2/5][0/15]	Loss: 0.478026
[INFO][09:51:31]: [Client #176] Epoch: [2/5][10/15]	Loss: 0.288745
[INFO][09:51:31]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][09:51:34]: [Client #176] Woke up.
[INFO][09:51:34]: [Client #176] Epoch: [3/5][0/15]	Loss: 0.339074
[INFO][09:51:34]: [Client #176] Epoch: [3/5][10/15]	Loss: 0.125033
[INFO][09:51:34]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][09:51:37]: [Client #176] Woke up.
[INFO][09:51:37]: [Client #176] Epoch: [4/5][0/15]	Loss: 0.002218
[INFO][09:51:37]: [Client #176] Epoch: [4/5][10/15]	Loss: 0.311037
[INFO][09:51:37]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][09:51:40]: [Client #176] Woke up.
[INFO][09:51:40]: [Client #176] Epoch: [5/5][0/15]	Loss: 1.029450
[INFO][09:51:40]: [Client #176] Epoch: [5/5][10/15]	Loss: 0.509442
[INFO][09:51:40]: [Client #176] Going to sleep for 2.93 seconds.
[INFO][09:51:43]: [Client #176] Woke up.
[INFO][09:51:43]: [Client #176] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554860.pth.
[INFO][09:51:43]: [Client #176] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_176_554860.pth.
[INFO][09:51:44]: [Client #176] Model trained.
[INFO][09:51:44]: [Client #176] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:51:44]: [Server #554754] Received 0.26 MB of payload data from client #176 (simulated).
[INFO][09:51:57]: [Client #152] Woke up.
[INFO][09:51:57]: [Client #152] Epoch: [2/5][0/16]	Loss: 1.239385
[INFO][09:51:57]: [Client #152] Epoch: [2/5][10/16]	Loss: 1.379597
[INFO][09:51:57]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:52:27]: [Client #152] Woke up.
[INFO][09:52:27]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.316010
[INFO][09:52:27]: [Client #152] Epoch: [3/5][10/16]	Loss: 1.341488
[INFO][09:52:27]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:52:57]: [Client #152] Woke up.
[INFO][09:52:57]: [Client #152] Epoch: [4/5][0/16]	Loss: 0.385266
[INFO][09:52:57]: [Client #152] Epoch: [4/5][10/16]	Loss: 0.831239
[INFO][09:52:57]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:53:27]: [Client #152] Woke up.
[INFO][09:53:27]: [Client #152] Epoch: [5/5][0/16]	Loss: 1.048269
[INFO][09:53:27]: [Client #152] Epoch: [5/5][10/16]	Loss: 0.764748
[INFO][09:53:27]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][09:53:56]: [Client #152] Woke up.
[INFO][09:53:57]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][09:53:57]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][09:53:57]: [Client #152] Model trained.
[INFO][09:53:57]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:53:57]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][09:53:57]: [Server #554754] Selecting client #115 for training.
[INFO][09:53:57]: [Server #554754] Sending the current model to client #115 (simulated).
[INFO][09:53:57]: [Server #554754] Sending 0.26 MB of payload data to client #115 (simulated).
[INFO][09:53:57]: [Server #554754] Selecting client #219 for training.
[INFO][09:53:57]: [Server #554754] Sending the current model to client #219 (simulated).
[INFO][09:53:57]: [Server #554754] Sending 0.26 MB of payload data to client #219 (simulated).
[INFO][09:53:57]: [Client #115] Selected by the server.
[INFO][09:53:57]: [Client #115] Loading its data source...
[INFO][09:53:57]: Data source: FEMNIST
[INFO][09:53:57]: [Client #219] Selected by the server.
[INFO][09:53:57]: [Client #219] Loading its data source...
[INFO][09:53:57]: Data source: FEMNIST
[INFO][09:53:57]: [Client #115] Dataset size: 126
[INFO][09:53:57]: [Client #115] Sampler: all_inclusive
[INFO][09:53:57]: [Client #115] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:53:57]: [93m[1m[Client #115] Started training in communication round #18.[0m
[INFO][09:53:57]: [Client #219] Dataset size: 154
[INFO][09:53:57]: [Client #219] Sampler: all_inclusive
[INFO][09:53:57]: [Client #219] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:53:57]: [93m[1m[Client #219] Started training in communication round #18.[0m
[INFO][09:53:59]: [Client #219] Loading the dataset.
[INFO][09:53:59]: [Client #115] Loading the dataset.
[INFO][09:54:05]: [Client #219] Epoch: [1/5][0/16]	Loss: 2.206716
[INFO][09:54:05]: [Client #115] Epoch: [1/5][0/13]	Loss: 0.607091
[INFO][09:54:05]: [Client #219] Epoch: [1/5][10/16]	Loss: 1.356122
[INFO][09:54:05]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][09:54:05]: [Client #115] Epoch: [1/5][10/13]	Loss: 1.929234
[INFO][09:54:05]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][09:54:05]: [Client #115] Woke up.
[INFO][09:54:05]: [Client #115] Epoch: [2/5][0/13]	Loss: 0.469954
[INFO][09:54:05]: [Client #115] Epoch: [2/5][10/13]	Loss: 1.079550
[INFO][09:54:05]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][09:54:05]: [Client #115] Woke up.
[INFO][09:54:05]: [Client #115] Epoch: [3/5][0/13]	Loss: 0.628852
[INFO][09:54:05]: [Client #115] Epoch: [3/5][10/13]	Loss: 0.879921
[INFO][09:54:05]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][09:54:05]: [Client #115] Woke up.
[INFO][09:54:05]: [Client #115] Epoch: [4/5][0/13]	Loss: 0.518421
[INFO][09:54:05]: [Client #115] Epoch: [4/5][10/13]	Loss: 0.312885
[INFO][09:54:05]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][09:54:06]: [Client #115] Woke up.
[INFO][09:54:06]: [Client #115] Epoch: [5/5][0/13]	Loss: 0.622758
[INFO][09:54:06]: [Client #115] Epoch: [5/5][10/13]	Loss: 1.387228
[INFO][09:54:06]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][09:54:06]: [Client #115] Woke up.
[INFO][09:54:06]: [Client #115] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554853.pth.
[INFO][09:54:06]: [Client #115] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554853.pth.
[INFO][09:54:06]: [Client #115] Model trained.
[INFO][09:54:06]: [Client #115] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:54:06]: [Server #554754] Received 0.26 MB of payload data from client #115 (simulated).
[INFO][09:54:10]: [Client #219] Woke up.
[INFO][09:54:10]: [Client #219] Epoch: [2/5][0/16]	Loss: 0.850086
[INFO][09:54:10]: [Client #219] Epoch: [2/5][10/16]	Loss: 1.319311
[INFO][09:54:10]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][09:54:15]: [Client #219] Woke up.
[INFO][09:54:15]: [Client #219] Epoch: [3/5][0/16]	Loss: 1.316480
[INFO][09:54:15]: [Client #219] Epoch: [3/5][10/16]	Loss: 1.363311
[INFO][09:54:15]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][09:54:19]: [Client #219] Woke up.
[INFO][09:54:19]: [Client #219] Epoch: [4/5][0/16]	Loss: 1.819252
[INFO][09:54:20]: [Client #219] Epoch: [4/5][10/16]	Loss: 1.104102
[INFO][09:54:20]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][09:54:24]: [Client #219] Woke up.
[INFO][09:54:24]: [Client #219] Epoch: [5/5][0/16]	Loss: 1.135989
[INFO][09:54:24]: [Client #219] Epoch: [5/5][10/16]	Loss: 1.000489
[INFO][09:54:25]: [Client #219] Going to sleep for 4.78 seconds.
[INFO][09:54:29]: [Client #219] Woke up.
[INFO][09:54:29]: [Client #219] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_219_554860.pth.
[INFO][09:54:30]: [Client #219] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_219_554860.pth.
[INFO][09:54:30]: [Client #219] Model trained.
[INFO][09:54:30]: [Client #219] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:54:30]: [Server #554754] Received 0.26 MB of payload data from client #219 (simulated).
[INFO][09:54:30]: [Server #554754] Selecting client #192 for training.
[INFO][09:54:30]: [Server #554754] Sending the current model to client #192 (simulated).
[INFO][09:54:30]: [Server #554754] Sending 0.26 MB of payload data to client #192 (simulated).
[INFO][09:54:30]: [Server #554754] Selecting client #236 for training.
[INFO][09:54:30]: [Server #554754] Sending the current model to client #236 (simulated).
[INFO][09:54:30]: [Server #554754] Sending 0.26 MB of payload data to client #236 (simulated).
[INFO][09:54:30]: [Client #192] Selected by the server.
[INFO][09:54:30]: [Client #192] Loading its data source...
[INFO][09:54:30]: Data source: FEMNIST
[INFO][09:54:30]: [Client #236] Selected by the server.
[INFO][09:54:30]: [Client #236] Loading its data source...
[INFO][09:54:30]: Data source: FEMNIST
[INFO][09:54:30]: [Client #192] Dataset size: 158
[INFO][09:54:30]: [Client #192] Sampler: all_inclusive
[INFO][09:54:30]: [Client #236] Dataset size: 161
[INFO][09:54:30]: [Client #236] Sampler: all_inclusive
[INFO][09:54:30]: [Client #192] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:54:30]: [Client #236] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:54:30]: [93m[1m[Client #192] Started training in communication round #18.[0m
[INFO][09:54:30]: [93m[1m[Client #236] Started training in communication round #18.[0m
[INFO][09:54:32]: [Client #236] Loading the dataset.
[INFO][09:54:32]: [Client #192] Loading the dataset.
[INFO][09:54:37]: [Client #236] Epoch: [1/5][0/17]	Loss: 2.190767
[INFO][09:54:37]: [Client #192] Epoch: [1/5][0/16]	Loss: 0.301543
[INFO][09:54:38]: [Client #236] Epoch: [1/5][10/17]	Loss: 0.548430
[INFO][09:54:38]: [Client #192] Epoch: [1/5][10/16]	Loss: 1.494692
[INFO][09:54:38]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:54:38]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][09:54:38]: [Client #192] Woke up.
[INFO][09:54:38]: [Client #192] Epoch: [2/5][0/16]	Loss: 0.764102
[INFO][09:54:38]: [Client #192] Epoch: [2/5][10/16]	Loss: 0.580507
[INFO][09:54:38]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][09:54:38]: [Client #192] Woke up.
[INFO][09:54:38]: [Client #192] Epoch: [3/5][0/16]	Loss: 0.670171
[INFO][09:54:38]: [Client #192] Epoch: [3/5][10/16]	Loss: 0.448575
[INFO][09:54:38]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][09:54:38]: [Client #192] Woke up.
[INFO][09:54:38]: [Client #192] Epoch: [4/5][0/16]	Loss: 0.821000
[INFO][09:54:38]: [Client #192] Epoch: [4/5][10/16]	Loss: 0.825876
[INFO][09:54:38]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][09:54:38]: [Client #192] Woke up.
[INFO][09:54:38]: [Client #192] Epoch: [5/5][0/16]	Loss: 0.855640
[INFO][09:54:38]: [Client #192] Epoch: [5/5][10/16]	Loss: 1.140512
[INFO][09:54:38]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][09:54:38]: [Client #192] Woke up.
[INFO][09:54:38]: [Client #192] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_554853.pth.
[INFO][09:54:39]: [Client #236] Woke up.
[INFO][09:54:39]: [Client #236] Epoch: [2/5][0/17]	Loss: 0.877592
[INFO][09:54:39]: [Client #192] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_554853.pth.
[INFO][09:54:39]: [Client #192] Model trained.
[INFO][09:54:39]: [Client #192] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:54:39]: [Server #554754] Received 0.26 MB of payload data from client #192 (simulated).
[INFO][09:54:39]: [Client #236] Epoch: [2/5][10/17]	Loss: 0.828565
[INFO][09:54:39]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:54:41]: [Client #236] Woke up.
[INFO][09:54:41]: [Client #236] Epoch: [3/5][0/17]	Loss: 0.541125
[INFO][09:54:41]: [Client #236] Epoch: [3/5][10/17]	Loss: 1.936710
[INFO][09:54:41]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:54:42]: [Client #236] Woke up.
[INFO][09:54:42]: [Client #236] Epoch: [4/5][0/17]	Loss: 0.439757
[INFO][09:54:42]: [Client #236] Epoch: [4/5][10/17]	Loss: 1.239304
[INFO][09:54:43]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:54:44]: [Client #236] Woke up.
[INFO][09:54:44]: [Client #236] Epoch: [5/5][0/17]	Loss: 0.813285
[INFO][09:54:44]: [Client #236] Epoch: [5/5][10/17]	Loss: 1.805431
[INFO][09:54:44]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][09:54:46]: [Client #236] Woke up.
[INFO][09:54:46]: [Client #236] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554860.pth.
[INFO][09:54:46]: [Client #236] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554860.pth.
[INFO][09:54:46]: [Client #236] Model trained.
[INFO][09:54:46]: [Client #236] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:54:46]: [Server #554754] Received 0.26 MB of payload data from client #236 (simulated).
[INFO][09:54:46]: [Server #554754] Selecting client #490 for training.
[INFO][09:54:46]: [Server #554754] Sending the current model to client #490 (simulated).
[INFO][09:54:46]: [Server #554754] Sending 0.26 MB of payload data to client #490 (simulated).
[INFO][09:54:46]: [Server #554754] Selecting client #183 for training.
[INFO][09:54:46]: [Server #554754] Sending the current model to client #183 (simulated).
[INFO][09:54:46]: [Server #554754] Sending 0.26 MB of payload data to client #183 (simulated).
[INFO][09:54:46]: [Client #183] Selected by the server.
[INFO][09:54:46]: [Client #490] Selected by the server.
[INFO][09:54:46]: [Client #183] Loading its data source...
[INFO][09:54:46]: [Client #490] Loading its data source...
[INFO][09:54:46]: Data source: FEMNIST
[INFO][09:54:46]: Data source: FEMNIST
[INFO][09:54:46]: [Client #490] Dataset size: 147
[INFO][09:54:46]: [Client #490] Sampler: all_inclusive
[INFO][09:54:46]: [Client #490] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:54:46]: [93m[1m[Client #490] Started training in communication round #18.[0m
[INFO][09:54:46]: [Client #183] Dataset size: 153
[INFO][09:54:46]: [Client #183] Sampler: all_inclusive
[INFO][09:54:46]: [Client #183] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:54:46]: [93m[1m[Client #183] Started training in communication round #18.[0m
[INFO][09:54:48]: [Client #490] Loading the dataset.
[INFO][09:54:48]: [Client #183] Loading the dataset.
[INFO][09:54:54]: [Client #183] Epoch: [1/5][0/16]	Loss: 1.047832
[INFO][09:54:54]: [Client #490] Epoch: [1/5][0/15]	Loss: 0.579606
[INFO][09:54:54]: [Client #183] Epoch: [1/5][10/16]	Loss: 1.259964
[INFO][09:54:54]: [Client #183] Going to sleep for 3.04 seconds.
[INFO][09:54:54]: [Client #490] Epoch: [1/5][10/15]	Loss: 1.004032
[INFO][09:54:54]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][09:54:54]: [Client #490] Woke up.
[INFO][09:54:55]: [Client #490] Epoch: [2/5][0/15]	Loss: 0.966169
[INFO][09:54:55]: [Client #490] Epoch: [2/5][10/15]	Loss: 0.675351
[INFO][09:54:55]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][09:54:55]: [Client #490] Woke up.
[INFO][09:54:55]: [Client #490] Epoch: [3/5][0/15]	Loss: 0.728300
[INFO][09:54:55]: [Client #490] Epoch: [3/5][10/15]	Loss: 0.563172
[INFO][09:54:55]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][09:54:56]: [Client #490] Woke up.
[INFO][09:54:56]: [Client #490] Epoch: [4/5][0/15]	Loss: 0.437763
[INFO][09:54:56]: [Client #490] Epoch: [4/5][10/15]	Loss: 1.093704
[INFO][09:54:56]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][09:54:56]: [Client #490] Woke up.
[INFO][09:54:56]: [Client #490] Epoch: [5/5][0/15]	Loss: 0.615072
[INFO][09:54:56]: [Client #490] Epoch: [5/5][10/15]	Loss: 0.295944
[INFO][09:54:56]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][09:54:57]: [Client #490] Woke up.
[INFO][09:54:57]: [Client #490] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_490_554853.pth.
[INFO][09:54:57]: [Client #183] Woke up.
[INFO][09:54:57]: [Client #183] Epoch: [2/5][0/16]	Loss: 0.910201
[INFO][09:54:57]: [Client #183] Epoch: [2/5][10/16]	Loss: 1.093702
[INFO][09:54:57]: [Client #183] Going to sleep for 3.04 seconds.
[INFO][09:54:58]: [Client #490] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_490_554853.pth.
[INFO][09:54:58]: [Client #490] Model trained.
[INFO][09:54:58]: [Client #490] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:54:58]: [Server #554754] Received 0.26 MB of payload data from client #490 (simulated).
[INFO][09:55:00]: [Client #183] Woke up.
[INFO][09:55:00]: [Client #183] Epoch: [3/5][0/16]	Loss: 1.238476
[INFO][09:55:00]: [Client #183] Epoch: [3/5][10/16]	Loss: 0.661522
[INFO][09:55:00]: [Client #183] Going to sleep for 3.04 seconds.
[INFO][09:55:03]: [Client #183] Woke up.
[INFO][09:55:03]: [Client #183] Epoch: [4/5][0/16]	Loss: 2.121296
[INFO][09:55:04]: [Client #183] Epoch: [4/5][10/16]	Loss: 0.594664
[INFO][09:55:04]: [Client #183] Going to sleep for 3.04 seconds.
[INFO][09:55:07]: [Client #183] Woke up.
[INFO][09:55:07]: [Client #183] Epoch: [5/5][0/16]	Loss: 0.350152
[INFO][09:55:07]: [Client #183] Epoch: [5/5][10/16]	Loss: 0.981519
[INFO][09:55:07]: [Client #183] Going to sleep for 3.04 seconds.
[INFO][09:55:10]: [Client #183] Woke up.
[INFO][09:55:10]: [Client #183] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_183_554860.pth.
[INFO][09:55:10]: [Client #183] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_183_554860.pth.
[INFO][09:55:10]: [Client #183] Model trained.
[INFO][09:55:10]: [Client #183] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:55:10]: [Server #554754] Received 0.26 MB of payload data from client #183 (simulated).
[INFO][09:55:10]: [Server #554754] Selecting client #388 for training.
[INFO][09:55:10]: [Server #554754] Sending the current model to client #388 (simulated).
[INFO][09:55:10]: [Server #554754] Sending 0.26 MB of payload data to client #388 (simulated).
[INFO][09:55:10]: [Server #554754] Selecting client #278 for training.
[INFO][09:55:10]: [Server #554754] Sending the current model to client #278 (simulated).
[INFO][09:55:10]: [Server #554754] Sending 0.26 MB of payload data to client #278 (simulated).
[INFO][09:55:10]: [Client #278] Selected by the server.
[INFO][09:55:10]: [Client #388] Selected by the server.
[INFO][09:55:10]: [Client #278] Loading its data source...
[INFO][09:55:10]: [Client #388] Loading its data source...
[INFO][09:55:10]: Data source: FEMNIST
[INFO][09:55:10]: Data source: FEMNIST
[INFO][09:55:10]: [Client #388] Dataset size: 163
[INFO][09:55:10]: [Client #388] Sampler: all_inclusive
[INFO][09:55:11]: [Client #388] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:55:11]: [93m[1m[Client #388] Started training in communication round #18.[0m
[INFO][09:55:11]: [Client #278] Dataset size: 196
[INFO][09:55:11]: [Client #278] Sampler: all_inclusive
[INFO][09:55:11]: [Client #278] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:55:11]: [93m[1m[Client #278] Started training in communication round #18.[0m
[INFO][09:55:12]: [Client #388] Loading the dataset.
[INFO][09:55:12]: [Client #278] Loading the dataset.
[INFO][09:55:18]: [Client #278] Epoch: [1/5][0/20]	Loss: 0.586624
[INFO][09:55:18]: [Client #388] Epoch: [1/5][0/17]	Loss: 0.171278
[INFO][09:55:18]: [Client #278] Epoch: [1/5][10/20]	Loss: 1.554623
[INFO][09:55:18]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][09:55:18]: [Client #388] Epoch: [1/5][10/17]	Loss: 0.176470
[INFO][09:55:18]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][09:55:19]: [Client #278] Woke up.
[INFO][09:55:19]: [Client #278] Epoch: [2/5][0/20]	Loss: 1.417234
[INFO][09:55:19]: [Client #278] Epoch: [2/5][10/20]	Loss: 1.611193
[INFO][09:55:19]: [Client #388] Woke up.
[INFO][09:55:19]: [Client #388] Epoch: [2/5][0/17]	Loss: 0.758701
[INFO][09:55:19]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][09:55:19]: [Client #388] Epoch: [2/5][10/17]	Loss: 0.649467
[INFO][09:55:19]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][09:55:20]: [Client #278] Woke up.
[INFO][09:55:20]: [Client #278] Epoch: [3/5][0/20]	Loss: 1.249574
[INFO][09:55:20]: [Client #278] Epoch: [3/5][10/20]	Loss: 0.655514
[INFO][09:55:20]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][09:55:20]: [Client #388] Woke up.
[INFO][09:55:20]: [Client #388] Epoch: [3/5][0/17]	Loss: 1.443272
[INFO][09:55:20]: [Client #388] Epoch: [3/5][10/17]	Loss: 1.233898
[INFO][09:55:20]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][09:55:21]: [Client #278] Woke up.
[INFO][09:55:21]: [Client #278] Epoch: [4/5][0/20]	Loss: 1.181091
[INFO][09:55:21]: [Client #278] Epoch: [4/5][10/20]	Loss: 1.070487
[INFO][09:55:21]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][09:55:21]: [Client #388] Woke up.
[INFO][09:55:21]: [Client #388] Epoch: [4/5][0/17]	Loss: 0.625617
[INFO][09:55:21]: [Client #388] Epoch: [4/5][10/17]	Loss: 0.198876
[INFO][09:55:21]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][09:55:22]: [Client #278] Woke up.
[INFO][09:55:22]: [Client #278] Epoch: [5/5][0/20]	Loss: 1.529201
[INFO][09:55:22]: [Client #278] Epoch: [5/5][10/20]	Loss: 0.514720
[INFO][09:55:22]: [Client #278] Going to sleep for 0.74 seconds.
[INFO][09:55:22]: [Client #388] Woke up.
[INFO][09:55:22]: [Client #388] Epoch: [5/5][0/17]	Loss: 0.443140
[INFO][09:55:22]: [Client #388] Epoch: [5/5][10/17]	Loss: 0.697836
[INFO][09:55:22]: [Client #388] Going to sleep for 0.84 seconds.
[INFO][09:55:23]: [Client #278] Woke up.
[INFO][09:55:23]: [Client #278] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_278_554860.pth.
[INFO][09:55:23]: [Client #388] Woke up.
[INFO][09:55:23]: [Client #388] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_388_554853.pth.
[INFO][09:55:23]: [Client #278] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_278_554860.pth.
[INFO][09:55:23]: [Client #278] Model trained.
[INFO][09:55:23]: [Client #278] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:55:23]: [Server #554754] Received 0.26 MB of payload data from client #278 (simulated).
[INFO][09:55:24]: [Client #388] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_388_554853.pth.
[INFO][09:55:24]: [Client #388] Model trained.
[INFO][09:55:24]: [Client #388] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:55:24]: [Server #554754] Received 0.26 MB of payload data from client #388 (simulated).
[INFO][09:55:24]: [Server #554754] Adding client #192 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #115 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #490 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #278 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #388 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #236 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #176 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #183 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #219 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][09:55:24]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12170883 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12287421 0.         0.         0.         0.
 0.         0.         0.1439302  0.         0.         0.
 0.         0.         0.         0.         0.         0.09762379
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15189451 0.         0.         0.         0.
 0.         0.         0.16147455 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.35138117 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13060911 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09757689 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1147023  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12170883 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12287421 0.         0.         0.         0.
 0.         0.         0.1439302  0.         0.         0.
 0.         0.         0.         0.         0.         0.09762379
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15189451 0.         0.         0.         0.
 0.         0.         0.16147455 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.35138117 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13060911 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09757689 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1147023  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][09:56:11]: [Server #554754] Global model accuracy: 56.15%

[INFO][09:56:11]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_18.pth.
[INFO][09:56:11]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_18.pth.
[INFO][09:56:11]: [93m[1m
[Server #554754] Starting round 19/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.05069552 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.09482257 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.09101124
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.08728324 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.100894
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.10217114 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.002      0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.10631443
 0.07951654 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.04484566 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.002      0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.002      0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.002
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.16878613 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.002      0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  3e-09  5e-10
 7:  6.9057e+00  6.9056e+00  1e-04  4e-09  7e-10
 8:  6.9057e+00  6.9056e+00  8e-05  5e-08  7e-09
 9:  6.9057e+00  6.9056e+00  4e-05  4e-08  7e-09
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  6e-09
Optimal solution found.
The calculated probability is:  [4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.85838380e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.85620711e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.85269676e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.85832123e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 9.75779957e-01 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.84966335e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.79161232e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.84882377e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.85797815e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.85726422e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05 4.86374921e-05
 4.86374921e-05 4.86374921e-05 4.86374921e-05]
current clients pool:  [INFO][09:56:12]: [Server #554754] Selected clients: [212 399 259  16 286  90 316 491 438 227]
[INFO][09:56:12]: [Server #554754] Selecting client #212 for training.
[INFO][09:56:12]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][09:56:12]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][09:56:12]: [Server #554754] Selecting client #399 for training.
[INFO][09:56:12]: [Server #554754] Sending the current model to client #399 (simulated).
[INFO][09:56:12]: [Server #554754] Sending 0.26 MB of payload data to client #399 (simulated).
[INFO][09:56:12]: [Client #212] Selected by the server.
[INFO][09:56:12]: [Client #212] Loading its data source...
[INFO][09:56:12]: Data source: FEMNIST
[INFO][09:56:12]: [Client #399] Selected by the server.
[INFO][09:56:12]: [Client #399] Loading its data source...
[INFO][09:56:12]: Data source: FEMNIST
[INFO][09:56:12]: [Client #212] Dataset size: 160
[INFO][09:56:12]: [Client #212] Sampler: all_inclusive
[INFO][09:56:12]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:56:12]: [93m[1m[Client #212] Started training in communication round #19.[0m
[INFO][09:56:12]: [Client #399] Dataset size: 155
[INFO][09:56:12]: [Client #399] Sampler: all_inclusive
[INFO][09:56:12]: [Client #399] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:56:12]: [93m[1m[Client #399] Started training in communication round #19.[0m
[INFO][09:56:14]: [Client #212] Loading the dataset.
[INFO][09:56:14]: [Client #399] Loading the dataset.
[INFO][09:56:19]: [Client #212] Epoch: [1/5][0/16]	Loss: 2.752684
[INFO][09:56:19]: [Client #399] Epoch: [1/5][0/16]	Loss: 1.409509
[INFO][09:56:19]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.403209
[INFO][09:56:19]: [Client #399] Epoch: [1/5][10/16]	Loss: 0.204781
[INFO][09:56:20]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:56:20]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][09:56:21]: [Client #399] Woke up.
[INFO][09:56:21]: [Client #399] Epoch: [2/5][0/16]	Loss: 0.148872
[INFO][09:56:21]: [Client #399] Epoch: [2/5][10/16]	Loss: 0.580065
[INFO][09:56:21]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][09:56:22]: [Client #399] Woke up.
[INFO][09:56:22]: [Client #399] Epoch: [3/5][0/16]	Loss: 0.746461
[INFO][09:56:22]: [Client #399] Epoch: [3/5][10/16]	Loss: 0.882783
[INFO][09:56:22]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][09:56:23]: [Client #399] Woke up.
[INFO][09:56:23]: [Client #399] Epoch: [4/5][0/16]	Loss: 1.030374
[INFO][09:56:23]: [Client #399] Epoch: [4/5][10/16]	Loss: 1.122230
[INFO][09:56:23]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][09:56:24]: [Client #399] Woke up.
[INFO][09:56:24]: [Client #399] Epoch: [5/5][0/16]	Loss: 1.815905
[INFO][09:56:24]: [Client #399] Epoch: [5/5][10/16]	Loss: 0.484497
[INFO][09:56:24]: [Client #399] Going to sleep for 1.05 seconds.
[INFO][09:56:25]: [Client #399] Woke up.
[INFO][09:56:25]: [Client #399] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_399_554860.pth.
[INFO][09:56:26]: [Client #399] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_399_554860.pth.
[INFO][09:56:26]: [Client #399] Model trained.
[INFO][09:56:26]: [Client #399] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:56:26]: [Server #554754] Received 0.26 MB of payload data from client #399 (simulated).
[INFO][09:56:46]: [Client #212] Woke up.
[INFO][09:56:46]: [Client #212] Epoch: [2/5][0/16]	Loss: 1.056227
[INFO][09:56:46]: [Client #212] Epoch: [2/5][10/16]	Loss: 2.344098
[INFO][09:56:46]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:57:12]: [Client #212] Woke up.
[INFO][09:57:12]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.422894
[INFO][09:57:12]: [Client #212] Epoch: [3/5][10/16]	Loss: 1.292193
[INFO][09:57:12]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:57:39]: [Client #212] Woke up.
[INFO][09:57:39]: [Client #212] Epoch: [4/5][0/16]	Loss: 1.338265
[INFO][09:57:39]: [Client #212] Epoch: [4/5][10/16]	Loss: 0.921339
[INFO][09:57:39]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:58:05]: [Client #212] Woke up.
[INFO][09:58:05]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.510357
[INFO][09:58:05]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.888868
[INFO][09:58:05]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][09:58:32]: [Client #212] Woke up.
[INFO][09:58:32]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][09:58:32]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][09:58:32]: [Client #212] Model trained.
[INFO][09:58:32]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:58:32]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][09:58:32]: [Server #554754] Selecting client #259 for training.
[INFO][09:58:32]: [Server #554754] Sending the current model to client #259 (simulated).
[INFO][09:58:32]: [Server #554754] Sending 0.26 MB of payload data to client #259 (simulated).
[INFO][09:58:32]: [Server #554754] Selecting client #16 for training.
[INFO][09:58:32]: [Server #554754] Sending the current model to client #16 (simulated).
[INFO][09:58:32]: [Server #554754] Sending 0.26 MB of payload data to client #16 (simulated).
[INFO][09:58:32]: [Client #259] Selected by the server.
[INFO][09:58:32]: [Client #259] Loading its data source...
[INFO][09:58:32]: Data source: FEMNIST
[INFO][09:58:32]: [Client #16] Selected by the server.
[INFO][09:58:32]: [Client #16] Loading its data source...
[INFO][09:58:32]: Data source: FEMNIST
[INFO][09:58:33]: [Client #259] Dataset size: 125
[INFO][09:58:33]: [Client #259] Sampler: all_inclusive
[INFO][09:58:33]: [Client #259] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:58:33]: [Client #16] Dataset size: 164
[INFO][09:58:33]: [Client #16] Sampler: all_inclusive
[INFO][09:58:33]: [Client #16] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:58:33]: [93m[1m[Client #16] Started training in communication round #19.[0m
[INFO][09:58:33]: [93m[1m[Client #259] Started training in communication round #19.[0m
[INFO][09:58:34]: [Client #259] Loading the dataset.
[INFO][09:58:34]: [Client #16] Loading the dataset.
[INFO][09:58:40]: [Client #259] Epoch: [1/5][0/13]	Loss: 1.324362
[INFO][09:58:40]: [Client #16] Epoch: [1/5][0/17]	Loss: 1.014045
[INFO][09:58:40]: [Client #259] Epoch: [1/5][10/13]	Loss: 1.766810
[INFO][09:58:40]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][09:58:40]: [Client #16] Epoch: [1/5][10/17]	Loss: 0.853190
[INFO][09:58:40]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][09:58:40]: [Client #259] Woke up.
[INFO][09:58:40]: [Client #259] Epoch: [2/5][0/13]	Loss: 1.803733
[INFO][09:58:41]: [Client #259] Epoch: [2/5][10/13]	Loss: 1.403369
[INFO][09:58:41]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][09:58:41]: [Client #259] Woke up.
[INFO][09:58:41]: [Client #259] Epoch: [3/5][0/13]	Loss: 0.714008
[INFO][09:58:41]: [Client #259] Epoch: [3/5][10/13]	Loss: 0.271384
[INFO][09:58:41]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][09:58:41]: [Client #259] Woke up.
[INFO][09:58:42]: [Client #259] Epoch: [4/5][0/13]	Loss: 0.658072
[INFO][09:58:42]: [Client #259] Epoch: [4/5][10/13]	Loss: 1.291900
[INFO][09:58:42]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][09:58:42]: [Client #259] Woke up.
[INFO][09:58:42]: [Client #259] Epoch: [5/5][0/13]	Loss: 0.282143
[INFO][09:58:42]: [Client #259] Epoch: [5/5][10/13]	Loss: 0.938858
[INFO][09:58:42]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][09:58:42]: [Client #16] Woke up.
[INFO][09:58:42]: [Client #16] Epoch: [2/5][0/17]	Loss: 0.399412
[INFO][09:58:42]: [Client #16] Epoch: [2/5][10/17]	Loss: 0.554195
[INFO][09:58:42]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][09:58:43]: [Client #259] Woke up.
[INFO][09:58:43]: [Client #259] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][09:58:43]: [Client #259] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][09:58:43]: [Client #259] Model trained.
[INFO][09:58:43]: [Client #259] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:58:43]: [Server #554754] Received 0.26 MB of payload data from client #259 (simulated).
[INFO][09:58:44]: [Client #16] Woke up.
[INFO][09:58:44]: [Client #16] Epoch: [3/5][0/17]	Loss: 0.594990
[INFO][09:58:45]: [Client #16] Epoch: [3/5][10/17]	Loss: 0.277694
[INFO][09:58:45]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][09:58:47]: [Client #16] Woke up.
[INFO][09:58:47]: [Client #16] Epoch: [4/5][0/17]	Loss: 0.777125
[INFO][09:58:47]: [Client #16] Epoch: [4/5][10/17]	Loss: 0.771318
[INFO][09:58:47]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][09:58:49]: [Client #16] Woke up.
[INFO][09:58:49]: [Client #16] Epoch: [5/5][0/17]	Loss: 0.527863
[INFO][09:58:49]: [Client #16] Epoch: [5/5][10/17]	Loss: 1.214448
[INFO][09:58:49]: [Client #16] Going to sleep for 2.03 seconds.
[INFO][09:58:51]: [Client #16] Woke up.
[INFO][09:58:51]: [Client #16] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_554860.pth.
[INFO][09:58:52]: [Client #16] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_16_554860.pth.
[INFO][09:58:52]: [Client #16] Model trained.
[INFO][09:58:52]: [Client #16] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:58:52]: [Server #554754] Received 0.26 MB of payload data from client #16 (simulated).
[INFO][09:58:52]: [Server #554754] Selecting client #286 for training.
[INFO][09:58:52]: [Server #554754] Sending the current model to client #286 (simulated).
[INFO][09:58:52]: [Server #554754] Sending 0.26 MB of payload data to client #286 (simulated).
[INFO][09:58:52]: [Server #554754] Selecting client #90 for training.
[INFO][09:58:52]: [Server #554754] Sending the current model to client #90 (simulated).
[INFO][09:58:52]: [Server #554754] Sending 0.26 MB of payload data to client #90 (simulated).
[INFO][09:58:52]: [Client #286] Selected by the server.
[INFO][09:58:52]: [Client #90] Selected by the server.
[INFO][09:58:52]: [Client #286] Loading its data source...
[INFO][09:58:52]: [Client #90] Loading its data source...
[INFO][09:58:52]: Data source: FEMNIST
[INFO][09:58:52]: Data source: FEMNIST
[INFO][09:58:52]: [Client #286] Dataset size: 154
[INFO][09:58:52]: [Client #286] Sampler: all_inclusive
[INFO][09:58:52]: [Client #90] Dataset size: 162
[INFO][09:58:52]: [Client #90] Sampler: all_inclusive
[INFO][09:58:52]: [Client #286] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:58:52]: [Client #90] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:58:52]: [93m[1m[Client #286] Started training in communication round #19.[0m
[INFO][09:58:52]: [93m[1m[Client #90] Started training in communication round #19.[0m
[INFO][09:58:54]: [Client #90] Loading the dataset.
[INFO][09:58:54]: [Client #286] Loading the dataset.
[INFO][09:58:59]: [Client #90] Epoch: [1/5][0/17]	Loss: 1.412304
[INFO][09:58:59]: [Client #286] Epoch: [1/5][0/16]	Loss: 0.726140
[INFO][09:58:59]: [Client #286] Epoch: [1/5][10/16]	Loss: 1.113779
[INFO][09:58:59]: [Client #90] Epoch: [1/5][10/17]	Loss: 0.528911
[INFO][09:58:59]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:58:59]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][09:59:01]: [Client #90] Woke up.
[INFO][09:59:01]: [Client #90] Epoch: [2/5][0/17]	Loss: 0.521560
[INFO][09:59:01]: [Client #90] Epoch: [2/5][10/17]	Loss: 1.877008
[INFO][09:59:01]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][09:59:03]: [Client #90] Woke up.
[INFO][09:59:03]: [Client #90] Epoch: [3/5][0/17]	Loss: 1.542435
[INFO][09:59:03]: [Client #90] Epoch: [3/5][10/17]	Loss: 1.369777
[INFO][09:59:03]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][09:59:05]: [Client #90] Woke up.
[INFO][09:59:05]: [Client #90] Epoch: [4/5][0/17]	Loss: 0.854524
[INFO][09:59:05]: [Client #90] Epoch: [4/5][10/17]	Loss: 1.515141
[INFO][09:59:05]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][09:59:05]: [Client #286] Woke up.
[INFO][09:59:05]: [Client #286] Epoch: [2/5][0/16]	Loss: 0.145575
[INFO][09:59:05]: [Client #286] Epoch: [2/5][10/16]	Loss: 0.277520
[INFO][09:59:05]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:59:06]: [Client #90] Woke up.
[INFO][09:59:06]: [Client #90] Epoch: [5/5][0/17]	Loss: 1.100183
[INFO][09:59:07]: [Client #90] Epoch: [5/5][10/17]	Loss: 0.956044
[INFO][09:59:07]: [Client #90] Going to sleep for 1.64 seconds.
[INFO][09:59:08]: [Client #90] Woke up.
[INFO][09:59:08]: [Client #90] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_90_554860.pth.
[INFO][09:59:09]: [Client #90] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_90_554860.pth.
[INFO][09:59:09]: [Client #90] Model trained.
[INFO][09:59:09]: [Client #90] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:59:09]: [Server #554754] Received 0.26 MB of payload data from client #90 (simulated).
[INFO][09:59:11]: [Client #286] Woke up.
[INFO][09:59:11]: [Client #286] Epoch: [3/5][0/16]	Loss: 0.153934
[INFO][09:59:11]: [Client #286] Epoch: [3/5][10/16]	Loss: 0.701860
[INFO][09:59:12]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:59:17]: [Client #286] Woke up.
[INFO][09:59:17]: [Client #286] Epoch: [4/5][0/16]	Loss: 0.715033
[INFO][09:59:18]: [Client #286] Epoch: [4/5][10/16]	Loss: 1.017343
[INFO][09:59:18]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:59:23]: [Client #286] Woke up.
[INFO][09:59:23]: [Client #286] Epoch: [5/5][0/16]	Loss: 0.351919
[INFO][09:59:24]: [Client #286] Epoch: [5/5][10/16]	Loss: 0.529103
[INFO][09:59:24]: [Client #286] Going to sleep for 5.89 seconds.
[INFO][09:59:30]: [Client #286] Woke up.
[INFO][09:59:30]: [Client #286] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554853.pth.
[INFO][09:59:30]: [Client #286] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_286_554853.pth.
[INFO][09:59:30]: [Client #286] Model trained.
[INFO][09:59:30]: [Client #286] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:59:30]: [Server #554754] Received 0.26 MB of payload data from client #286 (simulated).
[INFO][09:59:30]: [Server #554754] Selecting client #316 for training.
[INFO][09:59:30]: [Server #554754] Sending the current model to client #316 (simulated).
[INFO][09:59:30]: [Server #554754] Sending 0.26 MB of payload data to client #316 (simulated).
[INFO][09:59:30]: [Server #554754] Selecting client #491 for training.
[INFO][09:59:30]: [Server #554754] Sending the current model to client #491 (simulated).
[INFO][09:59:30]: [Server #554754] Sending 0.26 MB of payload data to client #491 (simulated).
[INFO][09:59:30]: [Client #316] Selected by the server.
[INFO][09:59:30]: [Client #316] Loading its data source...
[INFO][09:59:30]: Data source: FEMNIST
[INFO][09:59:30]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][09:59:30]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/316.zip.
[INFO][09:59:30]: [Client #491] Selected by the server.
[INFO][09:59:30]: [Client #491] Loading its data source...
[INFO][09:59:30]: Data source: FEMNIST
[INFO][09:59:30]: [Client #491] Dataset size: 162
[INFO][09:59:30]: [Client #491] Sampler: all_inclusive
[INFO][09:59:30]: [Client #491] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:59:30]: [93m[1m[Client #491] Started training in communication round #19.[0m

2.6%
5.3%
7.9%
10.6%
13.2%
15.8%
18.5%
21.1%
23.8%
26.4%
29.1%
31.7%
34.3%
37.0%
39.6%
42.3%
44.9%
47.5%
50.2%
52.8%
55.5%
58.1%
60.7%
63.4%
66.0%
68.7%
71.3%
74.0%
76.6%
79.2%
81.9%
84.5%
87.2%
89.8%
92.4%
95.1%
97.7%
100.0%[INFO][09:59:30]: Decompressing the dataset downloaded.
[INFO][09:59:30]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/316.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][09:59:30]: [Client #316] Dataset size: 153
[INFO][09:59:30]: [Client #316] Sampler: all_inclusive
[INFO][09:59:30]: [Client #316] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:59:30]: [93m[1m[Client #316] Started training in communication round #19.[0m

[INFO][09:59:32]: [Client #491] Loading the dataset.
[INFO][09:59:32]: [Client #316] Loading the dataset.
[INFO][09:59:38]: [Client #491] Epoch: [1/5][0/17]	Loss: 1.326451
[INFO][09:59:38]: [Client #316] Epoch: [1/5][0/16]	Loss: 0.338790
[INFO][09:59:38]: [Client #491] Epoch: [1/5][10/17]	Loss: 1.670819
[INFO][09:59:38]: [Client #316] Epoch: [1/5][10/16]	Loss: 0.685866
[INFO][09:59:38]: [Client #491] Going to sleep for 1.07 seconds.
[INFO][09:59:38]: [Client #316] Going to sleep for 1.00 seconds.
[INFO][09:59:39]: [Client #316] Woke up.
[INFO][09:59:39]: [Client #316] Epoch: [2/5][0/16]	Loss: 0.675914
[INFO][09:59:39]: [Client #491] Woke up.
[INFO][09:59:39]: [Client #491] Epoch: [2/5][0/17]	Loss: 0.654040
[INFO][09:59:39]: [Client #316] Epoch: [2/5][10/16]	Loss: 0.877570
[INFO][09:59:39]: [Client #491] Epoch: [2/5][10/17]	Loss: 0.595855
[INFO][09:59:39]: [Client #316] Going to sleep for 1.00 seconds.
[INFO][09:59:39]: [Client #491] Going to sleep for 1.07 seconds.
[INFO][09:59:40]: [Client #316] Woke up.
[INFO][09:59:40]: [Client #316] Epoch: [3/5][0/16]	Loss: 1.804424
[INFO][09:59:40]: [Client #491] Woke up.
[INFO][09:59:40]: [Client #491] Epoch: [3/5][0/17]	Loss: 0.721387
[INFO][09:59:40]: [Client #316] Epoch: [3/5][10/16]	Loss: 0.351325
[INFO][09:59:40]: [Client #316] Going to sleep for 1.00 seconds.
[INFO][09:59:40]: [Client #491] Epoch: [3/5][10/17]	Loss: 0.615714
[INFO][09:59:40]: [Client #491] Going to sleep for 1.07 seconds.
[INFO][09:59:41]: [Client #316] Woke up.
[INFO][09:59:41]: [Client #316] Epoch: [4/5][0/16]	Loss: 0.116115
[INFO][09:59:41]: [Client #316] Epoch: [4/5][10/16]	Loss: 0.861331
[INFO][09:59:41]: [Client #316] Going to sleep for 1.00 seconds.
[INFO][09:59:41]: [Client #491] Woke up.
[INFO][09:59:41]: [Client #491] Epoch: [4/5][0/17]	Loss: 1.480537
[INFO][09:59:41]: [Client #491] Epoch: [4/5][10/17]	Loss: 0.473203
[INFO][09:59:41]: [Client #491] Going to sleep for 1.07 seconds.
[INFO][09:59:42]: [Client #316] Woke up.
[INFO][09:59:42]: [Client #316] Epoch: [5/5][0/16]	Loss: 0.506788
[INFO][09:59:42]: [Client #316] Epoch: [5/5][10/16]	Loss: 1.506500
[INFO][09:59:42]: [Client #316] Going to sleep for 1.00 seconds.
[INFO][09:59:42]: [Client #491] Woke up.
[INFO][09:59:42]: [Client #491] Epoch: [5/5][0/17]	Loss: 0.433195
[INFO][09:59:43]: [Client #491] Epoch: [5/5][10/17]	Loss: 1.406369
[INFO][09:59:43]: [Client #491] Going to sleep for 1.07 seconds.
[INFO][09:59:43]: [Client #316] Woke up.
[INFO][09:59:43]: [Client #316] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_316_554853.pth.
[INFO][09:59:44]: [Client #491] Woke up.
[INFO][09:59:44]: [Client #491] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_491_554860.pth.
[INFO][09:59:44]: [Client #316] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_316_554853.pth.
[INFO][09:59:44]: [Client #316] Model trained.
[INFO][09:59:44]: [Client #316] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:59:44]: [Server #554754] Received 0.26 MB of payload data from client #316 (simulated).
[INFO][09:59:44]: [Client #491] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_491_554860.pth.
[INFO][09:59:44]: [Client #491] Model trained.
[INFO][09:59:44]: [Client #491] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:59:44]: [Server #554754] Received 0.26 MB of payload data from client #491 (simulated).
[INFO][09:59:44]: [Server #554754] Selecting client #438 for training.
[INFO][09:59:44]: [Server #554754] Sending the current model to client #438 (simulated).
[INFO][09:59:44]: [Server #554754] Sending 0.26 MB of payload data to client #438 (simulated).
[INFO][09:59:44]: [Server #554754] Selecting client #227 for training.
[INFO][09:59:44]: [Server #554754] Sending the current model to client #227 (simulated).
[INFO][09:59:44]: [Server #554754] Sending 0.26 MB of payload data to client #227 (simulated).
[INFO][09:59:44]: [Client #227] Selected by the server.
[INFO][09:59:44]: [Client #438] Selected by the server.
[INFO][09:59:44]: [Client #227] Loading its data source...
[INFO][09:59:44]: [Client #438] Loading its data source...
[INFO][09:59:44]: Data source: FEMNIST
[INFO][09:59:44]: Data source: FEMNIST
[INFO][09:59:44]: [Client #438] Dataset size: 164
[INFO][09:59:44]: [Client #438] Sampler: all_inclusive
[INFO][09:59:44]: [Client #438] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:59:44]: [93m[1m[Client #438] Started training in communication round #19.[0m
[INFO][09:59:44]: [Client #227] Dataset size: 154
[INFO][09:59:44]: [Client #227] Sampler: all_inclusive
[INFO][09:59:44]: [Client #227] Received 0.26 MB of payload data from the server (simulated).
[INFO][09:59:44]: [93m[1m[Client #227] Started training in communication round #19.[0m
[INFO][09:59:46]: [Client #438] Loading the dataset.
[INFO][09:59:46]: [Client #227] Loading the dataset.
[INFO][09:59:52]: [Client #227] Epoch: [1/5][0/16]	Loss: 0.270179
[INFO][09:59:52]: [Client #438] Epoch: [1/5][0/17]	Loss: 0.933516
[INFO][09:59:52]: [Client #227] Epoch: [1/5][10/16]	Loss: 0.133898
[INFO][09:59:52]: [Client #438] Epoch: [1/5][10/17]	Loss: 0.511189
[INFO][09:59:52]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][09:59:52]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][09:59:52]: [Client #438] Woke up.
[INFO][09:59:52]: [Client #438] Epoch: [2/5][0/17]	Loss: 0.240069
[INFO][09:59:52]: [Client #438] Epoch: [2/5][10/17]	Loss: 0.506732
[INFO][09:59:52]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][09:59:52]: [Client #438] Woke up.
[INFO][09:59:52]: [Client #438] Epoch: [3/5][0/17]	Loss: 0.121608
[INFO][09:59:52]: [Client #438] Epoch: [3/5][10/17]	Loss: 0.334785
[INFO][09:59:52]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][09:59:53]: [Client #438] Woke up.
[INFO][09:59:53]: [Client #438] Epoch: [4/5][0/17]	Loss: 0.448334
[INFO][09:59:53]: [Client #438] Epoch: [4/5][10/17]	Loss: 0.639147
[INFO][09:59:53]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][09:59:53]: [Client #438] Woke up.
[INFO][09:59:53]: [Client #438] Epoch: [5/5][0/17]	Loss: 0.602915
[INFO][09:59:53]: [Client #438] Epoch: [5/5][10/17]	Loss: 0.757837
[INFO][09:59:53]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][09:59:53]: [Client #438] Woke up.
[INFO][09:59:53]: [Client #438] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_438_554853.pth.
[INFO][09:59:53]: [Client #227] Woke up.
[INFO][09:59:53]: [Client #227] Epoch: [2/5][0/16]	Loss: 0.259288
[INFO][09:59:54]: [Client #227] Epoch: [2/5][10/16]	Loss: 0.812662
[INFO][09:59:54]: [Client #438] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_438_554853.pth.
[INFO][09:59:54]: [Client #438] Model trained.
[INFO][09:59:54]: [Client #438] Sent 0.26 MB of payload data to the server (simulated).
[INFO][09:59:54]: [Server #554754] Received 0.26 MB of payload data from client #438 (simulated).
[INFO][09:59:54]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][09:59:55]: [Client #227] Woke up.
[INFO][09:59:55]: [Client #227] Epoch: [3/5][0/16]	Loss: 0.389119
[INFO][09:59:55]: [Client #227] Epoch: [3/5][10/16]	Loss: 0.161907
[INFO][09:59:55]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][09:59:57]: [Client #227] Woke up.
[INFO][09:59:57]: [Client #227] Epoch: [4/5][0/16]	Loss: 0.341185
[INFO][09:59:57]: [Client #227] Epoch: [4/5][10/16]	Loss: 0.119597
[INFO][09:59:57]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][09:59:58]: [Client #227] Woke up.
[INFO][09:59:58]: [Client #227] Epoch: [5/5][0/16]	Loss: 0.249136
[INFO][09:59:58]: [Client #227] Epoch: [5/5][10/16]	Loss: 1.088163
[INFO][09:59:58]: [Client #227] Going to sleep for 1.39 seconds.
[INFO][10:00:00]: [Client #227] Woke up.
[INFO][10:00:00]: [Client #227] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_227_554860.pth.
[INFO][10:00:00]: [Client #227] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_227_554860.pth.
[INFO][10:00:00]: [Client #227] Model trained.
[INFO][10:00:00]: [Client #227] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:00:00]: [Server #554754] Received 0.26 MB of payload data from client #227 (simulated).
[INFO][10:00:00]: [Server #554754] Adding client #438 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #259 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #316 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #399 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #491 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #227 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #90 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #16 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #286 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][10:00:00]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07441497 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.37847476
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14348346 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07788854 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11689533 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13358376 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14989731 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1005381  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06361692
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24386947 0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07441497 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.37847476
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14348346 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07788854 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11689533 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.13358376 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14989731 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1005381  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06361692
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24386947 0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:00:44]: [Server #554754] Global model accuracy: 58.60%

[INFO][10:00:44]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_19.pth.
[INFO][10:00:44]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_19.pth.
[INFO][10:00:44]: [93m[1m
[Server #554754] Starting round 20/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.002      0.002      0.002      0.10621762 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.002      0.002
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.09482257 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.08247423 0.05058366 0.002      0.04920213 0.002      0.002
 0.04912068 0.09779793 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.100894
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.0837897  0.002      0.05007728 0.002      0.002      0.002
 0.002      0.10217114 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.002      0.002      0.002      0.002      0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.10621762
 0.002      0.002      0.002      0.002      0.04972711 0.002
 0.16878613 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  3e-09  4e-10
 7:  6.9057e+00  6.9056e+00  1e-04  4e-09  5e-10
 8:  6.9057e+00  6.9056e+00  7e-05  4e-08  6e-09
 9:  6.9057e+00  6.9056e+00  4e-05  4e-08  6e-09
10:  6.9056e+00  6.9056e+00  3e-06  3e-08  5e-09
Optimal solution found.
The calculated probability is:  [5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11019195e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.01975620e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 9.74534154e-01
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11032080e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.10854928e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.10322095e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.10061294e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.10780330e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11121228e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.07448546e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05 5.11398462e-05
 5.11398462e-05 5.11398462e-05 5.11398462e-05]
current clients pool:  [INFO][10:00:45]: [Server #554754] Selected clients: [152 444 265 205 134  36 210  13 146 253]
[INFO][10:00:45]: [Server #554754] Selecting client #152 for training.
[INFO][10:00:45]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][10:00:45]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][10:00:45]: [Server #554754] Selecting client #444 for training.
[INFO][10:00:45]: [Server #554754] Sending the current model to client #444 (simulated).
[INFO][10:00:45]: [Server #554754] Sending 0.26 MB of payload data to client #444 (simulated).
[INFO][10:00:45]: [Client #152] Selected by the server.
[INFO][10:00:45]: [Client #152] Loading its data source...
[INFO][10:00:45]: Data source: FEMNIST
[INFO][10:00:45]: [Client #444] Selected by the server.
[INFO][10:00:45]: [Client #444] Loading its data source...
[INFO][10:00:45]: Data source: FEMNIST
[INFO][10:00:45]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:00:45]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/444.zip.
[INFO][10:00:45]: [Client #152] Dataset size: 151
[INFO][10:00:45]: [Client #152] Sampler: all_inclusive
[INFO][10:00:45]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:00:45]: [93m[1m[Client #152] Started training in communication round #20.[0m

1.4%
2.8%
4.2%
5.7%
7.1%
8.5%
9.9%
11.3%
12.7%
14.2%
15.6%
17.0%
18.4%
19.8%
21.2%
22.7%
24.1%
25.5%
26.9%
28.3%
29.7%
31.1%
32.6%
34.0%
35.4%
36.8%
38.2%
39.6%
41.1%
42.5%
43.9%
45.3%
46.7%
48.1%
49.6%
51.0%
52.4%
53.8%
55.2%
56.6%
58.0%
59.5%
60.9%
62.3%
63.7%
65.1%
66.5%
68.0%
69.4%
70.8%
72.2%
73.6%
75.0%
76.4%
77.9%
79.3%
80.7%
82.1%
83.5%
84.9%
86.4%
87.8%
89.2%
90.6%
92.0%
93.4%
94.9%
96.3%
97.7%
99.1%
100.0%[INFO][10:00:45]: Decompressing the dataset downloaded.
[INFO][10:00:45]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/444.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:00:45]: [Client #444] Dataset size: 274
[INFO][10:00:45]: [Client #444] Sampler: all_inclusive
[INFO][10:00:45]: [Client #444] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:00:45]: [93m[1m[Client #444] Started training in communication round #20.[0m

[INFO][10:00:47]: [Client #152] Loading the dataset.
[INFO][10:00:47]: [Client #444] Loading the dataset.
[INFO][10:00:52]: [Client #152] Epoch: [1/5][0/16]	Loss: 1.705383
[INFO][10:00:52]: [Client #444] Epoch: [1/5][0/28]	Loss: 1.569651
[INFO][10:00:52]: [Client #152] Epoch: [1/5][10/16]	Loss: 0.836847
[INFO][10:00:52]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:00:53]: [Client #444] Epoch: [1/5][10/28]	Loss: 0.742695
[INFO][10:00:53]: [Client #444] Epoch: [1/5][20/28]	Loss: 0.843168
[INFO][10:00:53]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][10:00:53]: [Client #444] Woke up.
[INFO][10:00:53]: [Client #444] Epoch: [2/5][0/28]	Loss: 0.275145
[INFO][10:00:53]: [Client #444] Epoch: [2/5][10/28]	Loss: 0.580080
[INFO][10:00:53]: [Client #444] Epoch: [2/5][20/28]	Loss: 0.629536
[INFO][10:00:53]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][10:00:53]: [Client #444] Woke up.
[INFO][10:00:53]: [Client #444] Epoch: [3/5][0/28]	Loss: 1.010364
[INFO][10:00:53]: [Client #444] Epoch: [3/5][10/28]	Loss: 0.714062
[INFO][10:00:53]: [Client #444] Epoch: [3/5][20/28]	Loss: 0.968211
[INFO][10:00:53]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][10:00:53]: [Client #444] Woke up.
[INFO][10:00:53]: [Client #444] Epoch: [4/5][0/28]	Loss: 0.456901
[INFO][10:00:53]: [Client #444] Epoch: [4/5][10/28]	Loss: 0.757030
[INFO][10:00:53]: [Client #444] Epoch: [4/5][20/28]	Loss: 1.173123
[INFO][10:00:53]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][10:00:53]: [Client #444] Woke up.
[INFO][10:00:53]: [Client #444] Epoch: [5/5][0/28]	Loss: 0.841740
[INFO][10:00:53]: [Client #444] Epoch: [5/5][10/28]	Loss: 0.964160
[INFO][10:00:53]: [Client #444] Epoch: [5/5][20/28]	Loss: 0.432330
[INFO][10:00:54]: [Client #444] Going to sleep for 0.00 seconds.
[INFO][10:00:54]: [Client #444] Woke up.
[INFO][10:00:54]: [Client #444] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_444_554860.pth.
[INFO][10:00:54]: [Client #444] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_444_554860.pth.
[INFO][10:00:54]: [Client #444] Model trained.
[INFO][10:00:54]: [Client #444] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:00:54]: [Server #554754] Received 0.26 MB of payload data from client #444 (simulated).
[INFO][10:01:22]: [Client #152] Woke up.
[INFO][10:01:22]: [Client #152] Epoch: [2/5][0/16]	Loss: 0.950266
[INFO][10:01:22]: [Client #152] Epoch: [2/5][10/16]	Loss: 0.757428
[INFO][10:01:22]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:01:52]: [Client #152] Woke up.
[INFO][10:01:52]: [Client #152] Epoch: [3/5][0/16]	Loss: 0.868323
[INFO][10:01:52]: [Client #152] Epoch: [3/5][10/16]	Loss: 1.109833
[INFO][10:01:52]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:02:22]: [Client #152] Woke up.
[INFO][10:02:22]: [Client #152] Epoch: [4/5][0/16]	Loss: 1.217786
[INFO][10:02:22]: [Client #152] Epoch: [4/5][10/16]	Loss: 0.417667
[INFO][10:02:22]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:02:52]: [Client #152] Woke up.
[INFO][10:02:52]: [Client #152] Epoch: [5/5][0/16]	Loss: 0.447599
[INFO][10:02:52]: [Client #152] Epoch: [5/5][10/16]	Loss: 1.107867
[INFO][10:02:52]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:03:21]: [Client #152] Woke up.
[INFO][10:03:22]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:03:22]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:03:22]: [Client #152] Model trained.
[INFO][10:03:22]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:03:22]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][10:03:22]: [Server #554754] Selecting client #265 for training.
[INFO][10:03:22]: [Server #554754] Sending the current model to client #265 (simulated).
[INFO][10:03:22]: [Server #554754] Sending 0.26 MB of payload data to client #265 (simulated).
[INFO][10:03:22]: [Server #554754] Selecting client #205 for training.
[INFO][10:03:22]: [Server #554754] Sending the current model to client #205 (simulated).
[INFO][10:03:22]: [Server #554754] Sending 0.26 MB of payload data to client #205 (simulated).
[INFO][10:03:22]: [Client #265] Selected by the server.
[INFO][10:03:22]: [Client #265] Loading its data source...
[INFO][10:03:22]: Data source: FEMNIST
[INFO][10:03:22]: [Client #205] Selected by the server.
[INFO][10:03:22]: [Client #205] Loading its data source...
[INFO][10:03:22]: Data source: FEMNIST
[INFO][10:03:22]: [Client #265] Dataset size: 153
[INFO][10:03:22]: [Client #265] Sampler: all_inclusive
[INFO][10:03:22]: [Client #205] Dataset size: 153
[INFO][10:03:22]: [Client #205] Sampler: all_inclusive
[INFO][10:03:22]: [Client #265] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:03:22]: [Client #205] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:03:22]: [93m[1m[Client #265] Started training in communication round #20.[0m
[INFO][10:03:22]: [93m[1m[Client #205] Started training in communication round #20.[0m
[INFO][10:03:24]: [Client #205] Loading the dataset.
[INFO][10:03:24]: [Client #265] Loading the dataset.
[INFO][10:03:30]: [Client #265] Epoch: [1/5][0/16]	Loss: 1.338942
[INFO][10:03:30]: [Client #205] Epoch: [1/5][0/16]	Loss: 0.942479
[INFO][10:03:30]: [Client #265] Epoch: [1/5][10/16]	Loss: 0.637970
[INFO][10:03:30]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:03:30]: [Client #205] Epoch: [1/5][10/16]	Loss: 1.624912
[INFO][10:03:30]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][10:03:31]: [Client #205] Woke up.
[INFO][10:03:31]: [Client #205] Epoch: [2/5][0/16]	Loss: 1.280008
[INFO][10:03:31]: [Client #205] Epoch: [2/5][10/16]	Loss: 1.447626
[INFO][10:03:31]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][10:03:31]: [Client #205] Woke up.
[INFO][10:03:31]: [Client #205] Epoch: [3/5][0/16]	Loss: 0.967936
[INFO][10:03:31]: [Client #205] Epoch: [3/5][10/16]	Loss: 0.821102
[INFO][10:03:31]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][10:03:32]: [Client #205] Woke up.
[INFO][10:03:32]: [Client #205] Epoch: [4/5][0/16]	Loss: 0.542575
[INFO][10:03:32]: [Client #205] Epoch: [4/5][10/16]	Loss: 1.242932
[INFO][10:03:32]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][10:03:33]: [Client #205] Woke up.
[INFO][10:03:33]: [Client #205] Epoch: [5/5][0/16]	Loss: 0.698756
[INFO][10:03:33]: [Client #205] Epoch: [5/5][10/16]	Loss: 1.106800
[INFO][10:03:33]: [Client #205] Going to sleep for 0.64 seconds.
[INFO][10:03:34]: [Client #205] Woke up.
[INFO][10:03:34]: [Client #205] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_205_554860.pth.
[INFO][10:03:34]: [Client #205] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_205_554860.pth.
[INFO][10:03:34]: [Client #205] Model trained.
[INFO][10:03:34]: [Client #205] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:03:34]: [Server #554754] Received 0.26 MB of payload data from client #205 (simulated).
[INFO][10:03:36]: [Client #265] Woke up.
[INFO][10:03:36]: [Client #265] Epoch: [2/5][0/16]	Loss: 1.349568
[INFO][10:03:36]: [Client #265] Epoch: [2/5][10/16]	Loss: 0.708787
[INFO][10:03:36]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:03:43]: [Client #265] Woke up.
[INFO][10:03:43]: [Client #265] Epoch: [3/5][0/16]	Loss: 0.765733
[INFO][10:03:43]: [Client #265] Epoch: [3/5][10/16]	Loss: 1.225127
[INFO][10:03:43]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:03:49]: [Client #265] Woke up.
[INFO][10:03:49]: [Client #265] Epoch: [4/5][0/16]	Loss: 1.157615
[INFO][10:03:49]: [Client #265] Epoch: [4/5][10/16]	Loss: 0.812096
[INFO][10:03:49]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:03:56]: [Client #265] Woke up.
[INFO][10:03:56]: [Client #265] Epoch: [5/5][0/16]	Loss: 1.223399
[INFO][10:03:56]: [Client #265] Epoch: [5/5][10/16]	Loss: 0.238538
[INFO][10:03:56]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:04:02]: [Client #265] Woke up.
[INFO][10:04:02]: [Client #265] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_265_554853.pth.
[INFO][10:04:03]: [Client #265] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_265_554853.pth.
[INFO][10:04:03]: [Client #265] Model trained.
[INFO][10:04:03]: [Client #265] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:04:03]: [Server #554754] Received 0.26 MB of payload data from client #265 (simulated).
[INFO][10:04:03]: [Server #554754] Selecting client #134 for training.
[INFO][10:04:03]: [Server #554754] Sending the current model to client #134 (simulated).
[INFO][10:04:03]: [Server #554754] Sending 0.26 MB of payload data to client #134 (simulated).
[INFO][10:04:03]: [Server #554754] Selecting client #36 for training.
[INFO][10:04:03]: [Server #554754] Sending the current model to client #36 (simulated).
[INFO][10:04:03]: [Server #554754] Sending 0.26 MB of payload data to client #36 (simulated).
[INFO][10:04:03]: [Client #134] Selected by the server.
[INFO][10:04:03]: [Client #134] Loading its data source...
[INFO][10:04:03]: Data source: FEMNIST
[INFO][10:04:03]: [Client #36] Selected by the server.
[INFO][10:04:03]: [Client #36] Loading its data source...
[INFO][10:04:03]: Data source: FEMNIST
[INFO][10:04:03]: [Client #36] Dataset size: 162
[INFO][10:04:03]: [Client #36] Sampler: all_inclusive
[INFO][10:04:03]: [Client #36] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:04:03]: [93m[1m[Client #36] Started training in communication round #20.[0m
[INFO][10:04:03]: [Client #134] Dataset size: 289
[INFO][10:04:03]: [Client #134] Sampler: all_inclusive
[INFO][10:04:03]: [Client #134] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:04:03]: [93m[1m[Client #134] Started training in communication round #20.[0m
[INFO][10:04:05]: [Client #36] Loading the dataset.
[INFO][10:04:05]: [Client #134] Loading the dataset.
[INFO][10:04:10]: [Client #36] Epoch: [1/5][0/17]	Loss: 0.138304
[INFO][10:04:10]: [Client #134] Epoch: [1/5][0/29]	Loss: 1.418773
[INFO][10:04:10]: [Client #36] Epoch: [1/5][10/17]	Loss: 0.962732
[INFO][10:04:11]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:04:11]: [Client #134] Epoch: [1/5][10/29]	Loss: 1.483475
[INFO][10:04:11]: [Client #134] Epoch: [1/5][20/29]	Loss: 0.866863
[INFO][10:04:11]: [Client #134] Going to sleep for 0.02 seconds.
[INFO][10:04:11]: [Client #134] Woke up.
[INFO][10:04:11]: [Client #134] Epoch: [2/5][0/29]	Loss: 1.564475
[INFO][10:04:11]: [Client #134] Epoch: [2/5][10/29]	Loss: 0.943679
[INFO][10:04:11]: [Client #134] Epoch: [2/5][20/29]	Loss: 0.941588
[INFO][10:04:11]: [Client #134] Going to sleep for 0.02 seconds.
[INFO][10:04:11]: [Client #134] Woke up.
[INFO][10:04:11]: [Client #36] Woke up.
[INFO][10:04:11]: [Client #134] Epoch: [3/5][0/29]	Loss: 0.713267
[INFO][10:04:11]: [Client #36] Epoch: [2/5][0/17]	Loss: 0.924425
[INFO][10:04:11]: [Client #134] Epoch: [3/5][10/29]	Loss: 0.445495
[INFO][10:04:11]: [Client #36] Epoch: [2/5][10/17]	Loss: 0.635031
[INFO][10:04:11]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:04:11]: [Client #134] Epoch: [3/5][20/29]	Loss: 0.651231
[INFO][10:04:11]: [Client #134] Going to sleep for 0.02 seconds.
[INFO][10:04:11]: [Client #134] Woke up.
[INFO][10:04:11]: [Client #134] Epoch: [4/5][0/29]	Loss: 0.740825
[INFO][10:04:11]: [Client #134] Epoch: [4/5][10/29]	Loss: 0.366384
[INFO][10:04:11]: [Client #134] Epoch: [4/5][20/29]	Loss: 0.704737
[INFO][10:04:11]: [Client #134] Going to sleep for 0.02 seconds.
[INFO][10:04:12]: [Client #134] Woke up.
[INFO][10:04:12]: [Client #134] Epoch: [5/5][0/29]	Loss: 0.437285
[INFO][10:04:12]: [Client #134] Epoch: [5/5][10/29]	Loss: 1.088639
[INFO][10:04:12]: [Client #36] Woke up.
[INFO][10:04:12]: [Client #36] Epoch: [3/5][0/17]	Loss: 0.178297
[INFO][10:04:12]: [Client #134] Epoch: [5/5][20/29]	Loss: 0.564482
[INFO][10:04:12]: [Client #36] Epoch: [3/5][10/17]	Loss: 0.603946
[INFO][10:04:12]: [Client #134] Going to sleep for 0.02 seconds.
[INFO][10:04:12]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:04:12]: [Client #134] Woke up.
[INFO][10:04:12]: [Client #134] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_134_554853.pth.
[INFO][10:04:12]: [Client #36] Woke up.
[INFO][10:04:12]: [Client #36] Epoch: [4/5][0/17]	Loss: 1.036958
[INFO][10:04:12]: [Client #36] Epoch: [4/5][10/17]	Loss: 1.108439
[INFO][10:04:12]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:04:12]: [Client #134] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_134_554853.pth.
[INFO][10:04:12]: [Client #134] Model trained.
[INFO][10:04:12]: [Client #134] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:04:12]: [Server #554754] Received 0.26 MB of payload data from client #134 (simulated).
[INFO][10:04:13]: [Client #36] Woke up.
[INFO][10:04:13]: [Client #36] Epoch: [5/5][0/17]	Loss: 0.464017
[INFO][10:04:13]: [Client #36] Epoch: [5/5][10/17]	Loss: 1.195019
[INFO][10:04:13]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:04:13]: [Client #36] Woke up.
[INFO][10:04:13]: [Client #36] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554860.pth.
[INFO][10:04:14]: [Client #36] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554860.pth.
[INFO][10:04:14]: [Client #36] Model trained.
[INFO][10:04:14]: [Client #36] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:04:14]: [Server #554754] Received 0.26 MB of payload data from client #36 (simulated).
[INFO][10:04:14]: [Server #554754] Selecting client #210 for training.
[INFO][10:04:14]: [Server #554754] Sending the current model to client #210 (simulated).
[INFO][10:04:14]: [Server #554754] Sending 0.26 MB of payload data to client #210 (simulated).
[INFO][10:04:14]: [Server #554754] Selecting client #13 for training.
[INFO][10:04:14]: [Server #554754] Sending the current model to client #13 (simulated).
[INFO][10:04:14]: [Server #554754] Sending 0.26 MB of payload data to client #13 (simulated).
[INFO][10:04:14]: [Client #13] Selected by the server.
[INFO][10:04:14]: [Client #210] Selected by the server.
[INFO][10:04:14]: [Client #13] Loading its data source...
[INFO][10:04:14]: [Client #210] Loading its data source...
[INFO][10:04:14]: Data source: FEMNIST
[INFO][10:04:14]: Data source: FEMNIST
[INFO][10:04:14]: [Client #210] Dataset size: 163
[INFO][10:04:14]: [Client #210] Sampler: all_inclusive
[INFO][10:04:14]: [Client #210] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:04:14]: [Client #13] Dataset size: 144
[INFO][10:04:14]: [Client #13] Sampler: all_inclusive
[INFO][10:04:14]: [93m[1m[Client #210] Started training in communication round #20.[0m
[INFO][10:04:14]: [Client #13] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:04:14]: [93m[1m[Client #13] Started training in communication round #20.[0m
[INFO][10:04:16]: [Client #13] Loading the dataset.
[INFO][10:04:16]: [Client #210] Loading the dataset.
[INFO][10:04:21]: [Client #13] Epoch: [1/5][0/15]	Loss: 1.320189
[INFO][10:04:22]: [Client #210] Epoch: [1/5][0/17]	Loss: 0.852813
[INFO][10:04:22]: [Client #13] Epoch: [1/5][10/15]	Loss: 1.405910
[INFO][10:04:22]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][10:04:22]: [Client #210] Epoch: [1/5][10/17]	Loss: 0.653080
[INFO][10:04:22]: [Client #210] Going to sleep for 11.31 seconds.
[INFO][10:04:22]: [Client #13] Woke up.
[INFO][10:04:22]: [Client #13] Epoch: [2/5][0/15]	Loss: 0.390364
[INFO][10:04:22]: [Client #13] Epoch: [2/5][10/15]	Loss: 0.776649
[INFO][10:04:22]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][10:04:22]: [Client #13] Woke up.
[INFO][10:04:22]: [Client #13] Epoch: [3/5][0/15]	Loss: 0.551473
[INFO][10:04:22]: [Client #13] Epoch: [3/5][10/15]	Loss: 1.119292
[INFO][10:04:22]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][10:04:23]: [Client #13] Woke up.
[INFO][10:04:23]: [Client #13] Epoch: [4/5][0/15]	Loss: 1.463795
[INFO][10:04:23]: [Client #13] Epoch: [4/5][10/15]	Loss: 0.873774
[INFO][10:04:23]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][10:04:23]: [Client #13] Woke up.
[INFO][10:04:23]: [Client #13] Epoch: [5/5][0/15]	Loss: 0.777524
[INFO][10:04:23]: [Client #13] Epoch: [5/5][10/15]	Loss: 0.470336
[INFO][10:04:23]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][10:04:23]: [Client #13] Woke up.
[INFO][10:04:23]: [Client #13] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554860.pth.
[INFO][10:04:24]: [Client #13] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554860.pth.
[INFO][10:04:24]: [Client #13] Model trained.
[INFO][10:04:24]: [Client #13] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:04:24]: [Server #554754] Received 0.26 MB of payload data from client #13 (simulated).
[INFO][10:04:33]: [Client #210] Woke up.
[INFO][10:04:33]: [Client #210] Epoch: [2/5][0/17]	Loss: 1.122368
[INFO][10:04:33]: [Client #210] Epoch: [2/5][10/17]	Loss: 0.700675
[INFO][10:04:33]: [Client #210] Going to sleep for 11.31 seconds.
[INFO][10:04:44]: [Client #210] Woke up.
[INFO][10:04:44]: [Client #210] Epoch: [3/5][0/17]	Loss: 1.099913
[INFO][10:04:45]: [Client #210] Epoch: [3/5][10/17]	Loss: 1.013408
[INFO][10:04:45]: [Client #210] Going to sleep for 11.31 seconds.
[INFO][10:04:56]: [Client #210] Woke up.
[INFO][10:04:56]: [Client #210] Epoch: [4/5][0/17]	Loss: 0.524720
[INFO][10:04:56]: [Client #210] Epoch: [4/5][10/17]	Loss: 1.079374
[INFO][10:04:56]: [Client #210] Going to sleep for 11.31 seconds.
[INFO][10:05:07]: [Client #210] Woke up.
[INFO][10:05:07]: [Client #210] Epoch: [5/5][0/17]	Loss: 0.874739
[INFO][10:05:08]: [Client #210] Epoch: [5/5][10/17]	Loss: 0.834367
[INFO][10:05:08]: [Client #210] Going to sleep for 11.31 seconds.
[INFO][10:05:19]: [Client #210] Woke up.
[INFO][10:05:19]: [Client #210] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_210_554853.pth.
[INFO][10:05:20]: [Client #210] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_210_554853.pth.
[INFO][10:05:20]: [Client #210] Model trained.
[INFO][10:05:20]: [Client #210] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:05:20]: [Server #554754] Received 0.26 MB of payload data from client #210 (simulated).
[INFO][10:05:20]: [Server #554754] Selecting client #146 for training.
[INFO][10:05:20]: [Server #554754] Sending the current model to client #146 (simulated).
[INFO][10:05:20]: [Server #554754] Sending 0.26 MB of payload data to client #146 (simulated).
[INFO][10:05:20]: [Server #554754] Selecting client #253 for training.
[INFO][10:05:20]: [Server #554754] Sending the current model to client #253 (simulated).
[INFO][10:05:20]: [Server #554754] Sending 0.26 MB of payload data to client #253 (simulated).
[INFO][10:05:20]: [Client #146] Selected by the server.
[INFO][10:05:20]: [Client #146] Loading its data source...
[INFO][10:05:20]: Data source: FEMNIST
[INFO][10:05:20]: [Client #253] Selected by the server.
[INFO][10:05:20]: [Client #253] Loading its data source...
[INFO][10:05:20]: Data source: FEMNIST
[INFO][10:05:20]: [Client #146] Dataset size: 156
[INFO][10:05:20]: [Client #146] Sampler: all_inclusive
[INFO][10:05:20]: [Client #146] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:05:20]: [93m[1m[Client #146] Started training in communication round #20.[0m
[INFO][10:05:20]: [Client #253] Dataset size: 161
[INFO][10:05:20]: [Client #253] Sampler: all_inclusive
[INFO][10:05:20]: [Client #253] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:05:20]: [93m[1m[Client #253] Started training in communication round #20.[0m
[INFO][10:05:22]: [Client #146] Loading the dataset.
[INFO][10:05:22]: [Client #253] Loading the dataset.
[INFO][10:05:27]: [Client #253] Epoch: [1/5][0/17]	Loss: 0.098931
[INFO][10:05:27]: [Client #146] Epoch: [1/5][0/16]	Loss: 1.298287
[INFO][10:05:27]: [Client #253] Epoch: [1/5][10/17]	Loss: 0.619119
[INFO][10:05:27]: [Client #146] Epoch: [1/5][10/16]	Loss: 0.477812
[INFO][10:05:27]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][10:05:27]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][10:05:27]: [Client #146] Woke up.
[INFO][10:05:27]: [Client #146] Epoch: [2/5][0/16]	Loss: 0.326423
[INFO][10:05:27]: [Client #146] Epoch: [2/5][10/16]	Loss: 1.608364
[INFO][10:05:28]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][10:05:28]: [Client #146] Woke up.
[INFO][10:05:28]: [Client #146] Epoch: [3/5][0/16]	Loss: 1.055757
[INFO][10:05:28]: [Client #146] Epoch: [3/5][10/16]	Loss: 0.480845
[INFO][10:05:28]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][10:05:28]: [Client #253] Woke up.
[INFO][10:05:28]: [Client #253] Epoch: [2/5][0/17]	Loss: 0.933419
[INFO][10:05:28]: [Client #146] Woke up.
[INFO][10:05:28]: [Client #146] Epoch: [4/5][0/16]	Loss: 1.317997
[INFO][10:05:28]: [Client #253] Epoch: [2/5][10/17]	Loss: 1.664276
[INFO][10:05:28]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][10:05:28]: [Client #146] Epoch: [4/5][10/16]	Loss: 1.363834
[INFO][10:05:28]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][10:05:28]: [Client #146] Woke up.
[INFO][10:05:28]: [Client #146] Epoch: [5/5][0/16]	Loss: 1.937637
[INFO][10:05:28]: [Client #146] Epoch: [5/5][10/16]	Loss: 2.036428
[INFO][10:05:28]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][10:05:28]: [Client #146] Woke up.
[INFO][10:05:28]: [Client #146] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554853.pth.
[INFO][10:05:29]: [Client #253] Woke up.
[INFO][10:05:29]: [Client #253] Epoch: [3/5][0/17]	Loss: 1.542838
[INFO][10:05:29]: [Client #253] Epoch: [3/5][10/17]	Loss: 1.100194
[INFO][10:05:29]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][10:05:29]: [Client #146] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554853.pth.
[INFO][10:05:29]: [Client #146] Model trained.
[INFO][10:05:29]: [Client #146] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:05:29]: [Server #554754] Received 0.26 MB of payload data from client #146 (simulated).
[INFO][10:05:29]: [Client #253] Woke up.
[INFO][10:05:29]: [Client #253] Epoch: [4/5][0/17]	Loss: 1.333081
[INFO][10:05:29]: [Client #253] Epoch: [4/5][10/17]	Loss: 1.984715
[INFO][10:05:30]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][10:05:30]: [Client #253] Woke up.
[INFO][10:05:30]: [Client #253] Epoch: [5/5][0/17]	Loss: 1.280751
[INFO][10:05:30]: [Client #253] Epoch: [5/5][10/17]	Loss: 0.781481
[INFO][10:05:30]: [Client #253] Going to sleep for 0.60 seconds.
[INFO][10:05:31]: [Client #253] Woke up.
[INFO][10:05:31]: [Client #253] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_554860.pth.
[INFO][10:05:32]: [Client #253] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_253_554860.pth.
[INFO][10:05:32]: [Client #253] Model trained.
[INFO][10:05:32]: [Client #253] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:05:32]: [Server #554754] Received 0.26 MB of payload data from client #253 (simulated).
[INFO][10:05:32]: [Server #554754] Adding client #444 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #134 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #146 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #13 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #36 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #253 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #205 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #265 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Adding client #210 to the list of clients for aggregation.
[INFO][10:05:32]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09916358 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.41839273
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.20362463 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16290083 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10336314 0.         0.         0.         0.         0.11017615
 0.         0.17840734 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.02318089 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10085246 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15361426
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09916358 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.41839273
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.20362463 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16290083 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10336314 0.         0.         0.         0.         0.11017615
 0.         0.17840734 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.02318089 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10085246 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15361426
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:06:15]: [Server #554754] Global model accuracy: 60.34%

[INFO][10:06:15]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_20.pth.
[INFO][10:06:15]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_20.pth.
[INFO][10:06:15]: [93m[1m
[Server #554754] Starting round 21/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.002      0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.002      0.0892562
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.09482257 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.04942389 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.08247423 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09779793 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.002      0.100894
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08815427 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.002      0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.002
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08995585 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.10305344 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.10621762
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9052e+00  5e-04  9e-09  9e-09
 5:  6.9058e+00  6.9056e+00  2e-04  3e-09  3e-09
 6:  6.9057e+00  6.9056e+00  2e-04  6e-09  1e-09
 7:  6.9057e+00  6.9056e+00  1e-04  7e-09  1e-09
 8:  6.9057e+00  6.9056e+00  8e-05  7e-08  1e-08
 9:  6.9056e+00  6.9056e+00  4e-05  6e-08  1e-08
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  7e-09
Optimal solution found.
The calculated probability is:  [4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01473815e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 3.95859856e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 3.97293319e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.00902609e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01414037e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01320359e-05 4.01737860e-05 9.79998201e-01 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 3.69033628e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01429567e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 3.99453609e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05 4.01737860e-05
 4.01737860e-05 4.01737860e-05 4.01737860e-05]
current clients pool:  [INFO][10:06:16]: [Server #554754] Selected clients: [212 385 145 109   9 200 191 331  36  76]
[INFO][10:06:16]: [Server #554754] Selecting client #212 for training.
[INFO][10:06:16]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][10:06:16]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][10:06:16]: [Server #554754] Selecting client #385 for training.
[INFO][10:06:16]: [Server #554754] Sending the current model to client #385 (simulated).
[INFO][10:06:16]: [Server #554754] Sending 0.26 MB of payload data to client #385 (simulated).
[INFO][10:06:16]: [Client #212] Selected by the server.
[INFO][10:06:16]: [Client #212] Loading its data source...
[INFO][10:06:16]: Data source: FEMNIST
[INFO][10:06:16]: [Client #385] Selected by the server.
[INFO][10:06:16]: [Client #385] Loading its data source...
[INFO][10:06:16]: Data source: FEMNIST
[INFO][10:06:16]: [Client #385] Dataset size: 162
[INFO][10:06:16]: [Client #385] Sampler: all_inclusive
[INFO][10:06:16]: [Client #385] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:06:16]: [Client #212] Dataset size: 160
[INFO][10:06:16]: [Client #212] Sampler: all_inclusive
[INFO][10:06:16]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:06:16]: [93m[1m[Client #212] Started training in communication round #21.[0m
[INFO][10:06:16]: [93m[1m[Client #385] Started training in communication round #21.[0m
[INFO][10:06:18]: [Client #212] Loading the dataset.
[INFO][10:06:18]: [Client #385] Loading the dataset.
[INFO][10:06:23]: [Client #385] Epoch: [1/5][0/17]	Loss: 1.082825
[INFO][10:06:23]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.442338
[INFO][10:06:23]: [Client #385] Epoch: [1/5][10/17]	Loss: 1.499338
[INFO][10:06:23]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][10:06:23]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.271171
[INFO][10:06:23]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:06:24]: [Client #385] Woke up.
[INFO][10:06:24]: [Client #385] Epoch: [2/5][0/17]	Loss: 1.461496
[INFO][10:06:24]: [Client #385] Epoch: [2/5][10/17]	Loss: 0.847254
[INFO][10:06:24]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][10:06:24]: [Client #385] Woke up.
[INFO][10:06:24]: [Client #385] Epoch: [3/5][0/17]	Loss: 0.769430
[INFO][10:06:24]: [Client #385] Epoch: [3/5][10/17]	Loss: 0.924244
[INFO][10:06:24]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][10:06:25]: [Client #385] Woke up.
[INFO][10:06:25]: [Client #385] Epoch: [4/5][0/17]	Loss: 0.834507
[INFO][10:06:25]: [Client #385] Epoch: [4/5][10/17]	Loss: 0.591463
[INFO][10:06:25]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][10:06:25]: [Client #385] Woke up.
[INFO][10:06:25]: [Client #385] Epoch: [5/5][0/17]	Loss: 1.142895
[INFO][10:06:25]: [Client #385] Epoch: [5/5][10/17]	Loss: 0.823654
[INFO][10:06:25]: [Client #385] Going to sleep for 0.33 seconds.
[INFO][10:06:25]: [Client #385] Woke up.
[INFO][10:06:25]: [Client #385] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_385_554860.pth.
[INFO][10:06:26]: [Client #385] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_385_554860.pth.
[INFO][10:06:26]: [Client #385] Model trained.
[INFO][10:06:26]: [Client #385] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:06:26]: [Server #554754] Received 0.26 MB of payload data from client #385 (simulated).
[INFO][10:06:50]: [Client #212] Woke up.
[INFO][10:06:50]: [Client #212] Epoch: [2/5][0/16]	Loss: 2.809604
[INFO][10:06:50]: [Client #212] Epoch: [2/5][10/16]	Loss: 1.343814
[INFO][10:06:50]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:07:16]: [Client #212] Woke up.
[INFO][10:07:16]: [Client #212] Epoch: [3/5][0/16]	Loss: 0.884839
[INFO][10:07:16]: [Client #212] Epoch: [3/5][10/16]	Loss: 1.280864
[INFO][10:07:16]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:07:42]: [Client #212] Woke up.
[INFO][10:07:43]: [Client #212] Epoch: [4/5][0/16]	Loss: 0.558092
[INFO][10:07:43]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.014642
[INFO][10:07:43]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:08:09]: [Client #212] Woke up.
[INFO][10:08:09]: [Client #212] Epoch: [5/5][0/16]	Loss: 0.514552
[INFO][10:08:09]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.977044
[INFO][10:08:09]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:08:35]: [Client #212] Woke up.
[INFO][10:08:36]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:08:36]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:08:36]: [Client #212] Model trained.
[INFO][10:08:36]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:08:36]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][10:08:36]: [Server #554754] Selecting client #145 for training.
[INFO][10:08:36]: [Server #554754] Sending the current model to client #145 (simulated).
[INFO][10:08:36]: [Server #554754] Sending 0.26 MB of payload data to client #145 (simulated).
[INFO][10:08:36]: [Server #554754] Selecting client #109 for training.
[INFO][10:08:36]: [Server #554754] Sending the current model to client #109 (simulated).
[INFO][10:08:36]: [Server #554754] Sending 0.26 MB of payload data to client #109 (simulated).
[INFO][10:08:36]: [Client #145] Selected by the server.
[INFO][10:08:36]: [Client #145] Loading its data source...
[INFO][10:08:36]: Data source: FEMNIST
[INFO][10:08:36]: [Client #109] Selected by the server.
[INFO][10:08:36]: [Client #109] Loading its data source...
[INFO][10:08:36]: Data source: FEMNIST
[INFO][10:08:36]: [Client #109] Dataset size: 163
[INFO][10:08:36]: [Client #109] Sampler: all_inclusive
[INFO][10:08:36]: [Client #109] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:08:36]: [Client #145] Dataset size: 272
[INFO][10:08:36]: [Client #145] Sampler: all_inclusive
[INFO][10:08:36]: [93m[1m[Client #109] Started training in communication round #21.[0m
[INFO][10:08:36]: [Client #145] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:08:36]: [93m[1m[Client #145] Started training in communication round #21.[0m
[INFO][10:08:38]: [Client #145] Loading the dataset.
[INFO][10:08:38]: [Client #109] Loading the dataset.
[INFO][10:08:44]: [Client #145] Epoch: [1/5][0/28]	Loss: 1.987579
[INFO][10:08:44]: [Client #145] Epoch: [1/5][10/28]	Loss: 1.732027
[INFO][10:08:44]: [Client #109] Epoch: [1/5][0/17]	Loss: 0.560939
[INFO][10:08:44]: [Client #145] Epoch: [1/5][20/28]	Loss: 1.237446
[INFO][10:08:44]: [Client #109] Epoch: [1/5][10/17]	Loss: 0.447928
[INFO][10:08:44]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][10:08:44]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][10:08:44]: [Client #145] Woke up.
[INFO][10:08:44]: [Client #145] Epoch: [2/5][0/28]	Loss: 1.198738
[INFO][10:08:44]: [Client #145] Epoch: [2/5][10/28]	Loss: 1.081958
[INFO][10:08:44]: [Client #145] Epoch: [2/5][20/28]	Loss: 0.726330
[INFO][10:08:44]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][10:08:44]: [Client #145] Woke up.
[INFO][10:08:44]: [Client #145] Epoch: [3/5][0/28]	Loss: 0.947378
[INFO][10:08:44]: [Client #145] Epoch: [3/5][10/28]	Loss: 0.616448
[INFO][10:08:44]: [Client #145] Epoch: [3/5][20/28]	Loss: 0.807443
[INFO][10:08:44]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][10:08:44]: [Client #145] Woke up.
[INFO][10:08:44]: [Client #145] Epoch: [4/5][0/28]	Loss: 1.531093
[INFO][10:08:45]: [Client #145] Epoch: [4/5][10/28]	Loss: 1.119688
[INFO][10:08:45]: [Client #145] Epoch: [4/5][20/28]	Loss: 1.035493
[INFO][10:08:45]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][10:08:45]: [Client #145] Woke up.
[INFO][10:08:45]: [Client #145] Epoch: [5/5][0/28]	Loss: 1.509756
[INFO][10:08:45]: [Client #145] Epoch: [5/5][10/28]	Loss: 2.240893
[INFO][10:08:45]: [Client #145] Epoch: [5/5][20/28]	Loss: 1.591665
[INFO][10:08:45]: [Client #145] Going to sleep for 0.05 seconds.
[INFO][10:08:45]: [Client #145] Woke up.
[INFO][10:08:45]: [Client #145] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_145_554853.pth.
[INFO][10:08:46]: [Client #145] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_145_554853.pth.
[INFO][10:08:46]: [Client #145] Model trained.
[INFO][10:08:46]: [Client #145] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:08:46]: [Server #554754] Received 0.26 MB of payload data from client #145 (simulated).
[INFO][10:08:46]: [Client #109] Woke up.
[INFO][10:08:46]: [Client #109] Epoch: [2/5][0/17]	Loss: 0.434008
[INFO][10:08:46]: [Client #109] Epoch: [2/5][10/17]	Loss: 0.681595
[INFO][10:08:46]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][10:08:49]: [Client #109] Woke up.
[INFO][10:08:49]: [Client #109] Epoch: [3/5][0/17]	Loss: 0.948595
[INFO][10:08:49]: [Client #109] Epoch: [3/5][10/17]	Loss: 0.849818
[INFO][10:08:49]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][10:08:51]: [Client #109] Woke up.
[INFO][10:08:51]: [Client #109] Epoch: [4/5][0/17]	Loss: 1.168902
[INFO][10:08:51]: [Client #109] Epoch: [4/5][10/17]	Loss: 1.098057
[INFO][10:08:51]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][10:08:53]: [Client #109] Woke up.
[INFO][10:08:53]: [Client #109] Epoch: [5/5][0/17]	Loss: 0.453241
[INFO][10:08:53]: [Client #109] Epoch: [5/5][10/17]	Loss: 1.263265
[INFO][10:08:53]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][10:08:56]: [Client #109] Woke up.
[INFO][10:08:56]: [Client #109] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554860.pth.
[INFO][10:08:56]: [Client #109] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554860.pth.
[INFO][10:08:56]: [Client #109] Model trained.
[INFO][10:08:56]: [Client #109] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:08:56]: [Server #554754] Received 0.26 MB of payload data from client #109 (simulated).
[INFO][10:08:56]: [Server #554754] Selecting client #9 for training.
[INFO][10:08:56]: [Server #554754] Sending the current model to client #9 (simulated).
[INFO][10:08:56]: [Server #554754] Sending 0.26 MB of payload data to client #9 (simulated).
[INFO][10:08:56]: [Server #554754] Selecting client #200 for training.
[INFO][10:08:56]: [Server #554754] Sending the current model to client #200 (simulated).
[INFO][10:08:56]: [Server #554754] Sending 0.26 MB of payload data to client #200 (simulated).
[INFO][10:08:56]: [Client #200] Selected by the server.
[INFO][10:08:56]: [Client #9] Selected by the server.
[INFO][10:08:56]: [Client #200] Loading its data source...
[INFO][10:08:56]: [Client #9] Loading its data source...
[INFO][10:08:56]: Data source: FEMNIST
[INFO][10:08:56]: Data source: FEMNIST
[INFO][10:08:56]: [Client #9] Dataset size: 145
[INFO][10:08:56]: [Client #9] Sampler: all_inclusive
[INFO][10:08:56]: [Client #9] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:08:56]: [93m[1m[Client #9] Started training in communication round #21.[0m
[INFO][10:08:56]: [Client #200] Dataset size: 318
[INFO][10:08:56]: [Client #200] Sampler: all_inclusive
[INFO][10:08:56]: [Client #200] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:08:56]: [93m[1m[Client #200] Started training in communication round #21.[0m
[INFO][10:08:58]: [Client #9] Loading the dataset.
[INFO][10:08:58]: [Client #200] Loading the dataset.
[INFO][10:09:04]: [Client #200] Epoch: [1/5][0/32]	Loss: 1.775329
[INFO][10:09:04]: [Client #9] Epoch: [1/5][0/15]	Loss: 0.773271
[INFO][10:09:04]: [Client #200] Epoch: [1/5][10/32]	Loss: 0.828647
[INFO][10:09:04]: [Client #9] Epoch: [1/5][10/15]	Loss: 1.019224
[INFO][10:09:04]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][10:09:04]: [Client #200] Epoch: [1/5][20/32]	Loss: 1.013569
[INFO][10:09:04]: [Client #200] Epoch: [1/5][30/32]	Loss: 1.718919
[INFO][10:09:04]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][10:09:05]: [Client #9] Woke up.
[INFO][10:09:05]: [Client #9] Epoch: [2/5][0/15]	Loss: 1.488574
[INFO][10:09:05]: [Client #9] Epoch: [2/5][10/15]	Loss: 1.173800
[INFO][10:09:05]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][10:09:05]: [Client #9] Woke up.
[INFO][10:09:05]: [Client #9] Epoch: [3/5][0/15]	Loss: 0.526152
[INFO][10:09:06]: [Client #9] Epoch: [3/5][10/15]	Loss: 1.243246
[INFO][10:09:06]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][10:09:06]: [Client #9] Woke up.
[INFO][10:09:06]: [Client #9] Epoch: [4/5][0/15]	Loss: 0.516656
[INFO][10:09:06]: [Client #9] Epoch: [4/5][10/15]	Loss: 1.024013
[INFO][10:09:06]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][10:09:07]: [Client #9] Woke up.
[INFO][10:09:07]: [Client #9] Epoch: [5/5][0/15]	Loss: 0.486928
[INFO][10:09:07]: [Client #9] Epoch: [5/5][10/15]	Loss: 0.286944
[INFO][10:09:07]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][10:09:08]: [Client #9] Woke up.
[INFO][10:09:08]: [Client #9] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_9_554853.pth.
[INFO][10:09:08]: [Client #9] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_9_554853.pth.
[INFO][10:09:09]: [Client #9] Model trained.
[INFO][10:09:09]: [Client #9] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:09:09]: [Server #554754] Received 0.26 MB of payload data from client #9 (simulated).
[INFO][10:09:23]: [Client #200] Woke up.
[INFO][10:09:23]: [Client #200] Epoch: [2/5][0/32]	Loss: 1.397556
[INFO][10:09:23]: [Client #200] Epoch: [2/5][10/32]	Loss: 1.223448
[INFO][10:09:23]: [Client #200] Epoch: [2/5][20/32]	Loss: 1.620958
[INFO][10:09:23]: [Client #200] Epoch: [2/5][30/32]	Loss: 1.179553
[INFO][10:09:23]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][10:09:42]: [Client #200] Woke up.
[INFO][10:09:42]: [Client #200] Epoch: [3/5][0/32]	Loss: 1.361877
[INFO][10:09:42]: [Client #200] Epoch: [3/5][10/32]	Loss: 1.107255
[INFO][10:09:42]: [Client #200] Epoch: [3/5][20/32]	Loss: 1.091180
[INFO][10:09:42]: [Client #200] Epoch: [3/5][30/32]	Loss: 0.731096
[INFO][10:09:42]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][10:10:01]: [Client #200] Woke up.
[INFO][10:10:01]: [Client #200] Epoch: [4/5][0/32]	Loss: 0.971111
[INFO][10:10:01]: [Client #200] Epoch: [4/5][10/32]	Loss: 1.182761
[INFO][10:10:01]: [Client #200] Epoch: [4/5][20/32]	Loss: 0.625672
[INFO][10:10:01]: [Client #200] Epoch: [4/5][30/32]	Loss: 0.398912
[INFO][10:10:01]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][10:10:20]: [Client #200] Woke up.
[INFO][10:10:20]: [Client #200] Epoch: [5/5][0/32]	Loss: 2.049919
[INFO][10:10:20]: [Client #200] Epoch: [5/5][10/32]	Loss: 1.111531
[INFO][10:10:20]: [Client #200] Epoch: [5/5][20/32]	Loss: 0.736987
[INFO][10:10:20]: [Client #200] Epoch: [5/5][30/32]	Loss: 1.560238
[INFO][10:10:20]: [Client #200] Going to sleep for 18.61 seconds.
[INFO][10:10:39]: [Client #200] Woke up.
[INFO][10:10:39]: [Client #200] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_554860.pth.
[INFO][10:10:39]: [Client #200] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_200_554860.pth.
[INFO][10:10:40]: [Client #200] Model trained.
[INFO][10:10:40]: [Client #200] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:10:40]: [Server #554754] Received 0.26 MB of payload data from client #200 (simulated).
[INFO][10:10:40]: [Server #554754] Selecting client #191 for training.
[INFO][10:10:40]: [Server #554754] Sending the current model to client #191 (simulated).
[INFO][10:10:40]: [Server #554754] Sending 0.26 MB of payload data to client #191 (simulated).
[INFO][10:10:40]: [Server #554754] Selecting client #331 for training.
[INFO][10:10:40]: [Server #554754] Sending the current model to client #331 (simulated).
[INFO][10:10:40]: [Server #554754] Sending 0.26 MB of payload data to client #331 (simulated).
[INFO][10:10:40]: [Client #191] Selected by the server.
[INFO][10:10:40]: [Client #331] Selected by the server.
[INFO][10:10:40]: [Client #331] Loading its data source...
[INFO][10:10:40]: [Client #191] Loading its data source...
[INFO][10:10:40]: Data source: FEMNIST
[INFO][10:10:40]: Data source: FEMNIST
[INFO][10:10:40]: [Client #331] Dataset size: 163
[INFO][10:10:40]: [Client #331] Sampler: all_inclusive
[INFO][10:10:40]: [Client #331] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:10:40]: [93m[1m[Client #331] Started training in communication round #21.[0m
[INFO][10:10:40]: [Client #191] Dataset size: 164
[INFO][10:10:40]: [Client #191] Sampler: all_inclusive
[INFO][10:10:40]: [Client #191] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:10:40]: [93m[1m[Client #191] Started training in communication round #21.[0m
[INFO][10:10:42]: [Client #191] Loading the dataset.
[INFO][10:10:42]: [Client #331] Loading the dataset.
[INFO][10:10:47]: [Client #331] Epoch: [1/5][0/17]	Loss: 0.090386
[INFO][10:10:47]: [Client #191] Epoch: [1/5][0/17]	Loss: 1.313495
[INFO][10:10:47]: [Client #331] Epoch: [1/5][10/17]	Loss: 1.270471
[INFO][10:10:47]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][10:10:47]: [Client #191] Epoch: [1/5][10/17]	Loss: 0.707616
[INFO][10:10:47]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][10:10:47]: [Client #331] Woke up.
[INFO][10:10:47]: [Client #331] Epoch: [2/5][0/17]	Loss: 1.446871
[INFO][10:10:47]: [Client #331] Epoch: [2/5][10/17]	Loss: 0.324580
[INFO][10:10:47]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][10:10:48]: [Client #191] Woke up.
[INFO][10:10:48]: [Client #191] Epoch: [2/5][0/17]	Loss: 0.687822
[INFO][10:10:48]: [Client #331] Woke up.
[INFO][10:10:48]: [Client #331] Epoch: [3/5][0/17]	Loss: 0.632749
[INFO][10:10:48]: [Client #191] Epoch: [2/5][10/17]	Loss: 0.674518
[INFO][10:10:48]: [Client #331] Epoch: [3/5][10/17]	Loss: 0.972760
[INFO][10:10:48]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][10:10:48]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][10:10:48]: [Client #331] Woke up.
[INFO][10:10:48]: [Client #331] Epoch: [4/5][0/17]	Loss: 0.465244
[INFO][10:10:48]: [Client #331] Epoch: [4/5][10/17]	Loss: 0.303222
[INFO][10:10:48]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][10:10:48]: [Client #191] Woke up.
[INFO][10:10:48]: [Client #191] Epoch: [3/5][0/17]	Loss: 1.424989
[INFO][10:10:48]: [Client #191] Epoch: [3/5][10/17]	Loss: 0.308976
[INFO][10:10:48]: [Client #331] Woke up.
[INFO][10:10:48]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][10:10:48]: [Client #331] Epoch: [5/5][0/17]	Loss: 0.345320
[INFO][10:10:48]: [Client #331] Epoch: [5/5][10/17]	Loss: 0.819981
[INFO][10:10:48]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][10:10:49]: [Client #331] Woke up.
[INFO][10:10:49]: [Client #331] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554860.pth.
[INFO][10:10:49]: [Client #191] Woke up.
[INFO][10:10:49]: [Client #191] Epoch: [4/5][0/17]	Loss: 0.182970
[INFO][10:10:49]: [Client #191] Epoch: [4/5][10/17]	Loss: 0.835008
[INFO][10:10:49]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][10:10:49]: [Client #191] Woke up.
[INFO][10:10:49]: [Client #191] Epoch: [5/5][0/17]	Loss: 1.146935
[INFO][10:10:49]: [Client #191] Epoch: [5/5][10/17]	Loss: 0.499494
[INFO][10:10:49]: [Client #331] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554860.pth.
[INFO][10:10:49]: [Client #191] Going to sleep for 0.36 seconds.
[INFO][10:10:49]: [Client #331] Model trained.
[INFO][10:10:49]: [Client #331] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:10:49]: [Server #554754] Received 0.26 MB of payload data from client #331 (simulated).
[INFO][10:10:50]: [Client #191] Woke up.
[INFO][10:10:50]: [Client #191] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_191_554853.pth.
[INFO][10:10:50]: [Client #191] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_191_554853.pth.
[INFO][10:10:50]: [Client #191] Model trained.
[INFO][10:10:50]: [Client #191] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:10:50]: [Server #554754] Received 0.26 MB of payload data from client #191 (simulated).
[INFO][10:10:50]: [Server #554754] Selecting client #36 for training.
[INFO][10:10:50]: [Server #554754] Sending the current model to client #36 (simulated).
[INFO][10:10:50]: [Server #554754] Sending 0.26 MB of payload data to client #36 (simulated).
[INFO][10:10:50]: [Server #554754] Selecting client #76 for training.
[INFO][10:10:50]: [Server #554754] Sending the current model to client #76 (simulated).
[INFO][10:10:50]: [Server #554754] Sending 0.26 MB of payload data to client #76 (simulated).
[INFO][10:10:50]: [Client #36] Selected by the server.
[INFO][10:10:50]: [Client #36] Loading its data source...
[INFO][10:10:50]: Data source: FEMNIST
[INFO][10:10:50]: [Client #76] Selected by the server.
[INFO][10:10:50]: [Client #76] Loading its data source...
[INFO][10:10:50]: Data source: FEMNIST
[INFO][10:10:50]: [Client #76] Dataset size: 163
[INFO][10:10:50]: [Client #76] Sampler: all_inclusive
[INFO][10:10:50]: [Client #36] Dataset size: 162
[INFO][10:10:50]: [Client #36] Sampler: all_inclusive
[INFO][10:10:50]: [Client #76] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:10:50]: [Client #36] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:10:50]: [93m[1m[Client #76] Started training in communication round #21.[0m
[INFO][10:10:50]: [93m[1m[Client #36] Started training in communication round #21.[0m
[INFO][10:10:52]: [Client #36] Loading the dataset.
[INFO][10:10:52]: [Client #76] Loading the dataset.
[INFO][10:10:58]: [Client #36] Epoch: [1/5][0/17]	Loss: 0.705194
[INFO][10:10:58]: [Client #76] Epoch: [1/5][0/17]	Loss: 0.918128
[INFO][10:10:58]: [Client #36] Epoch: [1/5][10/17]	Loss: 1.066998
[INFO][10:10:58]: [Client #76] Epoch: [1/5][10/17]	Loss: 0.454166
[INFO][10:10:58]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:10:58]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][10:10:58]: [Client #76] Woke up.
[INFO][10:10:58]: [Client #76] Epoch: [2/5][0/17]	Loss: 0.300828
[INFO][10:10:58]: [Client #76] Epoch: [2/5][10/17]	Loss: 0.568860
[INFO][10:10:58]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][10:10:58]: [Client #36] Woke up.
[INFO][10:10:58]: [Client #36] Epoch: [2/5][0/17]	Loss: 1.655598
[INFO][10:10:58]: [Client #76] Woke up.
[INFO][10:10:58]: [Client #36] Epoch: [2/5][10/17]	Loss: 0.436832
[INFO][10:10:58]: [Client #76] Epoch: [3/5][0/17]	Loss: 0.396230
[INFO][10:10:58]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:10:58]: [Client #76] Epoch: [3/5][10/17]	Loss: 0.120376
[INFO][10:10:58]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][10:10:59]: [Client #76] Woke up.
[INFO][10:10:59]: [Client #76] Epoch: [4/5][0/17]	Loss: 0.274812
[INFO][10:10:59]: [Client #76] Epoch: [4/5][10/17]	Loss: 0.313928
[INFO][10:10:59]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][10:10:59]: [Client #36] Woke up.
[INFO][10:10:59]: [Client #36] Epoch: [3/5][0/17]	Loss: 1.166952
[INFO][10:10:59]: [Client #36] Epoch: [3/5][10/17]	Loss: 0.859596
[INFO][10:10:59]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:10:59]: [Client #76] Woke up.
[INFO][10:10:59]: [Client #76] Epoch: [5/5][0/17]	Loss: 0.378078
[INFO][10:10:59]: [Client #76] Epoch: [5/5][10/17]	Loss: 2.206455
[INFO][10:10:59]: [Client #76] Going to sleep for 0.20 seconds.
[INFO][10:10:59]: [Client #76] Woke up.
[INFO][10:10:59]: [Client #76] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_76_554860.pth.
[INFO][10:10:59]: [Client #36] Woke up.
[INFO][10:10:59]: [Client #36] Epoch: [4/5][0/17]	Loss: 0.989756
[INFO][10:11:00]: [Client #36] Epoch: [4/5][10/17]	Loss: 1.688926
[INFO][10:11:00]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:11:00]: [Client #76] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_76_554860.pth.
[INFO][10:11:00]: [Client #76] Model trained.
[INFO][10:11:00]: [Client #76] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:11:00]: [Server #554754] Received 0.26 MB of payload data from client #76 (simulated).
[INFO][10:11:00]: [Client #36] Woke up.
[INFO][10:11:00]: [Client #36] Epoch: [5/5][0/17]	Loss: 0.103629
[INFO][10:11:00]: [Client #36] Epoch: [5/5][10/17]	Loss: 0.784401
[INFO][10:11:00]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][10:11:01]: [Client #36] Woke up.
[INFO][10:11:01]: [Client #36] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][10:11:01]: [Client #36] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][10:11:01]: [Client #36] Model trained.
[INFO][10:11:01]: [Client #36] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:11:01]: [Server #554754] Received 0.26 MB of payload data from client #36 (simulated).
[INFO][10:11:01]: [Server #554754] Adding client #145 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #76 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #331 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #385 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #191 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #36 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #9 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #109 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Adding client #200 to the list of clients for aggregation.
[INFO][10:11:01]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.12446993 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10701923
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07088616 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15372284 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.27441266 0.         0.         0.         0.         0.
 0.         0.24426201 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14087698 0.
 0.         0.         0.         0.         0.         0.
 0.         0.20507111 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06625918 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1440691  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.12446993 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10701923
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07088616 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15372284 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.27441266 0.         0.         0.         0.         0.
 0.         0.24426201 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.14087698 0.
 0.         0.         0.         0.         0.         0.
 0.         0.20507111 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06625918 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1440691  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:11:52]: [Server #554754] Global model accuracy: 59.06%

[INFO][10:11:52]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_21.pth.
[INFO][10:11:52]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_21.pth.
[INFO][10:11:52]: [93m[1m
[Server #554754] Starting round 22/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.002      0.08695652
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08105207 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08554572 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08815427 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.002      0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.002
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.002      0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.002
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.04396604 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.10621762
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.002      0.002      0.002      0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.002      0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9052e+00  6e-04  1e-08  1e-08
 5:  6.9058e+00  6.9055e+00  2e-04  4e-09  4e-09
 6:  6.9057e+00  6.9055e+00  2e-04  2e-08  5e-09
 7:  6.9057e+00  6.9055e+00  2e-04  2e-08  5e-09
 8:  6.9056e+00  6.9055e+00  1e-04  1e-07  4e-08
 9:  6.9056e+00  6.9055e+00  4e-05  1e-07  3e-08
10:  6.9055e+00  6.9055e+00  3e-06  4e-08  1e-08
Optimal solution found.
The calculated probability is:  [2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67756952e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67774733e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67892854e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67543593e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.64091244e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 9.86655103e-01
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67609990e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.65004961e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67904779e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67602272e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05 2.67987305e-05
 2.67987305e-05 2.67987305e-05 2.67987305e-05]
current clients pool:  [INFO][10:11:53]: [Server #554754] Selected clients: [152 256  20  35 238 175 469 246 272 448]
[INFO][10:11:53]: [Server #554754] Selecting client #152 for training.
[INFO][10:11:53]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][10:11:53]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][10:11:53]: [Server #554754] Selecting client #256 for training.
[INFO][10:11:53]: [Server #554754] Sending the current model to client #256 (simulated).
[INFO][10:11:53]: [Server #554754] Sending 0.26 MB of payload data to client #256 (simulated).
[INFO][10:11:53]: [Client #152] Selected by the server.
[INFO][10:11:53]: [Client #152] Loading its data source...
[INFO][10:11:53]: Data source: FEMNIST
[INFO][10:11:53]: [Client #256] Selected by the server.
[INFO][10:11:53]: [Client #256] Loading its data source...
[INFO][10:11:53]: Data source: FEMNIST
[INFO][10:11:53]: [Client #152] Dataset size: 151
[INFO][10:11:53]: [Client #152] Sampler: all_inclusive
[INFO][10:11:53]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:11:53]: [93m[1m[Client #152] Started training in communication round #22.[0m
[INFO][10:11:53]: [Client #256] Dataset size: 310
[INFO][10:11:53]: [Client #256] Sampler: all_inclusive
[INFO][10:11:53]: [Client #256] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:11:53]: [93m[1m[Client #256] Started training in communication round #22.[0m
[INFO][10:11:55]: [Client #152] Loading the dataset.
[INFO][10:11:55]: [Client #256] Loading the dataset.
[INFO][10:12:00]: [Client #152] Epoch: [1/5][0/16]	Loss: 2.054710
[INFO][10:12:00]: [Client #256] Epoch: [1/5][0/31]	Loss: 1.160583
[INFO][10:12:00]: [Client #152] Epoch: [1/5][10/16]	Loss: 0.829927
[INFO][10:12:00]: [Client #256] Epoch: [1/5][10/31]	Loss: 1.273611
[INFO][10:12:00]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:12:00]: [Client #256] Epoch: [1/5][20/31]	Loss: 0.681319
[INFO][10:12:00]: [Client #256] Epoch: [1/5][30/31]	Loss: 0.842887
[INFO][10:12:00]: [Client #256] Going to sleep for 4.84 seconds.
[INFO][10:12:05]: [Client #256] Woke up.
[INFO][10:12:05]: [Client #256] Epoch: [2/5][0/31]	Loss: 1.279282
[INFO][10:12:05]: [Client #256] Epoch: [2/5][10/31]	Loss: 0.760832
[INFO][10:12:05]: [Client #256] Epoch: [2/5][20/31]	Loss: 1.721088
[INFO][10:12:06]: [Client #256] Epoch: [2/5][30/31]	Loss: 1.076401
[INFO][10:12:06]: [Client #256] Going to sleep for 4.84 seconds.
[INFO][10:12:10]: [Client #256] Woke up.
[INFO][10:12:10]: [Client #256] Epoch: [3/5][0/31]	Loss: 0.862083
[INFO][10:12:10]: [Client #256] Epoch: [3/5][10/31]	Loss: 2.490633
[INFO][10:12:11]: [Client #256] Epoch: [3/5][20/31]	Loss: 2.757841
[INFO][10:12:11]: [Client #256] Epoch: [3/5][30/31]	Loss: 0.320180
[INFO][10:12:11]: [Client #256] Going to sleep for 4.84 seconds.
[INFO][10:12:15]: [Client #256] Woke up.
[INFO][10:12:16]: [Client #256] Epoch: [4/5][0/31]	Loss: 0.250987
[INFO][10:12:16]: [Client #256] Epoch: [4/5][10/31]	Loss: 0.968738
[INFO][10:12:16]: [Client #256] Epoch: [4/5][20/31]	Loss: 0.389661
[INFO][10:12:16]: [Client #256] Epoch: [4/5][30/31]	Loss: 0.756054
[INFO][10:12:16]: [Client #256] Going to sleep for 4.84 seconds.
[INFO][10:12:21]: [Client #256] Woke up.
[INFO][10:12:21]: [Client #256] Epoch: [5/5][0/31]	Loss: 1.051686
[INFO][10:12:21]: [Client #256] Epoch: [5/5][10/31]	Loss: 1.048374
[INFO][10:12:21]: [Client #256] Epoch: [5/5][20/31]	Loss: 2.141173
[INFO][10:12:21]: [Client #256] Epoch: [5/5][30/31]	Loss: 1.254317
[INFO][10:12:21]: [Client #256] Going to sleep for 4.84 seconds.
[INFO][10:12:26]: [Client #256] Woke up.
[INFO][10:12:26]: [Client #256] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_256_554860.pth.
[INFO][10:12:26]: [Client #256] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_256_554860.pth.
[INFO][10:12:26]: [Client #256] Model trained.
[INFO][10:12:26]: [Client #256] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:12:26]: [Server #554754] Received 0.26 MB of payload data from client #256 (simulated).
[INFO][10:12:30]: [Client #152] Woke up.
[INFO][10:12:30]: [Client #152] Epoch: [2/5][0/16]	Loss: 0.897100
[INFO][10:12:30]: [Client #152] Epoch: [2/5][10/16]	Loss: 0.855998
[INFO][10:12:30]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:13:00]: [Client #152] Woke up.
[INFO][10:13:00]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.148796
[INFO][10:13:00]: [Client #152] Epoch: [3/5][10/16]	Loss: 0.733821
[INFO][10:13:00]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:13:29]: [Client #152] Woke up.
[INFO][10:13:30]: [Client #152] Epoch: [4/5][0/16]	Loss: 0.965590
[INFO][10:13:30]: [Client #152] Epoch: [4/5][10/16]	Loss: 1.192840
[INFO][10:13:30]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:13:59]: [Client #152] Woke up.
[INFO][10:13:59]: [Client #152] Epoch: [5/5][0/16]	Loss: 2.591627
[INFO][10:13:59]: [Client #152] Epoch: [5/5][10/16]	Loss: 1.799737
[INFO][10:14:00]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:14:29]: [Client #152] Woke up.
[INFO][10:14:29]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:14:30]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:14:30]: [Client #152] Model trained.
[INFO][10:14:30]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:14:30]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][10:14:30]: [Server #554754] Selecting client #20 for training.
[INFO][10:14:30]: [Server #554754] Sending the current model to client #20 (simulated).
[INFO][10:14:30]: [Server #554754] Sending 0.26 MB of payload data to client #20 (simulated).
[INFO][10:14:30]: [Server #554754] Selecting client #35 for training.
[INFO][10:14:30]: [Server #554754] Sending the current model to client #35 (simulated).
[INFO][10:14:30]: [Server #554754] Sending 0.26 MB of payload data to client #35 (simulated).
[INFO][10:14:30]: [Client #20] Selected by the server.
[INFO][10:14:30]: [Client #20] Loading its data source...
[INFO][10:14:30]: Data source: FEMNIST
[INFO][10:14:30]: [Client #35] Selected by the server.
[INFO][10:14:30]: [Client #35] Loading its data source...
[INFO][10:14:30]: Data source: FEMNIST
[INFO][10:14:30]: [Client #20] Dataset size: 144
[INFO][10:14:30]: [Client #20] Sampler: all_inclusive
[INFO][10:14:30]: [Client #20] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:14:30]: [93m[1m[Client #20] Started training in communication round #22.[0m
[INFO][10:14:30]: [Client #35] Dataset size: 147
[INFO][10:14:30]: [Client #35] Sampler: all_inclusive
[INFO][10:14:30]: [Client #35] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:14:30]: [93m[1m[Client #35] Started training in communication round #22.[0m
[INFO][10:14:32]: [Client #20] Loading the dataset.
[INFO][10:14:32]: [Client #35] Loading the dataset.
[INFO][10:14:37]: [Client #20] Epoch: [1/5][0/15]	Loss: 0.065460
[INFO][10:14:37]: [Client #35] Epoch: [1/5][0/15]	Loss: 0.246738
[INFO][10:14:37]: [Client #20] Epoch: [1/5][10/15]	Loss: 2.006716
[INFO][10:14:37]: [Client #35] Epoch: [1/5][10/15]	Loss: 0.794365
[INFO][10:14:38]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][10:14:38]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][10:14:38]: [Client #20] Woke up.
[INFO][10:14:38]: [Client #20] Epoch: [2/5][0/15]	Loss: 0.234784
[INFO][10:14:38]: [Client #20] Epoch: [2/5][10/15]	Loss: 0.989996
[INFO][10:14:38]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][10:14:38]: [Client #20] Woke up.
[INFO][10:14:38]: [Client #20] Epoch: [3/5][0/15]	Loss: 1.335623
[INFO][10:14:38]: [Client #20] Epoch: [3/5][10/15]	Loss: 0.732072
[INFO][10:14:38]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][10:14:39]: [Client #20] Woke up.
[INFO][10:14:39]: [Client #20] Epoch: [4/5][0/15]	Loss: 0.247327
[INFO][10:14:39]: [Client #20] Epoch: [4/5][10/15]	Loss: 0.305487
[INFO][10:14:39]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][10:14:39]: [Client #20] Woke up.
[INFO][10:14:39]: [Client #20] Epoch: [5/5][0/15]	Loss: 0.315624
[INFO][10:14:39]: [Client #20] Epoch: [5/5][10/15]	Loss: 0.662554
[INFO][10:14:39]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][10:14:39]: [Client #20] Woke up.
[INFO][10:14:39]: [Client #20] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_20_554853.pth.
[INFO][10:14:40]: [Client #35] Woke up.
[INFO][10:14:40]: [Client #35] Epoch: [2/5][0/15]	Loss: 0.134435
[INFO][10:14:40]: [Client #35] Epoch: [2/5][10/15]	Loss: 1.634223
[INFO][10:14:40]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][10:14:40]: [Client #20] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_20_554853.pth.
[INFO][10:14:40]: [Client #20] Model trained.
[INFO][10:14:40]: [Client #20] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:14:40]: [Server #554754] Received 0.26 MB of payload data from client #20 (simulated).
[INFO][10:14:42]: [Client #35] Woke up.
[INFO][10:14:42]: [Client #35] Epoch: [3/5][0/15]	Loss: 0.917378
[INFO][10:14:42]: [Client #35] Epoch: [3/5][10/15]	Loss: 1.273935
[INFO][10:14:42]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][10:14:44]: [Client #35] Woke up.
[INFO][10:14:45]: [Client #35] Epoch: [4/5][0/15]	Loss: 0.615714
[INFO][10:14:45]: [Client #35] Epoch: [4/5][10/15]	Loss: 0.703642
[INFO][10:14:45]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][10:14:47]: [Client #35] Woke up.
[INFO][10:14:47]: [Client #35] Epoch: [5/5][0/15]	Loss: 0.238367
[INFO][10:14:47]: [Client #35] Epoch: [5/5][10/15]	Loss: 0.933346
[INFO][10:14:47]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][10:14:49]: [Client #35] Woke up.
[INFO][10:14:49]: [Client #35] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_554860.pth.
[INFO][10:14:50]: [Client #35] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_554860.pth.
[INFO][10:14:50]: [Client #35] Model trained.
[INFO][10:14:50]: [Client #35] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:14:50]: [Server #554754] Received 0.26 MB of payload data from client #35 (simulated).
[INFO][10:14:50]: [Server #554754] Selecting client #238 for training.
[INFO][10:14:50]: [Server #554754] Sending the current model to client #238 (simulated).
[INFO][10:14:50]: [Server #554754] Sending 0.26 MB of payload data to client #238 (simulated).
[INFO][10:14:50]: [Server #554754] Selecting client #175 for training.
[INFO][10:14:50]: [Server #554754] Sending the current model to client #175 (simulated).
[INFO][10:14:50]: [Server #554754] Sending 0.26 MB of payload data to client #175 (simulated).
[INFO][10:14:50]: [Client #175] Selected by the server.
[INFO][10:14:50]: [Client #175] Loading its data source...
[INFO][10:14:50]: Data source: FEMNIST
[INFO][10:14:50]: [Client #238] Selected by the server.
[INFO][10:14:50]: [Client #238] Loading its data source...
[INFO][10:14:50]: Data source: FEMNIST
[INFO][10:14:50]: [Client #175] Dataset size: 145
[INFO][10:14:50]: [Client #175] Sampler: all_inclusive
[INFO][10:14:50]: [Client #175] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:14:50]: [93m[1m[Client #175] Started training in communication round #22.[0m
[INFO][10:14:50]: [Client #238] Dataset size: 144
[INFO][10:14:50]: [Client #238] Sampler: all_inclusive
[INFO][10:14:50]: [Client #238] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:14:50]: [93m[1m[Client #238] Started training in communication round #22.[0m
[INFO][10:14:52]: [Client #175] Loading the dataset.
[INFO][10:14:52]: [Client #238] Loading the dataset.
[INFO][10:14:57]: [Client #175] Epoch: [1/5][0/15]	Loss: 0.697296
[INFO][10:14:58]: [Client #238] Epoch: [1/5][0/15]	Loss: 1.099092
[INFO][10:14:58]: [Client #175] Epoch: [1/5][10/15]	Loss: 1.344926
[INFO][10:14:58]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][10:14:58]: [Client #238] Epoch: [1/5][10/15]	Loss: 0.666846
[INFO][10:14:58]: [Client #238] Going to sleep for 1.46 seconds.
[INFO][10:14:59]: [Client #175] Woke up.
[INFO][10:14:59]: [Client #175] Epoch: [2/5][0/15]	Loss: 0.880271
[INFO][10:14:59]: [Client #175] Epoch: [2/5][10/15]	Loss: 0.943751
[INFO][10:14:59]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][10:14:59]: [Client #238] Woke up.
[INFO][10:14:59]: [Client #238] Epoch: [2/5][0/15]	Loss: 0.588057
[INFO][10:14:59]: [Client #238] Epoch: [2/5][10/15]	Loss: 0.473407
[INFO][10:14:59]: [Client #238] Going to sleep for 1.46 seconds.
[INFO][10:15:00]: [Client #175] Woke up.
[INFO][10:15:00]: [Client #175] Epoch: [3/5][0/15]	Loss: 0.922609
[INFO][10:15:00]: [Client #175] Epoch: [3/5][10/15]	Loss: 0.124327
[INFO][10:15:00]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][10:15:01]: [Client #238] Woke up.
[INFO][10:15:01]: [Client #238] Epoch: [3/5][0/15]	Loss: 0.676510
[INFO][10:15:01]: [Client #238] Epoch: [3/5][10/15]	Loss: 0.404560
[INFO][10:15:01]: [Client #238] Going to sleep for 1.46 seconds.
[INFO][10:15:02]: [Client #175] Woke up.
[INFO][10:15:02]: [Client #175] Epoch: [4/5][0/15]	Loss: 0.493809
[INFO][10:15:02]: [Client #175] Epoch: [4/5][10/15]	Loss: 0.909214
[INFO][10:15:02]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][10:15:02]: [Client #238] Woke up.
[INFO][10:15:02]: [Client #238] Epoch: [4/5][0/15]	Loss: 0.383223
[INFO][10:15:02]: [Client #238] Epoch: [4/5][10/15]	Loss: 0.680408
[INFO][10:15:02]: [Client #238] Going to sleep for 1.46 seconds.
[INFO][10:15:03]: [Client #175] Woke up.
[INFO][10:15:03]: [Client #175] Epoch: [5/5][0/15]	Loss: 0.607733
[INFO][10:15:03]: [Client #175] Epoch: [5/5][10/15]	Loss: 0.689529
[INFO][10:15:03]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][10:15:04]: [Client #238] Woke up.
[INFO][10:15:04]: [Client #238] Epoch: [5/5][0/15]	Loss: 0.406271
[INFO][10:15:04]: [Client #238] Epoch: [5/5][10/15]	Loss: 0.828684
[INFO][10:15:04]: [Client #238] Going to sleep for 1.46 seconds.
[INFO][10:15:04]: [Client #175] Woke up.
[INFO][10:15:04]: [Client #175] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554860.pth.
[INFO][10:15:05]: [Client #175] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554860.pth.
[INFO][10:15:05]: [Client #175] Model trained.
[INFO][10:15:05]: [Client #175] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:15:05]: [Server #554754] Received 0.26 MB of payload data from client #175 (simulated).
[INFO][10:15:06]: [Client #238] Woke up.
[INFO][10:15:06]: [Client #238] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_238_554853.pth.
[INFO][10:15:06]: [Client #238] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_238_554853.pth.
[INFO][10:15:06]: [Client #238] Model trained.
[INFO][10:15:06]: [Client #238] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:15:06]: [Server #554754] Received 0.26 MB of payload data from client #238 (simulated).
[INFO][10:15:06]: [Server #554754] Selecting client #469 for training.
[INFO][10:15:06]: [Server #554754] Sending the current model to client #469 (simulated).
[INFO][10:15:06]: [Server #554754] Sending 0.26 MB of payload data to client #469 (simulated).
[INFO][10:15:06]: [Server #554754] Selecting client #246 for training.
[INFO][10:15:06]: [Server #554754] Sending the current model to client #246 (simulated).
[INFO][10:15:06]: [Server #554754] Sending 0.26 MB of payload data to client #246 (simulated).
[INFO][10:15:06]: [Client #469] Selected by the server.
[INFO][10:15:06]: [Client #469] Loading its data source...
[INFO][10:15:06]: Data source: FEMNIST
[INFO][10:15:06]: [Client #246] Selected by the server.
[INFO][10:15:06]: [Client #246] Loading its data source...
[INFO][10:15:06]: Data source: FEMNIST
[INFO][10:15:06]: [Client #246] Dataset size: 135
[INFO][10:15:06]: [Client #246] Sampler: all_inclusive
[INFO][10:15:06]: [Client #469] Dataset size: 163
[INFO][10:15:06]: [Client #469] Sampler: all_inclusive
[INFO][10:15:06]: [Client #246] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:15:06]: [Client #469] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:15:06]: [93m[1m[Client #246] Started training in communication round #22.[0m
[INFO][10:15:06]: [93m[1m[Client #469] Started training in communication round #22.[0m
[INFO][10:15:08]: [Client #246] Loading the dataset.
[INFO][10:15:08]: [Client #469] Loading the dataset.
[INFO][10:15:14]: [Client #246] Epoch: [1/5][0/14]	Loss: 0.102227
[INFO][10:15:14]: [Client #469] Epoch: [1/5][0/17]	Loss: 0.302520
[INFO][10:15:14]: [Client #246] Epoch: [1/5][10/14]	Loss: 0.428626
[INFO][10:15:14]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][10:15:14]: [Client #469] Epoch: [1/5][10/17]	Loss: 0.377423
[INFO][10:15:14]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][10:15:15]: [Client #469] Woke up.
[INFO][10:15:15]: [Client #469] Epoch: [2/5][0/17]	Loss: 1.285874
[INFO][10:15:15]: [Client #469] Epoch: [2/5][10/17]	Loss: 0.388999
[INFO][10:15:15]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][10:15:15]: [Client #246] Woke up.
[INFO][10:15:15]: [Client #246] Epoch: [2/5][0/14]	Loss: 0.355325
[INFO][10:15:15]: [Client #246] Epoch: [2/5][10/14]	Loss: 0.337567
[INFO][10:15:15]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][10:15:16]: [Client #469] Woke up.
[INFO][10:15:16]: [Client #469] Epoch: [3/5][0/17]	Loss: 0.268426
[INFO][10:15:16]: [Client #469] Epoch: [3/5][10/17]	Loss: 0.333069
[INFO][10:15:17]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][10:15:17]: [Client #246] Woke up.
[INFO][10:15:17]: [Client #246] Epoch: [3/5][0/14]	Loss: 0.248229
[INFO][10:15:17]: [Client #246] Epoch: [3/5][10/14]	Loss: 0.072923
[INFO][10:15:17]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][10:15:18]: [Client #469] Woke up.
[INFO][10:15:18]: [Client #469] Epoch: [4/5][0/17]	Loss: 0.528491
[INFO][10:15:18]: [Client #469] Epoch: [4/5][10/17]	Loss: 0.466496
[INFO][10:15:18]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][10:15:19]: [Client #246] Woke up.
[INFO][10:15:19]: [Client #246] Epoch: [4/5][0/14]	Loss: 0.209550
[INFO][10:15:19]: [Client #246] Epoch: [4/5][10/14]	Loss: 0.679291
[INFO][10:15:19]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][10:15:19]: [Client #469] Woke up.
[INFO][10:15:19]: [Client #469] Epoch: [5/5][0/17]	Loss: 0.381609
[INFO][10:15:19]: [Client #469] Epoch: [5/5][10/17]	Loss: 0.452099
[INFO][10:15:19]: [Client #469] Going to sleep for 1.14 seconds.
[INFO][10:15:20]: [Client #469] Woke up.
[INFO][10:15:20]: [Client #469] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_554853.pth.
[INFO][10:15:20]: [Client #246] Woke up.
[INFO][10:15:21]: [Client #246] Epoch: [5/5][0/14]	Loss: 0.795002
[INFO][10:15:21]: [Client #246] Epoch: [5/5][10/14]	Loss: 0.016614
[INFO][10:15:21]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][10:15:21]: [Client #469] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_469_554853.pth.
[INFO][10:15:21]: [Client #469] Model trained.
[INFO][10:15:21]: [Client #469] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:15:21]: [Server #554754] Received 0.26 MB of payload data from client #469 (simulated).
[INFO][10:15:22]: [Client #246] Woke up.
[INFO][10:15:22]: [Client #246] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_246_554860.pth.
[INFO][10:15:23]: [Client #246] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_246_554860.pth.
[INFO][10:15:23]: [Client #246] Model trained.
[INFO][10:15:23]: [Client #246] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:15:23]: [Server #554754] Received 0.26 MB of payload data from client #246 (simulated).
[INFO][10:15:23]: [Server #554754] Selecting client #272 for training.
[INFO][10:15:23]: [Server #554754] Sending the current model to client #272 (simulated).
[INFO][10:15:23]: [Server #554754] Sending 0.26 MB of payload data to client #272 (simulated).
[INFO][10:15:23]: [Server #554754] Selecting client #448 for training.
[INFO][10:15:23]: [Server #554754] Sending the current model to client #448 (simulated).
[INFO][10:15:23]: [Server #554754] Sending 0.26 MB of payload data to client #448 (simulated).
[INFO][10:15:23]: [Client #272] Selected by the server.
[INFO][10:15:23]: [Client #272] Loading its data source...
[INFO][10:15:23]: [Client #448] Selected by the server.
[INFO][10:15:23]: Data source: FEMNIST
[INFO][10:15:23]: [Client #448] Loading its data source...
[INFO][10:15:23]: Data source: FEMNIST
[INFO][10:15:23]: [Client #272] Dataset size: 145
[INFO][10:15:23]: [Client #272] Sampler: all_inclusive
[INFO][10:15:23]: [Client #448] Dataset size: 149
[INFO][10:15:23]: [Client #448] Sampler: all_inclusive
[INFO][10:15:23]: [Client #272] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:15:23]: [Client #448] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:15:23]: [93m[1m[Client #448] Started training in communication round #22.[0m
[INFO][10:15:23]: [93m[1m[Client #272] Started training in communication round #22.[0m
[INFO][10:15:25]: [Client #272] Loading the dataset.
[INFO][10:15:25]: [Client #448] Loading the dataset.
[INFO][10:15:30]: [Client #272] Epoch: [1/5][0/15]	Loss: 1.453353
[INFO][10:15:30]: [Client #448] Epoch: [1/5][0/15]	Loss: 0.810153
[INFO][10:15:30]: [Client #272] Epoch: [1/5][10/15]	Loss: 0.084897
[INFO][10:15:30]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][10:15:30]: [Client #448] Epoch: [1/5][10/15]	Loss: 1.517618
[INFO][10:15:30]: [Client #448] Going to sleep for 10.80 seconds.
[INFO][10:15:31]: [Client #272] Woke up.
[INFO][10:15:31]: [Client #272] Epoch: [2/5][0/15]	Loss: 0.644615
[INFO][10:15:31]: [Client #272] Epoch: [2/5][10/15]	Loss: 1.654632
[INFO][10:15:31]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][10:15:31]: [Client #272] Woke up.
[INFO][10:15:32]: [Client #272] Epoch: [3/5][0/15]	Loss: 0.891882
[INFO][10:15:32]: [Client #272] Epoch: [3/5][10/15]	Loss: 0.921284
[INFO][10:15:32]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][10:15:32]: [Client #272] Woke up.
[INFO][10:15:32]: [Client #272] Epoch: [4/5][0/15]	Loss: 1.277311
[INFO][10:15:32]: [Client #272] Epoch: [4/5][10/15]	Loss: 1.236682
[INFO][10:15:32]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][10:15:33]: [Client #272] Woke up.
[INFO][10:15:33]: [Client #272] Epoch: [5/5][0/15]	Loss: 1.249499
[INFO][10:15:33]: [Client #272] Epoch: [5/5][10/15]	Loss: 0.557227
[INFO][10:15:33]: [Client #272] Going to sleep for 0.46 seconds.
[INFO][10:15:33]: [Client #272] Woke up.
[INFO][10:15:33]: [Client #272] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_272_554853.pth.
[INFO][10:15:34]: [Client #272] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_272_554853.pth.
[INFO][10:15:34]: [Client #272] Model trained.
[INFO][10:15:34]: [Client #272] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:15:34]: [Server #554754] Received 0.26 MB of payload data from client #272 (simulated).
[INFO][10:15:41]: [Client #448] Woke up.
[INFO][10:15:41]: [Client #448] Epoch: [2/5][0/15]	Loss: 1.389991
[INFO][10:15:41]: [Client #448] Epoch: [2/5][10/15]	Loss: 2.254937
[INFO][10:15:41]: [Client #448] Going to sleep for 10.80 seconds.
[INFO][10:15:52]: [Client #448] Woke up.
[INFO][10:15:52]: [Client #448] Epoch: [3/5][0/15]	Loss: 0.664454
[INFO][10:15:52]: [Client #448] Epoch: [3/5][10/15]	Loss: 1.000162
[INFO][10:15:52]: [Client #448] Going to sleep for 10.80 seconds.
[INFO][10:16:03]: [Client #448] Woke up.
[INFO][10:16:03]: [Client #448] Epoch: [4/5][0/15]	Loss: 0.606105
[INFO][10:16:03]: [Client #448] Epoch: [4/5][10/15]	Loss: 0.694613
[INFO][10:16:03]: [Client #448] Going to sleep for 10.80 seconds.
[INFO][10:16:14]: [Client #448] Woke up.
[INFO][10:16:14]: [Client #448] Epoch: [5/5][0/15]	Loss: 0.897279
[INFO][10:16:14]: [Client #448] Epoch: [5/5][10/15]	Loss: 0.583489
[INFO][10:16:14]: [Client #448] Going to sleep for 10.80 seconds.
[INFO][10:16:25]: [Client #448] Woke up.
[INFO][10:16:25]: [Client #448] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_448_554860.pth.
[INFO][10:16:26]: [Client #448] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_448_554860.pth.
[INFO][10:16:26]: [Client #448] Model trained.
[INFO][10:16:26]: [Client #448] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:16:26]: [Server #554754] Received 0.26 MB of payload data from client #448 (simulated).
[INFO][10:16:26]: [Server #554754] Adding client #20 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #272 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #469 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #175 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #238 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #246 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #35 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #256 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Adding client #448 to the list of clients for aggregation.
[INFO][10:16:26]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0839508  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12346897 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08106801 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15608499 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08217844 0.         0.
 0.         0.         0.         0.         0.         0.12338047
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20426145 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15093143 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07325868 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09172145 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0839508  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12346897 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08106801 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15608499 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08217844 0.         0.
 0.         0.         0.         0.         0.         0.12338047
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.20426145 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15093143 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07325868 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09172145 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:17:10]: [Server #554754] Global model accuracy: 61.56%

[INFO][10:17:10]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_22.pth.
[INFO][10:17:10]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_22.pth.
[INFO][10:17:10]: [93m[1m
[Server #554754] Starting round 23/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.002      0.08769793 0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.002      0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.002      0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08105207 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.09744214 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.002
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.002      0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.002      0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.002      0.09342784 0.10621762
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.002      0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.07344332 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  4e-09  6e-10
 7:  6.9057e+00  6.9056e+00  1e-04  5e-09  7e-10
 8:  6.9057e+00  6.9056e+00  8e-05  5e-08  8e-09
 9:  6.9056e+00  6.9056e+00  4e-05  5e-08  8e-09
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  6e-09
Optimal solution found.
The calculated probability is:  [4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72137664e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.71773768e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72153489e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 9.76474231e-01 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72149795e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.71876935e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.64569278e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.71477231e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72191299e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.71983970e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05 4.72428177e-05
 4.72428177e-05 4.72428177e-05 4.72428177e-05]
current clients pool:  [INFO][10:17:10]: [Server #554754] Selected clients: [212 436 118 194 287 264  38 438 476 407]
[INFO][10:17:10]: [Server #554754] Selecting client #212 for training.
[INFO][10:17:10]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][10:17:10]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][10:17:10]: [Server #554754] Selecting client #436 for training.
[INFO][10:17:10]: [Server #554754] Sending the current model to client #436 (simulated).
[INFO][10:17:10]: [Server #554754] Sending 0.26 MB of payload data to client #436 (simulated).
[INFO][10:17:10]: [Client #212] Selected by the server.
[INFO][10:17:10]: [Client #212] Loading its data source...
[INFO][10:17:10]: Data source: FEMNIST
[INFO][10:17:10]: [Client #436] Selected by the server.
[INFO][10:17:10]: [Client #436] Loading its data source...
[INFO][10:17:10]: Data source: FEMNIST
[INFO][10:17:10]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:17:10]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/436.zip.
[INFO][10:17:10]: [Client #212] Dataset size: 160
[INFO][10:17:10]: [Client #212] Sampler: all_inclusive
[INFO][10:17:10]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:17:10]: [93m[1m[Client #212] Started training in communication round #23.[0m

3.0%
6.0%
9.1%
12.1%
15.1%
18.1%
21.1%
24.1%
27.2%
30.2%
33.2%
36.2%
39.2%
42.3%
45.3%
48.3%
51.3%
54.3%
57.3%
60.4%
63.4%
66.4%
69.4%
72.4%
75.5%
78.5%
81.5%
84.5%
87.5%
90.5%
93.6%
96.6%
99.6%
100.0%[INFO][10:17:10]: Decompressing the dataset downloaded.
[INFO][10:17:10]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/436.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:17:10]: [Client #436] Dataset size: 158
[INFO][10:17:10]: [Client #436] Sampler: all_inclusive
[INFO][10:17:10]: [Client #436] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:17:10]: [93m[1m[Client #436] Started training in communication round #23.[0m

[INFO][10:17:12]: [Client #212] Loading the dataset.
[INFO][10:17:12]: [Client #436] Loading the dataset.
[INFO][10:17:18]: [Client #212] Epoch: [1/5][0/16]	Loss: 2.250867
[INFO][10:17:18]: [Client #212] Epoch: [1/5][10/16]	Loss: 0.716292
[INFO][10:17:18]: [Client #436] Epoch: [1/5][0/16]	Loss: 0.099685
[INFO][10:17:18]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:17:18]: [Client #436] Epoch: [1/5][10/16]	Loss: 1.444190
[INFO][10:17:18]: [Client #436] Going to sleep for 0.67 seconds.
[INFO][10:17:18]: [Client #436] Woke up.
[INFO][10:17:18]: [Client #436] Epoch: [2/5][0/16]	Loss: 0.713739
[INFO][10:17:19]: [Client #436] Epoch: [2/5][10/16]	Loss: 0.454606
[INFO][10:17:19]: [Client #436] Going to sleep for 0.67 seconds.
[INFO][10:17:19]: [Client #436] Woke up.
[INFO][10:17:19]: [Client #436] Epoch: [3/5][0/16]	Loss: 1.032724
[INFO][10:17:19]: [Client #436] Epoch: [3/5][10/16]	Loss: 0.406651
[INFO][10:17:19]: [Client #436] Going to sleep for 0.67 seconds.
[INFO][10:17:20]: [Client #436] Woke up.
[INFO][10:17:20]: [Client #436] Epoch: [4/5][0/16]	Loss: 0.602335
[INFO][10:17:20]: [Client #436] Epoch: [4/5][10/16]	Loss: 0.542574
[INFO][10:17:20]: [Client #436] Going to sleep for 0.67 seconds.
[INFO][10:17:21]: [Client #436] Woke up.
[INFO][10:17:21]: [Client #436] Epoch: [5/5][0/16]	Loss: 0.479050
[INFO][10:17:21]: [Client #436] Epoch: [5/5][10/16]	Loss: 0.721333
[INFO][10:17:21]: [Client #436] Going to sleep for 0.67 seconds.
[INFO][10:17:22]: [Client #436] Woke up.
[INFO][10:17:22]: [Client #436] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_436_554860.pth.
[INFO][10:17:22]: [Client #436] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_436_554860.pth.
[INFO][10:17:22]: [Client #436] Model trained.
[INFO][10:17:22]: [Client #436] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:17:22]: [Server #554754] Received 0.26 MB of payload data from client #436 (simulated).
[INFO][10:17:44]: [Client #212] Woke up.
[INFO][10:17:44]: [Client #212] Epoch: [2/5][0/16]	Loss: 1.226836
[INFO][10:17:44]: [Client #212] Epoch: [2/5][10/16]	Loss: 1.851979
[INFO][10:17:44]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:18:10]: [Client #212] Woke up.
[INFO][10:18:11]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.938965
[INFO][10:18:11]: [Client #212] Epoch: [3/5][10/16]	Loss: 0.564426
[INFO][10:18:11]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:18:37]: [Client #212] Woke up.
[INFO][10:18:37]: [Client #212] Epoch: [4/5][0/16]	Loss: 1.178104
[INFO][10:18:37]: [Client #212] Epoch: [4/5][10/16]	Loss: 0.859215
[INFO][10:18:37]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:19:03]: [Client #212] Woke up.
[INFO][10:19:03]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.393544
[INFO][10:19:04]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.516280
[INFO][10:19:04]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:19:30]: [Client #212] Woke up.
[INFO][10:19:30]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:19:31]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:19:31]: [Client #212] Model trained.
[INFO][10:19:31]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:19:31]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][10:19:31]: [Server #554754] Selecting client #118 for training.
[INFO][10:19:31]: [Server #554754] Sending the current model to client #118 (simulated).
[INFO][10:19:31]: [Server #554754] Sending 0.26 MB of payload data to client #118 (simulated).
[INFO][10:19:31]: [Server #554754] Selecting client #194 for training.
[INFO][10:19:31]: [Server #554754] Sending the current model to client #194 (simulated).
[INFO][10:19:31]: [Server #554754] Sending 0.26 MB of payload data to client #194 (simulated).
[INFO][10:19:31]: [Client #118] Selected by the server.
[INFO][10:19:31]: [Client #118] Loading its data source...
[INFO][10:19:31]: Data source: FEMNIST
[INFO][10:19:31]: [Client #194] Selected by the server.
[INFO][10:19:31]: [Client #194] Loading its data source...
[INFO][10:19:31]: Data source: FEMNIST
[INFO][10:19:31]: [Client #118] Dataset size: 154
[INFO][10:19:31]: [Client #118] Sampler: all_inclusive
[INFO][10:19:31]: [Client #118] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:19:31]: [93m[1m[Client #118] Started training in communication round #23.[0m
[INFO][10:19:31]: [Client #194] Dataset size: 158
[INFO][10:19:31]: [Client #194] Sampler: all_inclusive
[INFO][10:19:31]: [Client #194] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:19:31]: [93m[1m[Client #194] Started training in communication round #23.[0m
[INFO][10:19:33]: [Client #118] Loading the dataset.
[INFO][10:19:33]: [Client #194] Loading the dataset.
[INFO][10:19:38]: [Client #118] Epoch: [1/5][0/16]	Loss: 2.414060
[INFO][10:19:38]: [Client #194] Epoch: [1/5][0/16]	Loss: 0.525422
[INFO][10:19:38]: [Client #118] Epoch: [1/5][10/16]	Loss: 1.773507
[INFO][10:19:38]: [Client #194] Epoch: [1/5][10/16]	Loss: 1.003134
[INFO][10:19:38]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][10:19:38]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][10:19:41]: [Client #194] Woke up.
[INFO][10:19:41]: [Client #194] Epoch: [2/5][0/16]	Loss: 0.523801
[INFO][10:19:42]: [Client #194] Epoch: [2/5][10/16]	Loss: 0.640865
[INFO][10:19:42]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][10:19:45]: [Client #194] Woke up.
[INFO][10:19:45]: [Client #194] Epoch: [3/5][0/16]	Loss: 0.571812
[INFO][10:19:45]: [Client #194] Epoch: [3/5][10/16]	Loss: 0.681124
[INFO][10:19:45]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][10:19:49]: [Client #194] Woke up.
[INFO][10:19:49]: [Client #194] Epoch: [4/5][0/16]	Loss: 0.647478
[INFO][10:19:49]: [Client #194] Epoch: [4/5][10/16]	Loss: 0.517660
[INFO][10:19:49]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][10:19:50]: [Client #118] Woke up.
[INFO][10:19:50]: [Client #118] Epoch: [2/5][0/16]	Loss: 0.272113
[INFO][10:19:50]: [Client #118] Epoch: [2/5][10/16]	Loss: 1.290314
[INFO][10:19:50]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][10:19:52]: [Client #194] Woke up.
[INFO][10:19:52]: [Client #194] Epoch: [5/5][0/16]	Loss: 0.348144
[INFO][10:19:52]: [Client #194] Epoch: [5/5][10/16]	Loss: 0.730421
[INFO][10:19:52]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][10:19:56]: [Client #194] Woke up.
[INFO][10:19:56]: [Client #194] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_554860.pth.
[INFO][10:19:56]: [Client #194] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_554860.pth.
[INFO][10:19:56]: [Client #194] Model trained.
[INFO][10:19:56]: [Client #194] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:19:56]: [Server #554754] Received 0.26 MB of payload data from client #194 (simulated).
[INFO][10:20:02]: [Client #118] Woke up.
[INFO][10:20:02]: [Client #118] Epoch: [3/5][0/16]	Loss: 0.834766
[INFO][10:20:02]: [Client #118] Epoch: [3/5][10/16]	Loss: 0.383542
[INFO][10:20:02]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][10:20:14]: [Client #118] Woke up.
[INFO][10:20:14]: [Client #118] Epoch: [4/5][0/16]	Loss: 0.518924
[INFO][10:20:14]: [Client #118] Epoch: [4/5][10/16]	Loss: 0.955683
[INFO][10:20:14]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][10:20:26]: [Client #118] Woke up.
[INFO][10:20:26]: [Client #118] Epoch: [5/5][0/16]	Loss: 0.068397
[INFO][10:20:27]: [Client #118] Epoch: [5/5][10/16]	Loss: 0.533220
[INFO][10:20:27]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][10:20:39]: [Client #118] Woke up.
[INFO][10:20:39]: [Client #118] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_118_554853.pth.
[INFO][10:20:39]: [Client #118] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_118_554853.pth.
[INFO][10:20:39]: [Client #118] Model trained.
[INFO][10:20:39]: [Client #118] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:20:39]: [Server #554754] Received 0.26 MB of payload data from client #118 (simulated).
[INFO][10:20:39]: [Server #554754] Selecting client #287 for training.
[INFO][10:20:39]: [Server #554754] Sending the current model to client #287 (simulated).
[INFO][10:20:39]: [Server #554754] Sending 0.26 MB of payload data to client #287 (simulated).
[INFO][10:20:39]: [Server #554754] Selecting client #264 for training.
[INFO][10:20:39]: [Server #554754] Sending the current model to client #264 (simulated).
[INFO][10:20:39]: [Server #554754] Sending 0.26 MB of payload data to client #264 (simulated).
[INFO][10:20:39]: [Client #287] Selected by the server.
[INFO][10:20:39]: [Client #287] Loading its data source...
[INFO][10:20:39]: Data source: FEMNIST
[INFO][10:20:39]: [Client #264] Selected by the server.
[INFO][10:20:39]: [Client #264] Loading its data source...
[INFO][10:20:39]: Data source: FEMNIST
[INFO][10:20:39]: [Client #264] Dataset size: 164
[INFO][10:20:39]: [Client #264] Sampler: all_inclusive
[INFO][10:20:39]: [Client #264] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:20:39]: [93m[1m[Client #264] Started training in communication round #23.[0m
[INFO][10:20:39]: [Client #287] Dataset size: 162
[INFO][10:20:39]: [Client #287] Sampler: all_inclusive
[INFO][10:20:39]: [Client #287] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:20:39]: [93m[1m[Client #287] Started training in communication round #23.[0m
[INFO][10:20:41]: [Client #287] Loading the dataset.
[INFO][10:20:41]: [Client #264] Loading the dataset.
[INFO][10:20:47]: [Client #287] Epoch: [1/5][0/17]	Loss: 0.594179
[INFO][10:20:47]: [Client #264] Epoch: [1/5][0/17]	Loss: 1.737214
[INFO][10:20:47]: [Client #287] Epoch: [1/5][10/17]	Loss: 1.233621
[INFO][10:20:47]: [Client #264] Epoch: [1/5][10/17]	Loss: 0.640780
[INFO][10:20:47]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][10:20:47]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][10:20:48]: [Client #287] Woke up.
[INFO][10:20:48]: [Client #287] Epoch: [2/5][0/17]	Loss: 0.196119
[INFO][10:20:48]: [Client #287] Epoch: [2/5][10/17]	Loss: 0.024454
[INFO][10:20:48]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][10:20:49]: [Client #264] Woke up.
[INFO][10:20:49]: [Client #264] Epoch: [2/5][0/17]	Loss: 1.033992
[INFO][10:20:49]: [Client #287] Woke up.
[INFO][10:20:49]: [Client #287] Epoch: [3/5][0/17]	Loss: 0.110064
[INFO][10:20:49]: [Client #264] Epoch: [2/5][10/17]	Loss: 0.916486
[INFO][10:20:49]: [Client #287] Epoch: [3/5][10/17]	Loss: 0.585013
[INFO][10:20:49]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][10:20:49]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][10:20:50]: [Client #287] Woke up.
[INFO][10:20:50]: [Client #287] Epoch: [4/5][0/17]	Loss: 0.593026
[INFO][10:20:51]: [Client #287] Epoch: [4/5][10/17]	Loss: 1.533379
[INFO][10:20:51]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][10:20:52]: [Client #264] Woke up.
[INFO][10:20:52]: [Client #264] Epoch: [3/5][0/17]	Loss: 0.447632
[INFO][10:20:52]: [Client #287] Woke up.
[INFO][10:20:52]: [Client #287] Epoch: [5/5][0/17]	Loss: 0.259733
[INFO][10:20:52]: [Client #264] Epoch: [3/5][10/17]	Loss: 1.682991
[INFO][10:20:52]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][10:20:52]: [Client #287] Epoch: [5/5][10/17]	Loss: 0.884358
[INFO][10:20:52]: [Client #287] Going to sleep for 1.12 seconds.
[INFO][10:20:53]: [Client #287] Woke up.
[INFO][10:20:53]: [Client #287] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_287_554853.pth.
[INFO][10:20:54]: [Client #287] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_287_554853.pth.
[INFO][10:20:54]: [Client #287] Model trained.
[INFO][10:20:54]: [Client #287] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:20:54]: [Server #554754] Received 0.26 MB of payload data from client #287 (simulated).
[INFO][10:20:54]: [Client #264] Woke up.
[INFO][10:20:54]: [Client #264] Epoch: [4/5][0/17]	Loss: 0.399600
[INFO][10:20:54]: [Client #264] Epoch: [4/5][10/17]	Loss: 1.284077
[INFO][10:20:54]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][10:20:57]: [Client #264] Woke up.
[INFO][10:20:57]: [Client #264] Epoch: [5/5][0/17]	Loss: 0.384064
[INFO][10:20:57]: [Client #264] Epoch: [5/5][10/17]	Loss: 0.868687
[INFO][10:20:57]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][10:20:59]: [Client #264] Woke up.
[INFO][10:20:59]: [Client #264] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_264_554860.pth.
[INFO][10:21:00]: [Client #264] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_264_554860.pth.
[INFO][10:21:00]: [Client #264] Model trained.
[INFO][10:21:00]: [Client #264] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:21:00]: [Server #554754] Received 0.26 MB of payload data from client #264 (simulated).
[INFO][10:21:00]: [Server #554754] Selecting client #38 for training.
[INFO][10:21:00]: [Server #554754] Sending the current model to client #38 (simulated).
[INFO][10:21:00]: [Server #554754] Sending 0.26 MB of payload data to client #38 (simulated).
[INFO][10:21:00]: [Server #554754] Selecting client #438 for training.
[INFO][10:21:00]: [Server #554754] Sending the current model to client #438 (simulated).
[INFO][10:21:00]: [Server #554754] Sending 0.26 MB of payload data to client #438 (simulated).
[INFO][10:21:00]: [Client #438] Selected by the server.
[INFO][10:21:00]: [Client #438] Loading its data source...
[INFO][10:21:00]: Data source: FEMNIST
[INFO][10:21:00]: [Client #38] Selected by the server.
[INFO][10:21:00]: [Client #38] Loading its data source...
[INFO][10:21:00]: Data source: FEMNIST
[INFO][10:21:00]: [Client #438] Dataset size: 164
[INFO][10:21:00]: [Client #438] Sampler: all_inclusive
[INFO][10:21:00]: [Client #438] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:21:00]: [93m[1m[Client #438] Started training in communication round #23.[0m
[INFO][10:21:00]: [Client #38] Dataset size: 162
[INFO][10:21:00]: [Client #38] Sampler: all_inclusive
[INFO][10:21:00]: [Client #38] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:21:00]: [93m[1m[Client #38] Started training in communication round #23.[0m
[INFO][10:21:02]: [Client #38] Loading the dataset.
[INFO][10:21:02]: [Client #438] Loading the dataset.
[INFO][10:21:07]: [Client #38] Epoch: [1/5][0/17]	Loss: 1.730755
[INFO][10:21:07]: [Client #438] Epoch: [1/5][0/17]	Loss: 0.631468
[INFO][10:21:07]: [Client #38] Epoch: [1/5][10/17]	Loss: 0.955222
[INFO][10:21:07]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][10:21:07]: [Client #438] Epoch: [1/5][10/17]	Loss: 1.370787
[INFO][10:21:07]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][10:21:07]: [Client #438] Woke up.
[INFO][10:21:07]: [Client #438] Epoch: [2/5][0/17]	Loss: 0.119133
[INFO][10:21:08]: [Client #438] Epoch: [2/5][10/17]	Loss: 0.733050
[INFO][10:21:08]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][10:21:08]: [Client #438] Woke up.
[INFO][10:21:08]: [Client #438] Epoch: [3/5][0/17]	Loss: 0.295677
[INFO][10:21:08]: [Client #438] Epoch: [3/5][10/17]	Loss: 0.253823
[INFO][10:21:08]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][10:21:08]: [Client #438] Woke up.
[INFO][10:21:08]: [Client #438] Epoch: [4/5][0/17]	Loss: 0.591041
[INFO][10:21:08]: [Client #438] Epoch: [4/5][10/17]	Loss: 0.360638
[INFO][10:21:08]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][10:21:08]: [Client #438] Woke up.
[INFO][10:21:08]: [Client #438] Epoch: [5/5][0/17]	Loss: 0.675302
[INFO][10:21:08]: [Client #438] Epoch: [5/5][10/17]	Loss: 0.785889
[INFO][10:21:08]: [Client #438] Going to sleep for 0.04 seconds.
[INFO][10:21:08]: [Client #438] Woke up.
[INFO][10:21:08]: [Client #438] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_438_554860.pth.
[INFO][10:21:09]: [Client #438] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_438_554860.pth.
[INFO][10:21:09]: [Client #438] Model trained.
[INFO][10:21:09]: [Client #438] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:21:09]: [Server #554754] Received 0.26 MB of payload data from client #438 (simulated).
[INFO][10:21:12]: [Client #38] Woke up.
[INFO][10:21:12]: [Client #38] Epoch: [2/5][0/17]	Loss: 0.695899
[INFO][10:21:12]: [Client #38] Epoch: [2/5][10/17]	Loss: 0.503260
[INFO][10:21:12]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][10:21:18]: [Client #38] Woke up.
[INFO][10:21:18]: [Client #38] Epoch: [3/5][0/17]	Loss: 0.077148
[INFO][10:21:18]: [Client #38] Epoch: [3/5][10/17]	Loss: 0.722929
[INFO][10:21:18]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][10:21:23]: [Client #38] Woke up.
[INFO][10:21:23]: [Client #38] Epoch: [4/5][0/17]	Loss: 0.533857
[INFO][10:21:23]: [Client #38] Epoch: [4/5][10/17]	Loss: 0.928375
[INFO][10:21:23]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][10:21:28]: [Client #38] Woke up.
[INFO][10:21:28]: [Client #38] Epoch: [5/5][0/17]	Loss: 0.396306
[INFO][10:21:28]: [Client #38] Epoch: [5/5][10/17]	Loss: 1.543110
[INFO][10:21:28]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][10:21:33]: [Client #38] Woke up.
[INFO][10:21:33]: [Client #38] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_554853.pth.
[INFO][10:21:34]: [Client #38] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_554853.pth.
[INFO][10:21:34]: [Client #38] Model trained.
[INFO][10:21:34]: [Client #38] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:21:34]: [Server #554754] Received 0.26 MB of payload data from client #38 (simulated).
[INFO][10:21:34]: [Server #554754] Selecting client #476 for training.
[INFO][10:21:34]: [Server #554754] Sending the current model to client #476 (simulated).
[INFO][10:21:34]: [Server #554754] Sending 0.26 MB of payload data to client #476 (simulated).
[INFO][10:21:34]: [Server #554754] Selecting client #407 for training.
[INFO][10:21:34]: [Server #554754] Sending the current model to client #407 (simulated).
[INFO][10:21:34]: [Server #554754] Sending 0.26 MB of payload data to client #407 (simulated).
[INFO][10:21:34]: [Client #476] Selected by the server.
[INFO][10:21:34]: [Client #476] Loading its data source...
[INFO][10:21:34]: Data source: FEMNIST
[INFO][10:21:34]: [Client #407] Selected by the server.
[INFO][10:21:34]: [Client #407] Loading its data source...
[INFO][10:21:34]: Data source: FEMNIST
[INFO][10:21:34]: [Client #476] Dataset size: 138
[INFO][10:21:34]: [Client #476] Sampler: all_inclusive
[INFO][10:21:34]: [Client #407] Dataset size: 159
[INFO][10:21:34]: [Client #407] Sampler: all_inclusive
[INFO][10:21:34]: [Client #476] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:21:34]: [Client #407] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:21:34]: [93m[1m[Client #476] Started training in communication round #23.[0m
[INFO][10:21:34]: [93m[1m[Client #407] Started training in communication round #23.[0m
[INFO][10:21:36]: [Client #476] Loading the dataset.
[INFO][10:21:36]: [Client #407] Loading the dataset.
[INFO][10:21:41]: [Client #476] Epoch: [1/5][0/14]	Loss: 1.711680
[INFO][10:21:41]: [Client #407] Epoch: [1/5][0/16]	Loss: 1.195832
[INFO][10:21:41]: [Client #476] Epoch: [1/5][10/14]	Loss: 1.000634
[INFO][10:21:41]: [Client #407] Epoch: [1/5][10/16]	Loss: 0.846260
[INFO][10:21:41]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][10:21:41]: [Client #476] Woke up.
[INFO][10:21:41]: [Client #476] Epoch: [2/5][0/14]	Loss: 0.395325
[INFO][10:21:41]: [Client #407] Going to sleep for 0.28 seconds.
[INFO][10:21:41]: [Client #476] Epoch: [2/5][10/14]	Loss: 0.524369
[INFO][10:21:41]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][10:21:42]: [Client #476] Woke up.
[INFO][10:21:42]: [Client #476] Epoch: [3/5][0/14]	Loss: 0.319909
[INFO][10:21:42]: [Client #476] Epoch: [3/5][10/14]	Loss: 0.653005
[INFO][10:21:42]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][10:21:42]: [Client #407] Woke up.
[INFO][10:21:42]: [Client #476] Woke up.
[INFO][10:21:42]: [Client #407] Epoch: [2/5][0/16]	Loss: 1.096561
[INFO][10:21:42]: [Client #476] Epoch: [4/5][0/14]	Loss: 0.522309
[INFO][10:21:42]: [Client #476] Epoch: [4/5][10/14]	Loss: 0.055559
[INFO][10:21:42]: [Client #407] Epoch: [2/5][10/16]	Loss: 1.093092
[INFO][10:21:42]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][10:21:42]: [Client #407] Going to sleep for 0.28 seconds.
[INFO][10:21:42]: [Client #476] Woke up.
[INFO][10:21:42]: [Client #476] Epoch: [5/5][0/14]	Loss: 0.341229
[INFO][10:21:42]: [Client #476] Epoch: [5/5][10/14]	Loss: 1.290629
[INFO][10:21:42]: [Client #476] Going to sleep for 0.03 seconds.
[INFO][10:21:42]: [Client #476] Woke up.
[INFO][10:21:42]: [Client #476] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_554853.pth.
[INFO][10:21:42]: [Client #407] Woke up.
[INFO][10:21:42]: [Client #407] Epoch: [3/5][0/16]	Loss: 0.543059
[INFO][10:21:42]: [Client #407] Epoch: [3/5][10/16]	Loss: 1.292563
[INFO][10:21:42]: [Client #407] Going to sleep for 0.28 seconds.
[INFO][10:21:43]: [Client #407] Woke up.
[INFO][10:21:43]: [Client #407] Epoch: [4/5][0/16]	Loss: 0.564908
[INFO][10:21:43]: [Client #476] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_476_554853.pth.
[INFO][10:21:43]: [Client #476] Model trained.
[INFO][10:21:43]: [Client #476] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:21:43]: [Server #554754] Received 0.26 MB of payload data from client #476 (simulated).
[INFO][10:21:43]: [Client #407] Epoch: [4/5][10/16]	Loss: 1.438187
[INFO][10:21:43]: [Client #407] Going to sleep for 0.28 seconds.
[INFO][10:21:43]: [Client #407] Woke up.
[INFO][10:21:43]: [Client #407] Epoch: [5/5][0/16]	Loss: 1.381458
[INFO][10:21:43]: [Client #407] Epoch: [5/5][10/16]	Loss: 0.343787
[INFO][10:21:43]: [Client #407] Going to sleep for 0.28 seconds.
[INFO][10:21:43]: [Client #407] Woke up.
[INFO][10:21:43]: [Client #407] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_407_554860.pth.
[INFO][10:21:44]: [Client #407] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_407_554860.pth.
[INFO][10:21:44]: [Client #407] Model trained.
[INFO][10:21:44]: [Client #407] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:21:44]: [Server #554754] Received 0.26 MB of payload data from client #407 (simulated).
[INFO][10:21:44]: [Server #554754] Adding client #476 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #438 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #407 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #436 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #287 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #264 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #194 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #38 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #118 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][10:21:44]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13481336 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11575147 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.51587802 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06365235 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1905196
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21346778 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09480388 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08518356 0.         0.08956028
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07393594 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13481336 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11575147 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.51587802 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06365235 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1905196
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21346778 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09480388 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08518356 0.         0.08956028
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07393594 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:22:28]: [Server #554754] Global model accuracy: 60.52%

[INFO][10:22:28]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_23.pth.
[INFO][10:22:28]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_23.pth.
[INFO][10:22:28]: [93m[1m
[Server #554754] Starting round 24/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.002      0.08769793 0.002      0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.08598028 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.09808917 0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09617834 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.09744214 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10280971 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.002
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.04720745 0.002
 0.002      0.10192308 0.002      0.002      0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09342784 0.1044586
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.002      0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.08789809 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9057e+00  6.9039e+00  2e-03  3e-08  3e-08
 5:  6.9057e+00  6.9043e+00  1e-03  2e-08  2e-08
 6:  6.9056e+00  6.9041e+00  1e-03  7e-07  1e-06
 7:  6.9055e+00  6.9046e+00  9e-04  5e-07  8e-07
 8:  6.9053e+00  6.9048e+00  5e-04  1e-06  2e-06
 9:  6.9051e+00  6.9050e+00  2e-04  2e-06  3e-06
10:  6.9050e+00  6.9050e+00  7e-05  1e-06  2e-06
11:  6.9050e+00  6.9050e+00  1e-05  3e-07  5e-07
12:  6.9050e+00  6.9050e+00  7e-07  2e-08  4e-08
Optimal solution found.
The calculated probability is:  [4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60374226e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60561909e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 9.97704579e-01
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60817425e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.59786399e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.59528161e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60668681e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60723033e-06 4.60936807e-06
 4.60682230e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60813933e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06 4.60936807e-06
 4.60936807e-06 4.60936807e-06 4.60936807e-06]
current clients pool:  [INFO][10:22:29]: [Server #554754] Selected clients: [152 446 377 382 236 105  21 162  19 348]
[INFO][10:22:29]: [Server #554754] Selecting client #152 for training.
[INFO][10:22:29]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][10:22:29]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][10:22:29]: [Server #554754] Selecting client #446 for training.
[INFO][10:22:29]: [Server #554754] Sending the current model to client #446 (simulated).
[INFO][10:22:29]: [Server #554754] Sending 0.26 MB of payload data to client #446 (simulated).
[INFO][10:22:29]: [Client #152] Selected by the server.
[INFO][10:22:29]: [Client #152] Loading its data source...
[INFO][10:22:29]: Data source: FEMNIST
[INFO][10:22:29]: [Client #446] Selected by the server.
[INFO][10:22:29]: [Client #446] Loading its data source...
[INFO][10:22:29]: Data source: FEMNIST
[INFO][10:22:29]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:22:29]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/446.zip.
[INFO][10:22:29]: [Client #152] Dataset size: 151
[INFO][10:22:29]: [Client #152] Sampler: all_inclusive
[INFO][10:22:29]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:22:29]: [93m[1m[Client #152] Started training in communication round #24.[0m

2.6%
5.3%
7.9%
10.6%
13.2%
15.9%
18.5%
21.2%
23.8%
26.5%
29.1%
31.8%
34.4%
37.1%
39.7%
42.4%
45.0%
47.7%
50.3%
53.0%
55.6%
58.3%
60.9%
63.6%
66.2%
68.9%
71.5%
74.2%
76.8%
79.5%
82.1%
84.8%
87.4%
90.1%
92.7%
95.4%
98.0%
100.0%[INFO][10:22:29]: Decompressing the dataset downloaded.
[INFO][10:22:29]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/446.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:22:29]: [Client #446] Dataset size: 162
[INFO][10:22:29]: [Client #446] Sampler: all_inclusive
[INFO][10:22:29]: [Client #446] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:22:29]: [93m[1m[Client #446] Started training in communication round #24.[0m

[INFO][10:22:31]: [Client #152] Loading the dataset.
[INFO][10:22:31]: [Client #446] Loading the dataset.
[INFO][10:22:37]: [Client #152] Epoch: [1/5][0/16]	Loss: 2.417670
[INFO][10:22:37]: [Client #446] Epoch: [1/5][0/17]	Loss: 0.885481
[INFO][10:22:37]: [Client #152] Epoch: [1/5][10/16]	Loss: 1.290788
[INFO][10:22:37]: [Client #446] Epoch: [1/5][10/17]	Loss: 0.991883
[INFO][10:22:37]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:22:37]: [Client #446] Going to sleep for 9.57 seconds.
[INFO][10:22:46]: [Client #446] Woke up.
[INFO][10:22:46]: [Client #446] Epoch: [2/5][0/17]	Loss: 0.421269
[INFO][10:22:46]: [Client #446] Epoch: [2/5][10/17]	Loss: 1.068319
[INFO][10:22:46]: [Client #446] Going to sleep for 9.57 seconds.
[INFO][10:22:56]: [Client #446] Woke up.
[INFO][10:22:56]: [Client #446] Epoch: [3/5][0/17]	Loss: 0.578462
[INFO][10:22:56]: [Client #446] Epoch: [3/5][10/17]	Loss: 0.951466
[INFO][10:22:56]: [Client #446] Going to sleep for 9.57 seconds.
[INFO][10:23:06]: [Client #446] Woke up.
[INFO][10:23:06]: [Client #446] Epoch: [4/5][0/17]	Loss: 0.677259
[INFO][10:23:06]: [Client #446] Epoch: [4/5][10/17]	Loss: 1.594112
[INFO][10:23:06]: [Client #446] Going to sleep for 9.57 seconds.
[INFO][10:23:06]: [Client #152] Woke up.
[INFO][10:23:06]: [Client #152] Epoch: [2/5][0/16]	Loss: 2.142221
[INFO][10:23:06]: [Client #152] Epoch: [2/5][10/16]	Loss: 2.314452
[INFO][10:23:06]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:23:15]: [Client #446] Woke up.
[INFO][10:23:15]: [Client #446] Epoch: [5/5][0/17]	Loss: 0.962290
[INFO][10:23:16]: [Client #446] Epoch: [5/5][10/17]	Loss: 1.217909
[INFO][10:23:16]: [Client #446] Going to sleep for 9.57 seconds.
[INFO][10:23:25]: [Client #446] Woke up.
[INFO][10:23:25]: [Client #446] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_446_554860.pth.
[INFO][10:23:26]: [Client #446] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_446_554860.pth.
[INFO][10:23:26]: [Client #446] Model trained.
[INFO][10:23:26]: [Client #446] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:23:26]: [Server #554754] Received 0.26 MB of payload data from client #446 (simulated).
[INFO][10:23:36]: [Client #152] Woke up.
[INFO][10:23:36]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.951205
[INFO][10:23:36]: [Client #152] Epoch: [3/5][10/16]	Loss: 1.439033
[INFO][10:23:36]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:24:06]: [Client #152] Woke up.
[INFO][10:24:06]: [Client #152] Epoch: [4/5][0/16]	Loss: 1.256278
[INFO][10:24:06]: [Client #152] Epoch: [4/5][10/16]	Loss: 1.682578
[INFO][10:24:06]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:24:36]: [Client #152] Woke up.
[INFO][10:24:36]: [Client #152] Epoch: [5/5][0/16]	Loss: 1.111462
[INFO][10:24:36]: [Client #152] Epoch: [5/5][10/16]	Loss: 1.992236
[INFO][10:24:36]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:25:06]: [Client #152] Woke up.
[INFO][10:25:06]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:25:06]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:25:06]: [Client #152] Model trained.
[INFO][10:25:06]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:25:06]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][10:25:06]: [Server #554754] Selecting client #377 for training.
[INFO][10:25:06]: [Server #554754] Sending the current model to client #377 (simulated).
[INFO][10:25:06]: [Server #554754] Sending 0.26 MB of payload data to client #377 (simulated).
[INFO][10:25:06]: [Server #554754] Selecting client #382 for training.
[INFO][10:25:06]: [Server #554754] Sending the current model to client #382 (simulated).
[INFO][10:25:06]: [Server #554754] Sending 0.26 MB of payload data to client #382 (simulated).
[INFO][10:25:06]: [Client #377] Selected by the server.
[INFO][10:25:06]: [Client #377] Loading its data source...
[INFO][10:25:06]: Data source: FEMNIST
[INFO][10:25:06]: [Client #382] Selected by the server.
[INFO][10:25:06]: [Client #382] Loading its data source...
[INFO][10:25:06]: Data source: FEMNIST
[INFO][10:25:06]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:25:06]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/382.zip.
[INFO][10:25:06]: [Client #377] Dataset size: 142
[INFO][10:25:06]: [Client #377] Sampler: all_inclusive
[INFO][10:25:06]: [Client #377] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:25:06]: [93m[1m[Client #377] Started training in communication round #24.[0m

2.5%
5.0%
7.5%
10.0%
12.5%
15.0%
17.5%
20.0%
22.5%
25.0%
27.5%
30.0%
32.5%
35.0%
37.5%
40.0%
42.5%
45.0%
47.6%
50.1%
52.6%
55.1%
57.6%
60.1%
62.6%
65.1%
67.6%
70.1%
72.6%
75.1%
77.6%
80.1%
82.6%
85.1%
87.6%
90.1%
92.6%
95.1%
97.6%
100.0%[INFO][10:25:07]: Decompressing the dataset downloaded.
[INFO][10:25:07]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/382.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:25:07]: [Client #382] Dataset size: 165
[INFO][10:25:07]: [Client #382] Sampler: all_inclusive
[INFO][10:25:07]: [Client #382] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:25:07]: [93m[1m[Client #382] Started training in communication round #24.[0m

[INFO][10:25:08]: [Client #377] Loading the dataset.
[INFO][10:25:08]: [Client #382] Loading the dataset.
[INFO][10:25:14]: [Client #377] Epoch: [1/5][0/15]	Loss: 0.691593
[INFO][10:25:14]: [Client #382] Epoch: [1/5][0/17]	Loss: 1.189802
[INFO][10:25:14]: [Client #377] Epoch: [1/5][10/15]	Loss: 0.652950
[INFO][10:25:14]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][10:25:14]: [Client #382] Epoch: [1/5][10/17]	Loss: 1.441334
[INFO][10:25:14]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][10:25:15]: [Client #382] Woke up.
[INFO][10:25:15]: [Client #382] Epoch: [2/5][0/17]	Loss: 1.276533
[INFO][10:25:15]: [Client #382] Epoch: [2/5][10/17]	Loss: 0.594020
[INFO][10:25:15]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][10:25:17]: [Client #382] Woke up.
[INFO][10:25:17]: [Client #382] Epoch: [3/5][0/17]	Loss: 0.380954
[INFO][10:25:17]: [Client #382] Epoch: [3/5][10/17]	Loss: 0.512056
[INFO][10:25:17]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][10:25:18]: [Client #382] Woke up.
[INFO][10:25:18]: [Client #382] Epoch: [4/5][0/17]	Loss: 0.651542
[INFO][10:25:18]: [Client #382] Epoch: [4/5][10/17]	Loss: 0.087905
[INFO][10:25:19]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][10:25:20]: [Client #382] Woke up.
[INFO][10:25:20]: [Client #382] Epoch: [5/5][0/17]	Loss: 0.160084
[INFO][10:25:20]: [Client #382] Epoch: [5/5][10/17]	Loss: 0.725408
[INFO][10:25:20]: [Client #382] Going to sleep for 1.39 seconds.
[INFO][10:25:20]: [Client #377] Woke up.
[INFO][10:25:20]: [Client #377] Epoch: [2/5][0/15]	Loss: 1.514455
[INFO][10:25:20]: [Client #377] Epoch: [2/5][10/15]	Loss: 1.311775
[INFO][10:25:20]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][10:25:21]: [Client #382] Woke up.
[INFO][10:25:21]: [Client #382] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_382_554860.pth.
[INFO][10:25:22]: [Client #382] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_382_554860.pth.
[INFO][10:25:22]: [Client #382] Model trained.
[INFO][10:25:22]: [Client #382] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:25:22]: [Server #554754] Received 0.26 MB of payload data from client #382 (simulated).
[INFO][10:25:26]: [Client #377] Woke up.
[INFO][10:25:26]: [Client #377] Epoch: [3/5][0/15]	Loss: 0.312074
[INFO][10:25:27]: [Client #377] Epoch: [3/5][10/15]	Loss: 0.939585
[INFO][10:25:27]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][10:25:33]: [Client #377] Woke up.
[INFO][10:25:33]: [Client #377] Epoch: [4/5][0/15]	Loss: 0.939153
[INFO][10:25:33]: [Client #377] Epoch: [4/5][10/15]	Loss: 0.935566
[INFO][10:25:33]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][10:25:39]: [Client #377] Woke up.
[INFO][10:25:39]: [Client #377] Epoch: [5/5][0/15]	Loss: 0.847269
[INFO][10:25:39]: [Client #377] Epoch: [5/5][10/15]	Loss: 1.114678
[INFO][10:25:39]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][10:25:46]: [Client #377] Woke up.
[INFO][10:25:46]: [Client #377] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][10:25:46]: [Client #377] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][10:25:46]: [Client #377] Model trained.
[INFO][10:25:46]: [Client #377] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:25:46]: [Server #554754] Received 0.26 MB of payload data from client #377 (simulated).
[INFO][10:25:46]: [Server #554754] Selecting client #236 for training.
[INFO][10:25:46]: [Server #554754] Sending the current model to client #236 (simulated).
[INFO][10:25:46]: [Server #554754] Sending 0.26 MB of payload data to client #236 (simulated).
[INFO][10:25:46]: [Server #554754] Selecting client #105 for training.
[INFO][10:25:46]: [Server #554754] Sending the current model to client #105 (simulated).
[INFO][10:25:46]: [Server #554754] Sending 0.26 MB of payload data to client #105 (simulated).
[INFO][10:25:46]: [Client #236] Selected by the server.
[INFO][10:25:46]: [Client #236] Loading its data source...
[INFO][10:25:46]: Data source: FEMNIST
[INFO][10:25:46]: [Client #105] Selected by the server.
[INFO][10:25:46]: [Client #105] Loading its data source...
[INFO][10:25:46]: Data source: FEMNIST
[INFO][10:25:46]: [Client #236] Dataset size: 161
[INFO][10:25:46]: [Client #236] Sampler: all_inclusive
[INFO][10:25:46]: [Client #105] Dataset size: 157
[INFO][10:25:46]: [Client #105] Sampler: all_inclusive
[INFO][10:25:46]: [Client #236] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:25:46]: [Client #105] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:25:46]: [93m[1m[Client #236] Started training in communication round #24.[0m
[INFO][10:25:46]: [93m[1m[Client #105] Started training in communication round #24.[0m
[INFO][10:25:48]: [Client #105] Loading the dataset.
[INFO][10:25:48]: [Client #236] Loading the dataset.
[INFO][10:25:54]: [Client #105] Epoch: [1/5][0/16]	Loss: 1.168861
[INFO][10:25:54]: [Client #236] Epoch: [1/5][0/17]	Loss: 1.258615
[INFO][10:25:54]: [Client #105] Epoch: [1/5][10/16]	Loss: 0.884691
[INFO][10:25:54]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][10:25:54]: [Client #236] Epoch: [1/5][10/17]	Loss: 0.378371
[INFO][10:25:54]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][10:25:56]: [Client #236] Woke up.
[INFO][10:25:56]: [Client #236] Epoch: [2/5][0/17]	Loss: 0.189945
[INFO][10:25:56]: [Client #236] Epoch: [2/5][10/17]	Loss: 0.677983
[INFO][10:25:56]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][10:25:57]: [Client #236] Woke up.
[INFO][10:25:57]: [Client #236] Epoch: [3/5][0/17]	Loss: 1.533490
[INFO][10:25:57]: [Client #236] Epoch: [3/5][10/17]	Loss: 1.491694
[INFO][10:25:57]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][10:25:59]: [Client #236] Woke up.
[INFO][10:25:59]: [Client #236] Epoch: [4/5][0/17]	Loss: 0.756807
[INFO][10:25:59]: [Client #236] Epoch: [4/5][10/17]	Loss: 0.276744
[INFO][10:25:59]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][10:26:01]: [Client #236] Woke up.
[INFO][10:26:01]: [Client #236] Epoch: [5/5][0/17]	Loss: 0.766259
[INFO][10:26:01]: [Client #236] Epoch: [5/5][10/17]	Loss: 2.271682
[INFO][10:26:01]: [Client #236] Going to sleep for 1.49 seconds.
[INFO][10:26:02]: [Client #236] Woke up.
[INFO][10:26:02]: [Client #236] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554853.pth.
[INFO][10:26:03]: [Client #236] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_236_554853.pth.
[INFO][10:26:03]: [Client #236] Model trained.
[INFO][10:26:03]: [Client #236] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:26:03]: [Server #554754] Received 0.26 MB of payload data from client #236 (simulated).
[INFO][10:26:04]: [Client #105] Woke up.
[INFO][10:26:04]: [Client #105] Epoch: [2/5][0/16]	Loss: 1.184746
[INFO][10:26:04]: [Client #105] Epoch: [2/5][10/16]	Loss: 0.547140
[INFO][10:26:04]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][10:26:14]: [Client #105] Woke up.
[INFO][10:26:14]: [Client #105] Epoch: [3/5][0/16]	Loss: 0.594197
[INFO][10:26:14]: [Client #105] Epoch: [3/5][10/16]	Loss: 0.706818
[INFO][10:26:14]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][10:26:24]: [Client #105] Woke up.
[INFO][10:26:24]: [Client #105] Epoch: [4/5][0/16]	Loss: 0.101486
[INFO][10:26:24]: [Client #105] Epoch: [4/5][10/16]	Loss: 0.460186
[INFO][10:26:24]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][10:26:34]: [Client #105] Woke up.
[INFO][10:26:34]: [Client #105] Epoch: [5/5][0/16]	Loss: 1.210849
[INFO][10:26:34]: [Client #105] Epoch: [5/5][10/16]	Loss: 1.066419
[INFO][10:26:34]: [Client #105] Going to sleep for 9.93 seconds.
[INFO][10:26:44]: [Client #105] Woke up.
[INFO][10:26:44]: [Client #105] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_105_554860.pth.
[INFO][10:26:45]: [Client #105] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_105_554860.pth.
[INFO][10:26:45]: [Client #105] Model trained.
[INFO][10:26:45]: [Client #105] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:26:45]: [Server #554754] Received 0.26 MB of payload data from client #105 (simulated).
[INFO][10:26:45]: [Server #554754] Selecting client #21 for training.
[INFO][10:26:45]: [Server #554754] Sending the current model to client #21 (simulated).
[INFO][10:26:45]: [Server #554754] Sending 0.26 MB of payload data to client #21 (simulated).
[INFO][10:26:45]: [Server #554754] Selecting client #162 for training.
[INFO][10:26:45]: [Server #554754] Sending the current model to client #162 (simulated).
[INFO][10:26:45]: [Server #554754] Sending 0.26 MB of payload data to client #162 (simulated).
[INFO][10:26:45]: [Client #162] Selected by the server.
[INFO][10:26:45]: [Client #21] Selected by the server.
[INFO][10:26:45]: [Client #162] Loading its data source...
[INFO][10:26:45]: [Client #21] Loading its data source...
[INFO][10:26:45]: Data source: FEMNIST
[INFO][10:26:45]: Data source: FEMNIST
[INFO][10:26:45]: [Client #21] Dataset size: 151
[INFO][10:26:45]: [Client #21] Sampler: all_inclusive
[INFO][10:26:45]: [Client #162] Dataset size: 159
[INFO][10:26:45]: [Client #162] Sampler: all_inclusive
[INFO][10:26:45]: [Client #21] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:26:45]: [Client #162] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:26:45]: [93m[1m[Client #21] Started training in communication round #24.[0m
[INFO][10:26:45]: [93m[1m[Client #162] Started training in communication round #24.[0m
[INFO][10:26:47]: [Client #21] Loading the dataset.
[INFO][10:26:47]: [Client #162] Loading the dataset.
[INFO][10:26:52]: [Client #21] Epoch: [1/5][0/16]	Loss: 1.668665
[INFO][10:26:52]: [Client #162] Epoch: [1/5][0/16]	Loss: 1.436867
[INFO][10:26:52]: [Client #21] Epoch: [1/5][10/16]	Loss: 1.242427
[INFO][10:26:53]: [Client #21] Going to sleep for 4.02 seconds.
[INFO][10:26:53]: [Client #162] Epoch: [1/5][10/16]	Loss: 0.284429
[INFO][10:26:53]: [Client #162] Going to sleep for 0.98 seconds.
[INFO][10:26:54]: [Client #162] Woke up.
[INFO][10:26:54]: [Client #162] Epoch: [2/5][0/16]	Loss: 1.108345
[INFO][10:26:54]: [Client #162] Epoch: [2/5][10/16]	Loss: 0.080178
[INFO][10:26:54]: [Client #162] Going to sleep for 0.98 seconds.
[INFO][10:26:55]: [Client #162] Woke up.
[INFO][10:26:55]: [Client #162] Epoch: [3/5][0/16]	Loss: 1.128866
[INFO][10:26:55]: [Client #162] Epoch: [3/5][10/16]	Loss: 0.261115
[INFO][10:26:55]: [Client #162] Going to sleep for 0.98 seconds.
[INFO][10:26:56]: [Client #162] Woke up.
[INFO][10:26:56]: [Client #162] Epoch: [4/5][0/16]	Loss: 0.743772
[INFO][10:26:56]: [Client #162] Epoch: [4/5][10/16]	Loss: 0.839661
[INFO][10:26:56]: [Client #162] Going to sleep for 0.98 seconds.
[INFO][10:26:57]: [Client #21] Woke up.
[INFO][10:26:57]: [Client #21] Epoch: [2/5][0/16]	Loss: 0.921903
[INFO][10:26:57]: [Client #21] Epoch: [2/5][10/16]	Loss: 0.773958
[INFO][10:26:57]: [Client #21] Going to sleep for 4.02 seconds.
[INFO][10:26:57]: [Client #162] Woke up.
[INFO][10:26:57]: [Client #162] Epoch: [5/5][0/16]	Loss: 0.595627
[INFO][10:26:57]: [Client #162] Epoch: [5/5][10/16]	Loss: 0.246393
[INFO][10:26:57]: [Client #162] Going to sleep for 0.98 seconds.
[INFO][10:26:58]: [Client #162] Woke up.
[INFO][10:26:58]: [Client #162] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_162_554860.pth.
[INFO][10:26:59]: [Client #162] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_162_554860.pth.
[INFO][10:26:59]: [Client #162] Model trained.
[INFO][10:26:59]: [Client #162] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:26:59]: [Server #554754] Received 0.26 MB of payload data from client #162 (simulated).
[INFO][10:27:01]: [Client #21] Woke up.
[INFO][10:27:01]: [Client #21] Epoch: [3/5][0/16]	Loss: 1.016015
[INFO][10:27:01]: [Client #21] Epoch: [3/5][10/16]	Loss: 1.899589
[INFO][10:27:01]: [Client #21] Going to sleep for 4.02 seconds.
[INFO][10:27:05]: [Client #21] Woke up.
[INFO][10:27:05]: [Client #21] Epoch: [4/5][0/16]	Loss: 1.351332
[INFO][10:27:05]: [Client #21] Epoch: [4/5][10/16]	Loss: 1.088105
[INFO][10:27:05]: [Client #21] Going to sleep for 4.02 seconds.
[INFO][10:27:09]: [Client #21] Woke up.
[INFO][10:27:09]: [Client #21] Epoch: [5/5][0/16]	Loss: 0.599031
[INFO][10:27:09]: [Client #21] Epoch: [5/5][10/16]	Loss: 0.990433
[INFO][10:27:09]: [Client #21] Going to sleep for 4.02 seconds.
[INFO][10:27:13]: [Client #21] Woke up.
[INFO][10:27:13]: [Client #21] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_21_554853.pth.
[INFO][10:27:14]: [Client #21] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_21_554853.pth.
[INFO][10:27:14]: [Client #21] Model trained.
[INFO][10:27:14]: [Client #21] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:27:14]: [Server #554754] Received 0.26 MB of payload data from client #21 (simulated).
[INFO][10:27:14]: [Server #554754] Selecting client #19 for training.
[INFO][10:27:14]: [Server #554754] Sending the current model to client #19 (simulated).
[INFO][10:27:14]: [Server #554754] Sending 0.26 MB of payload data to client #19 (simulated).
[INFO][10:27:14]: [Server #554754] Selecting client #348 for training.
[INFO][10:27:14]: [Server #554754] Sending the current model to client #348 (simulated).
[INFO][10:27:14]: [Server #554754] Sending 0.26 MB of payload data to client #348 (simulated).
[INFO][10:27:14]: [Client #19] Selected by the server.
[INFO][10:27:14]: [Client #19] Loading its data source...
[INFO][10:27:14]: Data source: FEMNIST
[INFO][10:27:14]: [Client #348] Selected by the server.
[INFO][10:27:14]: [Client #348] Loading its data source...
[INFO][10:27:14]: Data source: FEMNIST
[INFO][10:27:14]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:27:14]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/348.zip.
[INFO][10:27:14]: [Client #19] Dataset size: 144
[INFO][10:27:14]: [Client #19] Sampler: all_inclusive
[INFO][10:27:14]: [Client #19] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:27:14]: [93m[1m[Client #19] Started training in communication round #24.[0m

2.9%
5.9%
8.8%
11.8%
14.7%
17.6%
20.6%
23.5%
26.5%
29.4%
32.3%
35.3%
38.2%
41.2%
44.1%
47.0%
50.0%
52.9%
55.8%
58.8%
61.7%
64.7%
67.6%
70.5%
73.5%
76.4%
79.4%
82.3%
85.2%
88.2%
91.1%
94.1%
97.0%
99.9%
100.0%[INFO][10:27:14]: Decompressing the dataset downloaded.
[INFO][10:27:14]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/348.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:27:14]: [Client #348] Dataset size: 163
[INFO][10:27:14]: [Client #348] Sampler: all_inclusive
[INFO][10:27:14]: [Client #348] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:27:14]: [93m[1m[Client #348] Started training in communication round #24.[0m

[INFO][10:27:16]: [Client #19] Loading the dataset.
[INFO][10:27:16]: [Client #348] Loading the dataset.
[INFO][10:27:21]: [Client #19] Epoch: [1/5][0/15]	Loss: 0.831452
[INFO][10:27:21]: [Client #19] Epoch: [1/5][10/15]	Loss: 1.084730
[INFO][10:27:21]: [Client #348] Epoch: [1/5][0/17]	Loss: 1.852477
[INFO][10:27:21]: [Client #19] Going to sleep for 0.16 seconds.
[INFO][10:27:21]: [Client #348] Epoch: [1/5][10/17]	Loss: 0.274660
[INFO][10:27:21]: [Client #348] Going to sleep for 1.57 seconds.
[INFO][10:27:22]: [Client #19] Woke up.
[INFO][10:27:22]: [Client #19] Epoch: [2/5][0/15]	Loss: 0.165599
[INFO][10:27:22]: [Client #19] Epoch: [2/5][10/15]	Loss: 0.890572
[INFO][10:27:22]: [Client #19] Going to sleep for 0.16 seconds.
[INFO][10:27:22]: [Client #19] Woke up.
[INFO][10:27:22]: [Client #19] Epoch: [3/5][0/15]	Loss: 0.490630
[INFO][10:27:22]: [Client #19] Epoch: [3/5][10/15]	Loss: 0.626540
[INFO][10:27:22]: [Client #19] Going to sleep for 0.16 seconds.
[INFO][10:27:22]: [Client #19] Woke up.
[INFO][10:27:22]: [Client #19] Epoch: [4/5][0/15]	Loss: 0.714128
[INFO][10:27:22]: [Client #19] Epoch: [4/5][10/15]	Loss: 0.922984
[INFO][10:27:22]: [Client #19] Going to sleep for 0.16 seconds.
[INFO][10:27:22]: [Client #19] Woke up.
[INFO][10:27:22]: [Client #19] Epoch: [5/5][0/15]	Loss: 0.437270
[INFO][10:27:23]: [Client #19] Epoch: [5/5][10/15]	Loss: 0.405864
[INFO][10:27:23]: [Client #19] Going to sleep for 0.16 seconds.
[INFO][10:27:23]: [Client #19] Woke up.
[INFO][10:27:23]: [Client #19] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_19_554853.pth.
[INFO][10:27:23]: [Client #348] Woke up.
[INFO][10:27:23]: [Client #348] Epoch: [2/5][0/17]	Loss: 0.741117
[INFO][10:27:23]: [Client #348] Epoch: [2/5][10/17]	Loss: 0.307013
[INFO][10:27:23]: [Client #348] Going to sleep for 1.57 seconds.
[INFO][10:27:23]: [Client #19] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_19_554853.pth.
[INFO][10:27:23]: [Client #19] Model trained.
[INFO][10:27:23]: [Client #19] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:27:23]: [Server #554754] Received 0.26 MB of payload data from client #19 (simulated).
[INFO][10:27:25]: [Client #348] Woke up.
[INFO][10:27:25]: [Client #348] Epoch: [3/5][0/17]	Loss: 0.940739
[INFO][10:27:25]: [Client #348] Epoch: [3/5][10/17]	Loss: 0.676995
[INFO][10:27:25]: [Client #348] Going to sleep for 1.57 seconds.
[INFO][10:27:26]: [Client #348] Woke up.
[INFO][10:27:26]: [Client #348] Epoch: [4/5][0/17]	Loss: 0.965627
[INFO][10:27:27]: [Client #348] Epoch: [4/5][10/17]	Loss: 0.204514
[INFO][10:27:27]: [Client #348] Going to sleep for 1.57 seconds.
[INFO][10:27:28]: [Client #348] Woke up.
[INFO][10:27:28]: [Client #348] Epoch: [5/5][0/17]	Loss: 0.685547
[INFO][10:27:28]: [Client #348] Epoch: [5/5][10/17]	Loss: 0.022040
[INFO][10:27:28]: [Client #348] Going to sleep for 1.57 seconds.
[INFO][10:27:30]: [Client #348] Woke up.
[INFO][10:27:30]: [Client #348] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_348_554860.pth.
[INFO][10:27:31]: [Client #348] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_348_554860.pth.
[INFO][10:27:31]: [Client #348] Model trained.
[INFO][10:27:31]: [Client #348] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:27:31]: [Server #554754] Received 0.26 MB of payload data from client #348 (simulated).
[INFO][10:27:31]: [Server #554754] Adding client #19 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #162 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #382 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #348 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #236 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #21 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #377 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #446 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Adding client #105 to the list of clients for aggregation.
[INFO][10:27:31]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11855168 0.         1.0596857  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08750734 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09634491
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14287753 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.36582273 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12201232
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21305801 0.
 0.         0.         0.         0.11444891 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16272965 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11855168 0.         1.0596857  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08750734 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09634491
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14287753 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.36582273 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12201232
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.21305801 0.
 0.         0.         0.         0.11444891 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16272965 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:28:21]: [Server #554754] Global model accuracy: 59.00%

[INFO][10:28:21]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_24.pth.
[INFO][10:28:21]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_24.pth.
[INFO][10:28:21]: [93m[1m
[Server #554754] Starting round 25/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.002      0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.09808917 0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09617834 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.10230179 0.002      0.002      0.10373711 0.04717531
 0.002      0.002      0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.002      0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10631443
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.002      0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.002      0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.09079284 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.002
 0.09144543 0.08543264 0.09231217 0.002      0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.002      0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09342784 0.1044586
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.08789809 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  3e-09  4e-10
 7:  6.9057e+00  6.9056e+00  1e-04  3e-09  5e-10
 8:  6.9057e+00  6.9056e+00  7e-05  4e-08  6e-09
 9:  6.9057e+00  6.9056e+00  4e-05  4e-08  6e-09
10:  6.9056e+00  6.9056e+00  3e-06  3e-08  5e-09
Optimal solution found.
The calculated probability is:  [5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.12366785e-05 5.13093899e-05
 4.55526508e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.12622767e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.12508274e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 9.74455301e-01 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.04555999e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.12107506e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.10816341e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.12204429e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.11363001e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05 5.13093899e-05
 5.13093899e-05 5.13093899e-05 5.13093899e-05]
current clients pool:  [INFO][10:28:22]: [Server #554754] Selected clients: [212 258 310 218 425 229   8 437 329 412]
[INFO][10:28:22]: [Server #554754] Selecting client #212 for training.
[INFO][10:28:22]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][10:28:22]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][10:28:22]: [Server #554754] Selecting client #258 for training.
[INFO][10:28:22]: [Server #554754] Sending the current model to client #258 (simulated).
[INFO][10:28:22]: [Server #554754] Sending 0.26 MB of payload data to client #258 (simulated).
[INFO][10:28:22]: [Client #212] Selected by the server.
[INFO][10:28:22]: [Client #212] Loading its data source...
[INFO][10:28:22]: Data source: FEMNIST
[INFO][10:28:22]: [Client #258] Selected by the server.
[INFO][10:28:22]: [Client #258] Loading its data source...
[INFO][10:28:22]: Data source: FEMNIST
[INFO][10:28:22]: [Client #258] Dataset size: 165
[INFO][10:28:22]: [Client #258] Sampler: all_inclusive
[INFO][10:28:22]: [Client #258] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:28:22]: [93m[1m[Client #258] Started training in communication round #25.[0m
[INFO][10:28:22]: [Client #212] Dataset size: 160
[INFO][10:28:22]: [Client #212] Sampler: all_inclusive
[INFO][10:28:22]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:28:22]: [93m[1m[Client #212] Started training in communication round #25.[0m
[INFO][10:28:24]: [Client #212] Loading the dataset.
[INFO][10:28:24]: [Client #258] Loading the dataset.
[INFO][10:28:29]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.262972
[INFO][10:28:29]: [Client #258] Epoch: [1/5][0/17]	Loss: 0.367592
[INFO][10:28:29]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.469537
[INFO][10:28:30]: [Client #258] Epoch: [1/5][10/17]	Loss: 0.548409
[INFO][10:28:30]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:28:30]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][10:28:31]: [Client #258] Woke up.
[INFO][10:28:31]: [Client #258] Epoch: [2/5][0/17]	Loss: 1.041547
[INFO][10:28:31]: [Client #258] Epoch: [2/5][10/17]	Loss: 0.645618
[INFO][10:28:31]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][10:28:33]: [Client #258] Woke up.
[INFO][10:28:33]: [Client #258] Epoch: [3/5][0/17]	Loss: 0.761354
[INFO][10:28:33]: [Client #258] Epoch: [3/5][10/17]	Loss: 0.654505
[INFO][10:28:33]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][10:28:35]: [Client #258] Woke up.
[INFO][10:28:35]: [Client #258] Epoch: [4/5][0/17]	Loss: 0.750347
[INFO][10:28:35]: [Client #258] Epoch: [4/5][10/17]	Loss: 0.706925
[INFO][10:28:35]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][10:28:37]: [Client #258] Woke up.
[INFO][10:28:37]: [Client #258] Epoch: [5/5][0/17]	Loss: 1.631923
[INFO][10:28:37]: [Client #258] Epoch: [5/5][10/17]	Loss: 1.661888
[INFO][10:28:37]: [Client #258] Going to sleep for 1.69 seconds.
[INFO][10:28:39]: [Client #258] Woke up.
[INFO][10:28:39]: [Client #258] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][10:28:39]: [Client #258] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_258_554860.pth.
[INFO][10:28:39]: [Client #258] Model trained.
[INFO][10:28:39]: [Client #258] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:28:39]: [Server #554754] Received 0.26 MB of payload data from client #258 (simulated).
[INFO][10:28:56]: [Client #212] Woke up.
[INFO][10:28:56]: [Client #212] Epoch: [2/5][0/16]	Loss: 1.459573
[INFO][10:28:56]: [Client #212] Epoch: [2/5][10/16]	Loss: 1.856462
[INFO][10:28:56]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:29:22]: [Client #212] Woke up.
[INFO][10:29:22]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.680394
[INFO][10:29:22]: [Client #212] Epoch: [3/5][10/16]	Loss: 2.459231
[INFO][10:29:22]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:29:49]: [Client #212] Woke up.
[INFO][10:29:49]: [Client #212] Epoch: [4/5][0/16]	Loss: 0.773286
[INFO][10:29:49]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.620745
[INFO][10:29:49]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:30:15]: [Client #212] Woke up.
[INFO][10:30:15]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.093764
[INFO][10:30:15]: [Client #212] Epoch: [5/5][10/16]	Loss: 1.029547
[INFO][10:30:15]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:30:42]: [Client #212] Woke up.
[INFO][10:30:42]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:30:42]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:30:42]: [Client #212] Model trained.
[INFO][10:30:42]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:30:42]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][10:30:42]: [Server #554754] Selecting client #310 for training.
[INFO][10:30:42]: [Server #554754] Sending the current model to client #310 (simulated).
[INFO][10:30:42]: [Server #554754] Sending 0.26 MB of payload data to client #310 (simulated).
[INFO][10:30:42]: [Server #554754] Selecting client #218 for training.
[INFO][10:30:42]: [Server #554754] Sending the current model to client #218 (simulated).
[INFO][10:30:42]: [Server #554754] Sending 0.26 MB of payload data to client #218 (simulated).
[INFO][10:30:42]: [Client #310] Selected by the server.
[INFO][10:30:42]: [Client #310] Loading its data source...
[INFO][10:30:42]: Data source: FEMNIST
[INFO][10:30:42]: [Client #218] Selected by the server.
[INFO][10:30:42]: [Client #218] Loading its data source...
[INFO][10:30:42]: Data source: FEMNIST
[INFO][10:30:42]: [Client #310] Dataset size: 164
[INFO][10:30:42]: [Client #310] Sampler: all_inclusive
[INFO][10:30:42]: [Client #310] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:30:43]: [93m[1m[Client #310] Started training in communication round #25.[0m
[INFO][10:30:43]: [Client #218] Dataset size: 155
[INFO][10:30:43]: [Client #218] Sampler: all_inclusive
[INFO][10:30:43]: [Client #218] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:30:43]: [93m[1m[Client #218] Started training in communication round #25.[0m
[INFO][10:30:44]: [Client #310] Loading the dataset.
[INFO][10:30:44]: [Client #218] Loading the dataset.
[INFO][10:30:50]: [Client #310] Epoch: [1/5][0/17]	Loss: 1.439533
[INFO][10:30:50]: [Client #310] Epoch: [1/5][10/17]	Loss: 0.773258
[INFO][10:30:50]: [Client #218] Epoch: [1/5][0/16]	Loss: 0.294520
[INFO][10:30:50]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:30:50]: [Client #218] Epoch: [1/5][10/16]	Loss: 0.504941
[INFO][10:30:50]: [Client #218] Going to sleep for 18.22 seconds.
[INFO][10:30:50]: [Client #310] Woke up.
[INFO][10:30:50]: [Client #310] Epoch: [2/5][0/17]	Loss: 0.668142
[INFO][10:30:51]: [Client #310] Epoch: [2/5][10/17]	Loss: 1.275307
[INFO][10:30:51]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:30:51]: [Client #310] Woke up.
[INFO][10:30:51]: [Client #310] Epoch: [3/5][0/17]	Loss: 0.510196
[INFO][10:30:51]: [Client #310] Epoch: [3/5][10/17]	Loss: 0.754628
[INFO][10:30:51]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:30:52]: [Client #310] Woke up.
[INFO][10:30:52]: [Client #310] Epoch: [4/5][0/17]	Loss: 1.344862
[INFO][10:30:52]: [Client #310] Epoch: [4/5][10/17]	Loss: 0.888728
[INFO][10:30:52]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:30:52]: [Client #310] Woke up.
[INFO][10:30:52]: [Client #310] Epoch: [5/5][0/17]	Loss: 0.223726
[INFO][10:30:52]: [Client #310] Epoch: [5/5][10/17]	Loss: 1.609325
[INFO][10:30:52]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:30:53]: [Client #310] Woke up.
[INFO][10:30:53]: [Client #310] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_310_554853.pth.
[INFO][10:30:54]: [Client #310] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_310_554853.pth.
[INFO][10:30:54]: [Client #310] Model trained.
[INFO][10:30:54]: [Client #310] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:30:54]: [Server #554754] Received 0.26 MB of payload data from client #310 (simulated).
[INFO][10:31:08]: [Client #218] Woke up.
[INFO][10:31:08]: [Client #218] Epoch: [2/5][0/16]	Loss: 0.080258
[INFO][10:31:08]: [Client #218] Epoch: [2/5][10/16]	Loss: 0.441667
[INFO][10:31:09]: [Client #218] Going to sleep for 18.22 seconds.
[INFO][10:31:27]: [Client #218] Woke up.
[INFO][10:31:27]: [Client #218] Epoch: [3/5][0/16]	Loss: 0.268608
[INFO][10:31:27]: [Client #218] Epoch: [3/5][10/16]	Loss: 1.055567
[INFO][10:31:27]: [Client #218] Going to sleep for 18.22 seconds.
[INFO][10:31:45]: [Client #218] Woke up.
[INFO][10:31:45]: [Client #218] Epoch: [4/5][0/16]	Loss: 0.794372
[INFO][10:31:45]: [Client #218] Epoch: [4/5][10/16]	Loss: 1.841359
[INFO][10:31:45]: [Client #218] Going to sleep for 18.22 seconds.
[INFO][10:32:04]: [Client #218] Woke up.
[INFO][10:32:04]: [Client #218] Epoch: [5/5][0/16]	Loss: 0.591661
[INFO][10:32:04]: [Client #218] Epoch: [5/5][10/16]	Loss: 1.687644
[INFO][10:32:04]: [Client #218] Going to sleep for 18.22 seconds.
[INFO][10:32:22]: [Client #218] Woke up.
[INFO][10:32:22]: [Client #218] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_218_554860.pth.
[INFO][10:32:23]: [Client #218] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_218_554860.pth.
[INFO][10:32:23]: [Client #218] Model trained.
[INFO][10:32:23]: [Client #218] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:32:23]: [Server #554754] Received 0.26 MB of payload data from client #218 (simulated).
[INFO][10:32:23]: [Server #554754] Selecting client #425 for training.
[INFO][10:32:23]: [Server #554754] Sending the current model to client #425 (simulated).
[INFO][10:32:23]: [Server #554754] Sending 0.26 MB of payload data to client #425 (simulated).
[INFO][10:32:23]: [Server #554754] Selecting client #229 for training.
[INFO][10:32:23]: [Server #554754] Sending the current model to client #229 (simulated).
[INFO][10:32:23]: [Server #554754] Sending 0.26 MB of payload data to client #229 (simulated).
[INFO][10:32:23]: [Client #425] Selected by the server.
[INFO][10:32:23]: [Client #229] Selected by the server.
[INFO][10:32:23]: [Client #425] Loading its data source...
[INFO][10:32:23]: [Client #229] Loading its data source...
[INFO][10:32:23]: Data source: FEMNIST
[INFO][10:32:23]: Data source: FEMNIST
[INFO][10:32:23]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:32:23]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/425.zip.
[INFO][10:32:23]: [Client #229] Dataset size: 155
[INFO][10:32:23]: [Client #229] Sampler: all_inclusive
[INFO][10:32:23]: [Client #229] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:32:23]: [93m[1m[Client #229] Started training in communication round #25.[0m

2.5%
5.0%
7.5%
9.9%
12.4%
14.9%
17.4%
19.9%
22.4%
24.8%
27.3%
29.8%
32.3%
34.8%
37.3%
39.8%
42.2%
44.7%
47.2%
49.7%
52.2%
54.7%
57.1%
59.6%
62.1%
64.6%
67.1%
69.6%
72.0%
74.5%
77.0%
79.5%
82.0%
84.5%
87.0%
89.4%
91.9%
94.4%
96.9%
99.4%
100.0%[INFO][10:32:23]: Decompressing the dataset downloaded.
[INFO][10:32:23]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/425.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:32:23]: [Client #425] Dataset size: 152
[INFO][10:32:23]: [Client #425] Sampler: all_inclusive
[INFO][10:32:23]: [Client #425] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:32:23]: [93m[1m[Client #425] Started training in communication round #25.[0m

[INFO][10:32:25]: [Client #229] Loading the dataset.
[INFO][10:32:25]: [Client #425] Loading the dataset.
[INFO][10:32:30]: [Client #229] Epoch: [1/5][0/16]	Loss: 0.725523
[INFO][10:32:31]: [Client #229] Epoch: [1/5][10/16]	Loss: 1.026554
[INFO][10:32:31]: [Client #229] Going to sleep for 5.44 seconds.
[INFO][10:32:31]: [Client #425] Epoch: [1/5][0/16]	Loss: 0.398399
[INFO][10:32:31]: [Client #425] Epoch: [1/5][10/16]	Loss: 0.903102
[INFO][10:32:31]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][10:32:32]: [Client #425] Woke up.
[INFO][10:32:32]: [Client #425] Epoch: [2/5][0/16]	Loss: 0.759556
[INFO][10:32:32]: [Client #425] Epoch: [2/5][10/16]	Loss: 0.391602
[INFO][10:32:32]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][10:32:33]: [Client #425] Woke up.
[INFO][10:32:33]: [Client #425] Epoch: [3/5][0/16]	Loss: 1.277156
[INFO][10:32:33]: [Client #425] Epoch: [3/5][10/16]	Loss: 1.549695
[INFO][10:32:33]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][10:32:34]: [Client #425] Woke up.
[INFO][10:32:34]: [Client #425] Epoch: [4/5][0/16]	Loss: 0.265808
[INFO][10:32:34]: [Client #425] Epoch: [4/5][10/16]	Loss: 0.939064
[INFO][10:32:34]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][10:32:35]: [Client #425] Woke up.
[INFO][10:32:35]: [Client #425] Epoch: [5/5][0/16]	Loss: 0.871681
[INFO][10:32:35]: [Client #425] Epoch: [5/5][10/16]	Loss: 1.548729
[INFO][10:32:35]: [Client #425] Going to sleep for 0.85 seconds.
[INFO][10:32:36]: [Client #425] Woke up.
[INFO][10:32:36]: [Client #425] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_425_554853.pth.
[INFO][10:32:36]: [Client #229] Woke up.
[INFO][10:32:36]: [Client #229] Epoch: [2/5][0/16]	Loss: 0.275813
[INFO][10:32:36]: [Client #229] Epoch: [2/5][10/16]	Loss: 0.312665
[INFO][10:32:36]: [Client #229] Going to sleep for 5.44 seconds.
[INFO][10:32:36]: [Client #425] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_425_554853.pth.
[INFO][10:32:36]: [Client #425] Model trained.
[INFO][10:32:36]: [Client #425] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:32:36]: [Server #554754] Received 0.26 MB of payload data from client #425 (simulated).
[INFO][10:32:42]: [Client #229] Woke up.
[INFO][10:32:42]: [Client #229] Epoch: [3/5][0/16]	Loss: 0.515412
[INFO][10:32:42]: [Client #229] Epoch: [3/5][10/16]	Loss: 1.309987
[INFO][10:32:42]: [Client #229] Going to sleep for 5.44 seconds.
[INFO][10:32:47]: [Client #229] Woke up.
[INFO][10:32:47]: [Client #229] Epoch: [4/5][0/16]	Loss: 0.263149
[INFO][10:32:47]: [Client #229] Epoch: [4/5][10/16]	Loss: 0.447007
[INFO][10:32:47]: [Client #229] Going to sleep for 5.44 seconds.
[INFO][10:32:53]: [Client #229] Woke up.
[INFO][10:32:53]: [Client #229] Epoch: [5/5][0/16]	Loss: 0.839707
[INFO][10:32:53]: [Client #229] Epoch: [5/5][10/16]	Loss: 0.818085
[INFO][10:32:53]: [Client #229] Going to sleep for 5.44 seconds.
[INFO][10:32:58]: [Client #229] Woke up.
[INFO][10:32:58]: [Client #229] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_229_554860.pth.
[INFO][10:32:59]: [Client #229] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_229_554860.pth.
[INFO][10:32:59]: [Client #229] Model trained.
[INFO][10:32:59]: [Client #229] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:32:59]: [Server #554754] Received 0.26 MB of payload data from client #229 (simulated).
[INFO][10:32:59]: [Server #554754] Selecting client #8 for training.
[INFO][10:32:59]: [Server #554754] Sending the current model to client #8 (simulated).
[INFO][10:32:59]: [Server #554754] Sending 0.26 MB of payload data to client #8 (simulated).
[INFO][10:32:59]: [Server #554754] Selecting client #437 for training.
[INFO][10:32:59]: [Server #554754] Sending the current model to client #437 (simulated).
[INFO][10:32:59]: [Server #554754] Sending 0.26 MB of payload data to client #437 (simulated).
[INFO][10:32:59]: [Client #8] Selected by the server.
[INFO][10:32:59]: [Client #437] Selected by the server.
[INFO][10:32:59]: [Client #8] Loading its data source...
[INFO][10:32:59]: [Client #437] Loading its data source...
[INFO][10:32:59]: Data source: FEMNIST
[INFO][10:32:59]: Data source: FEMNIST
[INFO][10:32:59]: [Client #8] Dataset size: 141
[INFO][10:32:59]: [Client #8] Sampler: all_inclusive
[INFO][10:32:59]: [Client #437] Dataset size: 145
[INFO][10:32:59]: [Client #437] Sampler: all_inclusive
[INFO][10:32:59]: [Client #8] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:32:59]: [Client #437] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:32:59]: [93m[1m[Client #8] Started training in communication round #25.[0m
[INFO][10:32:59]: [93m[1m[Client #437] Started training in communication round #25.[0m
[INFO][10:33:01]: [Client #8] Loading the dataset.
[INFO][10:33:01]: [Client #437] Loading the dataset.
[INFO][10:33:06]: [Client #437] Epoch: [1/5][0/15]	Loss: 0.295976
[INFO][10:33:07]: [Client #8] Epoch: [1/5][0/15]	Loss: 0.670557
[INFO][10:33:07]: [Client #437] Epoch: [1/5][10/15]	Loss: 0.382815
[INFO][10:33:07]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][10:33:07]: [Client #8] Epoch: [1/5][10/15]	Loss: 2.044150
[INFO][10:33:07]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][10:33:07]: [Client #8] Woke up.
[INFO][10:33:07]: [Client #8] Epoch: [2/5][0/15]	Loss: 0.732954
[INFO][10:33:07]: [Client #8] Epoch: [2/5][10/15]	Loss: 1.215157
[INFO][10:33:07]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][10:33:08]: [Client #8] Woke up.
[INFO][10:33:08]: [Client #8] Epoch: [3/5][0/15]	Loss: 2.524006
[INFO][10:33:08]: [Client #8] Epoch: [3/5][10/15]	Loss: 0.460785
[INFO][10:33:08]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][10:33:09]: [Client #8] Woke up.
[INFO][10:33:09]: [Client #8] Epoch: [4/5][0/15]	Loss: 0.891972
[INFO][10:33:09]: [Client #8] Epoch: [4/5][10/15]	Loss: 2.335364
[INFO][10:33:09]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][10:33:09]: [Client #8] Woke up.
[INFO][10:33:09]: [Client #8] Epoch: [5/5][0/15]	Loss: 0.505958
[INFO][10:33:09]: [Client #8] Epoch: [5/5][10/15]	Loss: 1.893059
[INFO][10:33:09]: [Client #8] Going to sleep for 0.53 seconds.
[INFO][10:33:10]: [Client #8] Woke up.
[INFO][10:33:10]: [Client #8] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_8_554853.pth.
[INFO][10:33:10]: [Client #8] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_8_554853.pth.
[INFO][10:33:10]: [Client #8] Model trained.
[INFO][10:33:10]: [Client #8] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:33:10]: [Server #554754] Received 0.26 MB of payload data from client #8 (simulated).
[INFO][10:33:16]: [Client #437] Woke up.
[INFO][10:33:16]: [Client #437] Epoch: [2/5][0/15]	Loss: 0.752167
[INFO][10:33:16]: [Client #437] Epoch: [2/5][10/15]	Loss: 0.077594
[INFO][10:33:16]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][10:33:26]: [Client #437] Woke up.
[INFO][10:33:26]: [Client #437] Epoch: [3/5][0/15]	Loss: 0.138986
[INFO][10:33:26]: [Client #437] Epoch: [3/5][10/15]	Loss: 0.562643
[INFO][10:33:26]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][10:33:35]: [Client #437] Woke up.
[INFO][10:33:35]: [Client #437] Epoch: [4/5][0/15]	Loss: 0.568320
[INFO][10:33:35]: [Client #437] Epoch: [4/5][10/15]	Loss: 0.659405
[INFO][10:33:36]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][10:33:45]: [Client #437] Woke up.
[INFO][10:33:45]: [Client #437] Epoch: [5/5][0/15]	Loss: 0.712775
[INFO][10:33:45]: [Client #437] Epoch: [5/5][10/15]	Loss: 0.509493
[INFO][10:33:45]: [Client #437] Going to sleep for 9.49 seconds.
[INFO][10:33:55]: [Client #437] Woke up.
[INFO][10:33:55]: [Client #437] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_437_554860.pth.
[INFO][10:33:55]: [Client #437] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_437_554860.pth.
[INFO][10:33:55]: [Client #437] Model trained.
[INFO][10:33:55]: [Client #437] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:33:55]: [Server #554754] Received 0.26 MB of payload data from client #437 (simulated).
[INFO][10:33:55]: [Server #554754] Selecting client #329 for training.
[INFO][10:33:55]: [Server #554754] Sending the current model to client #329 (simulated).
[INFO][10:33:55]: [Server #554754] Sending 0.26 MB of payload data to client #329 (simulated).
[INFO][10:33:55]: [Server #554754] Selecting client #412 for training.
[INFO][10:33:55]: [Server #554754] Sending the current model to client #412 (simulated).
[INFO][10:33:55]: [Server #554754] Sending 0.26 MB of payload data to client #412 (simulated).
[INFO][10:33:55]: [Client #412] Selected by the server.
[INFO][10:33:55]: [Client #329] Selected by the server.
[INFO][10:33:55]: [Client #412] Loading its data source...
[INFO][10:33:55]: Data source: FEMNIST
[INFO][10:33:55]: [Client #329] Loading its data source...
[INFO][10:33:55]: Data source: FEMNIST
[INFO][10:33:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:33:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/412.zip.
[INFO][10:33:55]: [Client #329] Dataset size: 154
[INFO][10:33:55]: [Client #329] Sampler: all_inclusive
[INFO][10:33:55]: [Client #329] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:33:55]: [93m[1m[Client #329] Started training in communication round #25.[0m

2.1%
4.2%
6.3%
8.4%
10.5%
12.7%
14.8%
16.9%
19.0%
21.1%
23.2%
25.3%
27.4%
29.5%
31.6%
33.7%
35.9%
38.0%
40.1%
42.2%
44.3%
46.4%
48.5%
50.6%
52.7%
54.8%
56.9%
59.1%
61.2%
63.3%
65.4%
67.5%
69.6%
71.7%
73.8%
75.9%
78.0%
80.1%
82.3%
84.4%
86.5%
88.6%
90.7%
92.8%
94.9%
97.0%
99.1%
100.0%[INFO][10:33:56]: Decompressing the dataset downloaded.
[INFO][10:33:56]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/412.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:33:56]: [Client #412] Dataset size: 164
[INFO][10:33:56]: [Client #412] Sampler: all_inclusive
[INFO][10:33:56]: [Client #412] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:33:56]: [93m[1m[Client #412] Started training in communication round #25.[0m

[INFO][10:33:57]: [Client #329] Loading the dataset.
[INFO][10:33:57]: [Client #412] Loading the dataset.
[INFO][10:34:03]: [Client #329] Epoch: [1/5][0/16]	Loss: 0.149575
[INFO][10:34:03]: [Client #412] Epoch: [1/5][0/17]	Loss: 0.393754
[INFO][10:34:03]: [Client #412] Epoch: [1/5][10/17]	Loss: 0.415822
[INFO][10:34:03]: [Client #329] Epoch: [1/5][10/16]	Loss: 0.643355
[INFO][10:34:03]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][10:34:03]: [Client #412] Going to sleep for 1.73 seconds.
[INFO][10:34:04]: [Client #329] Woke up.
[INFO][10:34:04]: [Client #329] Epoch: [2/5][0/16]	Loss: 0.589953
[INFO][10:34:04]: [Client #329] Epoch: [2/5][10/16]	Loss: 0.445094
[INFO][10:34:04]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][10:34:05]: [Client #412] Woke up.
[INFO][10:34:05]: [Client #412] Epoch: [2/5][0/17]	Loss: 0.508354
[INFO][10:34:05]: [Client #412] Epoch: [2/5][10/17]	Loss: 0.827311
[INFO][10:34:05]: [Client #412] Going to sleep for 1.73 seconds.
[INFO][10:34:05]: [Client #329] Woke up.
[INFO][10:34:05]: [Client #329] Epoch: [3/5][0/16]	Loss: 0.535108
[INFO][10:34:06]: [Client #329] Epoch: [3/5][10/16]	Loss: 0.367221
[INFO][10:34:06]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][10:34:07]: [Client #412] Woke up.
[INFO][10:34:07]: [Client #412] Epoch: [3/5][0/17]	Loss: 0.587520
[INFO][10:34:07]: [Client #412] Epoch: [3/5][10/17]	Loss: 1.141285
[INFO][10:34:07]: [Client #412] Going to sleep for 1.73 seconds.
[INFO][10:34:07]: [Client #329] Woke up.
[INFO][10:34:07]: [Client #329] Epoch: [4/5][0/16]	Loss: 0.928887
[INFO][10:34:07]: [Client #329] Epoch: [4/5][10/16]	Loss: 1.081597
[INFO][10:34:07]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][10:34:08]: [Client #329] Woke up.
[INFO][10:34:08]: [Client #329] Epoch: [5/5][0/16]	Loss: 0.885786
[INFO][10:34:08]: [Client #329] Epoch: [5/5][10/16]	Loss: 0.648044
[INFO][10:34:08]: [Client #329] Going to sleep for 1.19 seconds.
[INFO][10:34:08]: [Client #412] Woke up.
[INFO][10:34:08]: [Client #412] Epoch: [4/5][0/17]	Loss: 0.454598
[INFO][10:34:09]: [Client #412] Epoch: [4/5][10/17]	Loss: 1.921979
[INFO][10:34:09]: [Client #412] Going to sleep for 1.73 seconds.
[INFO][10:34:09]: [Client #329] Woke up.
[INFO][10:34:09]: [Client #329] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_329_554853.pth.
[INFO][10:34:10]: [Client #329] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_329_554853.pth.
[INFO][10:34:10]: [Client #329] Model trained.
[INFO][10:34:10]: [Client #329] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:34:10]: [Server #554754] Received 0.26 MB of payload data from client #329 (simulated).
[INFO][10:34:10]: [Client #412] Woke up.
[INFO][10:34:10]: [Client #412] Epoch: [5/5][0/17]	Loss: 0.878446
[INFO][10:34:10]: [Client #412] Epoch: [5/5][10/17]	Loss: 0.334980
[INFO][10:34:10]: [Client #412] Going to sleep for 1.73 seconds.
[INFO][10:34:12]: [Client #412] Woke up.
[INFO][10:34:12]: [Client #412] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_412_554860.pth.
[INFO][10:34:13]: [Client #412] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_412_554860.pth.
[INFO][10:34:13]: [Client #412] Model trained.
[INFO][10:34:13]: [Client #412] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:34:13]: [Server #554754] Received 0.26 MB of payload data from client #412 (simulated).
[INFO][10:34:13]: [Server #554754] Adding client #310 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #8 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #425 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #329 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #412 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #258 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #229 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #437 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Adding client #218 to the list of clients for aggregation.
[INFO][10:34:13]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.76315495 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.05977868 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10982367 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08501329 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11759335
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12128255 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12808739 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11291993 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.31177449 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09723758 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.76315495 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.05977868 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10982367 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08501329 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11759335
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12128255 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12808739 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11291993 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.31177449 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09723758 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:34:57]: [Server #554754] Global model accuracy: 59.65%

[INFO][10:34:57]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_25.pth.
[INFO][10:34:57]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_25.pth.
[INFO][10:34:57]: [93m[1m
[Server #554754] Starting round 26/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.0912031  0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.09808917 0.04912068 0.08498896
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09767141 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08674827 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.10230179 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.002      0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.002      0.002      0.10608021 0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.09079284 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.002
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.002      0.002      0.0912721  0.09831824 0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.04746651 0.002
 0.08900524 0.08789809 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.04791345 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9044e+00  1e-03  2e-08  2e-08
 5:  6.9057e+00  6.9047e+00  1e-03  1e-08  1e-08
 6:  6.9056e+00  6.9046e+00  1e-03  5e-07  6e-07
 7:  6.9055e+00  6.9049e+00  6e-04  4e-07  4e-07
 8:  6.9054e+00  6.9050e+00  4e-04  7e-07  8e-07
 9:  6.9052e+00  6.9051e+00  1e-04  1e-06  1e-06
10:  6.9051e+00  6.9051e+00  4e-05  6e-07  7e-07
11:  6.9051e+00  6.9051e+00  3e-06  9e-08  1e-07
Optimal solution found.
The calculated probability is:  [1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.66801780e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 9.91462202e-01
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71335996e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71383554e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71300504e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71292665e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71295338e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71314226e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.70537832e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71373250e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05 1.71454693e-05
 1.71454693e-05 1.71454693e-05 1.71454693e-05]
current clients pool:  [INFO][10:34:58]: [Server #554754] Selected clients: [152 422  22 245 120 477 473 308 487 173]
[INFO][10:34:58]: [Server #554754] Selecting client #152 for training.
[INFO][10:34:58]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][10:34:58]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][10:34:58]: [Server #554754] Selecting client #422 for training.
[INFO][10:34:58]: [Server #554754] Sending the current model to client #422 (simulated).
[INFO][10:34:58]: [Server #554754] Sending 0.26 MB of payload data to client #422 (simulated).
[INFO][10:34:58]: [Client #152] Selected by the server.
[INFO][10:34:58]: [Client #152] Loading its data source...
[INFO][10:34:58]: Data source: FEMNIST
[INFO][10:34:58]: [Client #422] Selected by the server.
[INFO][10:34:58]: [Client #422] Loading its data source...
[INFO][10:34:58]: Data source: FEMNIST
[INFO][10:34:58]: [Client #152] Dataset size: 151
[INFO][10:34:58]: [Client #152] Sampler: all_inclusive
[INFO][10:34:58]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:34:58]: [93m[1m[Client #152] Started training in communication round #26.[0m
[INFO][10:34:58]: [Client #422] Dataset size: 273
[INFO][10:34:58]: [Client #422] Sampler: all_inclusive
[INFO][10:34:58]: [Client #422] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:34:58]: [93m[1m[Client #422] Started training in communication round #26.[0m
[INFO][10:35:00]: [Client #422] Loading the dataset.
[INFO][10:35:00]: [Client #152] Loading the dataset.
[INFO][10:35:05]: [Client #422] Epoch: [1/5][0/28]	Loss: 2.326863
[INFO][10:35:05]: [Client #152] Epoch: [1/5][0/16]	Loss: 1.905140
[INFO][10:35:05]: [Client #422] Epoch: [1/5][10/28]	Loss: 1.627130
[INFO][10:35:05]: [Client #152] Epoch: [1/5][10/16]	Loss: 1.381470
[INFO][10:35:05]: [Client #422] Epoch: [1/5][20/28]	Loss: 1.745248
[INFO][10:35:05]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:35:05]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:35:05]: [Client #422] Woke up.
[INFO][10:35:06]: [Client #422] Epoch: [2/5][0/28]	Loss: 1.159362
[INFO][10:35:06]: [Client #422] Epoch: [2/5][10/28]	Loss: 0.873570
[INFO][10:35:06]: [Client #422] Epoch: [2/5][20/28]	Loss: 1.582216
[INFO][10:35:06]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:35:06]: [Client #422] Woke up.
[INFO][10:35:06]: [Client #422] Epoch: [3/5][0/28]	Loss: 1.672771
[INFO][10:35:06]: [Client #422] Epoch: [3/5][10/28]	Loss: 1.209792
[INFO][10:35:06]: [Client #422] Epoch: [3/5][20/28]	Loss: 2.259682
[INFO][10:35:06]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:35:06]: [Client #422] Woke up.
[INFO][10:35:06]: [Client #422] Epoch: [4/5][0/28]	Loss: 1.291265
[INFO][10:35:06]: [Client #422] Epoch: [4/5][10/28]	Loss: 1.070536
[INFO][10:35:06]: [Client #422] Epoch: [4/5][20/28]	Loss: 0.460852
[INFO][10:35:06]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:35:06]: [Client #422] Woke up.
[INFO][10:35:06]: [Client #422] Epoch: [5/5][0/28]	Loss: 0.442163
[INFO][10:35:07]: [Client #422] Epoch: [5/5][10/28]	Loss: 0.392585
[INFO][10:35:07]: [Client #422] Epoch: [5/5][20/28]	Loss: 0.872154
[INFO][10:35:07]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:35:07]: [Client #422] Woke up.
[INFO][10:35:07]: [Client #422] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554860.pth.
[INFO][10:35:07]: [Client #422] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554860.pth.
[INFO][10:35:07]: [Client #422] Model trained.
[INFO][10:35:07]: [Client #422] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:35:07]: [Server #554754] Received 0.26 MB of payload data from client #422 (simulated).
[INFO][10:35:35]: [Client #152] Woke up.
[INFO][10:35:35]: [Client #152] Epoch: [2/5][0/16]	Loss: 1.597282
[INFO][10:35:35]: [Client #152] Epoch: [2/5][10/16]	Loss: 1.218090
[INFO][10:35:35]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:36:05]: [Client #152] Woke up.
[INFO][10:36:05]: [Client #152] Epoch: [3/5][0/16]	Loss: 0.331558
[INFO][10:36:05]: [Client #152] Epoch: [3/5][10/16]	Loss: 1.574587
[INFO][10:36:05]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:36:35]: [Client #152] Woke up.
[INFO][10:36:35]: [Client #152] Epoch: [4/5][0/16]	Loss: 1.320231
[INFO][10:36:35]: [Client #152] Epoch: [4/5][10/16]	Loss: 1.188329
[INFO][10:36:35]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:37:04]: [Client #152] Woke up.
[INFO][10:37:05]: [Client #152] Epoch: [5/5][0/16]	Loss: 0.840628
[INFO][10:37:05]: [Client #152] Epoch: [5/5][10/16]	Loss: 0.666055
[INFO][10:37:05]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][10:37:34]: [Client #152] Woke up.
[INFO][10:37:34]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:37:35]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][10:37:35]: [Client #152] Model trained.
[INFO][10:37:35]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:37:35]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][10:37:35]: [Server #554754] Selecting client #22 for training.
[INFO][10:37:35]: [Server #554754] Sending the current model to client #22 (simulated).
[INFO][10:37:35]: [Server #554754] Sending 0.26 MB of payload data to client #22 (simulated).
[INFO][10:37:35]: [Server #554754] Selecting client #245 for training.
[INFO][10:37:35]: [Server #554754] Sending the current model to client #245 (simulated).
[INFO][10:37:35]: [Server #554754] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][10:37:35]: [Client #22] Selected by the server.
[INFO][10:37:35]: [Client #22] Loading its data source...
[INFO][10:37:35]: Data source: FEMNIST
[INFO][10:37:35]: [Client #245] Selected by the server.
[INFO][10:37:35]: [Client #245] Loading its data source...
[INFO][10:37:35]: Data source: FEMNIST
[INFO][10:37:35]: [Client #22] Dataset size: 161
[INFO][10:37:35]: [Client #22] Sampler: all_inclusive
[INFO][10:37:35]: [Client #22] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:37:35]: [93m[1m[Client #22] Started training in communication round #26.[0m
[INFO][10:37:35]: [Client #245] Dataset size: 301
[INFO][10:37:35]: [Client #245] Sampler: all_inclusive
[INFO][10:37:35]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:37:35]: [93m[1m[Client #245] Started training in communication round #26.[0m
[INFO][10:37:37]: [Client #245] Loading the dataset.
[INFO][10:37:37]: [Client #22] Loading the dataset.
[INFO][10:37:43]: [Client #245] Epoch: [1/5][0/31]	Loss: 2.132094
[INFO][10:37:43]: [Client #22] Epoch: [1/5][0/17]	Loss: 1.502951
[INFO][10:37:43]: [Client #245] Epoch: [1/5][10/31]	Loss: 1.349967
[INFO][10:37:43]: [Client #22] Epoch: [1/5][10/17]	Loss: 0.670694
[INFO][10:37:43]: [Client #245] Epoch: [1/5][20/31]	Loss: 0.993062
[INFO][10:37:43]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:37:43]: [Client #245] Epoch: [1/5][30/31]	Loss: 0.009253
[INFO][10:37:43]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][10:37:47]: [Client #245] Woke up.
[INFO][10:37:47]: [Client #245] Epoch: [2/5][0/31]	Loss: 0.376544
[INFO][10:37:47]: [Client #245] Epoch: [2/5][10/31]	Loss: 1.680283
[INFO][10:37:47]: [Client #245] Epoch: [2/5][20/31]	Loss: 2.059802
[INFO][10:37:47]: [Client #245] Epoch: [2/5][30/31]	Loss: 1.199048
[INFO][10:37:47]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][10:37:51]: [Client #245] Woke up.
[INFO][10:37:51]: [Client #245] Epoch: [3/5][0/31]	Loss: 0.827606
[INFO][10:37:51]: [Client #245] Epoch: [3/5][10/31]	Loss: 0.554305
[INFO][10:37:51]: [Client #245] Epoch: [3/5][20/31]	Loss: 0.523344
[INFO][10:37:51]: [Client #245] Epoch: [3/5][30/31]	Loss: 0.298484
[INFO][10:37:51]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][10:37:55]: [Client #245] Woke up.
[INFO][10:37:55]: [Client #245] Epoch: [4/5][0/31]	Loss: 1.419266
[INFO][10:37:55]: [Client #245] Epoch: [4/5][10/31]	Loss: 0.635442
[INFO][10:37:55]: [Client #245] Epoch: [4/5][20/31]	Loss: 1.468350
[INFO][10:37:55]: [Client #245] Epoch: [4/5][30/31]	Loss: 0.108831
[INFO][10:37:55]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][10:37:59]: [Client #245] Woke up.
[INFO][10:37:59]: [Client #245] Epoch: [5/5][0/31]	Loss: 0.881424
[INFO][10:37:59]: [Client #245] Epoch: [5/5][10/31]	Loss: 1.204662
[INFO][10:37:59]: [Client #245] Epoch: [5/5][20/31]	Loss: 0.725685
[INFO][10:37:59]: [Client #245] Epoch: [5/5][30/31]	Loss: 2.375321
[INFO][10:37:59]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][10:38:03]: [Client #245] Woke up.
[INFO][10:38:03]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][10:38:03]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][10:38:03]: [Client #245] Model trained.
[INFO][10:38:03]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:38:03]: [Server #554754] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][10:38:14]: [Client #22] Woke up.
[INFO][10:38:14]: [Client #22] Epoch: [2/5][0/17]	Loss: 0.640539
[INFO][10:38:14]: [Client #22] Epoch: [2/5][10/17]	Loss: 0.970884
[INFO][10:38:14]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:38:44]: [Client #22] Woke up.
[INFO][10:38:44]: [Client #22] Epoch: [3/5][0/17]	Loss: 0.912271
[INFO][10:38:45]: [Client #22] Epoch: [3/5][10/17]	Loss: 0.661749
[INFO][10:38:45]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:39:15]: [Client #22] Woke up.
[INFO][10:39:15]: [Client #22] Epoch: [4/5][0/17]	Loss: 0.140369
[INFO][10:39:15]: [Client #22] Epoch: [4/5][10/17]	Loss: 0.751528
[INFO][10:39:15]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:39:46]: [Client #22] Woke up.
[INFO][10:39:46]: [Client #22] Epoch: [5/5][0/17]	Loss: 0.719130
[INFO][10:39:46]: [Client #22] Epoch: [5/5][10/17]	Loss: 1.797077
[INFO][10:39:46]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:40:17]: [Client #22] Woke up.
[INFO][10:40:17]: [Client #22] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_554853.pth.
[INFO][10:40:17]: [Client #22] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_554853.pth.
[INFO][10:40:17]: [Client #22] Model trained.
[INFO][10:40:17]: [Client #22] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:40:18]: [Server #554754] Received 0.26 MB of payload data from client #22 (simulated).
[INFO][10:40:18]: [Server #554754] Selecting client #120 for training.
[INFO][10:40:18]: [Server #554754] Sending the current model to client #120 (simulated).
[INFO][10:40:18]: [Server #554754] Sending 0.26 MB of payload data to client #120 (simulated).
[INFO][10:40:18]: [Server #554754] Selecting client #477 for training.
[INFO][10:40:18]: [Server #554754] Sending the current model to client #477 (simulated).
[INFO][10:40:18]: [Server #554754] Sending 0.26 MB of payload data to client #477 (simulated).
[INFO][10:40:18]: [Client #477] Selected by the server.
[INFO][10:40:18]: [Client #477] Loading its data source...
[INFO][10:40:18]: Data source: FEMNIST
[INFO][10:40:18]: [Client #120] Selected by the server.
[INFO][10:40:18]: [Client #120] Loading its data source...
[INFO][10:40:18]: Data source: FEMNIST
[INFO][10:40:18]: [Client #477] Dataset size: 144
[INFO][10:40:18]: [Client #477] Sampler: all_inclusive
[INFO][10:40:18]: [Client #477] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:18]: [93m[1m[Client #477] Started training in communication round #26.[0m
[INFO][10:40:18]: [Client #120] Dataset size: 154
[INFO][10:40:18]: [Client #120] Sampler: all_inclusive
[INFO][10:40:18]: [Client #120] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:18]: [93m[1m[Client #120] Started training in communication round #26.[0m
[INFO][10:40:19]: [Client #120] Loading the dataset.
[INFO][10:40:19]: [Client #477] Loading the dataset.
[INFO][10:40:25]: [Client #477] Epoch: [1/5][0/15]	Loss: 0.967274
[INFO][10:40:25]: [Client #120] Epoch: [1/5][0/16]	Loss: 0.526001
[INFO][10:40:25]: [Client #477] Epoch: [1/5][10/15]	Loss: 1.469676
[INFO][10:40:25]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][10:40:25]: [Client #120] Epoch: [1/5][10/16]	Loss: 0.654761
[INFO][10:40:25]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][10:40:25]: [Client #120] Woke up.
[INFO][10:40:25]: [Client #120] Epoch: [2/5][0/16]	Loss: 0.201541
[INFO][10:40:25]: [Client #120] Epoch: [2/5][10/16]	Loss: 0.387660
[INFO][10:40:25]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][10:40:25]: [Client #120] Woke up.
[INFO][10:40:26]: [Client #120] Epoch: [3/5][0/16]	Loss: 0.492364
[INFO][10:40:26]: [Client #120] Epoch: [3/5][10/16]	Loss: 0.695341
[INFO][10:40:26]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][10:40:26]: [Client #120] Woke up.
[INFO][10:40:26]: [Client #120] Epoch: [4/5][0/16]	Loss: 0.428072
[INFO][10:40:26]: [Client #120] Epoch: [4/5][10/16]	Loss: 1.016801
[INFO][10:40:26]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][10:40:26]: [Client #120] Woke up.
[INFO][10:40:26]: [Client #120] Epoch: [5/5][0/16]	Loss: 0.963111
[INFO][10:40:26]: [Client #120] Epoch: [5/5][10/16]	Loss: 0.807384
[INFO][10:40:26]: [Client #120] Going to sleep for 0.14 seconds.
[INFO][10:40:26]: [Client #120] Woke up.
[INFO][10:40:26]: [Client #120] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_554853.pth.
[INFO][10:40:27]: [Client #120] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_120_554853.pth.
[INFO][10:40:27]: [Client #120] Model trained.
[INFO][10:40:27]: [Client #120] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:40:27]: [Server #554754] Received 0.26 MB of payload data from client #120 (simulated).
[INFO][10:40:28]: [Client #477] Woke up.
[INFO][10:40:28]: [Client #477] Epoch: [2/5][0/15]	Loss: 1.256674
[INFO][10:40:28]: [Client #477] Epoch: [2/5][10/15]	Loss: 1.711595
[INFO][10:40:28]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][10:40:30]: [Client #477] Woke up.
[INFO][10:40:30]: [Client #477] Epoch: [3/5][0/15]	Loss: 0.550904
[INFO][10:40:30]: [Client #477] Epoch: [3/5][10/15]	Loss: 0.821911
[INFO][10:40:30]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][10:40:33]: [Client #477] Woke up.
[INFO][10:40:33]: [Client #477] Epoch: [4/5][0/15]	Loss: 0.876961
[INFO][10:40:33]: [Client #477] Epoch: [4/5][10/15]	Loss: 0.510890
[INFO][10:40:33]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][10:40:36]: [Client #477] Woke up.
[INFO][10:40:36]: [Client #477] Epoch: [5/5][0/15]	Loss: 1.808347
[INFO][10:40:36]: [Client #477] Epoch: [5/5][10/15]	Loss: 1.036196
[INFO][10:40:36]: [Client #477] Going to sleep for 2.53 seconds.
[INFO][10:40:38]: [Client #477] Woke up.
[INFO][10:40:38]: [Client #477] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_477_554860.pth.
[INFO][10:40:39]: [Client #477] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_477_554860.pth.
[INFO][10:40:39]: [Client #477] Model trained.
[INFO][10:40:39]: [Client #477] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:40:39]: [Server #554754] Received 0.26 MB of payload data from client #477 (simulated).
[INFO][10:40:39]: [Server #554754] Selecting client #473 for training.
[INFO][10:40:39]: [Server #554754] Sending the current model to client #473 (simulated).
[INFO][10:40:39]: [Server #554754] Sending 0.26 MB of payload data to client #473 (simulated).
[INFO][10:40:39]: [Server #554754] Selecting client #308 for training.
[INFO][10:40:39]: [Server #554754] Sending the current model to client #308 (simulated).
[INFO][10:40:39]: [Server #554754] Sending 0.26 MB of payload data to client #308 (simulated).
[INFO][10:40:39]: [Client #308] Selected by the server.
[INFO][10:40:39]: [Client #473] Selected by the server.
[INFO][10:40:39]: [Client #308] Loading its data source...
[INFO][10:40:39]: [Client #473] Loading its data source...
[INFO][10:40:39]: Data source: FEMNIST
[INFO][10:40:39]: Data source: FEMNIST
[INFO][10:40:39]: [Client #473] Dataset size: 163
[INFO][10:40:39]: [Client #473] Sampler: all_inclusive
[INFO][10:40:39]: [Client #308] Dataset size: 166
[INFO][10:40:39]: [Client #308] Sampler: all_inclusive
[INFO][10:40:39]: [Client #473] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:39]: [Client #308] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:39]: [93m[1m[Client #473] Started training in communication round #26.[0m
[INFO][10:40:39]: [93m[1m[Client #308] Started training in communication round #26.[0m
[INFO][10:40:41]: [Client #473] Loading the dataset.
[INFO][10:40:41]: [Client #308] Loading the dataset.
[INFO][10:40:46]: [Client #473] Epoch: [1/5][0/17]	Loss: 1.401927
[INFO][10:40:46]: [Client #308] Epoch: [1/5][0/17]	Loss: 0.874879
[INFO][10:40:46]: [Client #473] Epoch: [1/5][10/17]	Loss: 0.757424
[INFO][10:40:46]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][10:40:46]: [Client #308] Epoch: [1/5][10/17]	Loss: 0.317438
[INFO][10:40:46]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][10:40:47]: [Client #308] Woke up.
[INFO][10:40:47]: [Client #308] Epoch: [2/5][0/17]	Loss: 1.044468
[INFO][10:40:47]: [Client #308] Epoch: [2/5][10/17]	Loss: 0.408728
[INFO][10:40:47]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][10:40:47]: [Client #473] Woke up.
[INFO][10:40:47]: [Client #473] Epoch: [2/5][0/17]	Loss: 0.583375
[INFO][10:40:47]: [Client #308] Woke up.
[INFO][10:40:47]: [Client #308] Epoch: [3/5][0/17]	Loss: 0.153236
[INFO][10:40:47]: [Client #473] Epoch: [2/5][10/17]	Loss: 1.644050
[INFO][10:40:47]: [Client #308] Epoch: [3/5][10/17]	Loss: 0.297690
[INFO][10:40:47]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][10:40:47]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][10:40:48]: [Client #308] Woke up.
[INFO][10:40:48]: [Client #308] Epoch: [4/5][0/17]	Loss: 0.032252
[INFO][10:40:48]: [Client #308] Epoch: [4/5][10/17]	Loss: 0.970107
[INFO][10:40:48]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][10:40:48]: [Client #308] Woke up.
[INFO][10:40:48]: [Client #473] Woke up.
[INFO][10:40:48]: [Client #308] Epoch: [5/5][0/17]	Loss: 0.625233
[INFO][10:40:48]: [Client #473] Epoch: [3/5][0/17]	Loss: 1.035530
[INFO][10:40:48]: [Client #308] Epoch: [5/5][10/17]	Loss: 0.620333
[INFO][10:40:48]: [Client #473] Epoch: [3/5][10/17]	Loss: 1.032493
[INFO][10:40:48]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][10:40:48]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][10:40:48]: [Client #308] Woke up.
[INFO][10:40:48]: [Client #308] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_308_554860.pth.
[INFO][10:40:49]: [Client #473] Woke up.
[INFO][10:40:49]: [Client #473] Epoch: [4/5][0/17]	Loss: 0.505429
[INFO][10:40:49]: [Client #473] Epoch: [4/5][10/17]	Loss: 0.401895
[INFO][10:40:49]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][10:40:49]: [Client #308] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_308_554860.pth.
[INFO][10:40:49]: [Client #308] Model trained.
[INFO][10:40:49]: [Client #308] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:40:49]: [Server #554754] Received 0.26 MB of payload data from client #308 (simulated).
[INFO][10:40:50]: [Client #473] Woke up.
[INFO][10:40:50]: [Client #473] Epoch: [5/5][0/17]	Loss: 0.464741
[INFO][10:40:50]: [Client #473] Epoch: [5/5][10/17]	Loss: 1.019647
[INFO][10:40:50]: [Client #473] Going to sleep for 0.77 seconds.
[INFO][10:40:51]: [Client #473] Woke up.
[INFO][10:40:51]: [Client #473] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554853.pth.
[INFO][10:40:51]: [Client #473] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_473_554853.pth.
[INFO][10:40:51]: [Client #473] Model trained.
[INFO][10:40:51]: [Client #473] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:40:51]: [Server #554754] Received 0.26 MB of payload data from client #473 (simulated).
[INFO][10:40:51]: [Server #554754] Selecting client #487 for training.
[INFO][10:40:51]: [Server #554754] Sending the current model to client #487 (simulated).
[INFO][10:40:51]: [Server #554754] Sending 0.26 MB of payload data to client #487 (simulated).
[INFO][10:40:51]: [Server #554754] Selecting client #173 for training.
[INFO][10:40:51]: [Server #554754] Sending the current model to client #173 (simulated).
[INFO][10:40:51]: [Server #554754] Sending 0.26 MB of payload data to client #173 (simulated).
[INFO][10:40:51]: [Client #487] Selected by the server.
[INFO][10:40:51]: [Client #487] Loading its data source...
[INFO][10:40:51]: Data source: FEMNIST
[INFO][10:40:51]: [Client #173] Selected by the server.
[INFO][10:40:51]: [Client #173] Loading its data source...
[INFO][10:40:51]: Data source: FEMNIST
[INFO][10:40:51]: [Client #173] Dataset size: 163
[INFO][10:40:51]: [Client #173] Sampler: all_inclusive
[INFO][10:40:51]: [Client #487] Dataset size: 155
[INFO][10:40:51]: [Client #487] Sampler: all_inclusive
[INFO][10:40:51]: [Client #173] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:51]: [Client #487] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:40:51]: [93m[1m[Client #173] Started training in communication round #26.[0m
[INFO][10:40:51]: [93m[1m[Client #487] Started training in communication round #26.[0m
[INFO][10:40:53]: [Client #173] Loading the dataset.
[INFO][10:40:53]: [Client #487] Loading the dataset.
[INFO][10:40:59]: [Client #173] Epoch: [1/5][0/17]	Loss: 0.252116
[INFO][10:40:59]: [Client #487] Epoch: [1/5][0/16]	Loss: 1.351933
[INFO][10:40:59]: [Client #173] Epoch: [1/5][10/17]	Loss: 0.518341
[INFO][10:40:59]: [Client #487] Epoch: [1/5][10/16]	Loss: 0.462055
[INFO][10:40:59]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][10:40:59]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][10:40:59]: [Client #487] Woke up.
[INFO][10:40:59]: [Client #487] Epoch: [2/5][0/16]	Loss: 0.631598
[INFO][10:40:59]: [Client #487] Epoch: [2/5][10/16]	Loss: 1.241365
[INFO][10:40:59]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][10:41:00]: [Client #487] Woke up.
[INFO][10:41:00]: [Client #487] Epoch: [3/5][0/16]	Loss: 0.387862
[INFO][10:41:00]: [Client #487] Epoch: [3/5][10/16]	Loss: 1.264558
[INFO][10:41:00]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][10:41:00]: [Client #173] Woke up.
[INFO][10:41:00]: [Client #173] Epoch: [2/5][0/17]	Loss: 0.382494
[INFO][10:41:00]: [Client #173] Epoch: [2/5][10/17]	Loss: 0.200307
[INFO][10:41:00]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][10:41:00]: [Client #487] Woke up.
[INFO][10:41:00]: [Client #487] Epoch: [4/5][0/16]	Loss: 0.061432
[INFO][10:41:01]: [Client #487] Epoch: [4/5][10/16]	Loss: 0.258641
[INFO][10:41:01]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][10:41:01]: [Client #487] Woke up.
[INFO][10:41:01]: [Client #487] Epoch: [5/5][0/16]	Loss: 0.401335
[INFO][10:41:01]: [Client #487] Epoch: [5/5][10/16]	Loss: 1.760290
[INFO][10:41:01]: [Client #487] Going to sleep for 0.41 seconds.
[INFO][10:41:02]: [Client #487] Woke up.
[INFO][10:41:02]: [Client #487] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_554853.pth.
[INFO][10:41:02]: [Client #173] Woke up.
[INFO][10:41:02]: [Client #173] Epoch: [3/5][0/17]	Loss: 0.228935
[INFO][10:41:02]: [Client #173] Epoch: [3/5][10/17]	Loss: 0.006566
[INFO][10:41:02]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][10:41:02]: [Client #487] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_487_554853.pth.
[INFO][10:41:02]: [Client #487] Model trained.
[INFO][10:41:02]: [Client #487] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:41:02]: [Server #554754] Received 0.26 MB of payload data from client #487 (simulated).
[INFO][10:41:03]: [Client #173] Woke up.
[INFO][10:41:03]: [Client #173] Epoch: [4/5][0/17]	Loss: 0.230420
[INFO][10:41:03]: [Client #173] Epoch: [4/5][10/17]	Loss: 0.028435
[INFO][10:41:03]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][10:41:05]: [Client #173] Woke up.
[INFO][10:41:05]: [Client #173] Epoch: [5/5][0/17]	Loss: 0.471650
[INFO][10:41:05]: [Client #173] Epoch: [5/5][10/17]	Loss: 0.218307
[INFO][10:41:05]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][10:41:06]: [Client #173] Woke up.
[INFO][10:41:06]: [Client #173] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554860.pth.
[INFO][10:41:07]: [Client #173] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554860.pth.
[INFO][10:41:07]: [Client #173] Model trained.
[INFO][10:41:07]: [Client #173] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:41:07]: [Server #554754] Received 0.26 MB of payload data from client #173 (simulated).
[INFO][10:41:07]: [Server #554754] Adding client #422 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #120 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #308 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #487 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #473 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #173 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #477 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #245 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][10:41:07]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11282802
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.63998628 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06128627 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17294485 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.36620795 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11687832 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21053833 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07899258 0.
 0.         0.         0.15840609 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09256352 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11282802
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.63998628 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06128627 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17294485 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.36620795 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11687832 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.21053833 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07899258 0.
 0.         0.         0.15840609 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09256352 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:41:51]: [Server #554754] Global model accuracy: 62.85%

[INFO][10:41:51]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_26.pth.
[INFO][10:41:51]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_26.pth.
[INFO][10:41:51]: [93m[1m
[Server #554754] Starting round 27/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.0912031  0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.002      0.002      0.08439306
 0.002      0.002      0.09364162 0.002      0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.04717531
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.002      0.04775772
 0.09184256 0.002      0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08251366 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08743169 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.08429752 0.002      0.002      0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.002      0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.10608021 0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.09079284 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.002
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14918033 0.002      0.0912721  0.09831824 0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.08900524 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  3e-09  3e-09
 6:  6.9057e+00  6.9056e+00  2e-04  5e-09  1e-09
 7:  6.9057e+00  6.9056e+00  1e-04  6e-09  1e-09
 8:  6.9057e+00  6.9056e+00  8e-05  6e-08  1e-08
 9:  6.9056e+00  6.9056e+00  4e-05  6e-08  1e-08
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  7e-09
Optimal solution found.
The calculated probability is:  [4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17405366e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.05562704e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17677002e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 9.79196472e-01 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.01995569e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17305288e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.13406589e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17588277e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17112171e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17534432e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05 4.17811233e-05
 4.17811233e-05 4.17811233e-05 4.17811233e-05]
current clients pool:  [INFO][10:41:51]: [Server #554754] Selected clients: [212 128 302 408  28  66 422 310 267 125]
[INFO][10:41:51]: [Server #554754] Selecting client #212 for training.
[INFO][10:41:51]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][10:41:51]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][10:41:51]: [Server #554754] Selecting client #128 for training.
[INFO][10:41:51]: [Server #554754] Sending the current model to client #128 (simulated).
[INFO][10:41:51]: [Server #554754] Sending 0.26 MB of payload data to client #128 (simulated).
[INFO][10:41:51]: [Client #212] Selected by the server.
[INFO][10:41:51]: [Client #212] Loading its data source...
[INFO][10:41:51]: Data source: FEMNIST
[INFO][10:41:51]: [Client #128] Selected by the server.
[INFO][10:41:51]: [Client #128] Loading its data source...
[INFO][10:41:51]: Data source: FEMNIST
[INFO][10:41:51]: [Client #128] Dataset size: 158
[INFO][10:41:51]: [Client #128] Sampler: all_inclusive
[INFO][10:41:51]: [Client #128] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:41:51]: [Client #212] Dataset size: 160
[INFO][10:41:51]: [Client #212] Sampler: all_inclusive
[INFO][10:41:51]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:41:51]: [93m[1m[Client #212] Started training in communication round #27.[0m
[INFO][10:41:51]: [93m[1m[Client #128] Started training in communication round #27.[0m
[INFO][10:41:53]: [Client #128] Loading the dataset.
[INFO][10:41:53]: [Client #212] Loading the dataset.
[INFO][10:41:58]: [Client #128] Epoch: [1/5][0/16]	Loss: 0.202635
[INFO][10:41:59]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.207783
[INFO][10:41:59]: [Client #128] Epoch: [1/5][10/16]	Loss: 0.669336
[INFO][10:41:59]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][10:41:59]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.441157
[INFO][10:41:59]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:42:04]: [Client #128] Woke up.
[INFO][10:42:04]: [Client #128] Epoch: [2/5][0/16]	Loss: 1.761958
[INFO][10:42:04]: [Client #128] Epoch: [2/5][10/16]	Loss: 0.560442
[INFO][10:42:04]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][10:42:09]: [Client #128] Woke up.
[INFO][10:42:09]: [Client #128] Epoch: [3/5][0/16]	Loss: 0.200460
[INFO][10:42:10]: [Client #128] Epoch: [3/5][10/16]	Loss: 0.669823
[INFO][10:42:10]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][10:42:15]: [Client #128] Woke up.
[INFO][10:42:15]: [Client #128] Epoch: [4/5][0/16]	Loss: 0.059857
[INFO][10:42:15]: [Client #128] Epoch: [4/5][10/16]	Loss: 0.417846
[INFO][10:42:15]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][10:42:20]: [Client #128] Woke up.
[INFO][10:42:20]: [Client #128] Epoch: [5/5][0/16]	Loss: 0.206404
[INFO][10:42:20]: [Client #128] Epoch: [5/5][10/16]	Loss: 0.053032
[INFO][10:42:21]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][10:42:25]: [Client #212] Woke up.
[INFO][10:42:25]: [Client #212] Epoch: [2/5][0/16]	Loss: 1.432809
[INFO][10:42:25]: [Client #212] Epoch: [2/5][10/16]	Loss: 0.889413
[INFO][10:42:25]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:42:26]: [Client #128] Woke up.
[INFO][10:42:26]: [Client #128] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554860.pth.
[INFO][10:42:27]: [Client #128] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554860.pth.
[INFO][10:42:27]: [Client #128] Model trained.
[INFO][10:42:27]: [Client #128] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:42:27]: [Server #554754] Received 0.26 MB of payload data from client #128 (simulated).
[INFO][10:42:51]: [Client #212] Woke up.
[INFO][10:42:51]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.850551
[INFO][10:42:52]: [Client #212] Epoch: [3/5][10/16]	Loss: 0.933537
[INFO][10:42:52]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:43:18]: [Client #212] Woke up.
[INFO][10:43:18]: [Client #212] Epoch: [4/5][0/16]	Loss: 0.908492
[INFO][10:43:18]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.008865
[INFO][10:43:18]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:43:44]: [Client #212] Woke up.
[INFO][10:43:44]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.082442
[INFO][10:43:45]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.937682
[INFO][10:43:45]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:44:11]: [Client #212] Woke up.
[INFO][10:44:11]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:44:12]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:44:12]: [Client #212] Model trained.
[INFO][10:44:12]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:44:12]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][10:44:12]: [Server #554754] Selecting client #302 for training.
[INFO][10:44:12]: [Server #554754] Sending the current model to client #302 (simulated).
[INFO][10:44:12]: [Server #554754] Sending 0.26 MB of payload data to client #302 (simulated).
[INFO][10:44:12]: [Server #554754] Selecting client #408 for training.
[INFO][10:44:12]: [Server #554754] Sending the current model to client #408 (simulated).
[INFO][10:44:12]: [Server #554754] Sending 0.26 MB of payload data to client #408 (simulated).
[INFO][10:44:12]: [Client #302] Selected by the server.
[INFO][10:44:12]: [Client #302] Loading its data source...
[INFO][10:44:12]: Data source: FEMNIST
[INFO][10:44:12]: [Client #408] Selected by the server.
[INFO][10:44:12]: [Client #408] Loading its data source...
[INFO][10:44:12]: Data source: FEMNIST
[INFO][10:44:12]: [Client #302] Dataset size: 160
[INFO][10:44:12]: [Client #302] Sampler: all_inclusive
[INFO][10:44:12]: [Client #408] Dataset size: 156
[INFO][10:44:12]: [Client #408] Sampler: all_inclusive
[INFO][10:44:12]: [Client #302] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:44:12]: [Client #408] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:44:12]: [93m[1m[Client #302] Started training in communication round #27.[0m
[INFO][10:44:12]: [93m[1m[Client #408] Started training in communication round #27.[0m
[INFO][10:44:13]: [Client #302] Loading the dataset.
[INFO][10:44:14]: [Client #408] Loading the dataset.
[INFO][10:44:19]: [Client #302] Epoch: [1/5][0/16]	Loss: 0.239158
[INFO][10:44:19]: [Client #408] Epoch: [1/5][0/16]	Loss: 0.768027
[INFO][10:44:19]: [Client #302] Epoch: [1/5][10/16]	Loss: 1.376696
[INFO][10:44:19]: [Client #408] Epoch: [1/5][10/16]	Loss: 1.003539
[INFO][10:44:19]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][10:44:19]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][10:44:19]: [Client #408] Woke up.
[INFO][10:44:19]: [Client #408] Epoch: [2/5][0/16]	Loss: 1.255964
[INFO][10:44:19]: [Client #408] Epoch: [2/5][10/16]	Loss: 1.360178
[INFO][10:44:20]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][10:44:20]: [Client #408] Woke up.
[INFO][10:44:20]: [Client #408] Epoch: [3/5][0/16]	Loss: 0.406677
[INFO][10:44:20]: [Client #408] Epoch: [3/5][10/16]	Loss: 1.338451
[INFO][10:44:20]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][10:44:20]: [Client #408] Woke up.
[INFO][10:44:20]: [Client #408] Epoch: [4/5][0/16]	Loss: 0.315888
[INFO][10:44:21]: [Client #408] Epoch: [4/5][10/16]	Loss: 0.806834
[INFO][10:44:21]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][10:44:21]: [Client #408] Woke up.
[INFO][10:44:21]: [Client #408] Epoch: [5/5][0/16]	Loss: 0.504691
[INFO][10:44:21]: [Client #408] Epoch: [5/5][10/16]	Loss: 0.761365
[INFO][10:44:21]: [Client #408] Going to sleep for 0.36 seconds.
[INFO][10:44:21]: [Client #408] Woke up.
[INFO][10:44:21]: [Client #408] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_408_554860.pth.
[INFO][10:44:22]: [Client #408] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_408_554860.pth.
[INFO][10:44:22]: [Client #408] Model trained.
[INFO][10:44:22]: [Client #408] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:44:22]: [Server #554754] Received 0.26 MB of payload data from client #408 (simulated).
[INFO][10:44:26]: [Client #302] Woke up.
[INFO][10:44:26]: [Client #302] Epoch: [2/5][0/16]	Loss: 0.357442
[INFO][10:44:26]: [Client #302] Epoch: [2/5][10/16]	Loss: 1.700350
[INFO][10:44:26]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][10:44:33]: [Client #302] Woke up.
[INFO][10:44:33]: [Client #302] Epoch: [3/5][0/16]	Loss: 0.480371
[INFO][10:44:33]: [Client #302] Epoch: [3/5][10/16]	Loss: 0.726572
[INFO][10:44:33]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][10:44:40]: [Client #302] Woke up.
[INFO][10:44:40]: [Client #302] Epoch: [4/5][0/16]	Loss: 0.031324
[INFO][10:44:40]: [Client #302] Epoch: [4/5][10/16]	Loss: 0.882839
[INFO][10:44:40]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][10:44:47]: [Client #302] Woke up.
[INFO][10:44:47]: [Client #302] Epoch: [5/5][0/16]	Loss: 0.322609
[INFO][10:44:48]: [Client #302] Epoch: [5/5][10/16]	Loss: 0.601248
[INFO][10:44:48]: [Client #302] Going to sleep for 7.00 seconds.
[INFO][10:44:55]: [Client #302] Woke up.
[INFO][10:44:55]: [Client #302] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_302_554853.pth.
[INFO][10:44:55]: [Client #302] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_302_554853.pth.
[INFO][10:44:55]: [Client #302] Model trained.
[INFO][10:44:55]: [Client #302] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:44:55]: [Server #554754] Received 0.26 MB of payload data from client #302 (simulated).
[INFO][10:44:55]: [Server #554754] Selecting client #28 for training.
[INFO][10:44:55]: [Server #554754] Sending the current model to client #28 (simulated).
[INFO][10:44:55]: [Server #554754] Sending 0.26 MB of payload data to client #28 (simulated).
[INFO][10:44:55]: [Server #554754] Selecting client #66 for training.
[INFO][10:44:55]: [Server #554754] Sending the current model to client #66 (simulated).
[INFO][10:44:55]: [Server #554754] Sending 0.26 MB of payload data to client #66 (simulated).
[INFO][10:44:55]: [Client #28] Selected by the server.
[INFO][10:44:55]: [Client #28] Loading its data source...
[INFO][10:44:55]: Data source: FEMNIST
[INFO][10:44:55]: [Client #66] Selected by the server.
[INFO][10:44:55]: [Client #66] Loading its data source...
[INFO][10:44:55]: Data source: FEMNIST
[INFO][10:44:55]: [Client #66] Dataset size: 162
[INFO][10:44:55]: [Client #66] Sampler: all_inclusive
[INFO][10:44:55]: [Client #66] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:44:55]: [93m[1m[Client #66] Started training in communication round #27.[0m
[INFO][10:44:55]: [Client #28] Dataset size: 153
[INFO][10:44:55]: [Client #28] Sampler: all_inclusive
[INFO][10:44:55]: [Client #28] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:44:55]: [93m[1m[Client #28] Started training in communication round #27.[0m
[INFO][10:44:57]: [Client #28] Loading the dataset.
[INFO][10:44:57]: [Client #66] Loading the dataset.
[INFO][10:45:03]: [Client #28] Epoch: [1/5][0/16]	Loss: 1.018751
[INFO][10:45:03]: [Client #66] Epoch: [1/5][0/17]	Loss: 1.265199
[INFO][10:45:03]: [Client #28] Epoch: [1/5][10/16]	Loss: 0.287469
[INFO][10:45:03]: [Client #66] Epoch: [1/5][10/17]	Loss: 1.396704
[INFO][10:45:03]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][10:45:03]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][10:45:03]: [Client #28] Woke up.
[INFO][10:45:03]: [Client #28] Epoch: [2/5][0/16]	Loss: 0.523241
[INFO][10:45:03]: [Client #28] Epoch: [2/5][10/16]	Loss: 0.473800
[INFO][10:45:03]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][10:45:03]: [Client #28] Woke up.
[INFO][10:45:03]: [Client #28] Epoch: [3/5][0/16]	Loss: 0.480212
[INFO][10:45:03]: [Client #28] Epoch: [3/5][10/16]	Loss: 0.663259
[INFO][10:45:03]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][10:45:03]: [Client #28] Woke up.
[INFO][10:45:03]: [Client #28] Epoch: [4/5][0/16]	Loss: 0.903219
[INFO][10:45:03]: [Client #28] Epoch: [4/5][10/16]	Loss: 0.717890
[INFO][10:45:03]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][10:45:03]: [Client #28] Woke up.
[INFO][10:45:03]: [Client #28] Epoch: [5/5][0/16]	Loss: 0.108416
[INFO][10:45:03]: [Client #28] Epoch: [5/5][10/16]	Loss: 0.185997
[INFO][10:45:04]: [Client #28] Going to sleep for 0.04 seconds.
[INFO][10:45:04]: [Client #28] Woke up.
[INFO][10:45:04]: [Client #28] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_554853.pth.
[INFO][10:45:04]: [Client #66] Woke up.
[INFO][10:45:04]: [Client #66] Epoch: [2/5][0/17]	Loss: 0.861338
[INFO][10:45:04]: [Client #66] Epoch: [2/5][10/17]	Loss: 1.350197
[INFO][10:45:04]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][10:45:04]: [Client #28] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_28_554853.pth.
[INFO][10:45:04]: [Client #28] Model trained.
[INFO][10:45:04]: [Client #28] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:45:04]: [Server #554754] Received 0.26 MB of payload data from client #28 (simulated).
[INFO][10:45:05]: [Client #66] Woke up.
[INFO][10:45:05]: [Client #66] Epoch: [3/5][0/17]	Loss: 0.813903
[INFO][10:45:05]: [Client #66] Epoch: [3/5][10/17]	Loss: 0.324827
[INFO][10:45:05]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][10:45:07]: [Client #66] Woke up.
[INFO][10:45:07]: [Client #66] Epoch: [4/5][0/17]	Loss: 0.578211
[INFO][10:45:07]: [Client #66] Epoch: [4/5][10/17]	Loss: 0.455577
[INFO][10:45:07]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][10:45:08]: [Client #66] Woke up.
[INFO][10:45:08]: [Client #66] Epoch: [5/5][0/17]	Loss: 0.776689
[INFO][10:45:08]: [Client #66] Epoch: [5/5][10/17]	Loss: 0.598310
[INFO][10:45:08]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][10:45:09]: [Client #66] Woke up.
[INFO][10:45:09]: [Client #66] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][10:45:10]: [Client #66] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][10:45:10]: [Client #66] Model trained.
[INFO][10:45:10]: [Client #66] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:45:10]: [Server #554754] Received 0.26 MB of payload data from client #66 (simulated).
[INFO][10:45:10]: [Server #554754] Selecting client #422 for training.
[INFO][10:45:10]: [Server #554754] Sending the current model to client #422 (simulated).
[INFO][10:45:10]: [Server #554754] Sending 0.26 MB of payload data to client #422 (simulated).
[INFO][10:45:10]: [Server #554754] Selecting client #310 for training.
[INFO][10:45:10]: [Server #554754] Sending the current model to client #310 (simulated).
[INFO][10:45:10]: [Server #554754] Sending 0.26 MB of payload data to client #310 (simulated).
[INFO][10:45:10]: [Client #422] Selected by the server.
[INFO][10:45:10]: [Client #310] Selected by the server.
[INFO][10:45:10]: [Client #422] Loading its data source...
[INFO][10:45:10]: [Client #310] Loading its data source...
[INFO][10:45:10]: Data source: FEMNIST
[INFO][10:45:10]: Data source: FEMNIST
[INFO][10:45:10]: [Client #310] Dataset size: 164
[INFO][10:45:10]: [Client #310] Sampler: all_inclusive
[INFO][10:45:10]: [Client #310] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:45:10]: [93m[1m[Client #310] Started training in communication round #27.[0m
[INFO][10:45:10]: [Client #422] Dataset size: 273
[INFO][10:45:10]: [Client #422] Sampler: all_inclusive
[INFO][10:45:10]: [Client #422] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:45:10]: [93m[1m[Client #422] Started training in communication round #27.[0m
[INFO][10:45:12]: [Client #422] Loading the dataset.
[INFO][10:45:12]: [Client #310] Loading the dataset.
[INFO][10:45:17]: [Client #422] Epoch: [1/5][0/28]	Loss: 0.807934
[INFO][10:45:17]: [Client #310] Epoch: [1/5][0/17]	Loss: 0.453896
[INFO][10:45:17]: [Client #422] Epoch: [1/5][10/28]	Loss: 0.463213
[INFO][10:45:17]: [Client #310] Epoch: [1/5][10/17]	Loss: 2.233990
[INFO][10:45:17]: [Client #422] Epoch: [1/5][20/28]	Loss: 1.542360
[INFO][10:45:17]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:45:17]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:45:18]: [Client #422] Woke up.
[INFO][10:45:18]: [Client #422] Epoch: [2/5][0/28]	Loss: 0.683351
[INFO][10:45:18]: [Client #422] Epoch: [2/5][10/28]	Loss: 0.945949
[INFO][10:45:18]: [Client #422] Epoch: [2/5][20/28]	Loss: 0.980165
[INFO][10:45:18]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:45:18]: [Client #422] Woke up.
[INFO][10:45:18]: [Client #422] Epoch: [3/5][0/28]	Loss: 0.469163
[INFO][10:45:18]: [Client #310] Woke up.
[INFO][10:45:18]: [Client #422] Epoch: [3/5][10/28]	Loss: 1.323928
[INFO][10:45:18]: [Client #310] Epoch: [2/5][0/17]	Loss: 1.325644
[INFO][10:45:18]: [Client #422] Epoch: [3/5][20/28]	Loss: 1.129530
[INFO][10:45:18]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:45:18]: [Client #310] Epoch: [2/5][10/17]	Loss: 0.963176
[INFO][10:45:18]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:45:18]: [Client #422] Woke up.
[INFO][10:45:18]: [Client #422] Epoch: [4/5][0/28]	Loss: 0.622159
[INFO][10:45:18]: [Client #422] Epoch: [4/5][10/28]	Loss: 0.697702
[INFO][10:45:18]: [Client #422] Epoch: [4/5][20/28]	Loss: 0.908383
[INFO][10:45:18]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:45:18]: [Client #422] Woke up.
[INFO][10:45:18]: [Client #422] Epoch: [5/5][0/28]	Loss: 0.706581
[INFO][10:45:18]: [Client #422] Epoch: [5/5][10/28]	Loss: 1.066911
[INFO][10:45:19]: [Client #422] Epoch: [5/5][20/28]	Loss: 0.795779
[INFO][10:45:19]: [Client #310] Woke up.
[INFO][10:45:19]: [Client #310] Epoch: [3/5][0/17]	Loss: 0.453178
[INFO][10:45:19]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][10:45:19]: [Client #310] Epoch: [3/5][10/17]	Loss: 0.695095
[INFO][10:45:19]: [Client #422] Woke up.
[INFO][10:45:19]: [Client #422] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554853.pth.
[INFO][10:45:19]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:45:19]: [Client #310] Woke up.
[INFO][10:45:19]: [Client #310] Epoch: [4/5][0/17]	Loss: 1.170748
[INFO][10:45:19]: [Client #310] Epoch: [4/5][10/17]	Loss: 0.423560
[INFO][10:45:19]: [Client #422] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554853.pth.
[INFO][10:45:19]: [Client #422] Model trained.
[INFO][10:45:19]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:45:19]: [Client #422] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:45:19]: [Server #554754] Received 0.26 MB of payload data from client #422 (simulated).
[INFO][10:45:20]: [Client #310] Woke up.
[INFO][10:45:20]: [Client #310] Epoch: [5/5][0/17]	Loss: 0.463999
[INFO][10:45:20]: [Client #310] Epoch: [5/5][10/17]	Loss: 0.200875
[INFO][10:45:20]: [Client #310] Going to sleep for 0.45 seconds.
[INFO][10:45:20]: [Client #310] Woke up.
[INFO][10:45:20]: [Client #310] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_310_554860.pth.
[INFO][10:45:21]: [Client #310] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_310_554860.pth.
[INFO][10:45:21]: [Client #310] Model trained.
[INFO][10:45:21]: [Client #310] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:45:21]: [Server #554754] Received 0.26 MB of payload data from client #310 (simulated).
[INFO][10:45:21]: [Server #554754] Selecting client #267 for training.
[INFO][10:45:21]: [Server #554754] Sending the current model to client #267 (simulated).
[INFO][10:45:21]: [Server #554754] Sending 0.26 MB of payload data to client #267 (simulated).
[INFO][10:45:21]: [Server #554754] Selecting client #125 for training.
[INFO][10:45:21]: [Server #554754] Sending the current model to client #125 (simulated).
[INFO][10:45:21]: [Server #554754] Sending 0.26 MB of payload data to client #125 (simulated).
[INFO][10:45:21]: [Client #267] Selected by the server.
[INFO][10:45:21]: [Client #125] Selected by the server.
[INFO][10:45:21]: [Client #267] Loading its data source...
[INFO][10:45:21]: Data source: FEMNIST
[INFO][10:45:21]: [Client #125] Loading its data source...
[INFO][10:45:21]: Data source: FEMNIST
[INFO][10:45:21]: [Client #125] Dataset size: 158
[INFO][10:45:21]: [Client #125] Sampler: all_inclusive
[INFO][10:45:21]: [Client #125] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:45:21]: [93m[1m[Client #125] Started training in communication round #27.[0m
[INFO][10:45:21]: [Client #267] Dataset size: 288
[INFO][10:45:21]: [Client #267] Sampler: all_inclusive
[INFO][10:45:21]: [Client #267] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:45:21]: [93m[1m[Client #267] Started training in communication round #27.[0m
[INFO][10:45:23]: [Client #125] Loading the dataset.
[INFO][10:45:23]: [Client #267] Loading the dataset.
[INFO][10:45:28]: [Client #125] Epoch: [1/5][0/16]	Loss: 1.256185
[INFO][10:45:28]: [Client #267] Epoch: [1/5][0/29]	Loss: 1.323603
[INFO][10:45:29]: [Client #125] Epoch: [1/5][10/16]	Loss: 1.086474
[INFO][10:45:29]: [Client #267] Epoch: [1/5][10/29]	Loss: 0.377224
[INFO][10:45:29]: [Client #125] Going to sleep for 6.14 seconds.
[INFO][10:45:29]: [Client #267] Epoch: [1/5][20/29]	Loss: 0.480017
[INFO][10:45:29]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][10:45:31]: [Client #267] Woke up.
[INFO][10:45:31]: [Client #267] Epoch: [2/5][0/29]	Loss: 1.085837
[INFO][10:45:31]: [Client #267] Epoch: [2/5][10/29]	Loss: 0.246040
[INFO][10:45:31]: [Client #267] Epoch: [2/5][20/29]	Loss: 1.387093
[INFO][10:45:31]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][10:45:33]: [Client #267] Woke up.
[INFO][10:45:33]: [Client #267] Epoch: [3/5][0/29]	Loss: 0.589241
[INFO][10:45:33]: [Client #267] Epoch: [3/5][10/29]	Loss: 1.270591
[INFO][10:45:33]: [Client #267] Epoch: [3/5][20/29]	Loss: 1.495826
[INFO][10:45:33]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][10:45:35]: [Client #125] Woke up.
[INFO][10:45:35]: [Client #125] Epoch: [2/5][0/16]	Loss: 0.790037
[INFO][10:45:35]: [Client #125] Epoch: [2/5][10/16]	Loss: 0.579230
[INFO][10:45:35]: [Client #125] Going to sleep for 6.14 seconds.
[INFO][10:45:35]: [Client #267] Woke up.
[INFO][10:45:35]: [Client #267] Epoch: [4/5][0/29]	Loss: 1.077587
[INFO][10:45:35]: [Client #267] Epoch: [4/5][10/29]	Loss: 0.762107
[INFO][10:45:36]: [Client #267] Epoch: [4/5][20/29]	Loss: 1.597393
[INFO][10:45:36]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][10:45:38]: [Client #267] Woke up.
[INFO][10:45:38]: [Client #267] Epoch: [5/5][0/29]	Loss: 0.762999
[INFO][10:45:38]: [Client #267] Epoch: [5/5][10/29]	Loss: 1.495341
[INFO][10:45:38]: [Client #267] Epoch: [5/5][20/29]	Loss: 1.792983
[INFO][10:45:38]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][10:45:40]: [Client #267] Woke up.
[INFO][10:45:40]: [Client #267] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_267_554853.pth.
[INFO][10:45:41]: [Client #267] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_267_554853.pth.
[INFO][10:45:41]: [Client #267] Model trained.
[INFO][10:45:41]: [Client #267] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:45:41]: [Server #554754] Received 0.26 MB of payload data from client #267 (simulated).
[INFO][10:45:41]: [Client #125] Woke up.
[INFO][10:45:41]: [Client #125] Epoch: [3/5][0/16]	Loss: 0.375670
[INFO][10:45:41]: [Client #125] Epoch: [3/5][10/16]	Loss: 0.478568
[INFO][10:45:41]: [Client #125] Going to sleep for 6.14 seconds.
[INFO][10:45:47]: [Client #125] Woke up.
[INFO][10:45:47]: [Client #125] Epoch: [4/5][0/16]	Loss: 0.668826
[INFO][10:45:47]: [Client #125] Epoch: [4/5][10/16]	Loss: 0.401341
[INFO][10:45:47]: [Client #125] Going to sleep for 6.14 seconds.
[INFO][10:45:54]: [Client #125] Woke up.
[INFO][10:45:54]: [Client #125] Epoch: [5/5][0/16]	Loss: 0.964951
[INFO][10:45:54]: [Client #125] Epoch: [5/5][10/16]	Loss: 0.643741
[INFO][10:45:54]: [Client #125] Going to sleep for 6.14 seconds.
[INFO][10:46:00]: [Client #125] Woke up.
[INFO][10:46:00]: [Client #125] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_125_554860.pth.
[INFO][10:46:01]: [Client #125] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_125_554860.pth.
[INFO][10:46:01]: [Client #125] Model trained.
[INFO][10:46:01]: [Client #125] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:46:01]: [Server #554754] Received 0.26 MB of payload data from client #125 (simulated).
[INFO][10:46:01]: [Server #554754] Adding client #22 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #28 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #422 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #408 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #310 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #66 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #267 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #128 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #125 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Adding client #302 to the list of clients for aggregation.
[INFO][10:46:01]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12113576 0.         0.
 0.         0.         0.         0.08813785 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20323717
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10229201 0.
 0.         0.11092042 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.23798215 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10409037 0.         0.         0.         0.
 0.         0.         0.         0.10627288 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07963786
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.230368   0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.12113576 0.         0.
 0.         0.         0.         0.08813785 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20323717
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10229201 0.
 0.         0.11092042 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.23798215 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10409037 0.         0.         0.         0.
 0.         0.         0.         0.10627288 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07963786
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.230368   0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:46:44]: [Server #554754] Global model accuracy: 63.72%

[INFO][10:46:44]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_27.pth.
[INFO][10:46:44]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_27.pth.
[INFO][10:46:44]: [93m[1m
[Server #554754] Starting round 28/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.0912031  0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.08783415 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.002      0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08045977 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.09190751 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08251366 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08743169 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.08429752 0.002      0.15711948 0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.002      0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.002      0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.09079284 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.08510638
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.002      0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.04972711 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.08900524 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  4e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  1e-09  2e-10
 7:  6.9057e+00  6.9056e+00  1e-04  3e-09  3e-10
 8:  6.9057e+00  6.9056e+00  6e-05  3e-08  4e-09
 9:  6.9057e+00  6.9056e+00  3e-05  3e-08  4e-09
10:  6.9056e+00  6.9056e+00  2e-06  2e-08  3e-09
Optimal solution found.
The calculated probability is:  [4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 9.78499954e-01 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31448520e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.29875623e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31309736e-05 4.31766808e-05 4.31766808e-05 4.31229464e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.23676800e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31281494e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31235369e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31496634e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.24937217e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05 4.31766808e-05
 4.31766808e-05 4.31766808e-05 4.31766808e-05]
current clients pool:  [INFO][10:46:45]: [Server #554754] Selected clients: [ 22 265 314 428 142 443 285  59 115 299]
[INFO][10:46:45]: [Server #554754] Selecting client #22 for training.
[INFO][10:46:45]: [Server #554754] Sending the current model to client #22 (simulated).
[INFO][10:46:45]: [Server #554754] Sending 0.26 MB of payload data to client #22 (simulated).
[INFO][10:46:45]: [Server #554754] Selecting client #265 for training.
[INFO][10:46:45]: [Server #554754] Sending the current model to client #265 (simulated).
[INFO][10:46:45]: [Server #554754] Sending 0.26 MB of payload data to client #265 (simulated).
[INFO][10:46:45]: [Client #22] Selected by the server.
[INFO][10:46:45]: [Client #22] Loading its data source...
[INFO][10:46:45]: Data source: FEMNIST
[INFO][10:46:45]: [Client #265] Selected by the server.
[INFO][10:46:45]: [Client #265] Loading its data source...
[INFO][10:46:45]: Data source: FEMNIST
[INFO][10:46:45]: [Client #265] Dataset size: 153
[INFO][10:46:45]: [Client #265] Sampler: all_inclusive
[INFO][10:46:45]: [Client #265] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:46:45]: [Client #22] Dataset size: 161
[INFO][10:46:45]: [Client #22] Sampler: all_inclusive
[INFO][10:46:45]: [Client #22] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:46:45]: [93m[1m[Client #265] Started training in communication round #28.[0m
[INFO][10:46:45]: [93m[1m[Client #22] Started training in communication round #28.[0m
[INFO][10:46:47]: [Client #22] Loading the dataset.
[INFO][10:46:47]: [Client #265] Loading the dataset.
[INFO][10:46:52]: [Client #265] Epoch: [1/5][0/16]	Loss: 1.238854
[INFO][10:46:52]: [Client #22] Epoch: [1/5][0/17]	Loss: 0.484729
[INFO][10:46:52]: [Client #265] Epoch: [1/5][10/16]	Loss: 0.475292
[INFO][10:46:52]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:46:52]: [Client #22] Epoch: [1/5][10/17]	Loss: 0.633216
[INFO][10:46:52]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:46:59]: [Client #265] Woke up.
[INFO][10:46:59]: [Client #265] Epoch: [2/5][0/16]	Loss: 0.195662
[INFO][10:46:59]: [Client #265] Epoch: [2/5][10/16]	Loss: 0.485227
[INFO][10:46:59]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:47:05]: [Client #265] Woke up.
[INFO][10:47:05]: [Client #265] Epoch: [3/5][0/16]	Loss: 0.145395
[INFO][10:47:05]: [Client #265] Epoch: [3/5][10/16]	Loss: 0.472027
[INFO][10:47:05]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:47:12]: [Client #265] Woke up.
[INFO][10:47:12]: [Client #265] Epoch: [4/5][0/16]	Loss: 0.704374
[INFO][10:47:12]: [Client #265] Epoch: [4/5][10/16]	Loss: 0.808492
[INFO][10:47:12]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:47:18]: [Client #265] Woke up.
[INFO][10:47:18]: [Client #265] Epoch: [5/5][0/16]	Loss: 0.512940
[INFO][10:47:18]: [Client #265] Epoch: [5/5][10/16]	Loss: 0.212885
[INFO][10:47:18]: [Client #265] Going to sleep for 6.38 seconds.
[INFO][10:47:23]: [Client #22] Woke up.
[INFO][10:47:23]: [Client #22] Epoch: [2/5][0/17]	Loss: 0.666861
[INFO][10:47:23]: [Client #22] Epoch: [2/5][10/17]	Loss: 1.819286
[INFO][10:47:23]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:47:25]: [Client #265] Woke up.
[INFO][10:47:25]: [Client #265] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_265_554860.pth.
[INFO][10:47:25]: [Client #265] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_265_554860.pth.
[INFO][10:47:25]: [Client #265] Model trained.
[INFO][10:47:25]: [Client #265] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:47:25]: [Server #554754] Received 0.26 MB of payload data from client #265 (simulated).
[INFO][10:47:54]: [Client #22] Woke up.
[INFO][10:47:54]: [Client #22] Epoch: [3/5][0/17]	Loss: 0.632607
[INFO][10:47:54]: [Client #22] Epoch: [3/5][10/17]	Loss: 0.585045
[INFO][10:47:54]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:48:24]: [Client #22] Woke up.
[INFO][10:48:24]: [Client #22] Epoch: [4/5][0/17]	Loss: 0.738039
[INFO][10:48:25]: [Client #22] Epoch: [4/5][10/17]	Loss: 1.164001
[INFO][10:48:25]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:48:55]: [Client #22] Woke up.
[INFO][10:48:55]: [Client #22] Epoch: [5/5][0/17]	Loss: 0.552218
[INFO][10:48:55]: [Client #22] Epoch: [5/5][10/17]	Loss: 0.656425
[INFO][10:48:55]: [Client #22] Going to sleep for 30.51 seconds.
[INFO][10:49:26]: [Client #22] Woke up.
[INFO][10:49:26]: [Client #22] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_554853.pth.
[INFO][10:49:27]: [Client #22] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_22_554853.pth.
[INFO][10:49:27]: [Client #22] Model trained.
[INFO][10:49:27]: [Client #22] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:49:27]: [Server #554754] Received 0.26 MB of payload data from client #22 (simulated).
[INFO][10:49:27]: [Server #554754] Selecting client #314 for training.
[INFO][10:49:27]: [Server #554754] Sending the current model to client #314 (simulated).
[INFO][10:49:27]: [Server #554754] Sending 0.26 MB of payload data to client #314 (simulated).
[INFO][10:49:27]: [Server #554754] Selecting client #428 for training.
[INFO][10:49:27]: [Server #554754] Sending the current model to client #428 (simulated).
[INFO][10:49:27]: [Server #554754] Sending 0.26 MB of payload data to client #428 (simulated).
[INFO][10:49:27]: [Client #314] Selected by the server.
[INFO][10:49:27]: [Client #314] Loading its data source...
[INFO][10:49:27]: Data source: FEMNIST
[INFO][10:49:27]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][10:49:27]: [Client #428] Selected by the server.
[INFO][10:49:27]: [Client #428] Loading its data source...
[INFO][10:49:27]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/314.zip.
[INFO][10:49:27]: Data source: FEMNIST
[INFO][10:49:27]: [Client #428] Dataset size: 159
[INFO][10:49:27]: [Client #428] Sampler: all_inclusive
[INFO][10:49:27]: [Client #428] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:49:27]: [93m[1m[Client #428] Started training in communication round #28.[0m

3.5%
6.9%
10.4%
13.9%
17.4%
20.8%
24.3%
27.8%
31.2%
34.7%
38.2%
41.7%
45.1%
48.6%
52.1%
55.5%
59.0%
62.5%
66.0%
69.4%
72.9%
76.4%
79.8%
83.3%
86.8%
90.3%
93.7%
97.2%
100.0%[INFO][10:49:27]: Decompressing the dataset downloaded.
[INFO][10:49:27]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/314.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][10:49:27]: [Client #314] Dataset size: 122
[INFO][10:49:27]: [Client #314] Sampler: all_inclusive
[INFO][10:49:27]: [Client #314] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:49:27]: [93m[1m[Client #314] Started training in communication round #28.[0m

[INFO][10:49:29]: [Client #428] Loading the dataset.
[INFO][10:49:29]: [Client #314] Loading the dataset.
[INFO][10:49:34]: [Client #428] Epoch: [1/5][0/16]	Loss: 1.158053
[INFO][10:49:34]: [Client #314] Epoch: [1/5][0/13]	Loss: 1.834672
[INFO][10:49:34]: [Client #428] Epoch: [1/5][10/16]	Loss: 1.043385
[INFO][10:49:34]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][10:49:34]: [Client #314] Epoch: [1/5][10/13]	Loss: 0.690322
[INFO][10:49:34]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][10:49:34]: [Client #314] Woke up.
[INFO][10:49:34]: [Client #314] Epoch: [2/5][0/13]	Loss: 0.690167
[INFO][10:49:34]: [Client #314] Epoch: [2/5][10/13]	Loss: 0.421667
[INFO][10:49:34]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][10:49:35]: [Client #314] Woke up.
[INFO][10:49:35]: [Client #314] Epoch: [3/5][0/13]	Loss: 1.171757
[INFO][10:49:35]: [Client #314] Epoch: [3/5][10/13]	Loss: 0.757625
[INFO][10:49:35]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][10:49:35]: [Client #314] Woke up.
[INFO][10:49:35]: [Client #314] Epoch: [4/5][0/13]	Loss: 0.381460
[INFO][10:49:35]: [Client #314] Epoch: [4/5][10/13]	Loss: 0.439570
[INFO][10:49:35]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][10:49:35]: [Client #314] Woke up.
[INFO][10:49:35]: [Client #314] Epoch: [5/5][0/13]	Loss: 0.599303
[INFO][10:49:35]: [Client #314] Epoch: [5/5][10/13]	Loss: 0.943321
[INFO][10:49:35]: [Client #314] Going to sleep for 0.12 seconds.
[INFO][10:49:35]: [Client #314] Woke up.
[INFO][10:49:35]: [Client #314] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_314_554853.pth.
[INFO][10:49:36]: [Client #314] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_314_554853.pth.
[INFO][10:49:36]: [Client #314] Model trained.
[INFO][10:49:36]: [Client #314] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:49:36]: [Server #554754] Received 0.26 MB of payload data from client #314 (simulated).
[INFO][10:49:37]: [Client #428] Woke up.
[INFO][10:49:37]: [Client #428] Epoch: [2/5][0/16]	Loss: 1.316967
[INFO][10:49:37]: [Client #428] Epoch: [2/5][10/16]	Loss: 0.842648
[INFO][10:49:37]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][10:49:40]: [Client #428] Woke up.
[INFO][10:49:41]: [Client #428] Epoch: [3/5][0/16]	Loss: 0.580724
[INFO][10:49:41]: [Client #428] Epoch: [3/5][10/16]	Loss: 0.675204
[INFO][10:49:41]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][10:49:44]: [Client #428] Woke up.
[INFO][10:49:44]: [Client #428] Epoch: [4/5][0/16]	Loss: 0.621429
[INFO][10:49:44]: [Client #428] Epoch: [4/5][10/16]	Loss: 0.170520
[INFO][10:49:44]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][10:49:47]: [Client #428] Woke up.
[INFO][10:49:47]: [Client #428] Epoch: [5/5][0/16]	Loss: 0.308563
[INFO][10:49:47]: [Client #428] Epoch: [5/5][10/16]	Loss: 0.234239
[INFO][10:49:47]: [Client #428] Going to sleep for 3.08 seconds.
[INFO][10:49:50]: [Client #428] Woke up.
[INFO][10:49:50]: [Client #428] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_554860.pth.
[INFO][10:49:51]: [Client #428] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_428_554860.pth.
[INFO][10:49:51]: [Client #428] Model trained.
[INFO][10:49:51]: [Client #428] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:49:51]: [Server #554754] Received 0.26 MB of payload data from client #428 (simulated).
[INFO][10:49:51]: [Server #554754] Selecting client #142 for training.
[INFO][10:49:51]: [Server #554754] Sending the current model to client #142 (simulated).
[INFO][10:49:51]: [Server #554754] Sending 0.26 MB of payload data to client #142 (simulated).
[INFO][10:49:51]: [Server #554754] Selecting client #443 for training.
[INFO][10:49:51]: [Server #554754] Sending the current model to client #443 (simulated).
[INFO][10:49:51]: [Server #554754] Sending 0.26 MB of payload data to client #443 (simulated).
[INFO][10:49:51]: [Client #142] Selected by the server.
[INFO][10:49:51]: [Client #142] Loading its data source...
[INFO][10:49:51]: [Client #443] Selected by the server.
[INFO][10:49:51]: Data source: FEMNIST
[INFO][10:49:51]: [Client #443] Loading its data source...
[INFO][10:49:51]: Data source: FEMNIST
[INFO][10:49:51]: [Client #142] Dataset size: 159
[INFO][10:49:51]: [Client #142] Sampler: all_inclusive
[INFO][10:49:51]: [Client #443] Dataset size: 164
[INFO][10:49:51]: [Client #443] Sampler: all_inclusive
[INFO][10:49:51]: [Client #142] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:49:51]: [Client #443] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:49:51]: [93m[1m[Client #443] Started training in communication round #28.[0m
[INFO][10:49:51]: [93m[1m[Client #142] Started training in communication round #28.[0m
[INFO][10:49:53]: [Client #443] Loading the dataset.
[INFO][10:49:53]: [Client #142] Loading the dataset.
[INFO][10:49:58]: [Client #142] Epoch: [1/5][0/16]	Loss: 0.984483
[INFO][10:49:58]: [Client #443] Epoch: [1/5][0/17]	Loss: 0.616827
[INFO][10:49:58]: [Client #142] Epoch: [1/5][10/16]	Loss: 0.405817
[INFO][10:49:58]: [Client #443] Epoch: [1/5][10/17]	Loss: 0.412602
[INFO][10:49:58]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][10:49:58]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][10:49:59]: [Client #142] Woke up.
[INFO][10:49:59]: [Client #142] Epoch: [2/5][0/16]	Loss: 0.343028
[INFO][10:49:59]: [Client #142] Epoch: [2/5][10/16]	Loss: 0.541727
[INFO][10:49:59]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][10:49:59]: [Client #142] Woke up.
[INFO][10:49:59]: [Client #142] Epoch: [3/5][0/16]	Loss: 0.169625
[INFO][10:49:59]: [Client #142] Epoch: [3/5][10/16]	Loss: 0.106485
[INFO][10:49:59]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][10:49:59]: [Client #142] Woke up.
[INFO][10:49:59]: [Client #142] Epoch: [4/5][0/16]	Loss: 0.283478
[INFO][10:49:59]: [Client #142] Epoch: [4/5][10/16]	Loss: 0.807810
[INFO][10:49:59]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][10:49:59]: [Client #142] Woke up.
[INFO][10:50:00]: [Client #142] Epoch: [5/5][0/16]	Loss: 0.401817
[INFO][10:50:00]: [Client #142] Epoch: [5/5][10/16]	Loss: 0.468243
[INFO][10:50:00]: [Client #142] Going to sleep for 0.16 seconds.
[INFO][10:50:00]: [Client #443] Woke up.
[INFO][10:50:00]: [Client #443] Epoch: [2/5][0/17]	Loss: 0.512211
[INFO][10:50:00]: [Client #443] Epoch: [2/5][10/17]	Loss: 0.411249
[INFO][10:50:00]: [Client #142] Woke up.
[INFO][10:50:00]: [Client #142] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_554853.pth.
[INFO][10:50:00]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][10:50:00]: [Client #142] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_142_554853.pth.
[INFO][10:50:00]: [Client #142] Model trained.
[INFO][10:50:00]: [Client #142] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:50:00]: [Server #554754] Received 0.26 MB of payload data from client #142 (simulated).
[INFO][10:50:01]: [Client #443] Woke up.
[INFO][10:50:01]: [Client #443] Epoch: [3/5][0/17]	Loss: 0.513818
[INFO][10:50:01]: [Client #443] Epoch: [3/5][10/17]	Loss: 0.076736
[INFO][10:50:01]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][10:50:02]: [Client #443] Woke up.
[INFO][10:50:02]: [Client #443] Epoch: [4/5][0/17]	Loss: 0.758236
[INFO][10:50:02]: [Client #443] Epoch: [4/5][10/17]	Loss: 1.007650
[INFO][10:50:02]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][10:50:04]: [Client #443] Woke up.
[INFO][10:50:04]: [Client #443] Epoch: [5/5][0/17]	Loss: 0.699786
[INFO][10:50:04]: [Client #443] Epoch: [5/5][10/17]	Loss: 0.819511
[INFO][10:50:04]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][10:50:05]: [Client #443] Woke up.
[INFO][10:50:05]: [Client #443] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][10:50:06]: [Client #443] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][10:50:06]: [Client #443] Model trained.
[INFO][10:50:06]: [Client #443] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:50:06]: [Server #554754] Received 0.26 MB of payload data from client #443 (simulated).
[INFO][10:50:06]: [Server #554754] Selecting client #285 for training.
[INFO][10:50:06]: [Server #554754] Sending the current model to client #285 (simulated).
[INFO][10:50:06]: [Server #554754] Sending 0.26 MB of payload data to client #285 (simulated).
[INFO][10:50:06]: [Server #554754] Selecting client #59 for training.
[INFO][10:50:06]: [Server #554754] Sending the current model to client #59 (simulated).
[INFO][10:50:06]: [Server #554754] Sending 0.26 MB of payload data to client #59 (simulated).
[INFO][10:50:06]: [Client #285] Selected by the server.
[INFO][10:50:06]: [Client #285] Loading its data source...
[INFO][10:50:06]: Data source: FEMNIST
[INFO][10:50:06]: [Client #59] Selected by the server.
[INFO][10:50:06]: [Client #59] Loading its data source...
[INFO][10:50:06]: Data source: FEMNIST
[INFO][10:50:06]: [Client #285] Dataset size: 163
[INFO][10:50:06]: [Client #285] Sampler: all_inclusive
[INFO][10:50:06]: [Client #285] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:50:06]: [93m[1m[Client #285] Started training in communication round #28.[0m
[INFO][10:50:06]: [Client #59] Dataset size: 159
[INFO][10:50:06]: [Client #59] Sampler: all_inclusive
[INFO][10:50:06]: [Client #59] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:50:06]: [93m[1m[Client #59] Started training in communication round #28.[0m
[INFO][10:50:08]: [Client #59] Loading the dataset.
[INFO][10:50:08]: [Client #285] Loading the dataset.
[INFO][10:50:13]: [Client #59] Epoch: [1/5][0/16]	Loss: 0.739398
[INFO][10:50:13]: [Client #285] Epoch: [1/5][0/17]	Loss: 0.988351
[INFO][10:50:13]: [Client #59] Epoch: [1/5][10/16]	Loss: 0.737028
[INFO][10:50:13]: [Client #59] Going to sleep for 1.43 seconds.
[INFO][10:50:13]: [Client #285] Epoch: [1/5][10/17]	Loss: 1.319624
[INFO][10:50:13]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][10:50:14]: [Client #285] Woke up.
[INFO][10:50:14]: [Client #285] Epoch: [2/5][0/17]	Loss: 0.372780
[INFO][10:50:14]: [Client #285] Epoch: [2/5][10/17]	Loss: 1.889443
[INFO][10:50:14]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][10:50:14]: [Client #285] Woke up.
[INFO][10:50:14]: [Client #285] Epoch: [3/5][0/17]	Loss: 1.424400
[INFO][10:50:14]: [Client #285] Epoch: [3/5][10/17]	Loss: 0.730245
[INFO][10:50:14]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][10:50:15]: [Client #59] Woke up.
[INFO][10:50:15]: [Client #285] Woke up.
[INFO][10:50:15]: [Client #59] Epoch: [2/5][0/16]	Loss: 0.404314
[INFO][10:50:15]: [Client #285] Epoch: [4/5][0/17]	Loss: 0.369956
[INFO][10:50:15]: [Client #59] Epoch: [2/5][10/16]	Loss: 0.394839
[INFO][10:50:15]: [Client #285] Epoch: [4/5][10/17]	Loss: 0.310497
[INFO][10:50:15]: [Client #59] Going to sleep for 1.43 seconds.
[INFO][10:50:15]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][10:50:15]: [Client #285] Woke up.
[INFO][10:50:15]: [Client #285] Epoch: [5/5][0/17]	Loss: 0.176306
[INFO][10:50:15]: [Client #285] Epoch: [5/5][10/17]	Loss: 1.291924
[INFO][10:50:15]: [Client #285] Going to sleep for 0.34 seconds.
[INFO][10:50:16]: [Client #285] Woke up.
[INFO][10:50:16]: [Client #285] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_285_554853.pth.
[INFO][10:50:16]: [Client #59] Woke up.
[INFO][10:50:16]: [Client #59] Epoch: [3/5][0/16]	Loss: 0.302496
[INFO][10:50:16]: [Client #285] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_285_554853.pth.
[INFO][10:50:16]: [Client #285] Model trained.
[INFO][10:50:16]: [Client #285] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:50:16]: [Server #554754] Received 0.26 MB of payload data from client #285 (simulated).
[INFO][10:50:16]: [Client #59] Epoch: [3/5][10/16]	Loss: 0.553200
[INFO][10:50:16]: [Client #59] Going to sleep for 1.43 seconds.
[INFO][10:50:18]: [Client #59] Woke up.
[INFO][10:50:18]: [Client #59] Epoch: [4/5][0/16]	Loss: 0.157979
[INFO][10:50:18]: [Client #59] Epoch: [4/5][10/16]	Loss: 0.318055
[INFO][10:50:18]: [Client #59] Going to sleep for 1.43 seconds.
[INFO][10:50:19]: [Client #59] Woke up.
[INFO][10:50:19]: [Client #59] Epoch: [5/5][0/16]	Loss: 1.270948
[INFO][10:50:19]: [Client #59] Epoch: [5/5][10/16]	Loss: 0.339188
[INFO][10:50:19]: [Client #59] Going to sleep for 1.43 seconds.
[INFO][10:50:21]: [Client #59] Woke up.
[INFO][10:50:21]: [Client #59] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_59_554860.pth.
[INFO][10:50:21]: [Client #59] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_59_554860.pth.
[INFO][10:50:21]: [Client #59] Model trained.
[INFO][10:50:22]: [Client #59] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:50:22]: [Server #554754] Received 0.26 MB of payload data from client #59 (simulated).
[INFO][10:50:22]: [Server #554754] Selecting client #115 for training.
[INFO][10:50:22]: [Server #554754] Sending the current model to client #115 (simulated).
[INFO][10:50:22]: [Server #554754] Sending 0.26 MB of payload data to client #115 (simulated).
[INFO][10:50:22]: [Server #554754] Selecting client #299 for training.
[INFO][10:50:22]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][10:50:22]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][10:50:22]: [Client #299] Selected by the server.
[INFO][10:50:22]: [Client #115] Selected by the server.
[INFO][10:50:22]: [Client #299] Loading its data source...
[INFO][10:50:22]: Data source: FEMNIST
[INFO][10:50:22]: [Client #115] Loading its data source...
[INFO][10:50:22]: Data source: FEMNIST
[INFO][10:50:22]: [Client #299] Dataset size: 157
[INFO][10:50:22]: [Client #299] Sampler: all_inclusive
[INFO][10:50:22]: [Client #115] Dataset size: 126
[INFO][10:50:22]: [Client #115] Sampler: all_inclusive
[INFO][10:50:22]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:50:22]: [Client #115] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:50:22]: [93m[1m[Client #299] Started training in communication round #28.[0m
[INFO][10:50:22]: [93m[1m[Client #115] Started training in communication round #28.[0m
[INFO][10:50:23]: [Client #115] Loading the dataset.
[INFO][10:50:23]: [Client #299] Loading the dataset.
[INFO][10:50:29]: [Client #115] Epoch: [1/5][0/13]	Loss: 0.816183
[INFO][10:50:29]: [Client #299] Epoch: [1/5][0/16]	Loss: 1.094486
[INFO][10:50:29]: [Client #115] Epoch: [1/5][10/13]	Loss: 1.210006
[INFO][10:50:29]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][10:50:29]: [Client #299] Epoch: [1/5][10/16]	Loss: 0.784615
[INFO][10:50:29]: [Client #115] Woke up.
[INFO][10:50:29]: [Client #115] Epoch: [2/5][0/13]	Loss: 0.781046
[INFO][10:50:29]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][10:50:29]: [Client #115] Epoch: [2/5][10/13]	Loss: 0.439464
[INFO][10:50:29]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][10:50:29]: [Client #115] Woke up.
[INFO][10:50:29]: [Client #115] Epoch: [3/5][0/13]	Loss: 0.615005
[INFO][10:50:29]: [Client #115] Epoch: [3/5][10/13]	Loss: 0.166177
[INFO][10:50:29]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][10:50:29]: [Client #115] Woke up.
[INFO][10:50:29]: [Client #115] Epoch: [4/5][0/13]	Loss: 1.122808
[INFO][10:50:29]: [Client #115] Epoch: [4/5][10/13]	Loss: 0.479222
[INFO][10:50:29]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][10:50:29]: [Client #115] Woke up.
[INFO][10:50:30]: [Client #115] Epoch: [5/5][0/13]	Loss: 0.522931
[INFO][10:50:30]: [Client #115] Epoch: [5/5][10/13]	Loss: 0.364384
[INFO][10:50:30]: [Client #115] Going to sleep for 0.07 seconds.
[INFO][10:50:30]: [Client #115] Woke up.
[INFO][10:50:30]: [Client #115] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554853.pth.
[INFO][10:50:30]: [Client #115] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_115_554853.pth.
[INFO][10:50:30]: [Client #115] Model trained.
[INFO][10:50:30]: [Client #115] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:50:30]: [Server #554754] Received 0.26 MB of payload data from client #115 (simulated).
[INFO][10:51:26]: [Client #299] Woke up.
[INFO][10:51:26]: [Client #299] Epoch: [2/5][0/16]	Loss: 0.373605
[INFO][10:51:26]: [Client #299] Epoch: [2/5][10/16]	Loss: 0.137621
[INFO][10:51:26]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][10:52:24]: [Client #299] Woke up.
[INFO][10:52:24]: [Client #299] Epoch: [3/5][0/16]	Loss: 0.463870
[INFO][10:52:24]: [Client #299] Epoch: [3/5][10/16]	Loss: 0.477924
[INFO][10:52:24]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][10:53:21]: [Client #299] Woke up.
[INFO][10:53:21]: [Client #299] Epoch: [4/5][0/16]	Loss: 0.181879
[INFO][10:53:21]: [Client #299] Epoch: [4/5][10/16]	Loss: 0.330956
[INFO][10:53:21]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][10:54:19]: [Client #299] Woke up.
[INFO][10:54:19]: [Client #299] Epoch: [5/5][0/16]	Loss: 0.115491
[INFO][10:54:19]: [Client #299] Epoch: [5/5][10/16]	Loss: 1.186919
[INFO][10:54:19]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][10:55:16]: [Client #299] Woke up.
[INFO][10:55:16]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554860.pth.
[INFO][10:55:17]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554860.pth.
[INFO][10:55:17]: [Client #299] Model trained.
[INFO][10:55:17]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:55:17]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][10:55:17]: [Server #554754] Adding client #115 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #314 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #142 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #285 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #443 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #59 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #428 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #265 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Adding client #22 to the list of clients for aggregation.
[INFO][10:55:17]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18220899 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08050941 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10868811 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08119119 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15435798 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06476011 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15763824 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26940916 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12163873 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09646081 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.18220899 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08050941 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10868811 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08119119 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15435798 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06476011 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15763824 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.26940916 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12163873 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09646081 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][10:56:01]: [Server #554754] Global model accuracy: 62.72%

[INFO][10:56:01]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_28.pth.
[INFO][10:56:01]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_28.pth.
[INFO][10:56:01]: [93m[1m
[Server #554754] Starting round 29/100.[0m
[0.002      0.04639175 0.10496183 0.09070165 0.04717531 0.002
 0.10114504 0.0912031  0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.002
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.002
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08251366 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.002      0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.10484928 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.002      0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.04760461 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09679487 0.09079284 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.08510638
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.002      0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.08900524 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  4e-09  6e-10
 7:  6.9057e+00  6.9056e+00  1e-04  4e-09  7e-10
 8:  6.9057e+00  6.9056e+00  8e-05  5e-08  8e-09
 9:  6.9057e+00  6.9056e+00  4e-05  5e-08  7e-09
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  6e-09
Optimal solution found.
The calculated probability is:  [4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.76445550e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78073015e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78017542e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78066485e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 9.76173730e-01
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78226965e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.76912546e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.75934312e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.77581002e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.77870680e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05 4.78457204e-05
 4.78457204e-05 4.78457204e-05 4.78457204e-05]
current clients pool:  [INFO][10:56:02]: [Server #554754] Selected clients: [212  30 376 475 268  96 377   4 164 459]
[INFO][10:56:02]: [Server #554754] Selecting client #212 for training.
[INFO][10:56:02]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][10:56:02]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][10:56:02]: [Server #554754] Selecting client #30 for training.
[INFO][10:56:02]: [Server #554754] Sending the current model to client #30 (simulated).
[INFO][10:56:02]: [Server #554754] Sending 0.26 MB of payload data to client #30 (simulated).
[INFO][10:56:02]: [Client #212] Selected by the server.
[INFO][10:56:02]: [Client #212] Loading its data source...
[INFO][10:56:02]: Data source: FEMNIST
[INFO][10:56:02]: [Client #30] Selected by the server.
[INFO][10:56:02]: [Client #30] Loading its data source...
[INFO][10:56:02]: Data source: FEMNIST
[INFO][10:56:02]: [Client #30] Dataset size: 150
[INFO][10:56:02]: [Client #30] Sampler: all_inclusive
[INFO][10:56:02]: [Client #212] Dataset size: 160
[INFO][10:56:02]: [Client #212] Sampler: all_inclusive
[INFO][10:56:02]: [Client #30] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:56:02]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:56:02]: [93m[1m[Client #30] Started training in communication round #29.[0m
[INFO][10:56:02]: [93m[1m[Client #212] Started training in communication round #29.[0m
[INFO][10:56:04]: [Client #30] Loading the dataset.
[INFO][10:56:04]: [Client #212] Loading the dataset.
[INFO][10:56:09]: [Client #30] Epoch: [1/5][0/15]	Loss: 2.758477
[INFO][10:56:09]: [Client #30] Epoch: [1/5][10/15]	Loss: 2.092639
[INFO][10:56:09]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.377835
[INFO][10:56:09]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][10:56:09]: [Client #212] Epoch: [1/5][10/16]	Loss: 0.990236
[INFO][10:56:09]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:56:16]: [Client #30] Woke up.
[INFO][10:56:16]: [Client #30] Epoch: [2/5][0/15]	Loss: 2.436862
[INFO][10:56:16]: [Client #30] Epoch: [2/5][10/15]	Loss: 1.542806
[INFO][10:56:16]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][10:56:24]: [Client #30] Woke up.
[INFO][10:56:24]: [Client #30] Epoch: [3/5][0/15]	Loss: 0.822357
[INFO][10:56:24]: [Client #30] Epoch: [3/5][10/15]	Loss: 1.124124
[INFO][10:56:24]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][10:56:31]: [Client #30] Woke up.
[INFO][10:56:31]: [Client #30] Epoch: [4/5][0/15]	Loss: 2.331737
[INFO][10:56:31]: [Client #30] Epoch: [4/5][10/15]	Loss: 1.484854
[INFO][10:56:31]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][10:56:35]: [Client #212] Woke up.
[INFO][10:56:35]: [Client #212] Epoch: [2/5][0/16]	Loss: 0.276734
[INFO][10:56:35]: [Client #212] Epoch: [2/5][10/16]	Loss: 2.257216
[INFO][10:56:36]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:56:38]: [Client #30] Woke up.
[INFO][10:56:38]: [Client #30] Epoch: [5/5][0/15]	Loss: 0.869066
[INFO][10:56:38]: [Client #30] Epoch: [5/5][10/15]	Loss: 1.077680
[INFO][10:56:38]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][10:56:46]: [Client #30] Woke up.
[INFO][10:56:46]: [Client #30] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_30_554860.pth.
[INFO][10:56:46]: [Client #30] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_30_554860.pth.
[INFO][10:56:46]: [Client #30] Model trained.
[INFO][10:56:46]: [Client #30] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:56:46]: [Server #554754] Received 0.26 MB of payload data from client #30 (simulated).
[INFO][10:57:02]: [Client #212] Woke up.
[INFO][10:57:02]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.047463
[INFO][10:57:02]: [Client #212] Epoch: [3/5][10/16]	Loss: 2.806288
[INFO][10:57:02]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:57:28]: [Client #212] Woke up.
[INFO][10:57:28]: [Client #212] Epoch: [4/5][0/16]	Loss: 0.383431
[INFO][10:57:29]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.095655
[INFO][10:57:29]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:57:55]: [Client #212] Woke up.
[INFO][10:57:55]: [Client #212] Epoch: [5/5][0/16]	Loss: 0.591941
[INFO][10:57:55]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.343343
[INFO][10:57:55]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][10:58:21]: [Client #212] Woke up.
[INFO][10:58:21]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:58:22]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][10:58:22]: [Client #212] Model trained.
[INFO][10:58:22]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:58:22]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][10:58:22]: [Server #554754] Selecting client #376 for training.
[INFO][10:58:22]: [Server #554754] Sending the current model to client #376 (simulated).
[INFO][10:58:22]: [Server #554754] Sending 0.26 MB of payload data to client #376 (simulated).
[INFO][10:58:22]: [Server #554754] Selecting client #475 for training.
[INFO][10:58:22]: [Server #554754] Sending the current model to client #475 (simulated).
[INFO][10:58:22]: [Server #554754] Sending 0.26 MB of payload data to client #475 (simulated).
[INFO][10:58:22]: [Client #376] Selected by the server.
[INFO][10:58:22]: [Client #376] Loading its data source...
[INFO][10:58:22]: Data source: FEMNIST
[INFO][10:58:22]: [Client #475] Selected by the server.
[INFO][10:58:22]: [Client #475] Loading its data source...
[INFO][10:58:22]: Data source: FEMNIST
[INFO][10:58:22]: [Client #475] Dataset size: 153
[INFO][10:58:22]: [Client #475] Sampler: all_inclusive
[INFO][10:58:22]: [Client #376] Dataset size: 151
[INFO][10:58:22]: [Client #376] Sampler: all_inclusive
[INFO][10:58:22]: [Client #475] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:58:22]: [Client #376] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:58:22]: [93m[1m[Client #475] Started training in communication round #29.[0m
[INFO][10:58:22]: [93m[1m[Client #376] Started training in communication round #29.[0m
[INFO][10:58:24]: [Client #376] Loading the dataset.
[INFO][10:58:24]: [Client #475] Loading the dataset.
[INFO][10:58:29]: [Client #376] Epoch: [1/5][0/16]	Loss: 0.732871
[INFO][10:58:29]: [Client #475] Epoch: [1/5][0/16]	Loss: 0.576395
[INFO][10:58:29]: [Client #376] Epoch: [1/5][10/16]	Loss: 1.326120
[INFO][10:58:30]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][10:58:30]: [Client #475] Epoch: [1/5][10/16]	Loss: 1.368785
[INFO][10:58:30]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][10:58:30]: [Client #376] Woke up.
[INFO][10:58:30]: [Client #376] Epoch: [2/5][0/16]	Loss: 1.005864
[INFO][10:58:30]: [Client #376] Epoch: [2/5][10/16]	Loss: 0.400803
[INFO][10:58:30]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][10:58:31]: [Client #376] Woke up.
[INFO][10:58:31]: [Client #376] Epoch: [3/5][0/16]	Loss: 0.446271
[INFO][10:58:31]: [Client #376] Epoch: [3/5][10/16]	Loss: 1.801350
[INFO][10:58:31]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][10:58:32]: [Client #376] Woke up.
[INFO][10:58:32]: [Client #376] Epoch: [4/5][0/16]	Loss: 0.985607
[INFO][10:58:32]: [Client #376] Epoch: [4/5][10/16]	Loss: 1.126732
[INFO][10:58:32]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][10:58:32]: [Client #376] Woke up.
[INFO][10:58:32]: [Client #376] Epoch: [5/5][0/16]	Loss: 0.717881
[INFO][10:58:32]: [Client #376] Epoch: [5/5][10/16]	Loss: 2.477413
[INFO][10:58:32]: [Client #376] Going to sleep for 0.58 seconds.
[INFO][10:58:33]: [Client #376] Woke up.
[INFO][10:58:33]: [Client #376] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_376_554853.pth.
[INFO][10:58:34]: [Client #376] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_376_554853.pth.
[INFO][10:58:34]: [Client #376] Model trained.
[INFO][10:58:34]: [Client #376] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:58:34]: [Server #554754] Received 0.26 MB of payload data from client #376 (simulated).
[INFO][10:58:45]: [Client #475] Woke up.
[INFO][10:58:45]: [Client #475] Epoch: [2/5][0/16]	Loss: 0.937344
[INFO][10:58:45]: [Client #475] Epoch: [2/5][10/16]	Loss: 0.371419
[INFO][10:58:45]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][10:59:01]: [Client #475] Woke up.
[INFO][10:59:01]: [Client #475] Epoch: [3/5][0/16]	Loss: 1.382603
[INFO][10:59:01]: [Client #475] Epoch: [3/5][10/16]	Loss: 2.134715
[INFO][10:59:01]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][10:59:16]: [Client #475] Woke up.
[INFO][10:59:16]: [Client #475] Epoch: [4/5][0/16]	Loss: 1.862752
[INFO][10:59:16]: [Client #475] Epoch: [4/5][10/16]	Loss: 1.246746
[INFO][10:59:16]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][10:59:32]: [Client #475] Woke up.
[INFO][10:59:32]: [Client #475] Epoch: [5/5][0/16]	Loss: 0.175456
[INFO][10:59:32]: [Client #475] Epoch: [5/5][10/16]	Loss: 0.452608
[INFO][10:59:32]: [Client #475] Going to sleep for 15.36 seconds.
[INFO][10:59:47]: [Client #475] Woke up.
[INFO][10:59:47]: [Client #475] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554860.pth.
[INFO][10:59:48]: [Client #475] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_475_554860.pth.
[INFO][10:59:48]: [Client #475] Model trained.
[INFO][10:59:48]: [Client #475] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:59:48]: [Server #554754] Received 0.26 MB of payload data from client #475 (simulated).
[INFO][10:59:48]: [Server #554754] Selecting client #268 for training.
[INFO][10:59:48]: [Server #554754] Sending the current model to client #268 (simulated).
[INFO][10:59:48]: [Server #554754] Sending 0.26 MB of payload data to client #268 (simulated).
[INFO][10:59:48]: [Server #554754] Selecting client #96 for training.
[INFO][10:59:48]: [Server #554754] Sending the current model to client #96 (simulated).
[INFO][10:59:48]: [Server #554754] Sending 0.26 MB of payload data to client #96 (simulated).
[INFO][10:59:48]: [Client #268] Selected by the server.
[INFO][10:59:48]: [Client #268] Loading its data source...
[INFO][10:59:48]: [Client #96] Selected by the server.
[INFO][10:59:48]: Data source: FEMNIST
[INFO][10:59:48]: [Client #96] Loading its data source...
[INFO][10:59:48]: Data source: FEMNIST
[INFO][10:59:48]: [Client #96] Dataset size: 137
[INFO][10:59:48]: [Client #96] Sampler: all_inclusive
[INFO][10:59:48]: [Client #268] Dataset size: 161
[INFO][10:59:48]: [Client #268] Sampler: all_inclusive
[INFO][10:59:48]: [Client #96] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:59:48]: [93m[1m[Client #96] Started training in communication round #29.[0m
[INFO][10:59:48]: [Client #268] Received 0.26 MB of payload data from the server (simulated).
[INFO][10:59:48]: [93m[1m[Client #268] Started training in communication round #29.[0m
[INFO][10:59:50]: [Client #96] Loading the dataset.
[INFO][10:59:50]: [Client #268] Loading the dataset.
[INFO][10:59:55]: [Client #268] Epoch: [1/5][0/17]	Loss: 0.713541
[INFO][10:59:55]: [Client #96] Epoch: [1/5][0/14]	Loss: 2.143823
[INFO][10:59:55]: [Client #268] Epoch: [1/5][10/17]	Loss: 0.613478
[INFO][10:59:55]: [Client #96] Epoch: [1/5][10/14]	Loss: 1.303846
[INFO][10:59:55]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][10:59:55]: [Client #96] Going to sleep for 0.31 seconds.
[INFO][10:59:56]: [Client #96] Woke up.
[INFO][10:59:56]: [Client #96] Epoch: [2/5][0/14]	Loss: 0.661197
[INFO][10:59:56]: [Client #96] Epoch: [2/5][10/14]	Loss: 0.573269
[INFO][10:59:56]: [Client #96] Going to sleep for 0.31 seconds.
[INFO][10:59:56]: [Client #96] Woke up.
[INFO][10:59:56]: [Client #96] Epoch: [3/5][0/14]	Loss: 0.443826
[INFO][10:59:56]: [Client #268] Woke up.
[INFO][10:59:56]: [Client #268] Epoch: [2/5][0/17]	Loss: 0.208201
[INFO][10:59:56]: [Client #96] Epoch: [3/5][10/14]	Loss: 0.355589
[INFO][10:59:56]: [Client #96] Going to sleep for 0.31 seconds.
[INFO][10:59:56]: [Client #268] Epoch: [2/5][10/17]	Loss: 0.772694
[INFO][10:59:56]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][10:59:57]: [Client #96] Woke up.
[INFO][10:59:57]: [Client #96] Epoch: [4/5][0/14]	Loss: 1.359359
[INFO][10:59:57]: [Client #96] Epoch: [4/5][10/14]	Loss: 0.481829
[INFO][10:59:57]: [Client #96] Going to sleep for 0.31 seconds.
[INFO][10:59:57]: [Client #96] Woke up.
[INFO][10:59:57]: [Client #96] Epoch: [5/5][0/14]	Loss: 1.084145
[INFO][10:59:57]: [Client #96] Epoch: [5/5][10/14]	Loss: 0.355377
[INFO][10:59:57]: [Client #268] Woke up.
[INFO][10:59:57]: [Client #96] Going to sleep for 0.31 seconds.
[INFO][10:59:57]: [Client #268] Epoch: [3/5][0/17]	Loss: 0.954737
[INFO][10:59:57]: [Client #268] Epoch: [3/5][10/17]	Loss: 0.269440
[INFO][10:59:57]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][10:59:57]: [Client #96] Woke up.
[INFO][10:59:57]: [Client #96] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_96_554860.pth.
[INFO][10:59:58]: [Client #96] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_96_554860.pth.
[INFO][10:59:58]: [Client #268] Woke up.
[INFO][10:59:58]: [Client #96] Model trained.
[INFO][10:59:58]: [Client #96] Sent 0.26 MB of payload data to the server (simulated).
[INFO][10:59:58]: [Server #554754] Received 0.26 MB of payload data from client #96 (simulated).
[INFO][10:59:58]: [Client #268] Epoch: [4/5][0/17]	Loss: 0.413051
[INFO][10:59:58]: [Client #268] Epoch: [4/5][10/17]	Loss: 0.130288
[INFO][10:59:58]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][10:59:59]: [Client #268] Woke up.
[INFO][10:59:59]: [Client #268] Epoch: [5/5][0/17]	Loss: 0.439238
[INFO][10:59:59]: [Client #268] Epoch: [5/5][10/17]	Loss: 0.857951
[INFO][10:59:59]: [Client #268] Going to sleep for 0.82 seconds.
[INFO][11:00:00]: [Client #268] Woke up.
[INFO][11:00:00]: [Client #268] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_268_554853.pth.
[INFO][11:00:01]: [Client #268] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_268_554853.pth.
[INFO][11:00:01]: [Client #268] Model trained.
[INFO][11:00:01]: [Client #268] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:00:01]: [Server #554754] Received 0.26 MB of payload data from client #268 (simulated).
[INFO][11:00:01]: [Server #554754] Selecting client #377 for training.
[INFO][11:00:01]: [Server #554754] Sending the current model to client #377 (simulated).
[INFO][11:00:01]: [Server #554754] Sending 0.26 MB of payload data to client #377 (simulated).
[INFO][11:00:01]: [Server #554754] Selecting client #4 for training.
[INFO][11:00:01]: [Server #554754] Sending the current model to client #4 (simulated).
[INFO][11:00:01]: [Server #554754] Sending 0.26 MB of payload data to client #4 (simulated).
[INFO][11:00:01]: [Client #377] Selected by the server.
[INFO][11:00:01]: [Client #377] Loading its data source...
[INFO][11:00:01]: Data source: FEMNIST
[INFO][11:00:01]: [Client #4] Selected by the server.
[INFO][11:00:01]: [Client #4] Loading its data source...
[INFO][11:00:01]: Data source: FEMNIST
[INFO][11:00:01]: [Client #377] Dataset size: 142
[INFO][11:00:01]: [Client #377] Sampler: all_inclusive
[INFO][11:00:01]: [Client #4] Dataset size: 159
[INFO][11:00:01]: [Client #4] Sampler: all_inclusive
[INFO][11:00:01]: [Client #377] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:00:01]: [93m[1m[Client #377] Started training in communication round #29.[0m
[INFO][11:00:01]: [Client #4] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:00:01]: [93m[1m[Client #4] Started training in communication round #29.[0m
[INFO][11:00:03]: [Client #377] Loading the dataset.
[INFO][11:00:03]: [Client #4] Loading the dataset.
[INFO][11:00:08]: [Client #377] Epoch: [1/5][0/15]	Loss: 0.512599
[INFO][11:00:08]: [Client #377] Epoch: [1/5][10/15]	Loss: 0.454449
[INFO][11:00:08]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:00:08]: [Client #4] Epoch: [1/5][0/16]	Loss: 1.021841
[INFO][11:00:08]: [Client #4] Epoch: [1/5][10/16]	Loss: 1.240401
[INFO][11:00:08]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][11:00:09]: [Client #4] Woke up.
[INFO][11:00:09]: [Client #4] Epoch: [2/5][0/16]	Loss: 1.166024
[INFO][11:00:09]: [Client #4] Epoch: [2/5][10/16]	Loss: 0.822861
[INFO][11:00:09]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][11:00:09]: [Client #4] Woke up.
[INFO][11:00:09]: [Client #4] Epoch: [3/5][0/16]	Loss: 0.884850
[INFO][11:00:09]: [Client #4] Epoch: [3/5][10/16]	Loss: 0.408295
[INFO][11:00:10]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][11:00:10]: [Client #4] Woke up.
[INFO][11:00:10]: [Client #4] Epoch: [4/5][0/16]	Loss: 0.875079
[INFO][11:00:10]: [Client #4] Epoch: [4/5][10/16]	Loss: 2.332470
[INFO][11:00:10]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][11:00:11]: [Client #4] Woke up.
[INFO][11:00:11]: [Client #4] Epoch: [5/5][0/16]	Loss: 0.696796
[INFO][11:00:11]: [Client #4] Epoch: [5/5][10/16]	Loss: 0.694308
[INFO][11:00:11]: [Client #4] Going to sleep for 0.43 seconds.
[INFO][11:00:11]: [Client #4] Woke up.
[INFO][11:00:11]: [Client #4] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_4_554860.pth.
[INFO][11:00:12]: [Client #4] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_4_554860.pth.
[INFO][11:00:12]: [Client #4] Model trained.
[INFO][11:00:12]: [Client #4] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:00:12]: [Server #554754] Received 0.26 MB of payload data from client #4 (simulated).
[INFO][11:00:14]: [Client #377] Woke up.
[INFO][11:00:14]: [Client #377] Epoch: [2/5][0/15]	Loss: 0.161926
[INFO][11:00:15]: [Client #377] Epoch: [2/5][10/15]	Loss: 0.307655
[INFO][11:00:15]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:00:21]: [Client #377] Woke up.
[INFO][11:00:21]: [Client #377] Epoch: [3/5][0/15]	Loss: 0.112756
[INFO][11:00:21]: [Client #377] Epoch: [3/5][10/15]	Loss: 0.096964
[INFO][11:00:21]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:00:27]: [Client #377] Woke up.
[INFO][11:00:27]: [Client #377] Epoch: [4/5][0/15]	Loss: 0.779010
[INFO][11:00:27]: [Client #377] Epoch: [4/5][10/15]	Loss: 0.793221
[INFO][11:00:27]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:00:34]: [Client #377] Woke up.
[INFO][11:00:34]: [Client #377] Epoch: [5/5][0/15]	Loss: 0.045163
[INFO][11:00:34]: [Client #377] Epoch: [5/5][10/15]	Loss: 0.805743
[INFO][11:00:34]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:00:40]: [Client #377] Woke up.
[INFO][11:00:40]: [Client #377] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][11:00:41]: [Client #377] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][11:00:41]: [Client #377] Model trained.
[INFO][11:00:41]: [Client #377] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:00:41]: [Server #554754] Received 0.26 MB of payload data from client #377 (simulated).
[INFO][11:00:41]: [Server #554754] Selecting client #164 for training.
[INFO][11:00:41]: [Server #554754] Sending the current model to client #164 (simulated).
[INFO][11:00:41]: [Server #554754] Sending 0.26 MB of payload data to client #164 (simulated).
[INFO][11:00:41]: [Server #554754] Selecting client #459 for training.
[INFO][11:00:41]: [Server #554754] Sending the current model to client #459 (simulated).
[INFO][11:00:41]: [Server #554754] Sending 0.26 MB of payload data to client #459 (simulated).
[INFO][11:00:41]: [Client #164] Selected by the server.
[INFO][11:00:41]: [Client #164] Loading its data source...
[INFO][11:00:41]: Data source: FEMNIST
[INFO][11:00:41]: [Client #459] Selected by the server.
[INFO][11:00:41]: [Client #459] Loading its data source...
[INFO][11:00:41]: Data source: FEMNIST
[INFO][11:00:41]: [Client #164] Dataset size: 158
[INFO][11:00:41]: [Client #164] Sampler: all_inclusive
[INFO][11:00:41]: [Client #459] Dataset size: 165
[INFO][11:00:41]: [Client #459] Sampler: all_inclusive
[INFO][11:00:41]: [Client #164] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:00:41]: [Client #459] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:00:41]: [93m[1m[Client #459] Started training in communication round #29.[0m
[INFO][11:00:41]: [93m[1m[Client #164] Started training in communication round #29.[0m
[INFO][11:00:43]: [Client #164] Loading the dataset.
[INFO][11:00:43]: [Client #459] Loading the dataset.
[INFO][11:00:48]: [Client #459] Epoch: [1/5][0/17]	Loss: 0.364912
[INFO][11:00:48]: [Client #164] Epoch: [1/5][0/16]	Loss: 1.013323
[INFO][11:00:48]: [Client #459] Epoch: [1/5][10/17]	Loss: 0.692990
[INFO][11:00:48]: [Client #164] Epoch: [1/5][10/16]	Loss: 0.621053
[INFO][11:00:48]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][11:00:48]: [Client #164] Going to sleep for 4.85 seconds.
[INFO][11:00:49]: [Client #459] Woke up.
[INFO][11:00:49]: [Client #459] Epoch: [2/5][0/17]	Loss: 0.698155
[INFO][11:00:49]: [Client #459] Epoch: [2/5][10/17]	Loss: 0.652702
[INFO][11:00:49]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][11:00:49]: [Client #459] Woke up.
[INFO][11:00:49]: [Client #459] Epoch: [3/5][0/17]	Loss: 0.060986
[INFO][11:00:49]: [Client #459] Epoch: [3/5][10/17]	Loss: 0.391515
[INFO][11:00:49]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][11:00:49]: [Client #459] Woke up.
[INFO][11:00:50]: [Client #459] Epoch: [4/5][0/17]	Loss: 0.605521
[INFO][11:00:50]: [Client #459] Epoch: [4/5][10/17]	Loss: 0.600393
[INFO][11:00:50]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][11:00:50]: [Client #459] Woke up.
[INFO][11:00:50]: [Client #459] Epoch: [5/5][0/17]	Loss: 0.198719
[INFO][11:00:50]: [Client #459] Epoch: [5/5][10/17]	Loss: 0.303002
[INFO][11:00:50]: [Client #459] Going to sleep for 0.33 seconds.
[INFO][11:00:50]: [Client #459] Woke up.
[INFO][11:00:50]: [Client #459] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_554860.pth.
[INFO][11:00:51]: [Client #459] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_459_554860.pth.
[INFO][11:00:51]: [Client #459] Model trained.
[INFO][11:00:51]: [Client #459] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:00:51]: [Server #554754] Received 0.26 MB of payload data from client #459 (simulated).
[INFO][11:00:53]: [Client #164] Woke up.
[INFO][11:00:53]: [Client #164] Epoch: [2/5][0/16]	Loss: 0.013565
[INFO][11:00:53]: [Client #164] Epoch: [2/5][10/16]	Loss: 0.763454
[INFO][11:00:53]: [Client #164] Going to sleep for 4.85 seconds.
[INFO][11:00:58]: [Client #164] Woke up.
[INFO][11:00:58]: [Client #164] Epoch: [3/5][0/16]	Loss: 0.516752
[INFO][11:00:58]: [Client #164] Epoch: [3/5][10/16]	Loss: 0.267760
[INFO][11:00:58]: [Client #164] Going to sleep for 4.85 seconds.
[INFO][11:01:03]: [Client #164] Woke up.
[INFO][11:01:03]: [Client #164] Epoch: [4/5][0/16]	Loss: 0.255760
[INFO][11:01:03]: [Client #164] Epoch: [4/5][10/16]	Loss: 0.406464
[INFO][11:01:03]: [Client #164] Going to sleep for 4.85 seconds.
[INFO][11:01:08]: [Client #164] Woke up.
[INFO][11:01:08]: [Client #164] Epoch: [5/5][0/16]	Loss: 0.354327
[INFO][11:01:08]: [Client #164] Epoch: [5/5][10/16]	Loss: 0.384761
[INFO][11:01:08]: [Client #164] Going to sleep for 4.85 seconds.
[INFO][11:01:13]: [Client #164] Woke up.
[INFO][11:01:13]: [Client #164] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_164_554853.pth.
[INFO][11:01:14]: [Client #164] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_164_554853.pth.
[INFO][11:01:14]: [Client #164] Model trained.
[INFO][11:01:14]: [Client #164] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:01:14]: [Server #554754] Received 0.26 MB of payload data from client #164 (simulated).
[INFO][11:01:14]: [Server #554754] Adding client #96 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #459 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #4 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #376 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #268 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #164 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #377 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #30 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #475 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][11:01:14]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.09706906 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20951846
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15566289
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0713827  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.69839575 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1039717  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.30351227 0.09416587 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05447445 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15360601 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
local_gradient_bounds:  [0.         0.         0.         0.09706906 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.20951846
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15566289
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0713827  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.69839575 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1039717  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.30351227 0.09416587 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05447445 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15360601 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:01:58]: [Server #554754] Global model accuracy: 61.02%

[INFO][11:01:58]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_29.pth.
[INFO][11:01:58]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_29.pth.
[INFO][11:01:58]: [93m[1m
[Server #554754] Starting round 30/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.10114504 0.0912031  0.07783145 0.002      0.002      0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.002
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.002      0.1265896  0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.08251366 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.10306588 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.10484928 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.08674827 0.0460441  0.002      0.002
 0.002      0.002      0.05352394 0.002      0.10241357 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.09262883 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.002      0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.08510638
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.05193199 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  4e-04  7e-09  7e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  7e-10  2e-10
 7:  6.9057e+00  6.9056e+00  8e-05  7e-09  8e-10
 8:  6.9057e+00  6.9057e+00  6e-05  9e-09  1e-09
 9:  6.9057e+00  6.9057e+00  2e-05  4e-08  5e-09
10:  6.9057e+00  6.9057e+00  3e-06  1e-08  1e-09
Optimal solution found.
The calculated probability is:  [6.84799472e-05 6.84799472e-05 6.84799472e-05 6.83940331e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.81250784e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.83161007e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84340426e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.41932415e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 9.65902966e-01 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.77295652e-05 6.84154405e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84507855e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.82810595e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05 6.84799472e-05
 6.84799472e-05 6.84799472e-05 6.84799472e-05]
current clients pool:  [INFO][11:01:59]: [Server #554754] Selected clients: [299 295  18 100 395   7 152  11 499 291]
[INFO][11:01:59]: [Server #554754] Selecting client #299 for training.
[INFO][11:01:59]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][11:01:59]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][11:01:59]: [Server #554754] Selecting client #295 for training.
[INFO][11:01:59]: [Server #554754] Sending the current model to client #295 (simulated).
[INFO][11:01:59]: [Server #554754] Sending 0.26 MB of payload data to client #295 (simulated).
[INFO][11:01:59]: [Client #299] Selected by the server.
[INFO][11:01:59]: [Client #299] Loading its data source...
[INFO][11:01:59]: Data source: FEMNIST
[INFO][11:01:59]: [Client #295] Selected by the server.
[INFO][11:01:59]: [Client #295] Loading its data source...
[INFO][11:01:59]: Data source: FEMNIST
[INFO][11:01:59]: [Client #295] Dataset size: 142
[INFO][11:01:59]: [Client #295] Sampler: all_inclusive
[INFO][11:01:59]: [Client #295] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:01:59]: [Client #299] Dataset size: 157
[INFO][11:01:59]: [Client #299] Sampler: all_inclusive
[INFO][11:01:59]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:01:59]: [93m[1m[Client #299] Started training in communication round #30.[0m
[INFO][11:01:59]: [93m[1m[Client #295] Started training in communication round #30.[0m
[INFO][11:02:01]: [Client #299] Loading the dataset.
[INFO][11:02:01]: [Client #295] Loading the dataset.
[INFO][11:02:06]: [Client #299] Epoch: [1/5][0/16]	Loss: 0.603361
[INFO][11:02:06]: [Client #295] Epoch: [1/5][0/15]	Loss: 0.615452
[INFO][11:02:06]: [Client #299] Epoch: [1/5][10/16]	Loss: 0.304040
[INFO][11:02:06]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:02:06]: [Client #295] Epoch: [1/5][10/15]	Loss: 0.068989
[INFO][11:02:06]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:02:07]: [Client #295] Woke up.
[INFO][11:02:07]: [Client #295] Epoch: [2/5][0/15]	Loss: 0.075106
[INFO][11:02:07]: [Client #295] Epoch: [2/5][10/15]	Loss: 0.323207
[INFO][11:02:07]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:02:07]: [Client #295] Woke up.
[INFO][11:02:07]: [Client #295] Epoch: [3/5][0/15]	Loss: 1.355355
[INFO][11:02:07]: [Client #295] Epoch: [3/5][10/15]	Loss: 0.600331
[INFO][11:02:07]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:02:08]: [Client #295] Woke up.
[INFO][11:02:08]: [Client #295] Epoch: [4/5][0/15]	Loss: 0.646436
[INFO][11:02:08]: [Client #295] Epoch: [4/5][10/15]	Loss: 1.853470
[INFO][11:02:08]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:02:09]: [Client #295] Woke up.
[INFO][11:02:09]: [Client #295] Epoch: [5/5][0/15]	Loss: 0.485577
[INFO][11:02:09]: [Client #295] Epoch: [5/5][10/15]	Loss: 0.446127
[INFO][11:02:09]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:02:09]: [Client #295] Woke up.
[INFO][11:02:09]: [Client #295] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:02:10]: [Client #295] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:02:10]: [Client #295] Model trained.
[INFO][11:02:10]: [Client #295] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:02:10]: [Server #554754] Received 0.26 MB of payload data from client #295 (simulated).
[INFO][11:03:03]: [Client #299] Woke up.
[INFO][11:03:03]: [Client #299] Epoch: [2/5][0/16]	Loss: 0.675777
[INFO][11:03:03]: [Client #299] Epoch: [2/5][10/16]	Loss: 0.502154
[INFO][11:03:04]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:04:01]: [Client #299] Woke up.
[INFO][11:04:01]: [Client #299] Epoch: [3/5][0/16]	Loss: 0.511736
[INFO][11:04:01]: [Client #299] Epoch: [3/5][10/16]	Loss: 0.671580
[INFO][11:04:01]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:04:58]: [Client #299] Woke up.
[INFO][11:04:58]: [Client #299] Epoch: [4/5][0/16]	Loss: 0.554304
[INFO][11:04:58]: [Client #299] Epoch: [4/5][10/16]	Loss: 1.120341
[INFO][11:04:58]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:05:56]: [Client #299] Woke up.
[INFO][11:05:56]: [Client #299] Epoch: [5/5][0/16]	Loss: 0.015793
[INFO][11:05:56]: [Client #299] Epoch: [5/5][10/16]	Loss: 1.635992
[INFO][11:05:56]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:06:53]: [Client #299] Woke up.
[INFO][11:06:53]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:06:54]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:06:54]: [Client #299] Model trained.
[INFO][11:06:54]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:06:54]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][11:06:54]: [Server #554754] Selecting client #18 for training.
[INFO][11:06:54]: [Server #554754] Sending the current model to client #18 (simulated).
[INFO][11:06:54]: [Server #554754] Sending 0.26 MB of payload data to client #18 (simulated).
[INFO][11:06:54]: [Server #554754] Selecting client #100 for training.
[INFO][11:06:54]: [Server #554754] Sending the current model to client #100 (simulated).
[INFO][11:06:54]: [Server #554754] Sending 0.26 MB of payload data to client #100 (simulated).
[INFO][11:06:54]: [Client #18] Selected by the server.
[INFO][11:06:54]: [Client #18] Loading its data source...
[INFO][11:06:54]: Data source: FEMNIST
[INFO][11:06:54]: [Client #100] Selected by the server.
[INFO][11:06:54]: [Client #100] Loading its data source...
[INFO][11:06:54]: Data source: FEMNIST
[INFO][11:06:54]: [Client #18] Dataset size: 140
[INFO][11:06:54]: [Client #18] Sampler: all_inclusive
[INFO][11:06:54]: [Client #18] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:06:54]: [Client #100] Dataset size: 219
[INFO][11:06:54]: [Client #100] Sampler: all_inclusive
[INFO][11:06:54]: [Client #100] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:06:54]: [93m[1m[Client #18] Started training in communication round #30.[0m
[INFO][11:06:54]: [93m[1m[Client #100] Started training in communication round #30.[0m
[INFO][11:06:56]: [Client #100] Loading the dataset.
[INFO][11:06:56]: [Client #18] Loading the dataset.
[INFO][11:07:01]: [Client #100] Epoch: [1/5][0/22]	Loss: 0.936038
[INFO][11:07:01]: [Client #18] Epoch: [1/5][0/14]	Loss: 0.903461
[INFO][11:07:01]: [Client #100] Epoch: [1/5][10/22]	Loss: 1.271509
[INFO][11:07:02]: [Client #18] Epoch: [1/5][10/14]	Loss: 0.581040
[INFO][11:07:02]: [Client #18] Going to sleep for 1.27 seconds.
[INFO][11:07:02]: [Client #100] Epoch: [1/5][20/22]	Loss: 0.681585
[INFO][11:07:02]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][11:07:03]: [Client #18] Woke up.
[INFO][11:07:03]: [Client #18] Epoch: [2/5][0/14]	Loss: 0.447873
[INFO][11:07:03]: [Client #18] Epoch: [2/5][10/14]	Loss: 1.728399
[INFO][11:07:03]: [Client #18] Going to sleep for 1.27 seconds.
[INFO][11:07:03]: [Client #100] Woke up.
[INFO][11:07:03]: [Client #100] Epoch: [2/5][0/22]	Loss: 0.233033
[INFO][11:07:03]: [Client #100] Epoch: [2/5][10/22]	Loss: 0.731508
[INFO][11:07:03]: [Client #100] Epoch: [2/5][20/22]	Loss: 0.789822
[INFO][11:07:03]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][11:07:04]: [Client #18] Woke up.
[INFO][11:07:04]: [Client #18] Epoch: [3/5][0/14]	Loss: 0.473874
[INFO][11:07:04]: [Client #18] Epoch: [3/5][10/14]	Loss: 0.452453
[INFO][11:07:04]: [Client #18] Going to sleep for 1.27 seconds.
[INFO][11:07:05]: [Client #100] Woke up.
[INFO][11:07:05]: [Client #100] Epoch: [3/5][0/22]	Loss: 0.732650
[INFO][11:07:05]: [Client #100] Epoch: [3/5][10/22]	Loss: 0.735218
[INFO][11:07:05]: [Client #100] Epoch: [3/5][20/22]	Loss: 1.019376
[INFO][11:07:05]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][11:07:06]: [Client #18] Woke up.
[INFO][11:07:06]: [Client #18] Epoch: [4/5][0/14]	Loss: 0.226406
[INFO][11:07:06]: [Client #18] Epoch: [4/5][10/14]	Loss: 0.312400
[INFO][11:07:06]: [Client #18] Going to sleep for 1.27 seconds.
[INFO][11:07:07]: [Client #100] Woke up.
[INFO][11:07:07]: [Client #100] Epoch: [4/5][0/22]	Loss: 1.131214
[INFO][11:07:07]: [Client #100] Epoch: [4/5][10/22]	Loss: 0.369471
[INFO][11:07:07]: [Client #100] Epoch: [4/5][20/22]	Loss: 1.314691
[INFO][11:07:07]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][11:07:07]: [Client #18] Woke up.
[INFO][11:07:07]: [Client #18] Epoch: [5/5][0/14]	Loss: 0.834874
[INFO][11:07:07]: [Client #18] Epoch: [5/5][10/14]	Loss: 0.492760
[INFO][11:07:07]: [Client #18] Going to sleep for 1.27 seconds.
[INFO][11:07:08]: [Client #18] Woke up.
[INFO][11:07:08]: [Client #18] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_18_554853.pth.
[INFO][11:07:09]: [Client #100] Woke up.
[INFO][11:07:09]: [Client #100] Epoch: [5/5][0/22]	Loss: 0.294046
[INFO][11:07:09]: [Client #100] Epoch: [5/5][10/22]	Loss: 1.890604
[INFO][11:07:09]: [Client #100] Epoch: [5/5][20/22]	Loss: 0.775245
[INFO][11:07:09]: [Client #100] Going to sleep for 1.61 seconds.
[INFO][11:07:09]: [Client #18] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_18_554853.pth.
[INFO][11:07:09]: [Client #18] Model trained.
[INFO][11:07:09]: [Client #18] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:07:09]: [Server #554754] Received 0.26 MB of payload data from client #18 (simulated).
[INFO][11:07:10]: [Client #100] Woke up.
[INFO][11:07:10]: [Client #100] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_100_554860.pth.
[INFO][11:07:11]: [Client #100] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_100_554860.pth.
[INFO][11:07:11]: [Client #100] Model trained.
[INFO][11:07:11]: [Client #100] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:07:11]: [Server #554754] Received 0.26 MB of payload data from client #100 (simulated).
[INFO][11:07:11]: [Server #554754] Selecting client #395 for training.
[INFO][11:07:11]: [Server #554754] Sending the current model to client #395 (simulated).
[INFO][11:07:11]: [Server #554754] Sending 0.26 MB of payload data to client #395 (simulated).
[INFO][11:07:11]: [Server #554754] Selecting client #7 for training.
[INFO][11:07:11]: [Server #554754] Sending the current model to client #7 (simulated).
[INFO][11:07:11]: [Server #554754] Sending 0.26 MB of payload data to client #7 (simulated).
[INFO][11:07:11]: [Client #395] Selected by the server.
[INFO][11:07:11]: [Client #7] Selected by the server.
[INFO][11:07:11]: [Client #395] Loading its data source...
[INFO][11:07:11]: [Client #7] Loading its data source...
[INFO][11:07:11]: Data source: FEMNIST
[INFO][11:07:11]: Data source: FEMNIST
[INFO][11:07:11]: [Client #395] Dataset size: 153
[INFO][11:07:11]: [Client #395] Sampler: all_inclusive
[INFO][11:07:11]: [Client #7] Dataset size: 159
[INFO][11:07:11]: [Client #7] Sampler: all_inclusive
[INFO][11:07:11]: [Client #395] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:07:11]: [Client #7] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:07:11]: [93m[1m[Client #395] Started training in communication round #30.[0m
[INFO][11:07:11]: [93m[1m[Client #7] Started training in communication round #30.[0m
[INFO][11:07:13]: [Client #7] Loading the dataset.
[INFO][11:07:13]: [Client #395] Loading the dataset.
[INFO][11:07:18]: [Client #7] Epoch: [1/5][0/16]	Loss: 1.591085
[INFO][11:07:19]: [Client #395] Epoch: [1/5][0/16]	Loss: 0.424211
[INFO][11:07:19]: [Client #7] Epoch: [1/5][10/16]	Loss: 0.239236
[INFO][11:07:19]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][11:07:19]: [Client #395] Epoch: [1/5][10/16]	Loss: 0.581436
[INFO][11:07:19]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][11:07:19]: [Client #7] Woke up.
[INFO][11:07:19]: [Client #7] Epoch: [2/5][0/16]	Loss: 0.311767
[INFO][11:07:19]: [Client #7] Epoch: [2/5][10/16]	Loss: 0.211284
[INFO][11:07:19]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][11:07:19]: [Client #7] Woke up.
[INFO][11:07:19]: [Client #7] Epoch: [3/5][0/16]	Loss: 1.014099
[INFO][11:07:19]: [Client #7] Epoch: [3/5][10/16]	Loss: 0.005572
[INFO][11:07:19]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][11:07:20]: [Client #7] Woke up.
[INFO][11:07:20]: [Client #7] Epoch: [4/5][0/16]	Loss: 0.050771
[INFO][11:07:20]: [Client #7] Epoch: [4/5][10/16]	Loss: 0.561478
[INFO][11:07:20]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][11:07:20]: [Client #7] Woke up.
[INFO][11:07:20]: [Client #7] Epoch: [5/5][0/16]	Loss: 0.062589
[INFO][11:07:20]: [Client #7] Epoch: [5/5][10/16]	Loss: 0.214371
[INFO][11:07:20]: [Client #395] Woke up.
[INFO][11:07:20]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][11:07:20]: [Client #395] Epoch: [2/5][0/16]	Loss: 0.924457
[INFO][11:07:20]: [Client #395] Epoch: [2/5][10/16]	Loss: 0.354226
[INFO][11:07:20]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][11:07:20]: [Client #7] Woke up.
[INFO][11:07:20]: [Client #7] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554860.pth.
[INFO][11:07:21]: [Client #7] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554860.pth.
[INFO][11:07:21]: [Client #7] Model trained.
[INFO][11:07:21]: [Client #7] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:07:21]: [Server #554754] Received 0.26 MB of payload data from client #7 (simulated).
[INFO][11:07:22]: [Client #395] Woke up.
[INFO][11:07:22]: [Client #395] Epoch: [3/5][0/16]	Loss: 0.504332
[INFO][11:07:22]: [Client #395] Epoch: [3/5][10/16]	Loss: 0.652740
[INFO][11:07:22]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][11:07:23]: [Client #395] Woke up.
[INFO][11:07:23]: [Client #395] Epoch: [4/5][0/16]	Loss: 0.713901
[INFO][11:07:23]: [Client #395] Epoch: [4/5][10/16]	Loss: 0.746471
[INFO][11:07:24]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][11:07:25]: [Client #395] Woke up.
[INFO][11:07:25]: [Client #395] Epoch: [5/5][0/16]	Loss: 0.842564
[INFO][11:07:25]: [Client #395] Epoch: [5/5][10/16]	Loss: 0.636863
[INFO][11:07:25]: [Client #395] Going to sleep for 1.46 seconds.
[INFO][11:07:27]: [Client #395] Woke up.
[INFO][11:07:27]: [Client #395] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_395_554853.pth.
[INFO][11:07:27]: [Client #395] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_395_554853.pth.
[INFO][11:07:27]: [Client #395] Model trained.
[INFO][11:07:27]: [Client #395] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:07:27]: [Server #554754] Received 0.26 MB of payload data from client #395 (simulated).
[INFO][11:07:27]: [Server #554754] Selecting client #152 for training.
[INFO][11:07:27]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][11:07:27]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][11:07:27]: [Server #554754] Selecting client #11 for training.
[INFO][11:07:27]: [Server #554754] Sending the current model to client #11 (simulated).
[INFO][11:07:27]: [Server #554754] Sending 0.26 MB of payload data to client #11 (simulated).
[INFO][11:07:27]: [Client #152] Selected by the server.
[INFO][11:07:27]: [Client #152] Loading its data source...
[INFO][11:07:27]: Data source: FEMNIST
[INFO][11:07:27]: [Client #11] Selected by the server.
[INFO][11:07:27]: [Client #11] Loading its data source...
[INFO][11:07:27]: Data source: FEMNIST
[INFO][11:07:27]: [Client #152] Dataset size: 151
[INFO][11:07:27]: [Client #152] Sampler: all_inclusive
[INFO][11:07:27]: [Client #11] Dataset size: 153
[INFO][11:07:27]: [Client #11] Sampler: all_inclusive
[INFO][11:07:27]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:07:27]: [93m[1m[Client #152] Started training in communication round #30.[0m
[INFO][11:07:27]: [Client #11] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:07:27]: [93m[1m[Client #11] Started training in communication round #30.[0m
[INFO][11:07:29]: [Client #11] Loading the dataset.
[INFO][11:07:29]: [Client #152] Loading the dataset.
[INFO][11:07:35]: [Client #11] Epoch: [1/5][0/16]	Loss: 0.579506
[INFO][11:07:35]: [Client #152] Epoch: [1/5][0/16]	Loss: 1.008260
[INFO][11:07:35]: [Client #11] Epoch: [1/5][10/16]	Loss: 0.481505
[INFO][11:07:35]: [Client #152] Epoch: [1/5][10/16]	Loss: 1.545853
[INFO][11:07:35]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:07:35]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:07:36]: [Client #11] Woke up.
[INFO][11:07:36]: [Client #11] Epoch: [2/5][0/16]	Loss: 0.657817
[INFO][11:07:36]: [Client #11] Epoch: [2/5][10/16]	Loss: 0.965424
[INFO][11:07:36]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:07:36]: [Client #11] Woke up.
[INFO][11:07:36]: [Client #11] Epoch: [3/5][0/16]	Loss: 0.741978
[INFO][11:07:36]: [Client #11] Epoch: [3/5][10/16]	Loss: 0.565490
[INFO][11:07:37]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:07:37]: [Client #11] Woke up.
[INFO][11:07:37]: [Client #11] Epoch: [4/5][0/16]	Loss: 0.856636
[INFO][11:07:37]: [Client #11] Epoch: [4/5][10/16]	Loss: 0.742741
[INFO][11:07:37]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:07:38]: [Client #11] Woke up.
[INFO][11:07:38]: [Client #11] Epoch: [5/5][0/16]	Loss: 0.188903
[INFO][11:07:38]: [Client #11] Epoch: [5/5][10/16]	Loss: 0.271615
[INFO][11:07:38]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:07:39]: [Client #11] Woke up.
[INFO][11:07:39]: [Client #11] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_554860.pth.
[INFO][11:07:40]: [Client #11] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_554860.pth.
[INFO][11:07:40]: [Client #11] Model trained.
[INFO][11:07:40]: [Client #11] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:07:40]: [Server #554754] Received 0.26 MB of payload data from client #11 (simulated).
[INFO][11:08:04]: [Client #152] Woke up.
[INFO][11:08:05]: [Client #152] Epoch: [2/5][0/16]	Loss: 1.290265
[INFO][11:08:05]: [Client #152] Epoch: [2/5][10/16]	Loss: 0.360646
[INFO][11:08:05]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:08:34]: [Client #152] Woke up.
[INFO][11:08:34]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.288273
[INFO][11:08:34]: [Client #152] Epoch: [3/5][10/16]	Loss: 1.053773
[INFO][11:08:34]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:09:04]: [Client #152] Woke up.
[INFO][11:09:04]: [Client #152] Epoch: [4/5][0/16]	Loss: 1.578396
[INFO][11:09:04]: [Client #152] Epoch: [4/5][10/16]	Loss: 1.319328
[INFO][11:09:04]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:09:34]: [Client #152] Woke up.
[INFO][11:09:34]: [Client #152] Epoch: [5/5][0/16]	Loss: 0.222719
[INFO][11:09:34]: [Client #152] Epoch: [5/5][10/16]	Loss: 1.261570
[INFO][11:09:34]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:10:04]: [Client #152] Woke up.
[INFO][11:10:04]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][11:10:04]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554853.pth.
[INFO][11:10:04]: [Client #152] Model trained.
[INFO][11:10:04]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:10:04]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][11:10:04]: [Server #554754] Selecting client #499 for training.
[INFO][11:10:04]: [Server #554754] Sending the current model to client #499 (simulated).
[INFO][11:10:04]: [Server #554754] Sending 0.26 MB of payload data to client #499 (simulated).
[INFO][11:10:04]: [Server #554754] Selecting client #291 for training.
[INFO][11:10:04]: [Server #554754] Sending the current model to client #291 (simulated).
[INFO][11:10:04]: [Server #554754] Sending 0.26 MB of payload data to client #291 (simulated).
[INFO][11:10:04]: [Client #499] Selected by the server.
[INFO][11:10:04]: [Client #499] Loading its data source...
[INFO][11:10:04]: Data source: FEMNIST
[INFO][11:10:04]: [Client #291] Selected by the server.
[INFO][11:10:04]: [Client #291] Loading its data source...
[INFO][11:10:04]: Data source: FEMNIST
[INFO][11:10:05]: [Client #499] Dataset size: 168
[INFO][11:10:05]: [Client #499] Sampler: all_inclusive
[INFO][11:10:05]: [Client #291] Dataset size: 163
[INFO][11:10:05]: [Client #291] Sampler: all_inclusive
[INFO][11:10:05]: [Client #499] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:10:05]: [93m[1m[Client #499] Started training in communication round #30.[0m
[INFO][11:10:05]: [Client #291] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:10:05]: [93m[1m[Client #291] Started training in communication round #30.[0m
[INFO][11:10:06]: [Client #291] Loading the dataset.
[INFO][11:10:06]: [Client #499] Loading the dataset.
[INFO][11:10:12]: [Client #291] Epoch: [1/5][0/17]	Loss: 0.042739
[INFO][11:10:12]: [Client #499] Epoch: [1/5][0/17]	Loss: 0.306397
[INFO][11:10:12]: [Client #291] Epoch: [1/5][10/17]	Loss: 0.197439
[INFO][11:10:12]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][11:10:12]: [Client #499] Epoch: [1/5][10/17]	Loss: 0.627775
[INFO][11:10:12]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][11:10:13]: [Client #291] Woke up.
[INFO][11:10:13]: [Client #291] Epoch: [2/5][0/17]	Loss: 0.407381
[INFO][11:10:13]: [Client #291] Epoch: [2/5][10/17]	Loss: 0.753450
[INFO][11:10:13]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][11:10:14]: [Client #291] Woke up.
[INFO][11:10:14]: [Client #291] Epoch: [3/5][0/17]	Loss: 0.112196
[INFO][11:10:14]: [Client #291] Epoch: [3/5][10/17]	Loss: 0.154829
[INFO][11:10:15]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][11:10:16]: [Client #291] Woke up.
[INFO][11:10:16]: [Client #291] Epoch: [4/5][0/17]	Loss: 0.102184
[INFO][11:10:16]: [Client #291] Epoch: [4/5][10/17]	Loss: 0.297201
[INFO][11:10:16]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][11:10:17]: [Client #291] Woke up.
[INFO][11:10:17]: [Client #291] Epoch: [5/5][0/17]	Loss: 0.067397
[INFO][11:10:17]: [Client #291] Epoch: [5/5][10/17]	Loss: 0.443183
[INFO][11:10:17]: [Client #291] Going to sleep for 1.08 seconds.
[INFO][11:10:18]: [Client #291] Woke up.
[INFO][11:10:18]: [Client #291] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554860.pth.
[INFO][11:10:19]: [Client #291] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_291_554860.pth.
[INFO][11:10:19]: [Client #291] Model trained.
[INFO][11:10:19]: [Client #291] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:10:19]: [Server #554754] Received 0.26 MB of payload data from client #291 (simulated).
[INFO][11:10:24]: [Client #499] Woke up.
[INFO][11:10:24]: [Client #499] Epoch: [2/5][0/17]	Loss: 0.692021
[INFO][11:10:24]: [Client #499] Epoch: [2/5][10/17]	Loss: 0.572836
[INFO][11:10:24]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][11:10:35]: [Client #499] Woke up.
[INFO][11:10:35]: [Client #499] Epoch: [3/5][0/17]	Loss: 0.504519
[INFO][11:10:36]: [Client #499] Epoch: [3/5][10/17]	Loss: 0.164108
[INFO][11:10:36]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][11:10:47]: [Client #499] Woke up.
[INFO][11:10:47]: [Client #499] Epoch: [4/5][0/17]	Loss: 0.577480
[INFO][11:10:47]: [Client #499] Epoch: [4/5][10/17]	Loss: 0.487490
[INFO][11:10:47]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][11:10:59]: [Client #499] Woke up.
[INFO][11:10:59]: [Client #499] Epoch: [5/5][0/17]	Loss: 0.593537
[INFO][11:10:59]: [Client #499] Epoch: [5/5][10/17]	Loss: 0.093941
[INFO][11:10:59]: [Client #499] Going to sleep for 11.53 seconds.
[INFO][11:11:11]: [Client #499] Woke up.
[INFO][11:11:11]: [Client #499] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_499_554853.pth.
[INFO][11:11:11]: [Client #499] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_499_554853.pth.
[INFO][11:11:11]: [Client #499] Model trained.
[INFO][11:11:11]: [Client #499] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:11:11]: [Server #554754] Received 0.26 MB of payload data from client #499 (simulated).
[INFO][11:11:11]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #7 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #295 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #11 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #291 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #18 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #395 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #100 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #499 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][11:11:11]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.08998598 0.         0.         0.         0.10725155 0.
 0.         0.         0.         0.         0.         0.13745219
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16296415 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.40401841 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11309937 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08823613 0.         0.         0.
 0.35144974 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1313237  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11600187 0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.08998598 0.         0.         0.         0.10725155 0.
 0.         0.         0.         0.         0.         0.13745219
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16296415 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.40401841 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11309937 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08823613 0.         0.         0.
 0.35144974 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1313237  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11600187 0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:11:55]: [Server #554754] Global model accuracy: 62.70%

[INFO][11:11:55]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_30.pth.
[INFO][11:11:55]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_30.pth.
[INFO][11:11:55]: [93m[1m
[Server #554754] Starting round 31/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.09514925 0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.08695652
 0.002      0.10318471 0.09412436 0.002      0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.002      0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.10306588 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.09950249 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.002      0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.002      0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08830846 0.002      0.05352394 0.002      0.10241357 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.08871851 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.09262883 0.002
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08817087 0.05155642 0.002      0.10127389 0.08510638
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.05319149
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  4e-04  7e-09  7e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  1e-09  1e-10
 7:  6.9057e+00  6.9056e+00  8e-05  9e-09  1e-09
 8:  6.9057e+00  6.9056e+00  4e-05  4e-08  5e-09
 9:  6.9057e+00  6.9056e+00  1e-05  3e-08  3e-09
10:  6.9056e+00  6.9056e+00  1e-06  5e-09  6e-10
Optimal solution found.
The calculated probability is:  [2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47217135e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47144091e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47029863e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.46013021e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.43298021e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 9.87678084e-01
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47214709e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.44656152e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.46992119e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47449029e-05 2.47449029e-05 2.47449029e-05
 2.47449029e-05 2.47019140e-05 2.47449029e-05]
current clients pool:  [INFO][11:11:56]: [Server #554754] Selected clients: [212 349  36 486 378 404 377  40 241 223]
[INFO][11:11:56]: [Server #554754] Selecting client #212 for training.
[INFO][11:11:56]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][11:11:56]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][11:11:56]: [Server #554754] Selecting client #349 for training.
[INFO][11:11:56]: [Server #554754] Sending the current model to client #349 (simulated).
[INFO][11:11:56]: [Server #554754] Sending 0.26 MB of payload data to client #349 (simulated).
[INFO][11:11:56]: [Client #212] Selected by the server.
[INFO][11:11:56]: [Client #212] Loading its data source...
[INFO][11:11:56]: Data source: FEMNIST
[INFO][11:11:56]: [Client #349] Selected by the server.
[INFO][11:11:56]: [Client #349] Loading its data source...
[INFO][11:11:56]: Data source: FEMNIST
[INFO][11:11:56]: [Client #349] Dataset size: 162
[INFO][11:11:56]: [Client #349] Sampler: all_inclusive
[INFO][11:11:56]: [Client #349] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:11:56]: [Client #212] Dataset size: 160
[INFO][11:11:56]: [Client #212] Sampler: all_inclusive
[INFO][11:11:56]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:11:56]: [93m[1m[Client #212] Started training in communication round #31.[0m
[INFO][11:11:56]: [93m[1m[Client #349] Started training in communication round #31.[0m
[INFO][11:11:58]: [Client #212] Loading the dataset.
[INFO][11:11:58]: [Client #349] Loading the dataset.
[INFO][11:12:03]: [Client #349] Epoch: [1/5][0/17]	Loss: 0.517864
[INFO][11:12:03]: [Client #212] Epoch: [1/5][0/16]	Loss: 1.426522
[INFO][11:12:03]: [Client #349] Epoch: [1/5][10/17]	Loss: 1.011783
[INFO][11:12:03]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.405512
[INFO][11:12:04]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][11:12:04]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:12:08]: [Client #349] Woke up.
[INFO][11:12:08]: [Client #349] Epoch: [2/5][0/17]	Loss: 0.730356
[INFO][11:12:08]: [Client #349] Epoch: [2/5][10/17]	Loss: 0.694543
[INFO][11:12:08]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][11:12:12]: [Client #349] Woke up.
[INFO][11:12:12]: [Client #349] Epoch: [3/5][0/17]	Loss: 0.868004
[INFO][11:12:12]: [Client #349] Epoch: [3/5][10/17]	Loss: 0.375875
[INFO][11:12:12]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][11:12:16]: [Client #349] Woke up.
[INFO][11:12:16]: [Client #349] Epoch: [4/5][0/17]	Loss: 0.288853
[INFO][11:12:16]: [Client #349] Epoch: [4/5][10/17]	Loss: 0.383363
[INFO][11:12:16]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][11:12:20]: [Client #349] Woke up.
[INFO][11:12:20]: [Client #349] Epoch: [5/5][0/17]	Loss: 0.376791
[INFO][11:12:20]: [Client #349] Epoch: [5/5][10/17]	Loss: 1.043210
[INFO][11:12:20]: [Client #349] Going to sleep for 3.99 seconds.
[INFO][11:12:24]: [Client #349] Woke up.
[INFO][11:12:24]: [Client #349] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][11:12:25]: [Client #349] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_349_554860.pth.
[INFO][11:12:25]: [Client #349] Model trained.
[INFO][11:12:25]: [Client #349] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:12:25]: [Server #554754] Received 0.26 MB of payload data from client #349 (simulated).
[INFO][11:12:30]: [Client #212] Woke up.
[INFO][11:12:30]: [Client #212] Epoch: [2/5][0/16]	Loss: 1.470453
[INFO][11:12:30]: [Client #212] Epoch: [2/5][10/16]	Loss: 1.891045
[INFO][11:12:30]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:12:56]: [Client #212] Woke up.
[INFO][11:12:56]: [Client #212] Epoch: [3/5][0/16]	Loss: 0.701798
[INFO][11:12:56]: [Client #212] Epoch: [3/5][10/16]	Loss: 0.818761
[INFO][11:12:56]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:13:23]: [Client #212] Woke up.
[INFO][11:13:23]: [Client #212] Epoch: [4/5][0/16]	Loss: 1.975853
[INFO][11:13:23]: [Client #212] Epoch: [4/5][10/16]	Loss: 1.780349
[INFO][11:13:23]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:13:49]: [Client #212] Woke up.
[INFO][11:13:49]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.193017
[INFO][11:13:49]: [Client #212] Epoch: [5/5][10/16]	Loss: 1.422760
[INFO][11:13:49]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:14:16]: [Client #212] Woke up.
[INFO][11:14:16]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][11:14:16]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][11:14:16]: [Client #212] Model trained.
[INFO][11:14:16]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:14:16]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][11:14:16]: [Server #554754] Selecting client #36 for training.
[INFO][11:14:16]: [Server #554754] Sending the current model to client #36 (simulated).
[INFO][11:14:16]: [Server #554754] Sending 0.26 MB of payload data to client #36 (simulated).
[INFO][11:14:16]: [Server #554754] Selecting client #486 for training.
[INFO][11:14:16]: [Server #554754] Sending the current model to client #486 (simulated).
[INFO][11:14:16]: [Server #554754] Sending 0.26 MB of payload data to client #486 (simulated).
[INFO][11:14:16]: [Client #36] Selected by the server.
[INFO][11:14:16]: [Client #36] Loading its data source...
[INFO][11:14:16]: Data source: FEMNIST
[INFO][11:14:16]: [Client #486] Selected by the server.
[INFO][11:14:16]: [Client #486] Loading its data source...
[INFO][11:14:16]: Data source: FEMNIST
[INFO][11:14:17]: [Client #36] Dataset size: 162
[INFO][11:14:17]: [Client #36] Sampler: all_inclusive
[INFO][11:14:17]: [Client #486] Dataset size: 160
[INFO][11:14:17]: [Client #486] Sampler: all_inclusive
[INFO][11:14:17]: [Client #36] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:17]: [93m[1m[Client #36] Started training in communication round #31.[0m
[INFO][11:14:17]: [Client #486] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:17]: [93m[1m[Client #486] Started training in communication round #31.[0m
[INFO][11:14:18]: [Client #36] Loading the dataset.
[INFO][11:14:18]: [Client #486] Loading the dataset.
[INFO][11:14:24]: [Client #36] Epoch: [1/5][0/17]	Loss: 0.086553
[INFO][11:14:24]: [Client #486] Epoch: [1/5][0/16]	Loss: 2.406373
[INFO][11:14:24]: [Client #36] Epoch: [1/5][10/17]	Loss: 0.544398
[INFO][11:14:24]: [Client #486] Epoch: [1/5][10/16]	Loss: 1.150208
[INFO][11:14:24]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][11:14:24]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][11:14:25]: [Client #36] Woke up.
[INFO][11:14:25]: [Client #36] Epoch: [2/5][0/17]	Loss: 0.798390
[INFO][11:14:25]: [Client #36] Epoch: [2/5][10/17]	Loss: 0.165943
[INFO][11:14:25]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][11:14:25]: [Client #36] Woke up.
[INFO][11:14:25]: [Client #36] Epoch: [3/5][0/17]	Loss: 0.727740
[INFO][11:14:25]: [Client #36] Epoch: [3/5][10/17]	Loss: 1.033077
[INFO][11:14:25]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][11:14:26]: [Client #36] Woke up.
[INFO][11:14:26]: [Client #486] Woke up.
[INFO][11:14:26]: [Client #36] Epoch: [4/5][0/17]	Loss: 0.385147
[INFO][11:14:26]: [Client #486] Epoch: [2/5][0/16]	Loss: 0.521786
[INFO][11:14:26]: [Client #36] Epoch: [4/5][10/17]	Loss: 1.351843
[INFO][11:14:26]: [Client #486] Epoch: [2/5][10/16]	Loss: 0.821538
[INFO][11:14:26]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][11:14:26]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][11:14:26]: [Client #36] Woke up.
[INFO][11:14:26]: [Client #36] Epoch: [5/5][0/17]	Loss: 0.204898
[INFO][11:14:26]: [Client #36] Epoch: [5/5][10/17]	Loss: 0.768350
[INFO][11:14:27]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][11:14:27]: [Client #36] Woke up.
[INFO][11:14:27]: [Client #36] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][11:14:28]: [Client #486] Woke up.
[INFO][11:14:28]: [Client #486] Epoch: [3/5][0/16]	Loss: 0.555878
[INFO][11:14:28]: [Client #36] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][11:14:28]: [Client #36] Model trained.
[INFO][11:14:28]: [Client #36] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:14:28]: [Server #554754] Received 0.26 MB of payload data from client #36 (simulated).
[INFO][11:14:28]: [Client #486] Epoch: [3/5][10/16]	Loss: 0.880670
[INFO][11:14:28]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][11:14:29]: [Client #486] Woke up.
[INFO][11:14:29]: [Client #486] Epoch: [4/5][0/16]	Loss: 0.316389
[INFO][11:14:30]: [Client #486] Epoch: [4/5][10/16]	Loss: 0.290319
[INFO][11:14:30]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][11:14:31]: [Client #486] Woke up.
[INFO][11:14:31]: [Client #486] Epoch: [5/5][0/16]	Loss: 0.735933
[INFO][11:14:31]: [Client #486] Epoch: [5/5][10/16]	Loss: 0.873350
[INFO][11:14:31]: [Client #486] Going to sleep for 1.69 seconds.
[INFO][11:14:33]: [Client #486] Woke up.
[INFO][11:14:33]: [Client #486] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_554860.pth.
[INFO][11:14:34]: [Client #486] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_486_554860.pth.
[INFO][11:14:34]: [Client #486] Model trained.
[INFO][11:14:34]: [Client #486] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:14:34]: [Server #554754] Received 0.26 MB of payload data from client #486 (simulated).
[INFO][11:14:34]: [Server #554754] Selecting client #378 for training.
[INFO][11:14:34]: [Server #554754] Sending the current model to client #378 (simulated).
[INFO][11:14:34]: [Server #554754] Sending 0.26 MB of payload data to client #378 (simulated).
[INFO][11:14:34]: [Server #554754] Selecting client #404 for training.
[INFO][11:14:34]: [Server #554754] Sending the current model to client #404 (simulated).
[INFO][11:14:34]: [Server #554754] Sending 0.26 MB of payload data to client #404 (simulated).
[INFO][11:14:34]: [Client #404] Selected by the server.
[INFO][11:14:34]: [Client #378] Selected by the server.
[INFO][11:14:34]: [Client #404] Loading its data source...
[INFO][11:14:34]: [Client #378] Loading its data source...
[INFO][11:14:34]: Data source: FEMNIST
[INFO][11:14:34]: Data source: FEMNIST
[INFO][11:14:34]: [Client #404] Dataset size: 161
[INFO][11:14:34]: [Client #404] Sampler: all_inclusive
[INFO][11:14:34]: [Client #404] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:34]: [Client #378] Dataset size: 224
[INFO][11:14:34]: [Client #378] Sampler: all_inclusive
[INFO][11:14:34]: [93m[1m[Client #404] Started training in communication round #31.[0m
[INFO][11:14:34]: [Client #378] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:34]: [93m[1m[Client #378] Started training in communication round #31.[0m
[INFO][11:14:36]: [Client #404] Loading the dataset.
[INFO][11:14:36]: [Client #378] Loading the dataset.
[INFO][11:14:41]: [Client #404] Epoch: [1/5][0/17]	Loss: 0.561795
[INFO][11:14:41]: [Client #378] Epoch: [1/5][0/23]	Loss: 0.840114
[INFO][11:14:41]: [Client #404] Epoch: [1/5][10/17]	Loss: 1.728808
[INFO][11:14:41]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][11:14:41]: [Client #378] Epoch: [1/5][10/23]	Loss: 0.738482
[INFO][11:14:41]: [Client #378] Epoch: [1/5][20/23]	Loss: 1.469908
[INFO][11:14:41]: [Client #378] Going to sleep for 2.25 seconds.
[INFO][11:14:44]: [Client #378] Woke up.
[INFO][11:14:44]: [Client #378] Epoch: [2/5][0/23]	Loss: 0.700634
[INFO][11:14:44]: [Client #404] Woke up.
[INFO][11:14:44]: [Client #404] Epoch: [2/5][0/17]	Loss: 0.579079
[INFO][11:14:44]: [Client #378] Epoch: [2/5][10/23]	Loss: 0.879326
[INFO][11:14:44]: [Client #404] Epoch: [2/5][10/17]	Loss: 0.570394
[INFO][11:14:44]: [Client #378] Epoch: [2/5][20/23]	Loss: 0.589771
[INFO][11:14:44]: [Client #378] Going to sleep for 2.25 seconds.
[INFO][11:14:44]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][11:14:46]: [Client #378] Woke up.
[INFO][11:14:46]: [Client #378] Epoch: [3/5][0/23]	Loss: 0.599931
[INFO][11:14:46]: [Client #378] Epoch: [3/5][10/23]	Loss: 0.742729
[INFO][11:14:46]: [Client #378] Epoch: [3/5][20/23]	Loss: 0.833010
[INFO][11:14:46]: [Client #378] Going to sleep for 2.25 seconds.
[INFO][11:14:46]: [Client #404] Woke up.
[INFO][11:14:46]: [Client #404] Epoch: [3/5][0/17]	Loss: 0.154698
[INFO][11:14:46]: [Client #404] Epoch: [3/5][10/17]	Loss: 0.207061
[INFO][11:14:46]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][11:14:48]: [Client #378] Woke up.
[INFO][11:14:48]: [Client #378] Epoch: [4/5][0/23]	Loss: 0.432932
[INFO][11:14:49]: [Client #378] Epoch: [4/5][10/23]	Loss: 0.695741
[INFO][11:14:49]: [Client #378] Epoch: [4/5][20/23]	Loss: 1.465137
[INFO][11:14:49]: [Client #378] Going to sleep for 2.25 seconds.
[INFO][11:14:49]: [Client #404] Woke up.
[INFO][11:14:49]: [Client #404] Epoch: [4/5][0/17]	Loss: 0.654616
[INFO][11:14:49]: [Client #404] Epoch: [4/5][10/17]	Loss: 1.440979
[INFO][11:14:49]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][11:14:51]: [Client #378] Woke up.
[INFO][11:14:51]: [Client #378] Epoch: [5/5][0/23]	Loss: 0.615598
[INFO][11:14:51]: [Client #378] Epoch: [5/5][10/23]	Loss: 0.466322
[INFO][11:14:51]: [Client #378] Epoch: [5/5][20/23]	Loss: 1.351505
[INFO][11:14:51]: [Client #378] Going to sleep for 2.25 seconds.
[INFO][11:14:51]: [Client #404] Woke up.
[INFO][11:14:51]: [Client #404] Epoch: [5/5][0/17]	Loss: 2.628287
[INFO][11:14:51]: [Client #404] Epoch: [5/5][10/17]	Loss: 0.996327
[INFO][11:14:52]: [Client #404] Going to sleep for 2.44 seconds.
[INFO][11:14:53]: [Client #378] Woke up.
[INFO][11:14:53]: [Client #378] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_378_554853.pth.
[INFO][11:14:54]: [Client #404] Woke up.
[INFO][11:14:54]: [Client #404] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_404_554860.pth.
[INFO][11:14:54]: [Client #378] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_378_554853.pth.
[INFO][11:14:54]: [Client #378] Model trained.
[INFO][11:14:54]: [Client #378] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:14:54]: [Server #554754] Received 0.26 MB of payload data from client #378 (simulated).
[INFO][11:14:55]: [Client #404] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_404_554860.pth.
[INFO][11:14:55]: [Client #404] Model trained.
[INFO][11:14:55]: [Client #404] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:14:55]: [Server #554754] Received 0.26 MB of payload data from client #404 (simulated).
[INFO][11:14:55]: [Server #554754] Selecting client #377 for training.
[INFO][11:14:55]: [Server #554754] Sending the current model to client #377 (simulated).
[INFO][11:14:55]: [Server #554754] Sending 0.26 MB of payload data to client #377 (simulated).
[INFO][11:14:55]: [Server #554754] Selecting client #40 for training.
[INFO][11:14:55]: [Server #554754] Sending the current model to client #40 (simulated).
[INFO][11:14:55]: [Server #554754] Sending 0.26 MB of payload data to client #40 (simulated).
[INFO][11:14:55]: [Client #377] Selected by the server.
[INFO][11:14:55]: [Client #40] Selected by the server.
[INFO][11:14:55]: [Client #377] Loading its data source...
[INFO][11:14:55]: [Client #40] Loading its data source...
[INFO][11:14:55]: Data source: FEMNIST
[INFO][11:14:55]: Data source: FEMNIST
[INFO][11:14:55]: [Client #377] Dataset size: 142
[INFO][11:14:55]: [Client #377] Sampler: all_inclusive
[INFO][11:14:55]: [Client #40] Dataset size: 155
[INFO][11:14:55]: [Client #40] Sampler: all_inclusive
[INFO][11:14:55]: [Client #377] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:55]: [Client #40] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:14:55]: [93m[1m[Client #40] Started training in communication round #31.[0m
[INFO][11:14:55]: [93m[1m[Client #377] Started training in communication round #31.[0m
[INFO][11:14:57]: [Client #377] Loading the dataset.
[INFO][11:14:57]: [Client #40] Loading the dataset.
[INFO][11:15:02]: [Client #377] Epoch: [1/5][0/15]	Loss: 1.039574
[INFO][11:15:02]: [Client #40] Epoch: [1/5][0/16]	Loss: 0.813751
[INFO][11:15:02]: [Client #377] Epoch: [1/5][10/15]	Loss: 0.726098
[INFO][11:15:02]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:15:02]: [Client #40] Epoch: [1/5][10/16]	Loss: 0.725052
[INFO][11:15:02]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:15:05]: [Client #40] Woke up.
[INFO][11:15:05]: [Client #40] Epoch: [2/5][0/16]	Loss: 0.807004
[INFO][11:15:05]: [Client #40] Epoch: [2/5][10/16]	Loss: 1.005619
[INFO][11:15:05]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:15:08]: [Client #40] Woke up.
[INFO][11:15:08]: [Client #40] Epoch: [3/5][0/16]	Loss: 0.217212
[INFO][11:15:08]: [Client #377] Woke up.
[INFO][11:15:08]: [Client #377] Epoch: [2/5][0/15]	Loss: 0.842541
[INFO][11:15:09]: [Client #40] Epoch: [3/5][10/16]	Loss: 0.460318
[INFO][11:15:09]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:15:09]: [Client #377] Epoch: [2/5][10/15]	Loss: 0.392165
[INFO][11:15:09]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:15:12]: [Client #40] Woke up.
[INFO][11:15:12]: [Client #40] Epoch: [4/5][0/16]	Loss: 0.197401
[INFO][11:15:12]: [Client #40] Epoch: [4/5][10/16]	Loss: 0.172276
[INFO][11:15:12]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:15:15]: [Client #40] Woke up.
[INFO][11:15:15]: [Client #40] Epoch: [5/5][0/16]	Loss: 0.480613
[INFO][11:15:15]: [Client #40] Epoch: [5/5][10/16]	Loss: 0.394636
[INFO][11:15:15]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:15:15]: [Client #377] Woke up.
[INFO][11:15:15]: [Client #377] Epoch: [3/5][0/15]	Loss: 0.060449
[INFO][11:15:15]: [Client #377] Epoch: [3/5][10/15]	Loss: 0.481404
[INFO][11:15:15]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:15:18]: [Client #40] Woke up.
[INFO][11:15:18]: [Client #40] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_554860.pth.
[INFO][11:15:19]: [Client #40] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_554860.pth.
[INFO][11:15:19]: [Client #40] Model trained.
[INFO][11:15:19]: [Client #40] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:15:19]: [Server #554754] Received 0.26 MB of payload data from client #40 (simulated).
[INFO][11:15:21]: [Client #377] Woke up.
[INFO][11:15:21]: [Client #377] Epoch: [4/5][0/15]	Loss: 0.043654
[INFO][11:15:21]: [Client #377] Epoch: [4/5][10/15]	Loss: 0.214782
[INFO][11:15:21]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:15:28]: [Client #377] Woke up.
[INFO][11:15:28]: [Client #377] Epoch: [5/5][0/15]	Loss: 0.344192
[INFO][11:15:28]: [Client #377] Epoch: [5/5][10/15]	Loss: 1.401420
[INFO][11:15:28]: [Client #377] Going to sleep for 6.26 seconds.
[INFO][11:15:34]: [Client #377] Woke up.
[INFO][11:15:34]: [Client #377] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][11:15:35]: [Client #377] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_377_554853.pth.
[INFO][11:15:35]: [Client #377] Model trained.
[INFO][11:15:35]: [Client #377] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:15:35]: [Server #554754] Received 0.26 MB of payload data from client #377 (simulated).
[INFO][11:15:35]: [Server #554754] Selecting client #241 for training.
[INFO][11:15:35]: [Server #554754] Sending the current model to client #241 (simulated).
[INFO][11:15:35]: [Server #554754] Sending 0.26 MB of payload data to client #241 (simulated).
[INFO][11:15:35]: [Server #554754] Selecting client #223 for training.
[INFO][11:15:35]: [Server #554754] Sending the current model to client #223 (simulated).
[INFO][11:15:35]: [Server #554754] Sending 0.26 MB of payload data to client #223 (simulated).
[INFO][11:15:35]: [Client #241] Selected by the server.
[INFO][11:15:35]: [Client #241] Loading its data source...
[INFO][11:15:35]: Data source: FEMNIST
[INFO][11:15:35]: [Client #223] Selected by the server.
[INFO][11:15:35]: [Client #223] Loading its data source...
[INFO][11:15:35]: Data source: FEMNIST
[INFO][11:15:35]: [Client #241] Dataset size: 149
[INFO][11:15:35]: [Client #241] Sampler: all_inclusive
[INFO][11:15:35]: [Client #241] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:15:35]: [93m[1m[Client #241] Started training in communication round #31.[0m
[INFO][11:15:35]: [Client #223] Dataset size: 317
[INFO][11:15:35]: [Client #223] Sampler: all_inclusive
[INFO][11:15:35]: [Client #223] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:15:35]: [93m[1m[Client #223] Started training in communication round #31.[0m
[INFO][11:15:37]: [Client #241] Loading the dataset.
[INFO][11:15:37]: [Client #223] Loading the dataset.
[INFO][11:15:42]: [Client #241] Epoch: [1/5][0/15]	Loss: 1.043485
[INFO][11:15:42]: [Client #223] Epoch: [1/5][0/32]	Loss: 1.439671
[INFO][11:15:42]: [Client #241] Epoch: [1/5][10/15]	Loss: 0.175191
[INFO][11:15:42]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][11:15:42]: [Client #223] Epoch: [1/5][10/32]	Loss: 0.588117
[INFO][11:15:42]: [Client #223] Epoch: [1/5][20/32]	Loss: 0.871914
[INFO][11:15:42]: [Client #223] Epoch: [1/5][30/32]	Loss: 0.852377
[INFO][11:15:42]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][11:15:43]: [Client #223] Woke up.
[INFO][11:15:43]: [Client #223] Epoch: [2/5][0/32]	Loss: 1.004796
[INFO][11:15:43]: [Client #223] Epoch: [2/5][10/32]	Loss: 0.687607
[INFO][11:15:43]: [Client #241] Woke up.
[INFO][11:15:43]: [Client #241] Epoch: [2/5][0/15]	Loss: 0.988863
[INFO][11:15:43]: [Client #223] Epoch: [2/5][20/32]	Loss: 0.765658
[INFO][11:15:43]: [Client #241] Epoch: [2/5][10/15]	Loss: 1.086706
[INFO][11:15:43]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][11:15:43]: [Client #223] Epoch: [2/5][30/32]	Loss: 0.616469
[INFO][11:15:43]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][11:15:43]: [Client #223] Woke up.
[INFO][11:15:43]: [Client #223] Epoch: [3/5][0/32]	Loss: 1.636682
[INFO][11:15:43]: [Client #223] Epoch: [3/5][10/32]	Loss: 0.800004
[INFO][11:15:43]: [Client #223] Epoch: [3/5][20/32]	Loss: 1.379267
[INFO][11:15:43]: [Client #223] Epoch: [3/5][30/32]	Loss: 0.763841
[INFO][11:15:43]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][11:15:43]: [Client #241] Woke up.
[INFO][11:15:43]: [Client #241] Epoch: [3/5][0/15]	Loss: 0.906581
[INFO][11:15:43]: [Client #241] Epoch: [3/5][10/15]	Loss: 0.423557
[INFO][11:15:43]: [Client #223] Woke up.
[INFO][11:15:44]: [Client #223] Epoch: [4/5][0/32]	Loss: 0.445765
[INFO][11:15:44]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][11:15:44]: [Client #223] Epoch: [4/5][10/32]	Loss: 0.899239
[INFO][11:15:44]: [Client #223] Epoch: [4/5][20/32]	Loss: 1.234223
[INFO][11:15:44]: [Client #223] Epoch: [4/5][30/32]	Loss: 1.385452
[INFO][11:15:44]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][11:15:44]: [Client #223] Woke up.
[INFO][11:15:44]: [Client #223] Epoch: [5/5][0/32]	Loss: 0.563879
[INFO][11:15:44]: [Client #241] Woke up.
[INFO][11:15:44]: [Client #241] Epoch: [4/5][0/15]	Loss: 1.460000
[INFO][11:15:44]: [Client #223] Epoch: [5/5][10/32]	Loss: 0.874844
[INFO][11:15:44]: [Client #241] Epoch: [4/5][10/15]	Loss: 0.963968
[INFO][11:15:44]: [Client #223] Epoch: [5/5][20/32]	Loss: 1.066479
[INFO][11:15:44]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][11:15:44]: [Client #223] Epoch: [5/5][30/32]	Loss: 0.846010
[INFO][11:15:44]: [Client #223] Going to sleep for 0.15 seconds.
[INFO][11:15:44]: [Client #223] Woke up.
[INFO][11:15:44]: [Client #223] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_223_554860.pth.
[INFO][11:15:45]: [Client #241] Woke up.
[INFO][11:15:45]: [Client #241] Epoch: [5/5][0/15]	Loss: 0.883156
[INFO][11:15:45]: [Client #241] Epoch: [5/5][10/15]	Loss: 0.283989
[INFO][11:15:45]: [Client #241] Going to sleep for 0.46 seconds.
[INFO][11:15:45]: [Client #223] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_223_554860.pth.
[INFO][11:15:45]: [Client #223] Model trained.
[INFO][11:15:45]: [Client #223] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:15:45]: [Server #554754] Received 0.26 MB of payload data from client #223 (simulated).
[INFO][11:15:45]: [Client #241] Woke up.
[INFO][11:15:45]: [Client #241] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_554853.pth.
[INFO][11:15:46]: [Client #241] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_241_554853.pth.
[INFO][11:15:46]: [Client #241] Model trained.
[INFO][11:15:46]: [Client #241] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:15:46]: [Server #554754] Received 0.26 MB of payload data from client #241 (simulated).
[INFO][11:15:46]: [Server #554754] Adding client #223 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #241 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #36 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #486 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #378 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #404 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #40 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #349 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #377 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][11:15:46]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14780532
 0.         0.         0.         0.06893838 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.21744038 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1263857  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15780929 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05799957 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18337185 0.12341785
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.93305881 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1337283
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14780532
 0.         0.         0.         0.06893838 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.21744038 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1263857  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.15780929 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05799957 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18337185 0.12341785
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.93305881 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.1337283
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:16:30]: [Server #554754] Global model accuracy: 63.13%

[INFO][11:16:30]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_31.pth.
[INFO][11:16:30]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_31.pth.
[INFO][11:16:30]: [93m[1m
[Server #554754] Starting round 32/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.09514925 0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.10318471 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.002      0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.05007728 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.002      0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.002      0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.002      0.002      0.1016624
 0.002      0.10306588 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.002      0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.09950249 0.002      0.002      0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08830846 0.002      0.05352394 0.002      0.08775852 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.09071038 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.002      0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09144543 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  2e-04  3e-09  3e-09
 6:  6.9057e+00  6.9056e+00  2e-04  4e-09  6e-10
 7:  6.9057e+00  6.9056e+00  1e-04  5e-09  8e-10
 8:  6.9057e+00  6.9056e+00  8e-05  5e-08  9e-09
 9:  6.9056e+00  6.9056e+00  4e-05  5e-08  8e-09
10:  6.9056e+00  6.9056e+00  3e-06  4e-08  6e-09
Optimal solution found.
The calculated probability is:  [4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.65332294e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66085570e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.58574686e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.65690841e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 9.76784329e-01 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66128116e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.65160854e-05
 4.65019667e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.31588826e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.65521621e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05 4.66273217e-05
 4.66273217e-05 4.66273217e-05 4.66273217e-05]
current clients pool:  [INFO][11:16:31]: [Server #554754] Selected clients: [299 117  88 195 160 409 308 381 214  50]
[INFO][11:16:31]: [Server #554754] Selecting client #299 for training.
[INFO][11:16:31]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][11:16:31]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][11:16:31]: [Server #554754] Selecting client #117 for training.
[INFO][11:16:31]: [Server #554754] Sending the current model to client #117 (simulated).
[INFO][11:16:31]: [Server #554754] Sending 0.26 MB of payload data to client #117 (simulated).
[INFO][11:16:31]: [Client #299] Selected by the server.
[INFO][11:16:31]: [Client #299] Loading its data source...
[INFO][11:16:31]: Data source: FEMNIST
[INFO][11:16:31]: [Client #117] Selected by the server.
[INFO][11:16:31]: [Client #117] Loading its data source...
[INFO][11:16:31]: Data source: FEMNIST
[INFO][11:16:31]: [Client #117] Dataset size: 152
[INFO][11:16:31]: [Client #117] Sampler: all_inclusive
[INFO][11:16:31]: [Client #117] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:16:31]: [Client #299] Dataset size: 157
[INFO][11:16:31]: [Client #299] Sampler: all_inclusive
[INFO][11:16:31]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:16:31]: [93m[1m[Client #299] Started training in communication round #32.[0m
[INFO][11:16:31]: [93m[1m[Client #117] Started training in communication round #32.[0m
[INFO][11:16:33]: [Client #299] Loading the dataset.
[INFO][11:16:33]: [Client #117] Loading the dataset.
[INFO][11:16:38]: [Client #299] Epoch: [1/5][0/16]	Loss: 1.031429
[INFO][11:16:38]: [Client #117] Epoch: [1/5][0/16]	Loss: 0.339224
[INFO][11:16:38]: [Client #299] Epoch: [1/5][10/16]	Loss: 0.416606
[INFO][11:16:38]: [Client #117] Epoch: [1/5][10/16]	Loss: 0.567537
[INFO][11:16:38]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:16:38]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][11:16:41]: [Client #117] Woke up.
[INFO][11:16:41]: [Client #117] Epoch: [2/5][0/16]	Loss: 0.259899
[INFO][11:16:41]: [Client #117] Epoch: [2/5][10/16]	Loss: 0.238031
[INFO][11:16:41]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][11:16:44]: [Client #117] Woke up.
[INFO][11:16:44]: [Client #117] Epoch: [3/5][0/16]	Loss: 0.535255
[INFO][11:16:44]: [Client #117] Epoch: [3/5][10/16]	Loss: 0.106418
[INFO][11:16:44]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][11:16:48]: [Client #117] Woke up.
[INFO][11:16:48]: [Client #117] Epoch: [4/5][0/16]	Loss: 0.418044
[INFO][11:16:48]: [Client #117] Epoch: [4/5][10/16]	Loss: 0.689982
[INFO][11:16:48]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][11:16:51]: [Client #117] Woke up.
[INFO][11:16:51]: [Client #117] Epoch: [5/5][0/16]	Loss: 0.211736
[INFO][11:16:51]: [Client #117] Epoch: [5/5][10/16]	Loss: 0.268842
[INFO][11:16:51]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][11:16:54]: [Client #117] Woke up.
[INFO][11:16:54]: [Client #117] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_554860.pth.
[INFO][11:16:55]: [Client #117] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_554860.pth.
[INFO][11:16:55]: [Client #117] Model trained.
[INFO][11:16:55]: [Client #117] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:16:55]: [Server #554754] Received 0.26 MB of payload data from client #117 (simulated).
[INFO][11:17:35]: [Client #299] Woke up.
[INFO][11:17:35]: [Client #299] Epoch: [2/5][0/16]	Loss: 0.455850
[INFO][11:17:36]: [Client #299] Epoch: [2/5][10/16]	Loss: 0.350794
[INFO][11:17:36]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:18:33]: [Client #299] Woke up.
[INFO][11:18:33]: [Client #299] Epoch: [3/5][0/16]	Loss: 0.515174
[INFO][11:18:33]: [Client #299] Epoch: [3/5][10/16]	Loss: 0.337465
[INFO][11:18:33]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:19:30]: [Client #299] Woke up.
[INFO][11:19:30]: [Client #299] Epoch: [4/5][0/16]	Loss: 0.506555
[INFO][11:19:31]: [Client #299] Epoch: [4/5][10/16]	Loss: 0.872499
[INFO][11:19:31]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:20:28]: [Client #299] Woke up.
[INFO][11:20:28]: [Client #299] Epoch: [5/5][0/16]	Loss: 0.645957
[INFO][11:20:28]: [Client #299] Epoch: [5/5][10/16]	Loss: 1.100335
[INFO][11:20:28]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:21:25]: [Client #299] Woke up.
[INFO][11:21:25]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:21:26]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:21:26]: [Client #299] Model trained.
[INFO][11:21:26]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:21:26]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][11:21:26]: [Server #554754] Selecting client #88 for training.
[INFO][11:21:26]: [Server #554754] Sending the current model to client #88 (simulated).
[INFO][11:21:26]: [Server #554754] Sending 0.26 MB of payload data to client #88 (simulated).
[INFO][11:21:26]: [Server #554754] Selecting client #195 for training.
[INFO][11:21:26]: [Server #554754] Sending the current model to client #195 (simulated).
[INFO][11:21:26]: [Server #554754] Sending 0.26 MB of payload data to client #195 (simulated).
[INFO][11:21:26]: [Client #88] Selected by the server.
[INFO][11:21:26]: [Client #88] Loading its data source...
[INFO][11:21:26]: Data source: FEMNIST
[INFO][11:21:26]: [Client #195] Selected by the server.
[INFO][11:21:26]: [Client #195] Loading its data source...
[INFO][11:21:26]: Data source: FEMNIST
[INFO][11:21:26]: [Client #195] Dataset size: 162
[INFO][11:21:26]: [Client #195] Sampler: all_inclusive
[INFO][11:21:26]: [Client #88] Dataset size: 162
[INFO][11:21:26]: [Client #88] Sampler: all_inclusive
[INFO][11:21:26]: [Client #195] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:21:26]: [Client #88] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:21:26]: [93m[1m[Client #195] Started training in communication round #32.[0m
[INFO][11:21:26]: [93m[1m[Client #88] Started training in communication round #32.[0m
[INFO][11:21:28]: [Client #195] Loading the dataset.
[INFO][11:21:28]: [Client #88] Loading the dataset.
[INFO][11:21:33]: [Client #88] Epoch: [1/5][0/17]	Loss: 0.128816
[INFO][11:21:33]: [Client #195] Epoch: [1/5][0/17]	Loss: 1.122516
[INFO][11:21:33]: [Client #88] Epoch: [1/5][10/17]	Loss: 0.302012
[INFO][11:21:34]: [Client #195] Epoch: [1/5][10/17]	Loss: 1.205219
[INFO][11:21:34]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][11:21:34]: [Client #195] Going to sleep for 9.85 seconds.
[INFO][11:21:43]: [Client #195] Woke up.
[INFO][11:21:43]: [Client #195] Epoch: [2/5][0/17]	Loss: 2.167276
[INFO][11:21:44]: [Client #195] Epoch: [2/5][10/17]	Loss: 0.884159
[INFO][11:21:44]: [Client #195] Going to sleep for 9.85 seconds.
[INFO][11:21:53]: [Client #195] Woke up.
[INFO][11:21:53]: [Client #195] Epoch: [3/5][0/17]	Loss: 1.406840
[INFO][11:21:54]: [Client #195] Epoch: [3/5][10/17]	Loss: 2.018078
[INFO][11:21:54]: [Client #195] Going to sleep for 9.85 seconds.
[INFO][11:22:01]: [Client #88] Woke up.
[INFO][11:22:01]: [Client #88] Epoch: [2/5][0/17]	Loss: 0.495807
[INFO][11:22:01]: [Client #88] Epoch: [2/5][10/17]	Loss: 0.107470
[INFO][11:22:01]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][11:22:03]: [Client #195] Woke up.
[INFO][11:22:04]: [Client #195] Epoch: [4/5][0/17]	Loss: 1.312249
[INFO][11:22:04]: [Client #195] Epoch: [4/5][10/17]	Loss: 0.952290
[INFO][11:22:04]: [Client #195] Going to sleep for 9.85 seconds.
[INFO][11:22:14]: [Client #195] Woke up.
[INFO][11:22:14]: [Client #195] Epoch: [5/5][0/17]	Loss: 0.187822
[INFO][11:22:14]: [Client #195] Epoch: [5/5][10/17]	Loss: 0.528829
[INFO][11:22:14]: [Client #195] Going to sleep for 9.85 seconds.
[INFO][11:22:24]: [Client #195] Woke up.
[INFO][11:22:24]: [Client #195] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_195_554860.pth.
[INFO][11:22:24]: [Client #195] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_195_554860.pth.
[INFO][11:22:24]: [Client #195] Model trained.
[INFO][11:22:24]: [Client #195] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:22:24]: [Server #554754] Received 0.26 MB of payload data from client #195 (simulated).
[INFO][11:22:29]: [Client #88] Woke up.
[INFO][11:22:29]: [Client #88] Epoch: [3/5][0/17]	Loss: 0.487318
[INFO][11:22:29]: [Client #88] Epoch: [3/5][10/17]	Loss: 1.145730
[INFO][11:22:29]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][11:22:56]: [Client #88] Woke up.
[INFO][11:22:56]: [Client #88] Epoch: [4/5][0/17]	Loss: 0.617980
[INFO][11:22:57]: [Client #88] Epoch: [4/5][10/17]	Loss: 0.980916
[INFO][11:22:57]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][11:23:24]: [Client #88] Woke up.
[INFO][11:23:24]: [Client #88] Epoch: [5/5][0/17]	Loss: 1.069217
[INFO][11:23:24]: [Client #88] Epoch: [5/5][10/17]	Loss: 0.865266
[INFO][11:23:24]: [Client #88] Going to sleep for 27.44 seconds.
[INFO][11:23:52]: [Client #88] Woke up.
[INFO][11:23:52]: [Client #88] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_554853.pth.
[INFO][11:23:53]: [Client #88] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_88_554853.pth.
[INFO][11:23:53]: [Client #88] Model trained.
[INFO][11:23:53]: [Client #88] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:23:53]: [Server #554754] Received 0.26 MB of payload data from client #88 (simulated).
[INFO][11:23:53]: [Server #554754] Selecting client #160 for training.
[INFO][11:23:53]: [Server #554754] Sending the current model to client #160 (simulated).
[INFO][11:23:53]: [Server #554754] Sending 0.26 MB of payload data to client #160 (simulated).
[INFO][11:23:53]: [Server #554754] Selecting client #409 for training.
[INFO][11:23:53]: [Server #554754] Sending the current model to client #409 (simulated).
[INFO][11:23:53]: [Server #554754] Sending 0.26 MB of payload data to client #409 (simulated).
[INFO][11:23:53]: [Client #160] Selected by the server.
[INFO][11:23:53]: [Client #160] Loading its data source...
[INFO][11:23:53]: Data source: FEMNIST
[INFO][11:23:53]: [Client #409] Selected by the server.
[INFO][11:23:53]: [Client #409] Loading its data source...
[INFO][11:23:53]: Data source: FEMNIST
[INFO][11:23:53]: [Client #160] Dataset size: 151
[INFO][11:23:53]: [Client #160] Sampler: all_inclusive
[INFO][11:23:53]: [Client #409] Dataset size: 155
[INFO][11:23:53]: [Client #409] Sampler: all_inclusive
[INFO][11:23:53]: [Client #160] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:23:53]: [Client #409] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:23:53]: [93m[1m[Client #409] Started training in communication round #32.[0m
[INFO][11:23:53]: [93m[1m[Client #160] Started training in communication round #32.[0m
[INFO][11:23:54]: [Client #409] Loading the dataset.
[INFO][11:23:54]: [Client #160] Loading the dataset.
[INFO][11:24:00]: [Client #409] Epoch: [1/5][0/16]	Loss: 0.936439
[INFO][11:24:00]: [Client #160] Epoch: [1/5][0/16]	Loss: 1.281092
[INFO][11:24:00]: [Client #409] Epoch: [1/5][10/16]	Loss: 0.724889
[INFO][11:24:00]: [Client #160] Epoch: [1/5][10/16]	Loss: 0.961755
[INFO][11:24:00]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][11:24:00]: [Client #160] Going to sleep for 5.53 seconds.
[INFO][11:24:00]: [Client #409] Woke up.
[INFO][11:24:00]: [Client #409] Epoch: [2/5][0/16]	Loss: 0.921129
[INFO][11:24:00]: [Client #409] Epoch: [2/5][10/16]	Loss: 1.982898
[INFO][11:24:00]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][11:24:01]: [Client #409] Woke up.
[INFO][11:24:01]: [Client #409] Epoch: [3/5][0/16]	Loss: 0.569130
[INFO][11:24:01]: [Client #409] Epoch: [3/5][10/16]	Loss: 1.189217
[INFO][11:24:01]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][11:24:01]: [Client #409] Woke up.
[INFO][11:24:01]: [Client #409] Epoch: [4/5][0/16]	Loss: 0.810239
[INFO][11:24:01]: [Client #409] Epoch: [4/5][10/16]	Loss: 1.183912
[INFO][11:24:01]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][11:24:01]: [Client #409] Woke up.
[INFO][11:24:01]: [Client #409] Epoch: [5/5][0/16]	Loss: 1.054617
[INFO][11:24:01]: [Client #409] Epoch: [5/5][10/16]	Loss: 0.919216
[INFO][11:24:01]: [Client #409] Going to sleep for 0.09 seconds.
[INFO][11:24:01]: [Client #409] Woke up.
[INFO][11:24:01]: [Client #409] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_409_554860.pth.
[INFO][11:24:02]: [Client #409] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_409_554860.pth.
[INFO][11:24:02]: [Client #409] Model trained.
[INFO][11:24:02]: [Client #409] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:02]: [Server #554754] Received 0.26 MB of payload data from client #409 (simulated).
[INFO][11:24:06]: [Client #160] Woke up.
[INFO][11:24:06]: [Client #160] Epoch: [2/5][0/16]	Loss: 0.717627
[INFO][11:24:06]: [Client #160] Epoch: [2/5][10/16]	Loss: 0.668291
[INFO][11:24:06]: [Client #160] Going to sleep for 5.53 seconds.
[INFO][11:24:11]: [Client #160] Woke up.
[INFO][11:24:11]: [Client #160] Epoch: [3/5][0/16]	Loss: 0.375932
[INFO][11:24:12]: [Client #160] Epoch: [3/5][10/16]	Loss: 1.021271
[INFO][11:24:12]: [Client #160] Going to sleep for 5.53 seconds.
[INFO][11:24:17]: [Client #160] Woke up.
[INFO][11:24:17]: [Client #160] Epoch: [4/5][0/16]	Loss: 0.227532
[INFO][11:24:17]: [Client #160] Epoch: [4/5][10/16]	Loss: 3.067449
[INFO][11:24:17]: [Client #160] Going to sleep for 5.53 seconds.
[INFO][11:24:23]: [Client #160] Woke up.
[INFO][11:24:23]: [Client #160] Epoch: [5/5][0/16]	Loss: 0.820433
[INFO][11:24:23]: [Client #160] Epoch: [5/5][10/16]	Loss: 1.138368
[INFO][11:24:23]: [Client #160] Going to sleep for 5.53 seconds.
[INFO][11:24:28]: [Client #160] Woke up.
[INFO][11:24:28]: [Client #160] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_160_554853.pth.
[INFO][11:24:29]: [Client #160] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_160_554853.pth.
[INFO][11:24:29]: [Client #160] Model trained.
[INFO][11:24:29]: [Client #160] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:29]: [Server #554754] Received 0.26 MB of payload data from client #160 (simulated).
[INFO][11:24:29]: [Server #554754] Selecting client #308 for training.
[INFO][11:24:29]: [Server #554754] Sending the current model to client #308 (simulated).
[INFO][11:24:29]: [Server #554754] Sending 0.26 MB of payload data to client #308 (simulated).
[INFO][11:24:29]: [Server #554754] Selecting client #381 for training.
[INFO][11:24:29]: [Server #554754] Sending the current model to client #381 (simulated).
[INFO][11:24:29]: [Server #554754] Sending 0.26 MB of payload data to client #381 (simulated).
[INFO][11:24:29]: [Client #308] Selected by the server.
[INFO][11:24:29]: [Client #308] Loading its data source...
[INFO][11:24:29]: Data source: FEMNIST
[INFO][11:24:29]: [Client #381] Selected by the server.
[INFO][11:24:29]: [Client #381] Loading its data source...
[INFO][11:24:29]: Data source: FEMNIST
[INFO][11:24:29]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:24:29]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/381.zip.
[INFO][11:24:29]: [Client #308] Dataset size: 166
[INFO][11:24:29]: [Client #308] Sampler: all_inclusive
[INFO][11:24:29]: [Client #308] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:24:29]: [93m[1m[Client #308] Started training in communication round #32.[0m

2.4%
4.9%
7.3%
9.7%
12.1%
14.6%
17.0%
19.4%
21.8%
24.3%
26.7%
29.1%
31.6%
34.0%
36.4%
38.8%
41.3%
43.7%
46.1%
48.6%
51.0%
53.4%
55.8%
58.3%
60.7%
63.1%
65.5%
68.0%
70.4%
72.8%
75.3%
77.7%
80.1%
82.5%
85.0%
87.4%
89.8%
92.3%
94.7%
97.1%
99.5%
100.0%[INFO][11:24:29]: Decompressing the dataset downloaded.
[INFO][11:24:29]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/381.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:24:29]: [Client #381] Dataset size: 143
[INFO][11:24:29]: [Client #381] Sampler: all_inclusive
[INFO][11:24:29]: [Client #381] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:24:29]: [93m[1m[Client #381] Started training in communication round #32.[0m

[INFO][11:24:31]: [Client #308] Loading the dataset.
[INFO][11:24:31]: [Client #381] Loading the dataset.
[INFO][11:24:37]: [Client #381] Epoch: [1/5][0/15]	Loss: 0.095463
[INFO][11:24:37]: [Client #308] Epoch: [1/5][0/17]	Loss: 0.851243
[INFO][11:24:37]: [Client #381] Epoch: [1/5][10/15]	Loss: 0.070156
[INFO][11:24:37]: [Client #308] Epoch: [1/5][10/17]	Loss: 0.388412
[INFO][11:24:37]: [Client #381] Going to sleep for 0.79 seconds.
[INFO][11:24:37]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][11:24:37]: [Client #308] Woke up.
[INFO][11:24:37]: [Client #308] Epoch: [2/5][0/17]	Loss: 0.833355
[INFO][11:24:37]: [Client #308] Epoch: [2/5][10/17]	Loss: 0.651083
[INFO][11:24:37]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][11:24:38]: [Client #381] Woke up.
[INFO][11:24:38]: [Client #308] Woke up.
[INFO][11:24:38]: [Client #381] Epoch: [2/5][0/15]	Loss: 0.093407
[INFO][11:24:38]: [Client #308] Epoch: [3/5][0/17]	Loss: 0.212242
[INFO][11:24:38]: [Client #381] Epoch: [2/5][10/15]	Loss: 0.471812
[INFO][11:24:38]: [Client #308] Epoch: [3/5][10/17]	Loss: 0.659300
[INFO][11:24:38]: [Client #381] Going to sleep for 0.79 seconds.
[INFO][11:24:38]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][11:24:38]: [Client #308] Woke up.
[INFO][11:24:38]: [Client #308] Epoch: [4/5][0/17]	Loss: 0.515863
[INFO][11:24:38]: [Client #308] Epoch: [4/5][10/17]	Loss: 0.618037
[INFO][11:24:38]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][11:24:38]: [Client #308] Woke up.
[INFO][11:24:38]: [Client #381] Woke up.
[INFO][11:24:38]: [Client #308] Epoch: [5/5][0/17]	Loss: 0.127368
[INFO][11:24:38]: [Client #381] Epoch: [3/5][0/15]	Loss: 0.850833
[INFO][11:24:39]: [Client #381] Epoch: [3/5][10/15]	Loss: 0.713054
[INFO][11:24:39]: [Client #308] Epoch: [5/5][10/17]	Loss: 0.462013
[INFO][11:24:39]: [Client #381] Going to sleep for 0.79 seconds.
[INFO][11:24:39]: [Client #308] Going to sleep for 0.29 seconds.
[INFO][11:24:39]: [Client #308] Woke up.
[INFO][11:24:39]: [Client #308] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_308_554853.pth.
[INFO][11:24:39]: [Client #381] Woke up.
[INFO][11:24:39]: [Client #381] Epoch: [4/5][0/15]	Loss: 0.268765
[INFO][11:24:39]: [Client #381] Epoch: [4/5][10/15]	Loss: 0.223207
[INFO][11:24:40]: [Client #381] Going to sleep for 0.79 seconds.
[INFO][11:24:40]: [Client #308] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_308_554853.pth.
[INFO][11:24:40]: [Client #308] Model trained.
[INFO][11:24:40]: [Client #308] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:40]: [Server #554754] Received 0.26 MB of payload data from client #308 (simulated).
[INFO][11:24:40]: [Client #381] Woke up.
[INFO][11:24:40]: [Client #381] Epoch: [5/5][0/15]	Loss: 0.591667
[INFO][11:24:40]: [Client #381] Epoch: [5/5][10/15]	Loss: 0.942275
[INFO][11:24:40]: [Client #381] Going to sleep for 0.79 seconds.
[INFO][11:24:41]: [Client #381] Woke up.
[INFO][11:24:41]: [Client #381] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_381_554860.pth.
[INFO][11:24:42]: [Client #381] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_381_554860.pth.
[INFO][11:24:42]: [Client #381] Model trained.
[INFO][11:24:42]: [Client #381] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:42]: [Server #554754] Received 0.26 MB of payload data from client #381 (simulated).
[INFO][11:24:42]: [Server #554754] Selecting client #214 for training.
[INFO][11:24:42]: [Server #554754] Sending the current model to client #214 (simulated).
[INFO][11:24:42]: [Server #554754] Sending 0.26 MB of payload data to client #214 (simulated).
[INFO][11:24:42]: [Server #554754] Selecting client #50 for training.
[INFO][11:24:42]: [Server #554754] Sending the current model to client #50 (simulated).
[INFO][11:24:42]: [Server #554754] Sending 0.26 MB of payload data to client #50 (simulated).
[INFO][11:24:42]: [Client #50] Selected by the server.
[INFO][11:24:42]: [Client #214] Selected by the server.
[INFO][11:24:42]: [Client #50] Loading its data source...
[INFO][11:24:42]: [Client #214] Loading its data source...
[INFO][11:24:42]: Data source: FEMNIST
[INFO][11:24:42]: Data source: FEMNIST
[INFO][11:24:42]: [Client #214] Dataset size: 158
[INFO][11:24:42]: [Client #214] Sampler: all_inclusive
[INFO][11:24:42]: [Client #214] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:24:42]: [93m[1m[Client #214] Started training in communication round #32.[0m
[INFO][11:24:42]: [Client #50] Dataset size: 157
[INFO][11:24:42]: [Client #50] Sampler: all_inclusive
[INFO][11:24:42]: [Client #50] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:24:42]: [93m[1m[Client #50] Started training in communication round #32.[0m
[INFO][11:24:44]: [Client #214] Loading the dataset.
[INFO][11:24:44]: [Client #50] Loading the dataset.
[INFO][11:24:49]: [Client #214] Epoch: [1/5][0/16]	Loss: 0.755592
[INFO][11:24:49]: [Client #50] Epoch: [1/5][0/16]	Loss: 0.585887
[INFO][11:24:49]: [Client #214] Epoch: [1/5][10/16]	Loss: 0.880707
[INFO][11:24:49]: [Client #214] Going to sleep for 0.14 seconds.
[INFO][11:24:49]: [Client #50] Epoch: [1/5][10/16]	Loss: 0.324774
[INFO][11:24:50]: [Client #50] Going to sleep for 0.15 seconds.
[INFO][11:24:50]: [Client #214] Woke up.
[INFO][11:24:50]: [Client #214] Epoch: [2/5][0/16]	Loss: 0.681066
[INFO][11:24:50]: [Client #50] Woke up.
[INFO][11:24:50]: [Client #50] Epoch: [2/5][0/16]	Loss: 0.359346
[INFO][11:24:50]: [Client #214] Epoch: [2/5][10/16]	Loss: 0.250804
[INFO][11:24:50]: [Client #214] Going to sleep for 0.14 seconds.
[INFO][11:24:50]: [Client #50] Epoch: [2/5][10/16]	Loss: 0.414599
[INFO][11:24:50]: [Client #50] Going to sleep for 0.15 seconds.
[INFO][11:24:50]: [Client #214] Woke up.
[INFO][11:24:50]: [Client #214] Epoch: [3/5][0/16]	Loss: 0.301675
[INFO][11:24:50]: [Client #50] Woke up.
[INFO][11:24:50]: [Client #50] Epoch: [3/5][0/16]	Loss: 0.442206
[INFO][11:24:50]: [Client #214] Epoch: [3/5][10/16]	Loss: 0.046131
[INFO][11:24:50]: [Client #214] Going to sleep for 0.14 seconds.
[INFO][11:24:50]: [Client #50] Epoch: [3/5][10/16]	Loss: 0.662900
[INFO][11:24:50]: [Client #50] Going to sleep for 0.15 seconds.
[INFO][11:24:50]: [Client #214] Woke up.
[INFO][11:24:50]: [Client #214] Epoch: [4/5][0/16]	Loss: 1.098984
[INFO][11:24:50]: [Client #50] Woke up.
[INFO][11:24:50]: [Client #214] Epoch: [4/5][10/16]	Loss: 0.595688
[INFO][11:24:50]: [Client #50] Epoch: [4/5][0/16]	Loss: 0.290276
[INFO][11:24:50]: [Client #214] Going to sleep for 0.14 seconds.
[INFO][11:24:50]: [Client #50] Epoch: [4/5][10/16]	Loss: 0.140453
[INFO][11:24:50]: [Client #50] Going to sleep for 0.15 seconds.
[INFO][11:24:50]: [Client #214] Woke up.
[INFO][11:24:50]: [Client #214] Epoch: [5/5][0/16]	Loss: 0.293649
[INFO][11:24:51]: [Client #214] Epoch: [5/5][10/16]	Loss: 0.119631
[INFO][11:24:51]: [Client #50] Woke up.
[INFO][11:24:51]: [Client #50] Epoch: [5/5][0/16]	Loss: 1.040428
[INFO][11:24:51]: [Client #214] Going to sleep for 0.14 seconds.
[INFO][11:24:51]: [Client #50] Epoch: [5/5][10/16]	Loss: 0.562291
[INFO][11:24:51]: [Client #50] Going to sleep for 0.15 seconds.
[INFO][11:24:51]: [Client #214] Woke up.
[INFO][11:24:51]: [Client #214] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_214_554853.pth.
[INFO][11:24:51]: [Client #50] Woke up.
[INFO][11:24:51]: [Client #50] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_50_554860.pth.
[INFO][11:24:51]: [Client #214] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_214_554853.pth.
[INFO][11:24:51]: [Client #214] Model trained.
[INFO][11:24:51]: [Client #214] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:51]: [Server #554754] Received 0.26 MB of payload data from client #214 (simulated).
[INFO][11:24:52]: [Client #50] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_50_554860.pth.
[INFO][11:24:52]: [Client #50] Model trained.
[INFO][11:24:52]: [Client #50] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:24:52]: [Server #554754] Received 0.26 MB of payload data from client #50 (simulated).
[INFO][11:24:52]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #409 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #214 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #50 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #308 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #381 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #117 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #160 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #195 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Adding client #88 to the list of clients for aggregation.
[INFO][11:24:52]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13168157 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16429985 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.19475069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.69311989 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.17712168 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1402667  0.         0.07802292 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07635583 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1012075  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.21002091 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13168157 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16429985 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.19475069 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.69311989 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.17712168 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.1402667  0.         0.07802292 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07635583 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.1012075  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.21002091 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:25:36]: [Server #554754] Global model accuracy: 62.21%

[INFO][11:25:36]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_32.pth.
[INFO][11:25:36]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_32.pth.
[INFO][11:25:36]: [93m[1m
[Server #554754] Starting round 33/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.09514925 0.03769968
 0.07933884 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.10318471 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.10344828 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.002      0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.002      0.1016624
 0.002      0.10306588 0.002      0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.10344828 0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.10217114 0.002      0.100894   0.10373711 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08830846 0.002      0.05352394 0.002      0.08775852 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.002
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.002      0.04972711 0.05385638
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.002      0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.002      0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9058e+00  5e+02  1e+00  1e+00
 1:  6.8367e+00  5.9078e+00  6e+00  1e-02  1e-02
 2:  6.9054e+00  6.0705e+00  9e-01  6e-05  6e-05
 3:  6.9057e+00  6.8731e+00  3e-02  6e-07  6e-07
 4:  6.9058e+00  6.9053e+00  5e-04  8e-09  8e-09
 5:  6.9058e+00  6.9056e+00  1e-04  2e-09  2e-09
 6:  6.9057e+00  6.9056e+00  1e-04  2e-09  4e-10
 7:  6.9057e+00  6.9056e+00  1e-04  3e-09  5e-10
 8:  6.9057e+00  6.9056e+00  7e-05  4e-08  6e-09
 9:  6.9057e+00  6.9056e+00  4e-05  4e-08  6e-09
10:  6.9056e+00  6.9056e+00  3e-06  3e-08  5e-09
Optimal solution found.
The calculated probability is:  [5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.18028333e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.17315701e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.16890914e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 4.92475466e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.17024871e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 9.74151833e-01
 5.19115519e-05 5.18728499e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.18706391e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.18582229e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.16427387e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05 5.19115519e-05
 5.19115519e-05 5.19115519e-05 5.19115519e-05]
current clients pool:  [INFO][11:25:36]: [Server #554754] Selected clients: [212  99  13 366 364 165 423 215 433 330]
[INFO][11:25:36]: [Server #554754] Selecting client #212 for training.
[INFO][11:25:36]: [Server #554754] Sending the current model to client #212 (simulated).
[INFO][11:25:36]: [Server #554754] Sending 0.26 MB of payload data to client #212 (simulated).
[INFO][11:25:36]: [Server #554754] Selecting client #99 for training.
[INFO][11:25:36]: [Server #554754] Sending the current model to client #99 (simulated).
[INFO][11:25:36]: [Server #554754] Sending 0.26 MB of payload data to client #99 (simulated).
[INFO][11:25:36]: [Client #212] Selected by the server.
[INFO][11:25:36]: [Client #212] Loading its data source...
[INFO][11:25:36]: Data source: FEMNIST
[INFO][11:25:36]: [Client #99] Selected by the server.
[INFO][11:25:36]: [Client #99] Loading its data source...
[INFO][11:25:36]: Data source: FEMNIST
[INFO][11:25:37]: [Client #212] Dataset size: 160
[INFO][11:25:37]: [Client #212] Sampler: all_inclusive
[INFO][11:25:37]: [Client #212] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:25:37]: [Client #99] Dataset size: 160
[INFO][11:25:37]: [Client #99] Sampler: all_inclusive
[INFO][11:25:37]: [Client #99] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:25:37]: [93m[1m[Client #212] Started training in communication round #33.[0m
[INFO][11:25:37]: [93m[1m[Client #99] Started training in communication round #33.[0m
[INFO][11:25:38]: [Client #212] Loading the dataset.
[INFO][11:25:38]: [Client #99] Loading the dataset.
[INFO][11:25:44]: [Client #212] Epoch: [1/5][0/16]	Loss: 2.675437
[INFO][11:25:44]: [Client #99] Epoch: [1/5][0/16]	Loss: 0.426978
[INFO][11:25:44]: [Client #212] Epoch: [1/5][10/16]	Loss: 1.609475
[INFO][11:25:44]: [Client #99] Epoch: [1/5][10/16]	Loss: 0.726360
[INFO][11:25:44]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:25:44]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:25:44]: [Client #99] Woke up.
[INFO][11:25:44]: [Client #99] Epoch: [2/5][0/16]	Loss: 0.811476
[INFO][11:25:44]: [Client #99] Epoch: [2/5][10/16]	Loss: 0.711689
[INFO][11:25:44]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:25:44]: [Client #99] Woke up.
[INFO][11:25:44]: [Client #99] Epoch: [3/5][0/16]	Loss: 0.108407
[INFO][11:25:44]: [Client #99] Epoch: [3/5][10/16]	Loss: 0.438678
[INFO][11:25:44]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:25:44]: [Client #99] Woke up.
[INFO][11:25:44]: [Client #99] Epoch: [4/5][0/16]	Loss: 0.213757
[INFO][11:25:44]: [Client #99] Epoch: [4/5][10/16]	Loss: 0.574018
[INFO][11:25:44]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:25:44]: [Client #99] Woke up.
[INFO][11:25:44]: [Client #99] Epoch: [5/5][0/16]	Loss: 0.046603
[INFO][11:25:45]: [Client #99] Epoch: [5/5][10/16]	Loss: 0.112888
[INFO][11:25:45]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:25:45]: [Client #99] Woke up.
[INFO][11:25:45]: [Client #99] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_99_554860.pth.
[INFO][11:25:45]: [Client #99] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_99_554860.pth.
[INFO][11:25:45]: [Client #99] Model trained.
[INFO][11:25:45]: [Client #99] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:25:45]: [Server #554754] Received 0.26 MB of payload data from client #99 (simulated).
[INFO][11:26:10]: [Client #212] Woke up.
[INFO][11:26:10]: [Client #212] Epoch: [2/5][0/16]	Loss: 0.680442
[INFO][11:26:10]: [Client #212] Epoch: [2/5][10/16]	Loss: 0.614481
[INFO][11:26:10]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:26:37]: [Client #212] Woke up.
[INFO][11:26:37]: [Client #212] Epoch: [3/5][0/16]	Loss: 1.233370
[INFO][11:26:37]: [Client #212] Epoch: [3/5][10/16]	Loss: 0.303704
[INFO][11:26:37]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:27:03]: [Client #212] Woke up.
[INFO][11:27:03]: [Client #212] Epoch: [4/5][0/16]	Loss: 1.060475
[INFO][11:27:03]: [Client #212] Epoch: [4/5][10/16]	Loss: 0.899894
[INFO][11:27:03]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:27:30]: [Client #212] Woke up.
[INFO][11:27:30]: [Client #212] Epoch: [5/5][0/16]	Loss: 1.474045
[INFO][11:27:30]: [Client #212] Epoch: [5/5][10/16]	Loss: 0.341585
[INFO][11:27:30]: [Client #212] Going to sleep for 26.22 seconds.
[INFO][11:27:56]: [Client #212] Woke up.
[INFO][11:27:56]: [Client #212] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][11:27:57]: [Client #212] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_212_554853.pth.
[INFO][11:27:57]: [Client #212] Model trained.
[INFO][11:27:57]: [Client #212] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:27:57]: [Server #554754] Received 0.26 MB of payload data from client #212 (simulated).
[INFO][11:27:57]: [Server #554754] Selecting client #13 for training.
[INFO][11:27:57]: [Server #554754] Sending the current model to client #13 (simulated).
[INFO][11:27:57]: [Server #554754] Sending 0.26 MB of payload data to client #13 (simulated).
[INFO][11:27:57]: [Server #554754] Selecting client #366 for training.
[INFO][11:27:57]: [Server #554754] Sending the current model to client #366 (simulated).
[INFO][11:27:57]: [Server #554754] Sending 0.26 MB of payload data to client #366 (simulated).
[INFO][11:27:57]: [Client #13] Selected by the server.
[INFO][11:27:57]: [Client #13] Loading its data source...
[INFO][11:27:57]: Data source: FEMNIST
[INFO][11:27:57]: [Client #366] Selected by the server.
[INFO][11:27:57]: [Client #366] Loading its data source...
[INFO][11:27:57]: Data source: FEMNIST
[INFO][11:27:57]: [Client #366] Dataset size: 162
[INFO][11:27:57]: [Client #366] Sampler: all_inclusive
[INFO][11:27:57]: [Client #13] Dataset size: 144
[INFO][11:27:57]: [Client #13] Sampler: all_inclusive
[INFO][11:27:57]: [Client #366] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:27:57]: [Client #13] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:27:57]: [93m[1m[Client #366] Started training in communication round #33.[0m
[INFO][11:27:57]: [93m[1m[Client #13] Started training in communication round #33.[0m
[INFO][11:27:59]: [Client #366] Loading the dataset.
[INFO][11:27:59]: [Client #13] Loading the dataset.
[INFO][11:28:04]: [Client #366] Epoch: [1/5][0/17]	Loss: 0.073172
[INFO][11:28:04]: [Client #13] Epoch: [1/5][0/15]	Loss: 0.685730
[INFO][11:28:04]: [Client #366] Epoch: [1/5][10/17]	Loss: 0.116356
[INFO][11:28:05]: [Client #13] Epoch: [1/5][10/15]	Loss: 1.290080
[INFO][11:28:05]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][11:28:05]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][11:28:05]: [Client #13] Woke up.
[INFO][11:28:05]: [Client #13] Epoch: [2/5][0/15]	Loss: 0.511620
[INFO][11:28:05]: [Client #13] Epoch: [2/5][10/15]	Loss: 0.663422
[INFO][11:28:05]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][11:28:05]: [Client #13] Woke up.
[INFO][11:28:05]: [Client #13] Epoch: [3/5][0/15]	Loss: 0.387689
[INFO][11:28:05]: [Client #13] Epoch: [3/5][10/15]	Loss: 0.455382
[INFO][11:28:05]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][11:28:06]: [Client #13] Woke up.
[INFO][11:28:06]: [Client #13] Epoch: [4/5][0/15]	Loss: 0.473534
[INFO][11:28:06]: [Client #13] Epoch: [4/5][10/15]	Loss: 1.287562
[INFO][11:28:06]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][11:28:06]: [Client #13] Woke up.
[INFO][11:28:06]: [Client #13] Epoch: [5/5][0/15]	Loss: 0.382174
[INFO][11:28:06]: [Client #13] Epoch: [5/5][10/15]	Loss: 0.270392
[INFO][11:28:06]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][11:28:06]: [Client #366] Woke up.
[INFO][11:28:06]: [Client #366] Epoch: [2/5][0/17]	Loss: 0.371110
[INFO][11:28:06]: [Client #13] Woke up.
[INFO][11:28:06]: [Client #13] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554853.pth.
[INFO][11:28:06]: [Client #366] Epoch: [2/5][10/17]	Loss: 0.111850
[INFO][11:28:06]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][11:28:07]: [Client #13] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554853.pth.
[INFO][11:28:07]: [Client #13] Model trained.
[INFO][11:28:07]: [Client #13] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:07]: [Server #554754] Received 0.26 MB of payload data from client #13 (simulated).
[INFO][11:28:08]: [Client #366] Woke up.
[INFO][11:28:08]: [Client #366] Epoch: [3/5][0/17]	Loss: 0.222534
[INFO][11:28:08]: [Client #366] Epoch: [3/5][10/17]	Loss: 1.340220
[INFO][11:28:08]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][11:28:10]: [Client #366] Woke up.
[INFO][11:28:10]: [Client #366] Epoch: [4/5][0/17]	Loss: 0.881479
[INFO][11:28:10]: [Client #366] Epoch: [4/5][10/17]	Loss: 0.686068
[INFO][11:28:10]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][11:28:12]: [Client #366] Woke up.
[INFO][11:28:12]: [Client #366] Epoch: [5/5][0/17]	Loss: 0.496374
[INFO][11:28:12]: [Client #366] Epoch: [5/5][10/17]	Loss: 0.815162
[INFO][11:28:12]: [Client #366] Going to sleep for 1.75 seconds.
[INFO][11:28:14]: [Client #366] Woke up.
[INFO][11:28:14]: [Client #366] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_554860.pth.
[INFO][11:28:15]: [Client #366] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_366_554860.pth.
[INFO][11:28:15]: [Client #366] Model trained.
[INFO][11:28:15]: [Client #366] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:15]: [Server #554754] Received 0.26 MB of payload data from client #366 (simulated).
[INFO][11:28:15]: [Server #554754] Selecting client #364 for training.
[INFO][11:28:15]: [Server #554754] Sending the current model to client #364 (simulated).
[INFO][11:28:15]: [Server #554754] Sending 0.26 MB of payload data to client #364 (simulated).
[INFO][11:28:15]: [Server #554754] Selecting client #165 for training.
[INFO][11:28:15]: [Server #554754] Sending the current model to client #165 (simulated).
[INFO][11:28:15]: [Server #554754] Sending 0.26 MB of payload data to client #165 (simulated).
[INFO][11:28:15]: [Client #364] Selected by the server.
[INFO][11:28:15]: [Client #165] Selected by the server.
[INFO][11:28:15]: [Client #364] Loading its data source...
[INFO][11:28:15]: [Client #165] Loading its data source...
[INFO][11:28:15]: Data source: FEMNIST
[INFO][11:28:15]: Data source: FEMNIST
[INFO][11:28:15]: [Client #364] Dataset size: 147
[INFO][11:28:15]: [Client #364] Sampler: all_inclusive
[INFO][11:28:15]: [Client #165] Dataset size: 160
[INFO][11:28:15]: [Client #165] Sampler: all_inclusive
[INFO][11:28:15]: [Client #364] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:15]: [Client #165] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:15]: [93m[1m[Client #364] Started training in communication round #33.[0m
[INFO][11:28:15]: [93m[1m[Client #165] Started training in communication round #33.[0m
[INFO][11:28:17]: [Client #165] Loading the dataset.
[INFO][11:28:17]: [Client #364] Loading the dataset.
[INFO][11:28:22]: [Client #364] Epoch: [1/5][0/15]	Loss: 0.686796
[INFO][11:28:22]: [Client #165] Epoch: [1/5][0/16]	Loss: 0.788580
[INFO][11:28:22]: [Client #364] Epoch: [1/5][10/15]	Loss: 0.819313
[INFO][11:28:22]: [Client #364] Going to sleep for 1.18 seconds.
[INFO][11:28:22]: [Client #165] Epoch: [1/5][10/16]	Loss: 0.613498
[INFO][11:28:22]: [Client #165] Going to sleep for 0.19 seconds.
[INFO][11:28:22]: [Client #165] Woke up.
[INFO][11:28:22]: [Client #165] Epoch: [2/5][0/16]	Loss: 0.258887
[INFO][11:28:22]: [Client #165] Epoch: [2/5][10/16]	Loss: 0.453752
[INFO][11:28:23]: [Client #165] Going to sleep for 0.19 seconds.
[INFO][11:28:23]: [Client #165] Woke up.
[INFO][11:28:23]: [Client #165] Epoch: [3/5][0/16]	Loss: 0.489941
[INFO][11:28:23]: [Client #165] Epoch: [3/5][10/16]	Loss: 1.042651
[INFO][11:28:23]: [Client #165] Going to sleep for 0.19 seconds.
[INFO][11:28:23]: [Client #165] Woke up.
[INFO][11:28:23]: [Client #165] Epoch: [4/5][0/16]	Loss: 0.261997
[INFO][11:28:23]: [Client #165] Epoch: [4/5][10/16]	Loss: 0.249114
[INFO][11:28:23]: [Client #165] Going to sleep for 0.19 seconds.
[INFO][11:28:23]: [Client #364] Woke up.
[INFO][11:28:23]: [Client #364] Epoch: [2/5][0/15]	Loss: 0.180999
[INFO][11:28:23]: [Client #165] Woke up.
[INFO][11:28:23]: [Client #364] Epoch: [2/5][10/15]	Loss: 0.914663
[INFO][11:28:23]: [Client #165] Epoch: [5/5][0/16]	Loss: 0.095060
[INFO][11:28:23]: [Client #364] Going to sleep for 1.18 seconds.
[INFO][11:28:24]: [Client #165] Epoch: [5/5][10/16]	Loss: 0.146506
[INFO][11:28:24]: [Client #165] Going to sleep for 0.19 seconds.
[INFO][11:28:24]: [Client #165] Woke up.
[INFO][11:28:24]: [Client #165] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_165_554860.pth.
[INFO][11:28:24]: [Client #165] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_165_554860.pth.
[INFO][11:28:24]: [Client #165] Model trained.
[INFO][11:28:24]: [Client #165] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:24]: [Server #554754] Received 0.26 MB of payload data from client #165 (simulated).
[INFO][11:28:25]: [Client #364] Woke up.
[INFO][11:28:25]: [Client #364] Epoch: [3/5][0/15]	Loss: 0.113264
[INFO][11:28:25]: [Client #364] Epoch: [3/5][10/15]	Loss: 0.527318
[INFO][11:28:25]: [Client #364] Going to sleep for 1.18 seconds.
[INFO][11:28:26]: [Client #364] Woke up.
[INFO][11:28:26]: [Client #364] Epoch: [4/5][0/15]	Loss: 0.215324
[INFO][11:28:26]: [Client #364] Epoch: [4/5][10/15]	Loss: 0.211099
[INFO][11:28:26]: [Client #364] Going to sleep for 1.18 seconds.
[INFO][11:28:27]: [Client #364] Woke up.
[INFO][11:28:27]: [Client #364] Epoch: [5/5][0/15]	Loss: 0.565271
[INFO][11:28:27]: [Client #364] Epoch: [5/5][10/15]	Loss: 1.912489
[INFO][11:28:27]: [Client #364] Going to sleep for 1.18 seconds.
[INFO][11:28:29]: [Client #364] Woke up.
[INFO][11:28:29]: [Client #364] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_364_554853.pth.
[INFO][11:28:29]: [Client #364] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_364_554853.pth.
[INFO][11:28:29]: [Client #364] Model trained.
[INFO][11:28:29]: [Client #364] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:29]: [Server #554754] Received 0.26 MB of payload data from client #364 (simulated).
[INFO][11:28:29]: [Server #554754] Selecting client #423 for training.
[INFO][11:28:29]: [Server #554754] Sending the current model to client #423 (simulated).
[INFO][11:28:29]: [Server #554754] Sending 0.26 MB of payload data to client #423 (simulated).
[INFO][11:28:29]: [Server #554754] Selecting client #215 for training.
[INFO][11:28:29]: [Server #554754] Sending the current model to client #215 (simulated).
[INFO][11:28:29]: [Server #554754] Sending 0.26 MB of payload data to client #215 (simulated).
[INFO][11:28:29]: [Client #423] Selected by the server.
[INFO][11:28:29]: [Client #423] Loading its data source...
[INFO][11:28:29]: Data source: FEMNIST
[INFO][11:28:29]: [Client #215] Selected by the server.
[INFO][11:28:29]: [Client #215] Loading its data source...
[INFO][11:28:29]: Data source: FEMNIST
[INFO][11:28:29]: [Client #215] Dataset size: 161
[INFO][11:28:29]: [Client #215] Sampler: all_inclusive
[INFO][11:28:29]: [Client #215] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:29]: [93m[1m[Client #215] Started training in communication round #33.[0m
[INFO][11:28:29]: [Client #423] Dataset size: 165
[INFO][11:28:29]: [Client #423] Sampler: all_inclusive
[INFO][11:28:29]: [Client #423] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:29]: [93m[1m[Client #423] Started training in communication round #33.[0m
[INFO][11:28:31]: [Client #215] Loading the dataset.
[INFO][11:28:31]: [Client #423] Loading the dataset.
[INFO][11:28:37]: [Client #215] Epoch: [1/5][0/17]	Loss: 1.095472
[INFO][11:28:37]: [Client #423] Epoch: [1/5][0/17]	Loss: 0.816938
[INFO][11:28:37]: [Client #215] Epoch: [1/5][10/17]	Loss: 1.634038
[INFO][11:28:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:28:37]: [Client #423] Epoch: [1/5][10/17]	Loss: 0.611494
[INFO][11:28:37]: [Client #423] Going to sleep for 0.02 seconds.
[INFO][11:28:37]: [Client #423] Woke up.
[INFO][11:28:37]: [Client #423] Epoch: [2/5][0/17]	Loss: 1.178221
[INFO][11:28:37]: [Client #215] Woke up.
[INFO][11:28:37]: [Client #215] Epoch: [2/5][0/17]	Loss: 0.585056
[INFO][11:28:37]: [Client #423] Epoch: [2/5][10/17]	Loss: 0.302176
[INFO][11:28:37]: [Client #423] Going to sleep for 0.02 seconds.
[INFO][11:28:37]: [Client #215] Epoch: [2/5][10/17]	Loss: 1.261847
[INFO][11:28:37]: [Client #423] Woke up.
[INFO][11:28:37]: [Client #423] Epoch: [3/5][0/17]	Loss: 0.234752
[INFO][11:28:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:28:37]: [Client #423] Epoch: [3/5][10/17]	Loss: 0.619363
[INFO][11:28:37]: [Client #423] Going to sleep for 0.02 seconds.
[INFO][11:28:37]: [Client #423] Woke up.
[INFO][11:28:37]: [Client #423] Epoch: [4/5][0/17]	Loss: 0.950224
[INFO][11:28:37]: [Client #215] Woke up.
[INFO][11:28:37]: [Client #215] Epoch: [3/5][0/17]	Loss: 1.068620
[INFO][11:28:37]: [Client #423] Epoch: [4/5][10/17]	Loss: 0.676807
[INFO][11:28:37]: [Client #215] Epoch: [3/5][10/17]	Loss: 0.416643
[INFO][11:28:37]: [Client #423] Going to sleep for 0.02 seconds.
[INFO][11:28:37]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:28:37]: [Client #423] Woke up.
[INFO][11:28:37]: [Client #423] Epoch: [5/5][0/17]	Loss: 1.038123
[INFO][11:28:37]: [Client #423] Epoch: [5/5][10/17]	Loss: 0.140547
[INFO][11:28:37]: [Client #423] Going to sleep for 0.02 seconds.
[INFO][11:28:37]: [Client #215] Woke up.
[INFO][11:28:38]: [Client #423] Woke up.
[INFO][11:28:38]: [Client #215] Epoch: [4/5][0/17]	Loss: 0.347895
[INFO][11:28:38]: [Client #423] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_423_554853.pth.
[INFO][11:28:38]: [Client #215] Epoch: [4/5][10/17]	Loss: 0.265602
[INFO][11:28:38]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:28:38]: [Client #215] Woke up.
[INFO][11:28:38]: [Client #215] Epoch: [5/5][0/17]	Loss: 1.916175
[INFO][11:28:38]: [Client #215] Epoch: [5/5][10/17]	Loss: 0.750279
[INFO][11:28:38]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:28:38]: [Client #215] Woke up.
[INFO][11:28:38]: [Client #215] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][11:28:38]: [Client #423] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_423_554853.pth.
[INFO][11:28:38]: [Client #423] Model trained.
[INFO][11:28:38]: [Client #423] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:38]: [Server #554754] Received 0.26 MB of payload data from client #423 (simulated).
[INFO][11:28:39]: [Client #215] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][11:28:39]: [Client #215] Model trained.
[INFO][11:28:39]: [Client #215] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:39]: [Server #554754] Received 0.26 MB of payload data from client #215 (simulated).
[INFO][11:28:39]: [Server #554754] Selecting client #433 for training.
[INFO][11:28:39]: [Server #554754] Sending the current model to client #433 (simulated).
[INFO][11:28:39]: [Server #554754] Sending 0.26 MB of payload data to client #433 (simulated).
[INFO][11:28:39]: [Server #554754] Selecting client #330 for training.
[INFO][11:28:39]: [Server #554754] Sending the current model to client #330 (simulated).
[INFO][11:28:39]: [Server #554754] Sending 0.26 MB of payload data to client #330 (simulated).
[INFO][11:28:39]: [Client #330] Selected by the server.
[INFO][11:28:39]: [Client #330] Loading its data source...
[INFO][11:28:39]: Data source: FEMNIST
[INFO][11:28:39]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:28:39]: [Client #433] Selected by the server.
[INFO][11:28:39]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/330.zip.
[INFO][11:28:39]: [Client #433] Loading its data source...
[INFO][11:28:39]: Data source: FEMNIST
[INFO][11:28:39]: [Client #433] Dataset size: 240
[INFO][11:28:39]: [Client #433] Sampler: all_inclusive
[INFO][11:28:39]: [Client #433] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:39]: [93m[1m[Client #433] Started training in communication round #33.[0m

3.3%
6.5%
9.8%
13.0%
16.3%
19.5%
22.8%
26.0%
29.3%
32.5%
35.8%
39.0%
42.3%
45.5%
48.8%
52.0%
55.3%
58.6%
61.8%
65.1%
68.3%
71.6%
74.8%
78.1%
81.3%
84.6%
87.8%
91.1%
94.3%
97.6%
100.0%[INFO][11:28:39]: Decompressing the dataset downloaded.
[INFO][11:28:39]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/330.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:28:39]: [Client #330] Dataset size: 153
[INFO][11:28:39]: [Client #330] Sampler: all_inclusive
[INFO][11:28:39]: [Client #330] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:28:39]: [93m[1m[Client #330] Started training in communication round #33.[0m

[INFO][11:28:41]: [Client #433] Loading the dataset.
[INFO][11:28:41]: [Client #330] Loading the dataset.
[INFO][11:28:46]: [Client #433] Epoch: [1/5][0/24]	Loss: 1.688393
[INFO][11:28:46]: [Client #330] Epoch: [1/5][0/16]	Loss: 2.038965
[INFO][11:28:46]: [Client #433] Epoch: [1/5][10/24]	Loss: 0.352956
[INFO][11:28:46]: [Client #330] Epoch: [1/5][10/16]	Loss: 0.564364
[INFO][11:28:46]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][11:28:46]: [Client #433] Epoch: [1/5][20/24]	Loss: 1.356596
[INFO][11:28:46]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][11:28:47]: [Client #433] Woke up.
[INFO][11:28:47]: [Client #433] Epoch: [2/5][0/24]	Loss: 0.937190
[INFO][11:28:48]: [Client #433] Epoch: [2/5][10/24]	Loss: 0.826502
[INFO][11:28:48]: [Client #433] Epoch: [2/5][20/24]	Loss: 0.703290
[INFO][11:28:48]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][11:28:48]: [Client #330] Woke up.
[INFO][11:28:48]: [Client #330] Epoch: [2/5][0/16]	Loss: 0.413823
[INFO][11:28:48]: [Client #330] Epoch: [2/5][10/16]	Loss: 1.605041
[INFO][11:28:48]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][11:28:49]: [Client #433] Woke up.
[INFO][11:28:49]: [Client #433] Epoch: [3/5][0/24]	Loss: 0.868796
[INFO][11:28:49]: [Client #433] Epoch: [3/5][10/24]	Loss: 0.819738
[INFO][11:28:49]: [Client #433] Epoch: [3/5][20/24]	Loss: 0.614241
[INFO][11:28:49]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][11:28:50]: [Client #433] Woke up.
[INFO][11:28:50]: [Client #433] Epoch: [4/5][0/24]	Loss: 0.603795
[INFO][11:28:50]: [Client #433] Epoch: [4/5][10/24]	Loss: 0.870077
[INFO][11:28:50]: [Client #433] Epoch: [4/5][20/24]	Loss: 1.657260
[INFO][11:28:50]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][11:28:50]: [Client #330] Woke up.
[INFO][11:28:50]: [Client #330] Epoch: [3/5][0/16]	Loss: 1.000345
[INFO][11:28:50]: [Client #330] Epoch: [3/5][10/16]	Loss: 1.770344
[INFO][11:28:50]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][11:28:51]: [Client #433] Woke up.
[INFO][11:28:51]: [Client #433] Epoch: [5/5][0/24]	Loss: 0.706712
[INFO][11:28:51]: [Client #433] Epoch: [5/5][10/24]	Loss: 1.621794
[INFO][11:28:51]: [Client #433] Epoch: [5/5][20/24]	Loss: 1.342317
[INFO][11:28:51]: [Client #433] Going to sleep for 0.92 seconds.
[INFO][11:28:52]: [Client #433] Woke up.
[INFO][11:28:52]: [Client #433] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_554853.pth.
[INFO][11:28:52]: [Client #330] Woke up.
[INFO][11:28:52]: [Client #330] Epoch: [4/5][0/16]	Loss: 0.160781
[INFO][11:28:52]: [Client #330] Epoch: [4/5][10/16]	Loss: 1.799615
[INFO][11:28:52]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][11:28:53]: [Client #433] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_433_554853.pth.
[INFO][11:28:53]: [Client #433] Model trained.
[INFO][11:28:53]: [Client #433] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:53]: [Server #554754] Received 0.26 MB of payload data from client #433 (simulated).
[INFO][11:28:54]: [Client #330] Woke up.
[INFO][11:28:54]: [Client #330] Epoch: [5/5][0/16]	Loss: 0.372339
[INFO][11:28:54]: [Client #330] Epoch: [5/5][10/16]	Loss: 2.085625
[INFO][11:28:55]: [Client #330] Going to sleep for 1.89 seconds.
[INFO][11:28:56]: [Client #330] Woke up.
[INFO][11:28:56]: [Client #330] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_554860.pth.
[INFO][11:28:57]: [Client #330] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_330_554860.pth.
[INFO][11:28:57]: [Client #330] Model trained.
[INFO][11:28:57]: [Client #330] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:28:57]: [Server #554754] Received 0.26 MB of payload data from client #330 (simulated).
[INFO][11:28:57]: [Server #554754] Adding client #99 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #423 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #215 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #165 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #13 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #433 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #364 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #366 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #330 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #212 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][11:28:57]: [Server #554754] Aggregating 11 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11094671 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09850212 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11871485 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19564244 0.         0.         0.18982599 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11353262 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14355344
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11639036 0.         0.2420091
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11053465 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.17110076 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11094671 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09850212 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11871485 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.19564244 0.         0.         0.18982599 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11353262 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14355344
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11639036 0.         0.2420091
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11053465 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.17110076 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:29:41]: [Server #554754] Global model accuracy: 62.17%

[INFO][11:29:41]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_33.pth.
[INFO][11:29:41]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_33.pth.
[INFO][11:29:41]: [93m[1m
[Server #554754] Starting round 34/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.09514925 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.10318471 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.10344828 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.08844666 0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.002      0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.002      0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.10344828 0.002      0.002      0.002
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08844666 0.002      0.100894   0.08899945 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08095855 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08830846 0.002      0.05352394 0.002      0.08678828 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.002      0.09909326 0.09773124 0.002
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.002      0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9078e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9073e+00  4e-04  7e-09  7e-09
 5:  6.9078e+00  6.9076e+00  1e-04  2e-09  2e-09
 6:  6.9077e+00  6.9076e+00  1e-04  1e-09  1e-10
 7:  6.9077e+00  6.9076e+00  8e-05  9e-09  1e-09
 8:  6.9077e+00  6.9076e+00  4e-05  4e-08  5e-09
 9:  6.9077e+00  6.9076e+00  5e-06  2e-08  3e-09
Optimal solution found.
The calculated probability is:  [1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01757479e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01760025e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01718292e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01489023e-04
 1.01852367e-04 1.01852367e-04 1.01505961e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 9.49178304e-01 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01673174e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01743557e-04
 1.01852367e-04 1.01283516e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01728743e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01228626e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04
 1.01852367e-04 1.01852367e-04 1.01852367e-04 1.01852367e-04]
current clients pool:  [INFO][11:29:42]: [Server #554754] Selected clients: [299 315 479 295  99 215 169 496 190 497 259  86  38 185  62 318 207 466
  75 198]
[INFO][11:29:42]: [Server #554754] Selecting client #299 for training.
[INFO][11:29:42]: [Server #554754] Sending the current model to client #299 (simulated).
[INFO][11:29:42]: [Server #554754] Sending 0.26 MB of payload data to client #299 (simulated).
[INFO][11:29:42]: [Server #554754] Selecting client #315 for training.
[INFO][11:29:42]: [Server #554754] Sending the current model to client #315 (simulated).
[INFO][11:29:42]: [Server #554754] Sending 0.26 MB of payload data to client #315 (simulated).
[INFO][11:29:42]: [Client #299] Selected by the server.
[INFO][11:29:42]: [Client #299] Loading its data source...
[INFO][11:29:42]: Data source: FEMNIST
[INFO][11:29:42]: [Client #315] Selected by the server.
[INFO][11:29:42]: [Client #315] Loading its data source...
[INFO][11:29:42]: Data source: FEMNIST
[INFO][11:29:42]: [Client #299] Dataset size: 157
[INFO][11:29:42]: [Client #299] Sampler: all_inclusive
[INFO][11:29:42]: [Client #299] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:29:42]: [93m[1m[Client #299] Started training in communication round #34.[0m
[INFO][11:29:42]: [Client #315] Dataset size: 162
[INFO][11:29:42]: [Client #315] Sampler: all_inclusive
[INFO][11:29:42]: [Client #315] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:29:42]: [93m[1m[Client #315] Started training in communication round #34.[0m
[INFO][11:29:44]: [Client #299] Loading the dataset.
[INFO][11:29:44]: [Client #315] Loading the dataset.
[INFO][11:29:49]: [Client #315] Epoch: [1/5][0/17]	Loss: 0.666230
[INFO][11:29:49]: [Client #299] Epoch: [1/5][0/16]	Loss: 0.375324
[INFO][11:29:49]: [Client #315] Epoch: [1/5][10/17]	Loss: 1.992334
[INFO][11:29:49]: [Client #299] Epoch: [1/5][10/16]	Loss: 0.638564
[INFO][11:29:49]: [Client #315] Going to sleep for 0.24 seconds.
[INFO][11:29:49]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:29:50]: [Client #315] Woke up.
[INFO][11:29:50]: [Client #315] Epoch: [2/5][0/17]	Loss: 1.509856
[INFO][11:29:50]: [Client #315] Epoch: [2/5][10/17]	Loss: 1.718391
[INFO][11:29:50]: [Client #315] Going to sleep for 0.24 seconds.
[INFO][11:29:50]: [Client #315] Woke up.
[INFO][11:29:50]: [Client #315] Epoch: [3/5][0/17]	Loss: 1.937645
[INFO][11:29:50]: [Client #315] Epoch: [3/5][10/17]	Loss: 0.395364
[INFO][11:29:50]: [Client #315] Going to sleep for 0.24 seconds.
[INFO][11:29:50]: [Client #315] Woke up.
[INFO][11:29:50]: [Client #315] Epoch: [4/5][0/17]	Loss: 1.689309
[INFO][11:29:50]: [Client #315] Epoch: [4/5][10/17]	Loss: 0.435849
[INFO][11:29:51]: [Client #315] Going to sleep for 0.24 seconds.
[INFO][11:29:51]: [Client #315] Woke up.
[INFO][11:29:51]: [Client #315] Epoch: [5/5][0/17]	Loss: 0.805715
[INFO][11:29:51]: [Client #315] Epoch: [5/5][10/17]	Loss: 0.758569
[INFO][11:29:51]: [Client #315] Going to sleep for 0.24 seconds.
[INFO][11:29:51]: [Client #315] Woke up.
[INFO][11:29:51]: [Client #315] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_315_554860.pth.
[INFO][11:29:52]: [Client #315] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_315_554860.pth.
[INFO][11:29:52]: [Client #315] Model trained.
[INFO][11:29:52]: [Client #315] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:29:52]: [Server #554754] Received 0.26 MB of payload data from client #315 (simulated).
[INFO][11:30:47]: [Client #299] Woke up.
[INFO][11:30:47]: [Client #299] Epoch: [2/5][0/16]	Loss: 0.041426
[INFO][11:30:47]: [Client #299] Epoch: [2/5][10/16]	Loss: 0.278627
[INFO][11:30:47]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:31:44]: [Client #299] Woke up.
[INFO][11:31:44]: [Client #299] Epoch: [3/5][0/16]	Loss: 0.361061
[INFO][11:31:44]: [Client #299] Epoch: [3/5][10/16]	Loss: 0.867380
[INFO][11:31:44]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:32:42]: [Client #299] Woke up.
[INFO][11:32:42]: [Client #299] Epoch: [4/5][0/16]	Loss: 0.704399
[INFO][11:32:42]: [Client #299] Epoch: [4/5][10/16]	Loss: 0.078760
[INFO][11:32:42]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:33:39]: [Client #299] Woke up.
[INFO][11:33:39]: [Client #299] Epoch: [5/5][0/16]	Loss: 0.830602
[INFO][11:33:39]: [Client #299] Epoch: [5/5][10/16]	Loss: 0.791346
[INFO][11:33:39]: [Client #299] Going to sleep for 57.20 seconds.
[INFO][11:34:37]: [Client #299] Woke up.
[INFO][11:34:37]: [Client #299] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:34:37]: [Client #299] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_299_554853.pth.
[INFO][11:34:37]: [Client #299] Model trained.
[INFO][11:34:37]: [Client #299] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:34:37]: [Server #554754] Received 0.26 MB of payload data from client #299 (simulated).
[INFO][11:34:37]: [Server #554754] Selecting client #479 for training.
[INFO][11:34:37]: [Server #554754] Sending the current model to client #479 (simulated).
[INFO][11:34:37]: [Server #554754] Sending 0.26 MB of payload data to client #479 (simulated).
[INFO][11:34:37]: [Server #554754] Selecting client #295 for training.
[INFO][11:34:37]: [Server #554754] Sending the current model to client #295 (simulated).
[INFO][11:34:37]: [Server #554754] Sending 0.26 MB of payload data to client #295 (simulated).
[INFO][11:34:37]: [Client #479] Selected by the server.
[INFO][11:34:37]: [Client #479] Loading its data source...
[INFO][11:34:37]: Data source: FEMNIST
[INFO][11:34:37]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:34:37]: [Client #295] Selected by the server.
[INFO][11:34:37]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/479.zip.
[INFO][11:34:37]: [Client #295] Loading its data source...
[INFO][11:34:37]: Data source: FEMNIST
[INFO][11:34:38]: [Client #295] Dataset size: 142
[INFO][11:34:38]: [Client #295] Sampler: all_inclusive
[INFO][11:34:38]: [Client #295] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:38]: [93m[1m[Client #295] Started training in communication round #34.[0m

3.1%
6.3%
9.4%
12.5%
15.7%
18.8%
21.9%
25.0%
28.2%
31.3%
34.4%
37.6%
40.7%
43.8%
47.0%
50.1%
53.2%
56.3%
59.5%
62.6%
65.7%
68.9%
72.0%
75.1%
78.3%
81.4%
84.5%
87.6%
90.8%
93.9%
97.0%
100.0%[INFO][11:34:38]: Decompressing the dataset downloaded.
[INFO][11:34:38]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/479.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:34:38]: [Client #479] Dataset size: 158
[INFO][11:34:38]: [Client #479] Sampler: all_inclusive
[INFO][11:34:38]: [Client #479] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:38]: [93m[1m[Client #479] Started training in communication round #34.[0m

[INFO][11:34:39]: [Client #295] Loading the dataset.
[INFO][11:34:40]: [Client #479] Loading the dataset.
[INFO][11:34:45]: [Client #295] Epoch: [1/5][0/15]	Loss: 0.603117
[INFO][11:34:45]: [Client #479] Epoch: [1/5][0/16]	Loss: 0.892321
[INFO][11:34:45]: [Client #295] Epoch: [1/5][10/15]	Loss: 0.201786
[INFO][11:34:45]: [Client #479] Epoch: [1/5][10/16]	Loss: 0.410199
[INFO][11:34:45]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:34:45]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][11:34:45]: [Client #479] Woke up.
[INFO][11:34:45]: [Client #479] Epoch: [2/5][0/16]	Loss: 1.215967
[INFO][11:34:45]: [Client #479] Epoch: [2/5][10/16]	Loss: 0.699516
[INFO][11:34:45]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][11:34:45]: [Client #479] Woke up.
[INFO][11:34:45]: [Client #479] Epoch: [3/5][0/16]	Loss: 0.845154
[INFO][11:34:45]: [Client #479] Epoch: [3/5][10/16]	Loss: 0.626472
[INFO][11:34:45]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][11:34:45]: [Client #479] Woke up.
[INFO][11:34:45]: [Client #479] Epoch: [4/5][0/16]	Loss: 0.227252
[INFO][11:34:46]: [Client #479] Epoch: [4/5][10/16]	Loss: 0.322431
[INFO][11:34:46]: [Client #295] Woke up.
[INFO][11:34:46]: [Client #295] Epoch: [2/5][0/15]	Loss: 0.439495
[INFO][11:34:46]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][11:34:46]: [Client #479] Woke up.
[INFO][11:34:46]: [Client #479] Epoch: [5/5][0/16]	Loss: 0.140034
[INFO][11:34:46]: [Client #295] Epoch: [2/5][10/15]	Loss: 0.193719
[INFO][11:34:46]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:34:46]: [Client #479] Epoch: [5/5][10/16]	Loss: 0.489535
[INFO][11:34:46]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][11:34:46]: [Client #479] Woke up.
[INFO][11:34:46]: [Client #479] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_479_554853.pth.
[INFO][11:34:46]: [Client #295] Woke up.
[INFO][11:34:46]: [Client #295] Epoch: [3/5][0/15]	Loss: 1.094477
[INFO][11:34:46]: [Client #295] Epoch: [3/5][10/15]	Loss: 1.104956
[INFO][11:34:46]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:34:46]: [Client #479] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_479_554853.pth.
[INFO][11:34:46]: [Client #479] Model trained.
[INFO][11:34:46]: [Client #479] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:34:46]: [Server #554754] Received 0.26 MB of payload data from client #479 (simulated).
[INFO][11:34:47]: [Client #295] Woke up.
[INFO][11:34:47]: [Client #295] Epoch: [4/5][0/15]	Loss: 0.629155
[INFO][11:34:47]: [Client #295] Epoch: [4/5][10/15]	Loss: 1.219894
[INFO][11:34:47]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:34:48]: [Client #295] Woke up.
[INFO][11:34:48]: [Client #295] Epoch: [5/5][0/15]	Loss: 0.259512
[INFO][11:34:48]: [Client #295] Epoch: [5/5][10/15]	Loss: 0.271654
[INFO][11:34:48]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:34:48]: [Client #295] Woke up.
[INFO][11:34:48]: [Client #295] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:34:49]: [Client #295] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:34:49]: [Client #295] Model trained.
[INFO][11:34:49]: [Client #295] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:34:49]: [Server #554754] Received 0.26 MB of payload data from client #295 (simulated).
[INFO][11:34:49]: [Server #554754] Selecting client #99 for training.
[INFO][11:34:49]: [Server #554754] Sending the current model to client #99 (simulated).
[INFO][11:34:49]: [Server #554754] Sending 0.26 MB of payload data to client #99 (simulated).
[INFO][11:34:49]: [Server #554754] Selecting client #215 for training.
[INFO][11:34:49]: [Server #554754] Sending the current model to client #215 (simulated).
[INFO][11:34:49]: [Server #554754] Sending 0.26 MB of payload data to client #215 (simulated).
[INFO][11:34:49]: [Client #99] Selected by the server.
[INFO][11:34:49]: [Client #215] Selected by the server.
[INFO][11:34:49]: [Client #99] Loading its data source...
[INFO][11:34:49]: [Client #215] Loading its data source...
[INFO][11:34:49]: Data source: FEMNIST
[INFO][11:34:49]: Data source: FEMNIST
[INFO][11:34:49]: [Client #99] Dataset size: 160
[INFO][11:34:49]: [Client #99] Sampler: all_inclusive
[INFO][11:34:49]: [Client #215] Dataset size: 161
[INFO][11:34:49]: [Client #215] Sampler: all_inclusive
[INFO][11:34:49]: [Client #99] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:49]: [Client #215] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:49]: [93m[1m[Client #99] Started training in communication round #34.[0m
[INFO][11:34:49]: [93m[1m[Client #215] Started training in communication round #34.[0m
[INFO][11:34:51]: [Client #99] Loading the dataset.
[INFO][11:34:51]: [Client #215] Loading the dataset.
[INFO][11:34:56]: [Client #215] Epoch: [1/5][0/17]	Loss: 0.363494
[INFO][11:34:56]: [Client #99] Epoch: [1/5][0/16]	Loss: 0.843931
[INFO][11:34:57]: [Client #215] Epoch: [1/5][10/17]	Loss: 0.531151
[INFO][11:34:57]: [Client #99] Epoch: [1/5][10/16]	Loss: 0.522349
[INFO][11:34:57]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:34:57]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:34:57]: [Client #99] Woke up.
[INFO][11:34:57]: [Client #99] Epoch: [2/5][0/16]	Loss: 1.097853
[INFO][11:34:57]: [Client #99] Epoch: [2/5][10/16]	Loss: 0.272110
[INFO][11:34:57]: [Client #215] Woke up.
[INFO][11:34:57]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:34:57]: [Client #99] Woke up.
[INFO][11:34:57]: [Client #215] Epoch: [2/5][0/17]	Loss: 1.042791
[INFO][11:34:57]: [Client #99] Epoch: [3/5][0/16]	Loss: 0.194375
[INFO][11:34:57]: [Client #215] Epoch: [2/5][10/17]	Loss: 2.080144
[INFO][11:34:57]: [Client #99] Epoch: [3/5][10/16]	Loss: 0.622974
[INFO][11:34:57]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:34:57]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:34:57]: [Client #99] Woke up.
[INFO][11:34:57]: [Client #99] Epoch: [4/5][0/16]	Loss: 0.651151
[INFO][11:34:57]: [Client #99] Epoch: [4/5][10/16]	Loss: 0.277942
[INFO][11:34:57]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:34:57]: [Client #99] Woke up.
[INFO][11:34:57]: [Client #99] Epoch: [5/5][0/16]	Loss: 0.023034
[INFO][11:34:57]: [Client #215] Woke up.
[INFO][11:34:57]: [Client #215] Epoch: [3/5][0/17]	Loss: 0.845030
[INFO][11:34:57]: [Client #99] Epoch: [5/5][10/16]	Loss: 0.039844
[INFO][11:34:57]: [Client #215] Epoch: [3/5][10/17]	Loss: 0.586811
[INFO][11:34:57]: [Client #99] Going to sleep for 0.00 seconds.
[INFO][11:34:57]: [Client #99] Woke up.
[INFO][11:34:57]: [Client #99] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_99_554853.pth.
[INFO][11:34:57]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:34:57]: [Client #215] Woke up.
[INFO][11:34:57]: [Client #215] Epoch: [4/5][0/17]	Loss: 0.695528
[INFO][11:34:57]: [Client #215] Epoch: [4/5][10/17]	Loss: 1.102149
[INFO][11:34:57]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:34:58]: [Client #215] Woke up.
[INFO][11:34:58]: [Client #215] Epoch: [5/5][0/17]	Loss: 1.368495
[INFO][11:34:58]: [Client #215] Epoch: [5/5][10/17]	Loss: 1.101973
[INFO][11:34:58]: [Client #215] Going to sleep for 0.16 seconds.
[INFO][11:34:58]: [Client #99] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_99_554853.pth.
[INFO][11:34:58]: [Client #99] Model trained.
[INFO][11:34:58]: [Client #99] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:34:58]: [Server #554754] Received 0.26 MB of payload data from client #99 (simulated).
[INFO][11:34:58]: [Client #215] Woke up.
[INFO][11:34:58]: [Client #215] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][11:34:59]: [Client #215] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_215_554860.pth.
[INFO][11:34:59]: [Client #215] Model trained.
[INFO][11:34:59]: [Client #215] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:34:59]: [Server #554754] Received 0.26 MB of payload data from client #215 (simulated).
[INFO][11:34:59]: [Server #554754] Selecting client #169 for training.
[INFO][11:34:59]: [Server #554754] Sending the current model to client #169 (simulated).
[INFO][11:34:59]: [Server #554754] Sending 0.26 MB of payload data to client #169 (simulated).
[INFO][11:34:59]: [Server #554754] Selecting client #496 for training.
[INFO][11:34:59]: [Server #554754] Sending the current model to client #496 (simulated).
[INFO][11:34:59]: [Server #554754] Sending 0.26 MB of payload data to client #496 (simulated).
[INFO][11:34:59]: [Client #169] Selected by the server.
[INFO][11:34:59]: [Client #496] Selected by the server.
[INFO][11:34:59]: [Client #169] Loading its data source...
[INFO][11:34:59]: [Client #496] Loading its data source...
[INFO][11:34:59]: Data source: FEMNIST
[INFO][11:34:59]: Data source: FEMNIST
[INFO][11:34:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:34:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/496.zip.
[INFO][11:34:59]: [Client #169] Dataset size: 152
[INFO][11:34:59]: [Client #169] Sampler: all_inclusive
[INFO][11:34:59]: [Client #169] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:59]: [93m[1m[Client #169] Started training in communication round #34.[0m

2.5%
5.1%
7.6%
10.1%
12.6%
15.2%
17.7%
20.2%
22.7%
25.3%
27.8%
30.3%
32.8%
35.4%
37.9%
40.4%
42.9%
45.5%
48.0%
50.5%
53.0%
55.6%
58.1%
60.6%
63.1%
65.7%
68.2%
70.7%
73.3%
75.8%
78.3%
80.8%
83.4%
85.9%
88.4%
90.9%
93.5%
96.0%
98.5%
100.0%[INFO][11:34:59]: Decompressing the dataset downloaded.
[INFO][11:34:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/496.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:34:59]: [Client #496] Dataset size: 153
[INFO][11:34:59]: [Client #496] Sampler: all_inclusive
[INFO][11:34:59]: [Client #496] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:34:59]: [93m[1m[Client #496] Started training in communication round #34.[0m

[INFO][11:35:01]: [Client #169] Loading the dataset.
[INFO][11:35:01]: [Client #496] Loading the dataset.
[INFO][11:35:06]: [Client #169] Epoch: [1/5][0/16]	Loss: 0.497958
[INFO][11:35:06]: [Client #496] Epoch: [1/5][0/16]	Loss: 0.914459
[INFO][11:35:06]: [Client #169] Epoch: [1/5][10/16]	Loss: 0.537215
[INFO][11:35:06]: [Client #169] Going to sleep for 1.54 seconds.
[INFO][11:35:06]: [Client #496] Epoch: [1/5][10/16]	Loss: 1.154347
[INFO][11:35:06]: [Client #496] Going to sleep for 13.68 seconds.
[INFO][11:35:08]: [Client #169] Woke up.
[INFO][11:35:08]: [Client #169] Epoch: [2/5][0/16]	Loss: 0.736223
[INFO][11:35:08]: [Client #169] Epoch: [2/5][10/16]	Loss: 0.217881
[INFO][11:35:08]: [Client #169] Going to sleep for 1.54 seconds.
[INFO][11:35:09]: [Client #169] Woke up.
[INFO][11:35:09]: [Client #169] Epoch: [3/5][0/16]	Loss: 0.576900
[INFO][11:35:09]: [Client #169] Epoch: [3/5][10/16]	Loss: 0.446907
[INFO][11:35:10]: [Client #169] Going to sleep for 1.54 seconds.
[INFO][11:35:11]: [Client #169] Woke up.
[INFO][11:35:11]: [Client #169] Epoch: [4/5][0/16]	Loss: 0.017936
[INFO][11:35:11]: [Client #169] Epoch: [4/5][10/16]	Loss: 0.614699
[INFO][11:35:11]: [Client #169] Going to sleep for 1.54 seconds.
[INFO][11:35:13]: [Client #169] Woke up.
[INFO][11:35:13]: [Client #169] Epoch: [5/5][0/16]	Loss: 0.532637
[INFO][11:35:13]: [Client #169] Epoch: [5/5][10/16]	Loss: 0.229689
[INFO][11:35:13]: [Client #169] Going to sleep for 1.54 seconds.
[INFO][11:35:14]: [Client #169] Woke up.
[INFO][11:35:14]: [Client #169] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_169_554853.pth.
[INFO][11:35:15]: [Client #169] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_169_554853.pth.
[INFO][11:35:15]: [Client #169] Model trained.
[INFO][11:35:15]: [Client #169] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:35:15]: [Server #554754] Received 0.26 MB of payload data from client #169 (simulated).
[INFO][11:35:20]: [Client #496] Woke up.
[INFO][11:35:20]: [Client #496] Epoch: [2/5][0/16]	Loss: 0.210613
[INFO][11:35:20]: [Client #496] Epoch: [2/5][10/16]	Loss: 0.218413
[INFO][11:35:20]: [Client #496] Going to sleep for 13.68 seconds.
[INFO][11:35:34]: [Client #496] Woke up.
[INFO][11:35:34]: [Client #496] Epoch: [3/5][0/16]	Loss: 0.304161
[INFO][11:35:34]: [Client #496] Epoch: [3/5][10/16]	Loss: 0.257023
[INFO][11:35:34]: [Client #496] Going to sleep for 13.68 seconds.
[INFO][11:35:48]: [Client #496] Woke up.
[INFO][11:35:48]: [Client #496] Epoch: [4/5][0/16]	Loss: 1.040295
[INFO][11:35:48]: [Client #496] Epoch: [4/5][10/16]	Loss: 0.288557
[INFO][11:35:48]: [Client #496] Going to sleep for 13.68 seconds.
[INFO][11:36:01]: [Client #496] Woke up.
[INFO][11:36:01]: [Client #496] Epoch: [5/5][0/16]	Loss: 0.022585
[INFO][11:36:02]: [Client #496] Epoch: [5/5][10/16]	Loss: 0.924983
[INFO][11:36:02]: [Client #496] Going to sleep for 13.68 seconds.
[INFO][11:36:15]: [Client #496] Woke up.
[INFO][11:36:15]: [Client #496] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_496_554860.pth.
[INFO][11:36:16]: [Client #496] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_496_554860.pth.
[INFO][11:36:16]: [Client #496] Model trained.
[INFO][11:36:16]: [Client #496] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:36:16]: [Server #554754] Received 0.26 MB of payload data from client #496 (simulated).
[INFO][11:36:16]: [Server #554754] Selecting client #190 for training.
[INFO][11:36:16]: [Server #554754] Sending the current model to client #190 (simulated).
[INFO][11:36:16]: [Server #554754] Sending 0.26 MB of payload data to client #190 (simulated).
[INFO][11:36:16]: [Server #554754] Selecting client #497 for training.
[INFO][11:36:16]: [Server #554754] Sending the current model to client #497 (simulated).
[INFO][11:36:16]: [Server #554754] Sending 0.26 MB of payload data to client #497 (simulated).
[INFO][11:36:16]: [Client #190] Selected by the server.
[INFO][11:36:16]: [Client #497] Selected by the server.
[INFO][11:36:16]: [Client #190] Loading its data source...
[INFO][11:36:16]: [Client #497] Loading its data source...
[INFO][11:36:16]: Data source: FEMNIST
[INFO][11:36:16]: Data source: FEMNIST
[INFO][11:36:16]: [Client #497] Dataset size: 157
[INFO][11:36:16]: [Client #497] Sampler: all_inclusive
[INFO][11:36:16]: [Client #497] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:36:16]: [93m[1m[Client #497] Started training in communication round #34.[0m
[INFO][11:36:16]: [Client #190] Dataset size: 160
[INFO][11:36:16]: [Client #190] Sampler: all_inclusive
[INFO][11:36:16]: [Client #190] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:36:16]: [93m[1m[Client #190] Started training in communication round #34.[0m
[INFO][11:36:18]: [Client #497] Loading the dataset.
[INFO][11:36:18]: [Client #190] Loading the dataset.
[INFO][11:36:23]: [Client #497] Epoch: [1/5][0/16]	Loss: 1.172541
[INFO][11:36:23]: [Client #190] Epoch: [1/5][0/16]	Loss: 1.016132
[INFO][11:36:23]: [Client #497] Epoch: [1/5][10/16]	Loss: 1.078457
[INFO][11:36:24]: [Client #497] Going to sleep for 14.84 seconds.
[INFO][11:36:24]: [Client #190] Epoch: [1/5][10/16]	Loss: 1.158605
[INFO][11:36:24]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:36:36]: [Client #190] Woke up.
[INFO][11:36:36]: [Client #190] Epoch: [2/5][0/16]	Loss: 0.907780
[INFO][11:36:36]: [Client #190] Epoch: [2/5][10/16]	Loss: 0.471205
[INFO][11:36:36]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:36:38]: [Client #497] Woke up.
[INFO][11:36:38]: [Client #497] Epoch: [2/5][0/16]	Loss: 0.481092
[INFO][11:36:38]: [Client #497] Epoch: [2/5][10/16]	Loss: 0.892196
[INFO][11:36:39]: [Client #497] Going to sleep for 14.84 seconds.
[INFO][11:36:48]: [Client #190] Woke up.
[INFO][11:36:48]: [Client #190] Epoch: [3/5][0/16]	Loss: 0.544755
[INFO][11:36:49]: [Client #190] Epoch: [3/5][10/16]	Loss: 0.628859
[INFO][11:36:49]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:36:53]: [Client #497] Woke up.
[INFO][11:36:53]: [Client #497] Epoch: [3/5][0/16]	Loss: 0.260882
[INFO][11:36:53]: [Client #497] Epoch: [3/5][10/16]	Loss: 0.305436
[INFO][11:36:54]: [Client #497] Going to sleep for 14.84 seconds.
[INFO][11:37:01]: [Client #190] Woke up.
[INFO][11:37:01]: [Client #190] Epoch: [4/5][0/16]	Loss: 1.122111
[INFO][11:37:01]: [Client #190] Epoch: [4/5][10/16]	Loss: 0.914137
[INFO][11:37:01]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:37:08]: [Client #497] Woke up.
[INFO][11:37:08]: [Client #497] Epoch: [4/5][0/16]	Loss: 0.212886
[INFO][11:37:08]: [Client #497] Epoch: [4/5][10/16]	Loss: 0.479928
[INFO][11:37:09]: [Client #497] Going to sleep for 14.84 seconds.
[INFO][11:37:13]: [Client #190] Woke up.
[INFO][11:37:13]: [Client #190] Epoch: [5/5][0/16]	Loss: 0.689141
[INFO][11:37:13]: [Client #190] Epoch: [5/5][10/16]	Loss: 0.693213
[INFO][11:37:13]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:37:23]: [Client #497] Woke up.
[INFO][11:37:23]: [Client #497] Epoch: [5/5][0/16]	Loss: 0.291399
[INFO][11:37:23]: [Client #497] Epoch: [5/5][10/16]	Loss: 0.151426
[INFO][11:37:24]: [Client #497] Going to sleep for 14.84 seconds.
[INFO][11:37:26]: [Client #190] Woke up.
[INFO][11:37:26]: [Client #190] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_554853.pth.
[INFO][11:37:26]: [Client #190] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_554853.pth.
[INFO][11:37:26]: [Client #190] Model trained.
[INFO][11:37:26]: [Client #190] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:37:26]: [Server #554754] Received 0.26 MB of payload data from client #190 (simulated).
[INFO][11:37:38]: [Client #497] Woke up.
[INFO][11:37:38]: [Client #497] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_497_554860.pth.
[INFO][11:37:39]: [Client #497] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_497_554860.pth.
[INFO][11:37:39]: [Client #497] Model trained.
[INFO][11:37:39]: [Client #497] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:37:39]: [Server #554754] Received 0.26 MB of payload data from client #497 (simulated).
[INFO][11:37:39]: [Server #554754] Selecting client #259 for training.
[INFO][11:37:39]: [Server #554754] Sending the current model to client #259 (simulated).
[INFO][11:37:39]: [Server #554754] Sending 0.26 MB of payload data to client #259 (simulated).
[INFO][11:37:39]: [Server #554754] Selecting client #86 for training.
[INFO][11:37:39]: [Server #554754] Sending the current model to client #86 (simulated).
[INFO][11:37:39]: [Server #554754] Sending 0.26 MB of payload data to client #86 (simulated).
[INFO][11:37:39]: [Client #86] Selected by the server.
[INFO][11:37:39]: [Client #259] Selected by the server.
[INFO][11:37:39]: [Client #86] Loading its data source...
[INFO][11:37:39]: [Client #259] Loading its data source...
[INFO][11:37:39]: Data source: FEMNIST
[INFO][11:37:39]: Data source: FEMNIST
[INFO][11:37:39]: [Client #259] Dataset size: 125
[INFO][11:37:39]: [Client #259] Sampler: all_inclusive
[INFO][11:37:39]: [Client #86] Dataset size: 158
[INFO][11:37:39]: [Client #86] Sampler: all_inclusive
[INFO][11:37:39]: [Client #259] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:37:39]: [Client #86] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:37:39]: [93m[1m[Client #259] Started training in communication round #34.[0m
[INFO][11:37:39]: [93m[1m[Client #86] Started training in communication round #34.[0m
[INFO][11:37:41]: [Client #259] Loading the dataset.
[INFO][11:37:41]: [Client #86] Loading the dataset.
[INFO][11:37:47]: [Client #259] Epoch: [1/5][0/13]	Loss: 2.340397
[INFO][11:37:47]: [Client #86] Epoch: [1/5][0/16]	Loss: 1.188758
[INFO][11:37:47]: [Client #259] Epoch: [1/5][10/13]	Loss: 1.345410
[INFO][11:37:47]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][11:37:47]: [Client #86] Epoch: [1/5][10/16]	Loss: 1.190277
[INFO][11:37:47]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][11:37:47]: [Client #259] Woke up.
[INFO][11:37:47]: [Client #259] Epoch: [2/5][0/13]	Loss: 0.606724
[INFO][11:37:47]: [Client #259] Epoch: [2/5][10/13]	Loss: 0.585893
[INFO][11:37:47]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][11:37:48]: [Client #259] Woke up.
[INFO][11:37:48]: [Client #259] Epoch: [3/5][0/13]	Loss: 0.276647
[INFO][11:37:48]: [Client #259] Epoch: [3/5][10/13]	Loss: 1.297521
[INFO][11:37:48]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][11:37:48]: [Client #259] Woke up.
[INFO][11:37:48]: [Client #259] Epoch: [4/5][0/13]	Loss: 1.017326
[INFO][11:37:48]: [Client #259] Epoch: [4/5][10/13]	Loss: 0.749628
[INFO][11:37:48]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][11:37:49]: [Client #259] Woke up.
[INFO][11:37:49]: [Client #259] Epoch: [5/5][0/13]	Loss: 0.497705
[INFO][11:37:49]: [Client #259] Epoch: [5/5][10/13]	Loss: 3.088219
[INFO][11:37:49]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][11:37:49]: [Client #259] Woke up.
[INFO][11:37:49]: [Client #259] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][11:37:50]: [Client #259] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554853.pth.
[INFO][11:37:50]: [Client #259] Model trained.
[INFO][11:37:50]: [Client #259] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:37:50]: [Server #554754] Received 0.26 MB of payload data from client #259 (simulated).
[INFO][11:37:55]: [Client #86] Woke up.
[INFO][11:37:55]: [Client #86] Epoch: [2/5][0/16]	Loss: 0.196319
[INFO][11:37:56]: [Client #86] Epoch: [2/5][10/16]	Loss: 0.233250
[INFO][11:37:56]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][11:38:04]: [Client #86] Woke up.
[INFO][11:38:04]: [Client #86] Epoch: [3/5][0/16]	Loss: 1.118389
[INFO][11:38:04]: [Client #86] Epoch: [3/5][10/16]	Loss: 1.323758
[INFO][11:38:04]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][11:38:13]: [Client #86] Woke up.
[INFO][11:38:13]: [Client #86] Epoch: [4/5][0/16]	Loss: 0.447685
[INFO][11:38:13]: [Client #86] Epoch: [4/5][10/16]	Loss: 0.923409
[INFO][11:38:13]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][11:38:22]: [Client #86] Woke up.
[INFO][11:38:22]: [Client #86] Epoch: [5/5][0/16]	Loss: 1.027548
[INFO][11:38:22]: [Client #86] Epoch: [5/5][10/16]	Loss: 0.307731
[INFO][11:38:22]: [Client #86] Going to sleep for 8.60 seconds.
[INFO][11:38:30]: [Client #86] Woke up.
[INFO][11:38:31]: [Client #86] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_86_554860.pth.
[INFO][11:38:31]: [Client #86] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_86_554860.pth.
[INFO][11:38:31]: [Client #86] Model trained.
[INFO][11:38:31]: [Client #86] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:38:31]: [Server #554754] Received 0.26 MB of payload data from client #86 (simulated).
[INFO][11:38:31]: [Server #554754] Selecting client #38 for training.
[INFO][11:38:31]: [Server #554754] Sending the current model to client #38 (simulated).
[INFO][11:38:31]: [Server #554754] Sending 0.26 MB of payload data to client #38 (simulated).
[INFO][11:38:31]: [Server #554754] Selecting client #185 for training.
[INFO][11:38:31]: [Server #554754] Sending the current model to client #185 (simulated).
[INFO][11:38:31]: [Server #554754] Sending 0.26 MB of payload data to client #185 (simulated).
[INFO][11:38:31]: [Client #185] Selected by the server.
[INFO][11:38:31]: [Client #38] Selected by the server.
[INFO][11:38:31]: [Client #185] Loading its data source...
[INFO][11:38:31]: [Client #38] Loading its data source...
[INFO][11:38:31]: Data source: FEMNIST
[INFO][11:38:31]: Data source: FEMNIST
[INFO][11:38:31]: [Client #38] Dataset size: 162
[INFO][11:38:31]: [Client #38] Sampler: all_inclusive
[INFO][11:38:31]: [Client #38] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:38:31]: [93m[1m[Client #38] Started training in communication round #34.[0m
[INFO][11:38:31]: [Client #185] Dataset size: 156
[INFO][11:38:31]: [Client #185] Sampler: all_inclusive
[INFO][11:38:31]: [Client #185] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:38:31]: [93m[1m[Client #185] Started training in communication round #34.[0m
[INFO][11:38:33]: [Client #185] Loading the dataset.
[INFO][11:38:33]: [Client #38] Loading the dataset.
[INFO][11:38:39]: [Client #38] Epoch: [1/5][0/17]	Loss: 1.621059
[INFO][11:38:39]: [Client #185] Epoch: [1/5][0/16]	Loss: 0.669666
[INFO][11:38:39]: [Client #38] Epoch: [1/5][10/17]	Loss: 0.632418
[INFO][11:38:39]: [Client #185] Epoch: [1/5][10/16]	Loss: 0.688452
[INFO][11:38:39]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][11:38:39]: [Client #185] Going to sleep for 0.35 seconds.
[INFO][11:38:39]: [Client #185] Woke up.
[INFO][11:38:39]: [Client #185] Epoch: [2/5][0/16]	Loss: 0.546843
[INFO][11:38:39]: [Client #185] Epoch: [2/5][10/16]	Loss: 0.829612
[INFO][11:38:39]: [Client #185] Going to sleep for 0.35 seconds.
[INFO][11:38:40]: [Client #185] Woke up.
[INFO][11:38:40]: [Client #185] Epoch: [3/5][0/16]	Loss: 1.614239
[INFO][11:38:40]: [Client #185] Epoch: [3/5][10/16]	Loss: 1.083410
[INFO][11:38:40]: [Client #185] Going to sleep for 0.35 seconds.
[INFO][11:38:40]: [Client #185] Woke up.
[INFO][11:38:40]: [Client #185] Epoch: [4/5][0/16]	Loss: 0.445705
[INFO][11:38:40]: [Client #185] Epoch: [4/5][10/16]	Loss: 0.490186
[INFO][11:38:40]: [Client #185] Going to sleep for 0.35 seconds.
[INFO][11:38:41]: [Client #185] Woke up.
[INFO][11:38:41]: [Client #185] Epoch: [5/5][0/16]	Loss: 0.130439
[INFO][11:38:41]: [Client #185] Epoch: [5/5][10/16]	Loss: 0.713835
[INFO][11:38:41]: [Client #185] Going to sleep for 0.35 seconds.
[INFO][11:38:41]: [Client #185] Woke up.
[INFO][11:38:41]: [Client #185] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_185_554860.pth.
[INFO][11:38:42]: [Client #185] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_185_554860.pth.
[INFO][11:38:42]: [Client #185] Model trained.
[INFO][11:38:42]: [Client #185] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:38:42]: [Server #554754] Received 0.26 MB of payload data from client #185 (simulated).
[INFO][11:38:44]: [Client #38] Woke up.
[INFO][11:38:44]: [Client #38] Epoch: [2/5][0/17]	Loss: 0.354424
[INFO][11:38:44]: [Client #38] Epoch: [2/5][10/17]	Loss: 0.796568
[INFO][11:38:44]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][11:38:49]: [Client #38] Woke up.
[INFO][11:38:49]: [Client #38] Epoch: [3/5][0/17]	Loss: 0.381800
[INFO][11:38:49]: [Client #38] Epoch: [3/5][10/17]	Loss: 0.286247
[INFO][11:38:49]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][11:38:54]: [Client #38] Woke up.
[INFO][11:38:54]: [Client #38] Epoch: [4/5][0/17]	Loss: 0.725036
[INFO][11:38:54]: [Client #38] Epoch: [4/5][10/17]	Loss: 1.200500
[INFO][11:38:54]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][11:38:59]: [Client #38] Woke up.
[INFO][11:38:59]: [Client #38] Epoch: [5/5][0/17]	Loss: 0.216676
[INFO][11:39:00]: [Client #38] Epoch: [5/5][10/17]	Loss: 0.255282
[INFO][11:39:00]: [Client #38] Going to sleep for 5.05 seconds.
[INFO][11:39:05]: [Client #38] Woke up.
[INFO][11:39:05]: [Client #38] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_554853.pth.
[INFO][11:39:05]: [Client #38] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_38_554853.pth.
[INFO][11:39:05]: [Client #38] Model trained.
[INFO][11:39:05]: [Client #38] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:05]: [Server #554754] Received 0.26 MB of payload data from client #38 (simulated).
[INFO][11:39:05]: [Server #554754] Selecting client #62 for training.
[INFO][11:39:05]: [Server #554754] Sending the current model to client #62 (simulated).
[INFO][11:39:05]: [Server #554754] Sending 0.26 MB of payload data to client #62 (simulated).
[INFO][11:39:05]: [Server #554754] Selecting client #318 for training.
[INFO][11:39:05]: [Server #554754] Sending the current model to client #318 (simulated).
[INFO][11:39:05]: [Server #554754] Sending 0.26 MB of payload data to client #318 (simulated).
[INFO][11:39:05]: [Client #62] Selected by the server.
[INFO][11:39:05]: [Client #62] Loading its data source...
[INFO][11:39:05]: Data source: FEMNIST
[INFO][11:39:05]: [Client #318] Selected by the server.
[INFO][11:39:05]: [Client #318] Loading its data source...
[INFO][11:39:05]: Data source: FEMNIST
[INFO][11:39:05]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:39:05]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/318.zip.
[INFO][11:39:05]: [Client #62] Dataset size: 156
[INFO][11:39:05]: [Client #62] Sampler: all_inclusive
[INFO][11:39:05]: [Client #62] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:05]: [93m[1m[Client #62] Started training in communication round #34.[0m

2.7%
5.5%
8.2%
11.0%
13.7%
16.5%
19.2%
22.0%
24.7%
27.5%
30.2%
33.0%
35.7%
38.5%
41.2%
44.0%
46.7%
49.4%
52.2%
54.9%
57.7%
60.4%
63.2%
65.9%
68.7%
71.4%
74.2%
76.9%
79.7%
82.4%
85.2%
87.9%
90.7%
93.4%
96.1%
98.9%
100.0%[INFO][11:39:06]: Decompressing the dataset downloaded.
[INFO][11:39:06]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/318.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:39:06]: [Client #318] Dataset size: 149
[INFO][11:39:06]: [Client #318] Sampler: all_inclusive
[INFO][11:39:06]: [Client #318] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:06]: [93m[1m[Client #318] Started training in communication round #34.[0m

[INFO][11:39:07]: [Client #62] Loading the dataset.
[INFO][11:39:07]: [Client #318] Loading the dataset.
[INFO][11:39:13]: [Client #62] Epoch: [1/5][0/16]	Loss: 0.718107
[INFO][11:39:13]: [Client #62] Epoch: [1/5][10/16]	Loss: 0.995647
[INFO][11:39:13]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][11:39:13]: [Client #318] Epoch: [1/5][0/15]	Loss: 0.585182
[INFO][11:39:13]: [Client #318] Epoch: [1/5][10/15]	Loss: 0.986812
[INFO][11:39:13]: [Client #318] Going to sleep for 0.26 seconds.
[INFO][11:39:13]: [Client #318] Woke up.
[INFO][11:39:13]: [Client #318] Epoch: [2/5][0/15]	Loss: 1.105000
[INFO][11:39:13]: [Client #318] Epoch: [2/5][10/15]	Loss: 0.969468
[INFO][11:39:13]: [Client #318] Going to sleep for 0.26 seconds.
[INFO][11:39:14]: [Client #62] Woke up.
[INFO][11:39:14]: [Client #62] Epoch: [2/5][0/16]	Loss: 0.496464
[INFO][11:39:14]: [Client #318] Woke up.
[INFO][11:39:14]: [Client #62] Epoch: [2/5][10/16]	Loss: 1.300410
[INFO][11:39:14]: [Client #318] Epoch: [3/5][0/15]	Loss: 1.276939
[INFO][11:39:14]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][11:39:14]: [Client #318] Epoch: [3/5][10/15]	Loss: 0.460412
[INFO][11:39:14]: [Client #318] Going to sleep for 0.26 seconds.
[INFO][11:39:14]: [Client #318] Woke up.
[INFO][11:39:14]: [Client #318] Epoch: [4/5][0/15]	Loss: 0.189878
[INFO][11:39:14]: [Client #318] Epoch: [4/5][10/15]	Loss: 0.766841
[INFO][11:39:14]: [Client #318] Going to sleep for 0.26 seconds.
[INFO][11:39:14]: [Client #62] Woke up.
[INFO][11:39:14]: [Client #62] Epoch: [3/5][0/16]	Loss: 0.692265
[INFO][11:39:14]: [Client #318] Woke up.
[INFO][11:39:14]: [Client #318] Epoch: [5/5][0/15]	Loss: 0.492162
[INFO][11:39:14]: [Client #62] Epoch: [3/5][10/16]	Loss: 0.917247
[INFO][11:39:15]: [Client #318] Epoch: [5/5][10/15]	Loss: 0.490438
[INFO][11:39:15]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][11:39:15]: [Client #318] Going to sleep for 0.26 seconds.
[INFO][11:39:15]: [Client #318] Woke up.
[INFO][11:39:15]: [Client #318] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_318_554860.pth.
[INFO][11:39:15]: [Client #62] Woke up.
[INFO][11:39:15]: [Client #62] Epoch: [4/5][0/16]	Loss: 0.396595
[INFO][11:39:15]: [Client #62] Epoch: [4/5][10/16]	Loss: 1.399676
[INFO][11:39:15]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][11:39:15]: [Client #318] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_318_554860.pth.
[INFO][11:39:15]: [Client #318] Model trained.
[INFO][11:39:15]: [Client #318] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:15]: [Server #554754] Received 0.26 MB of payload data from client #318 (simulated).
[INFO][11:39:16]: [Client #62] Woke up.
[INFO][11:39:16]: [Client #62] Epoch: [5/5][0/16]	Loss: 0.990241
[INFO][11:39:16]: [Client #62] Epoch: [5/5][10/16]	Loss: 0.268375
[INFO][11:39:16]: [Client #62] Going to sleep for 0.71 seconds.
[INFO][11:39:17]: [Client #62] Woke up.
[INFO][11:39:17]: [Client #62] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_62_554853.pth.
[INFO][11:39:18]: [Client #62] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_62_554853.pth.
[INFO][11:39:18]: [Client #62] Model trained.
[INFO][11:39:18]: [Client #62] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:18]: [Server #554754] Received 0.26 MB of payload data from client #62 (simulated).
[INFO][11:39:18]: [Server #554754] Selecting client #207 for training.
[INFO][11:39:18]: [Server #554754] Sending the current model to client #207 (simulated).
[INFO][11:39:18]: [Server #554754] Sending 0.26 MB of payload data to client #207 (simulated).
[INFO][11:39:18]: [Server #554754] Selecting client #466 for training.
[INFO][11:39:18]: [Server #554754] Sending the current model to client #466 (simulated).
[INFO][11:39:18]: [Server #554754] Sending 0.26 MB of payload data to client #466 (simulated).
[INFO][11:39:18]: [Client #207] Selected by the server.
[INFO][11:39:18]: [Client #207] Loading its data source...
[INFO][11:39:18]: Data source: FEMNIST
[INFO][11:39:18]: [Client #466] Selected by the server.
[INFO][11:39:18]: [Client #466] Loading its data source...
[INFO][11:39:18]: Data source: FEMNIST
[INFO][11:39:18]: [Client #207] Dataset size: 162
[INFO][11:39:18]: [Client #207] Sampler: all_inclusive
[INFO][11:39:18]: [Client #466] Dataset size: 162
[INFO][11:39:18]: [Client #466] Sampler: all_inclusive
[INFO][11:39:18]: [Client #207] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:18]: [Client #466] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:18]: [93m[1m[Client #207] Started training in communication round #34.[0m
[INFO][11:39:18]: [93m[1m[Client #466] Started training in communication round #34.[0m
[INFO][11:39:19]: [Client #466] Loading the dataset.
[INFO][11:39:20]: [Client #207] Loading the dataset.
[INFO][11:39:25]: [Client #466] Epoch: [1/5][0/17]	Loss: 0.947516
[INFO][11:39:25]: [Client #207] Epoch: [1/5][0/17]	Loss: 0.920588
[INFO][11:39:25]: [Client #466] Epoch: [1/5][10/17]	Loss: 2.454732
[INFO][11:39:25]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:39:25]: [Client #207] Epoch: [1/5][10/17]	Loss: 0.724785
[INFO][11:39:25]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:39:26]: [Client #466] Woke up.
[INFO][11:39:26]: [Client #466] Epoch: [2/5][0/17]	Loss: 0.408526
[INFO][11:39:26]: [Client #466] Epoch: [2/5][10/17]	Loss: 0.326192
[INFO][11:39:26]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:39:26]: [Client #466] Woke up.
[INFO][11:39:26]: [Client #466] Epoch: [3/5][0/17]	Loss: 0.375679
[INFO][11:39:26]: [Client #466] Epoch: [3/5][10/17]	Loss: 0.830694
[INFO][11:39:26]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:39:27]: [Client #207] Woke up.
[INFO][11:39:27]: [Client #207] Epoch: [2/5][0/17]	Loss: 0.508122
[INFO][11:39:27]: [Client #466] Woke up.
[INFO][11:39:27]: [Client #466] Epoch: [4/5][0/17]	Loss: 0.392185
[INFO][11:39:27]: [Client #207] Epoch: [2/5][10/17]	Loss: 0.267028
[INFO][11:39:27]: [Client #466] Epoch: [4/5][10/17]	Loss: 0.793419
[INFO][11:39:27]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:39:27]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:39:27]: [Client #466] Woke up.
[INFO][11:39:27]: [Client #466] Epoch: [5/5][0/17]	Loss: 0.795656
[INFO][11:39:27]: [Client #466] Epoch: [5/5][10/17]	Loss: 1.177457
[INFO][11:39:28]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:39:28]: [Client #466] Woke up.
[INFO][11:39:28]: [Client #466] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_554860.pth.
[INFO][11:39:28]: [Client #207] Woke up.
[INFO][11:39:28]: [Client #207] Epoch: [3/5][0/17]	Loss: 0.250089
[INFO][11:39:29]: [Client #207] Epoch: [3/5][10/17]	Loss: 1.975681
[INFO][11:39:29]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:39:29]: [Client #466] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_554860.pth.
[INFO][11:39:29]: [Client #466] Model trained.
[INFO][11:39:29]: [Client #466] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:29]: [Server #554754] Received 0.26 MB of payload data from client #466 (simulated).
[INFO][11:39:30]: [Client #207] Woke up.
[INFO][11:39:30]: [Client #207] Epoch: [4/5][0/17]	Loss: 2.585248
[INFO][11:39:30]: [Client #207] Epoch: [4/5][10/17]	Loss: 0.503156
[INFO][11:39:30]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:39:32]: [Client #207] Woke up.
[INFO][11:39:32]: [Client #207] Epoch: [5/5][0/17]	Loss: 0.252084
[INFO][11:39:32]: [Client #207] Epoch: [5/5][10/17]	Loss: 0.405812
[INFO][11:39:32]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:39:33]: [Client #207] Woke up.
[INFO][11:39:33]: [Client #207] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554853.pth.
[INFO][11:39:34]: [Client #207] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554853.pth.
[INFO][11:39:34]: [Client #207] Model trained.
[INFO][11:39:34]: [Client #207] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:34]: [Server #554754] Received 0.26 MB of payload data from client #207 (simulated).
[INFO][11:39:34]: [Server #554754] Selecting client #75 for training.
[INFO][11:39:34]: [Server #554754] Sending the current model to client #75 (simulated).
[INFO][11:39:34]: [Server #554754] Sending 0.26 MB of payload data to client #75 (simulated).
[INFO][11:39:34]: [Server #554754] Selecting client #198 for training.
[INFO][11:39:34]: [Server #554754] Sending the current model to client #198 (simulated).
[INFO][11:39:34]: [Server #554754] Sending 0.26 MB of payload data to client #198 (simulated).
[INFO][11:39:34]: [Client #75] Selected by the server.
[INFO][11:39:34]: [Client #75] Loading its data source...
[INFO][11:39:34]: Data source: FEMNIST
[INFO][11:39:34]: [Client #198] Selected by the server.
[INFO][11:39:34]: [Client #198] Loading its data source...
[INFO][11:39:34]: Data source: FEMNIST
[INFO][11:39:34]: [Client #75] Dataset size: 153
[INFO][11:39:34]: [Client #75] Sampler: all_inclusive
[INFO][11:39:34]: [Client #198] Dataset size: 165
[INFO][11:39:34]: [Client #198] Sampler: all_inclusive
[INFO][11:39:34]: [Client #75] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:34]: [Client #198] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:39:34]: [93m[1m[Client #75] Started training in communication round #34.[0m
[INFO][11:39:34]: [93m[1m[Client #198] Started training in communication round #34.[0m
[INFO][11:39:36]: [Client #198] Loading the dataset.
[INFO][11:39:36]: [Client #75] Loading the dataset.
[INFO][11:39:42]: [Client #75] Epoch: [1/5][0/16]	Loss: 2.081000
[INFO][11:39:42]: [Client #198] Epoch: [1/5][0/17]	Loss: 0.758974
[INFO][11:39:42]: [Client #75] Epoch: [1/5][10/16]	Loss: 1.819533
[INFO][11:39:42]: [Client #198] Epoch: [1/5][10/17]	Loss: 0.227076
[INFO][11:39:42]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][11:39:42]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][11:39:42]: [Client #198] Woke up.
[INFO][11:39:42]: [Client #198] Epoch: [2/5][0/17]	Loss: 0.230228
[INFO][11:39:42]: [Client #198] Epoch: [2/5][10/17]	Loss: 0.974021
[INFO][11:39:42]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][11:39:42]: [Client #75] Woke up.
[INFO][11:39:42]: [Client #75] Epoch: [2/5][0/16]	Loss: 1.273491
[INFO][11:39:43]: [Client #75] Epoch: [2/5][10/16]	Loss: 0.797786
[INFO][11:39:43]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][11:39:43]: [Client #198] Woke up.
[INFO][11:39:43]: [Client #198] Epoch: [3/5][0/17]	Loss: 0.818726
[INFO][11:39:43]: [Client #198] Epoch: [3/5][10/17]	Loss: 0.407276
[INFO][11:39:43]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][11:39:43]: [Client #198] Woke up.
[INFO][11:39:43]: [Client #198] Epoch: [4/5][0/17]	Loss: 0.319328
[INFO][11:39:43]: [Client #198] Epoch: [4/5][10/17]	Loss: 0.243015
[INFO][11:39:43]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][11:39:43]: [Client #75] Woke up.
[INFO][11:39:43]: [Client #75] Epoch: [3/5][0/16]	Loss: 0.417708
[INFO][11:39:43]: [Client #75] Epoch: [3/5][10/16]	Loss: 0.669600
[INFO][11:39:43]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][11:39:43]: [Client #198] Woke up.
[INFO][11:39:43]: [Client #198] Epoch: [5/5][0/17]	Loss: 0.260767
[INFO][11:39:44]: [Client #198] Epoch: [5/5][10/17]	Loss: 0.782349
[INFO][11:39:44]: [Client #198] Going to sleep for 0.31 seconds.
[INFO][11:39:44]: [Client #198] Woke up.
[INFO][11:39:44]: [Client #198] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_554860.pth.
[INFO][11:39:44]: [Client #75] Woke up.
[INFO][11:39:44]: [Client #75] Epoch: [4/5][0/16]	Loss: 0.822184
[INFO][11:39:44]: [Client #75] Epoch: [4/5][10/16]	Loss: 0.627300
[INFO][11:39:44]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][11:39:45]: [Client #198] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_198_554860.pth.
[INFO][11:39:45]: [Client #198] Model trained.
[INFO][11:39:45]: [Client #198] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:45]: [Server #554754] Received 0.26 MB of payload data from client #198 (simulated).
[INFO][11:39:45]: [Client #75] Woke up.
[INFO][11:39:45]: [Client #75] Epoch: [5/5][0/16]	Loss: 0.586089
[INFO][11:39:45]: [Client #75] Epoch: [5/5][10/16]	Loss: 0.897602
[INFO][11:39:45]: [Client #75] Going to sleep for 0.66 seconds.
[INFO][11:39:46]: [Client #75] Woke up.
[INFO][11:39:46]: [Client #75] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_554853.pth.
[INFO][11:39:46]: [Client #75] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_75_554853.pth.
[INFO][11:39:46]: [Client #75] Model trained.
[INFO][11:39:46]: [Client #75] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:39:46]: [Server #554754] Received 0.26 MB of payload data from client #75 (simulated).
[INFO][11:39:46]: [Server #554754] Adding client #479 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #99 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #215 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #315 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #318 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #198 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #185 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #259 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #466 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Adding client #295 to the list of clients for aggregation.
[INFO][11:39:46]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13023994 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08443377 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08455818
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.52051289 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16730777 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07102215 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14358445 0.         0.         0.07149608
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.28902632 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11650403 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13023994 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.08443377 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08455818
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.52051289 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16730777 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07102215 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.14358445 0.         0.         0.07149608
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.28902632 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11650403 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:40:31]: [Server #554754] Global model accuracy: 61.87%

[INFO][11:40:31]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_34.pth.
[INFO][11:40:31]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_34.pth.
[INFO][11:40:31]: [93m[1m
[Server #554754] Starting round 35/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.09514925 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.10318471 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.002      0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.09858247 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.002      0.08762322 0.10344828 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.002      0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.002      0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.002      0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.002
 0.002      0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.1012987  0.002
 0.05069552 0.04972711 0.16072379 0.002      0.08803006 0.100894
 0.002      0.10063694 0.10344828 0.002      0.002      0.10714286
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.05007728 0.002      0.002      0.08980716
 0.002      0.08844666 0.002      0.100894   0.10454545 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.002
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.08221681
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.002
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.09220779 0.002      0.05352394 0.002      0.08678828 0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.09935897 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.09231217 0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04953457 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.10519481 0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.002      0.002      0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][11:40:31]: [Server #554754] Selected clients: [234 282 391 246 213 133 455  11 411  97]
[INFO][11:40:31]: [Server #554754] Selecting client #234 for training.
[INFO][11:40:31]: [Server #554754] Sending the current model to client #234 (simulated).
[INFO][11:40:31]: [Server #554754] Sending 0.26 MB of payload data to client #234 (simulated).
[INFO][11:40:31]: [Server #554754] Selecting client #282 for training.
[INFO][11:40:31]: [Server #554754] Sending the current model to client #282 (simulated).
[INFO][11:40:31]: [Server #554754] Sending 0.26 MB of payload data to client #282 (simulated).
[INFO][11:40:31]: [Client #234] Selected by the server.
[INFO][11:40:31]: [Client #234] Loading its data source...
[INFO][11:40:31]: Data source: FEMNIST
[INFO][11:40:31]: [Client #282] Selected by the server.
[INFO][11:40:31]: [Client #282] Loading its data source...
[INFO][11:40:31]: Data source: FEMNIST
[INFO][11:40:31]: [Client #282] Dataset size: 155
[INFO][11:40:31]: [Client #282] Sampler: all_inclusive
[INFO][11:40:31]: [Client #282] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:40:31]: [93m[1m[Client #282] Started training in communication round #35.[0m
[INFO][11:40:31]: [Client #234] Dataset size: 207
[INFO][11:40:31]: [Client #234] Sampler: all_inclusive
[INFO][11:40:31]: [Client #234] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:40:31]: [93m[1m[Client #234] Started training in communication round #35.[0m
[INFO][11:40:33]: [Client #234] Loading the dataset.
[INFO][11:40:33]: [Client #282] Loading the dataset.
[INFO][11:40:38]: [Client #282] Epoch: [1/5][0/16]	Loss: 1.193084
[INFO][11:40:38]: [Client #234] Epoch: [1/5][0/21]	Loss: 0.952415
[INFO][11:40:38]: [Client #282] Epoch: [1/5][10/16]	Loss: 0.708209
[INFO][11:40:38]: [Client #234] Epoch: [1/5][10/21]	Loss: 1.332893
[INFO][11:40:38]: [Client #282] Going to sleep for 9.40 seconds.
[INFO][11:40:38]: [Client #234] Epoch: [1/5][20/21]	Loss: 1.119703
[INFO][11:40:38]: [Client #234] Going to sleep for 0.40 seconds.
[INFO][11:40:39]: [Client #234] Woke up.
[INFO][11:40:39]: [Client #234] Epoch: [2/5][0/21]	Loss: 0.448363
[INFO][11:40:39]: [Client #234] Epoch: [2/5][10/21]	Loss: 0.540260
[INFO][11:40:39]: [Client #234] Epoch: [2/5][20/21]	Loss: 0.814956
[INFO][11:40:39]: [Client #234] Going to sleep for 0.40 seconds.
[INFO][11:40:39]: [Client #234] Woke up.
[INFO][11:40:39]: [Client #234] Epoch: [3/5][0/21]	Loss: 0.571907
[INFO][11:40:40]: [Client #234] Epoch: [3/5][10/21]	Loss: 0.291084
[INFO][11:40:40]: [Client #234] Epoch: [3/5][20/21]	Loss: 1.067825
[INFO][11:40:40]: [Client #234] Going to sleep for 0.40 seconds.
[INFO][11:40:40]: [Client #234] Woke up.
[INFO][11:40:40]: [Client #234] Epoch: [4/5][0/21]	Loss: 0.881318
[INFO][11:40:40]: [Client #234] Epoch: [4/5][10/21]	Loss: 0.255615
[INFO][11:40:40]: [Client #234] Epoch: [4/5][20/21]	Loss: 1.738900
[INFO][11:40:40]: [Client #234] Going to sleep for 0.40 seconds.
[INFO][11:40:41]: [Client #234] Woke up.
[INFO][11:40:41]: [Client #234] Epoch: [5/5][0/21]	Loss: 0.681211
[INFO][11:40:41]: [Client #234] Epoch: [5/5][10/21]	Loss: 2.686043
[INFO][11:40:41]: [Client #234] Epoch: [5/5][20/21]	Loss: 1.704924
[INFO][11:40:41]: [Client #234] Going to sleep for 0.40 seconds.
[INFO][11:40:41]: [Client #234] Woke up.
[INFO][11:40:41]: [Client #234] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_234_554853.pth.
[INFO][11:40:42]: [Client #234] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_234_554853.pth.
[INFO][11:40:42]: [Client #234] Model trained.
[INFO][11:40:42]: [Client #234] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:40:42]: [Server #554754] Received 0.26 MB of payload data from client #234 (simulated).
[INFO][11:40:48]: [Client #282] Woke up.
[INFO][11:40:48]: [Client #282] Epoch: [2/5][0/16]	Loss: 0.719173
[INFO][11:40:48]: [Client #282] Epoch: [2/5][10/16]	Loss: 0.569716
[INFO][11:40:48]: [Client #282] Going to sleep for 9.40 seconds.
[INFO][11:40:57]: [Client #282] Woke up.
[INFO][11:40:57]: [Client #282] Epoch: [3/5][0/16]	Loss: 0.257071
[INFO][11:40:57]: [Client #282] Epoch: [3/5][10/16]	Loss: 0.257348
[INFO][11:40:58]: [Client #282] Going to sleep for 9.40 seconds.
[INFO][11:41:07]: [Client #282] Woke up.
[INFO][11:41:07]: [Client #282] Epoch: [4/5][0/16]	Loss: 0.098083
[INFO][11:41:07]: [Client #282] Epoch: [4/5][10/16]	Loss: 0.889296
[INFO][11:41:07]: [Client #282] Going to sleep for 9.40 seconds.
[INFO][11:41:16]: [Client #282] Woke up.
[INFO][11:41:16]: [Client #282] Epoch: [5/5][0/16]	Loss: 0.711654
[INFO][11:41:17]: [Client #282] Epoch: [5/5][10/16]	Loss: 0.655266
[INFO][11:41:17]: [Client #282] Going to sleep for 9.40 seconds.
[INFO][11:41:26]: [Client #282] Woke up.
[INFO][11:41:26]: [Client #282] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_282_554860.pth.
[INFO][11:41:27]: [Client #282] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_282_554860.pth.
[INFO][11:41:27]: [Client #282] Model trained.
[INFO][11:41:27]: [Client #282] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:41:27]: [Server #554754] Received 0.26 MB of payload data from client #282 (simulated).
[INFO][11:41:27]: [Server #554754] Selecting client #391 for training.
[INFO][11:41:27]: [Server #554754] Sending the current model to client #391 (simulated).
[INFO][11:41:27]: [Server #554754] Sending 0.26 MB of payload data to client #391 (simulated).
[INFO][11:41:27]: [Server #554754] Selecting client #246 for training.
[INFO][11:41:27]: [Server #554754] Sending the current model to client #246 (simulated).
[INFO][11:41:27]: [Server #554754] Sending 0.26 MB of payload data to client #246 (simulated).
[INFO][11:41:27]: [Client #391] Selected by the server.
[INFO][11:41:27]: [Client #246] Selected by the server.
[INFO][11:41:27]: [Client #391] Loading its data source...
[INFO][11:41:27]: [Client #246] Loading its data source...
[INFO][11:41:27]: Data source: FEMNIST
[INFO][11:41:27]: Data source: FEMNIST
[INFO][11:41:27]: [Client #246] Dataset size: 135
[INFO][11:41:27]: [Client #246] Sampler: all_inclusive
[INFO][11:41:27]: [Client #391] Dataset size: 155
[INFO][11:41:27]: [Client #391] Sampler: all_inclusive
[INFO][11:41:27]: [Client #246] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:27]: [Client #391] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:27]: [93m[1m[Client #246] Started training in communication round #35.[0m
[INFO][11:41:27]: [93m[1m[Client #391] Started training in communication round #35.[0m
[INFO][11:41:29]: [Client #246] Loading the dataset.
[INFO][11:41:29]: [Client #391] Loading the dataset.
[INFO][11:41:34]: [Client #391] Epoch: [1/5][0/16]	Loss: 0.430271
[INFO][11:41:34]: [Client #246] Epoch: [1/5][0/14]	Loss: 0.166272
[INFO][11:41:34]: [Client #391] Epoch: [1/5][10/16]	Loss: 0.374056
[INFO][11:41:34]: [Client #246] Epoch: [1/5][10/14]	Loss: 0.886113
[INFO][11:41:34]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][11:41:34]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][11:41:35]: [Client #391] Woke up.
[INFO][11:41:35]: [Client #391] Epoch: [2/5][0/16]	Loss: 0.757129
[INFO][11:41:35]: [Client #391] Epoch: [2/5][10/16]	Loss: 0.144417
[INFO][11:41:35]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][11:41:35]: [Client #391] Woke up.
[INFO][11:41:35]: [Client #391] Epoch: [3/5][0/16]	Loss: 0.084061
[INFO][11:41:35]: [Client #391] Epoch: [3/5][10/16]	Loss: 0.883118
[INFO][11:41:35]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][11:41:35]: [Client #391] Woke up.
[INFO][11:41:35]: [Client #391] Epoch: [4/5][0/16]	Loss: 0.159662
[INFO][11:41:36]: [Client #391] Epoch: [4/5][10/16]	Loss: 0.724413
[INFO][11:41:36]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][11:41:36]: [Client #391] Woke up.
[INFO][11:41:36]: [Client #391] Epoch: [5/5][0/16]	Loss: 0.576628
[INFO][11:41:36]: [Client #246] Woke up.
[INFO][11:41:36]: [Client #246] Epoch: [2/5][0/14]	Loss: 0.265187
[INFO][11:41:36]: [Client #391] Epoch: [5/5][10/16]	Loss: 0.411079
[INFO][11:41:36]: [Client #391] Going to sleep for 0.27 seconds.
[INFO][11:41:36]: [Client #246] Epoch: [2/5][10/14]	Loss: 1.400444
[INFO][11:41:36]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][11:41:36]: [Client #391] Woke up.
[INFO][11:41:36]: [Client #391] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_554853.pth.
[INFO][11:41:37]: [Client #391] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_391_554853.pth.
[INFO][11:41:37]: [Client #391] Model trained.
[INFO][11:41:37]: [Client #391] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:41:37]: [Server #554754] Received 0.26 MB of payload data from client #391 (simulated).
[INFO][11:41:38]: [Client #246] Woke up.
[INFO][11:41:38]: [Client #246] Epoch: [3/5][0/14]	Loss: 0.123221
[INFO][11:41:38]: [Client #246] Epoch: [3/5][10/14]	Loss: 0.115633
[INFO][11:41:38]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][11:41:39]: [Client #246] Woke up.
[INFO][11:41:39]: [Client #246] Epoch: [4/5][0/14]	Loss: 0.116204
[INFO][11:41:39]: [Client #246] Epoch: [4/5][10/14]	Loss: 0.234888
[INFO][11:41:39]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][11:41:41]: [Client #246] Woke up.
[INFO][11:41:41]: [Client #246] Epoch: [5/5][0/14]	Loss: 0.069179
[INFO][11:41:41]: [Client #246] Epoch: [5/5][10/14]	Loss: 0.105565
[INFO][11:41:41]: [Client #246] Going to sleep for 1.58 seconds.
[INFO][11:41:43]: [Client #246] Woke up.
[INFO][11:41:43]: [Client #246] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_246_554860.pth.
[INFO][11:41:43]: [Client #246] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_246_554860.pth.
[INFO][11:41:43]: [Client #246] Model trained.
[INFO][11:41:43]: [Client #246] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:41:43]: [Server #554754] Received 0.26 MB of payload data from client #246 (simulated).
[INFO][11:41:43]: [Server #554754] Selecting client #213 for training.
[INFO][11:41:43]: [Server #554754] Sending the current model to client #213 (simulated).
[INFO][11:41:43]: [Server #554754] Sending 0.26 MB of payload data to client #213 (simulated).
[INFO][11:41:43]: [Server #554754] Selecting client #133 for training.
[INFO][11:41:43]: [Server #554754] Sending the current model to client #133 (simulated).
[INFO][11:41:43]: [Server #554754] Sending 0.26 MB of payload data to client #133 (simulated).
[INFO][11:41:43]: [Client #213] Selected by the server.
[INFO][11:41:43]: [Client #133] Selected by the server.
[INFO][11:41:43]: [Client #213] Loading its data source...
[INFO][11:41:43]: [Client #133] Loading its data source...
[INFO][11:41:43]: Data source: FEMNIST
[INFO][11:41:43]: Data source: FEMNIST
[INFO][11:41:43]: [Client #213] Dataset size: 160
[INFO][11:41:43]: [Client #213] Sampler: all_inclusive
[INFO][11:41:43]: [Client #133] Dataset size: 160
[INFO][11:41:43]: [Client #133] Sampler: all_inclusive
[INFO][11:41:43]: [Client #213] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:43]: [Client #133] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:44]: [93m[1m[Client #213] Started training in communication round #35.[0m
[INFO][11:41:44]: [93m[1m[Client #133] Started training in communication round #35.[0m
[INFO][11:41:45]: [Client #213] Loading the dataset.
[INFO][11:41:45]: [Client #133] Loading the dataset.
[INFO][11:41:51]: [Client #133] Epoch: [1/5][0/16]	Loss: 0.260170
[INFO][11:41:51]: [Client #213] Epoch: [1/5][0/16]	Loss: 0.745146
[INFO][11:41:51]: [Client #133] Epoch: [1/5][10/16]	Loss: 0.995712
[INFO][11:41:51]: [Client #133] Going to sleep for 1.28 seconds.
[INFO][11:41:51]: [Client #213] Epoch: [1/5][10/16]	Loss: 0.570650
[INFO][11:41:51]: [Client #213] Going to sleep for 0.21 seconds.
[INFO][11:41:51]: [Client #213] Woke up.
[INFO][11:41:51]: [Client #213] Epoch: [2/5][0/16]	Loss: 0.727627
[INFO][11:41:51]: [Client #213] Epoch: [2/5][10/16]	Loss: 0.748541
[INFO][11:41:51]: [Client #213] Going to sleep for 0.21 seconds.
[INFO][11:41:52]: [Client #213] Woke up.
[INFO][11:41:52]: [Client #213] Epoch: [3/5][0/16]	Loss: 0.360723
[INFO][11:41:52]: [Client #213] Epoch: [3/5][10/16]	Loss: 0.631230
[INFO][11:41:52]: [Client #213] Going to sleep for 0.21 seconds.
[INFO][11:41:52]: [Client #213] Woke up.
[INFO][11:41:52]: [Client #213] Epoch: [4/5][0/16]	Loss: 0.673523
[INFO][11:41:52]: [Client #213] Epoch: [4/5][10/16]	Loss: 0.099572
[INFO][11:41:52]: [Client #213] Going to sleep for 0.21 seconds.
[INFO][11:41:52]: [Client #133] Woke up.
[INFO][11:41:52]: [Client #133] Epoch: [2/5][0/16]	Loss: 0.622245
[INFO][11:41:52]: [Client #213] Woke up.
[INFO][11:41:52]: [Client #133] Epoch: [2/5][10/16]	Loss: 1.132927
[INFO][11:41:52]: [Client #213] Epoch: [5/5][0/16]	Loss: 0.058360
[INFO][11:41:52]: [Client #133] Going to sleep for 1.28 seconds.
[INFO][11:41:52]: [Client #213] Epoch: [5/5][10/16]	Loss: 0.215467
[INFO][11:41:52]: [Client #213] Going to sleep for 0.21 seconds.
[INFO][11:41:53]: [Client #213] Woke up.
[INFO][11:41:53]: [Client #213] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_213_554853.pth.
[INFO][11:41:53]: [Client #213] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_213_554853.pth.
[INFO][11:41:53]: [Client #213] Model trained.
[INFO][11:41:53]: [Client #213] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:41:53]: [Server #554754] Received 0.26 MB of payload data from client #213 (simulated).
[INFO][11:41:54]: [Client #133] Woke up.
[INFO][11:41:54]: [Client #133] Epoch: [3/5][0/16]	Loss: 1.112496
[INFO][11:41:54]: [Client #133] Epoch: [3/5][10/16]	Loss: 0.316390
[INFO][11:41:54]: [Client #133] Going to sleep for 1.28 seconds.
[INFO][11:41:55]: [Client #133] Woke up.
[INFO][11:41:55]: [Client #133] Epoch: [4/5][0/16]	Loss: 0.215018
[INFO][11:41:55]: [Client #133] Epoch: [4/5][10/16]	Loss: 0.608735
[INFO][11:41:55]: [Client #133] Going to sleep for 1.28 seconds.
[INFO][11:41:57]: [Client #133] Woke up.
[INFO][11:41:57]: [Client #133] Epoch: [5/5][0/16]	Loss: 0.262995
[INFO][11:41:57]: [Client #133] Epoch: [5/5][10/16]	Loss: 0.863574
[INFO][11:41:57]: [Client #133] Going to sleep for 1.28 seconds.
[INFO][11:41:58]: [Client #133] Woke up.
[INFO][11:41:58]: [Client #133] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_133_554860.pth.
[INFO][11:41:59]: [Client #133] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_133_554860.pth.
[INFO][11:41:59]: [Client #133] Model trained.
[INFO][11:41:59]: [Client #133] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:41:59]: [Server #554754] Received 0.26 MB of payload data from client #133 (simulated).
[INFO][11:41:59]: [Server #554754] Selecting client #455 for training.
[INFO][11:41:59]: [Server #554754] Sending the current model to client #455 (simulated).
[INFO][11:41:59]: [Server #554754] Sending 0.26 MB of payload data to client #455 (simulated).
[INFO][11:41:59]: [Server #554754] Selecting client #11 for training.
[INFO][11:41:59]: [Server #554754] Sending the current model to client #11 (simulated).
[INFO][11:41:59]: [Server #554754] Sending 0.26 MB of payload data to client #11 (simulated).
[INFO][11:41:59]: [Client #11] Selected by the server.
[INFO][11:41:59]: [Client #455] Selected by the server.
[INFO][11:41:59]: [Client #11] Loading its data source...
[INFO][11:41:59]: [Client #455] Loading its data source...
[INFO][11:41:59]: Data source: FEMNIST
[INFO][11:41:59]: Data source: FEMNIST
[INFO][11:41:59]: [Client #455] Dataset size: 149
[INFO][11:41:59]: [Client #455] Sampler: all_inclusive
[INFO][11:41:59]: [Client #11] Dataset size: 153
[INFO][11:41:59]: [Client #11] Sampler: all_inclusive
[INFO][11:41:59]: [Client #455] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:59]: [93m[1m[Client #455] Started training in communication round #35.[0m
[INFO][11:41:59]: [Client #11] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:41:59]: [93m[1m[Client #11] Started training in communication round #35.[0m
[INFO][11:42:01]: [Client #11] Loading the dataset.
[INFO][11:42:01]: [Client #455] Loading the dataset.
[INFO][11:42:06]: [Client #455] Epoch: [1/5][0/15]	Loss: 0.837924
[INFO][11:42:06]: [Client #11] Epoch: [1/5][0/16]	Loss: 0.512785
[INFO][11:42:06]: [Client #455] Epoch: [1/5][10/15]	Loss: 1.185952
[INFO][11:42:06]: [Client #11] Epoch: [1/5][10/16]	Loss: 1.774068
[INFO][11:42:06]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][11:42:06]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:42:07]: [Client #11] Woke up.
[INFO][11:42:07]: [Client #11] Epoch: [2/5][0/16]	Loss: 0.134100
[INFO][11:42:07]: [Client #11] Epoch: [2/5][10/16]	Loss: 0.449202
[INFO][11:42:07]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:42:08]: [Client #11] Woke up.
[INFO][11:42:08]: [Client #11] Epoch: [3/5][0/16]	Loss: 0.138148
[INFO][11:42:08]: [Client #11] Epoch: [3/5][10/16]	Loss: 0.413358
[INFO][11:42:08]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:42:09]: [Client #455] Woke up.
[INFO][11:42:09]: [Client #455] Epoch: [2/5][0/15]	Loss: 0.810651
[INFO][11:42:09]: [Client #11] Woke up.
[INFO][11:42:09]: [Client #11] Epoch: [4/5][0/16]	Loss: 0.415667
[INFO][11:42:09]: [Client #455] Epoch: [2/5][10/15]	Loss: 0.693373
[INFO][11:42:09]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][11:42:09]: [Client #11] Epoch: [4/5][10/16]	Loss: 1.368633
[INFO][11:42:09]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:42:09]: [Client #11] Woke up.
[INFO][11:42:09]: [Client #11] Epoch: [5/5][0/16]	Loss: 0.332972
[INFO][11:42:10]: [Client #11] Epoch: [5/5][10/16]	Loss: 0.838492
[INFO][11:42:10]: [Client #11] Going to sleep for 0.72 seconds.
[INFO][11:42:10]: [Client #11] Woke up.
[INFO][11:42:10]: [Client #11] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_554860.pth.
[INFO][11:42:11]: [Client #11] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_11_554860.pth.
[INFO][11:42:11]: [Client #11] Model trained.
[INFO][11:42:11]: [Client #11] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:42:11]: [Server #554754] Received 0.26 MB of payload data from client #11 (simulated).
[INFO][11:42:11]: [Client #455] Woke up.
[INFO][11:42:11]: [Client #455] Epoch: [3/5][0/15]	Loss: 0.099889
[INFO][11:42:11]: [Client #455] Epoch: [3/5][10/15]	Loss: 0.865629
[INFO][11:42:11]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][11:42:14]: [Client #455] Woke up.
[INFO][11:42:14]: [Client #455] Epoch: [4/5][0/15]	Loss: 0.513384
[INFO][11:42:14]: [Client #455] Epoch: [4/5][10/15]	Loss: 1.352906
[INFO][11:42:14]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][11:42:16]: [Client #455] Woke up.
[INFO][11:42:16]: [Client #455] Epoch: [5/5][0/15]	Loss: 0.235095
[INFO][11:42:16]: [Client #455] Epoch: [5/5][10/15]	Loss: 0.071237
[INFO][11:42:17]: [Client #455] Going to sleep for 2.46 seconds.
[INFO][11:42:19]: [Client #455] Woke up.
[INFO][11:42:19]: [Client #455] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_554853.pth.
[INFO][11:42:20]: [Client #455] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_455_554853.pth.
[INFO][11:42:20]: [Client #455] Model trained.
[INFO][11:42:20]: [Client #455] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:42:20]: [Server #554754] Received 0.26 MB of payload data from client #455 (simulated).
[INFO][11:42:20]: [Server #554754] Selecting client #411 for training.
[INFO][11:42:20]: [Server #554754] Sending the current model to client #411 (simulated).
[INFO][11:42:20]: [Server #554754] Sending 0.26 MB of payload data to client #411 (simulated).
[INFO][11:42:20]: [Server #554754] Selecting client #97 for training.
[INFO][11:42:20]: [Server #554754] Sending the current model to client #97 (simulated).
[INFO][11:42:20]: [Server #554754] Sending 0.26 MB of payload data to client #97 (simulated).
[INFO][11:42:20]: [Client #411] Selected by the server.
[INFO][11:42:20]: [Client #411] Loading its data source...
[INFO][11:42:20]: Data source: FEMNIST
[INFO][11:42:20]: [Client #97] Selected by the server.
[INFO][11:42:20]: [Client #97] Loading its data source...
[INFO][11:42:20]: Data source: FEMNIST
[INFO][11:42:20]: [Client #411] Dataset size: 317
[INFO][11:42:20]: [Client #411] Sampler: all_inclusive
[INFO][11:42:20]: [Client #411] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:42:20]: [93m[1m[Client #411] Started training in communication round #35.[0m
[INFO][11:42:20]: [Client #97] Dataset size: 158
[INFO][11:42:20]: [Client #97] Sampler: all_inclusive
[INFO][11:42:20]: [Client #97] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:42:20]: [93m[1m[Client #97] Started training in communication round #35.[0m
[INFO][11:42:22]: [Client #411] Loading the dataset.
[INFO][11:42:22]: [Client #97] Loading the dataset.
[INFO][11:42:27]: [Client #411] Epoch: [1/5][0/32]	Loss: 1.545949
[INFO][11:42:27]: [Client #97] Epoch: [1/5][0/16]	Loss: 0.734121
[INFO][11:42:27]: [Client #411] Epoch: [1/5][10/32]	Loss: 0.786653
[INFO][11:42:27]: [Client #97] Epoch: [1/5][10/16]	Loss: 0.662747
[INFO][11:42:27]: [Client #411] Epoch: [1/5][20/32]	Loss: 1.216731
[INFO][11:42:27]: [Client #97] Going to sleep for 9.35 seconds.
[INFO][11:42:27]: [Client #411] Epoch: [1/5][30/32]	Loss: 0.409450
[INFO][11:42:27]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][11:42:27]: [Client #411] Woke up.
[INFO][11:42:27]: [Client #411] Epoch: [2/5][0/32]	Loss: 0.565234
[INFO][11:42:28]: [Client #411] Epoch: [2/5][10/32]	Loss: 0.276525
[INFO][11:42:28]: [Client #411] Epoch: [2/5][20/32]	Loss: 1.552773
[INFO][11:42:28]: [Client #411] Epoch: [2/5][30/32]	Loss: 1.120522
[INFO][11:42:28]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][11:42:28]: [Client #411] Woke up.
[INFO][11:42:28]: [Client #411] Epoch: [3/5][0/32]	Loss: 0.519661
[INFO][11:42:28]: [Client #411] Epoch: [3/5][10/32]	Loss: 0.413473
[INFO][11:42:28]: [Client #411] Epoch: [3/5][20/32]	Loss: 0.535115
[INFO][11:42:28]: [Client #411] Epoch: [3/5][30/32]	Loss: 1.225338
[INFO][11:42:28]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][11:42:28]: [Client #411] Woke up.
[INFO][11:42:28]: [Client #411] Epoch: [4/5][0/32]	Loss: 0.147706
[INFO][11:42:28]: [Client #411] Epoch: [4/5][10/32]	Loss: 1.508832
[INFO][11:42:28]: [Client #411] Epoch: [4/5][20/32]	Loss: 0.722255
[INFO][11:42:28]: [Client #411] Epoch: [4/5][30/32]	Loss: 0.975030
[INFO][11:42:28]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][11:42:29]: [Client #411] Woke up.
[INFO][11:42:29]: [Client #411] Epoch: [5/5][0/32]	Loss: 1.100163
[INFO][11:42:29]: [Client #411] Epoch: [5/5][10/32]	Loss: 0.716742
[INFO][11:42:29]: [Client #411] Epoch: [5/5][20/32]	Loss: 1.472786
[INFO][11:42:29]: [Client #411] Epoch: [5/5][30/32]	Loss: 0.745832
[INFO][11:42:29]: [Client #411] Going to sleep for 0.12 seconds.
[INFO][11:42:29]: [Client #411] Woke up.
[INFO][11:42:29]: [Client #411] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554853.pth.
[INFO][11:42:30]: [Client #411] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_411_554853.pth.
[INFO][11:42:30]: [Client #411] Model trained.
[INFO][11:42:30]: [Client #411] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:42:30]: [Server #554754] Received 0.26 MB of payload data from client #411 (simulated).
[INFO][11:42:37]: [Client #97] Woke up.
[INFO][11:42:37]: [Client #97] Epoch: [2/5][0/16]	Loss: 0.220691
[INFO][11:42:37]: [Client #97] Epoch: [2/5][10/16]	Loss: 1.063653
[INFO][11:42:37]: [Client #97] Going to sleep for 9.35 seconds.
[INFO][11:42:46]: [Client #97] Woke up.
[INFO][11:42:46]: [Client #97] Epoch: [3/5][0/16]	Loss: 0.102820
[INFO][11:42:46]: [Client #97] Epoch: [3/5][10/16]	Loss: 0.285555
[INFO][11:42:46]: [Client #97] Going to sleep for 9.35 seconds.
[INFO][11:42:56]: [Client #97] Woke up.
[INFO][11:42:56]: [Client #97] Epoch: [4/5][0/16]	Loss: 0.151674
[INFO][11:42:56]: [Client #97] Epoch: [4/5][10/16]	Loss: 0.078461
[INFO][11:42:56]: [Client #97] Going to sleep for 9.35 seconds.
[INFO][11:43:05]: [Client #97] Woke up.
[INFO][11:43:05]: [Client #97] Epoch: [5/5][0/16]	Loss: 0.407312
[INFO][11:43:05]: [Client #97] Epoch: [5/5][10/16]	Loss: 0.884849
[INFO][11:43:05]: [Client #97] Going to sleep for 9.35 seconds.
[INFO][11:43:15]: [Client #97] Woke up.
[INFO][11:43:15]: [Client #97] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_97_554860.pth.
[INFO][11:43:15]: [Client #97] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_97_554860.pth.
[INFO][11:43:15]: [Client #97] Model trained.
[INFO][11:43:15]: [Client #97] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:43:15]: [Server #554754] Received 0.26 MB of payload data from client #97 (simulated).
[INFO][11:43:15]: [Server #554754] Adding client #75 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #62 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #169 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #207 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #213 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #411 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #391 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #234 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #11 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #133 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #246 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #455 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #38 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #86 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #97 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #282 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #190 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #496 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #497 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Adding client #299 to the list of clients for aggregation.
[INFO][11:43:15]: [Server #554754] Aggregating 20 clients in total.
[0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00203967 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.0020404
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204034
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00202145 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00203966
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.0020406
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00203937 0.00204088 0.00204088 0.00204056 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00203478 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00203994 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088 0.00204088
 0.00204088 0.00204088 0.00204088 0.00204088]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16527905 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12335397 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13725246 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15883003 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11821329 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09180283 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09022037 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06519308 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11124826 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.50403225 0.         0.         0.
 0.         0.         0.10701253 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17004052
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06589543
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17327284
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09794076 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1442911  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.3015987  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.090487   0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16015827 0.11322503 0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16527905 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.12335397 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13725246 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15883003 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11821329 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09180283 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09022037 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06519308 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11124826 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.50403225 0.         0.         0.
 0.         0.         0.10701253 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17004052
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.06589543
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.17327284
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09794076 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1442911  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.3015987  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.090487   0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.16015827 0.11322503 0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:43:59]: [Server #554754] Global model accuracy: 64.33%

[INFO][11:43:59]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_35.pth.
[INFO][11:43:59]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_35.pth.
[INFO][11:43:59]: [93m[1m
[Server #554754] Starting round 36/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.04880988 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.04700211 0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.05252918 0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.002      0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.08595041 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.002      0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.002
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.1012987  0.002
 0.05069552 0.04972711 0.16072379 0.04820729 0.08803006 0.100894
 0.002      0.10063694 0.10344828 0.002      0.002      0.10714286
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04880988 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.09220779 0.002      0.05352394 0.002      0.0473034  0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.002      0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.002      0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.0912721  0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10747051 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.10519481 0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9069e+00  8e-04  1e-08  1e-08
 5:  6.9078e+00  6.9072e+00  5e-04  7e-09  7e-09
 6:  6.9077e+00  6.9072e+00  5e-04  1e-07  8e-08
 7:  6.9076e+00  6.9073e+00  3e-04  1e-07  6e-08
 8:  6.9075e+00  6.9073e+00  2e-04  3e-07  1e-07
 9:  6.9074e+00  6.9074e+00  5e-05  5e-07  3e-07
10:  6.9074e+00  6.9074e+00  1e-05  1e-07  7e-08
11:  6.9074e+00  6.9074e+00  5e-07  9e-09  5e-09
Optimal solution found.
The calculated probability is:  [3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47672445e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 8.42435929e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 9.67882460e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 1.23173784e-05 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 8.02541555e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47746347e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47746694e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 5.21738534e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 7.53120578e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 9.98217797e-01 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47732089e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47569241e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47768959e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47658351e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 6.71346602e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47696429e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.46213639e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47751276e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06
 3.47782593e-06 3.47782593e-06 3.47782593e-06 1.25162019e-05
 7.66644503e-06 3.47782593e-06 3.47782593e-06 3.47782593e-06]
current clients pool:  [INFO][11:44:00]: [Server #554754] Selected clients: [207 466 190 245 124 445 189 146 360  91  60 421 373 295 118 311 319 161
  35 443]
[INFO][11:44:00]: [Server #554754] Selecting client #207 for training.
[INFO][11:44:00]: [Server #554754] Sending the current model to client #207 (simulated).
[INFO][11:44:00]: [Server #554754] Sending 0.26 MB of payload data to client #207 (simulated).
[INFO][11:44:00]: [Server #554754] Selecting client #466 for training.
[INFO][11:44:00]: [Server #554754] Sending the current model to client #466 (simulated).
[INFO][11:44:00]: [Server #554754] Sending 0.26 MB of payload data to client #466 (simulated).
[INFO][11:44:00]: [Client #207] Selected by the server.
[INFO][11:44:00]: [Client #207] Loading its data source...
[INFO][11:44:00]: Data source: FEMNIST
[INFO][11:44:00]: [Client #466] Selected by the server.
[INFO][11:44:00]: [Client #466] Loading its data source...
[INFO][11:44:00]: Data source: FEMNIST
[INFO][11:44:00]: [Client #466] Dataset size: 162
[INFO][11:44:00]: [Client #466] Sampler: all_inclusive
[INFO][11:44:00]: [Client #466] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:44:00]: [Client #207] Dataset size: 162
[INFO][11:44:00]: [Client #207] Sampler: all_inclusive
[INFO][11:44:00]: [93m[1m[Client #466] Started training in communication round #36.[0m
[INFO][11:44:00]: [Client #207] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:44:00]: [93m[1m[Client #207] Started training in communication round #36.[0m
[INFO][11:44:02]: [Client #466] Loading the dataset.
[INFO][11:44:02]: [Client #207] Loading the dataset.
[INFO][11:44:07]: [Client #466] Epoch: [1/5][0/17]	Loss: 0.841141
[INFO][11:44:07]: [Client #466] Epoch: [1/5][10/17]	Loss: 0.774436
[INFO][11:44:07]: [Client #207] Epoch: [1/5][0/17]	Loss: 0.655796
[INFO][11:44:07]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:44:07]: [Client #207] Epoch: [1/5][10/17]	Loss: 0.263445
[INFO][11:44:07]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:44:08]: [Client #466] Woke up.
[INFO][11:44:08]: [Client #466] Epoch: [2/5][0/17]	Loss: 0.175693
[INFO][11:44:08]: [Client #466] Epoch: [2/5][10/17]	Loss: 0.705289
[INFO][11:44:08]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:44:08]: [Client #466] Woke up.
[INFO][11:44:08]: [Client #466] Epoch: [3/5][0/17]	Loss: 0.816306
[INFO][11:44:08]: [Client #466] Epoch: [3/5][10/17]	Loss: 1.023249
[INFO][11:44:08]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:44:09]: [Client #466] Woke up.
[INFO][11:44:09]: [Client #207] Woke up.
[INFO][11:44:09]: [Client #466] Epoch: [4/5][0/17]	Loss: 0.901050
[INFO][11:44:09]: [Client #207] Epoch: [2/5][0/17]	Loss: 0.522066
[INFO][11:44:09]: [Client #466] Epoch: [4/5][10/17]	Loss: 0.844223
[INFO][11:44:09]: [Client #207] Epoch: [2/5][10/17]	Loss: 0.501040
[INFO][11:44:09]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:44:09]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:44:09]: [Client #466] Woke up.
[INFO][11:44:09]: [Client #466] Epoch: [5/5][0/17]	Loss: 1.085240
[INFO][11:44:09]: [Client #466] Epoch: [5/5][10/17]	Loss: 0.820602
[INFO][11:44:09]: [Client #466] Going to sleep for 0.45 seconds.
[INFO][11:44:10]: [Client #466] Woke up.
[INFO][11:44:10]: [Client #466] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_554860.pth.
[INFO][11:44:10]: [Client #207] Woke up.
[INFO][11:44:10]: [Client #207] Epoch: [3/5][0/17]	Loss: 0.674185
[INFO][11:44:11]: [Client #207] Epoch: [3/5][10/17]	Loss: 0.686752
[INFO][11:44:11]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:44:11]: [Client #466] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_466_554860.pth.
[INFO][11:44:11]: [Client #466] Model trained.
[INFO][11:44:11]: [Client #466] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:44:11]: [Server #554754] Received 0.26 MB of payload data from client #466 (simulated).
[INFO][11:44:12]: [Client #207] Woke up.
[INFO][11:44:12]: [Client #207] Epoch: [4/5][0/17]	Loss: 0.678290
[INFO][11:44:12]: [Client #207] Epoch: [4/5][10/17]	Loss: 0.657027
[INFO][11:44:12]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:44:14]: [Client #207] Woke up.
[INFO][11:44:14]: [Client #207] Epoch: [5/5][0/17]	Loss: 0.551681
[INFO][11:44:14]: [Client #207] Epoch: [5/5][10/17]	Loss: 0.228846
[INFO][11:44:14]: [Client #207] Going to sleep for 1.53 seconds.
[INFO][11:44:15]: [Client #207] Woke up.
[INFO][11:44:15]: [Client #207] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554853.pth.
[INFO][11:44:16]: [Client #207] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_207_554853.pth.
[INFO][11:44:16]: [Client #207] Model trained.
[INFO][11:44:16]: [Client #207] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:44:16]: [Server #554754] Received 0.26 MB of payload data from client #207 (simulated).
[INFO][11:44:16]: [Server #554754] Selecting client #190 for training.
[INFO][11:44:16]: [Server #554754] Sending the current model to client #190 (simulated).
[INFO][11:44:16]: [Server #554754] Sending 0.26 MB of payload data to client #190 (simulated).
[INFO][11:44:16]: [Server #554754] Selecting client #245 for training.
[INFO][11:44:16]: [Server #554754] Sending the current model to client #245 (simulated).
[INFO][11:44:16]: [Server #554754] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][11:44:16]: [Client #190] Selected by the server.
[INFO][11:44:16]: [Client #190] Loading its data source...
[INFO][11:44:16]: Data source: FEMNIST
[INFO][11:44:16]: [Client #245] Selected by the server.
[INFO][11:44:16]: [Client #245] Loading its data source...
[INFO][11:44:16]: Data source: FEMNIST
[INFO][11:44:16]: [Client #190] Dataset size: 160
[INFO][11:44:16]: [Client #190] Sampler: all_inclusive
[INFO][11:44:16]: [Client #190] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:44:16]: [93m[1m[Client #190] Started training in communication round #36.[0m
[INFO][11:44:16]: [Client #245] Dataset size: 301
[INFO][11:44:16]: [Client #245] Sampler: all_inclusive
[INFO][11:44:16]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:44:16]: [93m[1m[Client #245] Started training in communication round #36.[0m
[INFO][11:44:18]: [Client #190] Loading the dataset.
[INFO][11:44:18]: [Client #245] Loading the dataset.
[INFO][11:44:23]: [Client #190] Epoch: [1/5][0/16]	Loss: 0.676575
[INFO][11:44:24]: [Client #245] Epoch: [1/5][0/31]	Loss: 0.993721
[INFO][11:44:24]: [Client #190] Epoch: [1/5][10/16]	Loss: 1.067739
[INFO][11:44:24]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:44:24]: [Client #245] Epoch: [1/5][10/31]	Loss: 0.728846
[INFO][11:44:24]: [Client #245] Epoch: [1/5][20/31]	Loss: 1.225269
[INFO][11:44:24]: [Client #245] Epoch: [1/5][30/31]	Loss: 1.318068
[INFO][11:44:24]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][11:44:28]: [Client #245] Woke up.
[INFO][11:44:28]: [Client #245] Epoch: [2/5][0/31]	Loss: 0.571445
[INFO][11:44:28]: [Client #245] Epoch: [2/5][10/31]	Loss: 0.437896
[INFO][11:44:28]: [Client #245] Epoch: [2/5][20/31]	Loss: 1.146947
[INFO][11:44:28]: [Client #245] Epoch: [2/5][30/31]	Loss: 0.523851
[INFO][11:44:28]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][11:44:32]: [Client #245] Woke up.
[INFO][11:44:32]: [Client #245] Epoch: [3/5][0/31]	Loss: 0.710902
[INFO][11:44:32]: [Client #245] Epoch: [3/5][10/31]	Loss: 0.820552
[INFO][11:44:32]: [Client #245] Epoch: [3/5][20/31]	Loss: 1.437615
[INFO][11:44:32]: [Client #245] Epoch: [3/5][30/31]	Loss: 0.588110
[INFO][11:44:32]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][11:44:36]: [Client #245] Woke up.
[INFO][11:44:36]: [Client #245] Epoch: [4/5][0/31]	Loss: 0.161603
[INFO][11:44:36]: [Client #245] Epoch: [4/5][10/31]	Loss: 1.351462
[INFO][11:44:36]: [Client #245] Epoch: [4/5][20/31]	Loss: 1.009343
[INFO][11:44:36]: [Client #245] Epoch: [4/5][30/31]	Loss: 1.639396
[INFO][11:44:36]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][11:44:36]: [Client #190] Woke up.
[INFO][11:44:36]: [Client #190] Epoch: [2/5][0/16]	Loss: 0.457041
[INFO][11:44:36]: [Client #190] Epoch: [2/5][10/16]	Loss: 0.581290
[INFO][11:44:36]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:44:40]: [Client #245] Woke up.
[INFO][11:44:40]: [Client #245] Epoch: [5/5][0/31]	Loss: 0.835867
[INFO][11:44:40]: [Client #245] Epoch: [5/5][10/31]	Loss: 1.685884
[INFO][11:44:40]: [Client #245] Epoch: [5/5][20/31]	Loss: 1.285941
[INFO][11:44:40]: [Client #245] Epoch: [5/5][30/31]	Loss: 0.949623
[INFO][11:44:40]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][11:44:44]: [Client #245] Woke up.
[INFO][11:44:44]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][11:44:44]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][11:44:44]: [Client #245] Model trained.
[INFO][11:44:44]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:44:44]: [Server #554754] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][11:44:48]: [Client #190] Woke up.
[INFO][11:44:48]: [Client #190] Epoch: [3/5][0/16]	Loss: 0.644398
[INFO][11:44:48]: [Client #190] Epoch: [3/5][10/16]	Loss: 1.480253
[INFO][11:44:49]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:45:01]: [Client #190] Woke up.
[INFO][11:45:01]: [Client #190] Epoch: [4/5][0/16]	Loss: 0.649738
[INFO][11:45:01]: [Client #190] Epoch: [4/5][10/16]	Loss: 0.409530
[INFO][11:45:01]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:45:13]: [Client #190] Woke up.
[INFO][11:45:13]: [Client #190] Epoch: [5/5][0/16]	Loss: 0.834653
[INFO][11:45:13]: [Client #190] Epoch: [5/5][10/16]	Loss: 0.983084
[INFO][11:45:13]: [Client #190] Going to sleep for 12.30 seconds.
[INFO][11:45:26]: [Client #190] Woke up.
[INFO][11:45:26]: [Client #190] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_554853.pth.
[INFO][11:45:26]: [Client #190] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_190_554853.pth.
[INFO][11:45:26]: [Client #190] Model trained.
[INFO][11:45:26]: [Client #190] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:45:26]: [Server #554754] Received 0.26 MB of payload data from client #190 (simulated).
[INFO][11:45:26]: [Server #554754] Selecting client #124 for training.
[INFO][11:45:26]: [Server #554754] Sending the current model to client #124 (simulated).
[INFO][11:45:26]: [Server #554754] Sending 0.26 MB of payload data to client #124 (simulated).
[INFO][11:45:26]: [Server #554754] Selecting client #445 for training.
[INFO][11:45:26]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][11:45:26]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][11:45:26]: [Client #124] Selected by the server.
[INFO][11:45:26]: [Client #124] Loading its data source...
[INFO][11:45:26]: Data source: FEMNIST
[INFO][11:45:26]: [Client #445] Selected by the server.
[INFO][11:45:26]: [Client #445] Loading its data source...
[INFO][11:45:26]: Data source: FEMNIST
[INFO][11:45:26]: [Client #445] Dataset size: 292
[INFO][11:45:26]: [Client #445] Sampler: all_inclusive
[INFO][11:45:26]: [Client #124] Dataset size: 158
[INFO][11:45:26]: [Client #124] Sampler: all_inclusive
[INFO][11:45:26]: [Client #124] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:45:26]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:45:26]: [93m[1m[Client #124] Started training in communication round #36.[0m
[INFO][11:45:26]: [93m[1m[Client #445] Started training in communication round #36.[0m
[INFO][11:45:28]: [Client #445] Loading the dataset.
[INFO][11:45:28]: [Client #124] Loading the dataset.
[INFO][11:45:34]: [Client #124] Epoch: [1/5][0/16]	Loss: 1.144680
[INFO][11:45:34]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.468520
[INFO][11:45:34]: [Client #124] Epoch: [1/5][10/16]	Loss: 0.335342
[INFO][11:45:34]: [Client #445] Epoch: [1/5][10/30]	Loss: 1.496477
[INFO][11:45:34]: [Client #124] Going to sleep for 0.33 seconds.
[INFO][11:45:34]: [Client #445] Epoch: [1/5][20/30]	Loss: 0.832075
[INFO][11:45:34]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][11:45:34]: [Client #124] Woke up.
[INFO][11:45:34]: [Client #124] Epoch: [2/5][0/16]	Loss: 0.268286
[INFO][11:45:35]: [Client #124] Epoch: [2/5][10/16]	Loss: 0.598721
[INFO][11:45:35]: [Client #124] Going to sleep for 0.33 seconds.
[INFO][11:45:35]: [Client #124] Woke up.
[INFO][11:45:35]: [Client #124] Epoch: [3/5][0/16]	Loss: 0.066694
[INFO][11:45:35]: [Client #124] Epoch: [3/5][10/16]	Loss: 0.302861
[INFO][11:45:35]: [Client #124] Going to sleep for 0.33 seconds.
[INFO][11:45:35]: [Client #124] Woke up.
[INFO][11:45:35]: [Client #124] Epoch: [4/5][0/16]	Loss: 0.237834
[INFO][11:45:36]: [Client #124] Epoch: [4/5][10/16]	Loss: 0.058385
[INFO][11:45:36]: [Client #124] Going to sleep for 0.33 seconds.
[INFO][11:45:36]: [Client #124] Woke up.
[INFO][11:45:36]: [Client #124] Epoch: [5/5][0/16]	Loss: 0.045351
[INFO][11:45:36]: [Client #124] Epoch: [5/5][10/16]	Loss: 0.233831
[INFO][11:45:36]: [Client #124] Going to sleep for 0.33 seconds.
[INFO][11:45:36]: [Client #124] Woke up.
[INFO][11:45:36]: [Client #124] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_124_554853.pth.
[INFO][11:45:37]: [Client #124] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_124_554853.pth.
[INFO][11:45:37]: [Client #124] Model trained.
[INFO][11:45:37]: [Client #124] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:45:37]: [Server #554754] Received 0.26 MB of payload data from client #124 (simulated).
[INFO][11:45:54]: [Client #445] Woke up.
[INFO][11:45:54]: [Client #445] Epoch: [2/5][0/30]	Loss: 0.338061
[INFO][11:45:54]: [Client #445] Epoch: [2/5][10/30]	Loss: 1.545802
[INFO][11:45:54]: [Client #445] Epoch: [2/5][20/30]	Loss: 1.884793
[INFO][11:45:54]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][11:46:14]: [Client #445] Woke up.
[INFO][11:46:14]: [Client #445] Epoch: [3/5][0/30]	Loss: 1.666076
[INFO][11:46:14]: [Client #445] Epoch: [3/5][10/30]	Loss: 1.647944
[INFO][11:46:14]: [Client #445] Epoch: [3/5][20/30]	Loss: 0.487330
[INFO][11:46:14]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][11:46:33]: [Client #445] Woke up.
[INFO][11:46:34]: [Client #445] Epoch: [4/5][0/30]	Loss: 0.483540
[INFO][11:46:34]: [Client #445] Epoch: [4/5][10/30]	Loss: 0.491993
[INFO][11:46:34]: [Client #445] Epoch: [4/5][20/30]	Loss: 0.849777
[INFO][11:46:34]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][11:46:53]: [Client #445] Woke up.
[INFO][11:46:53]: [Client #445] Epoch: [5/5][0/30]	Loss: 0.970617
[INFO][11:46:54]: [Client #445] Epoch: [5/5][10/30]	Loss: 0.868253
[INFO][11:46:54]: [Client #445] Epoch: [5/5][20/30]	Loss: 1.342638
[INFO][11:46:54]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][11:47:13]: [Client #445] Woke up.
[INFO][11:47:13]: [Client #445] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][11:47:14]: [Client #445] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][11:47:14]: [Client #445] Model trained.
[INFO][11:47:14]: [Client #445] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:47:14]: [Server #554754] Received 0.26 MB of payload data from client #445 (simulated).
[INFO][11:47:14]: [Server #554754] Selecting client #189 for training.
[INFO][11:47:14]: [Server #554754] Sending the current model to client #189 (simulated).
[INFO][11:47:14]: [Server #554754] Sending 0.26 MB of payload data to client #189 (simulated).
[INFO][11:47:14]: [Server #554754] Selecting client #146 for training.
[INFO][11:47:14]: [Server #554754] Sending the current model to client #146 (simulated).
[INFO][11:47:14]: [Server #554754] Sending 0.26 MB of payload data to client #146 (simulated).
[INFO][11:47:14]: [Client #146] Selected by the server.
[INFO][11:47:14]: [Client #189] Selected by the server.
[INFO][11:47:14]: [Client #146] Loading its data source...
[INFO][11:47:14]: [Client #189] Loading its data source...
[INFO][11:47:14]: Data source: FEMNIST
[INFO][11:47:14]: Data source: FEMNIST
[INFO][11:47:14]: [Client #146] Dataset size: 156
[INFO][11:47:14]: [Client #146] Sampler: all_inclusive
[INFO][11:47:14]: [Client #146] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:47:14]: [93m[1m[Client #146] Started training in communication round #36.[0m
[INFO][11:47:14]: [Client #189] Dataset size: 302
[INFO][11:47:14]: [Client #189] Sampler: all_inclusive
[INFO][11:47:14]: [Client #189] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:47:14]: [93m[1m[Client #189] Started training in communication round #36.[0m
[INFO][11:47:16]: [Client #146] Loading the dataset.
[INFO][11:47:16]: [Client #189] Loading the dataset.
[INFO][11:47:21]: [Client #146] Epoch: [1/5][0/16]	Loss: 0.306263
[INFO][11:47:21]: [Client #189] Epoch: [1/5][0/31]	Loss: 1.662434
[INFO][11:47:21]: [Client #146] Epoch: [1/5][10/16]	Loss: 0.289791
[INFO][11:47:21]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][11:47:22]: [Client #189] Epoch: [1/5][10/31]	Loss: 0.986434
[INFO][11:47:22]: [Client #146] Woke up.
[INFO][11:47:22]: [Client #189] Epoch: [1/5][20/31]	Loss: 1.719378
[INFO][11:47:22]: [Client #146] Epoch: [2/5][0/16]	Loss: 0.863616
[INFO][11:47:22]: [Client #189] Epoch: [1/5][30/31]	Loss: 0.114479
[INFO][11:47:22]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][11:47:22]: [Client #146] Epoch: [2/5][10/16]	Loss: 0.317304
[INFO][11:47:22]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][11:47:22]: [Client #146] Woke up.
[INFO][11:47:22]: [Client #146] Epoch: [3/5][0/16]	Loss: 0.533353
[INFO][11:47:22]: [Client #146] Epoch: [3/5][10/16]	Loss: 0.916096
[INFO][11:47:22]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][11:47:22]: [Client #146] Woke up.
[INFO][11:47:22]: [Client #146] Epoch: [4/5][0/16]	Loss: 0.542376
[INFO][11:47:22]: [Client #146] Epoch: [4/5][10/16]	Loss: 0.661646
[INFO][11:47:22]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][11:47:22]: [Client #146] Woke up.
[INFO][11:47:22]: [Client #146] Epoch: [5/5][0/16]	Loss: 0.453445
[INFO][11:47:22]: [Client #146] Epoch: [5/5][10/16]	Loss: 0.288462
[INFO][11:47:22]: [Client #146] Going to sleep for 0.12 seconds.
[INFO][11:47:23]: [Client #146] Woke up.
[INFO][11:47:23]: [Client #146] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554860.pth.
[INFO][11:47:23]: [Client #189] Woke up.
[INFO][11:47:23]: [Client #189] Epoch: [2/5][0/31]	Loss: 0.749583
[INFO][11:47:23]: [Client #189] Epoch: [2/5][10/31]	Loss: 1.036028
[INFO][11:47:23]: [Client #189] Epoch: [2/5][20/31]	Loss: 1.051824
[INFO][11:47:23]: [Client #189] Epoch: [2/5][30/31]	Loss: 0.465730
[INFO][11:47:23]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][11:47:23]: [Client #146] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_146_554860.pth.
[INFO][11:47:23]: [Client #146] Model trained.
[INFO][11:47:23]: [Client #146] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:47:23]: [Server #554754] Received 0.26 MB of payload data from client #146 (simulated).
[INFO][11:47:24]: [Client #189] Woke up.
[INFO][11:47:24]: [Client #189] Epoch: [3/5][0/31]	Loss: 1.284989
[INFO][11:47:24]: [Client #189] Epoch: [3/5][10/31]	Loss: 0.723231
[INFO][11:47:24]: [Client #189] Epoch: [3/5][20/31]	Loss: 1.182954
[INFO][11:47:24]: [Client #189] Epoch: [3/5][30/31]	Loss: 0.001661
[INFO][11:47:24]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][11:47:26]: [Client #189] Woke up.
[INFO][11:47:26]: [Client #189] Epoch: [4/5][0/31]	Loss: 0.717900
[INFO][11:47:26]: [Client #189] Epoch: [4/5][10/31]	Loss: 1.568006
[INFO][11:47:26]: [Client #189] Epoch: [4/5][20/31]	Loss: 2.019676
[INFO][11:47:26]: [Client #189] Epoch: [4/5][30/31]	Loss: 1.012575
[INFO][11:47:26]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][11:47:27]: [Client #189] Woke up.
[INFO][11:47:27]: [Client #189] Epoch: [5/5][0/31]	Loss: 1.218633
[INFO][11:47:27]: [Client #189] Epoch: [5/5][10/31]	Loss: 1.642382
[INFO][11:47:27]: [Client #189] Epoch: [5/5][20/31]	Loss: 1.110545
[INFO][11:47:27]: [Client #189] Epoch: [5/5][30/31]	Loss: 2.212920
[INFO][11:47:27]: [Client #189] Going to sleep for 1.10 seconds.
[INFO][11:47:28]: [Client #189] Woke up.
[INFO][11:47:28]: [Client #189] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_189_554853.pth.
[INFO][11:47:29]: [Client #189] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_189_554853.pth.
[INFO][11:47:29]: [Client #189] Model trained.
[INFO][11:47:29]: [Client #189] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:47:29]: [Server #554754] Received 0.26 MB of payload data from client #189 (simulated).
[INFO][11:47:29]: [Server #554754] Selecting client #360 for training.
[INFO][11:47:29]: [Server #554754] Sending the current model to client #360 (simulated).
[INFO][11:47:29]: [Server #554754] Sending 0.26 MB of payload data to client #360 (simulated).
[INFO][11:47:29]: [Server #554754] Selecting client #91 for training.
[INFO][11:47:29]: [Server #554754] Sending the current model to client #91 (simulated).
[INFO][11:47:29]: [Server #554754] Sending 0.26 MB of payload data to client #91 (simulated).
[INFO][11:47:29]: [Client #360] Selected by the server.
[INFO][11:47:29]: [Client #360] Loading its data source...
[INFO][11:47:29]: Data source: FEMNIST
[INFO][11:47:29]: [Client #91] Selected by the server.
[INFO][11:47:29]: [Client #91] Loading its data source...
[INFO][11:47:29]: Data source: FEMNIST
[INFO][11:47:29]: [Client #360] Dataset size: 162
[INFO][11:47:29]: [Client #360] Sampler: all_inclusive
[INFO][11:47:29]: [Client #91] Dataset size: 162
[INFO][11:47:29]: [Client #91] Sampler: all_inclusive
[INFO][11:47:29]: [Client #360] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:47:29]: [Client #91] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:47:29]: [93m[1m[Client #360] Started training in communication round #36.[0m
[INFO][11:47:29]: [93m[1m[Client #91] Started training in communication round #36.[0m
[INFO][11:47:31]: [Client #91] Loading the dataset.
[INFO][11:47:31]: [Client #360] Loading the dataset.
[INFO][11:47:36]: [Client #91] Epoch: [1/5][0/17]	Loss: 1.112811
[INFO][11:47:36]: [Client #360] Epoch: [1/5][0/17]	Loss: 0.581189
[INFO][11:47:36]: [Client #91] Epoch: [1/5][10/17]	Loss: 1.401131
[INFO][11:47:36]: [Client #360] Epoch: [1/5][10/17]	Loss: 0.181865
[INFO][11:47:36]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][11:47:36]: [Client #360] Going to sleep for 60.00 seconds.
[INFO][11:47:37]: [Client #91] Woke up.
[INFO][11:47:37]: [Client #91] Epoch: [2/5][0/17]	Loss: 2.344714
[INFO][11:47:37]: [Client #91] Epoch: [2/5][10/17]	Loss: 1.185003
[INFO][11:47:37]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][11:47:37]: [Client #91] Woke up.
[INFO][11:47:37]: [Client #91] Epoch: [3/5][0/17]	Loss: 1.165122
[INFO][11:47:37]: [Client #91] Epoch: [3/5][10/17]	Loss: 0.985444
[INFO][11:47:37]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][11:47:37]: [Client #91] Woke up.
[INFO][11:47:37]: [Client #91] Epoch: [4/5][0/17]	Loss: 1.255548
[INFO][11:47:37]: [Client #91] Epoch: [4/5][10/17]	Loss: 0.813233
[INFO][11:47:37]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][11:47:37]: [Client #91] Woke up.
[INFO][11:47:37]: [Client #91] Epoch: [5/5][0/17]	Loss: 0.830919
[INFO][11:47:38]: [Client #91] Epoch: [5/5][10/17]	Loss: 0.559581
[INFO][11:47:38]: [Client #91] Going to sleep for 0.13 seconds.
[INFO][11:47:38]: [Client #91] Woke up.
[INFO][11:47:38]: [Client #91] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_91_554860.pth.
[INFO][11:47:38]: [Client #91] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_91_554860.pth.
[INFO][11:47:38]: [Client #91] Model trained.
[INFO][11:47:38]: [Client #91] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:47:38]: [Server #554754] Received 0.26 MB of payload data from client #91 (simulated).
[INFO][11:48:37]: [Client #360] Woke up.
[INFO][11:48:37]: [Client #360] Epoch: [2/5][0/17]	Loss: 0.494898
[INFO][11:48:37]: [Client #360] Epoch: [2/5][10/17]	Loss: 0.152892
[INFO][11:48:37]: [Client #360] Going to sleep for 60.00 seconds.
[INFO][11:49:37]: [Client #360] Woke up.
[INFO][11:49:37]: [Client #360] Epoch: [3/5][0/17]	Loss: 0.295584
[INFO][11:49:37]: [Client #360] Epoch: [3/5][10/17]	Loss: 0.553547
[INFO][11:49:37]: [Client #360] Going to sleep for 60.00 seconds.
[INFO][11:50:37]: [Client #360] Woke up.
[INFO][11:50:37]: [Client #360] Epoch: [4/5][0/17]	Loss: 0.266405
[INFO][11:50:37]: [Client #360] Epoch: [4/5][10/17]	Loss: 0.113436
[INFO][11:50:37]: [Client #360] Going to sleep for 60.00 seconds.
[INFO][11:51:37]: [Client #360] Woke up.
[INFO][11:51:38]: [Client #360] Epoch: [5/5][0/17]	Loss: 0.314690
[INFO][11:51:38]: [Client #360] Epoch: [5/5][10/17]	Loss: 1.240921
[INFO][11:51:38]: [Client #360] Going to sleep for 60.00 seconds.
[INFO][11:52:38]: [Client #360] Woke up.
[INFO][11:52:38]: [Client #360] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_360_554853.pth.
[INFO][11:52:38]: [Client #360] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_360_554853.pth.
[INFO][11:52:38]: [Client #360] Model trained.
[INFO][11:52:38]: [Client #360] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:52:39]: [Server #554754] Received 0.26 MB of payload data from client #360 (simulated).
[INFO][11:52:39]: [Server #554754] Selecting client #60 for training.
[INFO][11:52:39]: [Server #554754] Sending the current model to client #60 (simulated).
[INFO][11:52:39]: [Server #554754] Sending 0.26 MB of payload data to client #60 (simulated).
[INFO][11:52:39]: [Server #554754] Selecting client #421 for training.
[INFO][11:52:39]: [Server #554754] Sending the current model to client #421 (simulated).
[INFO][11:52:39]: [Server #554754] Sending 0.26 MB of payload data to client #421 (simulated).
[INFO][11:52:39]: [Client #60] Selected by the server.
[INFO][11:52:39]: [Client #60] Loading its data source...
[INFO][11:52:39]: Data source: FEMNIST
[INFO][11:52:39]: [Client #421] Selected by the server.
[INFO][11:52:39]: [Client #421] Loading its data source...
[INFO][11:52:39]: Data source: FEMNIST
[INFO][11:52:39]: [Client #421] Dataset size: 160
[INFO][11:52:39]: [Client #421] Sampler: all_inclusive
[INFO][11:52:39]: [Client #60] Dataset size: 162
[INFO][11:52:39]: [Client #60] Sampler: all_inclusive
[INFO][11:52:39]: [Client #421] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:52:39]: [Client #60] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:52:39]: [93m[1m[Client #421] Started training in communication round #36.[0m
[INFO][11:52:39]: [93m[1m[Client #60] Started training in communication round #36.[0m
[INFO][11:52:40]: [Client #60] Loading the dataset.
[INFO][11:52:40]: [Client #421] Loading the dataset.
[INFO][11:52:46]: [Client #60] Epoch: [1/5][0/17]	Loss: 0.603562
[INFO][11:52:46]: [Client #421] Epoch: [1/5][0/16]	Loss: 1.450515
[INFO][11:52:46]: [Client #421] Epoch: [1/5][10/16]	Loss: 0.390877
[INFO][11:52:46]: [Client #60] Epoch: [1/5][10/17]	Loss: 0.519742
[INFO][11:52:46]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][11:52:46]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][11:52:46]: [Client #421] Woke up.
[INFO][11:52:46]: [Client #421] Epoch: [2/5][0/16]	Loss: 0.030224
[INFO][11:52:46]: [Client #421] Epoch: [2/5][10/16]	Loss: 0.784769
[INFO][11:52:46]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][11:52:46]: [Client #421] Woke up.
[INFO][11:52:47]: [Client #421] Epoch: [3/5][0/16]	Loss: 0.283230
[INFO][11:52:47]: [Client #421] Epoch: [3/5][10/16]	Loss: 0.833002
[INFO][11:52:47]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][11:52:47]: [Client #421] Woke up.
[INFO][11:52:47]: [Client #421] Epoch: [4/5][0/16]	Loss: 0.268166
[INFO][11:52:47]: [Client #421] Epoch: [4/5][10/16]	Loss: 1.071866
[INFO][11:52:47]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][11:52:47]: [Client #421] Woke up.
[INFO][11:52:47]: [Client #421] Epoch: [5/5][0/16]	Loss: 0.039703
[INFO][11:52:47]: [Client #421] Epoch: [5/5][10/16]	Loss: 0.647695
[INFO][11:52:47]: [Client #421] Going to sleep for 0.17 seconds.
[INFO][11:52:47]: [Client #421] Woke up.
[INFO][11:52:47]: [Client #421] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_421_554860.pth.
[INFO][11:52:48]: [Client #421] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_421_554860.pth.
[INFO][11:52:48]: [Client #421] Model trained.
[INFO][11:52:48]: [Client #421] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:52:48]: [Server #554754] Received 0.26 MB of payload data from client #421 (simulated).
[INFO][11:52:48]: [Client #60] Woke up.
[INFO][11:52:48]: [Client #60] Epoch: [2/5][0/17]	Loss: 0.530983
[INFO][11:52:48]: [Client #60] Epoch: [2/5][10/17]	Loss: 1.124341
[INFO][11:52:49]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][11:52:51]: [Client #60] Woke up.
[INFO][11:52:51]: [Client #60] Epoch: [3/5][0/17]	Loss: 0.456151
[INFO][11:52:51]: [Client #60] Epoch: [3/5][10/17]	Loss: 0.218588
[INFO][11:52:51]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][11:52:53]: [Client #60] Woke up.
[INFO][11:52:53]: [Client #60] Epoch: [4/5][0/17]	Loss: 0.237129
[INFO][11:52:53]: [Client #60] Epoch: [4/5][10/17]	Loss: 0.148739
[INFO][11:52:53]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][11:52:56]: [Client #60] Woke up.
[INFO][11:52:56]: [Client #60] Epoch: [5/5][0/17]	Loss: 0.146532
[INFO][11:52:56]: [Client #60] Epoch: [5/5][10/17]	Loss: 0.313180
[INFO][11:52:56]: [Client #60] Going to sleep for 2.33 seconds.
[INFO][11:52:58]: [Client #60] Woke up.
[INFO][11:52:58]: [Client #60] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_60_554853.pth.
[INFO][11:52:59]: [Client #60] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_60_554853.pth.
[INFO][11:52:59]: [Client #60] Model trained.
[INFO][11:52:59]: [Client #60] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:52:59]: [Server #554754] Received 0.26 MB of payload data from client #60 (simulated).
[INFO][11:52:59]: [Server #554754] Selecting client #373 for training.
[INFO][11:52:59]: [Server #554754] Sending the current model to client #373 (simulated).
[INFO][11:52:59]: [Server #554754] Sending 0.26 MB of payload data to client #373 (simulated).
[INFO][11:52:59]: [Server #554754] Selecting client #295 for training.
[INFO][11:52:59]: [Server #554754] Sending the current model to client #295 (simulated).
[INFO][11:52:59]: [Server #554754] Sending 0.26 MB of payload data to client #295 (simulated).
[INFO][11:52:59]: [Client #373] Selected by the server.
[INFO][11:52:59]: [Client #373] Loading its data source...
[INFO][11:52:59]: Data source: FEMNIST
[INFO][11:52:59]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:52:59]: [Client #295] Selected by the server.
[INFO][11:52:59]: [Client #295] Loading its data source...
[INFO][11:52:59]: Data source: FEMNIST
[INFO][11:52:59]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/373.zip.
[INFO][11:52:59]: [Client #295] Dataset size: 142
[INFO][11:52:59]: [Client #295] Sampler: all_inclusive
[INFO][11:52:59]: [Client #295] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:52:59]: [93m[1m[Client #295] Started training in communication round #36.[0m

2.4%
4.7%
7.1%
9.5%
11.8%
14.2%
16.6%
18.9%
21.3%
23.7%
26.1%
28.4%
30.8%
33.2%
35.5%
37.9%
40.3%
42.6%
45.0%
47.4%
49.7%
52.1%
54.5%
56.8%
59.2%
61.6%
63.9%
66.3%
68.7%
71.1%
73.4%
75.8%
78.2%
80.5%
82.9%
85.3%
87.6%
90.0%
92.4%
94.7%
97.1%
99.5%
100.0%[INFO][11:52:59]: Decompressing the dataset downloaded.
[INFO][11:52:59]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/373.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:52:59]: [Client #373] Dataset size: 162
[INFO][11:52:59]: [Client #373] Sampler: all_inclusive
[INFO][11:52:59]: [Client #373] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:52:59]: [93m[1m[Client #373] Started training in communication round #36.[0m

[INFO][11:53:01]: [Client #295] Loading the dataset.
[INFO][11:53:01]: [Client #373] Loading the dataset.
[INFO][11:53:06]: [Client #295] Epoch: [1/5][0/15]	Loss: 1.076403
[INFO][11:53:06]: [Client #295] Epoch: [1/5][10/15]	Loss: 0.736702
[INFO][11:53:06]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:53:06]: [Client #373] Epoch: [1/5][0/17]	Loss: 1.404352
[INFO][11:53:06]: [Client #373] Epoch: [1/5][10/17]	Loss: 0.825884
[INFO][11:53:07]: [Client #373] Going to sleep for 0.19 seconds.
[INFO][11:53:07]: [Client #373] Woke up.
[INFO][11:53:07]: [Client #373] Epoch: [2/5][0/17]	Loss: 0.739186
[INFO][11:53:07]: [Client #373] Epoch: [2/5][10/17]	Loss: 0.456132
[INFO][11:53:07]: [Client #373] Going to sleep for 0.19 seconds.
[INFO][11:53:07]: [Client #295] Woke up.
[INFO][11:53:07]: [Client #295] Epoch: [2/5][0/15]	Loss: 0.239331
[INFO][11:53:07]: [Client #295] Epoch: [2/5][10/15]	Loss: 0.266260
[INFO][11:53:07]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:53:07]: [Client #373] Woke up.
[INFO][11:53:07]: [Client #373] Epoch: [3/5][0/17]	Loss: 0.523729
[INFO][11:53:07]: [Client #373] Epoch: [3/5][10/17]	Loss: 0.704583
[INFO][11:53:07]: [Client #373] Going to sleep for 0.19 seconds.
[INFO][11:53:07]: [Client #373] Woke up.
[INFO][11:53:07]: [Client #373] Epoch: [4/5][0/17]	Loss: 0.490218
[INFO][11:53:08]: [Client #295] Woke up.
[INFO][11:53:08]: [Client #373] Epoch: [4/5][10/17]	Loss: 1.358205
[INFO][11:53:08]: [Client #295] Epoch: [3/5][0/15]	Loss: 0.488938
[INFO][11:53:08]: [Client #373] Going to sleep for 0.19 seconds.
[INFO][11:53:08]: [Client #295] Epoch: [3/5][10/15]	Loss: 0.249512
[INFO][11:53:08]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:53:08]: [Client #373] Woke up.
[INFO][11:53:08]: [Client #373] Epoch: [5/5][0/17]	Loss: 0.810254
[INFO][11:53:08]: [Client #373] Epoch: [5/5][10/17]	Loss: 0.819398
[INFO][11:53:08]: [Client #373] Going to sleep for 0.19 seconds.
[INFO][11:53:08]: [Client #373] Woke up.
[INFO][11:53:08]: [Client #373] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_373_554853.pth.
[INFO][11:53:08]: [Client #295] Woke up.
[INFO][11:53:08]: [Client #295] Epoch: [4/5][0/15]	Loss: 0.302379
[INFO][11:53:08]: [Client #295] Epoch: [4/5][10/15]	Loss: 0.508419
[INFO][11:53:08]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:53:09]: [Client #373] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_373_554853.pth.
[INFO][11:53:09]: [Client #373] Model trained.
[INFO][11:53:09]: [Client #373] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:53:09]: [Server #554754] Received 0.26 MB of payload data from client #373 (simulated).
[INFO][11:53:09]: [Client #295] Woke up.
[INFO][11:53:09]: [Client #295] Epoch: [5/5][0/15]	Loss: 0.298461
[INFO][11:53:09]: [Client #295] Epoch: [5/5][10/15]	Loss: 0.509720
[INFO][11:53:09]: [Client #295] Going to sleep for 0.52 seconds.
[INFO][11:53:10]: [Client #295] Woke up.
[INFO][11:53:10]: [Client #295] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:53:10]: [Client #295] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_295_554860.pth.
[INFO][11:53:10]: [Client #295] Model trained.
[INFO][11:53:10]: [Client #295] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:53:10]: [Server #554754] Received 0.26 MB of payload data from client #295 (simulated).
[INFO][11:53:10]: [Server #554754] Selecting client #118 for training.
[INFO][11:53:10]: [Server #554754] Sending the current model to client #118 (simulated).
[INFO][11:53:10]: [Server #554754] Sending 0.26 MB of payload data to client #118 (simulated).
[INFO][11:53:10]: [Server #554754] Selecting client #311 for training.
[INFO][11:53:10]: [Server #554754] Sending the current model to client #311 (simulated).
[INFO][11:53:10]: [Server #554754] Sending 0.26 MB of payload data to client #311 (simulated).
[INFO][11:53:10]: [Client #311] Selected by the server.
[INFO][11:53:10]: [Client #118] Selected by the server.
[INFO][11:53:10]: [Client #311] Loading its data source...
[INFO][11:53:10]: [Client #118] Loading its data source...
[INFO][11:53:10]: Data source: FEMNIST
[INFO][11:53:10]: Data source: FEMNIST
[INFO][11:53:10]: [Client #118] Dataset size: 154
[INFO][11:53:10]: [Client #118] Sampler: all_inclusive
[INFO][11:53:10]: [Client #118] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:53:10]: [93m[1m[Client #118] Started training in communication round #36.[0m
[INFO][11:53:10]: [Client #311] Dataset size: 288
[INFO][11:53:10]: [Client #311] Sampler: all_inclusive
[INFO][11:53:10]: [Client #311] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:53:10]: [93m[1m[Client #311] Started training in communication round #36.[0m
[INFO][11:53:12]: [Client #118] Loading the dataset.
[INFO][11:53:12]: [Client #311] Loading the dataset.
[INFO][11:53:18]: [Client #118] Epoch: [1/5][0/16]	Loss: 0.934906
[INFO][11:53:18]: [Client #118] Epoch: [1/5][10/16]	Loss: 0.712341
[INFO][11:53:18]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][11:53:18]: [Client #311] Epoch: [1/5][0/29]	Loss: 1.776350
[INFO][11:53:18]: [Client #311] Epoch: [1/5][10/29]	Loss: 0.310788
[INFO][11:53:18]: [Client #311] Epoch: [1/5][20/29]	Loss: 0.460294
[INFO][11:53:18]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][11:53:29]: [Client #311] Woke up.
[INFO][11:53:29]: [Client #311] Epoch: [2/5][0/29]	Loss: 0.310569
[INFO][11:53:29]: [Client #311] Epoch: [2/5][10/29]	Loss: 0.383946
[INFO][11:53:29]: [Client #311] Epoch: [2/5][20/29]	Loss: 1.149965
[INFO][11:53:29]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][11:53:30]: [Client #118] Woke up.
[INFO][11:53:30]: [Client #118] Epoch: [2/5][0/16]	Loss: 0.447844
[INFO][11:53:30]: [Client #118] Epoch: [2/5][10/16]	Loss: 1.358234
[INFO][11:53:30]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][11:53:40]: [Client #311] Woke up.
[INFO][11:53:40]: [Client #311] Epoch: [3/5][0/29]	Loss: 1.536244
[INFO][11:53:40]: [Client #311] Epoch: [3/5][10/29]	Loss: 0.283038
[INFO][11:53:40]: [Client #311] Epoch: [3/5][20/29]	Loss: 0.661018
[INFO][11:53:40]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][11:53:42]: [Client #118] Woke up.
[INFO][11:53:42]: [Client #118] Epoch: [3/5][0/16]	Loss: 0.155568
[INFO][11:53:42]: [Client #118] Epoch: [3/5][10/16]	Loss: 0.743126
[INFO][11:53:42]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][11:53:51]: [Client #311] Woke up.
[INFO][11:53:51]: [Client #311] Epoch: [4/5][0/29]	Loss: 0.088472
[INFO][11:53:52]: [Client #311] Epoch: [4/5][10/29]	Loss: 0.777445
[INFO][11:53:52]: [Client #311] Epoch: [4/5][20/29]	Loss: 0.558667
[INFO][11:53:52]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][11:53:54]: [Client #118] Woke up.
[INFO][11:53:54]: [Client #118] Epoch: [4/5][0/16]	Loss: 0.244557
[INFO][11:53:54]: [Client #118] Epoch: [4/5][10/16]	Loss: 0.706240
[INFO][11:53:54]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][11:54:03]: [Client #311] Woke up.
[INFO][11:54:03]: [Client #311] Epoch: [5/5][0/29]	Loss: 0.996487
[INFO][11:54:03]: [Client #311] Epoch: [5/5][10/29]	Loss: 0.731893
[INFO][11:54:03]: [Client #311] Epoch: [5/5][20/29]	Loss: 0.218090
[INFO][11:54:03]: [Client #311] Going to sleep for 10.95 seconds.
[INFO][11:54:06]: [Client #118] Woke up.
[INFO][11:54:06]: [Client #118] Epoch: [5/5][0/16]	Loss: 0.312457
[INFO][11:54:06]: [Client #118] Epoch: [5/5][10/16]	Loss: 0.186811
[INFO][11:54:06]: [Client #118] Going to sleep for 11.99 seconds.
[INFO][11:54:14]: [Client #311] Woke up.
[INFO][11:54:14]: [Client #311] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][11:54:14]: [Client #311] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_311_554860.pth.
[INFO][11:54:14]: [Client #311] Model trained.
[INFO][11:54:15]: [Client #311] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:15]: [Server #554754] Received 0.26 MB of payload data from client #311 (simulated).
[INFO][11:54:18]: [Client #118] Woke up.
[INFO][11:54:18]: [Client #118] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_118_554853.pth.
[INFO][11:54:19]: [Client #118] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_118_554853.pth.
[INFO][11:54:19]: [Client #118] Model trained.
[INFO][11:54:19]: [Client #118] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:19]: [Server #554754] Received 0.26 MB of payload data from client #118 (simulated).
[INFO][11:54:19]: [Server #554754] Selecting client #319 for training.
[INFO][11:54:19]: [Server #554754] Sending the current model to client #319 (simulated).
[INFO][11:54:19]: [Server #554754] Sending 0.26 MB of payload data to client #319 (simulated).
[INFO][11:54:19]: [Server #554754] Selecting client #161 for training.
[INFO][11:54:19]: [Server #554754] Sending the current model to client #161 (simulated).
[INFO][11:54:19]: [Server #554754] Sending 0.26 MB of payload data to client #161 (simulated).
[INFO][11:54:19]: [Client #319] Selected by the server.
[INFO][11:54:19]: [Client #319] Loading its data source...
[INFO][11:54:19]: [Client #161] Selected by the server.
[INFO][11:54:19]: Data source: FEMNIST
[INFO][11:54:19]: [Client #161] Loading its data source...
[INFO][11:54:19]: Data source: FEMNIST
[INFO][11:54:19]: [Client #319] Dataset size: 159
[INFO][11:54:19]: [Client #319] Sampler: all_inclusive
[INFO][11:54:19]: [Client #319] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:54:19]: [93m[1m[Client #319] Started training in communication round #36.[0m
[INFO][11:54:19]: [Client #161] Dataset size: 153
[INFO][11:54:19]: [Client #161] Sampler: all_inclusive
[INFO][11:54:19]: [Client #161] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:54:19]: [93m[1m[Client #161] Started training in communication round #36.[0m
[INFO][11:54:21]: [Client #319] Loading the dataset.
[INFO][11:54:21]: [Client #161] Loading the dataset.
[INFO][11:54:26]: [Client #161] Epoch: [1/5][0/16]	Loss: 0.272253
[INFO][11:54:26]: [Client #319] Epoch: [1/5][0/16]	Loss: 0.424781
[INFO][11:54:26]: [Client #161] Epoch: [1/5][10/16]	Loss: 0.233199
[INFO][11:54:27]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][11:54:27]: [Client #319] Epoch: [1/5][10/16]	Loss: 0.677778
[INFO][11:54:27]: [Client #319] Going to sleep for 0.33 seconds.
[INFO][11:54:27]: [Client #161] Woke up.
[INFO][11:54:27]: [Client #161] Epoch: [2/5][0/16]	Loss: 0.621702
[INFO][11:54:27]: [Client #161] Epoch: [2/5][10/16]	Loss: 0.185132
[INFO][11:54:27]: [Client #319] Woke up.
[INFO][11:54:27]: [Client #319] Epoch: [2/5][0/16]	Loss: 0.224578
[INFO][11:54:27]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][11:54:27]: [Client #319] Epoch: [2/5][10/16]	Loss: 0.182927
[INFO][11:54:27]: [Client #319] Going to sleep for 0.33 seconds.
[INFO][11:54:27]: [Client #161] Woke up.
[INFO][11:54:27]: [Client #161] Epoch: [3/5][0/16]	Loss: 1.116509
[INFO][11:54:27]: [Client #161] Epoch: [3/5][10/16]	Loss: 0.195825
[INFO][11:54:27]: [Client #319] Woke up.
[INFO][11:54:27]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][11:54:27]: [Client #319] Epoch: [3/5][0/16]	Loss: 1.048840
[INFO][11:54:28]: [Client #319] Epoch: [3/5][10/16]	Loss: 0.959139
[INFO][11:54:28]: [Client #319] Going to sleep for 0.33 seconds.
[INFO][11:54:28]: [Client #161] Woke up.
[INFO][11:54:28]: [Client #161] Epoch: [4/5][0/16]	Loss: 1.132802
[INFO][11:54:28]: [Client #161] Epoch: [4/5][10/16]	Loss: 0.414205
[INFO][11:54:28]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][11:54:28]: [Client #319] Woke up.
[INFO][11:54:28]: [Client #319] Epoch: [4/5][0/16]	Loss: 1.055252
[INFO][11:54:28]: [Client #319] Epoch: [4/5][10/16]	Loss: 0.701457
[INFO][11:54:28]: [Client #319] Going to sleep for 0.33 seconds.
[INFO][11:54:28]: [Client #161] Woke up.
[INFO][11:54:28]: [Client #161] Epoch: [5/5][0/16]	Loss: 0.383316
[INFO][11:54:28]: [Client #161] Epoch: [5/5][10/16]	Loss: 2.028518
[INFO][11:54:28]: [Client #161] Going to sleep for 0.32 seconds.
[INFO][11:54:28]: [Client #319] Woke up.
[INFO][11:54:28]: [Client #319] Epoch: [5/5][0/16]	Loss: 0.068348
[INFO][11:54:29]: [Client #319] Epoch: [5/5][10/16]	Loss: 0.800656
[INFO][11:54:29]: [Client #319] Going to sleep for 0.33 seconds.
[INFO][11:54:29]: [Client #161] Woke up.
[INFO][11:54:29]: [Client #161] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_161_554860.pth.
[INFO][11:54:29]: [Client #319] Woke up.
[INFO][11:54:29]: [Client #319] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_319_554853.pth.
[INFO][11:54:29]: [Client #161] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_161_554860.pth.
[INFO][11:54:29]: [Client #161] Model trained.
[INFO][11:54:29]: [Client #161] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:29]: [Server #554754] Received 0.26 MB of payload data from client #161 (simulated).
[INFO][11:54:30]: [Client #319] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_319_554853.pth.
[INFO][11:54:30]: [Client #319] Model trained.
[INFO][11:54:30]: [Client #319] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:30]: [Server #554754] Received 0.26 MB of payload data from client #319 (simulated).
[INFO][11:54:30]: [Server #554754] Selecting client #35 for training.
[INFO][11:54:30]: [Server #554754] Sending the current model to client #35 (simulated).
[INFO][11:54:30]: [Server #554754] Sending 0.26 MB of payload data to client #35 (simulated).
[INFO][11:54:30]: [Server #554754] Selecting client #443 for training.
[INFO][11:54:30]: [Server #554754] Sending the current model to client #443 (simulated).
[INFO][11:54:30]: [Server #554754] Sending 0.26 MB of payload data to client #443 (simulated).
[INFO][11:54:30]: [Client #35] Selected by the server.
[INFO][11:54:30]: [Client #35] Loading its data source...
[INFO][11:54:30]: Data source: FEMNIST
[INFO][11:54:30]: [Client #443] Selected by the server.
[INFO][11:54:30]: [Client #443] Loading its data source...
[INFO][11:54:30]: Data source: FEMNIST
[INFO][11:54:30]: [Client #35] Dataset size: 147
[INFO][11:54:30]: [Client #35] Sampler: all_inclusive
[INFO][11:54:30]: [Client #443] Dataset size: 164
[INFO][11:54:30]: [Client #443] Sampler: all_inclusive
[INFO][11:54:30]: [Client #35] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:54:30]: [Client #443] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:54:30]: [93m[1m[Client #35] Started training in communication round #36.[0m
[INFO][11:54:30]: [93m[1m[Client #443] Started training in communication round #36.[0m
[INFO][11:54:32]: [Client #35] Loading the dataset.
[INFO][11:54:32]: [Client #443] Loading the dataset.
[INFO][11:54:37]: [Client #35] Epoch: [1/5][0/15]	Loss: 1.081907
[INFO][11:54:37]: [Client #443] Epoch: [1/5][0/17]	Loss: 1.095805
[INFO][11:54:37]: [Client #35] Epoch: [1/5][10/15]	Loss: 0.094489
[INFO][11:54:37]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][11:54:37]: [Client #443] Epoch: [1/5][10/17]	Loss: 0.914116
[INFO][11:54:37]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][11:54:38]: [Client #443] Woke up.
[INFO][11:54:38]: [Client #443] Epoch: [2/5][0/17]	Loss: 0.112624
[INFO][11:54:39]: [Client #443] Epoch: [2/5][10/17]	Loss: 0.432298
[INFO][11:54:39]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][11:54:39]: [Client #35] Woke up.
[INFO][11:54:39]: [Client #35] Epoch: [2/5][0/15]	Loss: 0.255790
[INFO][11:54:40]: [Client #35] Epoch: [2/5][10/15]	Loss: 1.223149
[INFO][11:54:40]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][11:54:40]: [Client #443] Woke up.
[INFO][11:54:40]: [Client #443] Epoch: [3/5][0/17]	Loss: 0.259292
[INFO][11:54:40]: [Client #443] Epoch: [3/5][10/17]	Loss: 0.904104
[INFO][11:54:40]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][11:54:41]: [Client #443] Woke up.
[INFO][11:54:41]: [Client #443] Epoch: [4/5][0/17]	Loss: 0.589262
[INFO][11:54:41]: [Client #443] Epoch: [4/5][10/17]	Loss: 2.327267
[INFO][11:54:41]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][11:54:42]: [Client #35] Woke up.
[INFO][11:54:42]: [Client #35] Epoch: [3/5][0/15]	Loss: 0.559397
[INFO][11:54:42]: [Client #35] Epoch: [3/5][10/15]	Loss: 1.437389
[INFO][11:54:42]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][11:54:42]: [Client #443] Woke up.
[INFO][11:54:42]: [Client #443] Epoch: [5/5][0/17]	Loss: 0.144471
[INFO][11:54:43]: [Client #443] Epoch: [5/5][10/17]	Loss: 0.646987
[INFO][11:54:43]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][11:54:44]: [Client #443] Woke up.
[INFO][11:54:44]: [Client #443] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][11:54:44]: [Client #35] Woke up.
[INFO][11:54:44]: [Client #35] Epoch: [4/5][0/15]	Loss: 0.437613
[INFO][11:54:44]: [Client #35] Epoch: [4/5][10/15]	Loss: 1.637264
[INFO][11:54:44]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][11:54:44]: [Client #443] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][11:54:44]: [Client #443] Model trained.
[INFO][11:54:44]: [Client #443] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:44]: [Server #554754] Received 0.26 MB of payload data from client #443 (simulated).
[INFO][11:54:47]: [Client #35] Woke up.
[INFO][11:54:47]: [Client #35] Epoch: [5/5][0/15]	Loss: 0.178986
[INFO][11:54:47]: [Client #35] Epoch: [5/5][10/15]	Loss: 0.532086
[INFO][11:54:47]: [Client #35] Going to sleep for 2.25 seconds.
[INFO][11:54:49]: [Client #35] Woke up.
[INFO][11:54:49]: [Client #35] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_554853.pth.
[INFO][11:54:50]: [Client #35] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_35_554853.pth.
[INFO][11:54:50]: [Client #35] Model trained.
[INFO][11:54:50]: [Client #35] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:54:50]: [Server #554754] Received 0.26 MB of payload data from client #35 (simulated).
[INFO][11:54:50]: [Server #554754] Adding client #146 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #91 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #421 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #373 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #161 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #124 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #319 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #466 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #295 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Adding client #443 to the list of clients for aggregation.
[INFO][11:54:50]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.25034954 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06442006 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10351958 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16950756 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08097869 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09597928 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16614834 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06633615 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09057327 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.22972943 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.25034954 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.06442006 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10351958 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16950756 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08097869 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09597928 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.16614834 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.06633615 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09057327 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.22972943 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][11:55:33]: [Server #554754] Global model accuracy: 62.94%

[INFO][11:55:33]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_36.pth.
[INFO][11:55:33]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_36.pth.
[INFO][11:55:33]: [93m[1m
[Server #554754] Starting round 37/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.08952497 0.09055338
 0.002      0.04880988 0.09412436 0.08664058 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.002
 0.04639175 0.04700211 0.08958697 0.002      0.002      0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.09808917 0.04912068 0.08415301
 0.09380531 0.002      0.19260486 0.10012674 0.08619749 0.04775772
 0.09184256 0.08619749 0.002      0.002      0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.09390547 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.002
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.1012987  0.002
 0.05069552 0.04972711 0.16072379 0.04820729 0.08803006 0.100894
 0.002      0.10063694 0.10344828 0.002      0.002      0.10714286
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04880988 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.002      0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.10438144 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.16448087 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.05352394 0.002      0.0473034  0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.1577218  0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.002
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.002
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10392902 0.15096419
 0.16878613 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.1026616  0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][11:55:33]: [Server #554754] Selected clients: [232 384 128 297 217 193  65 123  40 152]
[INFO][11:55:33]: [Server #554754] Selecting client #232 for training.
[INFO][11:55:33]: [Server #554754] Sending the current model to client #232 (simulated).
[INFO][11:55:33]: [Server #554754] Sending 0.26 MB of payload data to client #232 (simulated).
[INFO][11:55:33]: [Server #554754] Selecting client #384 for training.
[INFO][11:55:33]: [Server #554754] Sending the current model to client #384 (simulated).
[INFO][11:55:33]: [Server #554754] Sending 0.26 MB of payload data to client #384 (simulated).
[INFO][11:55:33]: [Client #232] Selected by the server.
[INFO][11:55:33]: [Client #232] Loading its data source...
[INFO][11:55:33]: Data source: FEMNIST
[INFO][11:55:33]: [Client #384] Selected by the server.
[INFO][11:55:33]: [Client #384] Loading its data source...
[INFO][11:55:33]: Data source: FEMNIST
[INFO][11:55:33]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][11:55:33]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/384.zip.
[INFO][11:55:33]: [Client #232] Dataset size: 162
[INFO][11:55:33]: [Client #232] Sampler: all_inclusive
[INFO][11:55:33]: [Client #232] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:55:33]: [93m[1m[Client #232] Started training in communication round #37.[0m

2.6%
5.3%
7.9%
10.6%
13.2%
15.9%
18.5%
21.2%
23.8%
26.5%
29.1%
31.7%
34.4%
37.0%
39.7%
42.3%
45.0%
47.6%
50.3%
52.9%
55.5%
58.2%
60.8%
63.5%
66.1%
68.8%
71.4%
74.1%
76.7%
79.4%
82.0%
84.6%
87.3%
89.9%
92.6%
95.2%
97.9%
100.0%[INFO][11:55:34]: Decompressing the dataset downloaded.
[INFO][11:55:34]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/384.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][11:55:34]: [Client #384] Dataset size: 131
[INFO][11:55:34]: [Client #384] Sampler: all_inclusive
[INFO][11:55:34]: [Client #384] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:55:34]: [93m[1m[Client #384] Started training in communication round #37.[0m

[INFO][11:55:35]: [Client #232] Loading the dataset.
[INFO][11:55:36]: [Client #384] Loading the dataset.
[INFO][11:55:41]: [Client #232] Epoch: [1/5][0/17]	Loss: 0.878795
[INFO][11:55:41]: [Client #232] Epoch: [1/5][10/17]	Loss: 0.630070
[INFO][11:55:41]: [Client #384] Epoch: [1/5][0/14]	Loss: 1.120669
[INFO][11:55:41]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][11:55:41]: [Client #384] Epoch: [1/5][10/14]	Loss: 1.240903
[INFO][11:55:41]: [Client #384] Going to sleep for 0.26 seconds.
[INFO][11:55:41]: [Client #384] Woke up.
[INFO][11:55:41]: [Client #384] Epoch: [2/5][0/14]	Loss: 0.321224
[INFO][11:55:41]: [Client #384] Epoch: [2/5][10/14]	Loss: 0.598945
[INFO][11:55:41]: [Client #384] Going to sleep for 0.26 seconds.
[INFO][11:55:42]: [Client #384] Woke up.
[INFO][11:55:42]: [Client #384] Epoch: [3/5][0/14]	Loss: 0.643682
[INFO][11:55:42]: [Client #384] Epoch: [3/5][10/14]	Loss: 2.135849
[INFO][11:55:42]: [Client #384] Going to sleep for 0.26 seconds.
[INFO][11:55:42]: [Client #384] Woke up.
[INFO][11:55:42]: [Client #384] Epoch: [4/5][0/14]	Loss: 1.143870
[INFO][11:55:42]: [Client #232] Woke up.
[INFO][11:55:42]: [Client #232] Epoch: [2/5][0/17]	Loss: 0.425778
[INFO][11:55:42]: [Client #384] Epoch: [4/5][10/14]	Loss: 1.479409
[INFO][11:55:42]: [Client #384] Going to sleep for 0.26 seconds.
[INFO][11:55:42]: [Client #232] Epoch: [2/5][10/17]	Loss: 0.975929
[INFO][11:55:42]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][11:55:42]: [Client #384] Woke up.
[INFO][11:55:42]: [Client #384] Epoch: [5/5][0/14]	Loss: 0.606874
[INFO][11:55:43]: [Client #384] Epoch: [5/5][10/14]	Loss: 1.309272
[INFO][11:55:43]: [Client #384] Going to sleep for 0.26 seconds.
[INFO][11:55:43]: [Client #384] Woke up.
[INFO][11:55:43]: [Client #384] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_384_554860.pth.
[INFO][11:55:43]: [Client #232] Woke up.
[INFO][11:55:43]: [Client #232] Epoch: [3/5][0/17]	Loss: 0.469877
[INFO][11:55:43]: [Client #384] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_384_554860.pth.
[INFO][11:55:43]: [Client #384] Model trained.
[INFO][11:55:43]: [Client #384] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:55:43]: [Server #554754] Received 0.26 MB of payload data from client #384 (simulated).
[INFO][11:55:44]: [Client #232] Epoch: [3/5][10/17]	Loss: 0.295323
[INFO][11:55:44]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][11:55:45]: [Client #232] Woke up.
[INFO][11:55:45]: [Client #232] Epoch: [4/5][0/17]	Loss: 0.544853
[INFO][11:55:45]: [Client #232] Epoch: [4/5][10/17]	Loss: 0.910614
[INFO][11:55:45]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][11:55:46]: [Client #232] Woke up.
[INFO][11:55:46]: [Client #232] Epoch: [5/5][0/17]	Loss: 0.508943
[INFO][11:55:46]: [Client #232] Epoch: [5/5][10/17]	Loss: 0.366540
[INFO][11:55:46]: [Client #232] Going to sleep for 1.20 seconds.
[INFO][11:55:47]: [Client #232] Woke up.
[INFO][11:55:47]: [Client #232] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][11:55:48]: [Client #232] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_232_554853.pth.
[INFO][11:55:48]: [Client #232] Model trained.
[INFO][11:55:48]: [Client #232] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:55:48]: [Server #554754] Received 0.26 MB of payload data from client #232 (simulated).
[INFO][11:55:48]: [Server #554754] Selecting client #128 for training.
[INFO][11:55:48]: [Server #554754] Sending the current model to client #128 (simulated).
[INFO][11:55:48]: [Server #554754] Sending 0.26 MB of payload data to client #128 (simulated).
[INFO][11:55:48]: [Server #554754] Selecting client #297 for training.
[INFO][11:55:48]: [Server #554754] Sending the current model to client #297 (simulated).
[INFO][11:55:48]: [Server #554754] Sending 0.26 MB of payload data to client #297 (simulated).
[INFO][11:55:48]: [Client #128] Selected by the server.
[INFO][11:55:48]: [Client #128] Loading its data source...
[INFO][11:55:48]: Data source: FEMNIST
[INFO][11:55:48]: [Client #297] Selected by the server.
[INFO][11:55:48]: [Client #297] Loading its data source...
[INFO][11:55:48]: Data source: FEMNIST
[INFO][11:55:48]: [Client #128] Dataset size: 158
[INFO][11:55:48]: [Client #128] Sampler: all_inclusive
[INFO][11:55:48]: [Client #297] Dataset size: 161
[INFO][11:55:48]: [Client #297] Sampler: all_inclusive
[INFO][11:55:48]: [Client #128] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:55:48]: [Client #297] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:55:48]: [93m[1m[Client #128] Started training in communication round #37.[0m
[INFO][11:55:48]: [93m[1m[Client #297] Started training in communication round #37.[0m
[INFO][11:55:50]: [Client #297] Loading the dataset.
[INFO][11:55:50]: [Client #128] Loading the dataset.
[INFO][11:55:55]: [Client #297] Epoch: [1/5][0/17]	Loss: 0.521325
[INFO][11:55:55]: [Client #128] Epoch: [1/5][0/16]	Loss: 0.250541
[INFO][11:55:55]: [Client #297] Epoch: [1/5][10/17]	Loss: 0.506947
[INFO][11:55:56]: [Client #128] Epoch: [1/5][10/16]	Loss: 0.769744
[INFO][11:55:56]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][11:55:56]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][11:55:56]: [Client #297] Woke up.
[INFO][11:55:56]: [Client #297] Epoch: [2/5][0/17]	Loss: 0.568575
[INFO][11:55:56]: [Client #297] Epoch: [2/5][10/17]	Loss: 0.187835
[INFO][11:55:56]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][11:55:57]: [Client #297] Woke up.
[INFO][11:55:57]: [Client #297] Epoch: [3/5][0/17]	Loss: 0.118719
[INFO][11:55:57]: [Client #297] Epoch: [3/5][10/17]	Loss: 1.164773
[INFO][11:55:57]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][11:55:58]: [Client #297] Woke up.
[INFO][11:55:58]: [Client #297] Epoch: [4/5][0/17]	Loss: 0.189784
[INFO][11:55:58]: [Client #297] Epoch: [4/5][10/17]	Loss: 0.391641
[INFO][11:55:58]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][11:55:58]: [Client #297] Woke up.
[INFO][11:55:58]: [Client #297] Epoch: [5/5][0/17]	Loss: 0.260064
[INFO][11:55:59]: [Client #297] Epoch: [5/5][10/17]	Loss: 0.670731
[INFO][11:55:59]: [Client #297] Going to sleep for 0.61 seconds.
[INFO][11:55:59]: [Client #297] Woke up.
[INFO][11:55:59]: [Client #297] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_297_554860.pth.
[INFO][11:56:00]: [Client #297] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_297_554860.pth.
[INFO][11:56:00]: [Client #297] Model trained.
[INFO][11:56:00]: [Client #297] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:00]: [Server #554754] Received 0.26 MB of payload data from client #297 (simulated).
[INFO][11:56:01]: [Client #128] Woke up.
[INFO][11:56:01]: [Client #128] Epoch: [2/5][0/16]	Loss: 0.042564
[INFO][11:56:01]: [Client #128] Epoch: [2/5][10/16]	Loss: 0.372067
[INFO][11:56:01]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][11:56:06]: [Client #128] Woke up.
[INFO][11:56:06]: [Client #128] Epoch: [3/5][0/16]	Loss: 0.194578
[INFO][11:56:07]: [Client #128] Epoch: [3/5][10/16]	Loss: 0.267301
[INFO][11:56:07]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][11:56:12]: [Client #128] Woke up.
[INFO][11:56:12]: [Client #128] Epoch: [4/5][0/16]	Loss: 0.149885
[INFO][11:56:12]: [Client #128] Epoch: [4/5][10/16]	Loss: 0.599293
[INFO][11:56:12]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][11:56:17]: [Client #128] Woke up.
[INFO][11:56:17]: [Client #128] Epoch: [5/5][0/16]	Loss: 0.206261
[INFO][11:56:17]: [Client #128] Epoch: [5/5][10/16]	Loss: 0.006509
[INFO][11:56:18]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][11:56:23]: [Client #128] Woke up.
[INFO][11:56:23]: [Client #128] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554853.pth.
[INFO][11:56:23]: [Client #128] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554853.pth.
[INFO][11:56:24]: [Client #128] Model trained.
[INFO][11:56:24]: [Client #128] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:24]: [Server #554754] Received 0.26 MB of payload data from client #128 (simulated).
[INFO][11:56:24]: [Server #554754] Selecting client #217 for training.
[INFO][11:56:24]: [Server #554754] Sending the current model to client #217 (simulated).
[INFO][11:56:24]: [Server #554754] Sending 0.26 MB of payload data to client #217 (simulated).
[INFO][11:56:24]: [Server #554754] Selecting client #193 for training.
[INFO][11:56:24]: [Server #554754] Sending the current model to client #193 (simulated).
[INFO][11:56:24]: [Server #554754] Sending 0.26 MB of payload data to client #193 (simulated).
[INFO][11:56:24]: [Client #217] Selected by the server.
[INFO][11:56:24]: [Client #217] Loading its data source...
[INFO][11:56:24]: Data source: FEMNIST
[INFO][11:56:24]: [Client #193] Selected by the server.
[INFO][11:56:24]: [Client #193] Loading its data source...
[INFO][11:56:24]: Data source: FEMNIST
[INFO][11:56:24]: [Client #217] Dataset size: 143
[INFO][11:56:24]: [Client #217] Sampler: all_inclusive
[INFO][11:56:24]: [Client #217] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:24]: [93m[1m[Client #217] Started training in communication round #37.[0m
[INFO][11:56:24]: [Client #193] Dataset size: 157
[INFO][11:56:24]: [Client #193] Sampler: all_inclusive
[INFO][11:56:24]: [Client #193] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:24]: [93m[1m[Client #193] Started training in communication round #37.[0m
[INFO][11:56:25]: [Client #217] Loading the dataset.
[INFO][11:56:26]: [Client #193] Loading the dataset.
[INFO][11:56:31]: [Client #217] Epoch: [1/5][0/15]	Loss: 1.136384
[INFO][11:56:31]: [Client #193] Epoch: [1/5][0/16]	Loss: 0.879318
[INFO][11:56:31]: [Client #217] Epoch: [1/5][10/15]	Loss: 2.155141
[INFO][11:56:31]: [Client #193] Epoch: [1/5][10/16]	Loss: 0.368706
[INFO][11:56:31]: [Client #217] Going to sleep for 0.02 seconds.
[INFO][11:56:31]: [Client #217] Woke up.
[INFO][11:56:31]: [Client #193] Going to sleep for 2.77 seconds.
[INFO][11:56:31]: [Client #217] Epoch: [2/5][0/15]	Loss: 1.269086
[INFO][11:56:31]: [Client #217] Epoch: [2/5][10/15]	Loss: 0.284517
[INFO][11:56:31]: [Client #217] Going to sleep for 0.02 seconds.
[INFO][11:56:31]: [Client #217] Woke up.
[INFO][11:56:31]: [Client #217] Epoch: [3/5][0/15]	Loss: 1.723782
[INFO][11:56:31]: [Client #217] Epoch: [3/5][10/15]	Loss: 1.470391
[INFO][11:56:31]: [Client #217] Going to sleep for 0.02 seconds.
[INFO][11:56:31]: [Client #217] Woke up.
[INFO][11:56:31]: [Client #217] Epoch: [4/5][0/15]	Loss: 0.361722
[INFO][11:56:31]: [Client #217] Epoch: [4/5][10/15]	Loss: 0.790638
[INFO][11:56:31]: [Client #217] Going to sleep for 0.02 seconds.
[INFO][11:56:32]: [Client #217] Woke up.
[INFO][11:56:32]: [Client #217] Epoch: [5/5][0/15]	Loss: 0.998183
[INFO][11:56:32]: [Client #217] Epoch: [5/5][10/15]	Loss: 1.025515
[INFO][11:56:32]: [Client #217] Going to sleep for 0.02 seconds.
[INFO][11:56:32]: [Client #217] Woke up.
[INFO][11:56:32]: [Client #217] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_217_554853.pth.
[INFO][11:56:32]: [Client #217] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_217_554853.pth.
[INFO][11:56:32]: [Client #217] Model trained.
[INFO][11:56:32]: [Client #217] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:32]: [Server #554754] Received 0.26 MB of payload data from client #217 (simulated).
[INFO][11:56:34]: [Client #193] Woke up.
[INFO][11:56:34]: [Client #193] Epoch: [2/5][0/16]	Loss: 0.689834
[INFO][11:56:34]: [Client #193] Epoch: [2/5][10/16]	Loss: 1.673250
[INFO][11:56:34]: [Client #193] Going to sleep for 2.77 seconds.
[INFO][11:56:37]: [Client #193] Woke up.
[INFO][11:56:37]: [Client #193] Epoch: [3/5][0/16]	Loss: 0.821589
[INFO][11:56:37]: [Client #193] Epoch: [3/5][10/16]	Loss: 0.222655
[INFO][11:56:37]: [Client #193] Going to sleep for 2.77 seconds.
[INFO][11:56:40]: [Client #193] Woke up.
[INFO][11:56:40]: [Client #193] Epoch: [4/5][0/16]	Loss: 0.285732
[INFO][11:56:40]: [Client #193] Epoch: [4/5][10/16]	Loss: 0.194756
[INFO][11:56:40]: [Client #193] Going to sleep for 2.77 seconds.
[INFO][11:56:43]: [Client #193] Woke up.
[INFO][11:56:43]: [Client #193] Epoch: [5/5][0/16]	Loss: 0.471584
[INFO][11:56:43]: [Client #193] Epoch: [5/5][10/16]	Loss: 0.174336
[INFO][11:56:43]: [Client #193] Going to sleep for 2.77 seconds.
[INFO][11:56:46]: [Client #193] Woke up.
[INFO][11:56:46]: [Client #193] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_193_554860.pth.
[INFO][11:56:46]: [Client #193] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_193_554860.pth.
[INFO][11:56:46]: [Client #193] Model trained.
[INFO][11:56:46]: [Client #193] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:46]: [Server #554754] Received 0.26 MB of payload data from client #193 (simulated).
[INFO][11:56:46]: [Server #554754] Selecting client #65 for training.
[INFO][11:56:46]: [Server #554754] Sending the current model to client #65 (simulated).
[INFO][11:56:46]: [Server #554754] Sending 0.26 MB of payload data to client #65 (simulated).
[INFO][11:56:46]: [Server #554754] Selecting client #123 for training.
[INFO][11:56:46]: [Server #554754] Sending the current model to client #123 (simulated).
[INFO][11:56:46]: [Server #554754] Sending 0.26 MB of payload data to client #123 (simulated).
[INFO][11:56:46]: [Client #65] Selected by the server.
[INFO][11:56:46]: [Client #65] Loading its data source...
[INFO][11:56:46]: [Client #123] Selected by the server.
[INFO][11:56:46]: Data source: FEMNIST
[INFO][11:56:46]: [Client #123] Loading its data source...
[INFO][11:56:46]: Data source: FEMNIST
[INFO][11:56:46]: [Client #65] Dataset size: 162
[INFO][11:56:46]: [Client #65] Sampler: all_inclusive
[INFO][11:56:46]: [Client #65] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:46]: [93m[1m[Client #65] Started training in communication round #37.[0m
[INFO][11:56:46]: [Client #123] Dataset size: 349
[INFO][11:56:46]: [Client #123] Sampler: all_inclusive
[INFO][11:56:46]: [Client #123] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:46]: [93m[1m[Client #123] Started training in communication round #37.[0m
[INFO][11:56:48]: [Client #123] Loading the dataset.
[INFO][11:56:48]: [Client #65] Loading the dataset.
[INFO][11:56:54]: [Client #123] Epoch: [1/5][0/35]	Loss: 0.828885
[INFO][11:56:54]: [Client #65] Epoch: [1/5][0/17]	Loss: 0.542840
[INFO][11:56:54]: [Client #123] Epoch: [1/5][10/35]	Loss: 1.394456
[INFO][11:56:54]: [Client #65] Epoch: [1/5][10/17]	Loss: 0.058709
[INFO][11:56:54]: [Client #123] Epoch: [1/5][20/35]	Loss: 0.547719
[INFO][11:56:54]: [Client #65] Going to sleep for 0.05 seconds.
[INFO][11:56:54]: [Client #123] Epoch: [1/5][30/35]	Loss: 2.004148
[INFO][11:56:54]: [Client #65] Woke up.
[INFO][11:56:54]: [Client #65] Epoch: [2/5][0/17]	Loss: 0.327684
[INFO][11:56:54]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][11:56:54]: [Client #123] Woke up.
[INFO][11:56:54]: [Client #123] Epoch: [2/5][0/35]	Loss: 0.235277
[INFO][11:56:54]: [Client #65] Epoch: [2/5][10/17]	Loss: 1.201092
[INFO][11:56:54]: [Client #123] Epoch: [2/5][10/35]	Loss: 1.833964
[INFO][11:56:54]: [Client #65] Going to sleep for 0.05 seconds.
[INFO][11:56:54]: [Client #65] Woke up.
[INFO][11:56:54]: [Client #123] Epoch: [2/5][20/35]	Loss: 0.908045
[INFO][11:56:54]: [Client #65] Epoch: [3/5][0/17]	Loss: 0.878839
[INFO][11:56:54]: [Client #123] Epoch: [2/5][30/35]	Loss: 1.951532
[INFO][11:56:54]: [Client #65] Epoch: [3/5][10/17]	Loss: 0.509294
[INFO][11:56:54]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][11:56:54]: [Client #123] Woke up.
[INFO][11:56:54]: [Client #65] Going to sleep for 0.05 seconds.
[INFO][11:56:54]: [Client #123] Epoch: [3/5][0/35]	Loss: 0.057220
[INFO][11:56:54]: [Client #65] Woke up.
[INFO][11:56:54]: [Client #65] Epoch: [4/5][0/17]	Loss: 0.384721
[INFO][11:56:54]: [Client #123] Epoch: [3/5][10/35]	Loss: 0.122272
[INFO][11:56:54]: [Client #65] Epoch: [4/5][10/17]	Loss: 1.807433
[INFO][11:56:54]: [Client #123] Epoch: [3/5][20/35]	Loss: 0.584450
[INFO][11:56:54]: [Client #65] Going to sleep for 0.05 seconds.
[INFO][11:56:54]: [Client #123] Epoch: [3/5][30/35]	Loss: 0.643175
[INFO][11:56:54]: [Client #65] Woke up.
[INFO][11:56:54]: [Client #65] Epoch: [5/5][0/17]	Loss: 0.678358
[INFO][11:56:54]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][11:56:55]: [Client #123] Woke up.
[INFO][11:56:55]: [Client #123] Epoch: [4/5][0/35]	Loss: 0.975575
[INFO][11:56:55]: [Client #65] Epoch: [5/5][10/17]	Loss: 1.162963
[INFO][11:56:55]: [Client #123] Epoch: [4/5][10/35]	Loss: 0.796184
[INFO][11:56:55]: [Client #65] Going to sleep for 0.05 seconds.
[INFO][11:56:55]: [Client #65] Woke up.
[INFO][11:56:55]: [Client #65] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_65_554853.pth.
[INFO][11:56:55]: [Client #123] Epoch: [4/5][20/35]	Loss: 0.307490
[INFO][11:56:55]: [Client #123] Epoch: [4/5][30/35]	Loss: 0.557010
[INFO][11:56:55]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][11:56:55]: [Client #123] Woke up.
[INFO][11:56:55]: [Client #123] Epoch: [5/5][0/35]	Loss: 0.725851
[INFO][11:56:55]: [Client #123] Epoch: [5/5][10/35]	Loss: 1.184451
[INFO][11:56:55]: [Client #123] Epoch: [5/5][20/35]	Loss: 0.481676
[INFO][11:56:55]: [Client #123] Epoch: [5/5][30/35]	Loss: 1.308700
[INFO][11:56:55]: [Client #123] Going to sleep for 0.03 seconds.
[INFO][11:56:55]: [Client #123] Woke up.
[INFO][11:56:55]: [Client #123] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_554860.pth.
[INFO][11:56:55]: [Client #65] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_65_554853.pth.
[INFO][11:56:55]: [Client #65] Model trained.
[INFO][11:56:55]: [Client #65] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:55]: [Server #554754] Received 0.26 MB of payload data from client #65 (simulated).
[INFO][11:56:56]: [Client #123] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_123_554860.pth.
[INFO][11:56:56]: [Client #123] Model trained.
[INFO][11:56:56]: [Client #123] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:56:56]: [Server #554754] Received 0.26 MB of payload data from client #123 (simulated).
[INFO][11:56:56]: [Server #554754] Selecting client #40 for training.
[INFO][11:56:56]: [Server #554754] Sending the current model to client #40 (simulated).
[INFO][11:56:56]: [Server #554754] Sending 0.26 MB of payload data to client #40 (simulated).
[INFO][11:56:56]: [Server #554754] Selecting client #152 for training.
[INFO][11:56:56]: [Server #554754] Sending the current model to client #152 (simulated).
[INFO][11:56:56]: [Server #554754] Sending 0.26 MB of payload data to client #152 (simulated).
[INFO][11:56:56]: [Client #40] Selected by the server.
[INFO][11:56:56]: [Client #152] Selected by the server.
[INFO][11:56:56]: [Client #40] Loading its data source...
[INFO][11:56:56]: [Client #152] Loading its data source...
[INFO][11:56:56]: Data source: FEMNIST
[INFO][11:56:56]: Data source: FEMNIST
[INFO][11:56:56]: [Client #152] Dataset size: 151
[INFO][11:56:56]: [Client #152] Sampler: all_inclusive
[INFO][11:56:56]: [Client #40] Dataset size: 155
[INFO][11:56:56]: [Client #40] Sampler: all_inclusive
[INFO][11:56:56]: [Client #40] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:56]: [Client #152] Received 0.26 MB of payload data from the server (simulated).
[INFO][11:56:56]: [93m[1m[Client #152] Started training in communication round #37.[0m
[INFO][11:56:56]: [93m[1m[Client #40] Started training in communication round #37.[0m
[INFO][11:56:58]: [Client #40] Loading the dataset.
[INFO][11:56:58]: [Client #152] Loading the dataset.
[INFO][11:57:03]: [Client #40] Epoch: [1/5][0/16]	Loss: 1.047761
[INFO][11:57:03]: [Client #152] Epoch: [1/5][0/16]	Loss: 0.866952
[INFO][11:57:03]: [Client #40] Epoch: [1/5][10/16]	Loss: 0.429000
[INFO][11:57:03]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:57:03]: [Client #152] Epoch: [1/5][10/16]	Loss: 0.856855
[INFO][11:57:03]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:57:06]: [Client #40] Woke up.
[INFO][11:57:06]: [Client #40] Epoch: [2/5][0/16]	Loss: 0.140079
[INFO][11:57:06]: [Client #40] Epoch: [2/5][10/16]	Loss: 0.754553
[INFO][11:57:06]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:57:09]: [Client #40] Woke up.
[INFO][11:57:09]: [Client #40] Epoch: [3/5][0/16]	Loss: 0.242876
[INFO][11:57:10]: [Client #40] Epoch: [3/5][10/16]	Loss: 0.018601
[INFO][11:57:10]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:57:13]: [Client #40] Woke up.
[INFO][11:57:13]: [Client #40] Epoch: [4/5][0/16]	Loss: 0.297412
[INFO][11:57:13]: [Client #40] Epoch: [4/5][10/16]	Loss: 0.836196
[INFO][11:57:13]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:57:16]: [Client #40] Woke up.
[INFO][11:57:16]: [Client #40] Epoch: [5/5][0/16]	Loss: 0.494614
[INFO][11:57:16]: [Client #40] Epoch: [5/5][10/16]	Loss: 0.300599
[INFO][11:57:16]: [Client #40] Going to sleep for 3.00 seconds.
[INFO][11:57:19]: [Client #40] Woke up.
[INFO][11:57:19]: [Client #40] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_554853.pth.
[INFO][11:57:20]: [Client #40] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_40_554853.pth.
[INFO][11:57:20]: [Client #40] Model trained.
[INFO][11:57:20]: [Client #40] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:57:20]: [Server #554754] Received 0.26 MB of payload data from client #40 (simulated).
[INFO][11:57:33]: [Client #152] Woke up.
[INFO][11:57:33]: [Client #152] Epoch: [2/5][0/16]	Loss: 0.541303
[INFO][11:57:33]: [Client #152] Epoch: [2/5][10/16]	Loss: 0.704767
[INFO][11:57:33]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:58:03]: [Client #152] Woke up.
[INFO][11:58:03]: [Client #152] Epoch: [3/5][0/16]	Loss: 1.103400
[INFO][11:58:03]: [Client #152] Epoch: [3/5][10/16]	Loss: 0.570244
[INFO][11:58:03]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:58:33]: [Client #152] Woke up.
[INFO][11:58:33]: [Client #152] Epoch: [4/5][0/16]	Loss: 0.980279
[INFO][11:58:33]: [Client #152] Epoch: [4/5][10/16]	Loss: 0.801407
[INFO][11:58:33]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:59:02]: [Client #152] Woke up.
[INFO][11:59:03]: [Client #152] Epoch: [5/5][0/16]	Loss: 0.348735
[INFO][11:59:03]: [Client #152] Epoch: [5/5][10/16]	Loss: 0.797889
[INFO][11:59:03]: [Client #152] Going to sleep for 29.56 seconds.
[INFO][11:59:32]: [Client #152] Woke up.
[INFO][11:59:32]: [Client #152] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554860.pth.
[INFO][11:59:33]: [Client #152] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_152_554860.pth.
[INFO][11:59:33]: [Client #152] Model trained.
[INFO][11:59:33]: [Client #152] Sent 0.26 MB of payload data to the server (simulated).
[INFO][11:59:33]: [Server #554754] Received 0.26 MB of payload data from client #152 (simulated).
[INFO][11:59:33]: [Server #554754] Adding client #189 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #207 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #35 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #60 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #217 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #65 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #123 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #384 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #297 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #245 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #232 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #193 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #40 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #128 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #311 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #118 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #190 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #445 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #152 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Adding client #360 to the list of clients for aggregation.
[INFO][11:59:33]: [Server #554754] Aggregating 20 clients in total.
[0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00203648 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204057 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204015 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00203906 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204049
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204023 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00203892 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204055 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204026 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00203717
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11842911 0.
 0.         0.         0.         0.10649607 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15967212
 0.         0.         0.         0.         0.28437179 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11778256 0.         0.
 0.         0.         0.20918425 0.         0.         0.
 0.         0.07916009 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.2039296  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.26535767 0.17506862 0.         0.
 0.08512234 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12556278 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15579418 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11935604 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.84732045 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11495756 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18509113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10064071
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.24465022
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.41325249 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11842911 0.
 0.         0.         0.         0.10649607 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15967212
 0.         0.         0.         0.         0.28437179 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11778256 0.         0.
 0.         0.         0.20918425 0.         0.         0.
 0.         0.07916009 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.2039296  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.26535767 0.17506862 0.         0.
 0.08512234 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12556278 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.15579418 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11935604 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.84732045 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11495756 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.18509113 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10064071
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.24465022
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.41325249 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][12:00:17]: [Server #554754] Global model accuracy: 66.28%

[INFO][12:00:17]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_37.pth.
[INFO][12:00:17]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_37.pth.
[INFO][12:00:17]: [93m[1m
[Server #554754] Starting round 38/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.09055338
 0.002      0.04880988 0.09412436 0.04016585 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.08837971
 0.002      0.002      0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04094325 0.002      0.002      0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.002
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.002      0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.10063694 0.10344828 0.002      0.002      0.10714286
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.002
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.07799948 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.09298346 0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.002      0.0473034  0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.002      0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.002
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.002      0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10392902 0.15096419
 0.07566727 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.002      0.002      0.002      0.1026616  0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9077e+00  6.9066e+00  1e-03  2e-08  2e-08
 5:  6.9077e+00  6.9069e+00  8e-04  1e-08  1e-08
 6:  6.9076e+00  6.9068e+00  8e-04  4e-07  4e-07
 7:  6.9076e+00  6.9071e+00  5e-04  3e-07  3e-07
 8:  6.9074e+00  6.9071e+00  3e-04  5e-07  5e-07
 9:  6.9073e+00  6.9072e+00  1e-04  1e-06  9e-07
10:  6.9072e+00  6.9072e+00  6e-05  4e-08  4e-08
11:  6.9072e+00  6.9072e+00  4e-05  2e-08  1e-08
12:  6.9072e+00  6.9072e+00  8e-06  1e-08  5e-09
13:  6.9072e+00  6.9072e+00  1e-06  2e-09  9e-10
Optimal solution found.
The calculated probability is:  [4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 7.32761040e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89902919e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 8.83837502e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89731933e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 7.30789689e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89435730e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89913650e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89840442e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 1.82246506e-05 9.57097256e-06 4.89928115e-06 4.89928115e-06
 4.89911600e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 7.55140359e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89882221e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89893544e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 8.89802653e-01 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89896440e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 1.01073806e-05 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 6.82214622e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.87481800e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 1.07720983e-01 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06
 4.89928115e-06 4.89928115e-06 4.89928115e-06 4.89928115e-06]
current clients pool:  [INFO][12:00:17]: [Server #554754] Selected clients: [245 445 267 184 301 480 194 394 320 343 199  68 222 168 109 463 298 372
 269 350]
[INFO][12:00:17]: [Server #554754] Selecting client #245 for training.
[INFO][12:00:17]: [Server #554754] Sending the current model to client #245 (simulated).
[INFO][12:00:17]: [Server #554754] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][12:00:17]: [Server #554754] Selecting client #445 for training.
[INFO][12:00:17]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][12:00:17]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][12:00:17]: [Client #245] Selected by the server.
[INFO][12:00:17]: [Client #245] Loading its data source...
[INFO][12:00:17]: Data source: FEMNIST
[INFO][12:00:17]: [Client #445] Selected by the server.
[INFO][12:00:17]: [Client #445] Loading its data source...
[INFO][12:00:17]: Data source: FEMNIST
[INFO][12:00:17]: [Client #245] Dataset size: 301
[INFO][12:00:17]: [Client #245] Sampler: all_inclusive
[INFO][12:00:17]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:00:17]: [93m[1m[Client #245] Started training in communication round #38.[0m
[INFO][12:00:17]: [Client #445] Dataset size: 292
[INFO][12:00:17]: [Client #445] Sampler: all_inclusive
[INFO][12:00:17]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:00:17]: [93m[1m[Client #445] Started training in communication round #38.[0m
[INFO][12:00:19]: [Client #445] Loading the dataset.
[INFO][12:00:19]: [Client #245] Loading the dataset.
[INFO][12:00:25]: [Client #245] Epoch: [1/5][0/31]	Loss: 1.148946
[INFO][12:00:25]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.430430
[INFO][12:00:25]: [Client #245] Epoch: [1/5][10/31]	Loss: 0.364083
[INFO][12:00:25]: [Client #445] Epoch: [1/5][10/30]	Loss: 1.068897
[INFO][12:00:25]: [Client #245] Epoch: [1/5][20/31]	Loss: 0.930099
[INFO][12:00:25]: [Client #445] Epoch: [1/5][20/30]	Loss: 1.086296
[INFO][12:00:25]: [Client #245] Epoch: [1/5][30/31]	Loss: 2.669894
[INFO][12:00:25]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:00:25]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:00:29]: [Client #245] Woke up.
[INFO][12:00:29]: [Client #245] Epoch: [2/5][0/31]	Loss: 1.374890
[INFO][12:00:29]: [Client #245] Epoch: [2/5][10/31]	Loss: 0.870412
[INFO][12:00:29]: [Client #245] Epoch: [2/5][20/31]	Loss: 0.588377
[INFO][12:00:29]: [Client #245] Epoch: [2/5][30/31]	Loss: 4.732627
[INFO][12:00:29]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:00:33]: [Client #245] Woke up.
[INFO][12:00:33]: [Client #245] Epoch: [3/5][0/31]	Loss: 1.326662
[INFO][12:00:33]: [Client #245] Epoch: [3/5][10/31]	Loss: 1.818404
[INFO][12:00:33]: [Client #245] Epoch: [3/5][20/31]	Loss: 1.040135
[INFO][12:00:33]: [Client #245] Epoch: [3/5][30/31]	Loss: 0.489125
[INFO][12:00:33]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:00:37]: [Client #245] Woke up.
[INFO][12:00:37]: [Client #245] Epoch: [4/5][0/31]	Loss: 1.342206
[INFO][12:00:37]: [Client #245] Epoch: [4/5][10/31]	Loss: 2.175435
[INFO][12:00:37]: [Client #245] Epoch: [4/5][20/31]	Loss: 0.582630
[INFO][12:00:37]: [Client #245] Epoch: [4/5][30/31]	Loss: 1.517098
[INFO][12:00:37]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:00:41]: [Client #245] Woke up.
[INFO][12:00:41]: [Client #245] Epoch: [5/5][0/31]	Loss: 0.868633
[INFO][12:00:41]: [Client #245] Epoch: [5/5][10/31]	Loss: 0.208046
[INFO][12:00:41]: [Client #245] Epoch: [5/5][20/31]	Loss: 1.474835
[INFO][12:00:41]: [Client #245] Epoch: [5/5][30/31]	Loss: 2.294199
[INFO][12:00:41]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:00:44]: [Client #445] Woke up.
[INFO][12:00:44]: [Client #445] Epoch: [2/5][0/30]	Loss: 1.258636
[INFO][12:00:45]: [Client #245] Woke up.
[INFO][12:00:45]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554853.pth.
[INFO][12:00:45]: [Client #445] Epoch: [2/5][10/30]	Loss: 1.224040
[INFO][12:00:45]: [Client #445] Epoch: [2/5][20/30]	Loss: 1.585995
[INFO][12:00:45]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:00:45]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554853.pth.
[INFO][12:00:45]: [Client #245] Model trained.
[INFO][12:00:45]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:00:45]: [Server #554754] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][12:01:04]: [Client #445] Woke up.
[INFO][12:01:04]: [Client #445] Epoch: [3/5][0/30]	Loss: 0.754973
[INFO][12:01:04]: [Client #445] Epoch: [3/5][10/30]	Loss: 0.904717
[INFO][12:01:05]: [Client #445] Epoch: [3/5][20/30]	Loss: 1.009937
[INFO][12:01:05]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:01:24]: [Client #445] Woke up.
[INFO][12:01:24]: [Client #445] Epoch: [4/5][0/30]	Loss: 1.333357
[INFO][12:01:24]: [Client #445] Epoch: [4/5][10/30]	Loss: 0.570446
[INFO][12:01:24]: [Client #445] Epoch: [4/5][20/30]	Loss: 0.603973
[INFO][12:01:25]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:01:44]: [Client #445] Woke up.
[INFO][12:01:44]: [Client #445] Epoch: [5/5][0/30]	Loss: 1.046786
[INFO][12:01:44]: [Client #445] Epoch: [5/5][10/30]	Loss: 0.434143
[INFO][12:01:44]: [Client #445] Epoch: [5/5][20/30]	Loss: 0.372843
[INFO][12:01:44]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:02:04]: [Client #445] Woke up.
[INFO][12:02:04]: [Client #445] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][12:02:05]: [Client #445] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_445_554860.pth.
[INFO][12:02:05]: [Client #445] Model trained.
[INFO][12:02:05]: [Client #445] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:02:05]: [Server #554754] Received 0.26 MB of payload data from client #445 (simulated).
[INFO][12:02:05]: [Server #554754] Selecting client #267 for training.
[INFO][12:02:05]: [Server #554754] Sending the current model to client #267 (simulated).
[INFO][12:02:05]: [Server #554754] Sending 0.26 MB of payload data to client #267 (simulated).
[INFO][12:02:05]: [Server #554754] Selecting client #184 for training.
[INFO][12:02:05]: [Server #554754] Sending the current model to client #184 (simulated).
[INFO][12:02:05]: [Server #554754] Sending 0.26 MB of payload data to client #184 (simulated).
[INFO][12:02:05]: [Client #267] Selected by the server.
[INFO][12:02:05]: [Client #184] Selected by the server.
[INFO][12:02:05]: [Client #267] Loading its data source...
[INFO][12:02:05]: [Client #184] Loading its data source...
[INFO][12:02:05]: Data source: FEMNIST
[INFO][12:02:05]: Data source: FEMNIST
[INFO][12:02:05]: [Client #184] Dataset size: 159
[INFO][12:02:05]: [Client #184] Sampler: all_inclusive
[INFO][12:02:05]: [Client #184] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:05]: [93m[1m[Client #184] Started training in communication round #38.[0m
[INFO][12:02:05]: [Client #267] Dataset size: 288
[INFO][12:02:05]: [Client #267] Sampler: all_inclusive
[INFO][12:02:05]: [Client #267] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:05]: [93m[1m[Client #267] Started training in communication round #38.[0m
[INFO][12:02:07]: [Client #184] Loading the dataset.
[INFO][12:02:07]: [Client #267] Loading the dataset.
[INFO][12:02:12]: [Client #267] Epoch: [1/5][0/29]	Loss: 1.018981
[INFO][12:02:12]: [Client #184] Epoch: [1/5][0/16]	Loss: 1.451349
[INFO][12:02:12]: [Client #267] Epoch: [1/5][10/29]	Loss: 1.106597
[INFO][12:02:12]: [Client #184] Epoch: [1/5][10/16]	Loss: 1.128634
[INFO][12:02:12]: [Client #267] Epoch: [1/5][20/29]	Loss: 1.808335
[INFO][12:02:12]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][12:02:12]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][12:02:12]: [Client #184] Woke up.
[INFO][12:02:12]: [Client #184] Epoch: [2/5][0/16]	Loss: 0.559611
[INFO][12:02:12]: [Client #184] Epoch: [2/5][10/16]	Loss: 0.811544
[INFO][12:02:12]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][12:02:13]: [Client #184] Woke up.
[INFO][12:02:13]: [Client #184] Epoch: [3/5][0/16]	Loss: 0.267895
[INFO][12:02:13]: [Client #184] Epoch: [3/5][10/16]	Loss: 0.147212
[INFO][12:02:13]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][12:02:13]: [Client #184] Woke up.
[INFO][12:02:13]: [Client #184] Epoch: [4/5][0/16]	Loss: 0.221851
[INFO][12:02:13]: [Client #184] Epoch: [4/5][10/16]	Loss: 0.337999
[INFO][12:02:13]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][12:02:13]: [Client #184] Woke up.
[INFO][12:02:13]: [Client #184] Epoch: [5/5][0/16]	Loss: 0.271853
[INFO][12:02:13]: [Client #184] Epoch: [5/5][10/16]	Loss: 0.338689
[INFO][12:02:13]: [Client #184] Going to sleep for 0.07 seconds.
[INFO][12:02:13]: [Client #184] Woke up.
[INFO][12:02:13]: [Client #184] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_554860.pth.
[INFO][12:02:14]: [Client #184] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_184_554860.pth.
[INFO][12:02:14]: [Client #184] Model trained.
[INFO][12:02:14]: [Client #184] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:02:14]: [Server #554754] Received 0.26 MB of payload data from client #184 (simulated).
[INFO][12:02:14]: [Client #267] Woke up.
[INFO][12:02:14]: [Client #267] Epoch: [2/5][0/29]	Loss: 1.103202
[INFO][12:02:14]: [Client #267] Epoch: [2/5][10/29]	Loss: 0.645560
[INFO][12:02:14]: [Client #267] Epoch: [2/5][20/29]	Loss: 1.044159
[INFO][12:02:15]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][12:02:17]: [Client #267] Woke up.
[INFO][12:02:17]: [Client #267] Epoch: [3/5][0/29]	Loss: 0.259687
[INFO][12:02:17]: [Client #267] Epoch: [3/5][10/29]	Loss: 0.281933
[INFO][12:02:17]: [Client #267] Epoch: [3/5][20/29]	Loss: 0.615527
[INFO][12:02:17]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][12:02:19]: [Client #267] Woke up.
[INFO][12:02:19]: [Client #267] Epoch: [4/5][0/29]	Loss: 0.497700
[INFO][12:02:19]: [Client #267] Epoch: [4/5][10/29]	Loss: 1.195333
[INFO][12:02:19]: [Client #267] Epoch: [4/5][20/29]	Loss: 1.774403
[INFO][12:02:19]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][12:02:21]: [Client #267] Woke up.
[INFO][12:02:21]: [Client #267] Epoch: [5/5][0/29]	Loss: 1.889389
[INFO][12:02:21]: [Client #267] Epoch: [5/5][10/29]	Loss: 0.864575
[INFO][12:02:21]: [Client #267] Epoch: [5/5][20/29]	Loss: 0.535423
[INFO][12:02:21]: [Client #267] Going to sleep for 2.04 seconds.
[INFO][12:02:23]: [Client #267] Woke up.
[INFO][12:02:23]: [Client #267] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_267_554853.pth.
[INFO][12:02:24]: [Client #267] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_267_554853.pth.
[INFO][12:02:24]: [Client #267] Model trained.
[INFO][12:02:24]: [Client #267] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:02:24]: [Server #554754] Received 0.26 MB of payload data from client #267 (simulated).
[INFO][12:02:24]: [Server #554754] Selecting client #301 for training.
[INFO][12:02:24]: [Server #554754] Sending the current model to client #301 (simulated).
[INFO][12:02:24]: [Server #554754] Sending 0.26 MB of payload data to client #301 (simulated).
[INFO][12:02:24]: [Server #554754] Selecting client #480 for training.
[INFO][12:02:24]: [Server #554754] Sending the current model to client #480 (simulated).
[INFO][12:02:24]: [Server #554754] Sending 0.26 MB of payload data to client #480 (simulated).
[INFO][12:02:24]: [Client #301] Selected by the server.
[INFO][12:02:24]: [Client #301] Loading its data source...
[INFO][12:02:24]: Data source: FEMNIST
[INFO][12:02:24]: [Client #480] Selected by the server.
[INFO][12:02:24]: [Client #480] Loading its data source...
[INFO][12:02:24]: Data source: FEMNIST
[INFO][12:02:24]: [Client #480] Dataset size: 163
[INFO][12:02:24]: [Client #480] Sampler: all_inclusive
[INFO][12:02:24]: [Client #301] Dataset size: 152
[INFO][12:02:24]: [Client #301] Sampler: all_inclusive
[INFO][12:02:24]: [Client #480] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:24]: [Client #301] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:24]: [93m[1m[Client #301] Started training in communication round #38.[0m
[INFO][12:02:24]: [93m[1m[Client #480] Started training in communication round #38.[0m
[INFO][12:02:26]: [Client #480] Loading the dataset.
[INFO][12:02:26]: [Client #301] Loading the dataset.
[INFO][12:02:32]: [Client #480] Epoch: [1/5][0/17]	Loss: 1.759052
[INFO][12:02:32]: [Client #480] Epoch: [1/5][10/17]	Loss: 0.712810
[INFO][12:02:32]: [Client #301] Epoch: [1/5][0/16]	Loss: 0.412222
[INFO][12:02:32]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][12:02:32]: [Client #301] Epoch: [1/5][10/16]	Loss: 0.411392
[INFO][12:02:32]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:02:33]: [Client #480] Woke up.
[INFO][12:02:33]: [Client #480] Epoch: [2/5][0/17]	Loss: 0.437391
[INFO][12:02:33]: [Client #480] Epoch: [2/5][10/17]	Loss: 0.297979
[INFO][12:02:33]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][12:02:34]: [Client #480] Woke up.
[INFO][12:02:34]: [Client #480] Epoch: [3/5][0/17]	Loss: 0.407256
[INFO][12:02:34]: [Client #480] Epoch: [3/5][10/17]	Loss: 0.086202
[INFO][12:02:34]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][12:02:35]: [Client #480] Woke up.
[INFO][12:02:35]: [Client #480] Epoch: [4/5][0/17]	Loss: 0.267392
[INFO][12:02:35]: [Client #480] Epoch: [4/5][10/17]	Loss: 1.228044
[INFO][12:02:35]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][12:02:36]: [Client #301] Woke up.
[INFO][12:02:36]: [Client #301] Epoch: [2/5][0/16]	Loss: 1.263817
[INFO][12:02:36]: [Client #301] Epoch: [2/5][10/16]	Loss: 1.433306
[INFO][12:02:36]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:02:37]: [Client #480] Woke up.
[INFO][12:02:37]: [Client #480] Epoch: [5/5][0/17]	Loss: 0.528863
[INFO][12:02:37]: [Client #480] Epoch: [5/5][10/17]	Loss: 0.262314
[INFO][12:02:37]: [Client #480] Going to sleep for 1.09 seconds.
[INFO][12:02:38]: [Client #480] Woke up.
[INFO][12:02:38]: [Client #480] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_480_554860.pth.
[INFO][12:02:38]: [Client #480] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_480_554860.pth.
[INFO][12:02:38]: [Client #480] Model trained.
[INFO][12:02:38]: [Client #480] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:02:38]: [Server #554754] Received 0.26 MB of payload data from client #480 (simulated).
[INFO][12:02:41]: [Client #301] Woke up.
[INFO][12:02:41]: [Client #301] Epoch: [3/5][0/16]	Loss: 0.212794
[INFO][12:02:41]: [Client #301] Epoch: [3/5][10/16]	Loss: 0.838098
[INFO][12:02:41]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:02:45]: [Client #301] Woke up.
[INFO][12:02:45]: [Client #301] Epoch: [4/5][0/16]	Loss: 1.004971
[INFO][12:02:45]: [Client #301] Epoch: [4/5][10/16]	Loss: 1.173837
[INFO][12:02:45]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:02:50]: [Client #301] Woke up.
[INFO][12:02:50]: [Client #301] Epoch: [5/5][0/16]	Loss: 0.646639
[INFO][12:02:50]: [Client #301] Epoch: [5/5][10/16]	Loss: 1.393958
[INFO][12:02:50]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:02:54]: [Client #301] Woke up.
[INFO][12:02:54]: [Client #301] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554853.pth.
[INFO][12:02:55]: [Client #301] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554853.pth.
[INFO][12:02:55]: [Client #301] Model trained.
[INFO][12:02:55]: [Client #301] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:02:55]: [Server #554754] Received 0.26 MB of payload data from client #301 (simulated).
[INFO][12:02:55]: [Server #554754] Selecting client #194 for training.
[INFO][12:02:55]: [Server #554754] Sending the current model to client #194 (simulated).
[INFO][12:02:55]: [Server #554754] Sending 0.26 MB of payload data to client #194 (simulated).
[INFO][12:02:55]: [Server #554754] Selecting client #394 for training.
[INFO][12:02:55]: [Server #554754] Sending the current model to client #394 (simulated).
[INFO][12:02:55]: [Server #554754] Sending 0.26 MB of payload data to client #394 (simulated).
[INFO][12:02:55]: [Client #194] Selected by the server.
[INFO][12:02:55]: [Client #194] Loading its data source...
[INFO][12:02:55]: Data source: FEMNIST
[INFO][12:02:55]: [Client #394] Selected by the server.
[INFO][12:02:55]: [Client #394] Loading its data source...
[INFO][12:02:55]: Data source: FEMNIST
[INFO][12:02:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:02:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/394.zip.
[INFO][12:02:55]: [Client #194] Dataset size: 158
[INFO][12:02:55]: [Client #194] Sampler: all_inclusive
[INFO][12:02:55]: [Client #194] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:55]: [93m[1m[Client #194] Started training in communication round #38.[0m

2.3%
4.7%
7.0%
9.3%
11.7%
14.0%
16.3%
18.7%
21.0%
23.3%
25.7%
28.0%
30.3%
32.7%
35.0%
37.4%
39.7%
42.0%
44.4%
46.7%
49.0%
51.4%
53.7%
56.0%
58.4%
60.7%
63.0%
65.4%
67.7%
70.0%
72.4%
74.7%
77.0%
79.4%
81.7%
84.0%
86.4%
88.7%
91.0%
93.4%
95.7%
98.0%
100.0%[INFO][12:02:55]: Decompressing the dataset downloaded.
[INFO][12:02:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/394.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:02:55]: [Client #394] Dataset size: 157
[INFO][12:02:55]: [Client #394] Sampler: all_inclusive
[INFO][12:02:55]: [Client #394] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:02:55]: [93m[1m[Client #394] Started training in communication round #38.[0m

[INFO][12:02:57]: [Client #194] Loading the dataset.
[INFO][12:02:57]: [Client #394] Loading the dataset.
[INFO][12:03:02]: [Client #194] Epoch: [1/5][0/16]	Loss: 0.549445
[INFO][12:03:02]: [Client #194] Epoch: [1/5][10/16]	Loss: 0.363103
[INFO][12:03:02]: [Client #394] Epoch: [1/5][0/16]	Loss: 0.687303
[INFO][12:03:02]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:03:02]: [Client #394] Epoch: [1/5][10/16]	Loss: 0.503791
[INFO][12:03:02]: [Client #394] Going to sleep for 0.03 seconds.
[INFO][12:03:02]: [Client #394] Woke up.
[INFO][12:03:02]: [Client #394] Epoch: [2/5][0/16]	Loss: 0.825369
[INFO][12:03:03]: [Client #394] Epoch: [2/5][10/16]	Loss: 1.165609
[INFO][12:03:03]: [Client #394] Going to sleep for 0.03 seconds.
[INFO][12:03:03]: [Client #394] Woke up.
[INFO][12:03:03]: [Client #394] Epoch: [3/5][0/16]	Loss: 0.317517
[INFO][12:03:03]: [Client #394] Epoch: [3/5][10/16]	Loss: 0.628904
[INFO][12:03:03]: [Client #394] Going to sleep for 0.03 seconds.
[INFO][12:03:03]: [Client #394] Woke up.
[INFO][12:03:03]: [Client #394] Epoch: [4/5][0/16]	Loss: 0.642765
[INFO][12:03:03]: [Client #394] Epoch: [4/5][10/16]	Loss: 0.518637
[INFO][12:03:03]: [Client #394] Going to sleep for 0.03 seconds.
[INFO][12:03:03]: [Client #394] Woke up.
[INFO][12:03:03]: [Client #394] Epoch: [5/5][0/16]	Loss: 0.407230
[INFO][12:03:03]: [Client #394] Epoch: [5/5][10/16]	Loss: 1.739047
[INFO][12:03:03]: [Client #394] Going to sleep for 0.03 seconds.
[INFO][12:03:03]: [Client #394] Woke up.
[INFO][12:03:03]: [Client #394] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_394_554860.pth.
[INFO][12:03:04]: [Client #394] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_394_554860.pth.
[INFO][12:03:04]: [Client #394] Model trained.
[INFO][12:03:04]: [Client #394] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:03:04]: [Server #554754] Received 0.26 MB of payload data from client #394 (simulated).
[INFO][12:03:06]: [Client #194] Woke up.
[INFO][12:03:06]: [Client #194] Epoch: [2/5][0/16]	Loss: 0.686924
[INFO][12:03:06]: [Client #194] Epoch: [2/5][10/16]	Loss: 0.784203
[INFO][12:03:06]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:03:09]: [Client #194] Woke up.
[INFO][12:03:09]: [Client #194] Epoch: [3/5][0/16]	Loss: 0.468193
[INFO][12:03:09]: [Client #194] Epoch: [3/5][10/16]	Loss: 0.268745
[INFO][12:03:09]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:03:13]: [Client #194] Woke up.
[INFO][12:03:13]: [Client #194] Epoch: [4/5][0/16]	Loss: 1.589587
[INFO][12:03:13]: [Client #194] Epoch: [4/5][10/16]	Loss: 0.924308
[INFO][12:03:13]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:03:16]: [Client #194] Woke up.
[INFO][12:03:16]: [Client #194] Epoch: [5/5][0/16]	Loss: 0.437730
[INFO][12:03:16]: [Client #194] Epoch: [5/5][10/16]	Loss: 1.032394
[INFO][12:03:16]: [Client #194] Going to sleep for 3.39 seconds.
[INFO][12:03:20]: [Client #194] Woke up.
[INFO][12:03:20]: [Client #194] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_554853.pth.
[INFO][12:03:20]: [Client #194] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_194_554853.pth.
[INFO][12:03:20]: [Client #194] Model trained.
[INFO][12:03:21]: [Client #194] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:03:21]: [Server #554754] Received 0.26 MB of payload data from client #194 (simulated).
[INFO][12:03:21]: [Server #554754] Selecting client #320 for training.
[INFO][12:03:21]: [Server #554754] Sending the current model to client #320 (simulated).
[INFO][12:03:21]: [Server #554754] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][12:03:21]: [Server #554754] Selecting client #343 for training.
[INFO][12:03:21]: [Server #554754] Sending the current model to client #343 (simulated).
[INFO][12:03:21]: [Server #554754] Sending 0.26 MB of payload data to client #343 (simulated).
[INFO][12:03:21]: [Client #320] Selected by the server.
[INFO][12:03:21]: [Client #320] Loading its data source...
[INFO][12:03:21]: Data source: FEMNIST
[INFO][12:03:21]: [Client #343] Selected by the server.
[INFO][12:03:21]: [Client #343] Loading its data source...
[INFO][12:03:21]: Data source: FEMNIST
[INFO][12:03:21]: [Client #320] Dataset size: 153
[INFO][12:03:21]: [Client #320] Sampler: all_inclusive
[INFO][12:03:21]: [Client #343] Dataset size: 155
[INFO][12:03:21]: [Client #343] Sampler: all_inclusive
[INFO][12:03:21]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:03:21]: [Client #343] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:03:21]: [93m[1m[Client #320] Started training in communication round #38.[0m
[INFO][12:03:21]: [93m[1m[Client #343] Started training in communication round #38.[0m
[INFO][12:03:22]: [Client #320] Loading the dataset.
[INFO][12:03:22]: [Client #343] Loading the dataset.
[INFO][12:03:28]: [Client #320] Epoch: [1/5][0/16]	Loss: 0.576158
[INFO][12:03:28]: [Client #343] Epoch: [1/5][0/16]	Loss: 0.681633
[INFO][12:03:28]: [Client #320] Epoch: [1/5][10/16]	Loss: 1.708560
[INFO][12:03:28]: [Client #343] Epoch: [1/5][10/16]	Loss: 0.171717
[INFO][12:03:28]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:03:28]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][12:03:33]: [Client #343] Woke up.
[INFO][12:03:33]: [Client #343] Epoch: [2/5][0/16]	Loss: 0.527857
[INFO][12:03:33]: [Client #343] Epoch: [2/5][10/16]	Loss: 0.873335
[INFO][12:03:33]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][12:03:34]: [Client #320] Woke up.
[INFO][12:03:34]: [Client #320] Epoch: [2/5][0/16]	Loss: 0.750568
[INFO][12:03:34]: [Client #320] Epoch: [2/5][10/16]	Loss: 0.382256
[INFO][12:03:34]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:03:38]: [Client #343] Woke up.
[INFO][12:03:38]: [Client #343] Epoch: [3/5][0/16]	Loss: 0.707738
[INFO][12:03:38]: [Client #343] Epoch: [3/5][10/16]	Loss: 0.831235
[INFO][12:03:38]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][12:03:40]: [Client #320] Woke up.
[INFO][12:03:40]: [Client #320] Epoch: [3/5][0/16]	Loss: 0.861361
[INFO][12:03:40]: [Client #320] Epoch: [3/5][10/16]	Loss: 0.695871
[INFO][12:03:40]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:03:43]: [Client #343] Woke up.
[INFO][12:03:43]: [Client #343] Epoch: [4/5][0/16]	Loss: 0.651396
[INFO][12:03:43]: [Client #343] Epoch: [4/5][10/16]	Loss: 0.064562
[INFO][12:03:43]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][12:03:46]: [Client #320] Woke up.
[INFO][12:03:46]: [Client #320] Epoch: [4/5][0/16]	Loss: 0.612949
[INFO][12:03:46]: [Client #320] Epoch: [4/5][10/16]	Loss: 0.364254
[INFO][12:03:46]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:03:48]: [Client #343] Woke up.
[INFO][12:03:48]: [Client #343] Epoch: [5/5][0/16]	Loss: 0.457035
[INFO][12:03:48]: [Client #343] Epoch: [5/5][10/16]	Loss: 0.682476
[INFO][12:03:48]: [Client #343] Going to sleep for 4.76 seconds.
[INFO][12:03:52]: [Client #320] Woke up.
[INFO][12:03:52]: [Client #320] Epoch: [5/5][0/16]	Loss: 0.791226
[INFO][12:03:52]: [Client #320] Epoch: [5/5][10/16]	Loss: 0.180429
[INFO][12:03:52]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:03:53]: [Client #343] Woke up.
[INFO][12:03:53]: [Client #343] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_343_554860.pth.
[INFO][12:03:53]: [Client #343] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_343_554860.pth.
[INFO][12:03:53]: [Client #343] Model trained.
[INFO][12:03:53]: [Client #343] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:03:53]: [Server #554754] Received 0.26 MB of payload data from client #343 (simulated).
[INFO][12:03:57]: [Client #320] Woke up.
[INFO][12:03:57]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554853.pth.
[INFO][12:03:58]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554853.pth.
[INFO][12:03:58]: [Client #320] Model trained.
[INFO][12:03:58]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:03:58]: [Server #554754] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][12:03:58]: [Server #554754] Selecting client #199 for training.
[INFO][12:03:58]: [Server #554754] Sending the current model to client #199 (simulated).
[INFO][12:03:58]: [Server #554754] Sending 0.26 MB of payload data to client #199 (simulated).
[INFO][12:03:58]: [Server #554754] Selecting client #68 for training.
[INFO][12:03:58]: [Server #554754] Sending the current model to client #68 (simulated).
[INFO][12:03:58]: [Server #554754] Sending 0.26 MB of payload data to client #68 (simulated).
[INFO][12:03:58]: [Client #199] Selected by the server.
[INFO][12:03:58]: [Client #68] Selected by the server.
[INFO][12:03:58]: [Client #199] Loading its data source...
[INFO][12:03:58]: [Client #68] Loading its data source...
[INFO][12:03:58]: Data source: FEMNIST
[INFO][12:03:58]: Data source: FEMNIST
[INFO][12:03:58]: [Client #68] Dataset size: 162
[INFO][12:03:58]: [Client #68] Sampler: all_inclusive
[INFO][12:03:58]: [Client #68] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:03:58]: [93m[1m[Client #68] Started training in communication round #38.[0m
[INFO][12:03:58]: [Client #199] Dataset size: 158
[INFO][12:03:58]: [Client #199] Sampler: all_inclusive
[INFO][12:03:58]: [Client #199] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:03:58]: [93m[1m[Client #199] Started training in communication round #38.[0m
[INFO][12:04:00]: [Client #68] Loading the dataset.
[INFO][12:04:00]: [Client #199] Loading the dataset.
[INFO][12:04:06]: [Client #68] Epoch: [1/5][0/17]	Loss: 0.769458
[INFO][12:04:06]: [Client #68] Epoch: [1/5][10/17]	Loss: 1.347916
[INFO][12:04:06]: [Client #199] Epoch: [1/5][0/16]	Loss: 0.194486
[INFO][12:04:06]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][12:04:06]: [Client #199] Epoch: [1/5][10/16]	Loss: 0.534310
[INFO][12:04:06]: [Client #199] Going to sleep for 1.61 seconds.
[INFO][12:04:07]: [Client #68] Woke up.
[INFO][12:04:07]: [Client #68] Epoch: [2/5][0/17]	Loss: 0.604005
[INFO][12:04:07]: [Client #68] Epoch: [2/5][10/17]	Loss: 1.067786
[INFO][12:04:07]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][12:04:07]: [Client #199] Woke up.
[INFO][12:04:07]: [Client #199] Epoch: [2/5][0/16]	Loss: 0.673157
[INFO][12:04:08]: [Client #199] Epoch: [2/5][10/16]	Loss: 0.401694
[INFO][12:04:08]: [Client #199] Going to sleep for 1.61 seconds.
[INFO][12:04:08]: [Client #68] Woke up.
[INFO][12:04:08]: [Client #68] Epoch: [3/5][0/17]	Loss: 0.710288
[INFO][12:04:08]: [Client #68] Epoch: [3/5][10/17]	Loss: 1.876940
[INFO][12:04:08]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][12:04:09]: [Client #199] Woke up.
[INFO][12:04:09]: [Client #68] Woke up.
[INFO][12:04:09]: [Client #199] Epoch: [3/5][0/16]	Loss: 0.210706
[INFO][12:04:09]: [Client #68] Epoch: [4/5][0/17]	Loss: 0.501010
[INFO][12:04:09]: [Client #199] Epoch: [3/5][10/16]	Loss: 0.334722
[INFO][12:04:09]: [Client #68] Epoch: [4/5][10/17]	Loss: 1.959791
[INFO][12:04:09]: [Client #199] Going to sleep for 1.61 seconds.
[INFO][12:04:09]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][12:04:10]: [Client #68] Woke up.
[INFO][12:04:10]: [Client #68] Epoch: [5/5][0/17]	Loss: 1.544093
[INFO][12:04:11]: [Client #68] Epoch: [5/5][10/17]	Loss: 0.641996
[INFO][12:04:11]: [Client #68] Going to sleep for 1.06 seconds.
[INFO][12:04:11]: [Client #199] Woke up.
[INFO][12:04:11]: [Client #199] Epoch: [4/5][0/16]	Loss: 0.214411
[INFO][12:04:11]: [Client #199] Epoch: [4/5][10/16]	Loss: 0.305778
[INFO][12:04:11]: [Client #199] Going to sleep for 1.61 seconds.
[INFO][12:04:12]: [Client #68] Woke up.
[INFO][12:04:12]: [Client #68] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_68_554860.pth.
[INFO][12:04:12]: [Client #68] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_68_554860.pth.
[INFO][12:04:12]: [Client #68] Model trained.
[INFO][12:04:12]: [Client #68] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:12]: [Server #554754] Received 0.26 MB of payload data from client #68 (simulated).
[INFO][12:04:13]: [Client #199] Woke up.
[INFO][12:04:13]: [Client #199] Epoch: [5/5][0/16]	Loss: 0.878010
[INFO][12:04:13]: [Client #199] Epoch: [5/5][10/16]	Loss: 0.132536
[INFO][12:04:13]: [Client #199] Going to sleep for 1.61 seconds.
[INFO][12:04:14]: [Client #199] Woke up.
[INFO][12:04:14]: [Client #199] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_199_554853.pth.
[INFO][12:04:15]: [Client #199] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_199_554853.pth.
[INFO][12:04:15]: [Client #199] Model trained.
[INFO][12:04:15]: [Client #199] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:15]: [Server #554754] Received 0.26 MB of payload data from client #199 (simulated).
[INFO][12:04:15]: [Server #554754] Selecting client #222 for training.
[INFO][12:04:15]: [Server #554754] Sending the current model to client #222 (simulated).
[INFO][12:04:15]: [Server #554754] Sending 0.26 MB of payload data to client #222 (simulated).
[INFO][12:04:15]: [Server #554754] Selecting client #168 for training.
[INFO][12:04:15]: [Server #554754] Sending the current model to client #168 (simulated).
[INFO][12:04:15]: [Server #554754] Sending 0.26 MB of payload data to client #168 (simulated).
[INFO][12:04:15]: [Client #222] Selected by the server.
[INFO][12:04:15]: [Client #222] Loading its data source...
[INFO][12:04:15]: Data source: FEMNIST
[INFO][12:04:15]: [Client #168] Selected by the server.
[INFO][12:04:15]: [Client #168] Loading its data source...
[INFO][12:04:15]: Data source: FEMNIST
[INFO][12:04:15]: [Client #168] Dataset size: 164
[INFO][12:04:15]: [Client #168] Sampler: all_inclusive
[INFO][12:04:15]: [Client #168] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:15]: [93m[1m[Client #168] Started training in communication round #38.[0m
[INFO][12:04:15]: [Client #222] Dataset size: 328
[INFO][12:04:15]: [Client #222] Sampler: all_inclusive
[INFO][12:04:15]: [Client #222] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:15]: [93m[1m[Client #222] Started training in communication round #38.[0m
[INFO][12:04:17]: [Client #168] Loading the dataset.
[INFO][12:04:17]: [Client #222] Loading the dataset.
[INFO][12:04:23]: [Client #222] Epoch: [1/5][0/33]	Loss: 0.957314
[INFO][12:04:23]: [Client #168] Epoch: [1/5][0/17]	Loss: 0.314736
[INFO][12:04:23]: [Client #222] Epoch: [1/5][10/33]	Loss: 1.020239
[INFO][12:04:23]: [Client #168] Epoch: [1/5][10/17]	Loss: 0.175322
[INFO][12:04:23]: [Client #222] Epoch: [1/5][20/33]	Loss: 1.145329
[INFO][12:04:23]: [Client #168] Going to sleep for 0.95 seconds.
[INFO][12:04:23]: [Client #222] Epoch: [1/5][30/33]	Loss: 0.696635
[INFO][12:04:23]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][12:04:23]: [Client #222] Woke up.
[INFO][12:04:23]: [Client #222] Epoch: [2/5][0/33]	Loss: 0.851905
[INFO][12:04:23]: [Client #222] Epoch: [2/5][10/33]	Loss: 1.300206
[INFO][12:04:23]: [Client #222] Epoch: [2/5][20/33]	Loss: 0.688500
[INFO][12:04:24]: [Client #222] Epoch: [2/5][30/33]	Loss: 0.836963
[INFO][12:04:24]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][12:04:24]: [Client #168] Woke up.
[INFO][12:04:24]: [Client #168] Epoch: [2/5][0/17]	Loss: 0.449231
[INFO][12:04:24]: [Client #168] Epoch: [2/5][10/17]	Loss: 0.228955
[INFO][12:04:24]: [Client #168] Going to sleep for 0.95 seconds.
[INFO][12:04:24]: [Client #222] Woke up.
[INFO][12:04:24]: [Client #222] Epoch: [3/5][0/33]	Loss: 1.196193
[INFO][12:04:24]: [Client #222] Epoch: [3/5][10/33]	Loss: 0.852906
[INFO][12:04:24]: [Client #222] Epoch: [3/5][20/33]	Loss: 0.530628
[INFO][12:04:24]: [Client #222] Epoch: [3/5][30/33]	Loss: 1.548239
[INFO][12:04:24]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][12:04:25]: [Client #168] Woke up.
[INFO][12:04:25]: [Client #168] Epoch: [3/5][0/17]	Loss: 0.055127
[INFO][12:04:25]: [Client #222] Woke up.
[INFO][12:04:25]: [Client #222] Epoch: [4/5][0/33]	Loss: 0.620165
[INFO][12:04:25]: [Client #168] Epoch: [3/5][10/17]	Loss: 1.578184
[INFO][12:04:25]: [Client #222] Epoch: [4/5][10/33]	Loss: 0.593939
[INFO][12:04:25]: [Client #168] Going to sleep for 0.95 seconds.
[INFO][12:04:25]: [Client #222] Epoch: [4/5][20/33]	Loss: 0.623546
[INFO][12:04:25]: [Client #222] Epoch: [4/5][30/33]	Loss: 1.030346
[INFO][12:04:25]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][12:04:26]: [Client #222] Woke up.
[INFO][12:04:26]: [Client #222] Epoch: [5/5][0/33]	Loss: 0.418830
[INFO][12:04:26]: [Client #222] Epoch: [5/5][10/33]	Loss: 1.907599
[INFO][12:04:26]: [Client #222] Epoch: [5/5][20/33]	Loss: 1.202104
[INFO][12:04:26]: [Client #222] Epoch: [5/5][30/33]	Loss: 1.380741
[INFO][12:04:26]: [Client #222] Going to sleep for 0.50 seconds.
[INFO][12:04:26]: [Client #168] Woke up.
[INFO][12:04:26]: [Client #168] Epoch: [4/5][0/17]	Loss: 0.333500
[INFO][12:04:26]: [Client #168] Epoch: [4/5][10/17]	Loss: 0.270702
[INFO][12:04:26]: [Client #168] Going to sleep for 0.95 seconds.
[INFO][12:04:26]: [Client #222] Woke up.
[INFO][12:04:26]: [Client #222] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_222_554853.pth.
[INFO][12:04:27]: [Client #222] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_222_554853.pth.
[INFO][12:04:27]: [Client #222] Model trained.
[INFO][12:04:27]: [Client #222] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:27]: [Server #554754] Received 0.26 MB of payload data from client #222 (simulated).
[INFO][12:04:27]: [Client #168] Woke up.
[INFO][12:04:27]: [Client #168] Epoch: [5/5][0/17]	Loss: 0.316841
[INFO][12:04:27]: [Client #168] Epoch: [5/5][10/17]	Loss: 0.267500
[INFO][12:04:27]: [Client #168] Going to sleep for 0.95 seconds.
[INFO][12:04:28]: [Client #168] Woke up.
[INFO][12:04:28]: [Client #168] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_168_554860.pth.
[INFO][12:04:29]: [Client #168] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_168_554860.pth.
[INFO][12:04:29]: [Client #168] Model trained.
[INFO][12:04:29]: [Client #168] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:29]: [Server #554754] Received 0.26 MB of payload data from client #168 (simulated).
[INFO][12:04:29]: [Server #554754] Selecting client #109 for training.
[INFO][12:04:29]: [Server #554754] Sending the current model to client #109 (simulated).
[INFO][12:04:29]: [Server #554754] Sending 0.26 MB of payload data to client #109 (simulated).
[INFO][12:04:29]: [Server #554754] Selecting client #463 for training.
[INFO][12:04:29]: [Server #554754] Sending the current model to client #463 (simulated).
[INFO][12:04:29]: [Server #554754] Sending 0.26 MB of payload data to client #463 (simulated).
[INFO][12:04:29]: [Client #463] Selected by the server.
[INFO][12:04:29]: [Client #109] Selected by the server.
[INFO][12:04:29]: [Client #463] Loading its data source...
[INFO][12:04:29]: [Client #109] Loading its data source...
[INFO][12:04:29]: Data source: FEMNIST
[INFO][12:04:29]: Data source: FEMNIST
[INFO][12:04:29]: [Client #463] Dataset size: 155
[INFO][12:04:29]: [Client #463] Sampler: all_inclusive
[INFO][12:04:29]: [Client #109] Dataset size: 163
[INFO][12:04:29]: [Client #109] Sampler: all_inclusive
[INFO][12:04:29]: [Client #463] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:29]: [Client #109] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:29]: [93m[1m[Client #463] Started training in communication round #38.[0m
[INFO][12:04:29]: [93m[1m[Client #109] Started training in communication round #38.[0m
[INFO][12:04:31]: [Client #109] Loading the dataset.
[INFO][12:04:31]: [Client #463] Loading the dataset.
[INFO][12:04:36]: [Client #463] Epoch: [1/5][0/16]	Loss: 0.972124
[INFO][12:04:36]: [Client #109] Epoch: [1/5][0/17]	Loss: 0.337609
[INFO][12:04:36]: [Client #463] Epoch: [1/5][10/16]	Loss: 0.736427
[INFO][12:04:36]: [Client #109] Epoch: [1/5][10/17]	Loss: 0.720360
[INFO][12:04:36]: [Client #463] Going to sleep for 0.17 seconds.
[INFO][12:04:36]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][12:04:36]: [Client #463] Woke up.
[INFO][12:04:36]: [Client #463] Epoch: [2/5][0/16]	Loss: 0.585850
[INFO][12:04:36]: [Client #463] Epoch: [2/5][10/16]	Loss: 0.501592
[INFO][12:04:37]: [Client #463] Going to sleep for 0.17 seconds.
[INFO][12:04:37]: [Client #463] Woke up.
[INFO][12:04:37]: [Client #463] Epoch: [3/5][0/16]	Loss: 0.404740
[INFO][12:04:37]: [Client #463] Epoch: [3/5][10/16]	Loss: 1.465999
[INFO][12:04:37]: [Client #463] Going to sleep for 0.17 seconds.
[INFO][12:04:37]: [Client #463] Woke up.
[INFO][12:04:37]: [Client #463] Epoch: [4/5][0/16]	Loss: 0.779936
[INFO][12:04:37]: [Client #463] Epoch: [4/5][10/16]	Loss: 1.285990
[INFO][12:04:37]: [Client #463] Going to sleep for 0.17 seconds.
[INFO][12:04:37]: [Client #463] Woke up.
[INFO][12:04:37]: [Client #463] Epoch: [5/5][0/16]	Loss: 0.524399
[INFO][12:04:37]: [Client #463] Epoch: [5/5][10/16]	Loss: 0.743375
[INFO][12:04:37]: [Client #463] Going to sleep for 0.17 seconds.
[INFO][12:04:38]: [Client #463] Woke up.
[INFO][12:04:38]: [Client #463] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_463_554860.pth.
[INFO][12:04:38]: [Client #463] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_463_554860.pth.
[INFO][12:04:38]: [Client #463] Model trained.
[INFO][12:04:38]: [Client #463] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:38]: [Server #554754] Received 0.26 MB of payload data from client #463 (simulated).
[INFO][12:04:38]: [Client #109] Woke up.
[INFO][12:04:38]: [Client #109] Epoch: [2/5][0/17]	Loss: 0.514884
[INFO][12:04:39]: [Client #109] Epoch: [2/5][10/17]	Loss: 0.550473
[INFO][12:04:39]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][12:04:41]: [Client #109] Woke up.
[INFO][12:04:41]: [Client #109] Epoch: [3/5][0/17]	Loss: 0.521413
[INFO][12:04:41]: [Client #109] Epoch: [3/5][10/17]	Loss: 0.524722
[INFO][12:04:41]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][12:04:43]: [Client #109] Woke up.
[INFO][12:04:43]: [Client #109] Epoch: [4/5][0/17]	Loss: 0.263107
[INFO][12:04:43]: [Client #109] Epoch: [4/5][10/17]	Loss: 0.932125
[INFO][12:04:43]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][12:04:46]: [Client #109] Woke up.
[INFO][12:04:46]: [Client #109] Epoch: [5/5][0/17]	Loss: 0.278808
[INFO][12:04:46]: [Client #109] Epoch: [5/5][10/17]	Loss: 0.617200
[INFO][12:04:46]: [Client #109] Going to sleep for 2.24 seconds.
[INFO][12:04:48]: [Client #109] Woke up.
[INFO][12:04:48]: [Client #109] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554853.pth.
[INFO][12:04:49]: [Client #109] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_109_554853.pth.
[INFO][12:04:49]: [Client #109] Model trained.
[INFO][12:04:49]: [Client #109] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:49]: [Server #554754] Received 0.26 MB of payload data from client #109 (simulated).
[INFO][12:04:49]: [Server #554754] Selecting client #298 for training.
[INFO][12:04:49]: [Server #554754] Sending the current model to client #298 (simulated).
[INFO][12:04:49]: [Server #554754] Sending 0.26 MB of payload data to client #298 (simulated).
[INFO][12:04:49]: [Server #554754] Selecting client #372 for training.
[INFO][12:04:49]: [Server #554754] Sending the current model to client #372 (simulated).
[INFO][12:04:49]: [Server #554754] Sending 0.26 MB of payload data to client #372 (simulated).
[INFO][12:04:49]: [Client #298] Selected by the server.
[INFO][12:04:49]: [Client #298] Loading its data source...
[INFO][12:04:49]: Data source: FEMNIST
[INFO][12:04:49]: [Client #372] Selected by the server.
[INFO][12:04:49]: [Client #372] Loading its data source...
[INFO][12:04:49]: Data source: FEMNIST
[INFO][12:04:49]: [Client #298] Dataset size: 160
[INFO][12:04:49]: [Client #298] Sampler: all_inclusive
[INFO][12:04:49]: [Client #372] Dataset size: 161
[INFO][12:04:49]: [Client #372] Sampler: all_inclusive
[INFO][12:04:49]: [Client #298] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:49]: [93m[1m[Client #298] Started training in communication round #38.[0m
[INFO][12:04:49]: [Client #372] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:49]: [93m[1m[Client #372] Started training in communication round #38.[0m
[INFO][12:04:51]: [Client #372] Loading the dataset.
[INFO][12:04:51]: [Client #298] Loading the dataset.
[INFO][12:04:56]: [Client #372] Epoch: [1/5][0/17]	Loss: 1.224052
[INFO][12:04:56]: [Client #298] Epoch: [1/5][0/16]	Loss: 0.557749
[INFO][12:04:56]: [Client #372] Epoch: [1/5][10/17]	Loss: 1.625249
[INFO][12:04:56]: [Client #298] Epoch: [1/5][10/16]	Loss: 0.128595
[INFO][12:04:56]: [Client #372] Going to sleep for 0.03 seconds.
[INFO][12:04:56]: [Client #298] Going to sleep for 0.09 seconds.
[INFO][12:04:56]: [Client #372] Woke up.
[INFO][12:04:56]: [Client #372] Epoch: [2/5][0/17]	Loss: 0.338447
[INFO][12:04:56]: [Client #298] Woke up.
[INFO][12:04:56]: [Client #298] Epoch: [2/5][0/16]	Loss: 0.596563
[INFO][12:04:56]: [Client #372] Epoch: [2/5][10/17]	Loss: 0.562448
[INFO][12:04:56]: [Client #372] Going to sleep for 0.03 seconds.
[INFO][12:04:56]: [Client #372] Woke up.
[INFO][12:04:56]: [Client #372] Epoch: [3/5][0/17]	Loss: 0.425425
[INFO][12:04:56]: [Client #298] Epoch: [2/5][10/16]	Loss: 0.173835
[INFO][12:04:56]: [Client #298] Going to sleep for 0.09 seconds.
[INFO][12:04:56]: [Client #372] Epoch: [3/5][10/17]	Loss: 0.888345
[INFO][12:04:57]: [Client #372] Going to sleep for 0.03 seconds.
[INFO][12:04:57]: [Client #298] Woke up.
[INFO][12:04:57]: [Client #372] Woke up.
[INFO][12:04:57]: [Client #298] Epoch: [3/5][0/16]	Loss: 0.184631
[INFO][12:04:57]: [Client #372] Epoch: [4/5][0/17]	Loss: 0.740029
[INFO][12:04:57]: [Client #298] Epoch: [3/5][10/16]	Loss: 0.342519
[INFO][12:04:57]: [Client #372] Epoch: [4/5][10/17]	Loss: 0.462580
[INFO][12:04:57]: [Client #298] Going to sleep for 0.09 seconds.
[INFO][12:04:57]: [Client #372] Going to sleep for 0.03 seconds.
[INFO][12:04:57]: [Client #372] Woke up.
[INFO][12:04:57]: [Client #372] Epoch: [5/5][0/17]	Loss: 0.706980
[INFO][12:04:57]: [Client #298] Woke up.
[INFO][12:04:57]: [Client #298] Epoch: [4/5][0/16]	Loss: 0.239382
[INFO][12:04:57]: [Client #372] Epoch: [5/5][10/17]	Loss: 0.729147
[INFO][12:04:57]: [Client #372] Going to sleep for 0.03 seconds.
[INFO][12:04:57]: [Client #298] Epoch: [4/5][10/16]	Loss: 0.139636
[INFO][12:04:57]: [Client #372] Woke up.
[INFO][12:04:57]: [Client #372] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_372_554860.pth.
[INFO][12:04:57]: [Client #298] Going to sleep for 0.09 seconds.
[INFO][12:04:57]: [Client #298] Woke up.
[INFO][12:04:57]: [Client #298] Epoch: [5/5][0/16]	Loss: 0.335023
[INFO][12:04:57]: [Client #298] Epoch: [5/5][10/16]	Loss: 0.114763
[INFO][12:04:57]: [Client #298] Going to sleep for 0.09 seconds.
[INFO][12:04:57]: [Client #298] Woke up.
[INFO][12:04:57]: [Client #298] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_298_554853.pth.
[INFO][12:04:58]: [Client #372] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_372_554860.pth.
[INFO][12:04:58]: [Client #372] Model trained.
[INFO][12:04:58]: [Client #372] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:58]: [Server #554754] Received 0.26 MB of payload data from client #372 (simulated).
[INFO][12:04:58]: [Client #298] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_298_554853.pth.
[INFO][12:04:58]: [Client #298] Model trained.
[INFO][12:04:58]: [Client #298] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:04:58]: [Server #554754] Received 0.26 MB of payload data from client #298 (simulated).
[INFO][12:04:58]: [Server #554754] Selecting client #269 for training.
[INFO][12:04:58]: [Server #554754] Sending the current model to client #269 (simulated).
[INFO][12:04:58]: [Server #554754] Sending 0.26 MB of payload data to client #269 (simulated).
[INFO][12:04:58]: [Server #554754] Selecting client #350 for training.
[INFO][12:04:58]: [Server #554754] Sending the current model to client #350 (simulated).
[INFO][12:04:58]: [Server #554754] Sending 0.26 MB of payload data to client #350 (simulated).
[INFO][12:04:58]: [Client #269] Selected by the server.
[INFO][12:04:58]: [Client #269] Loading its data source...
[INFO][12:04:58]: Data source: FEMNIST
[INFO][12:04:58]: [Client #350] Selected by the server.
[INFO][12:04:58]: [Client #350] Loading its data source...
[INFO][12:04:58]: Data source: FEMNIST
[INFO][12:04:58]: [Client #350] Dataset size: 138
[INFO][12:04:58]: [Client #350] Sampler: all_inclusive
[INFO][12:04:58]: [Client #269] Dataset size: 163
[INFO][12:04:58]: [Client #269] Sampler: all_inclusive
[INFO][12:04:58]: [Client #350] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:58]: [Client #269] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:04:58]: [93m[1m[Client #350] Started training in communication round #38.[0m
[INFO][12:04:58]: [93m[1m[Client #269] Started training in communication round #38.[0m
[INFO][12:05:00]: [Client #269] Loading the dataset.
[INFO][12:05:00]: [Client #350] Loading the dataset.
[INFO][12:05:05]: [Client #269] Epoch: [1/5][0/17]	Loss: 0.959760
[INFO][12:05:05]: [Client #350] Epoch: [1/5][0/14]	Loss: 2.136653
[INFO][12:05:05]: [Client #269] Epoch: [1/5][10/17]	Loss: 0.326443
[INFO][12:05:05]: [Client #350] Epoch: [1/5][10/14]	Loss: 1.522813
[INFO][12:05:06]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][12:05:06]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][12:05:06]: [Client #350] Woke up.
[INFO][12:05:06]: [Client #350] Epoch: [2/5][0/14]	Loss: 1.236311
[INFO][12:05:06]: [Client #350] Epoch: [2/5][10/14]	Loss: 1.227386
[INFO][12:05:06]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][12:05:06]: [Client #350] Woke up.
[INFO][12:05:06]: [Client #350] Epoch: [3/5][0/14]	Loss: 0.506276
[INFO][12:05:06]: [Client #350] Epoch: [3/5][10/14]	Loss: 1.166344
[INFO][12:05:06]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][12:05:06]: [Client #350] Woke up.
[INFO][12:05:06]: [Client #350] Epoch: [4/5][0/14]	Loss: 1.327960
[INFO][12:05:06]: [Client #350] Epoch: [4/5][10/14]	Loss: 0.450317
[INFO][12:05:06]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][12:05:06]: [Client #350] Woke up.
[INFO][12:05:06]: [Client #350] Epoch: [5/5][0/14]	Loss: 0.368693
[INFO][12:05:06]: [Client #269] Woke up.
[INFO][12:05:06]: [Client #269] Epoch: [2/5][0/17]	Loss: 0.311261
[INFO][12:05:06]: [Client #350] Epoch: [5/5][10/14]	Loss: 0.422517
[INFO][12:05:06]: [Client #350] Going to sleep for 0.04 seconds.
[INFO][12:05:06]: [Client #350] Woke up.
[INFO][12:05:06]: [Client #350] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_350_554860.pth.
[INFO][12:05:06]: [Client #269] Epoch: [2/5][10/17]	Loss: 1.257431
[INFO][12:05:06]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][12:05:07]: [Client #350] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_350_554860.pth.
[INFO][12:05:07]: [Client #350] Model trained.
[INFO][12:05:07]: [Client #350] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:05:07]: [Server #554754] Received 0.26 MB of payload data from client #350 (simulated).
[INFO][12:05:07]: [Client #269] Woke up.
[INFO][12:05:07]: [Client #269] Epoch: [3/5][0/17]	Loss: 0.177090
[INFO][12:05:07]: [Client #269] Epoch: [3/5][10/17]	Loss: 0.850693
[INFO][12:05:07]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][12:05:08]: [Client #269] Woke up.
[INFO][12:05:08]: [Client #269] Epoch: [4/5][0/17]	Loss: 0.567805
[INFO][12:05:08]: [Client #269] Epoch: [4/5][10/17]	Loss: 0.142344
[INFO][12:05:08]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][12:05:08]: [Client #269] Woke up.
[INFO][12:05:08]: [Client #269] Epoch: [5/5][0/17]	Loss: 1.609569
[INFO][12:05:09]: [Client #269] Epoch: [5/5][10/17]	Loss: 0.312542
[INFO][12:05:09]: [Client #269] Going to sleep for 0.62 seconds.
[INFO][12:05:09]: [Client #269] Woke up.
[INFO][12:05:09]: [Client #269] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_269_554853.pth.
[INFO][12:05:10]: [Client #269] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_269_554853.pth.
[INFO][12:05:10]: [Client #269] Model trained.
[INFO][12:05:10]: [Client #269] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:05:10]: [Server #554754] Received 0.26 MB of payload data from client #269 (simulated).
[INFO][12:05:10]: [Server #554754] Adding client #372 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #394 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #350 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #298 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #184 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #463 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #222 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #269 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #168 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Adding client #68 to the list of clients for aggregation.
[INFO][12:05:10]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.52899817 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07171565
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0940555  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.22925134
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.26922575 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.046266   0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09643228 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10415286
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15595818 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.18358006 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.52899817 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07171565
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0940555  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.22925134
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.26922575 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.046266   0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09643228 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10415286
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15595818 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.18358006 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][12:05:56]: [Server #554754] Global model accuracy: 64.89%

[INFO][12:05:56]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_38.pth.
[INFO][12:05:56]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_38.pth.
[INFO][12:05:56]: [93m[1m
[Server #554754] Starting round 39/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.09055338
 0.002      0.04880988 0.09412436 0.04016585 0.002      0.002
 0.002      0.05131376 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.08837971
 0.002      0.09273039 0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.002      0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.002      0.10038363 0.04421543 0.002      0.002
 0.08749329 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.09706258 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04094325 0.002      0.002      0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.09387521
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.09101317 0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.10063694 0.10344828 0.002      0.002      0.10714286
 0.002      0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.18775043
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.07799948 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.15711948 0.10502283 0.0933028  0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.09158558 0.0473034  0.07882535
 0.002      0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.08900524 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.08749329 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.0502594  0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.07899256 0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.09215799
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.08986835 0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.002      0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10392902 0.15096419
 0.07566727 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.08872353 0.002      0.002      0.1026616  0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.002
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.09386973 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][12:05:56]: [Server #554754] Selected clients: [465 431  83 130  36 490 117 331  44 104]
[INFO][12:05:56]: [Server #554754] Selecting client #465 for training.
[INFO][12:05:56]: [Server #554754] Sending the current model to client #465 (simulated).
[INFO][12:05:56]: [Server #554754] Sending 0.26 MB of payload data to client #465 (simulated).
[INFO][12:05:56]: [Server #554754] Selecting client #431 for training.
[INFO][12:05:56]: [Server #554754] Sending the current model to client #431 (simulated).
[INFO][12:05:56]: [Server #554754] Sending 0.26 MB of payload data to client #431 (simulated).
[INFO][12:05:56]: [Client #465] Selected by the server.
[INFO][12:05:56]: [Client #465] Loading its data source...
[INFO][12:05:56]: Data source: FEMNIST
[INFO][12:05:56]: [Client #431] Selected by the server.
[INFO][12:05:56]: [Client #431] Loading its data source...
[INFO][12:05:56]: Data source: FEMNIST
[INFO][12:05:56]: [Client #465] Dataset size: 103
[INFO][12:05:56]: [Client #465] Sampler: all_inclusive
[INFO][12:05:56]: [Client #465] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:05:56]: [Client #431] Dataset size: 162
[INFO][12:05:56]: [Client #431] Sampler: all_inclusive
[INFO][12:05:56]: [Client #431] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:05:56]: [93m[1m[Client #465] Started training in communication round #39.[0m
[INFO][12:05:56]: [93m[1m[Client #431] Started training in communication round #39.[0m
[INFO][12:05:58]: [Client #465] Loading the dataset.
[INFO][12:05:58]: [Client #431] Loading the dataset.
[INFO][12:06:03]: [Client #465] Epoch: [1/5][0/11]	Loss: 0.730528
[INFO][12:06:03]: [Client #431] Epoch: [1/5][0/17]	Loss: 0.635827
[INFO][12:06:03]: [Client #465] Epoch: [1/5][10/11]	Loss: 0.514809
[INFO][12:06:03]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][12:06:03]: [Client #431] Epoch: [1/5][10/17]	Loss: 0.667828
[INFO][12:06:03]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:06:04]: [Client #431] Woke up.
[INFO][12:06:04]: [Client #431] Epoch: [2/5][0/17]	Loss: 0.182547
[INFO][12:06:04]: [Client #431] Epoch: [2/5][10/17]	Loss: 0.182731
[INFO][12:06:04]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:06:05]: [Client #431] Woke up.
[INFO][12:06:05]: [Client #431] Epoch: [3/5][0/17]	Loss: 0.062802
[INFO][12:06:05]: [Client #431] Epoch: [3/5][10/17]	Loss: 0.358527
[INFO][12:06:05]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:06:06]: [Client #431] Woke up.
[INFO][12:06:06]: [Client #431] Epoch: [4/5][0/17]	Loss: 0.698226
[INFO][12:06:06]: [Client #431] Epoch: [4/5][10/17]	Loss: 0.382112
[INFO][12:06:06]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:06:07]: [Client #431] Woke up.
[INFO][12:06:07]: [Client #431] Epoch: [5/5][0/17]	Loss: 0.014375
[INFO][12:06:07]: [Client #431] Epoch: [5/5][10/17]	Loss: 0.079890
[INFO][12:06:07]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:06:08]: [Client #465] Woke up.
[INFO][12:06:08]: [Client #465] Epoch: [2/5][0/11]	Loss: 0.816614
[INFO][12:06:08]: [Client #465] Epoch: [2/5][10/11]	Loss: 1.182603
[INFO][12:06:08]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][12:06:08]: [Client #431] Woke up.
[INFO][12:06:08]: [Client #431] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_554860.pth.
[INFO][12:06:09]: [Client #431] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_554860.pth.
[INFO][12:06:09]: [Client #431] Model trained.
[INFO][12:06:09]: [Client #431] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:06:09]: [Server #554754] Received 0.26 MB of payload data from client #431 (simulated).
[INFO][12:06:12]: [Client #465] Woke up.
[INFO][12:06:13]: [Client #465] Epoch: [3/5][0/11]	Loss: 0.576445
[INFO][12:06:13]: [Client #465] Epoch: [3/5][10/11]	Loss: 0.108999
[INFO][12:06:13]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][12:06:17]: [Client #465] Woke up.
[INFO][12:06:17]: [Client #465] Epoch: [4/5][0/11]	Loss: 0.921595
[INFO][12:06:17]: [Client #465] Epoch: [4/5][10/11]	Loss: 1.136184
[INFO][12:06:17]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][12:06:22]: [Client #465] Woke up.
[INFO][12:06:22]: [Client #465] Epoch: [5/5][0/11]	Loss: 0.375529
[INFO][12:06:22]: [Client #465] Epoch: [5/5][10/11]	Loss: 0.604971
[INFO][12:06:22]: [Client #465] Going to sleep for 4.53 seconds.
[INFO][12:06:26]: [Client #465] Woke up.
[INFO][12:06:26]: [Client #465] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_554853.pth.
[INFO][12:06:27]: [Client #465] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_465_554853.pth.
[INFO][12:06:27]: [Client #465] Model trained.
[INFO][12:06:27]: [Client #465] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:06:27]: [Server #554754] Received 0.26 MB of payload data from client #465 (simulated).
[INFO][12:06:27]: [Server #554754] Selecting client #83 for training.
[INFO][12:06:27]: [Server #554754] Sending the current model to client #83 (simulated).
[INFO][12:06:27]: [Server #554754] Sending 0.26 MB of payload data to client #83 (simulated).
[INFO][12:06:27]: [Server #554754] Selecting client #130 for training.
[INFO][12:06:27]: [Server #554754] Sending the current model to client #130 (simulated).
[INFO][12:06:27]: [Server #554754] Sending 0.26 MB of payload data to client #130 (simulated).
[INFO][12:06:27]: [Client #83] Selected by the server.
[INFO][12:06:27]: [Client #83] Loading its data source...
[INFO][12:06:27]: Data source: FEMNIST
[INFO][12:06:27]: [Client #130] Selected by the server.
[INFO][12:06:27]: [Client #130] Loading its data source...
[INFO][12:06:27]: Data source: FEMNIST
[INFO][12:06:27]: [Client #83] Dataset size: 160
[INFO][12:06:27]: [Client #83] Sampler: all_inclusive
[INFO][12:06:27]: [Client #83] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:06:27]: [93m[1m[Client #83] Started training in communication round #39.[0m
[INFO][12:06:27]: [Client #130] Dataset size: 159
[INFO][12:06:27]: [Client #130] Sampler: all_inclusive
[INFO][12:06:27]: [Client #130] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:06:27]: [93m[1m[Client #130] Started training in communication round #39.[0m
[INFO][12:06:29]: [Client #130] Loading the dataset.
[INFO][12:06:29]: [Client #83] Loading the dataset.
[INFO][12:06:34]: [Client #130] Epoch: [1/5][0/16]	Loss: 1.551435
[INFO][12:06:34]: [Client #83] Epoch: [1/5][0/16]	Loss: 0.329471
[INFO][12:06:34]: [Client #130] Epoch: [1/5][10/16]	Loss: 0.179040
[INFO][12:06:35]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][12:06:35]: [Client #83] Epoch: [1/5][10/16]	Loss: 0.639554
[INFO][12:06:35]: [Client #83] Going to sleep for 3.02 seconds.
[INFO][12:06:35]: [Client #130] Woke up.
[INFO][12:06:35]: [Client #130] Epoch: [2/5][0/16]	Loss: 0.589633
[INFO][12:06:35]: [Client #130] Epoch: [2/5][10/16]	Loss: 0.118281
[INFO][12:06:35]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][12:06:35]: [Client #130] Woke up.
[INFO][12:06:35]: [Client #130] Epoch: [3/5][0/16]	Loss: 1.475583
[INFO][12:06:36]: [Client #130] Epoch: [3/5][10/16]	Loss: 0.176117
[INFO][12:06:36]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][12:06:36]: [Client #130] Woke up.
[INFO][12:06:36]: [Client #130] Epoch: [4/5][0/16]	Loss: 0.538418
[INFO][12:06:36]: [Client #130] Epoch: [4/5][10/16]	Loss: 0.346782
[INFO][12:06:36]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][12:06:37]: [Client #130] Woke up.
[INFO][12:06:37]: [Client #130] Epoch: [5/5][0/16]	Loss: 0.034261
[INFO][12:06:37]: [Client #130] Epoch: [5/5][10/16]	Loss: 0.058113
[INFO][12:06:37]: [Client #130] Going to sleep for 0.39 seconds.
[INFO][12:06:37]: [Client #130] Woke up.
[INFO][12:06:37]: [Client #130] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_130_554860.pth.
[INFO][12:06:38]: [Client #83] Woke up.
[INFO][12:06:38]: [Client #83] Epoch: [2/5][0/16]	Loss: 0.426463
[INFO][12:06:38]: [Client #83] Epoch: [2/5][10/16]	Loss: 0.327044
[INFO][12:06:38]: [Client #130] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_130_554860.pth.
[INFO][12:06:38]: [Client #130] Model trained.
[INFO][12:06:38]: [Client #130] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:06:38]: [Server #554754] Received 0.26 MB of payload data from client #130 (simulated).
[INFO][12:06:38]: [Client #83] Going to sleep for 3.02 seconds.
[INFO][12:06:41]: [Client #83] Woke up.
[INFO][12:06:41]: [Client #83] Epoch: [3/5][0/16]	Loss: 0.655899
[INFO][12:06:41]: [Client #83] Epoch: [3/5][10/16]	Loss: 0.089881
[INFO][12:06:41]: [Client #83] Going to sleep for 3.02 seconds.
[INFO][12:06:44]: [Client #83] Woke up.
[INFO][12:06:44]: [Client #83] Epoch: [4/5][0/16]	Loss: 0.178919
[INFO][12:06:44]: [Client #83] Epoch: [4/5][10/16]	Loss: 0.373162
[INFO][12:06:44]: [Client #83] Going to sleep for 3.02 seconds.
[INFO][12:06:47]: [Client #83] Woke up.
[INFO][12:06:47]: [Client #83] Epoch: [5/5][0/16]	Loss: 0.161461
[INFO][12:06:47]: [Client #83] Epoch: [5/5][10/16]	Loss: 0.718123
[INFO][12:06:47]: [Client #83] Going to sleep for 3.02 seconds.
[INFO][12:06:50]: [Client #83] Woke up.
[INFO][12:06:50]: [Client #83] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_83_554853.pth.
[INFO][12:06:51]: [Client #83] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_83_554853.pth.
[INFO][12:06:51]: [Client #83] Model trained.
[INFO][12:06:51]: [Client #83] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:06:51]: [Server #554754] Received 0.26 MB of payload data from client #83 (simulated).
[INFO][12:06:51]: [Server #554754] Selecting client #36 for training.
[INFO][12:06:51]: [Server #554754] Sending the current model to client #36 (simulated).
[INFO][12:06:51]: [Server #554754] Sending 0.26 MB of payload data to client #36 (simulated).
[INFO][12:06:51]: [Server #554754] Selecting client #490 for training.
[INFO][12:06:51]: [Server #554754] Sending the current model to client #490 (simulated).
[INFO][12:06:51]: [Server #554754] Sending 0.26 MB of payload data to client #490 (simulated).
[INFO][12:06:51]: [Client #36] Selected by the server.
[INFO][12:06:51]: [Client #36] Loading its data source...
[INFO][12:06:51]: Data source: FEMNIST
[INFO][12:06:51]: [Client #490] Selected by the server.
[INFO][12:06:51]: [Client #490] Loading its data source...
[INFO][12:06:51]: Data source: FEMNIST
[INFO][12:06:51]: [Client #36] Dataset size: 162
[INFO][12:06:51]: [Client #36] Sampler: all_inclusive
[INFO][12:06:51]: [Client #490] Dataset size: 147
[INFO][12:06:51]: [Client #490] Sampler: all_inclusive
[INFO][12:06:51]: [Client #36] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:06:51]: [Client #490] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:06:51]: [93m[1m[Client #490] Started training in communication round #39.[0m
[INFO][12:06:51]: [93m[1m[Client #36] Started training in communication round #39.[0m
[INFO][12:06:53]: [Client #36] Loading the dataset.
[INFO][12:06:53]: [Client #490] Loading the dataset.
[INFO][12:06:58]: [Client #490] Epoch: [1/5][0/15]	Loss: 0.462437
[INFO][12:06:58]: [Client #36] Epoch: [1/5][0/17]	Loss: 1.440044
[INFO][12:06:58]: [Client #490] Epoch: [1/5][10/15]	Loss: 0.637026
[INFO][12:06:58]: [Client #36] Epoch: [1/5][10/17]	Loss: 0.429715
[INFO][12:06:58]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][12:06:58]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][12:06:59]: [Client #490] Woke up.
[INFO][12:06:59]: [Client #490] Epoch: [2/5][0/15]	Loss: 0.527108
[INFO][12:06:59]: [Client #36] Woke up.
[INFO][12:06:59]: [Client #36] Epoch: [2/5][0/17]	Loss: 0.799534
[INFO][12:06:59]: [Client #490] Epoch: [2/5][10/15]	Loss: 0.373982
[INFO][12:06:59]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][12:06:59]: [Client #36] Epoch: [2/5][10/17]	Loss: 0.339376
[INFO][12:06:59]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][12:06:59]: [Client #490] Woke up.
[INFO][12:06:59]: [Client #490] Epoch: [3/5][0/15]	Loss: 0.222229
[INFO][12:07:00]: [Client #36] Woke up.
[INFO][12:07:00]: [Client #36] Epoch: [3/5][0/17]	Loss: 0.070694
[INFO][12:07:00]: [Client #490] Epoch: [3/5][10/15]	Loss: 0.674683
[INFO][12:07:00]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][12:07:00]: [Client #36] Epoch: [3/5][10/17]	Loss: 1.295551
[INFO][12:07:00]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][12:07:00]: [Client #490] Woke up.
[INFO][12:07:00]: [Client #490] Epoch: [4/5][0/15]	Loss: 0.525920
[INFO][12:07:00]: [Client #36] Woke up.
[INFO][12:07:00]: [Client #36] Epoch: [4/5][0/17]	Loss: 0.732553
[INFO][12:07:00]: [Client #490] Epoch: [4/5][10/15]	Loss: 0.134541
[INFO][12:07:00]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][12:07:00]: [Client #36] Epoch: [4/5][10/17]	Loss: 0.944657
[INFO][12:07:00]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][12:07:01]: [Client #490] Woke up.
[INFO][12:07:01]: [Client #490] Epoch: [5/5][0/15]	Loss: 0.867933
[INFO][12:07:01]: [Client #36] Woke up.
[INFO][12:07:01]: [Client #36] Epoch: [5/5][0/17]	Loss: 0.235971
[INFO][12:07:01]: [Client #490] Epoch: [5/5][10/15]	Loss: 0.694790
[INFO][12:07:01]: [Client #490] Going to sleep for 0.45 seconds.
[INFO][12:07:01]: [Client #36] Epoch: [5/5][10/17]	Loss: 0.361289
[INFO][12:07:01]: [Client #36] Going to sleep for 0.46 seconds.
[INFO][12:07:01]: [Client #490] Woke up.
[INFO][12:07:01]: [Client #490] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_490_554860.pth.
[INFO][12:07:01]: [Client #36] Woke up.
[INFO][12:07:01]: [Client #36] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][12:07:02]: [Client #490] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_490_554860.pth.
[INFO][12:07:02]: [Client #490] Model trained.
[INFO][12:07:02]: [Client #490] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:02]: [Server #554754] Received 0.26 MB of payload data from client #490 (simulated).
[INFO][12:07:02]: [Client #36] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_36_554853.pth.
[INFO][12:07:02]: [Client #36] Model trained.
[INFO][12:07:02]: [Client #36] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:02]: [Server #554754] Received 0.26 MB of payload data from client #36 (simulated).
[INFO][12:07:02]: [Server #554754] Selecting client #117 for training.
[INFO][12:07:02]: [Server #554754] Sending the current model to client #117 (simulated).
[INFO][12:07:02]: [Server #554754] Sending 0.26 MB of payload data to client #117 (simulated).
[INFO][12:07:02]: [Server #554754] Selecting client #331 for training.
[INFO][12:07:02]: [Server #554754] Sending the current model to client #331 (simulated).
[INFO][12:07:02]: [Server #554754] Sending 0.26 MB of payload data to client #331 (simulated).
[INFO][12:07:02]: [Client #117] Selected by the server.
[INFO][12:07:02]: [Client #117] Loading its data source...
[INFO][12:07:02]: Data source: FEMNIST
[INFO][12:07:02]: [Client #331] Selected by the server.
[INFO][12:07:02]: [Client #331] Loading its data source...
[INFO][12:07:02]: Data source: FEMNIST
[INFO][12:07:02]: [Client #117] Dataset size: 152
[INFO][12:07:02]: [Client #117] Sampler: all_inclusive
[INFO][12:07:02]: [Client #331] Dataset size: 163
[INFO][12:07:02]: [Client #331] Sampler: all_inclusive
[INFO][12:07:02]: [Client #117] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:07:02]: [Client #331] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:07:02]: [93m[1m[Client #117] Started training in communication round #39.[0m
[INFO][12:07:02]: [93m[1m[Client #331] Started training in communication round #39.[0m
[INFO][12:07:04]: [Client #117] Loading the dataset.
[INFO][12:07:04]: [Client #331] Loading the dataset.
[INFO][12:07:09]: [Client #117] Epoch: [1/5][0/16]	Loss: 0.071349
[INFO][12:07:09]: [Client #331] Epoch: [1/5][0/17]	Loss: 0.088704
[INFO][12:07:09]: [Client #117] Epoch: [1/5][10/16]	Loss: 1.144537
[INFO][12:07:09]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][12:07:09]: [Client #331] Epoch: [1/5][10/17]	Loss: 0.519002
[INFO][12:07:10]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][12:07:10]: [Client #331] Woke up.
[INFO][12:07:10]: [Client #331] Epoch: [2/5][0/17]	Loss: 0.135764
[INFO][12:07:10]: [Client #331] Epoch: [2/5][10/17]	Loss: 0.272249
[INFO][12:07:10]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][12:07:10]: [Client #331] Woke up.
[INFO][12:07:10]: [Client #331] Epoch: [3/5][0/17]	Loss: 0.324783
[INFO][12:07:10]: [Client #331] Epoch: [3/5][10/17]	Loss: 0.347264
[INFO][12:07:10]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][12:07:10]: [Client #331] Woke up.
[INFO][12:07:10]: [Client #331] Epoch: [4/5][0/17]	Loss: 0.441667
[INFO][12:07:10]: [Client #331] Epoch: [4/5][10/17]	Loss: 0.198428
[INFO][12:07:11]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][12:07:11]: [Client #331] Woke up.
[INFO][12:07:11]: [Client #331] Epoch: [5/5][0/17]	Loss: 0.331475
[INFO][12:07:11]: [Client #331] Epoch: [5/5][10/17]	Loss: 0.152223
[INFO][12:07:11]: [Client #331] Going to sleep for 0.17 seconds.
[INFO][12:07:11]: [Client #331] Woke up.
[INFO][12:07:11]: [Client #331] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554860.pth.
[INFO][12:07:12]: [Client #331] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_331_554860.pth.
[INFO][12:07:12]: [Client #331] Model trained.
[INFO][12:07:12]: [Client #331] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:12]: [Server #554754] Received 0.26 MB of payload data from client #331 (simulated).
[INFO][12:07:13]: [Client #117] Woke up.
[INFO][12:07:13]: [Client #117] Epoch: [2/5][0/16]	Loss: 0.411657
[INFO][12:07:13]: [Client #117] Epoch: [2/5][10/16]	Loss: 0.637454
[INFO][12:07:13]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][12:07:16]: [Client #117] Woke up.
[INFO][12:07:16]: [Client #117] Epoch: [3/5][0/16]	Loss: 0.199575
[INFO][12:07:16]: [Client #117] Epoch: [3/5][10/16]	Loss: 0.996494
[INFO][12:07:16]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][12:07:19]: [Client #117] Woke up.
[INFO][12:07:19]: [Client #117] Epoch: [4/5][0/16]	Loss: 0.221372
[INFO][12:07:19]: [Client #117] Epoch: [4/5][10/16]	Loss: 0.725682
[INFO][12:07:19]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][12:07:22]: [Client #117] Woke up.
[INFO][12:07:22]: [Client #117] Epoch: [5/5][0/16]	Loss: 0.809384
[INFO][12:07:22]: [Client #117] Epoch: [5/5][10/16]	Loss: 0.313215
[INFO][12:07:22]: [Client #117] Going to sleep for 3.06 seconds.
[INFO][12:07:25]: [Client #117] Woke up.
[INFO][12:07:25]: [Client #117] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_554853.pth.
[INFO][12:07:26]: [Client #117] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_117_554853.pth.
[INFO][12:07:26]: [Client #117] Model trained.
[INFO][12:07:26]: [Client #117] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:26]: [Server #554754] Received 0.26 MB of payload data from client #117 (simulated).
[INFO][12:07:26]: [Server #554754] Selecting client #44 for training.
[INFO][12:07:26]: [Server #554754] Sending the current model to client #44 (simulated).
[INFO][12:07:26]: [Server #554754] Sending 0.26 MB of payload data to client #44 (simulated).
[INFO][12:07:26]: [Server #554754] Selecting client #104 for training.
[INFO][12:07:26]: [Server #554754] Sending the current model to client #104 (simulated).
[INFO][12:07:26]: [Server #554754] Sending 0.26 MB of payload data to client #104 (simulated).
[INFO][12:07:26]: [Client #44] Selected by the server.
[INFO][12:07:26]: [Client #44] Loading its data source...
[INFO][12:07:26]: Data source: FEMNIST
[INFO][12:07:26]: [Client #104] Selected by the server.
[INFO][12:07:26]: [Client #104] Loading its data source...
[INFO][12:07:26]: Data source: FEMNIST
[INFO][12:07:26]: [Client #44] Dataset size: 166
[INFO][12:07:26]: [Client #44] Sampler: all_inclusive
[INFO][12:07:26]: [Client #44] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:07:26]: [93m[1m[Client #44] Started training in communication round #39.[0m
[INFO][12:07:26]: [Client #104] Dataset size: 152
[INFO][12:07:26]: [Client #104] Sampler: all_inclusive
[INFO][12:07:26]: [Client #104] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:07:26]: [93m[1m[Client #104] Started training in communication round #39.[0m
[INFO][12:07:28]: [Client #104] Loading the dataset.
[INFO][12:07:28]: [Client #44] Loading the dataset.
[INFO][12:07:34]: [Client #44] Epoch: [1/5][0/17]	Loss: 1.049473
[INFO][12:07:34]: [Client #104] Epoch: [1/5][0/16]	Loss: 0.279489
[INFO][12:07:34]: [Client #44] Epoch: [1/5][10/17]	Loss: 0.724272
[INFO][12:07:34]: [Client #104] Epoch: [1/5][10/16]	Loss: 0.778263
[INFO][12:07:34]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:07:34]: [Client #104] Going to sleep for 0.56 seconds.
[INFO][12:07:34]: [Client #104] Woke up.
[INFO][12:07:34]: [Client #104] Epoch: [2/5][0/16]	Loss: 0.213201
[INFO][12:07:34]: [Client #104] Epoch: [2/5][10/16]	Loss: 0.809674
[INFO][12:07:34]: [Client #104] Going to sleep for 0.56 seconds.
[INFO][12:07:35]: [Client #104] Woke up.
[INFO][12:07:35]: [Client #104] Epoch: [3/5][0/16]	Loss: 0.257485
[INFO][12:07:35]: [Client #104] Epoch: [3/5][10/16]	Loss: 0.350389
[INFO][12:07:35]: [Client #104] Going to sleep for 0.56 seconds.
[INFO][12:07:36]: [Client #104] Woke up.
[INFO][12:07:36]: [Client #104] Epoch: [4/5][0/16]	Loss: 0.345690
[INFO][12:07:36]: [Client #104] Epoch: [4/5][10/16]	Loss: 0.834688
[INFO][12:07:36]: [Client #104] Going to sleep for 0.56 seconds.
[INFO][12:07:36]: [Client #104] Woke up.
[INFO][12:07:36]: [Client #104] Epoch: [5/5][0/16]	Loss: 0.789283
[INFO][12:07:36]: [Client #104] Epoch: [5/5][10/16]	Loss: 0.343245
[INFO][12:07:37]: [Client #104] Going to sleep for 0.56 seconds.
[INFO][12:07:37]: [Client #104] Woke up.
[INFO][12:07:37]: [Client #104] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_104_554860.pth.
[INFO][12:07:37]: [Client #44] Woke up.
[INFO][12:07:37]: [Client #44] Epoch: [2/5][0/17]	Loss: 0.414760
[INFO][12:07:37]: [Client #44] Epoch: [2/5][10/17]	Loss: 0.201431
[INFO][12:07:38]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:07:38]: [Client #104] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_104_554860.pth.
[INFO][12:07:38]: [Client #104] Model trained.
[INFO][12:07:38]: [Client #104] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:38]: [Server #554754] Received 0.26 MB of payload data from client #104 (simulated).
[INFO][12:07:41]: [Client #44] Woke up.
[INFO][12:07:41]: [Client #44] Epoch: [3/5][0/17]	Loss: 0.475614
[INFO][12:07:41]: [Client #44] Epoch: [3/5][10/17]	Loss: 0.439737
[INFO][12:07:41]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:07:45]: [Client #44] Woke up.
[INFO][12:07:45]: [Client #44] Epoch: [4/5][0/17]	Loss: 0.574747
[INFO][12:07:45]: [Client #44] Epoch: [4/5][10/17]	Loss: 0.087371
[INFO][12:07:45]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:07:49]: [Client #44] Woke up.
[INFO][12:07:49]: [Client #44] Epoch: [5/5][0/17]	Loss: 0.573894
[INFO][12:07:49]: [Client #44] Epoch: [5/5][10/17]	Loss: 1.781203
[INFO][12:07:49]: [Client #44] Going to sleep for 3.75 seconds.
[INFO][12:07:53]: [Client #44] Woke up.
[INFO][12:07:53]: [Client #44] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_554853.pth.
[INFO][12:07:54]: [Client #44] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_44_554853.pth.
[INFO][12:07:54]: [Client #44] Model trained.
[INFO][12:07:54]: [Client #44] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:07:54]: [Server #554754] Received 0.26 MB of payload data from client #44 (simulated).
[INFO][12:07:54]: [Server #554754] Adding client #480 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #199 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #267 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #109 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #331 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #130 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #490 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #36 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #104 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #194 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #431 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #245 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #301 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #343 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #320 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #83 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #117 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #44 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #465 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Adding client #445 to the list of clients for aggregation.
[INFO][12:07:54]: [Server #554754] Aggregating 20 clients in total.
[0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00202508 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204059 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204041 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00202869 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00203672
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204077 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204051
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204028 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00203959 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00203914 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089 0.00204089
 0.00204089 0.00204089 0.00204089 0.00204089]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10341299
 0.         0.         0.         0.         0.         0.
 0.         0.1122154  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06588389 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13538227 0.         0.         0.         0.
 0.19261432 0.         0.         0.         0.         0.
 0.         0.         0.11003344 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1474803  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06612098 0.         0.         0.         0.
 0.09391986 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.42817586 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.21855521 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.2749541  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15166005 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08579519 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0850545  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07473489 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.2349312  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.22729098 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08830362
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1375085  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.10341299
 0.         0.         0.         0.         0.         0.
 0.         0.1122154  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06588389 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13538227 0.         0.         0.         0.
 0.19261432 0.         0.         0.         0.         0.
 0.         0.         0.11003344 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1474803  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.06612098 0.         0.         0.         0.
 0.09391986 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.42817586 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.21855521 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.2749541  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15166005 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08579519 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0850545  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07473489 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.2349312  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.22729098 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08830362
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.1375085  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][12:08:38]: [Server #554754] Global model accuracy: 65.48%

[INFO][12:08:38]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_39.pth.
[INFO][12:08:38]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_39.pth.
[INFO][12:08:38]: [93m[1m
[Server #554754] Starting round 40/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.0988806  0.0912031  0.07783145 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.046167
 0.002      0.04880988 0.09412436 0.04016585 0.002      0.002
 0.002      0.04730693 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08707865 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.08837971
 0.002      0.09273039 0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.002
 0.002      0.002      0.09858247 0.002      0.04559704 0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.04331718 0.10038363 0.04421543 0.002      0.002
 0.04645198 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.04331718 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04094325 0.002      0.04531205 0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.09387521
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.09101317 0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.04502707 0.10344828 0.002      0.002      0.10714286
 0.04502707 0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.18775043
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.08577942 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.08116883 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.08207467 0.10502283 0.0933028  0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.09158558 0.0473034  0.07882535
 0.04331718 0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.04360217 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.04645198 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.04417213 0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.07899256 0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.09215799
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.08986835 0.09514925 0.002
 0.09213483 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.002
 0.002      0.10419397 0.05415045 0.04659289 0.046167   0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10392902 0.15096419
 0.08321459 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.08872353 0.002      0.02935309 0.1026616  0.002      0.09615385
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.04645198
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.04189228 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.002     ]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9070e+00  7e-04  1e-08  1e-08
 5:  6.9078e+00  6.9073e+00  4e-04  6e-09  6e-09
 6:  6.9077e+00  6.9073e+00  4e-04  1e-07  4e-08
 7:  6.9076e+00  6.9074e+00  3e-04  8e-08  4e-08
 8:  6.9076e+00  6.9074e+00  2e-04  2e-07  1e-07
 9:  6.9074e+00  6.9074e+00  4e-05  4e-07  2e-07
10:  6.9074e+00  6.9074e+00  7e-06  9e-08  4e-08
11:  6.9074e+00  6.9074e+00  3e-07  5e-09  2e-09
Optimal solution found.
The calculated probability is:  [2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32092436e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32085012e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32111410e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32076456e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 1.81314337e-05 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32092540e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32062311e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 3.66357216e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 4.66602014e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 9.97117485e-01 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 3.41606232e-05 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 1.60736808e-03 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 9.03266911e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32101958e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 4.30188251e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32107441e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 5.93580727e-05 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32062512e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 4.42972241e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32078119e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06
 2.32123848e-06 2.32123848e-06 2.32123848e-06 2.32123848e-06]
current clients pool:  [INFO][12:08:39]: [Server #554754] Selected clients: [245 301   7  66 441  93 426 320 397 468 500  78  39  41   9 485  53 439
 352 259]
[INFO][12:08:39]: [Server #554754] Selecting client #245 for training.
[INFO][12:08:39]: [Server #554754] Sending the current model to client #245 (simulated).
[INFO][12:08:39]: [Server #554754] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][12:08:39]: [Server #554754] Selecting client #301 for training.
[INFO][12:08:39]: [Server #554754] Sending the current model to client #301 (simulated).
[INFO][12:08:39]: [Server #554754] Sending 0.26 MB of payload data to client #301 (simulated).
[INFO][12:08:39]: [Client #245] Selected by the server.
[INFO][12:08:39]: [Client #245] Loading its data source...
[INFO][12:08:39]: Data source: FEMNIST
[INFO][12:08:39]: [Client #301] Selected by the server.
[INFO][12:08:39]: [Client #301] Loading its data source...
[INFO][12:08:39]: Data source: FEMNIST
[INFO][12:08:39]: [Client #301] Dataset size: 152
[INFO][12:08:39]: [Client #301] Sampler: all_inclusive
[INFO][12:08:39]: [Client #245] Dataset size: 301
[INFO][12:08:39]: [Client #245] Sampler: all_inclusive
[INFO][12:08:39]: [Client #301] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:08:39]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:08:39]: [93m[1m[Client #301] Started training in communication round #40.[0m
[INFO][12:08:39]: [93m[1m[Client #245] Started training in communication round #40.[0m
[INFO][12:08:41]: [Client #245] Loading the dataset.
[INFO][12:08:41]: [Client #301] Loading the dataset.
[INFO][12:08:46]: [Client #245] Epoch: [1/5][0/31]	Loss: 0.656959
[INFO][12:08:46]: [Client #245] Epoch: [1/5][10/31]	Loss: 0.966114
[INFO][12:08:46]: [Client #301] Epoch: [1/5][0/16]	Loss: 0.957132
[INFO][12:08:46]: [Client #245] Epoch: [1/5][20/31]	Loss: 1.020329
[INFO][12:08:46]: [Client #301] Epoch: [1/5][10/16]	Loss: 0.632967
[INFO][12:08:46]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:08:46]: [Client #245] Epoch: [1/5][30/31]	Loss: 0.288172
[INFO][12:08:46]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:08:50]: [Client #245] Woke up.
[INFO][12:08:50]: [Client #245] Epoch: [2/5][0/31]	Loss: 1.132714
[INFO][12:08:50]: [Client #245] Epoch: [2/5][10/31]	Loss: 0.244935
[INFO][12:08:50]: [Client #245] Epoch: [2/5][20/31]	Loss: 0.714337
[INFO][12:08:50]: [Client #245] Epoch: [2/5][30/31]	Loss: 0.485855
[INFO][12:08:50]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:08:50]: [Client #301] Woke up.
[INFO][12:08:50]: [Client #301] Epoch: [2/5][0/16]	Loss: 0.249928
[INFO][12:08:50]: [Client #301] Epoch: [2/5][10/16]	Loss: 0.654275
[INFO][12:08:51]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:08:54]: [Client #245] Woke up.
[INFO][12:08:54]: [Client #245] Epoch: [3/5][0/31]	Loss: 0.401663
[INFO][12:08:54]: [Client #245] Epoch: [3/5][10/31]	Loss: 2.242266
[INFO][12:08:54]: [Client #245] Epoch: [3/5][20/31]	Loss: 0.564265
[INFO][12:08:54]: [Client #245] Epoch: [3/5][30/31]	Loss: 0.694798
[INFO][12:08:54]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:08:55]: [Client #301] Woke up.
[INFO][12:08:55]: [Client #301] Epoch: [3/5][0/16]	Loss: 0.268475
[INFO][12:08:55]: [Client #301] Epoch: [3/5][10/16]	Loss: 0.950958
[INFO][12:08:55]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:08:58]: [Client #245] Woke up.
[INFO][12:08:58]: [Client #245] Epoch: [4/5][0/31]	Loss: 0.986291
[INFO][12:08:58]: [Client #245] Epoch: [4/5][10/31]	Loss: 0.919070
[INFO][12:08:58]: [Client #245] Epoch: [4/5][20/31]	Loss: 0.560818
[INFO][12:08:58]: [Client #245] Epoch: [4/5][30/31]	Loss: 0.017348
[INFO][12:08:58]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:08:59]: [Client #301] Woke up.
[INFO][12:08:59]: [Client #301] Epoch: [4/5][0/16]	Loss: 0.169955
[INFO][12:08:59]: [Client #301] Epoch: [4/5][10/16]	Loss: 1.439756
[INFO][12:08:59]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:09:02]: [Client #245] Woke up.
[INFO][12:09:02]: [Client #245] Epoch: [5/5][0/31]	Loss: 0.985627
[INFO][12:09:02]: [Client #245] Epoch: [5/5][10/31]	Loss: 0.781981
[INFO][12:09:02]: [Client #245] Epoch: [5/5][20/31]	Loss: 1.000320
[INFO][12:09:02]: [Client #245] Epoch: [5/5][30/31]	Loss: 0.074394
[INFO][12:09:02]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:09:04]: [Client #301] Woke up.
[INFO][12:09:04]: [Client #301] Epoch: [5/5][0/16]	Loss: 1.063310
[INFO][12:09:04]: [Client #301] Epoch: [5/5][10/16]	Loss: 1.010483
[INFO][12:09:04]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:09:06]: [Client #245] Woke up.
[INFO][12:09:06]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554853.pth.
[INFO][12:09:06]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554853.pth.
[INFO][12:09:06]: [Client #245] Model trained.
[INFO][12:09:06]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:06]: [Server #554754] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][12:09:08]: [Client #301] Woke up.
[INFO][12:09:08]: [Client #301] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554860.pth.
[INFO][12:09:09]: [Client #301] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554860.pth.
[INFO][12:09:09]: [Client #301] Model trained.
[INFO][12:09:09]: [Client #301] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:09]: [Server #554754] Received 0.26 MB of payload data from client #301 (simulated).
[INFO][12:09:09]: [Server #554754] Selecting client #7 for training.
[INFO][12:09:09]: [Server #554754] Sending the current model to client #7 (simulated).
[INFO][12:09:09]: [Server #554754] Sending 0.26 MB of payload data to client #7 (simulated).
[INFO][12:09:09]: [Server #554754] Selecting client #66 for training.
[INFO][12:09:09]: [Server #554754] Sending the current model to client #66 (simulated).
[INFO][12:09:09]: [Server #554754] Sending 0.26 MB of payload data to client #66 (simulated).
[INFO][12:09:09]: [Client #66] Selected by the server.
[INFO][12:09:09]: [Client #7] Selected by the server.
[INFO][12:09:09]: [Client #66] Loading its data source...
[INFO][12:09:09]: [Client #7] Loading its data source...
[INFO][12:09:09]: Data source: FEMNIST
[INFO][12:09:09]: Data source: FEMNIST
[INFO][12:09:09]: [Client #7] Dataset size: 159
[INFO][12:09:09]: [Client #7] Sampler: all_inclusive
[INFO][12:09:09]: [Client #66] Dataset size: 162
[INFO][12:09:09]: [Client #66] Sampler: all_inclusive
[INFO][12:09:09]: [Client #66] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:09]: [Client #7] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:09]: [93m[1m[Client #7] Started training in communication round #40.[0m
[INFO][12:09:09]: [93m[1m[Client #66] Started training in communication round #40.[0m
[INFO][12:09:11]: [Client #7] Loading the dataset.
[INFO][12:09:11]: [Client #66] Loading the dataset.
[INFO][12:09:16]: [Client #66] Epoch: [1/5][0/17]	Loss: 1.811778
[INFO][12:09:17]: [Client #7] Epoch: [1/5][0/16]	Loss: 0.846786
[INFO][12:09:17]: [Client #66] Epoch: [1/5][10/17]	Loss: 0.773698
[INFO][12:09:17]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][12:09:17]: [Client #7] Epoch: [1/5][10/16]	Loss: 0.595303
[INFO][12:09:17]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][12:09:17]: [Client #7] Woke up.
[INFO][12:09:17]: [Client #7] Epoch: [2/5][0/16]	Loss: 0.138328
[INFO][12:09:17]: [Client #7] Epoch: [2/5][10/16]	Loss: 0.342562
[INFO][12:09:17]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][12:09:17]: [Client #7] Woke up.
[INFO][12:09:17]: [Client #7] Epoch: [3/5][0/16]	Loss: 0.225686
[INFO][12:09:17]: [Client #7] Epoch: [3/5][10/16]	Loss: 0.168644
[INFO][12:09:17]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][12:09:18]: [Client #7] Woke up.
[INFO][12:09:18]: [Client #7] Epoch: [4/5][0/16]	Loss: 0.244919
[INFO][12:09:18]: [Client #7] Epoch: [4/5][10/16]	Loss: 0.688683
[INFO][12:09:18]: [Client #66] Woke up.
[INFO][12:09:18]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][12:09:18]: [Client #66] Epoch: [2/5][0/17]	Loss: 0.615167
[INFO][12:09:18]: [Client #66] Epoch: [2/5][10/17]	Loss: 1.054515
[INFO][12:09:18]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][12:09:18]: [Client #7] Woke up.
[INFO][12:09:18]: [Client #7] Epoch: [5/5][0/16]	Loss: 0.308125
[INFO][12:09:18]: [Client #7] Epoch: [5/5][10/16]	Loss: 0.944898
[INFO][12:09:18]: [Client #7] Going to sleep for 0.23 seconds.
[INFO][12:09:18]: [Client #7] Woke up.
[INFO][12:09:18]: [Client #7] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554853.pth.
[INFO][12:09:19]: [Client #7] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_7_554853.pth.
[INFO][12:09:19]: [Client #7] Model trained.
[INFO][12:09:19]: [Client #7] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:19]: [Server #554754] Received 0.26 MB of payload data from client #7 (simulated).
[INFO][12:09:19]: [Client #66] Woke up.
[INFO][12:09:19]: [Client #66] Epoch: [3/5][0/17]	Loss: 0.582249
[INFO][12:09:19]: [Client #66] Epoch: [3/5][10/17]	Loss: 0.304739
[INFO][12:09:19]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][12:09:20]: [Client #66] Woke up.
[INFO][12:09:20]: [Client #66] Epoch: [4/5][0/17]	Loss: 0.093771
[INFO][12:09:20]: [Client #66] Epoch: [4/5][10/17]	Loss: 0.591632
[INFO][12:09:21]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][12:09:22]: [Client #66] Woke up.
[INFO][12:09:22]: [Client #66] Epoch: [5/5][0/17]	Loss: 0.731561
[INFO][12:09:22]: [Client #66] Epoch: [5/5][10/17]	Loss: 0.160140
[INFO][12:09:22]: [Client #66] Going to sleep for 1.15 seconds.
[INFO][12:09:23]: [Client #66] Woke up.
[INFO][12:09:23]: [Client #66] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][12:09:24]: [Client #66] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_66_554860.pth.
[INFO][12:09:24]: [Client #66] Model trained.
[INFO][12:09:24]: [Client #66] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:24]: [Server #554754] Received 0.26 MB of payload data from client #66 (simulated).
[INFO][12:09:24]: [Server #554754] Selecting client #441 for training.
[INFO][12:09:24]: [Server #554754] Sending the current model to client #441 (simulated).
[INFO][12:09:24]: [Server #554754] Sending 0.26 MB of payload data to client #441 (simulated).
[INFO][12:09:24]: [Server #554754] Selecting client #93 for training.
[INFO][12:09:24]: [Server #554754] Sending the current model to client #93 (simulated).
[INFO][12:09:24]: [Server #554754] Sending 0.26 MB of payload data to client #93 (simulated).
[INFO][12:09:24]: [Client #441] Selected by the server.
[INFO][12:09:24]: [Client #93] Selected by the server.
[INFO][12:09:24]: [Client #441] Loading its data source...
[INFO][12:09:24]: [Client #93] Loading its data source...
[INFO][12:09:24]: Data source: FEMNIST
[INFO][12:09:24]: Data source: FEMNIST
[INFO][12:09:24]: [Client #441] Dataset size: 155
[INFO][12:09:24]: [Client #441] Sampler: all_inclusive
[INFO][12:09:24]: [Client #93] Dataset size: 156
[INFO][12:09:24]: [Client #93] Sampler: all_inclusive
[INFO][12:09:24]: [Client #441] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:24]: [Client #93] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:24]: [93m[1m[Client #441] Started training in communication round #40.[0m
[INFO][12:09:24]: [93m[1m[Client #93] Started training in communication round #40.[0m
[INFO][12:09:26]: [Client #441] Loading the dataset.
[INFO][12:09:26]: [Client #93] Loading the dataset.
[INFO][12:09:31]: [Client #441] Epoch: [1/5][0/16]	Loss: 0.974013
[INFO][12:09:31]: [Client #93] Epoch: [1/5][0/16]	Loss: 1.472772
[INFO][12:09:31]: [Client #441] Epoch: [1/5][10/16]	Loss: 0.537164
[INFO][12:09:31]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][12:09:31]: [Client #93] Epoch: [1/5][10/16]	Loss: 1.062141
[INFO][12:09:31]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][12:09:32]: [Client #93] Woke up.
[INFO][12:09:32]: [Client #93] Epoch: [2/5][0/16]	Loss: 0.361297
[INFO][12:09:32]: [Client #93] Epoch: [2/5][10/16]	Loss: 0.710920
[INFO][12:09:32]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][12:09:33]: [Client #441] Woke up.
[INFO][12:09:33]: [Client #441] Epoch: [2/5][0/16]	Loss: 0.748930
[INFO][12:09:33]: [Client #441] Epoch: [2/5][10/16]	Loss: 0.616407
[INFO][12:09:33]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][12:09:33]: [Client #93] Woke up.
[INFO][12:09:33]: [Client #93] Epoch: [3/5][0/16]	Loss: 0.728676
[INFO][12:09:33]: [Client #93] Epoch: [3/5][10/16]	Loss: 0.928757
[INFO][12:09:33]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][12:09:34]: [Client #93] Woke up.
[INFO][12:09:34]: [Client #93] Epoch: [4/5][0/16]	Loss: 0.612726
[INFO][12:09:34]: [Client #93] Epoch: [4/5][10/16]	Loss: 0.247505
[INFO][12:09:34]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][12:09:35]: [Client #441] Woke up.
[INFO][12:09:35]: [Client #441] Epoch: [3/5][0/16]	Loss: 0.273721
[INFO][12:09:35]: [Client #441] Epoch: [3/5][10/16]	Loss: 0.186634
[INFO][12:09:35]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][12:09:35]: [Client #93] Woke up.
[INFO][12:09:35]: [Client #93] Epoch: [5/5][0/16]	Loss: 0.133036
[INFO][12:09:35]: [Client #93] Epoch: [5/5][10/16]	Loss: 0.248426
[INFO][12:09:35]: [Client #93] Going to sleep for 0.82 seconds.
[INFO][12:09:36]: [Client #93] Woke up.
[INFO][12:09:36]: [Client #93] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_554860.pth.
[INFO][12:09:36]: [Client #441] Woke up.
[INFO][12:09:36]: [Client #441] Epoch: [4/5][0/16]	Loss: 0.089841
[INFO][12:09:36]: [Client #441] Epoch: [4/5][10/16]	Loss: 0.401147
[INFO][12:09:36]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][12:09:37]: [Client #93] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_93_554860.pth.
[INFO][12:09:37]: [Client #93] Model trained.
[INFO][12:09:37]: [Client #93] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:37]: [Server #554754] Received 0.26 MB of payload data from client #93 (simulated).
[INFO][12:09:38]: [Client #441] Woke up.
[INFO][12:09:38]: [Client #441] Epoch: [5/5][0/16]	Loss: 1.120957
[INFO][12:09:38]: [Client #441] Epoch: [5/5][10/16]	Loss: 0.509327
[INFO][12:09:38]: [Client #441] Going to sleep for 1.62 seconds.
[INFO][12:09:40]: [Client #441] Woke up.
[INFO][12:09:40]: [Client #441] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_441_554853.pth.
[INFO][12:09:40]: [Client #441] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_441_554853.pth.
[INFO][12:09:40]: [Client #441] Model trained.
[INFO][12:09:41]: [Client #441] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:41]: [Server #554754] Received 0.26 MB of payload data from client #441 (simulated).
[INFO][12:09:41]: [Server #554754] Selecting client #426 for training.
[INFO][12:09:41]: [Server #554754] Sending the current model to client #426 (simulated).
[INFO][12:09:41]: [Server #554754] Sending 0.26 MB of payload data to client #426 (simulated).
[INFO][12:09:41]: [Server #554754] Selecting client #320 for training.
[INFO][12:09:41]: [Server #554754] Sending the current model to client #320 (simulated).
[INFO][12:09:41]: [Server #554754] Sending 0.26 MB of payload data to client #320 (simulated).
[INFO][12:09:41]: [Client #426] Selected by the server.
[INFO][12:09:41]: [Client #426] Loading its data source...
[INFO][12:09:41]: Data source: FEMNIST
[INFO][12:09:41]: [Client #320] Selected by the server.
[INFO][12:09:41]: [Client #320] Loading its data source...
[INFO][12:09:41]: Data source: FEMNIST
[INFO][12:09:41]: [Client #320] Dataset size: 153
[INFO][12:09:41]: [Client #320] Sampler: all_inclusive
[INFO][12:09:41]: [Client #320] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:41]: [Client #426] Dataset size: 160
[INFO][12:09:41]: [Client #426] Sampler: all_inclusive
[INFO][12:09:41]: [93m[1m[Client #320] Started training in communication round #40.[0m
[INFO][12:09:41]: [Client #426] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:09:41]: [93m[1m[Client #426] Started training in communication round #40.[0m
[INFO][12:09:42]: [Client #426] Loading the dataset.
[INFO][12:09:42]: [Client #320] Loading the dataset.
[INFO][12:09:48]: [Client #426] Epoch: [1/5][0/16]	Loss: 1.193035
[INFO][12:09:48]: [Client #426] Epoch: [1/5][10/16]	Loss: 0.211860
[INFO][12:09:48]: [Client #320] Epoch: [1/5][0/16]	Loss: 1.014568
[INFO][12:09:48]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:09:48]: [Client #320] Epoch: [1/5][10/16]	Loss: 0.392776
[INFO][12:09:48]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:09:48]: [Client #426] Woke up.
[INFO][12:09:48]: [Client #426] Epoch: [2/5][0/16]	Loss: 0.401565
[INFO][12:09:48]: [Client #426] Epoch: [2/5][10/16]	Loss: 0.348188
[INFO][12:09:48]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:09:48]: [Client #426] Woke up.
[INFO][12:09:48]: [Client #426] Epoch: [3/5][0/16]	Loss: 0.122605
[INFO][12:09:48]: [Client #426] Epoch: [3/5][10/16]	Loss: 0.229167
[INFO][12:09:49]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:09:49]: [Client #426] Woke up.
[INFO][12:09:49]: [Client #426] Epoch: [4/5][0/16]	Loss: 0.390722
[INFO][12:09:49]: [Client #426] Epoch: [4/5][10/16]	Loss: 0.772270
[INFO][12:09:49]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:09:49]: [Client #426] Woke up.
[INFO][12:09:49]: [Client #426] Epoch: [5/5][0/16]	Loss: 1.202926
[INFO][12:09:49]: [Client #426] Epoch: [5/5][10/16]	Loss: 0.214810
[INFO][12:09:49]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:09:49]: [Client #426] Woke up.
[INFO][12:09:49]: [Client #426] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_554853.pth.
[INFO][12:09:50]: [Client #426] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_554853.pth.
[INFO][12:09:50]: [Client #426] Model trained.
[INFO][12:09:50]: [Client #426] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:09:50]: [Server #554754] Received 0.26 MB of payload data from client #426 (simulated).
[INFO][12:09:54]: [Client #320] Woke up.
[INFO][12:09:54]: [Client #320] Epoch: [2/5][0/16]	Loss: 0.311645
[INFO][12:09:54]: [Client #320] Epoch: [2/5][10/16]	Loss: 1.122915
[INFO][12:09:54]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:10:00]: [Client #320] Woke up.
[INFO][12:10:00]: [Client #320] Epoch: [3/5][0/16]	Loss: 0.262108
[INFO][12:10:00]: [Client #320] Epoch: [3/5][10/16]	Loss: 0.123132
[INFO][12:10:00]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:10:06]: [Client #320] Woke up.
[INFO][12:10:06]: [Client #320] Epoch: [4/5][0/16]	Loss: 0.140755
[INFO][12:10:06]: [Client #320] Epoch: [4/5][10/16]	Loss: 0.311006
[INFO][12:10:06]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:10:11]: [Client #320] Woke up.
[INFO][12:10:11]: [Client #320] Epoch: [5/5][0/16]	Loss: 0.513907
[INFO][12:10:12]: [Client #320] Epoch: [5/5][10/16]	Loss: 0.239377
[INFO][12:10:12]: [Client #320] Going to sleep for 5.74 seconds.
[INFO][12:10:17]: [Client #320] Woke up.
[INFO][12:10:17]: [Client #320] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554860.pth.
[INFO][12:10:18]: [Client #320] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_320_554860.pth.
[INFO][12:10:18]: [Client #320] Model trained.
[INFO][12:10:18]: [Client #320] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:18]: [Server #554754] Received 0.26 MB of payload data from client #320 (simulated).
[INFO][12:10:18]: [Server #554754] Selecting client #397 for training.
[INFO][12:10:18]: [Server #554754] Sending the current model to client #397 (simulated).
[INFO][12:10:18]: [Server #554754] Sending 0.26 MB of payload data to client #397 (simulated).
[INFO][12:10:18]: [Server #554754] Selecting client #468 for training.
[INFO][12:10:18]: [Server #554754] Sending the current model to client #468 (simulated).
[INFO][12:10:18]: [Server #554754] Sending 0.26 MB of payload data to client #468 (simulated).
[INFO][12:10:18]: [Client #397] Selected by the server.
[INFO][12:10:18]: [Client #468] Selected by the server.
[INFO][12:10:18]: [Client #397] Loading its data source...
[INFO][12:10:18]: [Client #468] Loading its data source...
[INFO][12:10:18]: Data source: FEMNIST
[INFO][12:10:18]: Data source: FEMNIST
[INFO][12:10:18]: [Client #468] Dataset size: 150
[INFO][12:10:18]: [Client #468] Sampler: all_inclusive
[INFO][12:10:18]: [Client #397] Dataset size: 164
[INFO][12:10:18]: [Client #397] Sampler: all_inclusive
[INFO][12:10:18]: [Client #468] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:18]: [Client #397] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:18]: [93m[1m[Client #468] Started training in communication round #40.[0m
[INFO][12:10:18]: [93m[1m[Client #397] Started training in communication round #40.[0m
[INFO][12:10:20]: [Client #468] Loading the dataset.
[INFO][12:10:20]: [Client #397] Loading the dataset.
[INFO][12:10:25]: [Client #397] Epoch: [1/5][0/17]	Loss: 0.287785
[INFO][12:10:25]: [Client #468] Epoch: [1/5][0/15]	Loss: 0.775140
[INFO][12:10:25]: [Client #397] Epoch: [1/5][10/17]	Loss: 0.888804
[INFO][12:10:26]: [Client #468] Epoch: [1/5][10/15]	Loss: 0.887027
[INFO][12:10:26]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][12:10:26]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][12:10:26]: [Client #468] Woke up.
[INFO][12:10:26]: [Client #468] Epoch: [2/5][0/15]	Loss: 0.471795
[INFO][12:10:26]: [Client #468] Epoch: [2/5][10/15]	Loss: 0.299154
[INFO][12:10:26]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][12:10:26]: [Client #397] Woke up.
[INFO][12:10:26]: [Client #397] Epoch: [2/5][0/17]	Loss: 0.446300
[INFO][12:10:26]: [Client #397] Epoch: [2/5][10/17]	Loss: 0.688905
[INFO][12:10:26]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][12:10:26]: [Client #468] Woke up.
[INFO][12:10:26]: [Client #468] Epoch: [3/5][0/15]	Loss: 0.253033
[INFO][12:10:27]: [Client #468] Epoch: [3/5][10/15]	Loss: 0.159022
[INFO][12:10:27]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][12:10:27]: [Client #397] Woke up.
[INFO][12:10:27]: [Client #397] Epoch: [3/5][0/17]	Loss: 1.279215
[INFO][12:10:27]: [Client #468] Woke up.
[INFO][12:10:27]: [Client #468] Epoch: [4/5][0/15]	Loss: 0.033432
[INFO][12:10:27]: [Client #397] Epoch: [3/5][10/17]	Loss: 0.452920
[INFO][12:10:27]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][12:10:27]: [Client #468] Epoch: [4/5][10/15]	Loss: 1.193185
[INFO][12:10:27]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][12:10:27]: [Client #468] Woke up.
[INFO][12:10:27]: [Client #468] Epoch: [5/5][0/15]	Loss: 0.116054
[INFO][12:10:28]: [Client #468] Epoch: [5/5][10/15]	Loss: 0.582729
[INFO][12:10:28]: [Client #468] Going to sleep for 0.36 seconds.
[INFO][12:10:28]: [Client #397] Woke up.
[INFO][12:10:28]: [Client #397] Epoch: [4/5][0/17]	Loss: 0.091273
[INFO][12:10:28]: [Client #397] Epoch: [4/5][10/17]	Loss: 0.453112
[INFO][12:10:28]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][12:10:28]: [Client #468] Woke up.
[INFO][12:10:28]: [Client #468] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_468_554860.pth.
[INFO][12:10:28]: [Client #397] Woke up.
[INFO][12:10:28]: [Client #397] Epoch: [5/5][0/17]	Loss: 0.499085
[INFO][12:10:29]: [Client #397] Epoch: [5/5][10/17]	Loss: 1.101984
[INFO][12:10:29]: [Client #397] Going to sleep for 0.62 seconds.
[INFO][12:10:29]: [Client #468] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_468_554860.pth.
[INFO][12:10:29]: [Client #468] Model trained.
[INFO][12:10:29]: [Client #468] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:29]: [Server #554754] Received 0.26 MB of payload data from client #468 (simulated).
[INFO][12:10:29]: [Client #397] Woke up.
[INFO][12:10:29]: [Client #397] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_554853.pth.
[INFO][12:10:30]: [Client #397] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_397_554853.pth.
[INFO][12:10:30]: [Client #397] Model trained.
[INFO][12:10:30]: [Client #397] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:30]: [Server #554754] Received 0.26 MB of payload data from client #397 (simulated).
[INFO][12:10:30]: [Server #554754] Selecting client #500 for training.
[INFO][12:10:30]: [Server #554754] Sending the current model to client #500 (simulated).
[INFO][12:10:30]: [Server #554754] Sending 0.26 MB of payload data to client #500 (simulated).
[INFO][12:10:30]: [Server #554754] Selecting client #78 for training.
[INFO][12:10:30]: [Server #554754] Sending the current model to client #78 (simulated).
[INFO][12:10:30]: [Server #554754] Sending 0.26 MB of payload data to client #78 (simulated).
[INFO][12:10:30]: [Client #500] Selected by the server.
[INFO][12:10:30]: [Client #500] Loading its data source...
[INFO][12:10:30]: Data source: FEMNIST
[INFO][12:10:30]: [Client #78] Selected by the server.
[INFO][12:10:30]: [Client #78] Loading its data source...
[INFO][12:10:30]: Data source: FEMNIST
[INFO][12:10:30]: [Client #500] Dataset size: 296
[INFO][12:10:30]: [Client #500] Sampler: all_inclusive
[INFO][12:10:30]: [Client #500] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:30]: [93m[1m[Client #500] Started training in communication round #40.[0m
[INFO][12:10:30]: [Client #78] Dataset size: 207
[INFO][12:10:30]: [Client #78] Sampler: all_inclusive
[INFO][12:10:30]: [Client #78] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:30]: [93m[1m[Client #78] Started training in communication round #40.[0m
[INFO][12:10:32]: [Client #78] Loading the dataset.
[INFO][12:10:32]: [Client #500] Loading the dataset.
[INFO][12:10:37]: [Client #78] Epoch: [1/5][0/21]	Loss: 0.487653
[INFO][12:10:37]: [Client #78] Epoch: [1/5][10/21]	Loss: 0.503318
[INFO][12:10:37]: [Client #500] Epoch: [1/5][0/30]	Loss: 0.787042
[INFO][12:10:37]: [Client #78] Epoch: [1/5][20/21]	Loss: 0.816307
[INFO][12:10:37]: [Client #78] Going to sleep for 0.53 seconds.
[INFO][12:10:37]: [Client #500] Epoch: [1/5][10/30]	Loss: 1.546436
[INFO][12:10:37]: [Client #500] Epoch: [1/5][20/30]	Loss: 0.922023
[INFO][12:10:38]: [Client #500] Going to sleep for 0.30 seconds.
[INFO][12:10:38]: [Client #500] Woke up.
[INFO][12:10:38]: [Client #500] Epoch: [2/5][0/30]	Loss: 1.000534
[INFO][12:10:38]: [Client #78] Woke up.
[INFO][12:10:38]: [Client #78] Epoch: [2/5][0/21]	Loss: 1.038221
[INFO][12:10:38]: [Client #500] Epoch: [2/5][10/30]	Loss: 0.949780
[INFO][12:10:38]: [Client #78] Epoch: [2/5][10/21]	Loss: 0.276197
[INFO][12:10:38]: [Client #500] Epoch: [2/5][20/30]	Loss: 0.675827
[INFO][12:10:38]: [Client #78] Epoch: [2/5][20/21]	Loss: 0.128803
[INFO][12:10:38]: [Client #78] Going to sleep for 0.53 seconds.
[INFO][12:10:38]: [Client #500] Going to sleep for 0.30 seconds.
[INFO][12:10:38]: [Client #500] Woke up.
[INFO][12:10:38]: [Client #500] Epoch: [3/5][0/30]	Loss: 0.577181
[INFO][12:10:39]: [Client #500] Epoch: [3/5][10/30]	Loss: 0.816522
[INFO][12:10:39]: [Client #500] Epoch: [3/5][20/30]	Loss: 0.429711
[INFO][12:10:39]: [Client #78] Woke up.
[INFO][12:10:39]: [Client #78] Epoch: [3/5][0/21]	Loss: 0.011311
[INFO][12:10:39]: [Client #500] Going to sleep for 0.30 seconds.
[INFO][12:10:39]: [Client #78] Epoch: [3/5][10/21]	Loss: 0.261454
[INFO][12:10:39]: [Client #78] Epoch: [3/5][20/21]	Loss: 1.043556
[INFO][12:10:39]: [Client #78] Going to sleep for 0.53 seconds.
[INFO][12:10:39]: [Client #500] Woke up.
[INFO][12:10:39]: [Client #500] Epoch: [4/5][0/30]	Loss: 1.099397
[INFO][12:10:39]: [Client #500] Epoch: [4/5][10/30]	Loss: 1.688882
[INFO][12:10:39]: [Client #500] Epoch: [4/5][20/30]	Loss: 1.728622
[INFO][12:10:39]: [Client #500] Going to sleep for 0.30 seconds.
[INFO][12:10:39]: [Client #78] Woke up.
[INFO][12:10:39]: [Client #78] Epoch: [4/5][0/21]	Loss: 0.273780
[INFO][12:10:39]: [Client #78] Epoch: [4/5][10/21]	Loss: 2.005331
[INFO][12:10:40]: [Client #78] Epoch: [4/5][20/21]	Loss: 0.973027
[INFO][12:10:40]: [Client #78] Going to sleep for 0.53 seconds.
[INFO][12:10:40]: [Client #500] Woke up.
[INFO][12:10:40]: [Client #500] Epoch: [5/5][0/30]	Loss: 0.705473
[INFO][12:10:40]: [Client #500] Epoch: [5/5][10/30]	Loss: 1.078933
[INFO][12:10:40]: [Client #500] Epoch: [5/5][20/30]	Loss: 0.653382
[INFO][12:10:40]: [Client #500] Going to sleep for 0.30 seconds.
[INFO][12:10:40]: [Client #78] Woke up.
[INFO][12:10:40]: [Client #78] Epoch: [5/5][0/21]	Loss: 0.316868
[INFO][12:10:40]: [Client #500] Woke up.
[INFO][12:10:40]: [Client #500] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_500_554853.pth.
[INFO][12:10:40]: [Client #78] Epoch: [5/5][10/21]	Loss: 0.868242
[INFO][12:10:40]: [Client #78] Epoch: [5/5][20/21]	Loss: 1.543412
[INFO][12:10:40]: [Client #78] Going to sleep for 0.53 seconds.
[INFO][12:10:41]: [Client #500] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_500_554853.pth.
[INFO][12:10:41]: [Client #500] Model trained.
[INFO][12:10:41]: [Client #78] Woke up.
[INFO][12:10:41]: [Client #78] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_78_554860.pth.
[INFO][12:10:41]: [Client #500] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:41]: [Server #554754] Received 0.26 MB of payload data from client #500 (simulated).
[INFO][12:10:41]: [Client #78] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_78_554860.pth.
[INFO][12:10:41]: [Client #78] Model trained.
[INFO][12:10:41]: [Client #78] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:41]: [Server #554754] Received 0.26 MB of payload data from client #78 (simulated).
[INFO][12:10:41]: [Server #554754] Selecting client #39 for training.
[INFO][12:10:41]: [Server #554754] Sending the current model to client #39 (simulated).
[INFO][12:10:41]: [Server #554754] Sending 0.26 MB of payload data to client #39 (simulated).
[INFO][12:10:41]: [Server #554754] Selecting client #41 for training.
[INFO][12:10:41]: [Server #554754] Sending the current model to client #41 (simulated).
[INFO][12:10:41]: [Server #554754] Sending 0.26 MB of payload data to client #41 (simulated).
[INFO][12:10:41]: [Client #41] Selected by the server.
[INFO][12:10:41]: [Client #39] Selected by the server.
[INFO][12:10:41]: [Client #41] Loading its data source...
[INFO][12:10:41]: [Client #39] Loading its data source...
[INFO][12:10:41]: Data source: FEMNIST
[INFO][12:10:41]: Data source: FEMNIST
[INFO][12:10:42]: [Client #41] Dataset size: 158
[INFO][12:10:42]: [Client #41] Sampler: all_inclusive
[INFO][12:10:42]: [Client #39] Dataset size: 165
[INFO][12:10:42]: [Client #39] Sampler: all_inclusive
[INFO][12:10:42]: [Client #41] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:42]: [Client #39] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:10:42]: [93m[1m[Client #41] Started training in communication round #40.[0m
[INFO][12:10:42]: [93m[1m[Client #39] Started training in communication round #40.[0m
[INFO][12:10:43]: [Client #39] Loading the dataset.
[INFO][12:10:43]: [Client #41] Loading the dataset.
[INFO][12:10:49]: [Client #41] Epoch: [1/5][0/16]	Loss: 2.767976
[INFO][12:10:49]: [Client #39] Epoch: [1/5][0/17]	Loss: 0.770512
[INFO][12:10:49]: [Client #39] Epoch: [1/5][10/17]	Loss: 0.691678
[INFO][12:10:49]: [Client #41] Epoch: [1/5][10/16]	Loss: 0.797115
[INFO][12:10:49]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][12:10:49]: [Client #41] Going to sleep for 60.00 seconds.
[INFO][12:10:49]: [Client #39] Woke up.
[INFO][12:10:49]: [Client #39] Epoch: [2/5][0/17]	Loss: 0.474203
[INFO][12:10:49]: [Client #39] Epoch: [2/5][10/17]	Loss: 0.126031
[INFO][12:10:49]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][12:10:49]: [Client #39] Woke up.
[INFO][12:10:49]: [Client #39] Epoch: [3/5][0/17]	Loss: 0.205527
[INFO][12:10:49]: [Client #39] Epoch: [3/5][10/17]	Loss: 0.370515
[INFO][12:10:49]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][12:10:49]: [Client #39] Woke up.
[INFO][12:10:49]: [Client #39] Epoch: [4/5][0/17]	Loss: 0.026147
[INFO][12:10:49]: [Client #39] Epoch: [4/5][10/17]	Loss: 0.224654
[INFO][12:10:49]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][12:10:50]: [Client #39] Woke up.
[INFO][12:10:50]: [Client #39] Epoch: [5/5][0/17]	Loss: 0.195190
[INFO][12:10:50]: [Client #39] Epoch: [5/5][10/17]	Loss: 0.210030
[INFO][12:10:50]: [Client #39] Going to sleep for 0.02 seconds.
[INFO][12:10:50]: [Client #39] Woke up.
[INFO][12:10:50]: [Client #39] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_39_554853.pth.
[INFO][12:10:50]: [Client #39] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_39_554853.pth.
[INFO][12:10:50]: [Client #39] Model trained.
[INFO][12:10:50]: [Client #39] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:10:50]: [Server #554754] Received 0.26 MB of payload data from client #39 (simulated).
[INFO][12:11:49]: [Client #41] Woke up.
[INFO][12:11:49]: [Client #41] Epoch: [2/5][0/16]	Loss: 0.867449
[INFO][12:11:49]: [Client #41] Epoch: [2/5][10/16]	Loss: 1.975392
[INFO][12:11:49]: [Client #41] Going to sleep for 60.00 seconds.
[INFO][12:12:49]: [Client #41] Woke up.
[INFO][12:12:50]: [Client #41] Epoch: [3/5][0/16]	Loss: 1.452390
[INFO][12:12:50]: [Client #41] Epoch: [3/5][10/16]	Loss: 0.907449
[INFO][12:12:50]: [Client #41] Going to sleep for 60.00 seconds.
[INFO][12:13:50]: [Client #41] Woke up.
[INFO][12:13:50]: [Client #41] Epoch: [4/5][0/16]	Loss: 0.986478
[INFO][12:13:50]: [Client #41] Epoch: [4/5][10/16]	Loss: 2.367059
[INFO][12:13:50]: [Client #41] Going to sleep for 60.00 seconds.
[INFO][12:14:50]: [Client #41] Woke up.
[INFO][12:14:50]: [Client #41] Epoch: [5/5][0/16]	Loss: 0.536224
[INFO][12:14:50]: [Client #41] Epoch: [5/5][10/16]	Loss: 0.919120
[INFO][12:14:50]: [Client #41] Going to sleep for 60.00 seconds.
[INFO][12:15:50]: [Client #41] Woke up.
[INFO][12:15:50]: [Client #41] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_41_554860.pth.
[INFO][12:15:51]: [Client #41] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_41_554860.pth.
[INFO][12:15:51]: [Client #41] Model trained.
[INFO][12:15:51]: [Client #41] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:15:51]: [Server #554754] Received 0.26 MB of payload data from client #41 (simulated).
[INFO][12:15:51]: [Server #554754] Selecting client #9 for training.
[INFO][12:15:51]: [Server #554754] Sending the current model to client #9 (simulated).
[INFO][12:15:51]: [Server #554754] Sending 0.26 MB of payload data to client #9 (simulated).
[INFO][12:15:51]: [Server #554754] Selecting client #485 for training.
[INFO][12:15:51]: [Server #554754] Sending the current model to client #485 (simulated).
[INFO][12:15:51]: [Server #554754] Sending 0.26 MB of payload data to client #485 (simulated).
[INFO][12:15:51]: [Client #485] Selected by the server.
[INFO][12:15:51]: [Client #9] Selected by the server.
[INFO][12:15:51]: [Client #485] Loading its data source...
[INFO][12:15:51]: [Client #9] Loading its data source...
[INFO][12:15:51]: Data source: FEMNIST
[INFO][12:15:51]: Data source: FEMNIST
[INFO][12:15:51]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:15:51]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/485.zip.
[INFO][12:15:51]: [Client #9] Dataset size: 145
[INFO][12:15:51]: [Client #9] Sampler: all_inclusive
[INFO][12:15:51]: [Client #9] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:15:51]: [93m[1m[Client #9] Started training in communication round #40.[0m

2.7%
5.3%
8.0%
10.7%
13.4%
16.0%
18.7%
21.4%
24.0%
26.7%
29.4%
32.1%
34.7%
37.4%
40.1%
42.8%
45.4%
48.1%
50.8%
53.4%
56.1%
58.8%
61.5%
64.1%
66.8%
69.5%
72.1%
74.8%
77.5%
80.2%
82.8%
85.5%
88.2%
90.9%
93.5%
96.2%
98.9%
100.0%[INFO][12:15:51]: Decompressing the dataset downloaded.
[INFO][12:15:51]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/485.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:15:51]: [Client #485] Dataset size: 157
[INFO][12:15:51]: [Client #485] Sampler: all_inclusive
[INFO][12:15:51]: [Client #485] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:15:51]: [93m[1m[Client #485] Started training in communication round #40.[0m

[INFO][12:15:53]: [Client #9] Loading the dataset.
[INFO][12:15:53]: [Client #485] Loading the dataset.
[INFO][12:15:58]: [Client #9] Epoch: [1/5][0/15]	Loss: 0.883956
[INFO][12:15:58]: [Client #9] Epoch: [1/5][10/15]	Loss: 0.470311
[INFO][12:15:58]: [Client #485] Epoch: [1/5][0/16]	Loss: 0.860241
[INFO][12:15:58]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][12:15:59]: [Client #485] Epoch: [1/5][10/16]	Loss: 0.062927
[INFO][12:15:59]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][12:15:59]: [Client #9] Woke up.
[INFO][12:15:59]: [Client #9] Epoch: [2/5][0/15]	Loss: 0.610718
[INFO][12:15:59]: [Client #9] Epoch: [2/5][10/15]	Loss: 0.332548
[INFO][12:15:59]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][12:15:59]: [Client #485] Woke up.
[INFO][12:15:59]: [Client #485] Epoch: [2/5][0/16]	Loss: 0.363465
[INFO][12:16:00]: [Client #485] Epoch: [2/5][10/16]	Loss: 0.448205
[INFO][12:16:00]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][12:16:00]: [Client #9] Woke up.
[INFO][12:16:00]: [Client #9] Epoch: [3/5][0/15]	Loss: 0.140266
[INFO][12:16:00]: [Client #9] Epoch: [3/5][10/15]	Loss: 0.140604
[INFO][12:16:00]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][12:16:00]: [Client #485] Woke up.
[INFO][12:16:00]: [Client #485] Epoch: [3/5][0/16]	Loss: 0.131159
[INFO][12:16:01]: [Client #485] Epoch: [3/5][10/16]	Loss: 0.380294
[INFO][12:16:01]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][12:16:01]: [Client #9] Woke up.
[INFO][12:16:01]: [Client #9] Epoch: [4/5][0/15]	Loss: 1.155522
[INFO][12:16:01]: [Client #9] Epoch: [4/5][10/15]	Loss: 1.349572
[INFO][12:16:01]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][12:16:01]: [Client #485] Woke up.
[INFO][12:16:01]: [Client #485] Epoch: [4/5][0/16]	Loss: 0.185076
[INFO][12:16:01]: [Client #9] Woke up.
[INFO][12:16:02]: [Client #485] Epoch: [4/5][10/16]	Loss: 0.070423
[INFO][12:16:02]: [Client #9] Epoch: [5/5][0/15]	Loss: 0.080992
[INFO][12:16:02]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][12:16:02]: [Client #9] Epoch: [5/5][10/15]	Loss: 0.166610
[INFO][12:16:02]: [Client #9] Going to sleep for 0.66 seconds.
[INFO][12:16:02]: [Client #9] Woke up.
[INFO][12:16:02]: [Client #9] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_9_554853.pth.
[INFO][12:16:02]: [Client #485] Woke up.
[INFO][12:16:02]: [Client #485] Epoch: [5/5][0/16]	Loss: 0.620168
[INFO][12:16:02]: [Client #485] Epoch: [5/5][10/16]	Loss: 0.375730
[INFO][12:16:03]: [Client #485] Going to sleep for 0.83 seconds.
[INFO][12:16:03]: [Client #9] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_9_554853.pth.
[INFO][12:16:03]: [Client #9] Model trained.
[INFO][12:16:03]: [Client #9] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:03]: [Server #554754] Received 0.26 MB of payload data from client #9 (simulated).
[INFO][12:16:03]: [Client #485] Woke up.
[INFO][12:16:03]: [Client #485] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_485_554860.pth.
[INFO][12:16:04]: [Client #485] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_485_554860.pth.
[INFO][12:16:04]: [Client #485] Model trained.
[INFO][12:16:04]: [Client #485] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:04]: [Server #554754] Received 0.26 MB of payload data from client #485 (simulated).
[INFO][12:16:04]: [Server #554754] Selecting client #53 for training.
[INFO][12:16:04]: [Server #554754] Sending the current model to client #53 (simulated).
[INFO][12:16:04]: [Server #554754] Sending 0.26 MB of payload data to client #53 (simulated).
[INFO][12:16:04]: [Server #554754] Selecting client #439 for training.
[INFO][12:16:04]: [Server #554754] Sending the current model to client #439 (simulated).
[INFO][12:16:04]: [Server #554754] Sending 0.26 MB of payload data to client #439 (simulated).
[INFO][12:16:04]: [Client #53] Selected by the server.
[INFO][12:16:04]: [Client #439] Selected by the server.
[INFO][12:16:04]: [Client #53] Loading its data source...
[INFO][12:16:04]: [Client #439] Loading its data source...
[INFO][12:16:04]: Data source: FEMNIST
[INFO][12:16:04]: Data source: FEMNIST
[INFO][12:16:04]: [Client #53] Dataset size: 155
[INFO][12:16:04]: [Client #53] Sampler: all_inclusive
[INFO][12:16:04]: [Client #439] Dataset size: 144
[INFO][12:16:04]: [Client #439] Sampler: all_inclusive
[INFO][12:16:04]: [Client #53] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:16:04]: [Client #439] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:16:04]: [93m[1m[Client #53] Started training in communication round #40.[0m
[INFO][12:16:04]: [93m[1m[Client #439] Started training in communication round #40.[0m
[INFO][12:16:06]: [Client #439] Loading the dataset.
[INFO][12:16:06]: [Client #53] Loading the dataset.
[INFO][12:16:11]: [Client #53] Epoch: [1/5][0/16]	Loss: 0.645104
[INFO][12:16:11]: [Client #439] Epoch: [1/5][0/15]	Loss: 1.522139
[INFO][12:16:12]: [Client #53] Epoch: [1/5][10/16]	Loss: 1.203906
[INFO][12:16:12]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:16:12]: [Client #439] Epoch: [1/5][10/15]	Loss: 1.332039
[INFO][12:16:12]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][12:16:12]: [Client #53] Woke up.
[INFO][12:16:12]: [Client #53] Epoch: [2/5][0/16]	Loss: 0.978411
[INFO][12:16:12]: [Client #53] Epoch: [2/5][10/16]	Loss: 1.118132
[INFO][12:16:12]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:16:12]: [Client #53] Woke up.
[INFO][12:16:12]: [Client #53] Epoch: [3/5][0/16]	Loss: 1.444321
[INFO][12:16:12]: [Client #53] Epoch: [3/5][10/16]	Loss: 0.753226
[INFO][12:16:12]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:16:13]: [Client #53] Woke up.
[INFO][12:16:13]: [Client #53] Epoch: [4/5][0/16]	Loss: 0.247842
[INFO][12:16:13]: [Client #53] Epoch: [4/5][10/16]	Loss: 0.102393
[INFO][12:16:13]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:16:13]: [Client #53] Woke up.
[INFO][12:16:13]: [Client #53] Epoch: [5/5][0/16]	Loss: 0.438865
[INFO][12:16:13]: [Client #53] Epoch: [5/5][10/16]	Loss: 0.076922
[INFO][12:16:13]: [Client #53] Going to sleep for 0.27 seconds.
[INFO][12:16:13]: [Client #53] Woke up.
[INFO][12:16:13]: [Client #53] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_554853.pth.
[INFO][12:16:14]: [Client #53] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_53_554853.pth.
[INFO][12:16:14]: [Client #53] Model trained.
[INFO][12:16:14]: [Client #53] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:14]: [Server #554754] Received 0.26 MB of payload data from client #53 (simulated).
[INFO][12:16:15]: [Client #439] Woke up.
[INFO][12:16:15]: [Client #439] Epoch: [2/5][0/15]	Loss: 0.316777
[INFO][12:16:15]: [Client #439] Epoch: [2/5][10/15]	Loss: 0.813589
[INFO][12:16:15]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][12:16:19]: [Client #439] Woke up.
[INFO][12:16:19]: [Client #439] Epoch: [3/5][0/15]	Loss: 0.729806
[INFO][12:16:19]: [Client #439] Epoch: [3/5][10/15]	Loss: 0.821851
[INFO][12:16:19]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][12:16:22]: [Client #439] Woke up.
[INFO][12:16:22]: [Client #439] Epoch: [4/5][0/15]	Loss: 0.815155
[INFO][12:16:22]: [Client #439] Epoch: [4/5][10/15]	Loss: 0.266048
[INFO][12:16:22]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][12:16:26]: [Client #439] Woke up.
[INFO][12:16:26]: [Client #439] Epoch: [5/5][0/15]	Loss: 0.396215
[INFO][12:16:26]: [Client #439] Epoch: [5/5][10/15]	Loss: 1.426917
[INFO][12:16:26]: [Client #439] Going to sleep for 3.42 seconds.
[INFO][12:16:29]: [Client #439] Woke up.
[INFO][12:16:29]: [Client #439] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_439_554860.pth.
[INFO][12:16:30]: [Client #439] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_439_554860.pth.
[INFO][12:16:30]: [Client #439] Model trained.
[INFO][12:16:30]: [Client #439] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:30]: [Server #554754] Received 0.26 MB of payload data from client #439 (simulated).
[INFO][12:16:30]: [Server #554754] Selecting client #352 for training.
[INFO][12:16:30]: [Server #554754] Sending the current model to client #352 (simulated).
[INFO][12:16:30]: [Server #554754] Sending 0.26 MB of payload data to client #352 (simulated).
[INFO][12:16:30]: [Server #554754] Selecting client #259 for training.
[INFO][12:16:30]: [Server #554754] Sending the current model to client #259 (simulated).
[INFO][12:16:30]: [Server #554754] Sending 0.26 MB of payload data to client #259 (simulated).
[INFO][12:16:30]: [Client #259] Selected by the server.
[INFO][12:16:30]: [Client #352] Selected by the server.
[INFO][12:16:30]: [Client #259] Loading its data source...
[INFO][12:16:30]: [Client #352] Loading its data source...
[INFO][12:16:30]: Data source: FEMNIST
[INFO][12:16:30]: Data source: FEMNIST
[INFO][12:16:30]: [Client #259] Dataset size: 125
[INFO][12:16:30]: [Client #259] Sampler: all_inclusive
[INFO][12:16:30]: [Client #352] Dataset size: 163
[INFO][12:16:30]: [Client #352] Sampler: all_inclusive
[INFO][12:16:30]: [Client #259] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:16:30]: [Client #352] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:16:30]: [93m[1m[Client #259] Started training in communication round #40.[0m
[INFO][12:16:30]: [93m[1m[Client #352] Started training in communication round #40.[0m
[INFO][12:16:32]: [Client #259] Loading the dataset.
[INFO][12:16:32]: [Client #352] Loading the dataset.
[INFO][12:16:37]: [Client #352] Epoch: [1/5][0/17]	Loss: 0.370993
[INFO][12:16:37]: [Client #259] Epoch: [1/5][0/13]	Loss: 1.739789
[INFO][12:16:37]: [Client #352] Epoch: [1/5][10/17]	Loss: 1.776580
[INFO][12:16:38]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][12:16:38]: [Client #259] Epoch: [1/5][10/13]	Loss: 1.127864
[INFO][12:16:38]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:16:38]: [Client #259] Woke up.
[INFO][12:16:38]: [Client #259] Epoch: [2/5][0/13]	Loss: 0.812998
[INFO][12:16:38]: [Client #259] Epoch: [2/5][10/13]	Loss: 1.362417
[INFO][12:16:38]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:16:38]: [Client #259] Woke up.
[INFO][12:16:39]: [Client #259] Epoch: [3/5][0/13]	Loss: 0.248691
[INFO][12:16:39]: [Client #259] Epoch: [3/5][10/13]	Loss: 1.631105
[INFO][12:16:39]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:16:39]: [Client #259] Woke up.
[INFO][12:16:39]: [Client #259] Epoch: [4/5][0/13]	Loss: 0.557126
[INFO][12:16:39]: [Client #259] Epoch: [4/5][10/13]	Loss: 0.551344
[INFO][12:16:39]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:16:40]: [Client #259] Woke up.
[INFO][12:16:40]: [Client #259] Epoch: [5/5][0/13]	Loss: 0.403529
[INFO][12:16:40]: [Client #259] Epoch: [5/5][10/13]	Loss: 0.066289
[INFO][12:16:40]: [Client #259] Going to sleep for 0.40 seconds.
[INFO][12:16:40]: [Client #259] Woke up.
[INFO][12:16:40]: [Client #259] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554860.pth.
[INFO][12:16:40]: [Client #352] Woke up.
[INFO][12:16:40]: [Client #352] Epoch: [2/5][0/17]	Loss: 0.205984
[INFO][12:16:40]: [Client #352] Epoch: [2/5][10/17]	Loss: 0.891862
[INFO][12:16:40]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][12:16:41]: [Client #259] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_259_554860.pth.
[INFO][12:16:41]: [Client #259] Model trained.
[INFO][12:16:41]: [Client #259] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:41]: [Server #554754] Received 0.26 MB of payload data from client #259 (simulated).
[INFO][12:16:43]: [Client #352] Woke up.
[INFO][12:16:43]: [Client #352] Epoch: [3/5][0/17]	Loss: 0.325518
[INFO][12:16:43]: [Client #352] Epoch: [3/5][10/17]	Loss: 1.062097
[INFO][12:16:43]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][12:16:46]: [Client #352] Woke up.
[INFO][12:16:46]: [Client #352] Epoch: [4/5][0/17]	Loss: 0.456218
[INFO][12:16:46]: [Client #352] Epoch: [4/5][10/17]	Loss: 0.170263
[INFO][12:16:46]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][12:16:49]: [Client #352] Woke up.
[INFO][12:16:49]: [Client #352] Epoch: [5/5][0/17]	Loss: 0.779526
[INFO][12:16:49]: [Client #352] Epoch: [5/5][10/17]	Loss: 0.247182
[INFO][12:16:49]: [Client #352] Going to sleep for 2.73 seconds.
[INFO][12:16:52]: [Client #352] Woke up.
[INFO][12:16:52]: [Client #352] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_554853.pth.
[INFO][12:16:52]: [Client #352] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_352_554853.pth.
[INFO][12:16:52]: [Client #352] Model trained.
[INFO][12:16:52]: [Client #352] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:16:52]: [Server #554754] Received 0.26 MB of payload data from client #352 (simulated).
[INFO][12:16:52]: [Server #554754] Adding client #39 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #426 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #53 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #7 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #468 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #259 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #500 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #78 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #397 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Adding client #9 to the list of clients for aggregation.
[INFO][12:16:52]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.1006696  0.         0.07750214 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09468753 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16647776 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12061816
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09593937 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11353947 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15320423
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13768991
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22246313]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.1006696  0.         0.07750214 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.09468753 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16647776 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.12061816
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.09593937 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11353947 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15320423
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13768991
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.22246313]
!!!!!!The aggregation weights of this round are:  [INFO][12:17:36]: [Server #554754] Global model accuracy: 66.32%

[INFO][12:17:36]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_40.pth.
[INFO][12:17:36]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_40.pth.
[INFO][12:17:36]: [93m[1m
[Server #554754] Starting round 41/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.09212051 0.0912031  0.08400927 0.002      0.04609822 0.03769968
 0.07960199 0.002      0.002      0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.046167
 0.002      0.04880988 0.09559676 0.04016585 0.002      0.002
 0.002      0.04730693 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08980301 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.08837971
 0.002      0.09273039 0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.11993048
 0.002      0.002      0.09858247 0.002      0.04559704 0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.0920354  0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.04331718 0.10038363 0.04421543 0.002      0.002
 0.04645198 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.04331718 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04094325 0.002      0.04531205 0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.002      0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.09387521
 0.04579693 0.002      0.07291112 0.002      0.08907104 0.002
 0.08830694 0.0945083  0.002      0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.09101317 0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.04502707 0.10344828 0.002      0.002      0.10714286
 0.04502707 0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.18775043
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.002      0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.08577942 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.07242178 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.08207467 0.10502283 0.0933028  0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.09158558 0.0473034  0.07882535
 0.04331718 0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.04360217 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.04645198 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.04417213 0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.07899256 0.05007728 0.09421965 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.05385638 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.09215799
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.08986835 0.09514925 0.002
 0.09501738 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.09269988
 0.002      0.10419397 0.05415045 0.04659289 0.046167   0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.002      0.002      0.002      0.002      0.10392902 0.15096419
 0.08321459 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.002
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.08872353 0.002      0.02935309 0.1026616  0.002      0.08690614
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.04645198
 0.002      0.002      0.07291112 0.002      0.002      0.08943544
 0.08469945 0.04667697 0.002      0.04189228 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.17149479]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][12:17:36]: [Server #554754] Selected clients: [173 177 128 456 363  13 230 141  15 443]
[INFO][12:17:36]: [Server #554754] Selecting client #173 for training.
[INFO][12:17:36]: [Server #554754] Sending the current model to client #173 (simulated).
[INFO][12:17:36]: [Server #554754] Sending 0.26 MB of payload data to client #173 (simulated).
[INFO][12:17:36]: [Server #554754] Selecting client #177 for training.
[INFO][12:17:36]: [Server #554754] Sending the current model to client #177 (simulated).
[INFO][12:17:36]: [Server #554754] Sending 0.26 MB of payload data to client #177 (simulated).
[INFO][12:17:36]: [Client #173] Selected by the server.
[INFO][12:17:36]: [Client #173] Loading its data source...
[INFO][12:17:36]: Data source: FEMNIST
[INFO][12:17:36]: [Client #177] Selected by the server.
[INFO][12:17:36]: [Client #177] Loading its data source...
[INFO][12:17:36]: Data source: FEMNIST
[INFO][12:17:36]: [Client #173] Dataset size: 163
[INFO][12:17:36]: [Client #173] Sampler: all_inclusive
[INFO][12:17:36]: [Client #173] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:17:36]: [Client #177] Dataset size: 151
[INFO][12:17:36]: [Client #177] Sampler: all_inclusive
[INFO][12:17:36]: [Client #177] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:17:36]: [93m[1m[Client #177] Started training in communication round #41.[0m
[INFO][12:17:36]: [93m[1m[Client #173] Started training in communication round #41.[0m
[INFO][12:17:38]: [Client #177] Loading the dataset.
[INFO][12:17:38]: [Client #173] Loading the dataset.
[INFO][12:17:43]: [Client #177] Epoch: [1/5][0/16]	Loss: 1.564247
[INFO][12:17:44]: [Client #173] Epoch: [1/5][0/17]	Loss: 0.401555
[INFO][12:17:44]: [Client #177] Epoch: [1/5][10/16]	Loss: 0.636765
[INFO][12:17:44]: [Client #177] Going to sleep for 2.02 seconds.
[INFO][12:17:44]: [Client #173] Epoch: [1/5][10/17]	Loss: 0.433760
[INFO][12:17:44]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][12:17:45]: [Client #173] Woke up.
[INFO][12:17:45]: [Client #173] Epoch: [2/5][0/17]	Loss: 0.146572
[INFO][12:17:45]: [Client #173] Epoch: [2/5][10/17]	Loss: 0.104465
[INFO][12:17:45]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][12:17:46]: [Client #177] Woke up.
[INFO][12:17:46]: [Client #177] Epoch: [2/5][0/16]	Loss: 0.628542
[INFO][12:17:46]: [Client #177] Epoch: [2/5][10/16]	Loss: 1.150083
[INFO][12:17:46]: [Client #177] Going to sleep for 2.02 seconds.
[INFO][12:17:47]: [Client #173] Woke up.
[INFO][12:17:47]: [Client #173] Epoch: [3/5][0/17]	Loss: 0.120700
[INFO][12:17:47]: [Client #173] Epoch: [3/5][10/17]	Loss: 0.511392
[INFO][12:17:47]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][12:17:48]: [Client #177] Woke up.
[INFO][12:17:48]: [Client #177] Epoch: [3/5][0/16]	Loss: 0.928095
[INFO][12:17:48]: [Client #177] Epoch: [3/5][10/16]	Loss: 0.881166
[INFO][12:17:48]: [Client #177] Going to sleep for 2.02 seconds.
[INFO][12:17:48]: [Client #173] Woke up.
[INFO][12:17:48]: [Client #173] Epoch: [4/5][0/17]	Loss: 0.066634
[INFO][12:17:48]: [Client #173] Epoch: [4/5][10/17]	Loss: 0.557720
[INFO][12:17:48]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][12:17:50]: [Client #173] Woke up.
[INFO][12:17:50]: [Client #173] Epoch: [5/5][0/17]	Loss: 0.211933
[INFO][12:17:50]: [Client #173] Epoch: [5/5][10/17]	Loss: 0.583806
[INFO][12:17:50]: [Client #173] Going to sleep for 1.38 seconds.
[INFO][12:17:50]: [Client #177] Woke up.
[INFO][12:17:50]: [Client #177] Epoch: [4/5][0/16]	Loss: 0.449608
[INFO][12:17:50]: [Client #177] Epoch: [4/5][10/16]	Loss: 0.741461
[INFO][12:17:50]: [Client #177] Going to sleep for 2.02 seconds.
[INFO][12:17:51]: [Client #173] Woke up.
[INFO][12:17:51]: [Client #173] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554853.pth.
[INFO][12:17:52]: [Client #173] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_173_554853.pth.
[INFO][12:17:52]: [Client #173] Model trained.
[INFO][12:17:52]: [Client #173] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:17:52]: [Server #554754] Received 0.26 MB of payload data from client #173 (simulated).
[INFO][12:17:52]: [Client #177] Woke up.
[INFO][12:17:52]: [Client #177] Epoch: [5/5][0/16]	Loss: 0.584918
[INFO][12:17:52]: [Client #177] Epoch: [5/5][10/16]	Loss: 1.312381
[INFO][12:17:52]: [Client #177] Going to sleep for 2.02 seconds.
[INFO][12:17:54]: [Client #177] Woke up.
[INFO][12:17:54]: [Client #177] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_177_554860.pth.
[INFO][12:17:55]: [Client #177] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_177_554860.pth.
[INFO][12:17:55]: [Client #177] Model trained.
[INFO][12:17:55]: [Client #177] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:17:55]: [Server #554754] Received 0.26 MB of payload data from client #177 (simulated).
[INFO][12:17:55]: [Server #554754] Selecting client #128 for training.
[INFO][12:17:55]: [Server #554754] Sending the current model to client #128 (simulated).
[INFO][12:17:55]: [Server #554754] Sending 0.26 MB of payload data to client #128 (simulated).
[INFO][12:17:55]: [Server #554754] Selecting client #456 for training.
[INFO][12:17:55]: [Server #554754] Sending the current model to client #456 (simulated).
[INFO][12:17:55]: [Server #554754] Sending 0.26 MB of payload data to client #456 (simulated).
[INFO][12:17:55]: [Client #128] Selected by the server.
[INFO][12:17:55]: [Client #456] Selected by the server.
[INFO][12:17:55]: [Client #128] Loading its data source...
[INFO][12:17:55]: [Client #456] Loading its data source...
[INFO][12:17:55]: Data source: FEMNIST
[INFO][12:17:55]: Data source: FEMNIST
[INFO][12:17:55]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:17:55]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/456.zip.
[INFO][12:17:55]: [Client #128] Dataset size: 158
[INFO][12:17:55]: [Client #128] Sampler: all_inclusive
[INFO][12:17:55]: [Client #128] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:17:55]: [93m[1m[Client #128] Started training in communication round #41.[0m

2.1%
4.1%
6.2%
8.3%
10.4%
12.4%
14.5%
16.6%
18.6%
20.7%
22.8%
24.8%
26.9%
29.0%
31.1%
33.1%
35.2%
37.3%
39.3%
41.4%
43.5%
45.6%
47.6%
49.7%
51.8%
53.8%
55.9%
58.0%
60.0%
62.1%
64.2%
66.3%
68.3%
70.4%
72.5%
74.5%
76.6%
78.7%
80.8%
82.8%
84.9%
87.0%
89.0%
91.1%
93.2%
95.2%
97.3%
99.4%
100.0%[INFO][12:17:55]: Decompressing the dataset downloaded.
[INFO][12:17:55]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/456.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:17:55]: [Client #456] Dataset size: 207
[INFO][12:17:55]: [Client #456] Sampler: all_inclusive
[INFO][12:17:55]: [Client #456] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:17:55]: [93m[1m[Client #456] Started training in communication round #41.[0m

[INFO][12:17:57]: [Client #128] Loading the dataset.
[INFO][12:17:57]: [Client #456] Loading the dataset.
[INFO][12:18:02]: [Client #128] Epoch: [1/5][0/16]	Loss: 0.348345
[INFO][12:18:02]: [Client #128] Epoch: [1/5][10/16]	Loss: 0.637755
[INFO][12:18:02]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][12:18:02]: [Client #456] Epoch: [1/5][0/21]	Loss: 0.943309
[INFO][12:18:03]: [Client #456] Epoch: [1/5][10/21]	Loss: 0.802268
[INFO][12:18:03]: [Client #456] Epoch: [1/5][20/21]	Loss: 2.131051
[INFO][12:18:03]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][12:18:05]: [Client #456] Woke up.
[INFO][12:18:05]: [Client #456] Epoch: [2/5][0/21]	Loss: 1.078920
[INFO][12:18:05]: [Client #456] Epoch: [2/5][10/21]	Loss: 0.551434
[INFO][12:18:06]: [Client #456] Epoch: [2/5][20/21]	Loss: 0.707684
[INFO][12:18:06]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][12:18:08]: [Client #128] Woke up.
[INFO][12:18:08]: [Client #128] Epoch: [2/5][0/16]	Loss: 0.286537
[INFO][12:18:08]: [Client #128] Epoch: [2/5][10/16]	Loss: 0.403897
[INFO][12:18:08]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][12:18:08]: [Client #456] Woke up.
[INFO][12:18:08]: [Client #456] Epoch: [3/5][0/21]	Loss: 0.963094
[INFO][12:18:08]: [Client #456] Epoch: [3/5][10/21]	Loss: 1.138714
[INFO][12:18:08]: [Client #456] Epoch: [3/5][20/21]	Loss: 1.977574
[INFO][12:18:08]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][12:18:11]: [Client #456] Woke up.
[INFO][12:18:11]: [Client #456] Epoch: [4/5][0/21]	Loss: 0.855827
[INFO][12:18:11]: [Client #456] Epoch: [4/5][10/21]	Loss: 1.425014
[INFO][12:18:11]: [Client #456] Epoch: [4/5][20/21]	Loss: 0.899890
[INFO][12:18:11]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][12:18:13]: [Client #128] Woke up.
[INFO][12:18:13]: [Client #128] Epoch: [3/5][0/16]	Loss: 0.161315
[INFO][12:18:13]: [Client #128] Epoch: [3/5][10/16]	Loss: 0.371480
[INFO][12:18:13]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][12:18:14]: [Client #456] Woke up.
[INFO][12:18:14]: [Client #456] Epoch: [5/5][0/21]	Loss: 0.812731
[INFO][12:18:14]: [Client #456] Epoch: [5/5][10/21]	Loss: 0.630318
[INFO][12:18:14]: [Client #456] Epoch: [5/5][20/21]	Loss: 0.258730
[INFO][12:18:14]: [Client #456] Going to sleep for 2.73 seconds.
[INFO][12:18:17]: [Client #456] Woke up.
[INFO][12:18:17]: [Client #456] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_456_554860.pth.
[INFO][12:18:18]: [Client #456] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_456_554860.pth.
[INFO][12:18:18]: [Client #456] Model trained.
[INFO][12:18:18]: [Client #456] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:18:18]: [Server #554754] Received 0.26 MB of payload data from client #456 (simulated).
[INFO][12:18:19]: [Client #128] Woke up.
[INFO][12:18:19]: [Client #128] Epoch: [4/5][0/16]	Loss: 0.519633
[INFO][12:18:19]: [Client #128] Epoch: [4/5][10/16]	Loss: 0.080366
[INFO][12:18:19]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][12:18:24]: [Client #128] Woke up.
[INFO][12:18:24]: [Client #128] Epoch: [5/5][0/16]	Loss: 0.530246
[INFO][12:18:24]: [Client #128] Epoch: [5/5][10/16]	Loss: 0.255017
[INFO][12:18:24]: [Client #128] Going to sleep for 5.33 seconds.
[INFO][12:18:30]: [Client #128] Woke up.
[INFO][12:18:30]: [Client #128] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554853.pth.
[INFO][12:18:30]: [Client #128] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_128_554853.pth.
[INFO][12:18:30]: [Client #128] Model trained.
[INFO][12:18:30]: [Client #128] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:18:30]: [Server #554754] Received 0.26 MB of payload data from client #128 (simulated).
[INFO][12:18:30]: [Server #554754] Selecting client #363 for training.
[INFO][12:18:30]: [Server #554754] Sending the current model to client #363 (simulated).
[INFO][12:18:30]: [Server #554754] Sending 0.26 MB of payload data to client #363 (simulated).
[INFO][12:18:30]: [Server #554754] Selecting client #13 for training.
[INFO][12:18:30]: [Server #554754] Sending the current model to client #13 (simulated).
[INFO][12:18:30]: [Server #554754] Sending 0.26 MB of payload data to client #13 (simulated).
[INFO][12:18:30]: [Client #363] Selected by the server.
[INFO][12:18:30]: [Client #363] Loading its data source...
[INFO][12:18:30]: Data source: FEMNIST
[INFO][12:18:30]: [Client #13] Selected by the server.
[INFO][12:18:30]: [Client #13] Loading its data source...
[INFO][12:18:30]: Data source: FEMNIST
[INFO][12:18:30]: [Client #13] Dataset size: 144
[INFO][12:18:30]: [Client #13] Sampler: all_inclusive
[INFO][12:18:30]: [Client #363] Dataset size: 162
[INFO][12:18:30]: [Client #363] Sampler: all_inclusive
[INFO][12:18:30]: [Client #13] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:18:30]: [Client #363] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:18:30]: [93m[1m[Client #13] Started training in communication round #41.[0m
[INFO][12:18:30]: [93m[1m[Client #363] Started training in communication round #41.[0m
[INFO][12:18:32]: [Client #13] Loading the dataset.
[INFO][12:18:32]: [Client #363] Loading the dataset.
[INFO][12:18:38]: [Client #13] Epoch: [1/5][0/15]	Loss: 0.989295
[INFO][12:18:38]: [Client #363] Epoch: [1/5][0/17]	Loss: 0.830944
[INFO][12:18:38]: [Client #13] Epoch: [1/5][10/15]	Loss: 0.287433
[INFO][12:18:38]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][12:18:38]: [Client #363] Epoch: [1/5][10/17]	Loss: 0.529590
[INFO][12:18:38]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][12:18:38]: [Client #13] Woke up.
[INFO][12:18:38]: [Client #13] Epoch: [2/5][0/15]	Loss: 0.548808
[INFO][12:18:38]: [Client #13] Epoch: [2/5][10/15]	Loss: 0.452340
[INFO][12:18:38]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][12:18:38]: [Client #13] Woke up.
[INFO][12:18:38]: [Client #13] Epoch: [3/5][0/15]	Loss: 0.289766
[INFO][12:18:39]: [Client #13] Epoch: [3/5][10/15]	Loss: 0.931229
[INFO][12:18:39]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][12:18:39]: [Client #13] Woke up.
[INFO][12:18:39]: [Client #13] Epoch: [4/5][0/15]	Loss: 0.068926
[INFO][12:18:39]: [Client #13] Epoch: [4/5][10/15]	Loss: 1.676469
[INFO][12:18:39]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][12:18:39]: [Client #13] Woke up.
[INFO][12:18:39]: [Client #13] Epoch: [5/5][0/15]	Loss: 1.010731
[INFO][12:18:39]: [Client #13] Epoch: [5/5][10/15]	Loss: 0.867572
[INFO][12:18:39]: [Client #13] Going to sleep for 0.26 seconds.
[INFO][12:18:40]: [Client #13] Woke up.
[INFO][12:18:40]: [Client #13] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554860.pth.
[INFO][12:18:40]: [Client #13] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_13_554860.pth.
[INFO][12:18:40]: [Client #13] Model trained.
[INFO][12:18:40]: [Client #13] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:18:40]: [Server #554754] Received 0.26 MB of payload data from client #13 (simulated).
[INFO][12:18:47]: [Client #363] Woke up.
[INFO][12:18:47]: [Client #363] Epoch: [2/5][0/17]	Loss: 0.644552
[INFO][12:18:47]: [Client #363] Epoch: [2/5][10/17]	Loss: 0.403283
[INFO][12:18:47]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][12:18:56]: [Client #363] Woke up.
[INFO][12:18:56]: [Client #363] Epoch: [3/5][0/17]	Loss: 0.545030
[INFO][12:18:56]: [Client #363] Epoch: [3/5][10/17]	Loss: 0.466619
[INFO][12:18:57]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][12:19:06]: [Client #363] Woke up.
[INFO][12:19:06]: [Client #363] Epoch: [4/5][0/17]	Loss: 0.452458
[INFO][12:19:06]: [Client #363] Epoch: [4/5][10/17]	Loss: 0.468444
[INFO][12:19:06]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][12:19:15]: [Client #363] Woke up.
[INFO][12:19:15]: [Client #363] Epoch: [5/5][0/17]	Loss: 1.737507
[INFO][12:19:15]: [Client #363] Epoch: [5/5][10/17]	Loss: 0.134224
[INFO][12:19:15]: [Client #363] Going to sleep for 9.13 seconds.
[INFO][12:19:24]: [Client #363] Woke up.
[INFO][12:19:24]: [Client #363] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_554853.pth.
[INFO][12:19:25]: [Client #363] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_363_554853.pth.
[INFO][12:19:25]: [Client #363] Model trained.
[INFO][12:19:25]: [Client #363] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:19:25]: [Server #554754] Received 0.26 MB of payload data from client #363 (simulated).
[INFO][12:19:25]: [Server #554754] Selecting client #230 for training.
[INFO][12:19:25]: [Server #554754] Sending the current model to client #230 (simulated).
[INFO][12:19:25]: [Server #554754] Sending 0.26 MB of payload data to client #230 (simulated).
[INFO][12:19:25]: [Server #554754] Selecting client #141 for training.
[INFO][12:19:25]: [Server #554754] Sending the current model to client #141 (simulated).
[INFO][12:19:25]: [Server #554754] Sending 0.26 MB of payload data to client #141 (simulated).
[INFO][12:19:25]: [Client #230] Selected by the server.
[INFO][12:19:25]: [Client #230] Loading its data source...
[INFO][12:19:25]: Data source: FEMNIST
[INFO][12:19:25]: [Client #141] Selected by the server.
[INFO][12:19:25]: [Client #141] Loading its data source...
[INFO][12:19:25]: Data source: FEMNIST
[INFO][12:19:25]: [Client #141] Dataset size: 146
[INFO][12:19:25]: [Client #141] Sampler: all_inclusive
[INFO][12:19:25]: [Client #230] Dataset size: 152
[INFO][12:19:25]: [Client #230] Sampler: all_inclusive
[INFO][12:19:25]: [Client #141] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:19:25]: [Client #230] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:19:25]: [93m[1m[Client #141] Started training in communication round #41.[0m
[INFO][12:19:25]: [93m[1m[Client #230] Started training in communication round #41.[0m
[INFO][12:19:27]: [Client #141] Loading the dataset.
[INFO][12:19:27]: [Client #230] Loading the dataset.
[INFO][12:19:32]: [Client #230] Epoch: [1/5][0/16]	Loss: 0.724001
[INFO][12:19:32]: [Client #141] Epoch: [1/5][0/15]	Loss: 1.658290
[INFO][12:19:32]: [Client #230] Epoch: [1/5][10/16]	Loss: 1.037906
[INFO][12:19:32]: [Client #141] Epoch: [1/5][10/15]	Loss: 0.558758
[INFO][12:19:32]: [Client #230] Going to sleep for 9.57 seconds.
[INFO][12:19:32]: [Client #141] Going to sleep for 1.25 seconds.
[INFO][12:19:34]: [Client #141] Woke up.
[INFO][12:19:34]: [Client #141] Epoch: [2/5][0/15]	Loss: 0.858787
[INFO][12:19:34]: [Client #141] Epoch: [2/5][10/15]	Loss: 1.370834
[INFO][12:19:34]: [Client #141] Going to sleep for 1.25 seconds.
[INFO][12:19:35]: [Client #141] Woke up.
[INFO][12:19:35]: [Client #141] Epoch: [3/5][0/15]	Loss: 0.402107
[INFO][12:19:35]: [Client #141] Epoch: [3/5][10/15]	Loss: 0.164533
[INFO][12:19:35]: [Client #141] Going to sleep for 1.25 seconds.
[INFO][12:19:36]: [Client #141] Woke up.
[INFO][12:19:36]: [Client #141] Epoch: [4/5][0/15]	Loss: 0.342450
[INFO][12:19:37]: [Client #141] Epoch: [4/5][10/15]	Loss: 0.876254
[INFO][12:19:37]: [Client #141] Going to sleep for 1.25 seconds.
[INFO][12:19:38]: [Client #141] Woke up.
[INFO][12:19:38]: [Client #141] Epoch: [5/5][0/15]	Loss: 0.088318
[INFO][12:19:38]: [Client #141] Epoch: [5/5][10/15]	Loss: 0.535323
[INFO][12:19:38]: [Client #141] Going to sleep for 1.25 seconds.
[INFO][12:19:39]: [Client #141] Woke up.
[INFO][12:19:39]: [Client #141] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_141_554860.pth.
[INFO][12:19:40]: [Client #141] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_141_554860.pth.
[INFO][12:19:40]: [Client #141] Model trained.
[INFO][12:19:40]: [Client #141] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:19:40]: [Server #554754] Received 0.26 MB of payload data from client #141 (simulated).
[INFO][12:19:42]: [Client #230] Woke up.
[INFO][12:19:42]: [Client #230] Epoch: [2/5][0/16]	Loss: 0.716899
[INFO][12:19:42]: [Client #230] Epoch: [2/5][10/16]	Loss: 0.857349
[INFO][12:19:42]: [Client #230] Going to sleep for 9.57 seconds.
[INFO][12:19:52]: [Client #230] Woke up.
[INFO][12:19:52]: [Client #230] Epoch: [3/5][0/16]	Loss: 1.163650
[INFO][12:19:52]: [Client #230] Epoch: [3/5][10/16]	Loss: 0.163277
[INFO][12:19:52]: [Client #230] Going to sleep for 9.57 seconds.
[INFO][12:20:01]: [Client #230] Woke up.
[INFO][12:20:01]: [Client #230] Epoch: [4/5][0/16]	Loss: 0.359591
[INFO][12:20:02]: [Client #230] Epoch: [4/5][10/16]	Loss: 1.956749
[INFO][12:20:02]: [Client #230] Going to sleep for 9.57 seconds.
[INFO][12:20:11]: [Client #230] Woke up.
[INFO][12:20:11]: [Client #230] Epoch: [5/5][0/16]	Loss: 0.386755
[INFO][12:20:11]: [Client #230] Epoch: [5/5][10/16]	Loss: 0.463989
[INFO][12:20:11]: [Client #230] Going to sleep for 9.57 seconds.
[INFO][12:20:21]: [Client #230] Woke up.
[INFO][12:20:21]: [Client #230] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_230_554853.pth.
[INFO][12:20:22]: [Client #230] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_230_554853.pth.
[INFO][12:20:22]: [Client #230] Model trained.
[INFO][12:20:22]: [Client #230] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:20:22]: [Server #554754] Received 0.26 MB of payload data from client #230 (simulated).
[INFO][12:20:22]: [Server #554754] Selecting client #15 for training.
[INFO][12:20:22]: [Server #554754] Sending the current model to client #15 (simulated).
[INFO][12:20:22]: [Server #554754] Sending 0.26 MB of payload data to client #15 (simulated).
[INFO][12:20:22]: [Server #554754] Selecting client #443 for training.
[INFO][12:20:22]: [Server #554754] Sending the current model to client #443 (simulated).
[INFO][12:20:22]: [Server #554754] Sending 0.26 MB of payload data to client #443 (simulated).
[INFO][12:20:22]: [Client #15] Selected by the server.
[INFO][12:20:22]: [Client #15] Loading its data source...
[INFO][12:20:22]: Data source: FEMNIST
[INFO][12:20:22]: [Client #443] Selected by the server.
[INFO][12:20:22]: [Client #443] Loading its data source...
[INFO][12:20:22]: Data source: FEMNIST
[INFO][12:20:22]: [Client #15] Dataset size: 144
[INFO][12:20:22]: [Client #15] Sampler: all_inclusive
[INFO][12:20:22]: [Client #443] Dataset size: 164
[INFO][12:20:22]: [Client #443] Sampler: all_inclusive
[INFO][12:20:22]: [Client #15] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:20:22]: [Client #443] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:20:22]: [93m[1m[Client #15] Started training in communication round #41.[0m
[INFO][12:20:22]: [93m[1m[Client #443] Started training in communication round #41.[0m
[INFO][12:20:23]: [Client #15] Loading the dataset.
[INFO][12:20:23]: [Client #443] Loading the dataset.
[INFO][12:20:29]: [Client #443] Epoch: [1/5][0/17]	Loss: 0.801482
[INFO][12:20:29]: [Client #15] Epoch: [1/5][0/15]	Loss: 0.541283
[INFO][12:20:29]: [Client #15] Epoch: [1/5][10/15]	Loss: 0.800582
[INFO][12:20:29]: [Client #443] Epoch: [1/5][10/17]	Loss: 0.762543
[INFO][12:20:29]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][12:20:29]: [Client #15] Woke up.
[INFO][12:20:29]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][12:20:29]: [Client #15] Epoch: [2/5][0/15]	Loss: 1.130983
[INFO][12:20:29]: [Client #15] Epoch: [2/5][10/15]	Loss: 0.927827
[INFO][12:20:29]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][12:20:29]: [Client #15] Woke up.
[INFO][12:20:29]: [Client #15] Epoch: [3/5][0/15]	Loss: 0.549197
[INFO][12:20:29]: [Client #15] Epoch: [3/5][10/15]	Loss: 0.320836
[INFO][12:20:29]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][12:20:29]: [Client #15] Woke up.
[INFO][12:20:29]: [Client #15] Epoch: [4/5][0/15]	Loss: 0.406215
[INFO][12:20:29]: [Client #15] Epoch: [4/5][10/15]	Loss: 0.859477
[INFO][12:20:29]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][12:20:29]: [Client #15] Woke up.
[INFO][12:20:30]: [Client #15] Epoch: [5/5][0/15]	Loss: 0.896549
[INFO][12:20:30]: [Client #15] Epoch: [5/5][10/15]	Loss: 0.457735
[INFO][12:20:30]: [Client #15] Going to sleep for 0.03 seconds.
[INFO][12:20:30]: [Client #15] Woke up.
[INFO][12:20:30]: [Client #15] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_15_554853.pth.
[INFO][12:20:30]: [Client #443] Woke up.
[INFO][12:20:30]: [Client #443] Epoch: [2/5][0/17]	Loss: 0.427981
[INFO][12:20:30]: [Client #15] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_15_554853.pth.
[INFO][12:20:30]: [Client #443] Epoch: [2/5][10/17]	Loss: 1.026348
[INFO][12:20:30]: [Client #15] Model trained.
[INFO][12:20:30]: [Client #15] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:20:30]: [Server #554754] Received 0.26 MB of payload data from client #15 (simulated).
[INFO][12:20:30]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][12:20:32]: [Client #443] Woke up.
[INFO][12:20:32]: [Client #443] Epoch: [3/5][0/17]	Loss: 0.040683
[INFO][12:20:32]: [Client #443] Epoch: [3/5][10/17]	Loss: 0.184373
[INFO][12:20:32]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][12:20:33]: [Client #443] Woke up.
[INFO][12:20:33]: [Client #443] Epoch: [4/5][0/17]	Loss: 0.244207
[INFO][12:20:33]: [Client #443] Epoch: [4/5][10/17]	Loss: 0.280182
[INFO][12:20:33]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][12:20:34]: [Client #443] Woke up.
[INFO][12:20:34]: [Client #443] Epoch: [5/5][0/17]	Loss: 0.189956
[INFO][12:20:34]: [Client #443] Epoch: [5/5][10/17]	Loss: 0.546945
[INFO][12:20:34]: [Client #443] Going to sleep for 1.17 seconds.
[INFO][12:20:36]: [Client #443] Woke up.
[INFO][12:20:36]: [Client #443] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][12:20:36]: [Client #443] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_443_554860.pth.
[INFO][12:20:36]: [Client #443] Model trained.
[INFO][12:20:36]: [Client #443] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:20:36]: [Server #554754] Received 0.26 MB of payload data from client #443 (simulated).
[INFO][12:20:36]: [Server #554754] Adding client #485 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #93 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #66 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #441 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #15 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #13 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #352 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #439 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #443 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #141 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #173 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #245 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #301 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #177 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #456 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #320 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #128 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #363 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #230 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Adding client #41 to the list of clients for aggregation.
[INFO][12:20:36]: [Server #554754] Aggregating 20 clients in total.
[0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204028 0.00204085 0.00204057 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204031 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00203937 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00203947 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204053 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204008
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00203952 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.0020399  0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085 0.00204085
 0.00204085 0.00204085 0.00204085 0.00203126]
current clients pool:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 440, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10588127 0.         0.17631524 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.20081456 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13634536
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10128766 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0700604  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16436387 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07860467 0.
 0.         0.         0.38399004 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15339479 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.30562702 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.3048877  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16670784 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15680098 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11007655 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12377133 0.         0.09651668 0.         0.06585367 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15189251
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10231785 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10588127 0.         0.17631524 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.20081456 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.13634536
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.10128766 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0700604  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16436387 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07860467 0.
 0.         0.         0.38399004 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.15339479 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.30562702 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.3048877  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.16670784 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.15680098 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.11007655 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.12377133 0.         0.09651668 0.         0.06585367 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15189251
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10231785 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][12:21:20]: [Server #554754] Global model accuracy: 64.94%

[INFO][12:21:20]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_41.pth.
[INFO][12:21:20]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_41.pth.
[INFO][12:21:20]: [93m[1m
[Server #554754] Starting round 42/100.[0m
[0.002      0.04639175 0.10496183 0.1037182  0.04717531 0.002
 0.09212051 0.0912031  0.08400927 0.002      0.04609822 0.03769968
 0.04374241 0.002      0.04374241 0.10621762 0.002      0.08706468
 0.09207161 0.08769793 0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.09675516 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.046167
 0.002      0.04880988 0.09559676 0.04016585 0.04799514 0.002
 0.002      0.04730693 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08980301 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.04921021
 0.002      0.09273039 0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.11993048
 0.002      0.002      0.09858247 0.002      0.04559704 0.002
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.04738761 0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.04331718 0.10038363 0.04421543 0.002      0.002
 0.04645198 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.04331718 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04799514 0.002      0.04531205 0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.04434994 0.10419397 0.04730139 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.09387521
 0.04579693 0.002      0.07291112 0.002      0.04951397 0.002
 0.08830694 0.0945083  0.04586877 0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.09101317 0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.04502707 0.10344828 0.002      0.002      0.10714286
 0.04502707 0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.002      0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.18775043
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.04617254 0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.08719647 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.09143378 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.07242178 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.08207467 0.10502283 0.0933028  0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.09158558 0.0473034  0.07882535
 0.04617254 0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.04647631 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.04645198 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.04417213 0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.07899256 0.05007728 0.04951397 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.04921021 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.09215799
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.08986835 0.09514925 0.002
 0.09501738 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.09269988
 0.002      0.10419397 0.05415045 0.04659289 0.046167   0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.04374241 0.002      0.04708384 0.002      0.04981774 0.15096419
 0.08321459 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.06287971
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.08872353 0.002      0.02935309 0.1026616  0.002      0.08690614
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.1025974  0.04645198
 0.002      0.002      0.07291112 0.002      0.04769137 0.08943544
 0.08469945 0.04667697 0.002      0.04189228 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.17149479]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.9078e+00  5e+02  1e+00  1e+00
 1:  6.8387e+00  5.9098e+00  6e+00  1e-02  1e-02
 2:  6.9074e+00  6.0722e+00  9e-01  6e-05  6e-05
 3:  6.9077e+00  6.8750e+00  3e-02  6e-07  6e-07
 4:  6.9078e+00  6.9071e+00  6e-04  1e-08  1e-08
 5:  6.9078e+00  6.9074e+00  3e-04  4e-09  4e-09
 6:  6.9077e+00  6.9074e+00  3e-04  5e-08  1e-08
 7:  6.9076e+00  6.9075e+00  2e-04  4e-08  9e-09
 8:  6.9076e+00  6.9075e+00  1e-04  7e-08  2e-08
 9:  6.9075e+00  6.9075e+00  3e-05  9e-08  2e-08
10:  6.9075e+00  6.9075e+00  3e-06  2e-08  4e-09
Optimal solution found.
The calculated probability is:  [2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56473296e-05 2.56499518e-05 2.56426819e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 1.88918749e-04 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 6.74118370e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 4.82462879e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56485696e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56434572e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56481000e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56120798e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56438206e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 4.93129179e-01 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 4.93657866e-01 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 9.93923253e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 8.63830961e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56463650e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 5.91440413e-05 2.56499518e-05
 4.63988805e-05 2.56499518e-05 2.56486361e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56388044e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 4.86630738e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05
 2.56499518e-05 2.56499518e-05 2.56499518e-05 2.56499518e-05]
current clients pool:  [INFO][12:21:20]: [Server #554754] Selected clients: [301 245 264 206 401 467  84 431 479 481  20  30   3 153  29 143 175 478
 237 135]
[INFO][12:21:20]: [Server #554754] Selecting client #301 for training.
[INFO][12:21:20]: [Server #554754] Sending the current model to client #301 (simulated).
[INFO][12:21:20]: [Server #554754] Sending 0.26 MB of payload data to client #301 (simulated).
[INFO][12:21:20]: [Server #554754] Selecting client #245 for training.
[INFO][12:21:20]: [Server #554754] Sending the current model to client #245 (simulated).
[INFO][12:21:20]: [Server #554754] Sending 0.26 MB of payload data to client #245 (simulated).
[INFO][12:21:20]: [Client #301] Selected by the server.
[INFO][12:21:20]: [Client #301] Loading its data source...
[INFO][12:21:20]: Data source: FEMNIST
[INFO][12:21:20]: [Client #245] Selected by the server.
[INFO][12:21:20]: [Client #245] Loading its data source...
[INFO][12:21:20]: Data source: FEMNIST
[INFO][12:21:20]: [Client #301] Dataset size: 152
[INFO][12:21:20]: [Client #301] Sampler: all_inclusive
[INFO][12:21:20]: [Client #301] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:21:20]: [Client #245] Dataset size: 301
[INFO][12:21:20]: [Client #245] Sampler: all_inclusive
[INFO][12:21:20]: [93m[1m[Client #301] Started training in communication round #42.[0m
[INFO][12:21:20]: [Client #245] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:21:20]: [93m[1m[Client #245] Started training in communication round #42.[0m
[INFO][12:21:22]: [Client #301] Loading the dataset.
[INFO][12:21:22]: [Client #245] Loading the dataset.
[INFO][12:21:28]: [Client #301] Epoch: [1/5][0/16]	Loss: 0.434516
[INFO][12:21:28]: [Client #301] Epoch: [1/5][10/16]	Loss: 0.792928
[INFO][12:21:28]: [Client #245] Epoch: [1/5][0/31]	Loss: 1.152997
[INFO][12:21:28]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:21:28]: [Client #245] Epoch: [1/5][10/31]	Loss: 0.943032
[INFO][12:21:28]: [Client #245] Epoch: [1/5][20/31]	Loss: 0.759608
[INFO][12:21:28]: [Client #245] Epoch: [1/5][30/31]	Loss: 0.000050
[INFO][12:21:28]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:21:32]: [Client #245] Woke up.
[INFO][12:21:32]: [Client #245] Epoch: [2/5][0/31]	Loss: 0.365094
[INFO][12:21:32]: [Client #245] Epoch: [2/5][10/31]	Loss: 0.734571
[INFO][12:21:32]: [Client #245] Epoch: [2/5][20/31]	Loss: 1.334739
[INFO][12:21:32]: [Client #245] Epoch: [2/5][30/31]	Loss: 4.716077
[INFO][12:21:32]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:21:32]: [Client #301] Woke up.
[INFO][12:21:32]: [Client #301] Epoch: [2/5][0/16]	Loss: 0.696617
[INFO][12:21:32]: [Client #301] Epoch: [2/5][10/16]	Loss: 0.511862
[INFO][12:21:32]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:21:36]: [Client #245] Woke up.
[INFO][12:21:36]: [Client #245] Epoch: [3/5][0/31]	Loss: 1.160262
[INFO][12:21:36]: [Client #245] Epoch: [3/5][10/31]	Loss: 2.335712
[INFO][12:21:36]: [Client #245] Epoch: [3/5][20/31]	Loss: 2.579878
[INFO][12:21:36]: [Client #245] Epoch: [3/5][30/31]	Loss: 1.265650
[INFO][12:21:36]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:21:36]: [Client #301] Woke up.
[INFO][12:21:36]: [Client #301] Epoch: [3/5][0/16]	Loss: 0.606637
[INFO][12:21:37]: [Client #301] Epoch: [3/5][10/16]	Loss: 0.572147
[INFO][12:21:37]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:21:40]: [Client #245] Woke up.
[INFO][12:21:40]: [Client #245] Epoch: [4/5][0/31]	Loss: 1.328713
[INFO][12:21:40]: [Client #245] Epoch: [4/5][10/31]	Loss: 1.462075
[INFO][12:21:40]: [Client #245] Epoch: [4/5][20/31]	Loss: 1.254696
[INFO][12:21:40]: [Client #245] Epoch: [4/5][30/31]	Loss: 0.476559
[INFO][12:21:40]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:21:41]: [Client #301] Woke up.
[INFO][12:21:41]: [Client #301] Epoch: [4/5][0/16]	Loss: 0.624566
[INFO][12:21:41]: [Client #301] Epoch: [4/5][10/16]	Loss: 0.705178
[INFO][12:21:41]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:21:44]: [Client #245] Woke up.
[INFO][12:21:44]: [Client #245] Epoch: [5/5][0/31]	Loss: 2.514453
[INFO][12:21:44]: [Client #245] Epoch: [5/5][10/31]	Loss: 1.505368
[INFO][12:21:44]: [Client #245] Epoch: [5/5][20/31]	Loss: 0.723020
[INFO][12:21:44]: [Client #245] Epoch: [5/5][30/31]	Loss: 0.870370
[INFO][12:21:44]: [Client #245] Going to sleep for 3.72 seconds.
[INFO][12:21:45]: [Client #301] Woke up.
[INFO][12:21:45]: [Client #301] Epoch: [5/5][0/16]	Loss: 0.140472
[INFO][12:21:45]: [Client #301] Epoch: [5/5][10/16]	Loss: 1.107031
[INFO][12:21:45]: [Client #301] Going to sleep for 4.32 seconds.
[INFO][12:21:47]: [Client #245] Woke up.
[INFO][12:21:48]: [Client #245] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][12:21:48]: [Client #245] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_245_554860.pth.
[INFO][12:21:48]: [Client #245] Model trained.
[INFO][12:21:48]: [Client #245] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:21:48]: [Server #554754] Received 0.26 MB of payload data from client #245 (simulated).
[INFO][12:21:50]: [Client #301] Woke up.
[INFO][12:21:50]: [Client #301] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554853.pth.
[INFO][12:21:50]: [Client #301] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_301_554853.pth.
[INFO][12:21:50]: [Client #301] Model trained.
[INFO][12:21:50]: [Client #301] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:21:50]: [Server #554754] Received 0.26 MB of payload data from client #301 (simulated).
[INFO][12:21:50]: [Server #554754] Selecting client #264 for training.
[INFO][12:21:50]: [Server #554754] Sending the current model to client #264 (simulated).
[INFO][12:21:50]: [Server #554754] Sending 0.26 MB of payload data to client #264 (simulated).
[INFO][12:21:50]: [Server #554754] Selecting client #206 for training.
[INFO][12:21:50]: [Server #554754] Sending the current model to client #206 (simulated).
[INFO][12:21:50]: [Server #554754] Sending 0.26 MB of payload data to client #206 (simulated).
[INFO][12:21:50]: [Client #264] Selected by the server.
[INFO][12:21:50]: [Client #264] Loading its data source...
[INFO][12:21:50]: Data source: FEMNIST
[INFO][12:21:50]: [Client #206] Selected by the server.
[INFO][12:21:50]: [Client #206] Loading its data source...
[INFO][12:21:50]: Data source: FEMNIST
[INFO][12:21:50]: [Client #264] Dataset size: 164
[INFO][12:21:50]: [Client #264] Sampler: all_inclusive
[INFO][12:21:50]: [Client #206] Dataset size: 162
[INFO][12:21:50]: [Client #206] Sampler: all_inclusive
[INFO][12:21:50]: [Client #264] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:21:50]: [Client #206] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:21:50]: [93m[1m[Client #264] Started training in communication round #42.[0m
[INFO][12:21:50]: [93m[1m[Client #206] Started training in communication round #42.[0m
[INFO][12:21:52]: [Client #206] Loading the dataset.
[INFO][12:21:52]: [Client #264] Loading the dataset.
[INFO][12:21:58]: [Client #206] Epoch: [1/5][0/17]	Loss: 0.294564
[INFO][12:21:58]: [Client #264] Epoch: [1/5][0/17]	Loss: 0.656523
[INFO][12:21:58]: [Client #206] Epoch: [1/5][10/17]	Loss: 0.790162
[INFO][12:21:58]: [Client #206] Going to sleep for 0.95 seconds.
[INFO][12:21:58]: [Client #264] Epoch: [1/5][10/17]	Loss: 0.448803
[INFO][12:21:58]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][12:21:59]: [Client #206] Woke up.
[INFO][12:21:59]: [Client #206] Epoch: [2/5][0/17]	Loss: 0.484024
[INFO][12:21:59]: [Client #206] Epoch: [2/5][10/17]	Loss: 0.319545
[INFO][12:21:59]: [Client #206] Going to sleep for 0.95 seconds.
[INFO][12:22:00]: [Client #206] Woke up.
[INFO][12:22:00]: [Client #206] Epoch: [3/5][0/17]	Loss: 0.337921
[INFO][12:22:00]: [Client #206] Epoch: [3/5][10/17]	Loss: 0.521745
[INFO][12:22:00]: [Client #206] Going to sleep for 0.95 seconds.
[INFO][12:22:00]: [Client #264] Woke up.
[INFO][12:22:00]: [Client #264] Epoch: [2/5][0/17]	Loss: 1.384960
[INFO][12:22:00]: [Client #264] Epoch: [2/5][10/17]	Loss: 0.309983
[INFO][12:22:00]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][12:22:01]: [Client #206] Woke up.
[INFO][12:22:01]: [Client #206] Epoch: [4/5][0/17]	Loss: 0.340889
[INFO][12:22:01]: [Client #206] Epoch: [4/5][10/17]	Loss: 0.354285
[INFO][12:22:01]: [Client #206] Going to sleep for 0.95 seconds.
[INFO][12:22:02]: [Client #206] Woke up.
[INFO][12:22:02]: [Client #206] Epoch: [5/5][0/17]	Loss: 0.110668
[INFO][12:22:02]: [Client #206] Epoch: [5/5][10/17]	Loss: 0.888033
[INFO][12:22:02]: [Client #206] Going to sleep for 0.95 seconds.
[INFO][12:22:03]: [Client #264] Woke up.
[INFO][12:22:03]: [Client #264] Epoch: [3/5][0/17]	Loss: 0.300032
[INFO][12:22:03]: [Client #264] Epoch: [3/5][10/17]	Loss: 0.213826
[INFO][12:22:03]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][12:22:03]: [Client #206] Woke up.
[INFO][12:22:03]: [Client #206] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_206_554860.pth.
[INFO][12:22:04]: [Client #206] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_206_554860.pth.
[INFO][12:22:04]: [Client #206] Model trained.
[INFO][12:22:04]: [Client #206] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:22:04]: [Server #554754] Received 0.26 MB of payload data from client #206 (simulated).
[INFO][12:22:05]: [Client #264] Woke up.
[INFO][12:22:05]: [Client #264] Epoch: [4/5][0/17]	Loss: 0.344193
[INFO][12:22:05]: [Client #264] Epoch: [4/5][10/17]	Loss: 0.211049
[INFO][12:22:05]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][12:22:08]: [Client #264] Woke up.
[INFO][12:22:08]: [Client #264] Epoch: [5/5][0/17]	Loss: 0.060563
[INFO][12:22:08]: [Client #264] Epoch: [5/5][10/17]	Loss: 0.463495
[INFO][12:22:08]: [Client #264] Going to sleep for 2.31 seconds.
[INFO][12:22:10]: [Client #264] Woke up.
[INFO][12:22:10]: [Client #264] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_264_554853.pth.
[INFO][12:22:11]: [Client #264] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_264_554853.pth.
[INFO][12:22:11]: [Client #264] Model trained.
[INFO][12:22:11]: [Client #264] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:22:11]: [Server #554754] Received 0.26 MB of payload data from client #264 (simulated).
[INFO][12:22:11]: [Server #554754] Selecting client #401 for training.
[INFO][12:22:11]: [Server #554754] Sending the current model to client #401 (simulated).
[INFO][12:22:11]: [Server #554754] Sending 0.26 MB of payload data to client #401 (simulated).
[INFO][12:22:11]: [Server #554754] Selecting client #467 for training.
[INFO][12:22:11]: [Server #554754] Sending the current model to client #467 (simulated).
[INFO][12:22:11]: [Server #554754] Sending 0.26 MB of payload data to client #467 (simulated).
[INFO][12:22:11]: [Client #401] Selected by the server.
[INFO][12:22:11]: [Client #401] Loading its data source...
[INFO][12:22:11]: Data source: FEMNIST
[INFO][12:22:11]: [Client #467] Selected by the server.
[INFO][12:22:11]: [Client #467] Loading its data source...
[INFO][12:22:11]: Data source: FEMNIST
[INFO][12:22:11]: Downloading the Federated EMNIST dataset with the client datasets pre-partitioned. This may take a while.
[INFO][12:22:11]: Downloading https://jiangzhifeng.s3.us-east-2.amazonaws.com/FEMNIST/train/467.zip.
[INFO][12:22:11]: [Client #401] Dataset size: 151
[INFO][12:22:11]: [Client #401] Sampler: all_inclusive
[INFO][12:22:11]: [Client #401] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:22:11]: [93m[1m[Client #401] Started training in communication round #42.[0m

1.9%
3.9%
5.8%
7.8%
9.7%
11.6%
13.6%
15.5%
17.5%
19.4%
21.3%
23.3%
25.2%
27.2%
29.1%
31.0%
33.0%
34.9%
36.9%
38.8%
40.7%
42.7%
44.6%
46.6%
48.5%
50.4%
52.4%
54.3%
56.3%
58.2%
60.1%
62.1%
64.0%
66.0%
67.9%
69.8%
71.8%
73.7%
75.7%
77.6%
79.5%
81.5%
83.4%
85.4%
87.3%
89.2%
91.2%
93.1%
95.1%
97.0%
98.9%
100.0%[INFO][12:22:11]: Decompressing the dataset downloaded.
[INFO][12:22:11]: Extracting /data/ykang/plato/data/FEMNIST/packaged_data/train/467.zip to /data/ykang/plato/data/FEMNIST/packaged_data/train.
[INFO][12:22:11]: [Client #467] Dataset size: 229
[INFO][12:22:11]: [Client #467] Sampler: all_inclusive
[INFO][12:22:11]: [Client #467] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:22:11]: [93m[1m[Client #467] Started training in communication round #42.[0m

[INFO][12:22:13]: [Client #401] Loading the dataset.
[INFO][12:22:13]: [Client #467] Loading the dataset.
[INFO][12:22:18]: [Client #401] Epoch: [1/5][0/16]	Loss: 1.208991
[INFO][12:22:18]: [Client #467] Epoch: [1/5][0/23]	Loss: 0.322341
[INFO][12:22:18]: [Client #401] Epoch: [1/5][10/16]	Loss: 0.434689
[INFO][12:22:18]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][12:22:18]: [Client #467] Epoch: [1/5][10/23]	Loss: 1.022794
[INFO][12:22:18]: [Client #467] Epoch: [1/5][20/23]	Loss: 1.034275
[INFO][12:22:18]: [Client #467] Going to sleep for 55.87 seconds.
[INFO][12:22:42]: [Client #401] Woke up.
[INFO][12:22:42]: [Client #401] Epoch: [2/5][0/16]	Loss: 0.392721
[INFO][12:22:42]: [Client #401] Epoch: [2/5][10/16]	Loss: 0.818407
[INFO][12:22:42]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][12:23:06]: [Client #401] Woke up.
[INFO][12:23:06]: [Client #401] Epoch: [3/5][0/16]	Loss: 1.226656
[INFO][12:23:06]: [Client #401] Epoch: [3/5][10/16]	Loss: 0.679760
[INFO][12:23:06]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][12:23:14]: [Client #467] Woke up.
[INFO][12:23:14]: [Client #467] Epoch: [2/5][0/23]	Loss: 0.693810
[INFO][12:23:14]: [Client #467] Epoch: [2/5][10/23]	Loss: 1.131402
[INFO][12:23:14]: [Client #467] Epoch: [2/5][20/23]	Loss: 0.393387
[INFO][12:23:14]: [Client #467] Going to sleep for 55.87 seconds.
[INFO][12:23:30]: [Client #401] Woke up.
[INFO][12:23:30]: [Client #401] Epoch: [4/5][0/16]	Loss: 0.834979
[INFO][12:23:30]: [Client #401] Epoch: [4/5][10/16]	Loss: 0.524324
[INFO][12:23:30]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][12:23:54]: [Client #401] Woke up.
[INFO][12:23:54]: [Client #401] Epoch: [5/5][0/16]	Loss: 1.279414
[INFO][12:23:54]: [Client #401] Epoch: [5/5][10/16]	Loss: 0.879316
[INFO][12:23:54]: [Client #401] Going to sleep for 23.65 seconds.
[INFO][12:24:10]: [Client #467] Woke up.
[INFO][12:24:10]: [Client #467] Epoch: [3/5][0/23]	Loss: 0.844664
[INFO][12:24:10]: [Client #467] Epoch: [3/5][10/23]	Loss: 1.051969
[INFO][12:24:11]: [Client #467] Epoch: [3/5][20/23]	Loss: 0.349707
[INFO][12:24:11]: [Client #467] Going to sleep for 55.87 seconds.
[INFO][12:24:17]: [Client #401] Woke up.
[INFO][12:24:17]: [Client #401] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554853.pth.
[INFO][12:24:18]: [Client #401] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_401_554853.pth.
[INFO][12:24:18]: [Client #401] Model trained.
[INFO][12:24:18]: [Client #401] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:24:18]: [Server #554754] Received 0.26 MB of payload data from client #401 (simulated).
[INFO][12:25:06]: [Client #467] Woke up.
[INFO][12:25:07]: [Client #467] Epoch: [4/5][0/23]	Loss: 0.598411
[INFO][12:25:07]: [Client #467] Epoch: [4/5][10/23]	Loss: 0.712784
[INFO][12:25:07]: [Client #467] Epoch: [4/5][20/23]	Loss: 0.575105
[INFO][12:25:07]: [Client #467] Going to sleep for 55.87 seconds.
[INFO][12:26:03]: [Client #467] Woke up.
[INFO][12:26:03]: [Client #467] Epoch: [5/5][0/23]	Loss: 0.654463
[INFO][12:26:03]: [Client #467] Epoch: [5/5][10/23]	Loss: 0.738162
[INFO][12:26:03]: [Client #467] Epoch: [5/5][20/23]	Loss: 1.822325
[INFO][12:26:03]: [Client #467] Going to sleep for 55.87 seconds.
[INFO][12:26:59]: [Client #467] Woke up.
[INFO][12:26:59]: [Client #467] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_467_554860.pth.
[INFO][12:27:00]: [Client #467] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_467_554860.pth.
[INFO][12:27:00]: [Client #467] Model trained.
[INFO][12:27:00]: [Client #467] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:00]: [Server #554754] Received 0.26 MB of payload data from client #467 (simulated).
[INFO][12:27:00]: [Server #554754] Selecting client #84 for training.
[INFO][12:27:00]: [Server #554754] Sending the current model to client #84 (simulated).
[INFO][12:27:00]: [Server #554754] Sending 0.26 MB of payload data to client #84 (simulated).
[INFO][12:27:00]: [Server #554754] Selecting client #431 for training.
[INFO][12:27:00]: [Server #554754] Sending the current model to client #431 (simulated).
[INFO][12:27:00]: [Server #554754] Sending 0.26 MB of payload data to client #431 (simulated).
[INFO][12:27:00]: [Client #431] Selected by the server.
[INFO][12:27:00]: [Client #84] Selected by the server.
[INFO][12:27:00]: [Client #431] Loading its data source...
[INFO][12:27:00]: [Client #84] Loading its data source...
[INFO][12:27:00]: Data source: FEMNIST
[INFO][12:27:00]: Data source: FEMNIST
[INFO][12:27:00]: [Client #84] Dataset size: 127
[INFO][12:27:00]: [Client #84] Sampler: all_inclusive
[INFO][12:27:00]: [Client #84] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:00]: [Client #431] Dataset size: 162
[INFO][12:27:00]: [Client #431] Sampler: all_inclusive
[INFO][12:27:00]: [93m[1m[Client #84] Started training in communication round #42.[0m
[INFO][12:27:00]: [Client #431] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:00]: [93m[1m[Client #431] Started training in communication round #42.[0m
[INFO][12:27:02]: [Client #84] Loading the dataset.
[INFO][12:27:02]: [Client #431] Loading the dataset.
[INFO][12:27:07]: [Client #431] Epoch: [1/5][0/17]	Loss: 0.106228
[INFO][12:27:07]: [Client #84] Epoch: [1/5][0/13]	Loss: 0.993881
[INFO][12:27:07]: [Client #431] Epoch: [1/5][10/17]	Loss: 0.160554
[INFO][12:27:07]: [Client #84] Epoch: [1/5][10/13]	Loss: 1.016716
[INFO][12:27:07]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:27:07]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][12:27:08]: [Client #84] Woke up.
[INFO][12:27:08]: [Client #84] Epoch: [2/5][0/13]	Loss: 1.884766
[INFO][12:27:08]: [Client #84] Epoch: [2/5][10/13]	Loss: 1.300977
[INFO][12:27:08]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][12:27:08]: [Client #431] Woke up.
[INFO][12:27:08]: [Client #431] Epoch: [2/5][0/17]	Loss: 0.397136
[INFO][12:27:08]: [Client #431] Epoch: [2/5][10/17]	Loss: 0.352591
[INFO][12:27:08]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:27:08]: [Client #84] Woke up.
[INFO][12:27:08]: [Client #84] Epoch: [3/5][0/13]	Loss: 0.868886
[INFO][12:27:09]: [Client #84] Epoch: [3/5][10/13]	Loss: 0.660397
[INFO][12:27:09]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][12:27:09]: [Client #431] Woke up.
[INFO][12:27:09]: [Client #431] Epoch: [3/5][0/17]	Loss: 0.624640
[INFO][12:27:09]: [Client #84] Woke up.
[INFO][12:27:09]: [Client #84] Epoch: [4/5][0/13]	Loss: 0.109877
[INFO][12:27:09]: [Client #431] Epoch: [3/5][10/17]	Loss: 0.455367
[INFO][12:27:09]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:27:09]: [Client #84] Epoch: [4/5][10/13]	Loss: 0.329789
[INFO][12:27:09]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][12:27:10]: [Client #84] Woke up.
[INFO][12:27:10]: [Client #84] Epoch: [5/5][0/13]	Loss: 0.587162
[INFO][12:27:10]: [Client #84] Epoch: [5/5][10/13]	Loss: 0.601670
[INFO][12:27:10]: [Client #84] Going to sleep for 0.54 seconds.
[INFO][12:27:10]: [Client #431] Woke up.
[INFO][12:27:10]: [Client #431] Epoch: [4/5][0/17]	Loss: 0.044973
[INFO][12:27:10]: [Client #431] Epoch: [4/5][10/17]	Loss: 0.020910
[INFO][12:27:10]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:27:10]: [Client #84] Woke up.
[INFO][12:27:10]: [Client #84] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_84_554853.pth.
[INFO][12:27:11]: [Client #431] Woke up.
[INFO][12:27:11]: [Client #431] Epoch: [5/5][0/17]	Loss: 0.095794
[INFO][12:27:11]: [Client #431] Epoch: [5/5][10/17]	Loss: 0.828782
[INFO][12:27:11]: [Client #84] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_84_554853.pth.
[INFO][12:27:11]: [Client #84] Model trained.
[INFO][12:27:11]: [Client #84] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:11]: [Server #554754] Received 0.26 MB of payload data from client #84 (simulated).
[INFO][12:27:11]: [Client #431] Going to sleep for 0.83 seconds.
[INFO][12:27:12]: [Client #431] Woke up.
[INFO][12:27:12]: [Client #431] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_554860.pth.
[INFO][12:27:13]: [Client #431] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_431_554860.pth.
[INFO][12:27:13]: [Client #431] Model trained.
[INFO][12:27:13]: [Client #431] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:13]: [Server #554754] Received 0.26 MB of payload data from client #431 (simulated).
[INFO][12:27:13]: [Server #554754] Selecting client #479 for training.
[INFO][12:27:13]: [Server #554754] Sending the current model to client #479 (simulated).
[INFO][12:27:13]: [Server #554754] Sending 0.26 MB of payload data to client #479 (simulated).
[INFO][12:27:13]: [Server #554754] Selecting client #481 for training.
[INFO][12:27:13]: [Server #554754] Sending the current model to client #481 (simulated).
[INFO][12:27:13]: [Server #554754] Sending 0.26 MB of payload data to client #481 (simulated).
[INFO][12:27:13]: [Client #479] Selected by the server.
[INFO][12:27:13]: [Client #481] Selected by the server.
[INFO][12:27:13]: [Client #479] Loading its data source...
[INFO][12:27:13]: [Client #481] Loading its data source...
[INFO][12:27:13]: Data source: FEMNIST
[INFO][12:27:13]: Data source: FEMNIST
[INFO][12:27:13]: [Client #479] Dataset size: 158
[INFO][12:27:13]: [Client #479] Sampler: all_inclusive
[INFO][12:27:13]: [Client #481] Dataset size: 163
[INFO][12:27:13]: [Client #481] Sampler: all_inclusive
[INFO][12:27:13]: [Client #479] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:13]: [Client #481] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:13]: [93m[1m[Client #479] Started training in communication round #42.[0m
[INFO][12:27:13]: [93m[1m[Client #481] Started training in communication round #42.[0m
[INFO][12:27:14]: [Client #481] Loading the dataset.
[INFO][12:27:14]: [Client #479] Loading the dataset.
[INFO][12:27:20]: [Client #481] Epoch: [1/5][0/17]	Loss: 1.306936
[INFO][12:27:20]: [Client #481] Epoch: [1/5][10/17]	Loss: 0.114491
[INFO][12:27:20]: [Client #479] Epoch: [1/5][0/16]	Loss: 0.605924
[INFO][12:27:20]: [Client #481] Going to sleep for 0.48 seconds.
[INFO][12:27:20]: [Client #479] Epoch: [1/5][10/16]	Loss: 0.650725
[INFO][12:27:20]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][12:27:20]: [Client #479] Woke up.
[INFO][12:27:20]: [Client #479] Epoch: [2/5][0/16]	Loss: 0.194058
[INFO][12:27:20]: [Client #479] Epoch: [2/5][10/16]	Loss: 0.851003
[INFO][12:27:20]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][12:27:20]: [Client #479] Woke up.
[INFO][12:27:20]: [Client #479] Epoch: [3/5][0/16]	Loss: 0.216473
[INFO][12:27:21]: [Client #479] Epoch: [3/5][10/16]	Loss: 1.170541
[INFO][12:27:21]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][12:27:21]: [Client #481] Woke up.
[INFO][12:27:21]: [Client #479] Woke up.
[INFO][12:27:21]: [Client #481] Epoch: [2/5][0/17]	Loss: 0.201958
[INFO][12:27:21]: [Client #479] Epoch: [4/5][0/16]	Loss: 0.459531
[INFO][12:27:21]: [Client #481] Epoch: [2/5][10/17]	Loss: 0.550446
[INFO][12:27:21]: [Client #479] Epoch: [4/5][10/16]	Loss: 0.496139
[INFO][12:27:21]: [Client #481] Going to sleep for 0.48 seconds.
[INFO][12:27:21]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][12:27:21]: [Client #479] Woke up.
[INFO][12:27:21]: [Client #479] Epoch: [5/5][0/16]	Loss: 0.399171
[INFO][12:27:21]: [Client #479] Epoch: [5/5][10/16]	Loss: 0.598632
[INFO][12:27:21]: [Client #479] Going to sleep for 0.03 seconds.
[INFO][12:27:21]: [Client #479] Woke up.
[INFO][12:27:21]: [Client #479] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_479_554853.pth.
[INFO][12:27:21]: [Client #481] Woke up.
[INFO][12:27:21]: [Client #481] Epoch: [3/5][0/17]	Loss: 0.324662
[INFO][12:27:21]: [Client #481] Epoch: [3/5][10/17]	Loss: 0.446162
[INFO][12:27:21]: [Client #481] Going to sleep for 0.48 seconds.
[INFO][12:27:22]: [Client #479] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_479_554853.pth.
[INFO][12:27:22]: [Client #479] Model trained.
[INFO][12:27:22]: [Client #479] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:22]: [Server #554754] Received 0.26 MB of payload data from client #479 (simulated).
[INFO][12:27:22]: [Client #481] Woke up.
[INFO][12:27:22]: [Client #481] Epoch: [4/5][0/17]	Loss: 0.436711
[INFO][12:27:22]: [Client #481] Epoch: [4/5][10/17]	Loss: 1.289839
[INFO][12:27:22]: [Client #481] Going to sleep for 0.48 seconds.
[INFO][12:27:23]: [Client #481] Woke up.
[INFO][12:27:23]: [Client #481] Epoch: [5/5][0/17]	Loss: 0.397579
[INFO][12:27:23]: [Client #481] Epoch: [5/5][10/17]	Loss: 0.757687
[INFO][12:27:23]: [Client #481] Going to sleep for 0.48 seconds.
[INFO][12:27:23]: [Client #481] Woke up.
[INFO][12:27:23]: [Client #481] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_481_554860.pth.
[INFO][12:27:24]: [Client #481] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_481_554860.pth.
[INFO][12:27:24]: [Client #481] Model trained.
[INFO][12:27:24]: [Client #481] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:24]: [Server #554754] Received 0.26 MB of payload data from client #481 (simulated).
[INFO][12:27:24]: [Server #554754] Selecting client #20 for training.
[INFO][12:27:24]: [Server #554754] Sending the current model to client #20 (simulated).
[INFO][12:27:24]: [Server #554754] Sending 0.26 MB of payload data to client #20 (simulated).
[INFO][12:27:24]: [Server #554754] Selecting client #30 for training.
[INFO][12:27:24]: [Server #554754] Sending the current model to client #30 (simulated).
[INFO][12:27:24]: [Server #554754] Sending 0.26 MB of payload data to client #30 (simulated).
[INFO][12:27:24]: [Client #30] Selected by the server.
[INFO][12:27:24]: [Client #20] Selected by the server.
[INFO][12:27:24]: [Client #30] Loading its data source...
[INFO][12:27:24]: Data source: FEMNIST
[INFO][12:27:24]: [Client #20] Loading its data source...
[INFO][12:27:24]: Data source: FEMNIST
[INFO][12:27:24]: [Client #30] Dataset size: 150
[INFO][12:27:24]: [Client #30] Sampler: all_inclusive
[INFO][12:27:24]: [Client #20] Dataset size: 144
[INFO][12:27:24]: [Client #20] Sampler: all_inclusive
[INFO][12:27:24]: [Client #30] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:24]: [Client #20] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:27:24]: [93m[1m[Client #30] Started training in communication round #42.[0m
[INFO][12:27:24]: [93m[1m[Client #20] Started training in communication round #42.[0m
[INFO][12:27:26]: [Client #30] Loading the dataset.
[INFO][12:27:26]: [Client #20] Loading the dataset.
[INFO][12:27:31]: [Client #20] Epoch: [1/5][0/15]	Loss: 0.132930
[INFO][12:27:31]: [Client #30] Epoch: [1/5][0/15]	Loss: 2.245960
[INFO][12:27:31]: [Client #20] Epoch: [1/5][10/15]	Loss: 0.340353
[INFO][12:27:31]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][12:27:31]: [Client #30] Epoch: [1/5][10/15]	Loss: 2.065710
[INFO][12:27:32]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][12:27:32]: [Client #20] Woke up.
[INFO][12:27:32]: [Client #20] Epoch: [2/5][0/15]	Loss: 0.761216
[INFO][12:27:32]: [Client #20] Epoch: [2/5][10/15]	Loss: 0.283129
[INFO][12:27:32]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][12:27:32]: [Client #20] Woke up.
[INFO][12:27:32]: [Client #20] Epoch: [3/5][0/15]	Loss: 0.110660
[INFO][12:27:32]: [Client #20] Epoch: [3/5][10/15]	Loss: 1.283083
[INFO][12:27:32]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][12:27:32]: [Client #20] Woke up.
[INFO][12:27:32]: [Client #20] Epoch: [4/5][0/15]	Loss: 0.288779
[INFO][12:27:33]: [Client #20] Epoch: [4/5][10/15]	Loss: 1.046823
[INFO][12:27:33]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][12:27:33]: [Client #20] Woke up.
[INFO][12:27:33]: [Client #20] Epoch: [5/5][0/15]	Loss: 0.635958
[INFO][12:27:33]: [Client #20] Epoch: [5/5][10/15]	Loss: 0.960721
[INFO][12:27:33]: [Client #20] Going to sleep for 0.25 seconds.
[INFO][12:27:33]: [Client #20] Woke up.
[INFO][12:27:33]: [Client #20] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_20_554853.pth.
[INFO][12:27:34]: [Client #20] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_20_554853.pth.
[INFO][12:27:34]: [Client #20] Model trained.
[INFO][12:27:34]: [Client #20] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:27:34]: [Server #554754] Received 0.26 MB of payload data from client #20 (simulated).
[INFO][12:27:39]: [Client #30] Woke up.
[INFO][12:27:39]: [Client #30] Epoch: [2/5][0/15]	Loss: 0.858430
[INFO][12:27:39]: [Client #30] Epoch: [2/5][10/15]	Loss: 1.102178
[INFO][12:27:39]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][12:27:46]: [Client #30] Woke up.
[INFO][12:27:46]: [Client #30] Epoch: [3/5][0/15]	Loss: 1.945508
[INFO][12:27:46]: [Client #30] Epoch: [3/5][10/15]	Loss: 1.688589
[INFO][12:27:46]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][12:27:53]: [Client #30] Woke up.
[INFO][12:27:53]: [Client #30] Epoch: [4/5][0/15]	Loss: 1.422345
[INFO][12:27:54]: [Client #30] Epoch: [4/5][10/15]	Loss: 0.514827
[INFO][12:27:54]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][12:28:01]: [Client #30] Woke up.
[INFO][12:28:01]: [Client #30] Epoch: [5/5][0/15]	Loss: 0.277205
[INFO][12:28:01]: [Client #30] Epoch: [5/5][10/15]	Loss: 1.510144
[INFO][12:28:01]: [Client #30] Going to sleep for 7.21 seconds.
[INFO][12:28:08]: [Client #30] Woke up.
[INFO][12:28:08]: [Client #30] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_30_554860.pth.
[INFO][12:28:09]: [Client #30] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_30_554860.pth.
[INFO][12:28:09]: [Client #30] Model trained.
[INFO][12:28:09]: [Client #30] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:09]: [Server #554754] Received 0.26 MB of payload data from client #30 (simulated).
[INFO][12:28:09]: [Server #554754] Selecting client #3 for training.
[INFO][12:28:09]: [Server #554754] Sending the current model to client #3 (simulated).
[INFO][12:28:09]: [Server #554754] Sending 0.26 MB of payload data to client #3 (simulated).
[INFO][12:28:09]: [Server #554754] Selecting client #153 for training.
[INFO][12:28:09]: [Server #554754] Sending the current model to client #153 (simulated).
[INFO][12:28:09]: [Server #554754] Sending 0.26 MB of payload data to client #153 (simulated).
[INFO][12:28:09]: [Client #3] Selected by the server.
[INFO][12:28:09]: [Client #153] Selected by the server.
[INFO][12:28:09]: [Client #3] Loading its data source...
[INFO][12:28:09]: [Client #153] Loading its data source...
[INFO][12:28:09]: Data source: FEMNIST
[INFO][12:28:09]: Data source: FEMNIST
[INFO][12:28:09]: [Client #3] Dataset size: 165
[INFO][12:28:09]: [Client #3] Sampler: all_inclusive
[INFO][12:28:09]: [Client #153] Dataset size: 159
[INFO][12:28:09]: [Client #153] Sampler: all_inclusive
[INFO][12:28:09]: [Client #3] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:09]: [Client #153] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:09]: [93m[1m[Client #3] Started training in communication round #42.[0m
[INFO][12:28:09]: [93m[1m[Client #153] Started training in communication round #42.[0m
[INFO][12:28:11]: [Client #153] Loading the dataset.
[INFO][12:28:11]: [Client #3] Loading the dataset.
[INFO][12:28:16]: [Client #153] Epoch: [1/5][0/16]	Loss: 0.703595
[INFO][12:28:16]: [Client #3] Epoch: [1/5][0/17]	Loss: 0.371425
[INFO][12:28:16]: [Client #153] Epoch: [1/5][10/16]	Loss: 0.748867
[INFO][12:28:16]: [Client #153] Going to sleep for 1.32 seconds.
[INFO][12:28:16]: [Client #3] Epoch: [1/5][10/17]	Loss: 0.505431
[INFO][12:28:16]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][12:28:16]: [Client #3] Woke up.
[INFO][12:28:16]: [Client #3] Epoch: [2/5][0/17]	Loss: 0.169754
[INFO][12:28:17]: [Client #3] Epoch: [2/5][10/17]	Loss: 0.353724
[INFO][12:28:17]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][12:28:17]: [Client #3] Woke up.
[INFO][12:28:17]: [Client #3] Epoch: [3/5][0/17]	Loss: 0.463858
[INFO][12:28:17]: [Client #3] Epoch: [3/5][10/17]	Loss: 0.265336
[INFO][12:28:17]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][12:28:17]: [Client #3] Woke up.
[INFO][12:28:17]: [Client #3] Epoch: [4/5][0/17]	Loss: 0.335841
[INFO][12:28:17]: [Client #3] Epoch: [4/5][10/17]	Loss: 0.700657
[INFO][12:28:17]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][12:28:17]: [Client #3] Woke up.
[INFO][12:28:17]: [Client #3] Epoch: [5/5][0/17]	Loss: 0.103817
[INFO][12:28:17]: [Client #3] Epoch: [5/5][10/17]	Loss: 0.098384
[INFO][12:28:17]: [Client #3] Going to sleep for 0.00 seconds.
[INFO][12:28:17]: [Client #3] Woke up.
[INFO][12:28:17]: [Client #3] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_3_554853.pth.
[INFO][12:28:18]: [Client #3] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_3_554853.pth.
[INFO][12:28:18]: [Client #3] Model trained.
[INFO][12:28:18]: [Client #3] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:18]: [Server #554754] Received 0.26 MB of payload data from client #3 (simulated).
[INFO][12:28:18]: [Client #153] Woke up.
[INFO][12:28:18]: [Client #153] Epoch: [2/5][0/16]	Loss: 0.084591
[INFO][12:28:18]: [Client #153] Epoch: [2/5][10/16]	Loss: 0.518354
[INFO][12:28:18]: [Client #153] Going to sleep for 1.32 seconds.
[INFO][12:28:19]: [Client #153] Woke up.
[INFO][12:28:19]: [Client #153] Epoch: [3/5][0/16]	Loss: 0.228643
[INFO][12:28:19]: [Client #153] Epoch: [3/5][10/16]	Loss: 0.524868
[INFO][12:28:19]: [Client #153] Going to sleep for 1.32 seconds.
[INFO][12:28:21]: [Client #153] Woke up.
[INFO][12:28:21]: [Client #153] Epoch: [4/5][0/16]	Loss: 0.110274
[INFO][12:28:21]: [Client #153] Epoch: [4/5][10/16]	Loss: 1.293403
[INFO][12:28:21]: [Client #153] Going to sleep for 1.32 seconds.
[INFO][12:28:22]: [Client #153] Woke up.
[INFO][12:28:22]: [Client #153] Epoch: [5/5][0/16]	Loss: 0.267071
[INFO][12:28:22]: [Client #153] Epoch: [5/5][10/16]	Loss: 0.396501
[INFO][12:28:22]: [Client #153] Going to sleep for 1.32 seconds.
[INFO][12:28:24]: [Client #153] Woke up.
[INFO][12:28:24]: [Client #153] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_153_554860.pth.
[INFO][12:28:24]: [Client #153] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_153_554860.pth.
[INFO][12:28:24]: [Client #153] Model trained.
[INFO][12:28:24]: [Client #153] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:24]: [Server #554754] Received 0.26 MB of payload data from client #153 (simulated).
[INFO][12:28:24]: [Server #554754] Selecting client #29 for training.
[INFO][12:28:24]: [Server #554754] Sending the current model to client #29 (simulated).
[INFO][12:28:24]: [Server #554754] Sending 0.26 MB of payload data to client #29 (simulated).
[INFO][12:28:24]: [Server #554754] Selecting client #143 for training.
[INFO][12:28:24]: [Server #554754] Sending the current model to client #143 (simulated).
[INFO][12:28:24]: [Server #554754] Sending 0.26 MB of payload data to client #143 (simulated).
[INFO][12:28:24]: [Client #29] Selected by the server.
[INFO][12:28:24]: [Client #143] Selected by the server.
[INFO][12:28:24]: [Client #29] Loading its data source...
[INFO][12:28:24]: [Client #143] Loading its data source...
[INFO][12:28:24]: Data source: FEMNIST
[INFO][12:28:24]: Data source: FEMNIST
[INFO][12:28:24]: [Client #143] Dataset size: 156
[INFO][12:28:24]: [Client #143] Sampler: all_inclusive
[INFO][12:28:24]: [Client #29] Dataset size: 164
[INFO][12:28:24]: [Client #29] Sampler: all_inclusive
[INFO][12:28:24]: [Client #143] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:24]: [Client #29] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:24]: [93m[1m[Client #143] Started training in communication round #42.[0m
[INFO][12:28:24]: [93m[1m[Client #29] Started training in communication round #42.[0m
[INFO][12:28:26]: [Client #29] Loading the dataset.
[INFO][12:28:26]: [Client #143] Loading the dataset.
[INFO][12:28:32]: [Client #143] Epoch: [1/5][0/16]	Loss: 0.492397
[INFO][12:28:32]: [Client #29] Epoch: [1/5][0/17]	Loss: 0.786758
[INFO][12:28:32]: [Client #143] Epoch: [1/5][10/16]	Loss: 2.125698
[INFO][12:28:32]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][12:28:32]: [Client #29] Epoch: [1/5][10/17]	Loss: 1.360066
[INFO][12:28:32]: [Client #143] Woke up.
[INFO][12:28:32]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][12:28:32]: [Client #143] Epoch: [2/5][0/16]	Loss: 0.898477
[INFO][12:28:32]: [Client #143] Epoch: [2/5][10/16]	Loss: 0.849977
[INFO][12:28:32]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][12:28:32]: [Client #143] Woke up.
[INFO][12:28:32]: [Client #29] Woke up.
[INFO][12:28:32]: [Client #143] Epoch: [3/5][0/16]	Loss: 1.040494
[INFO][12:28:32]: [Client #29] Epoch: [2/5][0/17]	Loss: 0.581584
[INFO][12:28:32]: [Client #143] Epoch: [3/5][10/16]	Loss: 0.391478
[INFO][12:28:32]: [Client #29] Epoch: [2/5][10/17]	Loss: 0.354616
[INFO][12:28:32]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][12:28:32]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][12:28:32]: [Client #143] Woke up.
[INFO][12:28:32]: [Client #143] Epoch: [4/5][0/16]	Loss: 0.023270
[INFO][12:28:32]: [Client #143] Epoch: [4/5][10/16]	Loss: 0.102308
[INFO][12:28:32]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][12:28:32]: [Client #29] Woke up.
[INFO][12:28:32]: [Client #143] Woke up.
[INFO][12:28:32]: [Client #29] Epoch: [3/5][0/17]	Loss: 1.393800
[INFO][12:28:32]: [Client #143] Epoch: [5/5][0/16]	Loss: 0.360347
[INFO][12:28:32]: [Client #29] Epoch: [3/5][10/17]	Loss: 0.360116
[INFO][12:28:32]: [Client #143] Epoch: [5/5][10/16]	Loss: 0.803017
[INFO][12:28:32]: [Client #143] Going to sleep for 0.06 seconds.
[INFO][12:28:32]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][12:28:33]: [Client #143] Woke up.
[INFO][12:28:33]: [Client #143] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_554860.pth.
[INFO][12:28:33]: [Client #29] Woke up.
[INFO][12:28:33]: [Client #29] Epoch: [4/5][0/17]	Loss: 0.127864
[INFO][12:28:33]: [Client #29] Epoch: [4/5][10/17]	Loss: 0.777746
[INFO][12:28:33]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][12:28:33]: [Client #29] Woke up.
[INFO][12:28:33]: [Client #29] Epoch: [5/5][0/17]	Loss: 0.287161
[INFO][12:28:33]: [Client #29] Epoch: [5/5][10/17]	Loss: 0.029948
[INFO][12:28:33]: [Client #143] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_143_554860.pth.
[INFO][12:28:33]: [Client #143] Model trained.
[INFO][12:28:33]: [Client #143] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:33]: [Server #554754] Received 0.26 MB of payload data from client #143 (simulated).
[INFO][12:28:33]: [Client #29] Going to sleep for 0.20 seconds.
[INFO][12:28:33]: [Client #29] Woke up.
[INFO][12:28:33]: [Client #29] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_29_554853.pth.
[INFO][12:28:34]: [Client #29] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_29_554853.pth.
[INFO][12:28:34]: [Client #29] Model trained.
[INFO][12:28:34]: [Client #29] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:34]: [Server #554754] Received 0.26 MB of payload data from client #29 (simulated).
[INFO][12:28:34]: [Server #554754] Selecting client #175 for training.
[INFO][12:28:34]: [Server #554754] Sending the current model to client #175 (simulated).
[INFO][12:28:34]: [Server #554754] Sending 0.26 MB of payload data to client #175 (simulated).
[INFO][12:28:34]: [Server #554754] Selecting client #478 for training.
[INFO][12:28:34]: [Server #554754] Sending the current model to client #478 (simulated).
[INFO][12:28:34]: [Server #554754] Sending 0.26 MB of payload data to client #478 (simulated).
[INFO][12:28:34]: [Client #175] Selected by the server.
[INFO][12:28:34]: [Client #175] Loading its data source...
[INFO][12:28:34]: Data source: FEMNIST
[INFO][12:28:34]: [Client #478] Selected by the server.
[INFO][12:28:34]: [Client #478] Loading its data source...
[INFO][12:28:34]: Data source: FEMNIST
[INFO][12:28:34]: [Client #175] Dataset size: 145
[INFO][12:28:34]: [Client #175] Sampler: all_inclusive
[INFO][12:28:34]: [Client #175] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:34]: [Client #478] Dataset size: 200
[INFO][12:28:34]: [Client #478] Sampler: all_inclusive
[INFO][12:28:34]: [93m[1m[Client #175] Started training in communication round #42.[0m
[INFO][12:28:34]: [Client #478] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:28:34]: [93m[1m[Client #478] Started training in communication round #42.[0m
[INFO][12:28:36]: [Client #175] Loading the dataset.
[INFO][12:28:36]: [Client #478] Loading the dataset.
[INFO][12:28:41]: [Client #478] Epoch: [1/5][0/20]	Loss: 1.649022
[INFO][12:28:41]: [Client #175] Epoch: [1/5][0/15]	Loss: 0.583157
[INFO][12:28:41]: [Client #478] Epoch: [1/5][10/20]	Loss: 1.234499
[INFO][12:28:42]: [Client #175] Epoch: [1/5][10/15]	Loss: 0.401022
[INFO][12:28:42]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][12:28:42]: [Client #478] Going to sleep for 8.18 seconds.
[INFO][12:28:43]: [Client #175] Woke up.
[INFO][12:28:43]: [Client #175] Epoch: [2/5][0/15]	Loss: 1.450787
[INFO][12:28:43]: [Client #175] Epoch: [2/5][10/15]	Loss: 0.344416
[INFO][12:28:43]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][12:28:44]: [Client #175] Woke up.
[INFO][12:28:44]: [Client #175] Epoch: [3/5][0/15]	Loss: 0.300139
[INFO][12:28:44]: [Client #175] Epoch: [3/5][10/15]	Loss: 0.388717
[INFO][12:28:44]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][12:28:46]: [Client #175] Woke up.
[INFO][12:28:46]: [Client #175] Epoch: [4/5][0/15]	Loss: 0.833862
[INFO][12:28:46]: [Client #175] Epoch: [4/5][10/15]	Loss: 0.338300
[INFO][12:28:46]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][12:28:47]: [Client #175] Woke up.
[INFO][12:28:47]: [Client #175] Epoch: [5/5][0/15]	Loss: 0.464153
[INFO][12:28:47]: [Client #175] Epoch: [5/5][10/15]	Loss: 0.348608
[INFO][12:28:47]: [Client #175] Going to sleep for 1.23 seconds.
[INFO][12:28:48]: [Client #175] Woke up.
[INFO][12:28:48]: [Client #175] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554853.pth.
[INFO][12:28:49]: [Client #175] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_175_554853.pth.
[INFO][12:28:49]: [Client #175] Model trained.
[INFO][12:28:49]: [Client #175] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:28:49]: [Server #554754] Received 0.26 MB of payload data from client #175 (simulated).
[INFO][12:28:50]: [Client #478] Woke up.
[INFO][12:28:50]: [Client #478] Epoch: [2/5][0/20]	Loss: 0.659492
[INFO][12:28:50]: [Client #478] Epoch: [2/5][10/20]	Loss: 0.679461
[INFO][12:28:50]: [Client #478] Going to sleep for 8.18 seconds.
[INFO][12:28:58]: [Client #478] Woke up.
[INFO][12:28:58]: [Client #478] Epoch: [3/5][0/20]	Loss: 0.786214
[INFO][12:28:58]: [Client #478] Epoch: [3/5][10/20]	Loss: 1.263151
[INFO][12:28:58]: [Client #478] Going to sleep for 8.18 seconds.
[INFO][12:29:06]: [Client #478] Woke up.
[INFO][12:29:07]: [Client #478] Epoch: [4/5][0/20]	Loss: 0.571118
[INFO][12:29:07]: [Client #478] Epoch: [4/5][10/20]	Loss: 1.064124
[INFO][12:29:07]: [Client #478] Going to sleep for 8.18 seconds.
[INFO][12:29:15]: [Client #478] Woke up.
[INFO][12:29:15]: [Client #478] Epoch: [5/5][0/20]	Loss: 0.448009
[INFO][12:29:15]: [Client #478] Epoch: [5/5][10/20]	Loss: 1.157511
[INFO][12:29:15]: [Client #478] Going to sleep for 8.18 seconds.
[INFO][12:29:23]: [Client #478] Woke up.
[INFO][12:29:23]: [Client #478] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_478_554860.pth.
[INFO][12:29:24]: [Client #478] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_478_554860.pth.
[INFO][12:29:24]: [Client #478] Model trained.
[INFO][12:29:24]: [Client #478] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:29:24]: [Server #554754] Received 0.26 MB of payload data from client #478 (simulated).
[INFO][12:29:24]: [Server #554754] Selecting client #237 for training.
[INFO][12:29:24]: [Server #554754] Sending the current model to client #237 (simulated).
[INFO][12:29:24]: [Server #554754] Sending 0.26 MB of payload data to client #237 (simulated).
[INFO][12:29:24]: [Server #554754] Selecting client #135 for training.
[INFO][12:29:24]: [Server #554754] Sending the current model to client #135 (simulated).
[INFO][12:29:24]: [Server #554754] Sending 0.26 MB of payload data to client #135 (simulated).
[INFO][12:29:24]: [Client #237] Selected by the server.
[INFO][12:29:24]: [Client #135] Selected by the server.
[INFO][12:29:24]: [Client #237] Loading its data source...
[INFO][12:29:24]: [Client #135] Loading its data source...
[INFO][12:29:24]: Data source: FEMNIST
[INFO][12:29:24]: Data source: FEMNIST
[INFO][12:29:24]: [Client #237] Dataset size: 158
[INFO][12:29:24]: [Client #237] Sampler: all_inclusive
[INFO][12:29:24]: [Client #135] Dataset size: 151
[INFO][12:29:24]: [Client #135] Sampler: all_inclusive
[INFO][12:29:24]: [Client #237] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:29:24]: [Client #135] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:29:24]: [93m[1m[Client #237] Started training in communication round #42.[0m
[INFO][12:29:24]: [93m[1m[Client #135] Started training in communication round #42.[0m
[INFO][12:29:26]: [Client #237] Loading the dataset.
[INFO][12:29:26]: [Client #135] Loading the dataset.
[INFO][12:29:31]: [Client #237] Epoch: [1/5][0/16]	Loss: 2.411866
[INFO][12:29:31]: [Client #135] Epoch: [1/5][0/16]	Loss: 1.983353
[INFO][12:29:31]: [Client #237] Epoch: [1/5][10/16]	Loss: 0.973786
[INFO][12:29:31]: [Client #135] Epoch: [1/5][10/16]	Loss: 1.510705
[INFO][12:29:31]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][12:29:31]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:29:31]: [Client #237] Woke up.
[INFO][12:29:31]: [Client #237] Epoch: [2/5][0/16]	Loss: 0.726951
[INFO][12:29:32]: [Client #237] Epoch: [2/5][10/16]	Loss: 0.412966
[INFO][12:29:32]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][12:29:32]: [Client #237] Woke up.
[INFO][12:29:32]: [Client #237] Epoch: [3/5][0/16]	Loss: 0.268886
[INFO][12:29:32]: [Client #237] Epoch: [3/5][10/16]	Loss: 0.351666
[INFO][12:29:32]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][12:29:32]: [Client #237] Woke up.
[INFO][12:29:32]: [Client #237] Epoch: [4/5][0/16]	Loss: 0.138458
[INFO][12:29:32]: [Client #237] Epoch: [4/5][10/16]	Loss: 0.475143
[INFO][12:29:32]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][12:29:32]: [Client #237] Woke up.
[INFO][12:29:32]: [Client #237] Epoch: [5/5][0/16]	Loss: 0.924790
[INFO][12:29:32]: [Client #237] Epoch: [5/5][10/16]	Loss: 0.228070
[INFO][12:29:32]: [Client #237] Going to sleep for 0.02 seconds.
[INFO][12:29:32]: [Client #237] Woke up.
[INFO][12:29:32]: [Client #237] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_237_554853.pth.
[INFO][12:29:33]: [Client #237] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_237_554853.pth.
[INFO][12:29:33]: [Client #237] Model trained.
[INFO][12:29:33]: [Client #237] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:29:33]: [Server #554754] Received 0.26 MB of payload data from client #237 (simulated).
[INFO][12:29:35]: [Client #135] Woke up.
[INFO][12:29:36]: [Client #135] Epoch: [2/5][0/16]	Loss: 0.051991
[INFO][12:29:36]: [Client #135] Epoch: [2/5][10/16]	Loss: 0.639742
[INFO][12:29:36]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:29:40]: [Client #135] Woke up.
[INFO][12:29:40]: [Client #135] Epoch: [3/5][0/16]	Loss: 0.427584
[INFO][12:29:40]: [Client #135] Epoch: [3/5][10/16]	Loss: 1.167306
[INFO][12:29:40]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:29:44]: [Client #135] Woke up.
[INFO][12:29:44]: [Client #135] Epoch: [4/5][0/16]	Loss: 0.279648
[INFO][12:29:44]: [Client #135] Epoch: [4/5][10/16]	Loss: 0.555127
[INFO][12:29:44]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:29:48]: [Client #135] Woke up.
[INFO][12:29:48]: [Client #135] Epoch: [5/5][0/16]	Loss: 0.483700
[INFO][12:29:48]: [Client #135] Epoch: [5/5][10/16]	Loss: 0.608167
[INFO][12:29:48]: [Client #135] Going to sleep for 4.02 seconds.
[INFO][12:29:52]: [Client #135] Woke up.
[INFO][12:29:52]: [Client #135] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_554860.pth.
[INFO][12:29:53]: [Client #135] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_135_554860.pth.
[INFO][12:29:53]: [Client #135] Model trained.
[INFO][12:29:53]: [Client #135] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:29:53]: [Server #554754] Received 0.26 MB of payload data from client #135 (simulated).
[INFO][12:29:53]: [Server #554754] Adding client #3 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #237 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #143 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #479 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #29 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #20 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #481 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #84 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #431 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Adding client #206 to the list of clients for aggregation.
[INFO][12:29:53]: [Server #554754] Aggregating 10 clients in total.
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
type of selected clients:  <class 'numpy.ndarray'>
start aggregating weights
!!!!!!The squared deltas bound of this round are:  [0.         0.         0.06441318 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0804822  0.         0.         0.         0.
 0.         0.         0.         0.         0.11005396 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.140029
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13523591 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11156767 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13500481 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07365151 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09245793 0.
 0.13763573 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
start updating records...
!!!The staleness of this round are:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
local_gradient_bounds:  [0.         0.         0.06441318 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.0804822  0.         0.         0.         0.
 0.         0.         0.         0.         0.11005396 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.140029
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.13523591 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.11156767 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.13500481 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.07365151 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09245793 0.
 0.13763573 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
!!!!!!The aggregation weights of this round are:  [INFO][12:30:43]: [Server #554754] Global model accuracy: 63.93%

[INFO][12:30:43]: [Server #554754] Saving the checkpoint to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_42.pth.
[INFO][12:30:43]: [Server #554754] Model saved to /data/ykang/plato/results/FEMNIST/test/checkpoint/checkpoint_lenet5_42.pth.
[INFO][12:30:43]: [93m[1m
[Server #554754] Starting round 43/100.[0m
[0.002      0.04639175 0.10583708 0.1037182  0.04717531 0.002
 0.09212051 0.0912031  0.08400927 0.002      0.04609822 0.03769968
 0.04374241 0.002      0.04374241 0.10621762 0.002      0.08706468
 0.09207161 0.0923669  0.09654731 0.10550459 0.002      0.08439306
 0.002      0.002      0.09364162 0.08346972 0.10519564 0.09784736
 0.08554913 0.002      0.04945904 0.17626925 0.03809277 0.046167
 0.002      0.04880988 0.09559676 0.04016585 0.04799514 0.002
 0.002      0.04730693 0.002      0.002      0.09044944 0.002
 0.002      0.10025543 0.002      0.002      0.08980301 0.07861272
 0.002      0.002      0.08707865 0.002      0.10419397 0.04197979
 0.04639175 0.04700211 0.08958697 0.002      0.04197979 0.04921021
 0.002      0.09273039 0.04881747 0.002      0.002      0.08719647
 0.002      0.05452128 0.04609822 0.08749329 0.002      0.11993048
 0.002      0.002      0.09858247 0.002      0.04559704 0.08146248
 0.09987113 0.0476047  0.08762322 0.10344828 0.002      0.10492228
 0.1026616  0.10502577 0.04738761 0.08774834 0.08719647 0.08936725
 0.0476047  0.0912721  0.1038961  0.13619403 0.002      0.002
 0.002      0.04331718 0.10038363 0.04421543 0.002      0.002
 0.04645198 0.002      0.002      0.002      0.002      0.04729521
 0.08256881 0.002      0.04331718 0.03990671 0.04912068 0.08415301
 0.09380531 0.002      0.09043794 0.10012674 0.08619749 0.04775772
 0.09184256 0.04799514 0.002      0.04531205 0.002      0.002
 0.04820729 0.15922865 0.002      0.002      0.04920213 0.002
 0.04790782 0.08324206 0.04434994 0.10419397 0.10006414 0.002
 0.14600107 0.09885932 0.002      0.04920213 0.002      0.002
 0.04912068 0.03912931 0.002      0.002      0.002      0.05367412
 0.002      0.04717531 0.002      0.09642401 0.09695817 0.1016624
 0.002      0.10306588 0.08844666 0.002      0.002      0.09387521
 0.04579693 0.002      0.07291112 0.002      0.04951397 0.002
 0.08830694 0.0945083  0.04586877 0.11479029 0.08461948 0.002
 0.002      0.002      0.09770115 0.09101317 0.1012987  0.002
 0.05069552 0.04972711 0.07825862 0.04146152 0.08803006 0.100894
 0.04068412 0.04502707 0.10344828 0.002      0.002      0.10714286
 0.04502707 0.17069243 0.04669497 0.002      0.002      0.002
 0.08429752 0.10391276 0.04197979 0.002      0.002      0.08980716
 0.002      0.08844666 0.04820729 0.100894   0.10454545 0.04717531
 0.03705623 0.10025873 0.09833972 0.05317769 0.002      0.18775043
 0.17719396 0.05207668 0.002      0.04513138 0.09974093 0.05058366
 0.10025873 0.04617254 0.002      0.04197979 0.002      0.06236818
 0.04076878 0.10294118 0.10134702 0.08769793 0.002      0.05058366
 0.08328675 0.08202247 0.05155642 0.002      0.09143378 0.0406749
 0.002      0.09355391 0.09278351 0.04701686 0.002      0.04338963
 0.08870523 0.002      0.002      0.18879415 0.002      0.10672704
 0.07242178 0.04513138 0.002      0.002      0.002      0.1044586
 0.10026212 0.002      0.08207467 0.10502283 0.0933028  0.002
 0.04701686 0.08830694 0.002      0.002      0.002      0.002
 0.002      0.12515964 0.002      0.002      0.05239617 0.04670081
 0.002      0.002      0.1068152  0.09974093 0.10318471 0.0514377
 0.002      0.05058366 0.10136816 0.0460441  0.002      0.002
 0.08998733 0.002      0.04172065 0.09158558 0.0473034  0.07882535
 0.04617254 0.0872886  0.002      0.08849558 0.002      0.002
 0.04912068 0.10600255 0.002      0.08947081 0.07463073 0.08901734
 0.002      0.07994758 0.10519481 0.09909326 0.09773124 0.09675325
 0.10076046 0.04647631 0.002      0.12247191 0.08958697 0.002
 0.002      0.002      0.04952077 0.05452128 0.0996119  0.08457711
 0.04645198 0.002      0.09498525 0.002      0.002      0.09307737
 0.09860051 0.05047923 0.04632588 0.002      0.002      0.002
 0.04417213 0.04888179 0.12719532 0.002      0.002      0.10421995
 0.09055338 0.07899256 0.05007728 0.04951397 0.002      0.09615385
 0.002      0.15220862 0.002      0.002      0.0468841  0.04197979
 0.002      0.002      0.04921021 0.08126036 0.04972711 0.08955224
 0.002      0.08249069 0.002      0.002      0.002      0.09215799
 0.1026616  0.05152926 0.002      0.09849967 0.07937395 0.12520961
 0.002      0.10192308 0.09131545 0.10549872 0.0468841  0.03394662
 0.08695652 0.09423077 0.002      0.10408685 0.002      0.002
 0.04670081 0.002      0.002      0.08986835 0.09514925 0.002
 0.09501738 0.002      0.1003886  0.002      0.04397204 0.002
 0.002      0.08999441 0.05155642 0.002      0.10127389 0.08510638
 0.09897829 0.08543264 0.0955107  0.10608021 0.002      0.002
 0.002      0.002      0.05015974 0.002      0.07940854 0.002
 0.10139417 0.14893617 0.09121061 0.0912721  0.09831824 0.09269988
 0.002      0.10419397 0.05415045 0.04659289 0.10391276 0.05111821
 0.13266998 0.002      0.002      0.10063694 0.09379043 0.1044586
 0.04374241 0.002      0.04708384 0.002      0.04981774 0.15096419
 0.08321459 0.10358056 0.002      0.090743   0.10384615 0.05252918
 0.08057395 0.002      0.002      0.002      0.04489304 0.06287971
 0.002      0.10368957 0.10763209 0.002      0.002      0.002
 0.08872353 0.002      0.02935309 0.1026616  0.002      0.08690614
 0.09926918 0.002      0.04455446 0.002      0.08907104 0.002
 0.09980431 0.08789809 0.07868852 0.002      0.10134702 0.04645198
 0.1045542  0.002      0.07291112 0.002      0.04769137 0.08943544
 0.08469945 0.04667697 0.002      0.04189228 0.10492228 0.002
 0.002      0.0936591  0.0867085  0.04609822 0.0473034  0.002
 0.10447761 0.17149479]
Calculating selection probabitliy ... 
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  6.8876e+00  5e+02  1e+00  1e+00
 1:  6.8187e+00  5.8897e+00  6e+00  1e-02  1e-02
 2:  6.8872e+00  6.0548e+00  9e-01  6e-05  6e-05
 3:  6.8875e+00  6.8559e+00  3e-02  6e-07  6e-07
 4:  6.8876e+00  6.8872e+00  3e-04  6e-09  6e-09
 5:  6.8876e+00  6.8875e+00  3e-06  6e-11  6e-11
Optimal solution found.
The calculated probability is:  [INFO][12:30:44]: [Server #554754] Selected clients: [252 323  56 379 426 422 445 192 222  51]
[INFO][12:30:44]: [Server #554754] Selecting client #252 for training.
[INFO][12:30:44]: [Server #554754] Sending the current model to client #252 (simulated).
[INFO][12:30:44]: [Server #554754] Sending 0.26 MB of payload data to client #252 (simulated).
[INFO][12:30:44]: [Server #554754] Selecting client #323 for training.
[INFO][12:30:44]: [Server #554754] Sending the current model to client #323 (simulated).
[INFO][12:30:44]: [Server #554754] Sending 0.26 MB of payload data to client #323 (simulated).
[INFO][12:30:44]: [Client #252] Selected by the server.
[INFO][12:30:44]: [Client #252] Loading its data source...
[INFO][12:30:44]: Data source: FEMNIST
[INFO][12:30:44]: [Client #323] Selected by the server.
[INFO][12:30:44]: [Client #323] Loading its data source...
[INFO][12:30:44]: Data source: FEMNIST
[INFO][12:30:44]: [Client #323] Dataset size: 154
[INFO][12:30:44]: [Client #323] Sampler: all_inclusive
[INFO][12:30:44]: [Client #323] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:30:44]: [Client #252] Dataset size: 149
[INFO][12:30:44]: [Client #252] Sampler: all_inclusive
[INFO][12:30:44]: [Client #252] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:30:44]: [93m[1m[Client #252] Started training in communication round #43.[0m
[INFO][12:30:44]: [93m[1m[Client #323] Started training in communication round #43.[0m
[INFO][12:30:46]: [Client #323] Loading the dataset.
[INFO][12:30:46]: [Client #252] Loading the dataset.
[INFO][12:30:51]: [Client #323] Epoch: [1/5][0/16]	Loss: 0.737974
[INFO][12:30:51]: [Client #252] Epoch: [1/5][0/15]	Loss: 0.920919
[INFO][12:30:51]: [Client #323] Epoch: [1/5][10/16]	Loss: 0.079173
[INFO][12:30:51]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][12:30:51]: [Client #252] Epoch: [1/5][10/15]	Loss: 1.345910
[INFO][12:30:51]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][12:30:51]: [Client #323] Woke up.
[INFO][12:30:51]: [Client #323] Epoch: [2/5][0/16]	Loss: 0.203394
[INFO][12:30:52]: [Client #323] Epoch: [2/5][10/16]	Loss: 0.415614
[INFO][12:30:52]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][12:30:52]: [Client #323] Woke up.
[INFO][12:30:52]: [Client #323] Epoch: [3/5][0/16]	Loss: 0.076511
[INFO][12:30:52]: [Client #323] Epoch: [3/5][10/16]	Loss: 0.819027
[INFO][12:30:52]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][12:30:52]: [Client #323] Woke up.
[INFO][12:30:52]: [Client #323] Epoch: [4/5][0/16]	Loss: 0.335719
[INFO][12:30:52]: [Client #323] Epoch: [4/5][10/16]	Loss: 0.068876
[INFO][12:30:52]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][12:30:53]: [Client #323] Woke up.
[INFO][12:30:53]: [Client #323] Epoch: [5/5][0/16]	Loss: 0.306427
[INFO][12:30:53]: [Client #323] Epoch: [5/5][10/16]	Loss: 0.275204
[INFO][12:30:53]: [Client #323] Going to sleep for 0.30 seconds.
[INFO][12:30:53]: [Client #323] Woke up.
[INFO][12:30:53]: [Client #323] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_323_554860.pth.
[INFO][12:30:54]: [Client #323] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_323_554860.pth.
[INFO][12:30:54]: [Client #323] Model trained.
[INFO][12:30:54]: [Client #323] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:30:54]: [Server #554754] Received 0.26 MB of payload data from client #323 (simulated).
[INFO][12:31:33]: [Client #252] Woke up.
[INFO][12:31:33]: [Client #252] Epoch: [2/5][0/15]	Loss: 1.723215
[INFO][12:31:33]: [Client #252] Epoch: [2/5][10/15]	Loss: 1.241332
[INFO][12:31:34]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][12:32:16]: [Client #252] Woke up.
[INFO][12:32:16]: [Client #252] Epoch: [3/5][0/15]	Loss: 0.168735
[INFO][12:32:16]: [Client #252] Epoch: [3/5][10/15]	Loss: 1.461415
[INFO][12:32:16]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][12:32:58]: [Client #252] Woke up.
[INFO][12:32:58]: [Client #252] Epoch: [4/5][0/15]	Loss: 0.423619
[INFO][12:32:58]: [Client #252] Epoch: [4/5][10/15]	Loss: 0.304814
[INFO][12:32:58]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][12:33:40]: [Client #252] Woke up.
[INFO][12:33:40]: [Client #252] Epoch: [5/5][0/15]	Loss: 0.329710
[INFO][12:33:40]: [Client #252] Epoch: [5/5][10/15]	Loss: 1.195483
[INFO][12:33:40]: [Client #252] Going to sleep for 42.03 seconds.
[INFO][12:34:23]: [Client #252] Woke up.
[INFO][12:34:23]: [Client #252] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554853.pth.
[INFO][12:34:23]: [Client #252] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_252_554853.pth.
[INFO][12:34:23]: [Client #252] Model trained.
[INFO][12:34:23]: [Client #252] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:34:23]: [Server #554754] Received 0.26 MB of payload data from client #252 (simulated).
[INFO][12:34:23]: [Server #554754] Selecting client #56 for training.
[INFO][12:34:23]: [Server #554754] Sending the current model to client #56 (simulated).
[INFO][12:34:23]: [Server #554754] Sending 0.26 MB of payload data to client #56 (simulated).
[INFO][12:34:23]: [Server #554754] Selecting client #379 for training.
[INFO][12:34:23]: [Server #554754] Sending the current model to client #379 (simulated).
[INFO][12:34:23]: [Server #554754] Sending 0.26 MB of payload data to client #379 (simulated).
[INFO][12:34:23]: [Client #56] Selected by the server.
[INFO][12:34:23]: [Client #56] Loading its data source...
[INFO][12:34:23]: Data source: FEMNIST
[INFO][12:34:23]: [Client #379] Selected by the server.
[INFO][12:34:23]: [Client #379] Loading its data source...
[INFO][12:34:23]: Data source: FEMNIST
[INFO][12:34:23]: [Client #379] Dataset size: 159
[INFO][12:34:23]: [Client #379] Sampler: all_inclusive
[INFO][12:34:23]: [Client #379] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:23]: [93m[1m[Client #379] Started training in communication round #43.[0m
[INFO][12:34:23]: [Client #56] Dataset size: 250
[INFO][12:34:23]: [Client #56] Sampler: all_inclusive
[INFO][12:34:23]: [Client #56] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:23]: [93m[1m[Client #56] Started training in communication round #43.[0m
[INFO][12:34:25]: [Client #379] Loading the dataset.
[INFO][12:34:25]: [Client #56] Loading the dataset.
[INFO][12:34:31]: [Client #379] Epoch: [1/5][0/16]	Loss: 0.691105
[INFO][12:34:31]: [Client #56] Epoch: [1/5][0/25]	Loss: 1.017577
[INFO][12:34:31]: [Client #379] Epoch: [1/5][10/16]	Loss: 1.388915
[INFO][12:34:31]: [Client #56] Epoch: [1/5][10/25]	Loss: 1.112045
[INFO][12:34:31]: [Client #379] Going to sleep for 2.24 seconds.
[INFO][12:34:31]: [Client #56] Epoch: [1/5][20/25]	Loss: 1.432406
[INFO][12:34:31]: [Client #56] Going to sleep for 0.06 seconds.
[INFO][12:34:31]: [Client #56] Woke up.
[INFO][12:34:31]: [Client #56] Epoch: [2/5][0/25]	Loss: 0.555005
[INFO][12:34:31]: [Client #56] Epoch: [2/5][10/25]	Loss: 0.925022
[INFO][12:34:31]: [Client #56] Epoch: [2/5][20/25]	Loss: 0.844532
[INFO][12:34:31]: [Client #56] Going to sleep for 0.06 seconds.
[INFO][12:34:31]: [Client #56] Woke up.
[INFO][12:34:31]: [Client #56] Epoch: [3/5][0/25]	Loss: 0.639941
[INFO][12:34:31]: [Client #56] Epoch: [3/5][10/25]	Loss: 1.146483
[INFO][12:34:31]: [Client #56] Epoch: [3/5][20/25]	Loss: 1.036828
[INFO][12:34:31]: [Client #56] Going to sleep for 0.06 seconds.
[INFO][12:34:31]: [Client #56] Woke up.
[INFO][12:34:31]: [Client #56] Epoch: [4/5][0/25]	Loss: 0.807732
[INFO][12:34:32]: [Client #56] Epoch: [4/5][10/25]	Loss: 0.567081
[INFO][12:34:32]: [Client #56] Epoch: [4/5][20/25]	Loss: 0.200582
[INFO][12:34:32]: [Client #56] Going to sleep for 0.06 seconds.
[INFO][12:34:32]: [Client #56] Woke up.
[INFO][12:34:32]: [Client #56] Epoch: [5/5][0/25]	Loss: 0.640007
[INFO][12:34:32]: [Client #56] Epoch: [5/5][10/25]	Loss: 0.291878
[INFO][12:34:32]: [Client #56] Epoch: [5/5][20/25]	Loss: 0.828481
[INFO][12:34:32]: [Client #56] Going to sleep for 0.06 seconds.
[INFO][12:34:32]: [Client #56] Woke up.
[INFO][12:34:32]: [Client #56] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_56_554853.pth.
[INFO][12:34:33]: [Client #56] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_56_554853.pth.
[INFO][12:34:33]: [Client #56] Model trained.
[INFO][12:34:33]: [Client #56] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:34:33]: [Server #554754] Received 0.26 MB of payload data from client #56 (simulated).
[INFO][12:34:33]: [Client #379] Woke up.
[INFO][12:34:33]: [Client #379] Epoch: [2/5][0/16]	Loss: 1.138974
[INFO][12:34:33]: [Client #379] Epoch: [2/5][10/16]	Loss: 0.373094
[INFO][12:34:33]: [Client #379] Going to sleep for 2.24 seconds.
[INFO][12:34:35]: [Client #379] Woke up.
[INFO][12:34:35]: [Client #379] Epoch: [3/5][0/16]	Loss: 0.516781
[INFO][12:34:35]: [Client #379] Epoch: [3/5][10/16]	Loss: 0.366443
[INFO][12:34:36]: [Client #379] Going to sleep for 2.24 seconds.
[INFO][12:34:38]: [Client #379] Woke up.
[INFO][12:34:38]: [Client #379] Epoch: [4/5][0/16]	Loss: 0.207616
[INFO][12:34:38]: [Client #379] Epoch: [4/5][10/16]	Loss: 0.306985
[INFO][12:34:38]: [Client #379] Going to sleep for 2.24 seconds.
[INFO][12:34:40]: [Client #379] Woke up.
[INFO][12:34:40]: [Client #379] Epoch: [5/5][0/16]	Loss: 0.259984
[INFO][12:34:40]: [Client #379] Epoch: [5/5][10/16]	Loss: 0.270478
[INFO][12:34:40]: [Client #379] Going to sleep for 2.24 seconds.
[INFO][12:34:43]: [Client #379] Woke up.
[INFO][12:34:43]: [Client #379] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_379_554860.pth.
[INFO][12:34:43]: [Client #379] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_379_554860.pth.
[INFO][12:34:43]: [Client #379] Model trained.
[INFO][12:34:43]: [Client #379] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:34:43]: [Server #554754] Received 0.26 MB of payload data from client #379 (simulated).
[INFO][12:34:43]: [Server #554754] Selecting client #426 for training.
[INFO][12:34:43]: [Server #554754] Sending the current model to client #426 (simulated).
[INFO][12:34:43]: [Server #554754] Sending 0.26 MB of payload data to client #426 (simulated).
[INFO][12:34:43]: [Server #554754] Selecting client #422 for training.
[INFO][12:34:43]: [Server #554754] Sending the current model to client #422 (simulated).
[INFO][12:34:43]: [Server #554754] Sending 0.26 MB of payload data to client #422 (simulated).
[INFO][12:34:43]: [Client #426] Selected by the server.
[INFO][12:34:43]: [Client #422] Selected by the server.
[INFO][12:34:43]: [Client #426] Loading its data source...
[INFO][12:34:43]: [Client #422] Loading its data source...
[INFO][12:34:43]: Data source: FEMNIST
[INFO][12:34:43]: Data source: FEMNIST
[INFO][12:34:43]: [Client #426] Dataset size: 160
[INFO][12:34:43]: [Client #426] Sampler: all_inclusive
[INFO][12:34:43]: [Client #426] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:43]: [93m[1m[Client #426] Started training in communication round #43.[0m
[INFO][12:34:43]: [Client #422] Dataset size: 273
[INFO][12:34:43]: [Client #422] Sampler: all_inclusive
[INFO][12:34:43]: [Client #422] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:43]: [93m[1m[Client #422] Started training in communication round #43.[0m
[INFO][12:34:45]: [Client #426] Loading the dataset.
[INFO][12:34:45]: [Client #422] Loading the dataset.
[INFO][12:34:51]: [Client #422] Epoch: [1/5][0/28]	Loss: 2.127760
[INFO][12:34:51]: [Client #426] Epoch: [1/5][0/16]	Loss: 0.564659
[INFO][12:34:51]: [Client #422] Epoch: [1/5][10/28]	Loss: 0.694203
[INFO][12:34:51]: [Client #426] Epoch: [1/5][10/16]	Loss: 0.264052
[INFO][12:34:51]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:34:51]: [Client #422] Epoch: [1/5][20/28]	Loss: 1.218371
[INFO][12:34:51]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:34:51]: [Client #426] Woke up.
[INFO][12:34:51]: [Client #426] Epoch: [2/5][0/16]	Loss: 0.217482
[INFO][12:34:51]: [Client #422] Woke up.
[INFO][12:34:51]: [Client #422] Epoch: [2/5][0/28]	Loss: 0.241878
[INFO][12:34:51]: [Client #426] Epoch: [2/5][10/16]	Loss: 0.389026
[INFO][12:34:51]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:34:51]: [Client #422] Epoch: [2/5][10/28]	Loss: 0.399401
[INFO][12:34:51]: [Client #422] Epoch: [2/5][20/28]	Loss: 0.654647
[INFO][12:34:51]: [Client #426] Woke up.
[INFO][12:34:51]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:34:51]: [Client #426] Epoch: [3/5][0/16]	Loss: 0.838251
[INFO][12:34:51]: [Client #422] Woke up.
[INFO][12:34:51]: [Client #426] Epoch: [3/5][10/16]	Loss: 0.472647
[INFO][12:34:51]: [Client #422] Epoch: [3/5][0/28]	Loss: 0.736590
[INFO][12:34:51]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:34:51]: [Client #422] Epoch: [3/5][10/28]	Loss: 1.289473
[INFO][12:34:51]: [Client #426] Woke up.
[INFO][12:34:51]: [Client #422] Epoch: [3/5][20/28]	Loss: 0.676330
[INFO][12:34:51]: [Client #426] Epoch: [4/5][0/16]	Loss: 0.068194
[INFO][12:34:52]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:34:52]: [Client #426] Epoch: [4/5][10/16]	Loss: 0.227424
[INFO][12:34:52]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:34:52]: [Client #422] Woke up.
[INFO][12:34:52]: [Client #422] Epoch: [4/5][0/28]	Loss: 0.264246
[INFO][12:34:52]: [Client #422] Epoch: [4/5][10/28]	Loss: 0.675037
[INFO][12:34:52]: [Client #426] Woke up.
[INFO][12:34:52]: [Client #426] Epoch: [5/5][0/16]	Loss: 0.210331
[INFO][12:34:52]: [Client #422] Epoch: [4/5][20/28]	Loss: 1.312480
[INFO][12:34:52]: [Client #426] Epoch: [5/5][10/16]	Loss: 0.909401
[INFO][12:34:52]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:34:52]: [Client #426] Going to sleep for 0.13 seconds.
[INFO][12:34:52]: [Client #422] Woke up.
[INFO][12:34:52]: [Client #422] Epoch: [5/5][0/28]	Loss: 0.432496
[INFO][12:34:52]: [Client #426] Woke up.
[INFO][12:34:52]: [Client #426] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_554853.pth.
[INFO][12:34:52]: [Client #422] Epoch: [5/5][10/28]	Loss: 0.604468
[INFO][12:34:52]: [Client #422] Epoch: [5/5][20/28]	Loss: 1.088678
[INFO][12:34:52]: [Client #422] Going to sleep for 0.09 seconds.
[INFO][12:34:52]: [Client #422] Woke up.
[INFO][12:34:52]: [Client #422] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554860.pth.
[INFO][12:34:53]: [Client #426] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_426_554853.pth.
[INFO][12:34:53]: [Client #426] Model trained.
[INFO][12:34:53]: [Client #426] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:34:53]: [Server #554754] Received 0.26 MB of payload data from client #426 (simulated).
[INFO][12:34:53]: [Client #422] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_422_554860.pth.
[INFO][12:34:53]: [Client #422] Model trained.
[INFO][12:34:53]: [Client #422] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:34:53]: [Server #554754] Received 0.26 MB of payload data from client #422 (simulated).
[INFO][12:34:53]: [Server #554754] Selecting client #445 for training.
[INFO][12:34:53]: [Server #554754] Sending the current model to client #445 (simulated).
[INFO][12:34:53]: [Server #554754] Sending 0.26 MB of payload data to client #445 (simulated).
[INFO][12:34:53]: [Server #554754] Selecting client #192 for training.
[INFO][12:34:53]: [Server #554754] Sending the current model to client #192 (simulated).
[INFO][12:34:53]: [Server #554754] Sending 0.26 MB of payload data to client #192 (simulated).
[INFO][12:34:53]: [Client #445] Selected by the server.
[INFO][12:34:53]: [Client #192] Selected by the server.
[INFO][12:34:53]: [Client #445] Loading its data source...
[INFO][12:34:53]: [Client #192] Loading its data source...
[INFO][12:34:53]: Data source: FEMNIST
[INFO][12:34:53]: Data source: FEMNIST
[INFO][12:34:53]: [Client #192] Dataset size: 158
[INFO][12:34:53]: [Client #192] Sampler: all_inclusive
[INFO][12:34:53]: [Client #192] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:53]: [93m[1m[Client #192] Started training in communication round #43.[0m
[INFO][12:34:53]: [Client #445] Dataset size: 292
[INFO][12:34:53]: [Client #445] Sampler: all_inclusive
[INFO][12:34:53]: [Client #445] Received 0.26 MB of payload data from the server (simulated).
[INFO][12:34:53]: [93m[1m[Client #445] Started training in communication round #43.[0m
[INFO][12:34:55]: [Client #192] Loading the dataset.
[INFO][12:34:55]: [Client #445] Loading the dataset.
[INFO][12:35:00]: [Client #192] Epoch: [1/5][0/16]	Loss: 0.423919
[INFO][12:35:00]: [Client #445] Epoch: [1/5][0/30]	Loss: 1.503869
[INFO][12:35:00]: [Client #192] Epoch: [1/5][10/16]	Loss: 2.066002
[INFO][12:35:00]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][12:35:00]: [Client #445] Epoch: [1/5][10/30]	Loss: 0.814845
[INFO][12:35:00]: [Client #192] Woke up.
[INFO][12:35:00]: [Client #192] Epoch: [2/5][0/16]	Loss: 0.311747
[INFO][12:35:00]: [Client #445] Epoch: [1/5][20/30]	Loss: 0.849804
[INFO][12:35:01]: [Client #192] Epoch: [2/5][10/16]	Loss: 0.540790
[INFO][12:35:01]: [Client #445] Going to sleep for 19.49 seconds.
[INFO][12:35:01]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][12:35:01]: [Client #192] Woke up.
[INFO][12:35:01]: [Client #192] Epoch: [3/5][0/16]	Loss: 0.671004
[INFO][12:35:01]: [Client #192] Epoch: [3/5][10/16]	Loss: 0.207473
[INFO][12:35:01]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][12:35:01]: [Client #192] Woke up.
[INFO][12:35:01]: [Client #192] Epoch: [4/5][0/16]	Loss: 0.249080
[INFO][12:35:01]: [Client #192] Epoch: [4/5][10/16]	Loss: 0.354084
[INFO][12:35:01]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][12:35:01]: [Client #192] Woke up.
[INFO][12:35:01]: [Client #192] Epoch: [5/5][0/16]	Loss: 1.488941
[INFO][12:35:01]: [Client #192] Epoch: [5/5][10/16]	Loss: 0.448000
[INFO][12:35:01]: [Client #192] Going to sleep for 0.07 seconds.
[INFO][12:35:01]: [Client #192] Woke up.
[INFO][12:35:01]: [Client #192] Model saved to /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_554860.pth.
[INFO][12:35:02]: [Client #192] Loading a model from /data/ykang/plato/results/FEMNIST/test/model/lenet5_192_554860.pth.
[INFO][12:35:02]: [Client #192] Model trained.
[INFO][12:35:02]: [Client #192] Sent 0.26 MB of payload data to the server (simulated).
[INFO][12:35:02]: [Server #554754] Received 0.26 MB of payload data from client #192 (simulated).
[INFO][12:35:20]: [Client #445] Woke up.
[INFO][12:35:20]: [Client #445] Epoch: [2/5][0/30]	Loss: 0.728483
[INFO][12:35:20]: [Client #445] Epoch: [2/5][10/30]	Loss: 1.260029
[INFO][12:35:20]: [Client #445] Epoch: [2/5][20/30]	Loss: 1.816135
[INFO][12:35:20]: [Client #445] Going to sleep for 19.49 seconds.
slurmstepd-sim: error: *** JOB 2908 ON sim CANCELLED AT 2022-07-08T12:35:35 ***
